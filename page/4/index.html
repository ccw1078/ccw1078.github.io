<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Ccw&#39;s Blogs</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Ccw&#39;s Blogs">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Ccw&#39;s Blogs">
<meta property="og:locale">
<meta property="article:author" content="ccw">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Ccw's Blogs" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ccw&#39;s Blogs</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Python 深度学习" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/08/27/Python%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="article-date">
  <time class="dt-published" datetime="2020-08-27T01:51:00.000Z" itemprop="datePublished">2020-08-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/08/27/Python%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">Python 深度学习</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是深度学习"><a href="#1-什么是深度学习" class="headerlink" title="1. 什么是深度学习"></a>1. 什么是深度学习</h2><h3 id="人工智能、机器学习和深度学习"><a href="#人工智能、机器学习和深度学习" class="headerlink" title="人工智能、机器学习和深度学习"></a>人工智能、机器学习和深度学习</h3><h4 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h4><p>将通常由人类完成的智能任务，尽量实现自动化；</p>
<h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><ul>
<li><p>程序设计：输入数据和计算规则，输出计算结果；</p>
</li>
<li><p>机器学习：输入数据和结果，输出计算规则；</p>
</li>
</ul>
<blockquote>
<p> 机器学习系统是训练出来的，而不是通过程序编写出来的</p>
</blockquote>
<h4 id="从数据中学习表示"><a href="#从数据中学习表示" class="headerlink" title="从数据中学习表示"></a>从数据中学习表示</h4><p>机器学习的三要素：输入数据点、预期输出的示例、衡量算法好坏的方法；</p>
<p>机器学习的核心：在预先定义的一组方法（即 hypothesis space 假设空间）中，找到一种有意义的变换数据的方法，使得数据转换成更加有用的表示 representation ；</p>
<h4 id="深度学习之“深度”"><a href="#深度学习之“深度”" class="headerlink" title="深度学习之“深度”"></a>深度学习之“深度”</h4><p>深度 depth 是指学习的过程，涉及很多层级的堆叠，所以深度学习也叫 hierarchical representation learning 层级表示学习（或 layer representation learning 分层表示学习）；</p>
<p>分层的做法，来源于神经网络模型（neural network）启发，但事实上它跟人类大脑的神经网络模型，并没有任何关系；只是恰好用这个启发来命名这个学习模型而已；</p>
<p>传统的机器学习因只注重1-2层的数据表示，因此有时也叫做浅层学习 shallow learning；</p>
<p>深度学习可以简单理解为：学习数据表示的多级方法；每一级的方法，就像是一个蒸馏的操作，虽然每经过一级数据变得越来越少，但纯度却越来越高，跟解决任务越来越相关；</p>
<h4 id="用三张图理解深度学习的工作原理"><a href="#用三张图理解深度学习的工作原理" class="headerlink" title="用三张图理解深度学习的工作原理"></a>用三张图理解深度学习的工作原理</h4><p>权重 weight ：神经网络中，某一层对数据所做的变换操作，存储于该层的权重中；权重是一组数字，它是该层操作的参数 parameter ；每层的变换，由权重来实现参数化 parameterize ；</p>
<p>学习的过程，即为神经网络中的所有层，找到最合适的一组权重值，使得输入的示例，能够与目标一一对应；</p>
<p>损失函数 loss function ：用于计算神经网络的预测值与真实目标值之间的距离值；损失函数有时也叫目标函数 objective function；</p>
<p>深度学习技巧：根据损失函数计算出的距离值，作为反馈信号，对权重进行微调，以降低损失值；这种调节由优化器 optimizer 来完成，它实现了反向传播 backpropagation 的算法；</p>
<p>整个调节的过程，称为训练循环；通过对几千个示例，做几十次的循环后，就有可能得到损失最小的网络模型；</p>
<h3 id="机器学习简史"><a href="#机器学习简史" class="headerlink" title="机器学习简史"></a>机器学习简史</h3><h4 id="概率建模"><a href="#概率建模" class="headerlink" title="概率建模"></a>概率建模</h4><p>朴素贝叶斯算法：基于朴素贝叶斯定理的分类器；</p>
<p>logistic regression 逻辑回归（简称 logreg）：名字虽然有回归两个字，其实是一种分类算法，而不是回归算法；</p>
<h4 id="早期神经网络"><a href="#早期神经网络" class="headerlink" title="早期神经网络"></a>早期神经网络</h4><p>Yann LeCun 使用卷积神经网络+反向传播算法，应用于美国邮政的手写邮政编码识别；早期的神经网络算法目前都被一些更现代的算法取代了；</p>
<h4 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h4><p>核方法是一种分类算法，其中最有名的是 SVM 支持向量机 support vector machine；其致力于在两级不同类别的数据集合中，寻找一个良好的决策平面（边界），从而解决分类问题；</p>
<p>步骤：</p>
<ul>
<li>将数据映射到高维空间；</li>
<li>在高维空间中找到一个超平面，该平面使得两个类别的数据点之间的距离最大化；</li>
</ul>
<p>kernel trick 核技巧：由于映射高维空间很抽象，因此，可以通过核函数（kernel function）来简化这个过程；核函数的原理是抛弃高维空间，转而求数据点对之间的距离；之后根据求得的距离结果，来寻找超平面；但这也有缺点：当数据集很大时，或需要解决感知问题时，这一思路变得不那么可行；因为如果想将 SVM 应用于感知表示，则需要先提取有用的表示（即特征工程），但这个提取过程比较麻烦，而且也不太稳定，从而限制了 SVM 的使用场景;</p>
<h4 id="决策树、随机森林与梯度提升机"><a href="#决策树、随机森林与梯度提升机" class="headerlink" title="决策树、随机森林与梯度提升机"></a>决策树、随机森林与梯度提升机</h4><p>decision tree 决策树：挑出一个待选特征，对输入数据点进行分类，如果分类的数据符合目标，则特征有意义，如果不符合，则没有意义；通过对这个过程的反复迭代，最终得到由特征判断组成的整个决策树；另外决策树也可用于给定输入预测输出；</p>
<p>random forest 随机森林：一种决策树学习算法；它首先构建很多决策树，然后再把这些决策集成起来；对于浅层学习任务，它几乎总是第二好的算法；</p>
<ul>
<li>步骤：<ul>
<li>数据随机抽取；</li>
<li>待选特征随机抽取；</li>
<li>对各子树的分类结果进行投票，量多者胜；</li>
</ul>
</li>
<li>思想：相对于决策树寻找最厉害的专家的策略，随机森林的策略为：三个臭皮匠，顶个诸葛亮；</li>
</ul>
<p>gradient boosting machine 梯度提升机：将多个弱预测模型集成起来，并通过训练循环不断改进弱预测模型；最后与决策树方法进行结合得到模型，其性质与随机森林类似，但效果更好；对于非感知问题，基本上是目前最适用的算法；</p>
<h4 id="深度学习的不同点"><a href="#深度学习的不同点" class="headerlink" title="深度学习的不同点"></a>深度学习的不同点</h4><p>通过渐进的、逐层的方式，形成越来越复杂的表示；（貌似需要记录各层之间的依赖关系）</p>
<p>模型可以在同一时间共同学习所有表示层，而不是依次渐进的学习（基于前一步的不同层之间的依赖关系进行调整，但貌似计算量也很大）</p>
<p>决策树、随机森林和梯度提升机，都涉及到特征的提取（即特征工程），但深度学习则绕过了这个问题，它通过假设空间对每一层做简单变换，然后再根据反向传播不断微调，最终取得最好的权重值组合；（不过话说回来，怎么感觉假设空间与特征工程其实是一回事？差别在于后者没有记录依赖关系，学习的效率降低了）;</p>
<h4 id="机器学习现状"><a href="#机器学习现状" class="headerlink" title="机器学习现状"></a>机器学习现状</h4><p>梯度提升机的常用框架：XGBoost；</p>
<p>深度学习的常用框架：Keras;</p>
<p>深度学习的两个核心思想卷积神经网络和反向传播，在70年代就已经提出了，但由于硬件和数据集的瓶颈，直到最近几年才开始发挥影响力；</p>
<ul>
<li>硬件：CPU 的设计面向复杂的计算场景，使用多种指令集；GPU 的设计面向单一的使用场景，所以在特定场景中，其计算效率要远远高于 CPU；Google 则研发 TPU 进行专用的运算；</li>
<li>数据：由于互联网的普及，使得数据的收集变得非常容易；</li>
<li>算法：神经需要足够多的层数，才能发挥作用；早期没有找到有效增加层数进行梯度传播的办法；最近几年，越来越多的算法被提出，得以实现足够多的层数；包括：更好的神经层激活函数 activation function，更好的权重初始化方案 weight initialization scheme；更好的优化方案 optimization scheme；2014年以后，又增加了更好的覆盖率传播方法，例如：批标准化、残差连接、深度可分离卷积等；</li>
</ul>
<h2 id="2-神经网络的数学基础"><a href="#2-神经网络的数学基础" class="headerlink" title="2. 神经网络的数学基础"></a>2. 神经网络的数学基础</h2><h3 id="初识神经网络"><a href="#初识神经网络" class="headerlink" title="初识神经网络"></a>初识神经网络</h3><p>分类问题中的某个类别叫作类 class，数据点叫做样本 sample，标签 label 用来表示样本对应某个类；</p>
<p>训练集（trainng set） 一般由 train_images 和 train_labels 组成；测试集（test set） 一般用 test_images 和 test_labels 组成；</p>
<p>神经网络的核心组件是层 layer，它是一个数据处理模块，它从输入数据中提取表示，有点像是一个数据过滤器，或者数据蒸馏器；大多数深度学习是将多个层链接起来，实现渐进式的数据蒸馏 data distillation；</p>
<p>在训练和测试过程中，需要指定需要监控的指标 metric，以便网络可以根据指标进行改进，拟合（fit）模型；</p>
<p>过拟合：学习模型是测试集上面的表现比训练集差；</p>
<h3 id="神经网络的数据表示"><a href="#神经网络的数据表示" class="headerlink" title="神经网络的数据表示"></a>神经网络的数据表示</h3><p>张量 tensor 是一种数据结构，用来存储输入网络的数据对象；张量是一种数字容器，可以看做是矩阵在任意维度的推广；</p>
<p>仅包含一个数字的张量，称为标量 scalar（也叫标量张量，零维张量，0D张量），标量张量的轴数为0；</p>
<p>数字组成的数组，叫做向量 vertor（也叫一维张量，1D张量），向量的轴数为1；向量（即数组）有几个元素，称为几D向量，例如5个元素称为5D向量；</p>
<p>向量组成的数组，叫做矩阵（也叫二维张量，2D张量），矩阵的轴数为2；</p>
<p>多个矩阵组成的数级，可以得到3D张量；多个3D张量组成的数组，可以得到 4D 张量，以此类推；多数深度学习使用 0D - 4D 张量的数据结构，视频处理则可能用 5D 张量；</p>
<p>张量的三个关键属性：轴数（即阶数，arr.ndim），形状（每个轴的维度大小, arr.shape）、数据类型(arr.dtype)；</p>
<p>张量切片：选择张量的特定元素；所有张量的第一个轴（即0轴）用于做样本轴（sample axis，也叫样本维度）；</p>
<p>深度学习模型为提高计算速度，会将数据集分成多个小批量，并行处理；每个小批量的第一个轴叫做批量轴或批量维度（其实本质和样本轴一样，只是数据量大小不同）；</p>
<p>几种常见的数据张量类型：</p>
<ul>
<li>2D张量（即矩阵）：samples, features</li>
<li>时间序列：samples, timestamps, features</li>
<li>图像：samples, height, width, channels</li>
<li>视频：samples, frames, height, width, channels</li>
</ul>
<h3 id="张量运算"><a href="#张量运算" class="headerlink" title="张量运算"></a>张量运算</h3><p>逐元素（element-wise）运算：该运算独立应用于张量中的每个元素（因此这种运算非常适合用来做并行计算）；</p>
<p>广播：将轴数较小的张量，与轴数较大的张量进行运算时，小张量会在大张量的其他轴上进行广播；</p>
<p>张量点积 tensor product：其实它就是矩阵的乘法，背后的本质是求解多项式的应用；注意别跟逐元素的乘法弄混了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827103156.png"></p>
<p>张量变形 tensor reshaping：保持元素数量不变，但改变形状，也即 numpy 里面的 reshape，以及转置 np.transpose</p>
<p>张量运算可以视为几何空间中的运算；神经网络对输入数据在几何空间中做各种变换尝试，最终将原本复杂混合的数据，转换成清晰分类的数据（红纸蓝纸揉成一团后再解开的例子）；</p>
<h3 id="基于梯度的优化"><a href="#基于梯度的优化" class="headerlink" title="基于梯度的优化"></a>基于梯度的优化</h3><p>output &#x3D; relu(dot(W, input), b)，其中 W，b 都是张量，属于该层的属性，分别对应 kernel 属性和 bias 属性；二者即该层的可训练参数 trainable parameter，或者叫权重 weight；一开始这些权重取很小的初始值，即随机初始化 random initialization；</p>
<p>抽取训练样本 x 和对应的目标样本 y 组成数据批量，将 x 输入网络运行得到预测值 y_pred；这一步叫做正向传播 forward pass；</p>
<p>由于网络中所有的运算都是可微的，因此可以计算损失相对于网络系数的梯度（张量运算的导数），之后按梯度的反方向改变网络系统大小；这一步叫做反向传播 backward pass；</p>
<p>随机梯度下降 stochastic gradient descent（SGD）：将参数沿着梯度的反方向随机移动一点点，从而使得损失减少一点点；</p>
<p>为了避免局部最小值和收敛速度问题，引入动量的概念：根据动量的概念，每次移动参数的幅度，要同时考虑加速度（斜率值）和当前速度（来自于之前的加速度），这样可以跳过局部最小点，同时加快收敛的速度；</p>
<p>链式法则：基于求导恒等式 (f(g(x))<code> = f</code>(g(x)) * g&#96;(x)，推导出反向传播算法 back-propagation（也叫反式微分 reverse-mode differentiation），即根据最终损失值，从最顶层开始到最低层，推导每个参数对损失值的贡献大小；此处引入了符号微分 symbolic differentiation 算法，该算法可以实现：给定一个运算链，并且已知每个运算环节的导数，则可以求得整个运算链的梯度函数；</p>
<h2 id="3-神经网络入门"><a href="#3-神经网络入门" class="headerlink" title="3. 神经网络入门"></a>3. 神经网络入门</h2><h3 id="神经网络剖析"><a href="#神经网络剖析" class="headerlink" title="神经网络剖析"></a>神经网络剖析</h3><h4 id="层：深度学习的基础组件"><a href="#层：深度学习的基础组件" class="headerlink" title="层：深度学习的基础组件"></a>层：深度学习的基础组件</h4><p>不同的张量格式的不同的数据类型通常会使用到不同各类的层进行处理；</p>
<ul>
<li>向量数据(2D)：密集层，也叫全连接层或密集连接层</li>
<li>图像数据(4D)：二维卷积层</li>
<li>序列数据(3D)：循环层</li>
</ul>
<p>层兼容性：每一层只接收特定形状的输入，产生特定形状的输出；</p>
<h4 id="模型：层构成的网络"><a href="#模型：层构成的网络" class="headerlink" title="模型：层构成的网络"></a>模型：层构成的网络</h4><p>它有很多种结构，常见的如线性堆叠、双分支（two-branch）、多头（multi-head）、Inception模块等；网络的拓扑结构定义了一个假设空间，也因此限定了一系列特定的张量运算；选择合适有效的网络结构，更像是一门艺术而科学；</p>
<h4 id="损失函数与优化器：配置学习过程的关键"><a href="#损失函数与优化器：配置学习过程的关键" class="headerlink" title="损失函数与优化器：配置学习过程的关键"></a>损失函数与优化器：配置学习过程的关键</h4><p>损失函数：选择正确的损失函数对解决问题至关重要，对于常见的问题，已经有一些现成的目标函数可以使用，例如二分类问题使用二元交叉熵(binary crossentropy)，序列问题使用联结主义时序分类(connectionist temporal classification)；多分类问题使用分类交叉熵(categorical crossentropy)；回归问题使用均方误差(mean-squared error)；只有真正面对全新问题的时候，才需要自主开发新的目标函数；</p>
<p>具有多个输出的神经网络，可能具有多个损失函数，但只能有一个损失标量值，因此需要将多个损失函数的结果取平均；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827111845.png"></p>
<h3 id="Keras-简介"><a href="#Keras-简介" class="headerlink" title="Keras 简介"></a>Keras 简介</h3><p>Keras 是一模型库，因此它可以和张量库（如 TensorFlow, Theano, CNTK 等）配合使用，简化了用户的学习和上手成本；</p>
<h4 id="使用-Keras-开发：概述"><a href="#使用-Keras-开发：概述" class="headerlink" title="使用 Keras 开发：概述"></a>使用 Keras 开发：概述</h4><p>典型的工作流程：</p>
<ul>
<li>定义训练数据：输入张量和目标张量</li>
<li>定义模型（即由层组成的网络），将输入映射到目标；</li>
<li>配置学习过程：选择损失函数、优化器和过程中需要监控的指标；</li>
<li>调用模型的 fit 方法在训练数据上进行迭代；</li>
</ul>
<p>定义模型的两种方法</p>
<ul>
<li>使用 Sequential 类：用于层的线性堆叠，属于目前最常见的网络架构；</li>
<li>使用 函数式 API：通过有向无环图，用于构建任何形式的架构；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Sequential 构建模型</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用函数式 API 构建模型</span></span><br><span class="line">input_tensor = layers.Input(shape=(<span class="number">784</span>,))</span><br><span class="line">x = layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>)(input_tensor)</span><br><span class="line">output_tensor = layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>)(x)</span><br><span class="line">model = models.Model(inputs=input_tensor, outputs=output_tensor)</span><br></pre></td></tr></table></figure>

<p>配置学习过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>), </span><br><span class="line">	loss=<span class="string">&quot;mse&quot;</span>, </span><br><span class="line">	metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">	)</span><br></pre></td></tr></table></figure>

<p>调用 fit 方法进行迭代训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(input_tensor, target_tensor, batch_size=<span class="number">128</span>, epoch=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>深度学习的原理并不复杂，最难的部分可能是根据待解决的问题，找到最适合的模型；对于常见的问题，前人们已经找到和总结了很多高效的模型；但在实际业务过程中，有可能会遇到不完全相同的问题，此时便需要在前人模型的基础，进一步调整和测试；这一步才是最难的，搞不好整个过程中都需要有一定的运气成分；</p>
</blockquote>
<h3 id="建立深度学习工作站"><a href="#建立深度学习工作站" class="headerlink" title="建立深度学习工作站"></a>建立深度学习工作站</h3><p>推荐使用 Linux 系统 + GPU 机器；</p>
<p>虽然书上提供了在本地原生安装的方法，但其实更好的安装方式应该是使用 Docker 镜像，但可惜书上并没有提到；</p>
<h3 id="电影评论分类：二分类问题"><a href="#电影评论分类：二分类问题" class="headerlink" title="电影评论分类：二分类问题"></a>电影评论分类：二分类问题</h3><h4 id="导入-IMDB-数据集"><a href="#导入-IMDB-数据集" class="headerlink" title="导入 IMDB 数据集"></a>导入 IMDB 数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处导入 keras 已经提前内置的 imdb 数据集</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="comment"># imdb 对象的 load_data 方法可导入训练数据和测试数据，元组格式，每个元组由数据和标签两部分组成，一一对应</span></span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>

<h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><p>导入的数据只是列表，但 keras 只接收张量格式，因此需要将数据从列表格式转变成张量格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将列表转成张量，若存在某个单词，则在对应的索引位置标记1</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vectorize_sequences</span>(<span class="params">sequences, demension=<span class="number">10000</span></span>):</span><br><span class="line">	results = np.zeros((<span class="built_in">len</span>(sequences), demension))</span><br><span class="line">	<span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">		results[i, sequence] = <span class="number">1.</span></span><br><span class="line">	<span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">tensor_train_data = vectorize_sequences(train_data)</span><br><span class="line">tensor_test_data = vectorize_sequences(test_data)</span><br><span class="line"></span><br><span class="line">tensor_train_labels = np.asarray(train_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">tensor_test_labels = np.asarray(test_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始构建网络</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line"><span class="comment"># 此处的16表示使用16的隐藏单元，用来表示结果空间，16即表示空间有16个维度</span></span><br><span class="line"><span class="comment"># 维度太高不一定好，一来计算量更大，二来有可能和训练数据过耦合，导致预测效果并不好</span></span><br><span class="line"><span class="comment"># 维度太低则有可能没有提到出最有用的特征，导致预测准确率下降</span></span><br><span class="line"><span class="comment"># 激活函数 relu 用来对计算结果中的负值归零，正值则保持不变</span></span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 由于最终的目标是一个标量，1表示正面评论，0表示负面评论</span></span><br><span class="line"><span class="comment"># 因此模型的最终输出的那层只需设置一个隐藏单元，这样就将计算结果映射到一个维度的标量中</span></span><br><span class="line"><span class="comment"># 激活函数 sigmoid 用来对计算结果进行归一处理，这样可以表示最终的概率</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line"><span class="comment"># 如果没有激活函数，则层的计算将只是 output = dot(W, input) + b 的矩阵点积计算，其结果</span></span><br><span class="line"><span class="comment"># 将只是对数据进行简单的线性仿射变换，并没有实质性的改变数据的空间映射；而通过引入激活函数</span></span><br><span class="line"><span class="comment"># 计算结果将不再是简单的线性变换，变成了非线性变换，因此空间映射发生了改变</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处的模型编译使用了默认内置的优化器、损失函数和指标器，但是，这三个东西也是可以</span></span><br><span class="line"><span class="comment"># 自定义的，即自定义优化函数、损失函数、衡量指标等；</span></span><br><span class="line"><span class="comment"># 此处使用的损失函数为二元交叉熵 binary_crossentropy，因为最终的结果是一个二元问题，即是或者否</span></span><br><span class="line"><span class="comment"># 因此特别适合使用二元交叉熵来做损失判断，它能够计算判断正确的概率</span></span><br><span class="line"><span class="comment"># 如果结果并不是一个二元问题，而是一个范围问题，则应使用其他损失函数，例如均方误差 MSE，mean squared error</span></span><br><span class="line"><span class="comment"># 它能够用来判断计算结果与预期目标的误差范围；</span></span><br><span class="line"><span class="comment"># 另外此处使用的度量指标是准确度 accuracy，表示计算结果是否准确等于目标值；</span></span><br><span class="line"><span class="comment"># 如果计算结果不需要准确等于目标值，而只需要控制在目标值一定范围内即可算是正确，则</span></span><br><span class="line"><span class="comment"># 应该使用平均绝对误差 MAE，mean absolube error；</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=<span class="string">&quot;rmsprop&quot;</span>,</span><br><span class="line">	loss=<span class="string">&quot;binary_crossentropy&quot;</span>,</span><br><span class="line">	metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据问题场景的不同，内置的损失函数、度量指标、优化器不一定能够满足需求，此时</span></span><br><span class="line"><span class="comment"># 可以使用自定义的损失函数、度量指标、优化器</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> losses</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=optimizers.RMSprop(1r=<span class="number">0.001</span>),</span><br><span class="line">    loss=losses.binary_crossentropy,</span><br><span class="line">    metrics=[metrics.binary_accuracy]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="验证模型"><a href="#验证模型" class="headerlink" title="验证模型"></a>验证模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 虽然在训练模型时将数据分为训练集和测试集，但在训练过程中，是分很多轮进行迭代训练的，这意味着每一轮都得对</span></span><br><span class="line"><span class="comment"># 训练结果进行测试；此时不能将测试集引入测试，因为它将直接测试集被耦合进模型；因此，需要从训练集中，再拆分</span></span><br><span class="line"><span class="comment"># 一部分数据出来，做为验证训练结果的测试数据，来训练模型；这样对最终的模型结果来说，测试集的数据仍然</span></span><br><span class="line"><span class="comment"># 保持是前所未见的数据</span></span><br><span class="line">tensor_val_data = tensor_train_data[:<span class="number">10000</span>]</span><br><span class="line">partial_tensor_train_data = tensor_train_data[<span class="number">10000</span>:]</span><br><span class="line"></span><br><span class="line">tensor_val_labels = tensor_train_labels[:<span class="number">10000</span>]</span><br><span class="line">partial_tensor_train_labels =  tensor_train_labels[<span class="number">10000</span>:]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=<span class="string">&quot;rmsprop&quot;</span>,</span><br><span class="line">	loss=<span class="string">&quot;binary_crossentropy&quot;</span>,</span><br><span class="line">	metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">	partial_tensor_train_data,</span><br><span class="line">    partial_tensor_train_labels,</span><br><span class="line">    epochs=<span class="number">20</span>,</span><br><span class="line">    batch_size=<span class="number">512</span>,</span><br><span class="line">    validation_data=(tensor_val_data, tensor_val_labels)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制图表，将训练结果可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="comment"># 绘制预测损失的图表</span></span><br><span class="line">history_dict = history.history</span><br><span class="line">loss_values = history_dict.get(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">val_loss_values = history_dict.get(<span class="string">&quot;val_loss&quot;</span>)</span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(loss_values) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&quot;Training loss&quot;</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training and validation loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制预测精度的图表</span></span><br><span class="line">plt.clf()</span><br><span class="line">acc = history_dict.get(<span class="string">&quot;acc&quot;</span>)</span><br><span class="line">val_acc = history_dict.get(<span class="string">&quot;val_acc&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&quot;Training acc&quot;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&quot;Valication acc&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training and validation accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="调整模型"><a href="#调整模型" class="headerlink" title="调整模型"></a>调整模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调整轮次重新训练网络模型，这次使用全部的训练集，没有使用验证集</span></span><br><span class="line">new_history = model.fit(</span><br><span class="line">	tensor_train_data,</span><br><span class="line">    tensor_train_labels,</span><br><span class="line">    epochs=<span class="number">4</span>,</span><br><span class="line">    batch_size=<span class="number">512</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练好的模型，使用测试集对其进行评估，看模型预测的准确性</span></span><br><span class="line">results = model.evaluate(tensor_test_data, tensor_test_labels)</span><br><span class="line"><span class="built_in">print</span>(resutls)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看模型在测试集上的预测结果</span></span><br><span class="line">model.predict(tensor_test_data)</span><br></pre></td></tr></table></figure>

<h3 id="新闻分类：多分类问题"><a href="#新闻分类：多分类问题" class="headerlink" title="新闻分类：多分类问题"></a>新闻分类：多分类问题</h3><p>总共有46个主题标签，每条新闻只属于其中的一个主题，即只拥有一个标签；因此这是一个单标签、多种类别的问题；另外对于电影，则有可能是多标签、多种类别的问题；</p>
<blockquote>
<p>此处联想到图片上的目标识别，可能也可以算是一个单标签多分类的问题；因为可以假设目标物体由多个部位组成，例如由头、手、脚组成；这些部位即是目标类别，然后图片上的每一个点，有且只有可能属于其中的某个类别，或者完全不属于任何一个部位的类别；</p>
</blockquote>
<h4 id="整理数据"><a href="#整理数据" class="headerlink" title="整理数据"></a>整理数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处导入 keras 已经提前内置的 reuters 数据集</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> reuters</span><br><span class="line"></span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据张量化</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vectorize_sequences</span>(<span class="params">sequences, demension=<span class="number">10000</span></span>):</span><br><span class="line">	results = np.zeros((<span class="built_in">len</span>(sequences), demension))</span><br><span class="line">	<span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">		results[i, sequence] = <span class="number">1.</span></span><br><span class="line">	<span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">tensor_train_data = vectorize_sequences(train_data)</span><br><span class="line">tensor_test_data = vectorize_sequences(test_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签向量化，有两种方法， 一种是将标签列表转换为整数张量，另一种是使用 one-hot 编码</span></span><br><span class="line"><span class="comment"># one-hot 的意思就是将 n 个标签中，被命中的那个标记为 1，其他的标记为 0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_one_hot</span>(<span class="params">labels, dimension=<span class="number">46</span></span>):</span><br><span class="line">	results = np.zeros((<span class="built_in">len</span>(labels), dimension))</span><br><span class="line">	<span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels):</span><br><span class="line">		results[i, label] = <span class="number">1.</span></span><br><span class="line">	<span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class="line">one_hot_test_labels = to_one_hot(test_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果是转换为整数张量的话，则损失函数应该选择 sparse_categorical_crossentropy，即离散分类交叉熵</span></span><br><span class="line">tensor_train_data = np.array(train_data)</span><br><span class="line">tensor_train_labels = np.array(train_labels)</span><br></pre></td></tr></table></figure>

<h4 id="构建网络-1"><a href="#构建网络-1" class="headerlink" title="构建网络"></a>构建网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建网络</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始构建网络</span></span><br><span class="line"><span class="comment"># 由于最后的结果需要将概率映射到46个标签的空间中，因此前面两层的空间不应该小于46</span></span><br><span class="line"><span class="comment"># 此处空间隐藏单元数量取值 64，以避免计算过程中的信息丢失</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 由于最后的目标是从46个标签中选择一个，所以此处最后一层选择的激活函数为 softmax，</span></span><br><span class="line"><span class="comment"># 它用来计算某个样本在46种标签中，属于某一种标签的概率，46个概率的总共刚好等于 1</span></span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处的损失函数不再使用二元分类问题的交叉熵，而是使用多元分类问题的交叉熵</span></span><br><span class="line"><span class="comment"># 度量指标仍然使用 accuracy，因为它本质上仍然是计算分类的准确率</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=<span class="string">&quot;rmsprop&quot;</span>,</span><br><span class="line">	loss=<span class="string">&quot;categorical_crossentropy&quot;</span>,</span><br><span class="line">	metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预留部分数据作为验证集</span></span><br><span class="line">val_data = tensor_train_data[:<span class="number">1000</span>]</span><br><span class="line">partial_train_data = tensor_train_data[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line">val_labels = one_hot_train_labels[:<span class="number">1000</span>]</span><br><span class="line">partial_train_labels = one_hot_train_labels[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">history = model.fit(</span><br><span class="line">	partial_train_data,</span><br><span class="line">	partial_train_labels,</span><br><span class="line">	epochs=<span class="number">20</span>,</span><br><span class="line">	batch_size=<span class="number">512</span>,</span><br><span class="line">	validation_data=(val_data, val_labels)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制表格，将数据可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="comment"># 绘制预测损失的图表</span></span><br><span class="line">history_dict = history.history</span><br><span class="line">loss_values = history_dict.get(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">val_loss_values = history_dict.get(<span class="string">&quot;val_loss&quot;</span>)</span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(loss_values) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&quot;Training loss&quot;</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training and validation loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制预测精度的图表</span></span><br><span class="line">plt.clf()</span><br><span class="line">acc = history_dict.get(<span class="string">&quot;acc&quot;</span>)</span><br><span class="line">val_acc = history_dict.get(<span class="string">&quot;val_acc&quot;</span>)</span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(loss_values) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&quot;Training acc&quot;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&quot;Valication acc&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training and validation accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新训练模型，因为从第 9 轮开始就过拟合了</span></span><br><span class="line">history = model.fit(</span><br><span class="line">	partial_train_data,</span><br><span class="line">	partial_train_labels,</span><br><span class="line">	epochs=<span class="number">9</span>,</span><br><span class="line">	batch_size=<span class="number">512</span>,</span><br><span class="line">	validation_data=(val_data, val_labels)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">results = model.evaluate(tensor_test_data, one_hot_test_labels)</span><br></pre></td></tr></table></figure>

<h3 id="预测房价：回归问题"><a href="#预测房价：回归问题" class="headerlink" title="预测房价：回归问题"></a>预测房价：回归问题</h3><h4 id="整理数据-1"><a href="#整理数据-1" class="headerlink" title="整理数据"></a>整理数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处导入 keras 已经提前内置的 boston housing 数据集</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> boston_housing</span><br><span class="line"></span><br><span class="line">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line"><span class="comment"># 如果数据过于离散，取值范围跨度很大，虽然模型仍然可以从中进行学习</span></span><br><span class="line"><span class="comment"># 但是这样会加大学习的难度，所以对于取值范围跨度很大的数据，最好一开始对其进行标准化操作</span></span><br><span class="line">mean = train_data.mean(axis=<span class="number">0</span>)</span><br><span class="line">train_data -= mean</span><br><span class="line">std = train_data.std(axis=<span class="number">0</span>)</span><br><span class="line">train_data /= std</span><br><span class="line"></span><br><span class="line">test_data -= mean</span><br><span class="line">test_data /= std</span><br></pre></td></tr></table></figure>

<h4 id="构建网络-2"><a href="#构建网络-2" class="headerlink" title="构建网络"></a>构建网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_model</span>():</span><br><span class="line">	model = models.Sequential()</span><br><span class="line">	model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(train_data.shape[<span class="number">1</span>],)))</span><br><span class="line">	model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">	<span class="comment"># 最后一层没有使用激活函数，是因为现在要解决的是一个标量回归的问题</span></span><br><span class="line">	<span class="comment"># 因此最后一层计算出来的结果，可以直接作为目标值使用</span></span><br><span class="line">	model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">	model.<span class="built_in">compile</span>(</span><br><span class="line">		optimizer=<span class="string">&quot;rmsprop&quot;</span>,</span><br><span class="line">		loss=<span class="string">&quot;mse&quot;</span>,</span><br><span class="line">		metrics=[<span class="string">&#x27;mae&#x27;</span>]</span><br><span class="line">	)</span><br><span class="line">	<span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h4 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="comment"># 使用 K 折验证，解决样本数过小的问题</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">num_val_samples = <span class="built_in">len</span>(train_data) // k</span><br><span class="line">num_epochs = <span class="number">500</span></span><br><span class="line">all_mae_histories = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;processing fold: &quot;</span>, i)</span><br><span class="line">	val_data = train_data[i * num_val_samples : (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">	val_targets = train_targets[i * num_val_samples : (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line"></span><br><span class="line">	partial_train_data = np.concatenate(</span><br><span class="line">		[train_data[: i * num_val_samples],</span><br><span class="line">		train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">		axis=<span class="number">0</span></span><br><span class="line">	)</span><br><span class="line">	partial_train_targets = np.concatenate(</span><br><span class="line">		[train_targets[: i * num_val_samples],</span><br><span class="line">		train_targets[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">		axis=<span class="number">0</span></span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	model = build_model()</span><br><span class="line">	history = model.fit(</span><br><span class="line">		partial_train_data, </span><br><span class="line">		partial_train_targets,</span><br><span class="line">		validation_data=(val_data, val_targets),</span><br><span class="line">		epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">	<span class="comment"># print(history.history.keys())</span></span><br><span class="line">	<span class="comment"># break</span></span><br><span class="line">	mae_history = history.history[<span class="string">&#x27;val_mae&#x27;</span>]</span><br><span class="line">	all_mae_histories.append(mae_history)</span><br></pre></td></tr></table></figure>

<h4 id="绘制图表"><a href="#绘制图表" class="headerlink" title="绘制图表"></a>绘制图表</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">average_mae_history = [</span><br><span class="line">	np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> all_mae_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制图表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(average_mae_history) + <span class="number">1</span>), average_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Validation MAE&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除无效值，平滑曲线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smooth_curve</span>(<span class="params">points, factor=<span class="number">0.9</span></span>):</span><br><span class="line">	smoothed_points = []</span><br><span class="line">	<span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">		<span class="keyword">if</span> smoothed_points:</span><br><span class="line">			previous = smoothed_points[-<span class="number">1</span>]</span><br><span class="line">			smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			smoothed_points.append(point)</span><br><span class="line">	<span class="keyword">return</span> smoothed_points</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除前10个数据点，因为它们跟其他点偏差过大</span></span><br><span class="line">smooth_mae_history = smooth_curve(average_mae_history[<span class="number">10</span>:])</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(smooth_mae_history) + <span class="number">1</span>), smooth_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Validation MAE&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="重新训练"><a href="#重新训练" class="headerlink" title="重新训练"></a>重新训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练最终的模型</span></span><br><span class="line">model = build_model()</span><br><span class="line">model.fit(</span><br><span class="line">	train_data,</span><br><span class="line">	train_targets,</span><br><span class="line">	epochs=<span class="number">80</span>,</span><br><span class="line">	batch_size=<span class="number">16</span>,</span><br><span class="line">	verbose=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(test_mae_score)</span><br></pre></td></tr></table></figure>

<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>回归问题与分类问题不同；对于分类问题，要么对，要么错，因此可以使用准确率作为预测结果的度量指标；但对于回归问题，它的结果跟目标之间是以差值多少出现的，而非对或者错，因此它需要使用平均绝对误差  MAE 作为度量指标；同时它的损失函数使用均方误差 MSE 来计算；</li>
<li>由于回归问题的标签值是某个数值，每个值与值之间可能存在较大的取值范围，因此在使用模型学习之前，一般要对它们进行标准化处理，让它们的取值范围呈现标准化；</li>
<li>当样本数量比较少时，可以考虑使用 K 折验证来降低偶然因素；</li>
<li>如果样本数很少，模型的层数也应该尽量少一些，不然模型容易与数据产生过拟合；</li>
</ul>
<h2 id="4-机器学习基础"><a href="#4-机器学习基础" class="headerlink" title="4. 机器学习基础"></a>4. 机器学习基础</h2><h3 id="机器学习的四个分支"><a href="#机器学习的四个分支" class="headerlink" title="机器学习的四个分支"></a>机器学习的四个分支</h3><h4 id="1-监督学习"><a href="#1-监督学习" class="headerlink" title="1. 监督学习"></a>1. 监督学习</h4><p>目标：学会将输入数据映射到已知目标；</p>
<ul>
<li>分类问题：二分类、多分类；</li>
<li>回归问题：根据打分预测房价；</li>
<li>序列生成：给定一张图像，预测描述图像的文字（感觉像是多分类问题）；</li>
<li>语法树预测：给定一个句子，预测其生成的语法树；</li>
<li>目标检测：给定一张图像，在特定目标的周围画一个框；</li>
<li>图像分割：给定一张图像，在特定物体上画一个像素级的掩模；</li>
</ul>
<h4 id="2-无监督学习"><a href="#2-无监督学习" class="headerlink" title="2. 无监督学习"></a>2. 无监督学习</h4><ul>
<li>定义：没有特定目标的情况下，寻找输入数据的有趣变换；</li>
<li>目的：数据可视化、数据压缩、数据去噪，或者更好的理解数据的相关性；它常用于数据分析，在解决监督学习的问题之前，对数据进行分析通常是必要的，以便更好的了解数据集；</li>
<li>常用方法：降维（dimension reducion）、聚类（clustering）；</li>
</ul>
<h4 id="3-自监督学习"><a href="#3-自监督学习" class="headerlink" title="3. 自监督学习"></a>3. 自监督学习</h4><ul>
<li>定义：它是监督学习的一个特例；初始的时候，并没有输入标签，而只是给了一个启发式的算法，让机器来自己生成标签，然后靠这些标签进行自监督学习；</li>
<li>自监督学习的一个例子是自编码器，它用输入作为目标，来比对对数据所提取的抽象表征能否顺利的还原；</li>
</ul>
<blockquote>
<p>以前曾经用它来学习压缩算法，后来发现没有什么卵用，一个是压缩效率不高，二是跟输入数据强相关，在不同类型的数据上面，压缩效率急剧变差；目前研究到最有用的应用领域是图像去噪；另外一个应用是将数据降维，让其可视化，方便人类发现数据的一些有趣特征；</p>
</blockquote>
<h4 id="4-强化学习"><a href="#4-强化学习" class="headerlink" title="4. 强化学习"></a>4. 强化学习</h4><p>智能体接收环境的信息，然后选择某种可以使奖励最大化的行动；目前主要在游戏领域比较成功，其他方面的应用则仍处于研究阶段；</p>
<h3 id="常见术语"><a href="#常见术语" class="headerlink" title="常见术语"></a>常见术语</h3><ul>
<li>样本：也叫输入，进入模型的数据；</li>
<li>预测：也叫输出，模型给出的结果；</li>
<li>目标：真实准确的值，模型在理想情况下给出的结果应跟目标一致；</li>
<li>预测误差：也叫损失值，预测与目标之间的距离；</li>
<li>类别：分类问题中的一组分类标签；</li>
<li>标签：分类问题中的单个类别标签；</li>
<li>真值：也叫标注：数据集的所有目标；</li>
<li>二分类：预测结果只有两个类型的分类任务；</li>
<li>多分类：预测结果应分配到2个以上类型的分类任务；</li>
<li>多标签分类：预测结果可以分配多个标签的任务；</li>
<li>标量回归：目标是连续的标量值的任务，例如房价；</li>
<li>向量回归：目标是一组连续值的任务，例如图像边框检测；</li>
<li>小批量：模型同时进行处理的一小组样本；样本数量通常取2的幂，这样在 GPU 内存上比较好分配；</li>
<li>特征图：feature map，其实就是 3D 张量（包含高度和宽度两个空间轴，和一个深度轴，深度轴也叫通道轴），它即可以是输入，也可以是输出（此处的通道很像 Dense 层里面的隐藏单元，用来存放计算结果）；</li>
<li>过滤器：filter，3D 张量深度轴的不同通道即是代表过滤器；通道值是过滤器对输入数据的某一方面进行编码的结果；</li>
</ul>
<h3 id="评估机器学习模型"><a href="#评估机器学习模型" class="headerlink" title="评估机器学习模型"></a>评估机器学习模型</h3><p>可泛化的模型：在新数据上面表现良好的模型；泛化能力是评估一个模型优秀与否的指标；</p>
<blockquote>
<p>模型的超参数：指模型的层数、每层大小（隐藏单元数量）这些参数；<br>模型的参数：指每层的权重值；</p>
</blockquote>
<h4 id="训练集、验证集和测试集"><a href="#训练集、验证集和测试集" class="headerlink" title="训练集、验证集和测试集"></a>训练集、验证集和测试集</h4><p>将数据分成三个集合是必要的，因为在训练过程中，模型反复根据验证集的验证结果进行参数的调整，这会导致模型与验证集的拟合性越来越好，但是在全新数据上面的性能却不一定更好；所以需要有一个测试集，做为全新的数据来对模型进行评估；</p>
<h5 id="三种经典的模型评估方法"><a href="#三种经典的模型评估方法" class="headerlink" title="三种经典的模型评估方法"></a>三种经典的模型评估方法</h5><h6 id="1-简单留出验证"><a href="#1-简单留出验证" class="headerlink" title="1. 简单留出验证"></a>1. 简单留出验证</h6><p>将数据分成三部分，其中的训练集、验证集用来训练模型，测试集用来评估模型；<br>缺点：当样本数很少时，这种方法很容易跟数据过拟合；过拟合可以通过随机打乱数据集来训练模型，看最后的结果是否波动很大；</p>
<h6 id="2-K-折验证"><a href="#2-K-折验证" class="headerlink" title="2. K 折验证"></a>2. K 折验证</h6><p>将数据均分大小相同的 K 个分区，每次取其中一个分区作为验证集，余下做为训练集；最后取 K 个分数的平均值作为评分；</p>
<h6 id="3-重复-K-折验证"><a href="#3-重复-K-折验证" class="headerlink" title="3. 重复 K 折验证"></a>3. 重复 K 折验证</h6><p>进行多次 K 折验证，每次都将数据先打乱；这种方式的计算成本比较高；需要计算 K * P 次</p>
<h5 id="评估模型的注意事项"><a href="#评估模型的注意事项" class="headerlink" title="评估模型的注意事项"></a>评估模型的注意事项</h5><ul>
<li>数据代表性：一般通过随机打乱数据来实现；</li>
<li>时间箭头：如果是解决用旧数据预测未来新数据的问题，则注意训练的数据与测试的数据有时间点的区隔，不可重叠；</li>
<li>数据冗余：确保训练集和测试集没有任何交集，避免因为有数据冗余导致隐藏交集；</li>
</ul>
<h3 id="数据预处理、特征工程和特征学习"><a href="#数据预处理、特征工程和特征学习" class="headerlink" title="数据预处理、特征工程和特征学习"></a>数据预处理、特征工程和特征学习</h3><h4 id="神经网络的数据预处理"><a href="#神经网络的数据预处理" class="headerlink" title="神经网络的数据预处理"></a>神经网络的数据预处理</h4><ul>
<li>向量化：data vectorization，神经网络的输入和目标都必须是浮点数张量（少数特殊情况可接收整数）；</li>
<li>值标准化：让所有特征的均值为0，标准差为1；输入数据应满足同质性，即大致相同的取值范围；</li>
<li>处理缺失值：一般使用 0 来代表缺失值；如果样本集中没有缺失值，但未来的新数据有可能有缺失值，那么训练出来的网络无法应对有缺失值的情况，此时需要人工生成一些缺失值的样本；</li>
</ul>
<h4 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h4><p>特征工程的作用在于：用更简单的方式来表达问题，从而使得问题的解决变得更容易；</p>
<p>虽然现代的卷积神经网络可以自动学习特征，使得大部分特征工程变得没有必要，但是良好的特征工程仍然重要，原因有二：</p>
<ul>
<li>用更少的计算资源更优雅的解决问题</li>
<li>用更少的数据样本即可解决问题；</li>
</ul>
<h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><p>机器学习的根本问题是优化（optimization）和泛化（generalization）的对立；</p>
<p>防止模型从训练数据中学到错误或无关紧要的模式，方法有二：</p>
<ul>
<li>最优的方法：收集更多的数据用于训练；</li>
<li>次优的方法：调节模型允许存储的信息量，或对允许存储的信息增加约束；原因：模型允许存储的信息量越少，模型越容易记住更关键的信息；</li>
</ul>
<h4 id="降低过拟合的方法：正则化-regularization"><a href="#降低过拟合的方法：正则化-regularization" class="headerlink" title="降低过拟合的方法：正则化 regularization"></a>降低过拟合的方法：正则化 regularization</h4><h5 id="1-减少网络大小"><a href="#1-减少网络大小" class="headerlink" title="1. 减少网络大小"></a>1. 减少网络大小</h5><p>如果模型的容量足够大（由层数和每层单元数决定），模型将很容易实现样本和目标之间的映射关系，但这种映射却对泛化能力有害；</p>
<p>反之，如果容量不那么大，则无法轻松实现映射，此时模型就需要学会对目标具有很强预测能力的压缩表示，这样对泛化有利；但容量也不能太小，不然容易出现欠拟合问题；</p>
<p>暂时没有魔法公式可以确定最佳层数和每层最佳单元数，这需要使用验证集进行反复实验才能得到最佳结果；</p>
<h5 id="2-添加权重正则化"><a href="#2-添加权重正则化" class="headerlink" title="2. 添加权重正则化"></a>2. 添加权重正则化</h5><blockquote>
<p>奥卡姆剃刀原则：如果一件事情有两种解释，那么最可能正确的是最简单的那个（即假设条件最少的那个）；</p>
</blockquote>
<p>给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据，此时，简单的模型比复杂的模型更不容易过拟合；</p>
<blockquote>
<p>这里的简单模型指参数分布的熵更小的模型，或参数更少的模型；<br>熵被用计算一个系统中的失序现象，即系统的混乱程度；熵越高 ，系统越混乱；</p>
</blockquote>
<p>通过强制让模型权重取较小的值，从而限制模型的复杂度，使得权重值的分布更加规则（regular）；这种方法叫权重正则化（weight regularization）；实现方法：向网络的损失函数中添加与较大权重值相关的成本，Keras 中通过向层传递权重正则化项实例（weight regularizer）；</p>
<ul>
<li>L1 正则化：添加的成本与权重系数的绝对值成正比；</li>
<li>L2 正则化：添加的成本与权重系数的平方成正比；此方法也叫权重衰减（weight decay）；</li>
</ul>
<blockquote>
<p>由于惩罚项只在训练时添加，测试没有添加，因此网络的训练损失会比测试损失大很多；</p>
</blockquote>
<h5 id="3-添加-dropout-正则化"><a href="#3-添加-dropout-正则化" class="headerlink" title="3. 添加 dropout 正则化"></a>3. 添加 dropout 正则化</h5><p>对某一层使用 dropout，就是在训练过程中随机将该层的一些输出特征舍弃（设置为 0）；dropout 的比率通常在 0.2~0.5 范围内；</p>
<blockquote>
<p>测试时没有单元被舍弃，而该层的输出值需要按 dropout 比率缩小，因为此时有更多的单元被激活，需要加以平衡；<br>但在实践中，一般这个平衡的动作是在训练时操作，即先 dropout，再将输出成比例放大；而最后测试时输出保持不变；<br>dropout 的思想在于在层的输出中引入一些噪声，从而避免模型学习到一些偶然的模式，从而降低过拟合的概率；</p>
</blockquote>
<h3 id="机器学习的通用工作流程"><a href="#机器学习的通用工作流程" class="headerlink" title="机器学习的通用工作流程"></a>机器学习的通用工作流程</h3><h4 id="1-定义问题，收集数据集"><a href="#1-定义问题，收集数据集" class="headerlink" title="1. 定义问题，收集数据集"></a>1. 定义问题，收集数据集</h4><p>使用机器学习解决问题的关键在于以下两个假设成立：</p>
<ul>
<li><p>假设输出是可以根据输入进行预测的；（数据与答案有关联）</p>
<blockquote>
<p>现实中，有很多问题的答案，如果跟过去的历史并没有关系，则机器学习到的模型并不能用来很好的预测未来；</p>
</blockquote>
</li>
<li><p>假设可用数据包含足够多的信息，足以学习输入和输出之间的关系；（数据足够多）</p>
<blockquote>
<p>数据必须是在一个平稳的尺度上收集的；例如用夏天的服装销售数据预测冬天的销量并没有意义，因为机器学习无法解决非平稳问题（nonstationary problem）；</p>
</blockquote>
</li>
</ul>
<h4 id="2-选择衡量成功的指标"><a href="#2-选择衡量成功的指标" class="headerlink" title="2. 选择衡量成功的指标"></a>2. 选择衡量成功的指标</h4><p>制定衡量成功的指标，与损失函数的选择相关；不同类别的问题，选择不同的指标；</p>
<ul>
<li>平衡分类问题（每种类别的可能性相同）：常用指标为精度和 ROC AUC（area under the receiver operating characteristis curve，接收者操作特征曲线下面积）；</li>
<li>不平衡的分类问题：常用指标为准确率和召回率（问：啥是召回率？答：所有为真值的样本，被正确识别出来的比例，而准确率表示被认为是真的那些样本，确实为真的比例）；</li>
<li>排序问题或多标签分类：常用指标为平均准确率均值（mean average precision）；</li>
</ul>
<blockquote>
<p>其他更多的问题类型和对应的自定义指标，可以浏览 Kaggle 网站上的数据竞赛，上面有各式各样的问题和评估指标；</p>
</blockquote>
<h4 id="3-确定评估方法"><a href="#3-确定评估方法" class="headerlink" title="3. 确定评估方法"></a>3. 确定评估方法</h4><p>留出验证集、K 折验证、重复 K 折验证，三者选其一；一般情况下，第一种方法即可满足要求（除非样本数很小）；</p>
<h4 id="4-准备数据"><a href="#4-准备数据" class="headerlink" title="4. 准备数据"></a>4. 准备数据</h4><p>将数据格式化，转换成张量数据；</p>
<h4 id="5-开发比基准更好的模型"><a href="#5-开发比基准更好的模型" class="headerlink" title="5. 开发比基准更好的模型"></a>5. 开发比基准更好的模型</h4><p>此阶段的目标在于先开发一个”<strong>小型</strong>“模型，它要能够打败纯随机的基准（dumb baseline），即获得统计功效（statistical power）；</p>
<blockquote>
<p>如果不能获得统计功效，那有可能答案并不在数据里，先前的两个假设可能是错误的；</p>
</blockquote>
<p>构建模型需要选择的三个关键参数：</p>
<ul>
<li>最后一层的激活：它用来对网络的输出做有效的限制；</li>
<li>损失函数：需要匹配问题类型；</li>
<li>优化器：一般使用 rmsprop 即可；</li>
</ul>
<blockquote>
<p>衡量问题成功与否的指标，有时并不能用损失函数进行优化，因为损失函数有两个要求，一是即使小批量数据也可以计算，二是必须是可微的；此时的办法是使用替代指标，例如 ROC AUC 的替代指标为交叉熵；</p>
</blockquote>
<h4 id="6-扩大模型规模：开发过拟合的模型"><a href="#6-扩大模型规模：开发过拟合的模型" class="headerlink" title="6. 扩大模型规模：开发过拟合的模型"></a>6. 扩大模型规模：开发过拟合的模型</h4><p>在有了统计功效的小模型之后，接下来要做的是扩大它，让它变成过拟合；因为理想的模型刚好处在欠拟合和过拟合的分界线上；所以需要先达到过拟合的状态，才能发现二者的分界线；</p>
<h5 id="开发过拟合模型的办法："><a href="#开发过拟合模型的办法：" class="headerlink" title="开发过拟合模型的办法："></a>开发过拟合模型的办法：</h5><ul>
<li>添加更多的层；</li>
<li>每层变得更大；</li>
<li>训练更多的轮次；</li>
</ul>
<blockquote>
<p>通过始终监控训练损失和验证损失，以及所关注指标的训练值和验证值，来发现是否出现过拟合；</p>
</blockquote>
<h4 id="7-模型正则化与调节参数"><a href="#7-模型正则化与调节参数" class="headerlink" title="7. 模型正则化与调节参数"></a>7. 模型正则化与调节参数</h4><p>此步的目标是反复对模型进行局部的调节优化，以便达到最佳的性能；</p>
<h5 id="调节模型的方法："><a href="#调节模型的方法：" class="headerlink" title="调节模型的方法："></a>调节模型的方法：</h5><ul>
<li>添加 dropout</li>
<li>尝试不同的架构：增加或减少层数；</li>
<li>添加 L1 和(或) L2 正则化（正则化：在损失函数中，给更大的权重值添加一些成本）；</li>
<li>尝试不同的超参数（比如每层的单元个数，或优化器的学习率），以找到最佳配置</li>
<li>（可选）反复做特征工程：添加新特征，或者删除没有信息量的特征；</li>
</ul>
<p><strong>一旦开发出满意的模型配置后，就可以在训练集和验证集上训练最终的生产模型，然后在测试集上最后评估一次；</strong></p>
<blockquote>
<p>如果测试集上的性能比验证集差很多，则说明验证流程并不可靠，或者模型在验证数据上出现了过拟合；此时，需要更换为更可靠的验证方法，如 K 折验证等；</p>
</blockquote>
<h2 id="5-深度学习用于计算机视觉"><a href="#5-深度学习用于计算机视觉" class="headerlink" title="5. 深度学习用于计算机视觉"></a>5. 深度学习用于计算机视觉</h2><h3 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h3><p>卷积网络在处理图像时特别好用，原因在于它对应了图像的两种基本特征：</p>
<ul>
<li>平移不变性：在某个局部位置学习到的模式，可以适用于其他位置，即局部模式可以进行平移；密集连接网络学习到的模式是全局关系，因此它不具备平移不变性；（可移植）</li>
<li>空间层次性：在某个层次学习到的模式，可以在下一个层次中进行组合，变成更大的模式；（可组合）</li>
</ul>
<h4 id="卷积运算过程"><a href="#卷积运算过程" class="headerlink" title="卷积运算过程"></a>卷积运算过程</h4><ul>
<li>按一定大小的窗口，例如 3 * 3，对图片进行某个局部位置做卷积运算，得到一个有深度的输出结果；在深度维度上的每一个值，代表在这个小窗口中学习到的一个小特征；深度可以自定义；</li>
<li>平移小窗口，对整张图片进行卷积运算，就会得到由各种小特征组成的一个 3D 特征矩阵；矩阵的长宽分别代表一个窗口运算的结果，矩阵的深度则是该窗口的小特征集合；</li>
<li>接下来使用最大池化技术，对上一步获取的特征矩阵，进行采样；使用 2 * 2 窗口按步幅 2 进行采样，而卷积层是使用 3 * 3 窗口按步幅 1 进行计算；</li>
</ul>
<blockquote>
<p>总结来说就是两步，第一步是找特征，第二步是对特征进行采样（采集明显与众不同的那些特征）；</p>
</blockquote>
<blockquote>
<p>除了卷积计算外，还是一个反向卷积计算，叫 Deconvolution，也叫 transpose convolution；先使用正向卷积提取关键特征后，再用反向卷积可以提纯这些特征，去除最原始的噪声；在做反卷积计算时，由于输出比输入大，因此需要做一些 padding 的工作，然后才能够作常规的卷积核乘积计算；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20220713145156.png"></p>
<p>反向卷积常用于图片分割任务，因为分割涉及像素级的操作，所以不能使用样本来代表整个图片，因此需要让最后的数据仍然保持和输入时一样，此时就可以先通过正向卷积获取关键特征，最后再通过反向卷积重新生成图片，用于分割；另外在 super-resolution，GAN，Surface depth estimation 任务中也会用到；可以说，凡是输出需要输入大的场景，都有可能会用到它；</p>
</blockquote>
<h4 id="用最大池化进行采样的目的"><a href="#用最大池化进行采样的目的" class="headerlink" title="用最大池化进行采样的目的"></a>用最大池化进行采样的目的</h4><ul>
<li>一是可以减少需要处理的特征图的元素的个数；</li>
<li>二是让观察窗口越来越大，覆盖原输入图的全部位置，从而可以学习到由局部图像组成的空间层次模式；</li>
<li>观察不同特征的最大值，而非平均值，更容易发现一些特征信息，因为特征通常是突出表现，与众不同的；</li>
</ul>
<h3 id="在小型数据集上从头开始训练一个卷积神经网络"><a href="#在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="在小型数据集上从头开始训练一个卷积神经网络"></a>在小型数据集上从头开始训练一个卷积神经网络</h3><ul>
<li>卷积网络学习到的模式因为具有局部性和平移不变性的特点，相比其他网络模型，它可以在一个相对较小的数据集上学到较多的有用信息，取得还不错的效果；</li>
<li>如果要处理问题和数据比较大比较复杂，则应相应增加一些层数和单元数，以便有足够的容量存储学习到特征信息，避免欠拟合；</li>
<li>Keras 有自带一个图像处理类，它能很好的完成图像处理的一些常见任务（以 python 生成器来实现）；</li>
<li>在较小的图片数据集上，可以使用数据增强（data augmentation）的技巧，来间接扩大数据集（它的本质上对图像做一些变形以生成新图片，例如旋转、翻转、缩放、拉伸等）；但是由于数据增强的数据来源仍是原始数据，所以部分数据是高度相关的，为避免产生过拟合，一般配合使用 dropout 层添加一些噪声来平衡；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载图片，准备数据</span></span><br><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line"><span class="comment"># 原始数据解压后的存放目标</span></span><br><span class="line">original_dataset_dir = <span class="string">&quot;/downloads/kaggle_original_data&quot;</span></span><br><span class="line"><span class="comment"># 较小数据集的保存目录</span></span><br><span class="line">base_dir = <span class="string">&#x27;/downloads/cats_and_dogs_small&#x27;</span></span><br><span class="line">os.mkdir(base_dir)</span><br><span class="line"></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">os.mkdir(train_dir)</span><br><span class="line"></span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">&quot;validation&quot;</span>)</span><br><span class="line">os.mkdir(validation_dir)</span><br><span class="line"></span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">&quot;test&quot;</span>)</span><br><span class="line">os.mkdir(test_dir)</span><br><span class="line"></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">&quot;cats&quot;</span>)</span><br><span class="line">os.mkdir(train_cats_dir)</span><br><span class="line"></span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">&quot;dogs&quot;</span>)</span><br><span class="line">os.mkdir(train_dogs_dir)</span><br><span class="line"></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">&quot;cats&quot;</span>)</span><br><span class="line">os.mkdir(validation_cats_dir)</span><br><span class="line"></span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">&quot;dogs&quot;</span>)</span><br><span class="line">os.mkdir(validation_dogs_dir)</span><br><span class="line"></span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">&quot;cats&quot;</span>)</span><br><span class="line">os.mkdir(test_cats_dir)</span><br><span class="line"></span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">&quot;dogs&quot;</span>)</span><br><span class="line">os.mkdir(test_dogs_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;cat.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(train_cats_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;cat.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(validation_cats_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;cat.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(test_cats_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;dog.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(train_dogs_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;dog.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(validation_dogs_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">&#x27;dog.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">	src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">	dst = os.path.join(test_dogs_dir, fname)</span><br><span class="line">	shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>

<h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 读取图片，将图片转换为像素风格；将像素网络转换为浮点数张量；将像素值缩放到[0, 1] 之间；</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_data_gen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">test_data_gen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># generator 表示生成器，它会在每次被调用时，生成并返回一份数据</span></span><br><span class="line"><span class="comment"># 有点像迭代器，通常和 for...in... 配合使用</span></span><br><span class="line"><span class="comment"># 生成器跟迭代器不同的地方在于，它没有终点，只要一直被调用，就会不断生成数据</span></span><br><span class="line"><span class="comment"># 所以需要在某个时间点使用 break 进行终止</span></span><br><span class="line">train_data_generator = train_data_gen.flow_from_director(</span><br><span class="line">	train_dir,</span><br><span class="line">	target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">	batch_size=<span class="number">20</span>,</span><br><span class="line">	<span class="comment"># 此处使用二进制类模式，原因在于问题本身是一个二元分类问题，后续计算时</span></span><br><span class="line">	<span class="comment"># 将使用二元交叉熵作为损失函数</span></span><br><span class="line">	class_mode=<span class="string">&#x27;binary&#x27;</span> </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">validation_data_generator = test_data_gen.flow_from_director(</span><br><span class="line">	valication_dir,</span><br><span class="line">	target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">	batch_size=<span class="number">20</span>,</span><br><span class="line">	class_mode=<span class="string">&#x27;binary&#x27;</span> </span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="构建网络-3"><a href="#构建网络-3" class="headerlink" title="构建网络"></a>构建网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建网络</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = model.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&quot;relu&quot;</span>), input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">model.add(layers.Maxpooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">model.add(layers.Maxpooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Maxpooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Maxpooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练，此处使用了 fit_generator 方法，跟之前用的 fit 方法不同</span></span><br><span class="line"><span class="comment"># 它的不同之处在于，它接受生成器作为参数，而不是 numpy 数组</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">	train_generator,</span><br><span class="line">	steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">	epochs=<span class="number">30</span>,</span><br><span class="line">	validation_data=validation_generator,</span><br><span class="line">	validation_steps=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 在训练完成后保存模型</span></span><br><span class="line">model.save(<span class="string">&quot;path/to/model.h5&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据增强，可以通过对图片进行随机的变形，来增加训练的数据量</span></span><br><span class="line"><span class="comment"># 通过在实例化 Image 数据生成器时，引入更多参数来实现</span></span><br><span class="line"><span class="comment"># 之后通过这个实例化后的对象来处理图片时，会自动随机添加变形</span></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">	rotation_range=<span class="number">40</span>,</span><br><span class="line">	width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">	height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">	shear_range=<span class="number">0.2</span>,</span><br><span class="line">	zoom_range=<span class="number">0.2</span>,</span><br><span class="line">	horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">	fill_mode=<span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了尽可能避免过拟合，还有一种方法是在展平层之后，添加 dropout 层，引入一些随机的噪音</span></span><br><span class="line"><span class="comment"># 强迫模型去学习噪音背后有用和真实存在的识别模式</span></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="使用预训练的卷积神经网络"><a href="#使用预训练的卷积神经网络" class="headerlink" title="使用预训练的卷积神经网络"></a>使用预训练的卷积神经网络</h3><blockquote>
<p>深度学习的模型在本质天生具备高度的可复用性，这意味着，可以利用别人在大数据集上训练好的模型，做一些微调，来完成一些小数据集上面的任务；前提是该预训练的网络模型的原始数据集是足够大、足够通用的；而不是某种特定的任务；</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用预训练的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br></pre></td></tr></table></figure>



<p>使用预训练网络的两种方法：特征提取、微调模型；</p>
<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><ul>
<li>一般来说，一个训练好的卷积神经网络包含两个部分，一个是由卷积层和池化层组成的卷积基，一个是密集连接层组成的分类器；除非问题完全相同，不然一般只复用卷积基，而不复用分类器，因为分类器是面向特定问题的；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化模型，获得其卷积基（通过将 include_top 设置为 false 来实现，表示不复用顶层的分类器）</span></span><br><span class="line">conv_base = VGG16(</span><br><span class="line">	weights=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">	include_top=<span class="literal">False</span>,</span><br><span class="line">	input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="comment"># 指定数据存储的目录</span></span><br><span class="line">base_dir = <span class="string">&#x27;/downloads/cats_and_dogs_small&#x27;</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">&quot;validation&quot;</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处实例化的数据生成器没有使用数据增强</span></span><br><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图片做为输入，利用已训练好的模型的卷积基，获得计算后的特征（即输出）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">directory, sample_count</span>):</span><br><span class="line">	features = np.zeros(shape=(sample_count, <span class="number">4</span>, <span class="number">4</span>, <span class="number">512</span>))</span><br><span class="line">	<span class="comment"># 现在处理的是一个二元分类问题，所以 labels 只有一维</span></span><br><span class="line">	labels = np.zeros(shape=(sample_count))</span><br><span class="line">	generator = datagen.flow_from_directory(</span><br><span class="line">		directory,</span><br><span class="line">		target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">		batch_size=batch_size,</span><br><span class="line">		class_mode=<span class="string">&#x27;binary&#x27;</span></span><br><span class="line">	)</span><br><span class="line">	i = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> inputs_batch, labels_batch <span class="keyword">in</span> generator:</span><br><span class="line">		features_batch = conv_base.predict(inputs_batch)</span><br><span class="line">		features[i * batch_size : (i + <span class="number">1</span>) * batch_size] = features_batch</span><br><span class="line">		labels[i * batch_size : (i + <span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">		i += <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> i * batch_size &gt;= sample_count:</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">	<span class="keyword">return</span> features, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从目录中提取图片，用卷积基进行计算，将结果保存下来</span></span><br><span class="line">train_features, train_labels = extract_features(train_dir, <span class="number">2000</span>)</span><br><span class="line">validation_features, validation_labels = extract_features(validation_dir, <span class="number">1000</span>)</span><br><span class="line">test_features, test_labels = extract_features(test_dir, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以上获得的特征的形状是 (sample, 4, 4, 512)，由于接下来要将这些</span></span><br><span class="line"><span class="comment"># 特征做为密集层的输入，因此需要将它们展开成二维的</span></span><br><span class="line">train_features = np.reshape(train_features, (sample_count, (<span class="number">2000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>)))</span><br><span class="line">validation_features = np.reshape(validation_features, (sample_count, (<span class="number">2000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>)))</span><br><span class="line">test_features = np.reshape(test_features, (sample_count, (<span class="number">2000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下根据自身的业务场景，添加自己的密集层进行训练</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_dim=<span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=optimizers.RMSprop(1r=<span class="number">2e-5</span>),</span><br><span class="line">	loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">	metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">	train_features,</span><br><span class="line">	train_labels,</span><br><span class="line">	epochs=<span class="number">30</span>,</span><br><span class="line">	batch_size=<span class="number">30</span>,</span><br><span class="line">	validation_data=(validation_features, validation_labels)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>如果特征提取想要使用数据增强（当样本数比较少时），则需要换一种方法：扩展卷积基；</p>
<blockquote>
<p> 这种方法的计算代价比较大，因为数据要流过整个卷积基，按模型训练的方式重新计算，而不是像前一种方法基于已有参数快速进行预测计算即可；</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 扩展卷积基</span></span><br><span class="line">model = model.Sequential()</span><br><span class="line"><span class="comment"># 在将卷积基加上模型前，需要先对其进行冻结，避免训练过程中改变了它们的参数</span></span><br><span class="line">conv_base.trainable = <span class="literal">False</span></span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>))</span><br></pre></td></tr></table></figure>


<h4 id="微调模型"><a href="#微调模型" class="headerlink" title="微调模型"></a>微调模型</h4><ul>
<li>同时，对于卷积基，越靠近输入端的那几层，其提取的特征通用性越好；越靠近输出的层，则越是面向特定分类的模式组成，越是定向化，通用性降低；因此，虽然也可以解决全部层进行重新训练，但更靠底部的层，训练回报越少；</li>
</ul>
<h5 id="微调步骤"><a href="#微调步骤" class="headerlink" title="微调步骤"></a>微调步骤</h5><ol>
<li>复用预训练网络的整个卷积基，添加自己的分类器到模型中；</li>
<li>冻结卷积基，对分类器进行训练；</li>
<li>解冻顶部的一个卷积块，联合训练解决冻这些层和分类器；</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 微调模型，解冻顶部的少数层</span></span><br><span class="line"><span class="comment"># 先将整个卷积基的 trainable 属性设置为 True</span></span><br><span class="line">conv_base.trainable = <span class="literal">True</span> </span><br><span class="line"><span class="comment"># 指定将某个层的 trainable 属性设置为 True，其他仍为 Fasle</span></span><br><span class="line">set_trainable = <span class="literal">False</span> </span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">	<span class="keyword">if</span> layer.name == <span class="string">&#x27;block5_conv1&#x27;</span>:</span><br><span class="line">		set_trainable = <span class="literal">True</span></span><br><span class="line">	<span class="keyword">if</span> set_trainable:</span><br><span class="line">		layer.trainable = <span class="literal">True</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		layer.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用非常小的学习率开始训练模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">	optimizer=optimizers.RMSprop(lr=<span class="number">1e-5</span>),</span><br><span class="line">	loss=<span class="string">&quot;binary_crossentropy&quot;</span>,</span><br><span class="line">	metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<h3 id="卷积神经网络的可视化"><a href="#卷积神经网络的可视化" class="headerlink" title="卷积神经网络的可视化"></a>卷积神经网络的可视化</h3><p>网络模型本质上是由层组成的，而每一层实际上又由多个过滤器组成；而过滤器本质上是一个有着特定参数的函数，它对输入数据进行计算，得到一个输出结果；该输出结果做出下一层的输入数据；</p>
<p>可视化网络模型，本质是就是可视化这些过滤器函数的功能；有三种观察它的方式：</p>
<ul>
<li>一种是给定输入，看它的输出（可视化中间激活）</li>
<li>一种是看该函数得到最大值时的输入（可视化过滤器）</li>
<li>一种是看涉及分类决策在原输入图中的部位（可视化类激活图）</li>
</ul>
<h4 id="可视化中间激活"><a href="#可视化中间激活" class="headerlink" title="可视化中间激活"></a>可视化中间激活</h4><blockquote>
<p>层的输出一般称为激活（原因：层的输出即为激活函数的输出）</p>
</blockquote>
<p>随着层数的增加，模型不断对输入图像进行特征提取并进行组合，因此，到了越高的层级，特征变得越来越抽象，越无法直观理解，但是与目标类别需的信息越来越接近；</p>
<p>实现方法：</p>
<ul>
<li>获取已训练好的模型的各层输出，组成一个输出列表</li>
<li>创建一个新的模型实例，该实现以已训练好的模型的输入和输出列表为参数；</li>
<li>用新模型对一张图片进行预测，得到输出结果列表；</li>
<li>为每一层输出的每一个通道生成一张图像（为了让图片美观，此处会对数值进行标准化处理）</li>
</ul>
<h4 id="可视化卷积神经网络的过滤器"><a href="#可视化卷积神经网络的过滤器" class="headerlink" title="可视化卷积神经网络的过滤器"></a>可视化卷积神经网络的过滤器</h4><p>根据过滤器的参数，反向来计算让参数获得最大值的输入，从而知悉过滤器对什么样的模式产生响应；</p>
<p>实现方法：</p>
<ul>
<li>从模型中获取某一层的输出；</li>
<li>使用 backend.mean 函数，计算该层输出的损失值；</li>
<li>使用 backend.gradients 函数，计算损失相对模型原始输入的梯度；</li>
<li>对梯度进行标准化（这样可以比较不同输入图像之间的计算结果）；</li>
<li>定义后端函数，它可以将输入的张量，转换为损失值张量和梯度值张量；</li>
<li>初始化一张灰度图，并随机加入一些噪声；</li>
<li>使用该灰度图做为初始输入值，用刚定义的后端函数进行计算损失值和梯度值张量；</li>
<li>将梯度值添加到灰度图中，再重复上一个步骤，循环多次（例如40次），最后将得到一系列图像，该系列图像可最大化的激活对应通道的过滤器</li>
</ul>
<h4 id="可视化图像中类激活的热力图"><a href="#可视化图像中类激活的热力图" class="headerlink" title="可视化图像中类激活的热力图"></a>可视化图像中类激活的热力图</h4><p>图像上的不同部分，对最终分类决策重要程度不同，有些部分强相关，有些部分弱相关；假设已知输入图像对不同通道的激活强度，再加上每个通道对分类决策的重要程度，我们就可以求得输入图像的不同部分对分类决策的不同重要程度；</p>
<h5 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选定一张待分类的图片，先进行预处理，以便可以做为模型的输入数据 </span></span><br><span class="line">x = preprocess_input(image)；</span><br><span class="line"><span class="comment"># 使用模型对图片进行预测分类，得到分类结果的输出；该输出是一个向量，由于每种类别的概率组成 </span></span><br><span class="line">preds = model.predict(x)；</span><br><span class="line"><span class="comment"># 找到最大概率类型所在的下标 </span></span><br><span class="line"> index = np.argmax(preds[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 根据该下标，在模型预测向量中取得输入图像的相关输出 </span></span><br><span class="line"> image_output = model.output(:, index)；</span><br><span class="line"><span class="comment"># 从模型中取出最后一个卷积层 </span></span><br><span class="line">last_conv_layer = model.get_layer(layer_name)；</span><br><span class="line"><span class="comment"># 计算图像的最终输出与最后一个卷积层的梯度 </span></span><br><span class="line">grads = K.gradients(image_output, last_conv_layer.ouput)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 计算梯度中每个通道的平均值 </span></span><br><span class="line">pooled_grads = K.mean(grads, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 定义后端函数，它接受一个输入，给出 pooled_grads 和 last_conv_layer 的输出特征图</span></span><br><span class="line">iterate = K.function([model.<span class="built_in">input</span>], [pooled_grads, last_conv_layer.output[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 计算输入的测试图像 x 的 pooled_grads_value 和 conv_layer_output_value</span></span><br><span class="line">pooled_grads_value, conv_layer_output_value = iterate([x])</span><br><span class="line"><span class="comment"># 将特征数据的每个通道，乘以该通道对大象类型的重要程度</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">512</span>):</span><br><span class="line">    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]</span><br><span class="line"><span class="comment"># 上一步得到的特征图，对每个通道求平均值，即可得到热力图</span></span><br><span class="line">heatmap = np.mean(conv_layer_output_value, axis=-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 为了方便查看，将热力图标准化处理</span></span><br><span class="line">heatmap = np.maxmium(heatmap, <span class="number">0</span>)</span><br><span class="line">heatmap /= np.<span class="built_in">max</span>(heatmap)</span><br><span class="line"><span class="comment"># 将热力图叠加到原始图片上</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(img_path)</span><br><span class="line">heatmap = cv2.resize(heatmap, img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>])</span><br><span class="line">heatmap = np.uint8(<span class="number">255</span> * heatmap)</span><br><span class="line">heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)</span><br><span class="line">superimposed_img = heatmap * <span class="number">0.4</span> + img</span><br><span class="line">cv2.imwrite(superimposed_img_path, superimposed_img)</span><br></pre></td></tr></table></figure>



      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/08/27/Python%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" data-id="cm1c2djav0005wchp3ycwgb6g" data-title="Python 深度学习" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Gnicorn" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/08/19/Gnicorn/" class="article-date">
  <time class="dt-published" datetime="2020-08-19T02:38:00.000Z" itemprop="datePublished">2020-08-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/08/19/Gnicorn/">Gunicorn</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在编写好 python 的 web 程序后，可使用 Gunicorn 进行部署，以便快速实现并发目标，避免重复造轮子；</p>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><h3 id="使用命令"><a href="#使用命令" class="headerlink" title="使用命令"></a>使用命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn [OPTIONS] [WSGI_APP]</span><br></pre></td></tr></table></figure>

<p>WSGI_APP 的完整格式为：$(MODULE_NAME):$(VARIABLE_NAME)</p>
<p>MODULE_NAME 指待载入运行的文件或模块名称；可以是一个相对路径；</p>
<p>VARIABLE_NAME 指文件中的指向 WSGI 接口的变量名称；例如 app &#x3D; Flask() 中的 app；也可以是一个返回 app 的函数调用；例如：”app:create_app()”</p>
<blockquote>
<p>如果已经在配置文件中指定了 WSGI_APP，则命令行中的此参数是可选的；</p>
</blockquote>
<h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><p>-c 指定配置文件的路径</p>
<p>-b 绑定的 socket，格式可以为 $(HOST), $(HOST):$(PORT), fd:&#x2F;&#x2F;$(FD), unix:$(PATH), $(IP_ADDRESS)</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>Gunicorn 会从五个地方读取配置信息</p>
<ul>
<li>环境变量；</li>
<li>Web 框架中的特定配置文件；</li>
<li>指定目录下（默认当前目录）的 gunicorn.conf.py 文件（会覆盖框架配置文件的值）</li>
<li>通过命令行参数传递给环境变量 GUNICORN_CMD_ARGS 的值；</li>
<li>命令行参数；</li>
</ul>
<h3 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h3><p>命令行参数的优先级最高，它会覆盖其他方式的配置信息；但不是所有配置项都可以使用命令行进行设置；</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>配置文件需要是以 .py 为后缀的 python 文件；它可以是只读的；设置配置项时，只需要在文件中定义相应的变量名称并赋值即可；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bind = <span class="string">&quot;127.0.0.1:8000&quot;</span></span><br><span class="line">workers = <span class="number">2</span></span><br></pre></td></tr></table></figure>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/08/19/Gnicorn/" data-id="cm1bmo1if00600khp5paub0i0" data-title="Gunicorn" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Kubernetes 实战" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/08/12/Kubernetes%20%E5%AE%9E%E6%88%98/" class="article-date">
  <time class="dt-published" datetime="2020-08-12T01:25:00.000Z" itemprop="datePublished">2020-08-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/08/12/Kubernetes%20%E5%AE%9E%E6%88%98/">Kubernetes 实战</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-Kubernetes-系统的需求"><a href="#1-Kubernetes-系统的需求" class="headerlink" title="1. Kubernetes 系统的需求"></a>1. Kubernetes 系统的需求</h2><p>实现硬件资源的管理和应用执行环境管理二者的分离，即开发人员和运维人员不再需要有交集，而只需专注自己的那一部分工作；</p>
<h3 id="介绍容器技术"><a href="#介绍容器技术" class="headerlink" title="介绍容器技术"></a>介绍容器技术</h3><p>Linux 从内核层面实现的隔离技术，包括进程命名空间和 cgroup 资源隔离两种机制；</p>
<p>优点：同样实现隔离功能，容器技术相对重量级的 VM 虚拟机机制，更加轻量化，相同的硬件资源，可以更大效率的利用；</p>
<p>缺点：由于不同容器共用主机的内核，因此当容器环境对内核有特定要求时，会降低容器的可移植性；</p>
<h3 id="Kubernetes-介绍"><a href="#Kubernetes-介绍" class="headerlink" title="Kubernetes 介绍"></a>Kubernetes 介绍</h3><p>Kubernetes 对硬件资源进行了抽象，部署应用程序时，不用再关心需要使用哪些硬件资源；所有资源都被抽象成单个大节点；不管集群中包含多少节点，集群规模都不会造成差异性，额外的集群节点只是代表一些额外的可用来部署应用的资源；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180707.png"></p>
<p>在开发者眼中，Kubernetes 可以被视为关于集群的一个操作系统，因此只需专注实现应用本身，而无须关心应用与基础设施如何集成；</p>
<h4 id="Kubernetes-集群结构"><a href="#Kubernetes-集群结构" class="headerlink" title="Kubernetes 集群结构"></a>Kubernetes 集群结构</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180748.png"></p>
<h5 id="主节点"><a href="#主节点" class="headerlink" title="主节点"></a>主节点</h5><ul>
<li>scheduler：负责调度，为应用分配节点；</li>
<li>controler manager；负责管理集群；</li>
<li>etcd：负责存储，持久化存储集群的配置信息；</li>
<li>API 服务器：负责各个组件之间的通讯；</li>
</ul>
<h5 id="工作节点"><a href="#工作节点" class="headerlink" title="工作节点"></a>工作节点</h5><ul>
<li>容器运行时：即 Docker 或 rtk等；</li>
<li>Kubelet：负责与 API 服务器通信，并管理当前节点内的容器；</li>
<li>Kube-proxy：负责网络流量的负载均衡；</li>
</ul>
<h4 id="在-Kubernetes-中运行应用"><a href="#在-Kubernetes-中运行应用" class="headerlink" title="在 Kubernetes 中运行应用"></a>在 Kubernetes 中运行应用</h4><h5 id="应用转描述"><a href="#应用转描述" class="headerlink" title="应用转描述"></a>应用转描述</h5><ol>
<li>将应用打包成镜像；</li>
<li>将镜像推送到仓库；</li>
<li>将应用的描述发布到 Kubernetes API 服务器；</li>
</ol>
<h5 id="描述转容器"><a href="#描述转容器" class="headerlink" title="描述转容器"></a>描述转容器</h5><p>调度器根据描述文件中每组所需的计算资源，以及每个节点当前未分配的资源，调度指定的组到可用的工作节点上；</p>
<p>节点收到调度器指派的组后，从仓库拉取镜像并运行容器；</p>
<h5 id="保持容器运行"><a href="#保持容器运行" class="headerlink" title="保持容器运行"></a>保持容器运行</h5><p>对运行中的容器和工作节点进行监控，如果容器退出则重新创建；若工作节点宕机，则分配相应组到新的工作节点；</p>
<h5 id="扩展副本数量"><a href="#扩展副本数量" class="headerlink" title="扩展副本数量"></a>扩展副本数量</h5><p>副本数量可以手工进行增加或减少，也可以交给 Kubernetes 自行调整为最佳副本数；</p>
<h5 id="命中移动目标"><a href="#命中移动目标" class="headerlink" title="命中移动目标"></a>命中移动目标</h5><p>由于容器是动态调度的，这意味着它们会移动；因此 Kubernetes 通过提供服务的静态 IP 或 DNS 服务查找 IP 两种方式，来对外提供稳定的服务；</p>
<h4 id="使用-Kubernetes-的好处"><a href="#使用-Kubernetes-的好处" class="headerlink" title="使用 Kubernetes 的好处"></a>使用 Kubernetes 的好处</h4><p>在任何部署了 Kubernetes 的机器上，系统管理员不再需要安装任何东西来部署和运行应用程序；而开发人员也将不需要系统管理员的任何帮助，即可以立即运行应用程序；</p>
<ul>
<li>简化应用程序部署：所有的工作节点被抽象成一个部署平台；对于异构节点，只需在描述中增加对应用程序所需资源的选择条件即可；</li>
<li>更好的利用硬件：当硬件资源很多时，人工找到最佳组合的难度会变得很大；</li>
<li>健康检查和自修复：通过自动监控，当出现故障时，可以将应用程序迁移到备用资源上；运维人员无需立即做出反应，可以等到上班时间再排查故障即可；</li>
<li>自动扩容：自动根据应用程序的荷载，放大或缩小集群的规模；</li>
<li>简化开发人员的部署：无须系统管理员的帮助即可实现部署；同时方便 BUG 排查，在部署出错时可以停止更新自动回滚；</li>
</ul>
<h2 id="2-开始使用-Kubernetes-和-Docker"><a href="#2-开始使用-Kubernetes-和-Docker" class="headerlink" title="2. 开始使用 Kubernetes 和 Docker"></a>2. 开始使用 Kubernetes 和 Docker</h2><p>创建、运行和推送镜像（略）</p>
<h3 id="配置-Kubernetes-集群"><a href="#配置-Kubernetes-集群" class="headerlink" title="配置 Kubernetes 集群"></a>配置 Kubernetes 集群</h3><p>有多种方法可以安装 Kubernetes 集群，包括：</p>
<ol>
<li>本地的开发机器；</li>
<li>自己组织的机器；</li>
<li>虚拟机提供商的机器；</li>
<li>托管的集群；</li>
</ol>
<blockquote>
<p>由于集群的配置工作比较复杂，因此使用较多的是第1和第4种，即本地和托管两种；另外两种需要使用 kubeadm 或 kops 工具来实现；</p>
</blockquote>
<h3 id="在-Kubernetes-上运行应用"><a href="#在-Kubernetes-上运行应用" class="headerlink" title="在 Kubernetes 上运行应用"></a>在 Kubernetes 上运行应用</h3><p>最简单的方式是使用 run 命令，但常规的方式是使用 YAML 或 JSON 描述文件；</p>
<p>pod 很像一个独立的逻辑机器，拥有自己的 IP、主机名、进程等；因此，pod 内的容器总是运行在同一个工作节点上；</p>
<p>每个 pod 都有自己的 IP，但这个 IP 是集群内使用的，不能被外部访问，需要通过创建服务来公开它；</p>
<p>loadBalancer 类型的服务，会创建一个可以公开访问的公网 IP，因此它需要使用托管的集群才能实现这点，本地运行的 minikube 做不到；</p>
<h4 id="服务与-pod-的关系"><a href="#服务与-pod-的关系" class="headerlink" title="服务与 pod 的关系"></a>服务与 pod 的关系</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180816.png"></p>
<p>之所以需要服务这个抽象层，其原因在于 pod 的生命周期是短暂的，它有可能因为各种意外的场景消失了，而重新创建的 pod 会有不一样的 IP 地址；因此，需要有一个能够提供静态 IP 访问地址的服务层，并由这个服务层将访问请求路由到当前正常工作的 pod 中；</p>
<h2 id="3-pod：运行于-Kubernetes-中的容器"><a href="#3-pod：运行于-Kubernetes-中的容器" class="headerlink" title="3. pod：运行于 Kubernetes 中的容器"></a>3. pod：运行于 Kubernetes 中的容器</h2><p>pod 是 kubernetes 中最核心的概念，而其他组件仅仅是管理或暴露它，或者被它所使用；</p>
<h3 id="介绍-pod"><a href="#介绍-pod" class="headerlink" title="介绍 pod"></a>介绍 pod</h3><p>每个容器只运行一个单独的进程是一种好的 docker 实践（除非是该进程自行产生的子进程）；</p>
<blockquote>
<p>为什么多容器协作优于单容器多进程的协作？</p>
<ul>
<li>多进程之间需要解释依赖冲突的问题；</li>
<li>当某个进程崩溃需要重启时，多进程场景增加了复杂度；</li>
</ul>
</blockquote>
<h4 id="为何需要-pod"><a href="#为何需要-pod" class="headerlink" title="为何需要 pod"></a>为何需要 pod</h4><p>Kubernetes 通过配置 docker 让一个 pod 内的所有容器共享相同的 Linux 命令空间，而不是每个容器都有自己的一组命名空间；这种做法可以让容器之间很方便的实现资源共享，包括 IP 地址、端口空间、主机名、IPC命名空间等；但不共享文件系统，而是通过 docker 的 volume 机制来实现数据的共享；</p>
<p>一个 pod 中的所有容器具有相同的 loopback 网络接口，因此容器之间可以通过 localhost 与同一个 pod 中的其他容器进行通信；</p>
<p>集群中的所有 pod 都在同一个网络地址空间中，这意味着每个 pod 都可以使用其他 pod 的 IP 地址，与该 pod 直接进行通信，而无须 NAT 网络地址转换；</p>
<p>总结：pod 就像一台逻辑主机，其行为和物理主机或虚拟主机非常相似，区别在于运行于 pod 当中的每个进程被封装在一个容器之中；</p>
<h4 id="通过-pod-合理管理容器"><a href="#通过-pod-合理管理容器" class="headerlink" title="通过 pod 合理管理容器"></a>通过 pod 合理管理容器</h4><p>将多层应用分散到多个 pod 中是一种更好的实践，这样可以更充分的利用集群中的节点的计算资源，因为单个 pod 只会被安装在一个工作节点上；并且这样也方便更细粒度的对应用进行扩容；</p>
<h5 id="何时在一个-pod-中使用多个容器？"><a href="#何时在一个-pod-中使用多个容器？" class="headerlink" title="何时在一个 pod 中使用多个容器？"></a>何时在一个 pod 中使用多个容器？</h5><p>仅当其他容器是做为主容器的辅助身份出现时，例如提供日志转换器和收集器、数据处理器、通信适配器等；</p>
<h5 id="做决定前待思考的问题"><a href="#做决定前待思考的问题" class="headerlink" title="做决定前待思考的问题"></a>做决定前待思考的问题</h5><ul>
<li>它们需要一起运行，还是可以在不同的主机上运行？</li>
<li>它们代表的是一个整体，还是相互独立的组件？</li>
<li>它们必须一起进行扩缩容还是可以分别进行？</li>
</ul>
<h3 id="以-YAML-或-JSON-描述文件创建-pod"><a href="#以-YAML-或-JSON-描述文件创建-pod" class="headerlink" title="以 YAML 或 JSON 描述文件创建 pod"></a>以 YAML 或 JSON 描述文件创建 pod</h3><p>YAML 的基本结构组成</p>
<ul>
<li>版本</li>
<li>类型</li>
<li>元信息</li>
<li>规格</li>
</ul>
<p>在 pod 定义中指定端口仅起到展示性的作用，以便让看到这个文件的人知道当前 pod 有哪些端口可以被访问，即使不写，也仍然可以访问；另外一个好处是可以给该端口指定名称，这样使用起来将更加方便；</p>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h6 id="kubectl-get-pod-o-yaml"><a href="#kubectl-get-pod-o-yaml" class="headerlink" title="kubectl get pod  -o yaml"></a>kubectl get pod <pod-name> -o yaml</h6><p>查看容器的描述，支持 yaml 和 json 两种格式</p>
<h6 id="kubectl-create-f"><a href="#kubectl-create-f" class="headerlink" title="kubectl create -f "></a>kubectl create -f <yaml-file-name></h6><p>按 yaml 文件创建相应的资源；</p>
<blockquote>
<p>好奇 create 和 apply 有什么区别？答：使用 apply 创建的资源，后果可以再次使用 apply 来检查声明文件是否存在更新，如果有更新，会自动删除旧资源，并创建新资源；</p>
</blockquote>
<h6 id="kubectl-logs"><a href="#kubectl-logs" class="headerlink" title="kubectl logs "></a>kubectl logs <pod-name></h6><p>查看 pod 的日志；</p>
<blockquote>
<p>当日志文件达到 10MB 大小时，日志会自动轮替；</p>
</blockquote>
<h6 id="kubectl-logs-c"><a href="#kubectl-logs-c" class="headerlink" title="kubectl logs  -c "></a>kubectl logs <pod-name> -c <container-name></h6><p>获取 pod 中某个容器的日志；</p>
<blockquote>
<p>默认情况下，日志的生命周期和 pod 绑定，即 pod 删除后，日志也消失了；如果想保留日志，则需要另外建立一个中心化的日志系统来存储日志；</p>
</blockquote>
<h4 id="向-pod-发送请求"><a href="#向-pod-发送请求" class="headerlink" title="向 pod 发送请求"></a>向 pod 发送请求</h4><h6 id="kubectl-port-forwad-kubia-manual-8888-8080"><a href="#kubectl-port-forwad-kubia-manual-8888-8080" class="headerlink" title="kubectl port-forwad kubia-manual 8888:8080"></a>kubectl port-forwad kubia-manual 8888:8080</h6><p>在不使用 service 的情况下，port-forwad 可将本地端口转发到 pod 中的某个端口</p>
<h3 id="使用标签组织-pod"><a href="#使用标签组织-pod" class="headerlink" title="使用标签组织 pod"></a>使用标签组织 pod</h3><p>标签不仅可以用来组织 pod，也可以用来组织其他的 kubernetes 资源；</p>
<p>创建资源时，可以附加标签；创建之后，仍然可以添加标签或修改标签；</p>
<p>通过标签，可以非常方便的对资源进行分类管理；也可以实现批量化操作；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180838.png"></p>
<h4 id="添加或修改标签"><a href="#添加或修改标签" class="headerlink" title="添加或修改标签"></a>添加或修改标签</h4><h6 id="kubectl-label-po"><a href="#kubectl-label-po" class="headerlink" title="kubectl label po  &#x3D;"></a>kubectl label po <pod-name> <key>&#x3D;<value></h6><p>新增标签</p>
<h6 id="kubectl-label-po-–overwrite"><a href="#kubectl-label-po-–overwrite" class="headerlink" title="kubectl label po  &#x3D; –overwrite"></a>kubectl label po <pod-name> <key>&#x3D;<value> –overwrite</h6><p>通过 –overwrite 选项更改旧标签</p>
<h3 id="通过标签选择器列出-pod-子集"><a href="#通过标签选择器列出-pod-子集" class="headerlink" title="通过标签选择器列出 pod 子集"></a>通过标签选择器列出 pod 子集</h3><h4 id="标签选择器的选择条件"><a href="#标签选择器的选择条件" class="headerlink" title="标签选择器的选择条件"></a>标签选择器的选择条件</h4><ul>
<li>包含（或不包含）特定键；</li>
<li>包含特定的键值对；</li>
<li>包含特定键，但值不同；</li>
</ul>
<blockquote>
<p>标签选择器支持多个条件，此时需要满足全部条件才算匹配成功；</p>
</blockquote>
<h3 id="使用标签和选择器来约束-pod-调度"><a href="#使用标签和选择器来约束-pod-调度" class="headerlink" title="使用标签和选择器来约束 pod 调度"></a>使用标签和选择器来约束 pod 调度</h3><p>当节点是同质的时候，无须显式的声明 pod 应该被调度的位置；但当节点是异质的时候，如果应用程序对硬件有要求，则需要使用需求描述，来告知 kubernetes 对调度的要求（但仍然不是显式指定节点，而是由 kubernetes 自行安排），例如设置标签做为过滤的条件 label gpu&#x3D;true；</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubia-gpu</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">gpu:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">luksa/kubia</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">kubia</span></span><br></pre></td></tr></table></figure>

<p>虽然也可以将 pod 调度到某个确定的节点（通过节点唯一标签实现，即 kubernetes.io&#x2F;hostname），但是这样风险很大，因为有可能该节点刚好处于不可用状态，这样会导致部署不成功；所以，最好的方式是使用标签选择器；</p>
<h3 id="注解-pod"><a href="#注解-pod" class="headerlink" title="注解 pod"></a>注解 pod</h3><p>注解也是一个类似标签的键值对的形式，但是它不能用于选择器，它的用途在于给对象添加更多说明性的信息，方便其他人了解对象的一些重要信息；</p>
<p>除了手动添加注解后，Kubernetes 本身也会根据需要，自动给对象添加一些注解；</p>
<p>注解信息存储于对象 metadata 下的 annotations 字段中；</p>
<h5 id="添加和修改注解"><a href="#添加和修改注解" class="headerlink" title="添加和修改注解"></a>添加和修改注解</h5><h6 id="kubectl-annotate-pod-kubia-manual-mycompany-com-somea-nnotation-”foo-bar”"><a href="#kubectl-annotate-pod-kubia-manual-mycompany-com-somea-nnotation-”foo-bar”" class="headerlink" title="kubectl annotate pod kubia-manual mycompany.com&#x2F;somea nnotation&#x3D;”foo bar”"></a>kubectl annotate pod kubia-manual mycompany.com&#x2F;somea nnotation&#x3D;”foo bar”</h6><p>使用“mycompany.com&#x2F;someannotation”这种格式的目的在于尽量减少冲突，避免不小心覆盖的可能性</p>
<h3 id="使用命名空间对资源进行分组"><a href="#使用命名空间对资源进行分组" class="headerlink" title="使用命名空间对资源进行分组"></a>使用命名空间对资源进行分组</h3><p>通过标签来分组，存在的问题是不同标签之间的对象可能会有重叠，如果想实现不重叠，则可以通过命名空间来进行分组；这样可以解决资源名称冲突、不同用户误删除其他用户资源的问题；同时还可以限制某些用户仅可访问某些资源、限制单个用户可用的计算资源数量等；</p>
<p>命名空间是比资源更高一个层级的抽象，所以对象都默认属于某个命名空间中；如果没有特意指明哪个命名空间，一般是在 default 命名空间中操作对象；命名空间相当于给资源名称提供了一个作用域；</p>
<p>当需要操作某个特定命名空间中的对象时，需要在命令中指定相应的命名空间名称；</p>
<h4 id="创建一个命名空间"><a href="#创建一个命名空间" class="headerlink" title="创建一个命名空间"></a>创建一个命名空间</h4><p>有两种创建方法：</p>
<ul>
<li>直接通过 create 命令创建，示例： kubectl create namespace <space_name></li>
<li>通过 YAML 描述文件创建；</li>
</ul>
<blockquote>
<p>领悟：在 kubernetes 中，所有东西其实都是对象，都可以使用 YAML 文件来描述对象的一些属性特征，然后通过 create 命令创建该对象；</p>
</blockquote>
<h4 id="管理命名空间中的资源"><a href="#管理命名空间中的资源" class="headerlink" title="管理命名空间中的资源"></a>管理命名空间中的资源</h4><p>当命名空间创建好了以后，如果要将某个对象放入该空间，也有两种方法：</p>
<ul>
<li>在 create 命令中通过 -n 选项指定空间名，示例：kubectl create -f <yaml_file> -n <space_name></li>
<li>在 YAML 文件中的 metadata 下的字段 namespace 指定所属的命名空间</li>
</ul>
<p>在对命名空间中的对象进行增删改查操作时，需要指定相应的命名空间名称，否则将默认操作当前上下文命名空间中的资源（默认是  default ，但可以通过 kubectl config 对当前上下文进行修改）；</p>
<blockquote>
<p>注：命名空间仅仅是一种逻辑上的资源分组，它并不提供资源之间的物理隔离，因此不同命名空间的对象之间，如果知道对方的 IP 地址，仍然是可以相互通信的；</p>
</blockquote>
<h3 id="停止和移除-pod"><a href="#停止和移除-pod" class="headerlink" title="停止和移除 pod"></a>停止和移除 pod</h3><h4 id="按名称删除-pod"><a href="#按名称删除-pod" class="headerlink" title="按名称删除 pod"></a>按名称删除 pod</h4><h6 id="kubectl-delete-po"><a href="#kubectl-delete-po" class="headerlink" title="kubectl delete po  "></a>kubectl delete po <pod_name1> <pod_name2></h6><h4 id="使用标签选择器删除-pod"><a href="#使用标签选择器删除-pod" class="headerlink" title="使用标签选择器删除 pod"></a>使用标签选择器删除 pod</h4><h6 id="kubectl-delete-po-l"><a href="#kubectl-delete-po-l" class="headerlink" title="kubectl delete po -l &#x3D;"></a>kubectl delete po -l <label_key>&#x3D;<label_value></h6><h4 id="通过删除整个命名空间来删除-pod"><a href="#通过删除整个命名空间来删除-pod" class="headerlink" title="通过删除整个命名空间来删除 pod"></a>通过删除整个命名空间来删除 pod</h4><h6 id="kubectl-delete-ns"><a href="#kubectl-delete-ns" class="headerlink" title="kubectl delete ns "></a>kubectl delete ns <space_name></h6><p>该命名将删除整个命名空间，以及里面的 pod</p>
<h4 id="删除命名空间中的-pod，但保留命名空间"><a href="#删除命名空间中的-pod，但保留命名空间" class="headerlink" title="删除命名空间中的 pod，但保留命名空间"></a>删除命名空间中的 pod，但保留命名空间</h4><h6 id="kubectl-delete-po-–all"><a href="#kubectl-delete-po-–all" class="headerlink" title="kubectl delete po –all"></a>kubectl delete po –all</h6><p>–all 选项确实会删除当前运行中的所有 pod，但问题是如果控制器没有停止运行的话，它将根据描述文件的描述，重新创建 pod 出来；</p>
<h4 id="删除命名空间中的（几乎）所有资源"><a href="#删除命名空间中的（几乎）所有资源" class="headerlink" title="删除命名空间中的（几乎）所有资源"></a>删除命名空间中的（几乎）所有资源</h4><h6 id="kubectl-delete-all-–all"><a href="#kubectl-delete-all-–all" class="headerlink" title="kubectl delete all –all"></a>kubectl delete all –all</h6><h2 id="4-副本机制和其他控制器：部署托管的-pod"><a href="#4-副本机制和其他控制器：部署托管的-pod" class="headerlink" title="4. 副本机制和其他控制器：部署托管的 pod"></a>4. 副本机制和其他控制器：部署托管的 pod</h2><p>pod 是最小的单元，它需要被部署到节点上，而这意味着当节点失败时，pod 也将被删除；因此需要引入一种机制，当发现节点失败时，会在新节点上面部署 pod，这样才可以确保 pod 随时健康运行；一般通过 ReplicationController 或 Deployment 来实现这一点；</p>
<h3 id="保持-pod-健康"><a href="#保持-pod-健康" class="headerlink" title="保持 pod 健康"></a>保持 pod 健康</h3><p>应用存在于容器之中，如果是容器挂了，K8s 会重启容器，但如果是应用程序挂了而容器还正常运行时，就需要引入一种监控机制，来重启应用程序了；</p>
<h4 id="介绍存活探针"><a href="#介绍存活探针" class="headerlink" title="介绍存活探针"></a>介绍存活探针</h4><p>存活探针：liveness probe，用来探测应用程序是否在正常运行中，如果探测失败，就会重启容器；</p>
<blockquote>
<p>另外还有一种就绪探针，readiness probe，它适用于不同的场景；</p>
</blockquote>
<h5 id="三种类型的探针："><a href="#三种类型的探针：" class="headerlink" title="三种类型的探针："></a>三种类型的探针：</h5><ul>
<li>HTTP GET 探针：向应用发送 GET 请求，像是否收到正确的响应码；</li>
<li>TCP 套接字探针：与容器中的指定端口建立连接，像是否能够连接成功；</li>
<li>Exec 探针：在容器内运行指定的命令，看退出状态码是否为 0（表示正常），非零表示失败；</li>
</ul>
<h4 id="创建基于-HTTP-的存活探针"><a href="#创建基于-HTTP-的存活探针" class="headerlink" title="创建基于 HTTP 的存活探针"></a>创建基于 HTTP 的存活探针</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180904.png"></p>
<h4 id="使用存活探针"><a href="#使用存活探针" class="headerlink" title="使用存活探针"></a>使用存活探针</h4><blockquote>
<p>logs 命令是查看当前 pod 的日志，如果加上 –previous 选项，则可以查看之前 pod 的日志</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180920.png"></p>
<p>当探针检查到容器不健康后，K8s 会删除旧的容器，创建新容器，而不是重启原来的容器；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180936.png"></p>
<h4 id="配置存活探针的附加属性"><a href="#配置存活探针的附加属性" class="headerlink" title="配置存活探针的附加属性"></a>配置存活探针的附加属性</h4><h5 id="设置首次探测等待时间"><a href="#设置首次探测等待时间" class="headerlink" title="设置首次探测等待时间"></a>设置首次探测等待时间</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815180956.png"></p>
<blockquote>
<p>如果不设置初始等待时间，则将在启动时马上探测容器，这样通常会导致失败；</p>
</blockquote>
<h4 id="创建有效的存活探针"><a href="#创建有效的存活探针" class="headerlink" title="创建有效的存活探针"></a>创建有效的存活探针</h4><h5 id="存活探针应该检查什么"><a href="#存活探针应该检查什么" class="headerlink" title="存活探针应该检查什么"></a>存活探针应该检查什么</h5><p>存活探针的作用在于确保应用程序健康工作，因此可以在应用程序中增加一个 API，当正常工作时，访问该 API 可以运行相应的代码，检查各项组件正常工作，之后返回一个正确的代号；</p>
<h5 id="保持探针轻量"><a href="#保持探针轻量" class="headerlink" title="保持探针轻量"></a>保持探针轻量</h5><p>探针本身是会消耗计算资源的，而且由于它的运行频率也比较高，因此非常有必要保证它是轻量的，一般可以使用 HTTP GET 探针；</p>
<h5 id="无须在探针中实现重试循环"><a href="#无须在探针中实现重试循环" class="headerlink" title="无须在探针中实现重试循环"></a>无须在探针中实现重试循环</h5><p>虽然探针的失败阈值是可以配置的，但是貌似没有必要；</p>
<h3 id="了解-ReplicationController"><a href="#了解-ReplicationController" class="headerlink" title="了解 ReplicationController"></a>了解 ReplicationController</h3><p>ReplicationController 副本管理器；pod 运行在节点中，只有当 pod 被 ReplicationController 管理时，pod 才会在节点故障消失后马上被重建；</p>
<p>ReplicationController 通过标签选择器来判断符合条件的 pod 数量是否与预期相符；</p>
<h4 id="ReplicationController-的操作"><a href="#ReplicationController-的操作" class="headerlink" title="ReplicationController 的操作"></a>ReplicationController 的操作</h4><p>ReplicationController 有三个组件，分别是标签选择器、副本数量、pod 模板；当更改副本数量时，会影响现有的 pod；当更改标签选择器和模板时，会使现在的 pod 脱离监控；ReplicationController 将不再关注这些 pod；</p>
<h4 id="创建一个-ReplicationController"><a href="#创建一个-ReplicationController" class="headerlink" title="创建一个 ReplicationController"></a>创建一个 ReplicationController</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181014.png"></p>
<blockquote>
<p>如果不指定选择器，则 K8S 会以模板里面的标签自动作为选择器的内容，这样更安全，避免因为不小心写错选择器，导致无休止的一直创建 pod；</p>
</blockquote>
<h4 id="使用-ReplicationController"><a href="#使用-ReplicationController" class="headerlink" title="使用 ReplicationController"></a>使用 ReplicationController</h4><p>查看 rc 的状态</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181029.png"></p>
<h4 id="将-pod-移入或移出-ReplicationController-的作用域"><a href="#将-pod-移入或移出-ReplicationController-的作用域" class="headerlink" title="将 pod 移入或移出 ReplicationController 的作用域"></a>将 pod 移入或移出 ReplicationController 的作用域</h4><p>ReplicationController 与 pod 之间其实没有任何的绑定管理，它们纯粹是通过标签选择器联系在一起的，因此只需要改变 rc 的标签选择器，或者改变 pod 的标签，它们就会建立或者断开联系；</p>
<p>如果改动了 pod 的标签，它与原来的 rc 失去联系，rc 会发现少了一个家伙，之后 rc 会重新创建一个 pod；</p>
<p>如果改动了 rc 的标签选择器，将导致现有的 pod 全部脱离联系，并且会生成三个新的 pod；</p>
<h4 id="修改-pod-模板"><a href="#修改-pod-模板" class="headerlink" title="修改 pod 模板"></a>修改 pod 模板</h4><p>rc 的 pod 模板也可以被修改，但是修改之后并不会影响当前正在运行的 pod，而只会影响后续新创建出来的 pod；这样方法可以用来升级 pod，但它不是升级 pod 的最好方法；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181053.png"></p>
<blockquote>
<p>edit 命令会使用默认的编辑器来操作 yaml 文件，可以通过设置 KUBE_EDITOR 环境变量来改变默认编辑器</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181107.png"></p>
<h4 id="水平缩放-pod"><a href="#水平缩放-pod" class="headerlink" title="水平缩放 pod"></a>水平缩放 pod</h4><p>有两种方法可以实现水平缩放，一种是使用 kubectl scale 命令，一种是直接编辑修改 yaml 文件；</p>
<h4 id="删除一个-ReplicationCotroller"><a href="#删除一个-ReplicationCotroller" class="headerlink" title="删除一个 ReplicationCotroller"></a>删除一个 ReplicationCotroller</h4><p>删除 ReplicationCotroller 时，默认会删除由其监管的 pod，但如果加上 cascade 选项后，就可以仅删除 rc 本身，而不删除 pod；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181126.png"></p>
<h3 id="使用-ReplicaSet-而不是-ReplicationController"><a href="#使用-ReplicaSet-而不是-ReplicationController" class="headerlink" title="使用 ReplicaSet 而不是 ReplicationController"></a>使用 ReplicaSet 而不是 ReplicationController</h3><p>ReplicaSet 是新一代的 ReplicationController，用来取代 ReplicationController；</p>
<h4 id="比较-ReplicationController-和-ReplicaSet"><a href="#比较-ReplicationController-和-ReplicaSet" class="headerlink" title="比较 ReplicationController 和 ReplicaSet"></a>比较 ReplicationController 和 ReplicaSet</h4><p>它们二者基本上完全相同，区别在于 ReplicaSet 里面标签选择器的表达能力更强；例如可以支持：包含、不包含、等于等多种条件表达式；</p>
<h4 id="定义-ReplicaSet"><a href="#定义-ReplicaSet" class="headerlink" title="定义 ReplicaSet"></a>定义 ReplicaSet</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181144.png"></p>
<h4 id="创建和检查-ReplicaSet"><a href="#创建和检查-ReplicaSet" class="headerlink" title="创建和检查 ReplicaSet"></a>创建和检查 ReplicaSet</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181202.png"></p>
<h4 id="使用-ReplicaSet-的更富表达力的标签选择器"><a href="#使用-ReplicaSet-的更富表达力的标签选择器" class="headerlink" title="使用 ReplicaSet 的更富表达力的标签选择器"></a>使用 ReplicaSet 的更富表达力的标签选择器</h4><p>ReplicaSet 的更富表达力的标签选择器主要由它的 matchExpressions 属性来体现，它由三部分组成，分别是键名、条件运算符、键值（可以是列表）；</p>
<p>条件运算符包括：</p>
<ul>
<li>In：标签值包含在列表中</li>
<li>NotIn：标签值不在列表中</li>
<li>Exists：存在指定的标签（值无所谓）；</li>
<li>DoesNotExist：不存在指定的标签（值无所谓）；</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181217.png"></p>
<h3 id="使用-DaemonSet-在每个节点上运行一个-pod"><a href="#使用-DaemonSet-在每个节点上运行一个-pod" class="headerlink" title="使用 DaemonSet 在每个节点上运行一个 pod"></a>使用 DaemonSet 在每个节点上运行一个 pod</h3><p>由 ReplicaSet 管理的 pod 是随机分布在节点上面的，有可能每个节点刚好一个 pod，也有可能不那么平均，有些多点，有些少点；如果想让每个节点刚好运行一个 pod，则需要用到 DaemonSet 来搞定；</p>
<blockquote>
<p>一般来说，有这种特殊部署要求的 pod 主要是用来运行一些系统服务进程的；</p>
</blockquote>
<h4 id="使用-DaemonSet-在每个节点上运行一个-pod-1"><a href="#使用-DaemonSet-在每个节点上运行一个-pod-1" class="headerlink" title="使用 DaemonSet 在每个节点上运行一个 pod"></a>使用 DaemonSet 在每个节点上运行一个 pod</h4><p>DaemonSet 根据选择器选择出匹配的节点后，就会在每个节点上运行一个 pod；</p>
<ul>
<li>如果节点挂了，则它不会有动作；</li>
<li>但如果添加一个新节点到集群中，则它会马上给这个新节点创建一个 pod；</li>
<li>如果节点上面的 pod 挂了，则它会重新在该节点上面创建一个 pod；</li>
</ul>
<h4 id="使用-DaemonSet-只在特定的节点上运行-pod"><a href="#使用-DaemonSet-只在特定的节点上运行-pod" class="headerlink" title="使用 DaemonSet 只在特定的节点上运行 pod"></a>使用 DaemonSet 只在特定的节点上运行 pod</h4><p>DaemonSet 通过 pod 模板中的 nodeSelector 来选择匹配的节点；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181234.png"></p>
<p>由于 DaemonSet 是使用标签选择器来匹配节点，因此让节点的标签被修改后不再匹配时，DaemonSet 会帮忙将该节点上面已经创建的 pod 删除掉；</p>
<h3 id="运行执行单个任务的-pod"><a href="#运行执行单个任务的-pod" class="headerlink" title="运行执行单个任务的 pod"></a>运行执行单个任务的 pod</h3><p>ReplicationController、ReplicaSet、DaemonSet 创建出来的 pod 都是持续运行的，当需要创建一些只运行一次就退出的 pod 时，这个时候 Job 出场才能搞定了；</p>
<h4 id="介绍-Job-资源"><a href="#介绍-Job-资源" class="headerlink" title="介绍 Job 资源"></a>介绍 Job 资源</h4><p>Job 很适合去干一些临时任务，尤其是这些临时任务需要在每个节点上面跑一次，而且每次跑的时间比较长，有可能中途出现意外，需要重新再跑的时候；这时用 Job 的优势就体现出来了，因为它可以通过选择器批量在多个节点上面跑任务，然后会持续监控任务顺利完成才罢休，不然会自动重新运行意外退出的任务，直到它成功为止，这样是可以让人很省心的；</p>
<h4 id="定义-Job-资源"><a href="#定义-Job-资源" class="headerlink" title="定义 Job 资源"></a>定义 Job 资源</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815181251.png"></p>
<p>Job 的 restartPolicy 只能是 onFailure 或者 Never，不能是通常默认的 Always；</p>
<h4 id="在-Job-运行一个-pod"><a href="#在-Job-运行一个-pod" class="headerlink" title="在 Job 运行一个 pod"></a>在 Job 运行一个 pod</h4><p>Job 管理的 pod 在运行完成后，会变成“已完成”的状态，但不会被删除，因为这样可以查阅日志，如果删除了就没有办法看到运行的日志了；</p>
<h4 id="在-Job-中运行多个-pod-实例"><a href="#在-Job-中运行多个-pod-实例" class="headerlink" title="在 Job 中运行多个 pod 实例"></a>在 Job 中运行多个 pod 实例</h4><p>Job 可以运行一次创建一个 pod，也可以运行多次，创建多个 pod 实例，这些实例可以并行运行，也可以串行；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152647.png"></p>
<h4 id="限制-Job-pod-完成任务的时间"><a href="#限制-Job-pod-完成任务的时间" class="headerlink" title="限制 Job pod 完成任务的时间"></a>限制 Job pod 完成任务的时间</h4><p>有些 pod 有可能运行很久才能结束，但有时候万一卡住了则将永不结束；因此，可以通过设置运行时间的上限来解决这个问题；当超时后，就会 pod 终止，并将 Job 标记为失败；</p>
<blockquote>
<p>通过设置 activeDeadlineSeconds 属性来实现；</p>
</blockquote>
<h3 id="安排-Job-定期运行或在将来运行一次"><a href="#安排-Job-定期运行或在将来运行一次" class="headerlink" title="安排 Job 定期运行或在将来运行一次"></a>安排 Job 定期运行或在将来运行一次</h3><p>如果有些任务需要定期重复执行，如果在某个特定的时间点执行，则此时通过通过创建 CronJob 来实现；</p>
<h4 id="创建一个-CronJob"><a href="#创建一个-CronJob" class="headerlink" title="创建一个 CronJob"></a>创建一个 CronJob</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152714.png"></p>
<h4 id="了解计划任务的运行方式"><a href="#了解计划任务的运行方式" class="headerlink" title="了解计划任务的运行方式"></a>了解计划任务的运行方式</h4><p>设置 pod 的最迟开始时间，如果超过了指定的时间还没有开始运行，则 Job 会被标记为失败；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152734.png"></p>
<h6 id="问题一：如果-CronJob-同时创建了两个任务怎么办？"><a href="#问题一：如果-CronJob-同时创建了两个任务怎么办？" class="headerlink" title="问题一：如果 CronJob 同时创建了两个任务怎么办？"></a>问题一：如果 CronJob 同时创建了两个任务怎么办？</h6><p>答：执行的任务需要是幂等的，即多次运行仍然会得到相同的结果；</p>
<h6 id="问题二：如果-CronJob-遗漏没有创建任务怎么办？"><a href="#问题二：如果-CronJob-遗漏没有创建任务怎么办？" class="headerlink" title="问题二：如果 CronJob 遗漏没有创建任务怎么办？"></a>问题二：如果 CronJob 遗漏没有创建任务怎么办？</h6><p>答：当下一个任务开始时，如果发现上一个任务错过了，则应该先完成前面一个任务的工作；</p>
<h2 id="5-服务：让客户端发现-pod-并与之通信"><a href="#5-服务：让客户端发现-pod-并与之通信" class="headerlink" title="5. 服务：让客户端发现 pod 并与之通信"></a>5. 服务：让客户端发现 pod 并与之通信</h2><p>由于 pod 的生命周期是短暂的，因此它的 IP 地址是动态变化的，所以需要有一种机制，能够稳定的连接到提供服务的 pod，这种机制就是服务；服务需要做两个事情，当 pod 就绪后，能够将请求路由给 pod 进行响应；当 pod 变动后，能够发现新 pod 的通信地址；</p>
<blockquote>
<p>猜测它的实现机制是让 pod 被创建并进入就绪状态后，就向相关控制器进行报告，相当于在控制器那里做一个登记备案，之后控制器就可以将外部请求路由给它了；</p>
</blockquote>
<h3 id="介绍服务"><a href="#介绍服务" class="headerlink" title="介绍服务"></a>介绍服务</h3><p>概念：服务很像一个有固定 IP 地址的负载均衡器，既能够被内部的 Pod 稳定的访问，也能够被外部稳定的访问，同时能够将外部请求路由给当前正在工作的 Pod；</p>
<h4 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h4><p>与其他资源类似，服务同样是通过标签选择器，来判断当前服务应该路由匹配到哪些 Pod；</p>
<h5 id="通过-kubectl-expose-创建服务"><a href="#通过-kubectl-expose-创建服务" class="headerlink" title="通过 kubectl expose 创建服务"></a>通过 kubectl expose 创建服务</h5><p>kubectl expose deployment hello-world –type&#x3D;LoadBalancer –name&#x3D;my-service</p>
<h5 id="通过-YAML-文件创建服务"><a href="#通过-YAML-文件创建服务" class="headerlink" title="通过 YAML 文件创建服务"></a>通过 YAML 文件创建服务</h5><h6 id="kubectl-create-kubia-svc-yaml"><a href="#kubectl-create-kubia-svc-yaml" class="headerlink" title="kubectl create kubia-svc.yaml"></a>kubectl create kubia-svc.yaml</h6><blockquote>
<p>kubia-svc.yaml</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152754.png"></p>
<h4 id="检测新的服务"><a href="#检测新的服务" class="headerlink" title="检测新的服务"></a>检测新的服务</h4><h6 id="kubectl-get-svc"><a href="#kubectl-get-svc" class="headerlink" title="kubectl get svc"></a>kubectl get svc</h6><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152816.png"></p>
<blockquote>
<p>默认情况下，服务的作用范围在集群内部，让 pod 之间可以通讯；</p>
</blockquote>
<h5 id="从内部集群测试服务"><a href="#从内部集群测试服务" class="headerlink" title="从内部集群测试服务"></a>从内部集群测试服务</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152836.png"></p>
<blockquote>
<p>此处的双横杠是命令的间隔，以便匹配给 kubectl 的参数和远程要执行的命令 curl</p>
</blockquote>
<h5 id="配置服务上的会话亲和性"><a href="#配置服务上的会话亲和性" class="headerlink" title="配置服务上的会话亲和性"></a>配置服务上的会话亲和性</h5><p>由于负载均衡的存在，一般来说每次服务调用都会随机分配给不同的 pod 进行响应，但是可以通过设置 sessionAffinity 属性来指定倾向性的 pod IP；它会将来源某个特定 ClientIP 的请求都转发到某个特定的 Pod 上面；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20210825114013.png"></p>
<h5 id="同一个服务暴露多个端口"><a href="#同一个服务暴露多个端口" class="headerlink" title="同一个服务暴露多个端口"></a>同一个服务暴露多个端口</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152856.png"></p>
<h5 id="使用命名的端口"><a href="#使用命名的端口" class="headerlink" title="使用命名的端口"></a>使用命名的端口</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152912.png"></p>
<blockquote>
<p>使用命名端口的好处是万一端口号改了，也不需要改动调用的地方；</p>
</blockquote>
<h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>当服务创建好了后，Kubernetes 会将服务的地址存起来，这样当后续有创建新的 Pod 时，它就会把服务的地址写入新 Pod 的环境变量中，这样新 Pod 就可以通过环境变量来访问服务了；</p>
<blockquote>
<p>但是如果 Pod 早于服务之前创建的话，就没有办法使用写入环境变量的方式了；</p>
</blockquote>
<h5 id="通过环境变量发现服务"><a href="#通过环境变量发现服务" class="headerlink" title="通过环境变量发现服务"></a>通过环境变量发现服务</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152929.png"></p>
<h5 id="通过-DNS-发现服务"><a href="#通过-DNS-发现服务" class="headerlink" title="通过 DNS 发现服务"></a>通过 DNS 发现服务</h5><p>当 Kubernetes 启动的时候，它其实会创建一个 Kube-dns 的 Pod，这个 Pod 的功能就是用来做 DNS 的工作的；所有服务都会在那里备案（即添加一个条目），以便其他 Pod 可以通过全限定域名（FQDN）查询到服务；</p>
<blockquote>
<p>Kubernetes 通过修改 Pod 中的 &#x2F;etc&#x2F;resolv.conf 文件， 强制 Pod 访问其创建的 内部 DNS 服务器（即名为 Kube-dns 的 Pod） ；但是 Pod 可以通过修改 spec 中的 dnsPolicy 属性来绕过它；</p>
</blockquote>
<h5 id="通过-FQDN-连接服务"><a href="#通过-FQDN-连接服务" class="headerlink" title="通过 FQDN 连接服务"></a>通过 FQDN 连接服务</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816152951.png"></p>
<ul>
<li>backend-database 表示服务的名称</li>
<li>default 表示命名空间</li>
<li>svc.cluster.local 表示本地集群</li>
</ul>
<blockquote>
<p>虽然服务可以通过名称进行访问，但访问者仍然需要知道服务的端口号，除非服务使用了标准端口号；</p>
</blockquote>
<p>如果访问者的 Pod 与提供服务的 Pod 在同一个命名空间和集群，则只需要服务名称就够了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153006.png"></p>
<h3 id="连接集群外部的服务"><a href="#连接集群外部的服务" class="headerlink" title="连接集群外部的服务"></a>连接集群外部的服务</h3><h4 id="介绍服务-endpoint"><a href="#介绍服务-endpoint" class="headerlink" title="介绍服务 endpoint"></a>介绍服务 endpoint</h4><p>直觉上服务和 pod 是直接连接的，但实际上之间隔着 endpoint 资源，服务直接对话的是 endpoint，之后才是 Pod；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153022.png"></p>
<h4 id="手动配置服务的-endpoint"><a href="#手动配置服务的-endpoint" class="headerlink" title="手动配置服务的 endpoint"></a>手动配置服务的 endpoint</h4><p>服务是通过标签选择器来创建相应数量的 endpoint 资源的，因此，如果服务没有写标签选择器，则 Kubernets 就不会为服务创建 endpoint，但是我们可以通过手动创建的方式，为服务创建相应的 endpoint；服务和 endpoint 需要使用相应的名称，才能建立关联；</p>
<p>此时通过创建外部 IP 地址的 endpoint，就可以实现对外部服务的访问；</p>
<h4 id="为外部服务创建别名"><a href="#为外部服务创建别名" class="headerlink" title="为外部服务创建别名"></a>为外部服务创建别名</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153039.png"></p>
<p>由于 ExternalName 已经提供了外部域名和端口，因此实际内部 Pod 在获得这些信息后，并不需要再走内部的 DNS 服务代理，而是可以直接访问公网的 DNS 服务器，完成对外部服务的访问；</p>
<blockquote>
<p>因此 Kubernetes 都不需要为 ExternalName 类型的服务分配内部 IP 地址了；</p>
</blockquote>
<h3 id="将服务暴露给外部客户端"><a href="#将服务暴露给外部客户端" class="headerlink" title="将服务暴露给外部客户端"></a>将服务暴露给外部客户端</h3><p>暴露服务给外部有三种方法：</p>
<ul>
<li>NodePort</li>
<li>LoadBalance</li>
<li>Ingress</li>
</ul>
<h4 id="使用-NodePort-类型的服务"><a href="#使用-NodePort-类型的服务" class="headerlink" title="使用 NodePort 类型的服务"></a>使用 NodePort 类型的服务</h4><p>NodePort 的机制是在所有的节点上预留一个相同的端口，当外部访问该端口时，就将请求转发到内部提供服务的资源（其实它也是一个 Pod）；这意味着不仅可以通过 ClusterIP 访问服务，也可以通过任意节点的公网 IP 访问服务；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153053.png"></p>
<blockquote>
<p>虽然 NodePort 服务的好处是访问任意节点的 IP 和相应端口即可以访问服务，但其实这种方式并不好，因为万一节点刚好宕机了，则访问将被拒绝；</p>
</blockquote>
<h4 id="通过负载均衡器将服务暴露出来"><a href="#通过负载均衡器将服务暴露出来" class="headerlink" title="通过负载均衡器将服务暴露出来"></a>通过负载均衡器将服务暴露出来</h4><p>负载均衡器需要集群托管供应商支持才行；如果支持的话，当配置服务的类型为 LoadBalancer 时，Kubernetes 就会调用供应商提供的接口，创建一个负载均衡器服务；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153106.png"></p>
<p>负载均衡器的本质仍然是一个 NodePort 服务，唯一的区别是它由云基础架构的供应商支持并单独部署出来，如果打开防火墙的话，仍然可以像 NodePort 服务那样通过节点的公网 IP 来访问服务；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153123.png"></p>
<blockquote>
<p>由于负载均衡器由云基础架构供应商单独提供，这意味着它是在集群外部、独立的；因此它需要将请求先路由到某个 node，再由该 node 将请求转给服务，之后服务再去寻找对应的 pod；</p>
</blockquote>
<h4 id="了解外部连接的特性"><a href="#了解外部连接的特性" class="headerlink" title="了解外部连接的特性"></a>了解外部连接的特性</h4><h5 id="了解并防止不必要的网络跳数"><a href="#了解并防止不必要的网络跳数" class="headerlink" title="了解并防止不必要的网络跳数"></a>了解并防止不必要的网络跳数</h5><p>正常来说，当外部请求到达节点时，节点会将连接请求转发到内部服务，然后由内部服务转发给任一 Pod，而这个 Pod 有可能在另外一个节点上面，导致出现不必要的跳转，因为本来在当前节点就有 Pod 可以提供服务了；</p>
<p>为了避免这个问题，可以通过设置 externalTrafficPolicy：local 来阻止额外的跳转；但是如果设置了这个属性为 local，则如果当前节点没有可用的 Pod 时，连接不会被转发，而是会被挂起，这就糟糕了；此时需要负载均衡器将连接转到至少有一个可用 pod 的节点上；</p>
<p>另外这个属性还有一个缺点是它会导致负载均衡器的效率变低，因为负载均衡本来是以 Pod 为单位进行均衡的，但是启用这个属性后，就变成以 Node 为单位了；</p>
<h5 id="记住客户端-IP-是不记录的"><a href="#记住客户端-IP-是不记录的" class="headerlink" title="记住客户端 IP 是不记录的"></a>记住客户端 IP 是不记录的</h5><p>如果外部请求是先到节点，再到服务，则会存在一个问题，即请求中的数据包的源地址将会被节点做 SNAT 转换，这会导致最终提供服务的 Pod 无法看到请求的源地址；如果请求是先到服务，则不存在以上问题；</p>
<blockquote>
<p>貌似使用负载均衡器将不可避免会遇到上述的问题？</p>
</blockquote>
<h3 id="通过-Ingress-暴露服务"><a href="#通过-Ingress-暴露服务" class="headerlink" title="通过 Ingress 暴露服务"></a>通过 Ingress 暴露服务</h3><p>LoadBalance 类型的服务的成本是很高的，因为每个服务都需要有自己的公网 IP；Ingress 即是为了解决这个问题而出现的；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153142.png"></p>
<p>由于 Ingress 是在 HTTP 层工作，因此它还可以提供 cookie 亲和性的功能；</p>
<blockquote>
<p>不是每一种 Kubernetes 实现都默认开启支持 Ingress 的，需要提前确认一下功能开启可用；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153201.png"></p>
<h4 id="创建-Ingress-资源"><a href="#创建-Ingress-资源" class="headerlink" title="创建 Ingress 资源"></a>创建 Ingress 资源</h4><p>使用描述文件创建：</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153219.png"></p>
<h4 id="通过-Ingress-访问服务"><a href="#通过-Ingress-访问服务" class="headerlink" title="通过 Ingress 访问服务"></a>通过 Ingress 访问服务</h4><p>它的工作原理跟 Nginx 几乎是一模一样的，唯一的区别是不需要在 Nginx 配置文件中说明如何转发请求了，而是在 Ingress 的描述文件中说明；</p>
<h4 id="通过相同的-Ingress-暴露多个服务"><a href="#通过相同的-Ingress-暴露多个服务" class="headerlink" title="通过相同的 Ingress 暴露多个服务"></a>通过相同的 Ingress 暴露多个服务</h4><h5 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153233.png"></p>
<h5 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153246.png"></p>
<h4 id="配置-Ingress-处理-TLS-传输"><a href="#配置-Ingress-处理-TLS-传输" class="headerlink" title="配置 Ingress 处理 TLS 传输"></a>配置 Ingress 处理 TLS 传输</h4><p>在 Kubernetes 中创建 secrets 资源，然后在 Ingress 中引用它，就可以实现与客户端的加密传输了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153302.png"></p>
<blockquote>
<p>当增加证书选项后，如果 Ingress 资源已经创建，此时不需要删除重建，只需要再次运行 kubectl apply 命令，即可更新资源；</p>
</blockquote>
<blockquote>
<p>问：如何给证书添加 secret 以便 ingress 可以引用？<br><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200820103419.png"></p>
</blockquote>
<h3 id="pod-就绪后发出信号"><a href="#pod-就绪后发出信号" class="headerlink" title="pod 就绪后发出信号"></a>pod 就绪后发出信号</h3><p>pod 的就绪一般需要一点时间，如果 pod 启动后，立刻将请求接入进来，则第一个响应可能花费的时间比较久，因此需要有个机制能够声明自己是否进入就绪状态；</p>
<h4 id="介绍就绪探针"><a href="#介绍就绪探针" class="headerlink" title="介绍就绪探针"></a>介绍就绪探针</h4><p>每个容器就绪的状态各有不同，因此就绪探针需要开发人员针对每个容器单独设置；</p>
<h5 id="就绪探针的三种类型"><a href="#就绪探针的三种类型" class="headerlink" title="就绪探针的三种类型"></a>就绪探针的三种类型</h5><ul>
<li>Exec 探针：执行某个进程，状态由进程的退出状态码来确定；</li>
<li>HTTP GET 探针：发送 HTTP GET 请求，就绪状态由响应码确定；</li>
<li>TCP socket 探针：创建一个 TCP 连接，创建成功表示就绪</li>
</ul>
<h5 id="了解就绪探针的操作"><a href="#了解就绪探针的操作" class="headerlink" title="了解就绪探针的操作"></a>了解就绪探针的操作</h5><p>一般会设置一段等待的时间，之后再开启就绪探针的探测；如果容器未通过就绪状态的检查，容器不会被终止或者重新启动，但是存活探针就会；这是二者的主要区别；</p>
<h4 id="向-pod-添加就绪探针"><a href="#向-pod-添加就绪探针" class="headerlink" title="向 pod 添加就绪探针"></a>向 pod 添加就绪探针</h4><p>可以 ReplicationController 描述文件中的模板添加关于探针的描述，示例如下：</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153319.png"></p>
<h4 id="了解就绪探针的实际作用"><a href="#了解就绪探针的实际作用" class="headerlink" title="了解就绪探针的实际作用"></a>了解就绪探针的实际作用</h4><ul>
<li>务必定义就绪探针：因为 Pod 的就绪是需要时间的，如果一创建就接入请求，会导致客户端收到错误的响应；</li>
<li>不要将停止 Pod 的操作逻辑放在就绪探针中，这超出了就绪探针的使用范围；</li>
</ul>
<h3 id="使用-headless-服务来发现独立的-pod"><a href="#使用-headless-服务来发现独立的-pod" class="headerlink" title="使用 headless 服务来发现独立的 pod"></a>使用 headless 服务来发现独立的 pod</h3><p>在一些特殊的情况下，客户端可能连接到每个 Pod，而不是只连接到其中一个 Pod；此时客户端需要能够获取到所有 Pod 的 IP 地址列表，然后向它们发起请求；此时可以通过向 Kubernetes 中的 DNS 发起服务查询请求，正常情况下，这个请求返回的是服务 的 IP，但是如果配置服务的时候，其 ClusterIP 字段设置为 None，此该查询请求会获得所有的 Pod 的 IP；</p>
<h4 id="创建-Headless-服务"><a href="#创建-Headless-服务" class="headerlink" title="创建 Headless 服务"></a>创建 Headless 服务</h4><p>将服务的 ClusterIP 字段设置为 None 会使该服务变成一个 headless 服务；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153332.png"></p>
<h4 id="通过-DNS-发现-pod"><a href="#通过-DNS-发现-pod" class="headerlink" title="通过 DNS 发现 pod"></a>通过 DNS 发现 pod</h4><p>Kubernetes 没有自带 nslookup 功能，但查询 DNS 需要使用这个功能，因此，可以通过创建一个带此功能的临时 pod 来实现查询（只需选择一个包含该功能的镜像就可以创建相应的 pod 了，使用 kubectl run 命令来创建，而不是使用描述文件）；</p>
<h4 id="发现所有的-pod（包括未就绪的）"><a href="#发现所有的-pod（包括未就绪的）" class="headerlink" title="发现所有的 pod（包括未就绪的）"></a>发现所有的 pod（包括未就绪的）</h4><p>headless 类型的服务，可以查询到所有 pod，但默认只限为已经准备就绪的，如果想让它返回的结果包含未就绪的，需要在服务的 metadata 中添加一个字段进行描述，示例如下：</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153345.png"></p>
<blockquote>
<p>貌似这是一个老方案了，最新的版本中据说要使用 publishNotReadyAddress 字段来实现相同的功能；</p>
</blockquote>
<h3 id="排除服务故障"><a href="#排除服务故障" class="headerlink" title="排除服务故障"></a>排除服务故障</h3><p>有时候服务不能正常工作，此时需要进行调试，以排除故障，找出原因；调试的如下：</p>
<ul>
<li>确保是从集群内部发起的服务连接请求，而不是从集群外部；</li>
<li>不要通过 ping 来尝试连接集群内的服务，因为服务的 IP 是虚拟的；</li>
<li>如果有定义了就绪探针，确保它已经返回成功，因为未就绪的 pod 不会成为服务的组成部分；</li>
<li>可通过 kubectl get endpoints 来确认某个容器是否已经是服务的一部分了；</li>
<li>当尝试通过 FQDN 来访问服务时，可以试一下能够使用服务的集群 IP 来访问；</li>
<li>检查连接是否访问的是服务的公开端口，而不是其映射的目标端口；</li>
<li>尝试直接连接 pod IP，以确认 Pod 已经在正常工作；</li>
<li>如果 Pod IP 不可访问，需要检查一下 Pod 中的应用是否绑定并暴露相应的端口；</li>
</ul>
<h2 id="6-卷：将磁盘挂载到容器"><a href="#6-卷：将磁盘挂载到容器" class="headerlink" title="6. 卷：将磁盘挂载到容器"></a>6. 卷：将磁盘挂载到容器</h2><p>存储卷的级别低于 pod，它被定义为 pod 的一部分；因此，它不能被单独创建或者删除；当 pod 被销毁时，存储卷也会被销毁；（好奇如何存储全局数据？）</p>
<h3 id="介绍卷"><a href="#介绍卷" class="headerlink" title="介绍卷"></a>介绍卷</h3><h4 id="卷的应用示例"><a href="#卷的应用示例" class="headerlink" title="卷的应用示例"></a>卷的应用示例</h4><p>发现跟之前了解的 docker 存储卷的用法并没有区别，卷需要在 pod 文件中定义，而且，还需要在 containers 部分将它们进行挂载；</p>
<p>存储卷的生命周期跟 pod 绑定，但是据说即使在 pod 和存储卷被销毁后，里面的内容仍然存在（好奇如何实现）；</p>
<h4 id="可用的卷类型"><a href="#可用的卷类型" class="headerlink" title="可用的卷类型"></a>可用的卷类型</h4><ul>
<li>emptyDir：用于存储临时数据的简单空目录；</li>
<li>hostPath：用于将目录从工作节点的文件系统挂载到 pod 中；</li>
<li>gitRepo：用于检出 Git 仓库的内容来初始化的卷；p</li>
<li>nfs：挂载到 pod 中的 NFS 共享卷；</li>
<li>云存储：用于挂载云供应商提供的特定存储类型，例如 Google 的 gcePersistentDisk，亚马逊的 awsElastic BlockStore；微软的 azureDisk等；</li>
<li>网络存储：用于挂载其他类型的网络存储，例如 cinder, cephfs, iscsi, flocker, glusterfs 等等；</li>
<li>资源卷：用于将 Kubernetes 中的元数据资源公开给 pod 使用的特殊类型存储卷，例如 configMap, secret, downwardAPI 等；</li>
<li>persistentVolumeClaim：使用预置或者动态配置的持久存储类型；</li>
</ul>
<h3 id="通过卷在容器之间共享数据"><a href="#通过卷在容器之间共享数据" class="headerlink" title="通过卷在容器之间共享数据"></a>通过卷在容器之间共享数据</h3><h4 id="使用-emptyDir-卷"><a href="#使用-emptyDir-卷" class="headerlink" title="使用 emptyDir 卷"></a>使用 emptyDir 卷</h4><p>在 pod 的描述文件中使用存储卷</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153416.png"></p>
<p>另外，可通过 medium:Memory 将存储卷的介质限定为内存；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153428.png"></p>
<h4 id="使用-Git-仓库作为存储卷"><a href="#使用-Git-仓库作为存储卷" class="headerlink" title="使用 Git 仓库作为存储卷"></a>使用 Git 仓库作为存储卷</h4><p>gitRepo 本质上也是一个 emptyDir 存储卷，差别在于初始化的时候，会检出代码进行数据填充；但是如果 Git 仓库中的代码出现更新时，存储卷并不会跟着更新，此时如果删除旧 pod，重新创建新 pod 时就会拉取最新的代码；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153512.png"></p>
<p>保持代码和仓库同步的办法，可以在 pod 中增加一个 git sync 镜像（这类型的镜像有很多），存储卷同时也挂载到基于该镜像所创建的容器（这类容器称为 sidecar 容器）中，然后配置 Github 的 Webhook 进行访问即可；</p>
<blockquote>
<p>gitRepo 卷有一个缺点，它不能拉取私有的仓库；如果需要拉取私有仓库，则只能使用 sidecar 容器了；</p>
</blockquote>
<h3 id="访问工作节点文件系统上的文件"><a href="#访问工作节点文件系统上的文件" class="headerlink" title="访问工作节点文件系统上的文件"></a>访问工作节点文件系统上的文件</h3><p>由于 pod 跟 Node 是解耦的，因此 pod 理论上不应该使用 node 文件系统中的数据，但存在一些例外情况；当 pod 需要根据 node 的配置文件，对 node 做一些管理工作时，就需要去读取 node 上的文件（这种类型的 pod 一般由 DaemonSet 来管理）；</p>
<h4 id="hostPath-卷"><a href="#hostPath-卷" class="headerlink" title="hostPath 卷"></a>hostPath 卷</h4><p>hostPath 卷指向节点上的某个特定文件或者目录；同一个节点上的多个 pod，如果都有挂载相同路径的 hostPath 卷，则会实现文件的共享；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153528.png"></p>
<blockquote>
<p>hostPath 卷可以实现一定程度的持久性，即当一个 pod 被删除后，后续在同一个节点上建立的 pod 仍然可以使用上一个 pod 的遗留数据；但是这些数据无法在不同节点之间同步，所以它并不是一个适用于放置数据库文件的方案；</p>
</blockquote>
<h4 id="使用-hostPath-卷的-pod"><a href="#使用-hostPath-卷的-pod" class="headerlink" title="使用 hostPath 卷的 pod"></a>使用 hostPath 卷的 pod</h4><p>貌似 hostPath 卷挺适合用来访问节点上的日志文件或者 CA 证书；</p>
<h3 id="使用持久化存储"><a href="#使用持久化存储" class="headerlink" title="使用持久化存储"></a>使用持久化存储</h3><p>当数据需要在不同节点的 pod 之间共享时，此时需要使用某种类型的网络存储，pod 通过访问网络存储（NAS）进行数据的读取和写入；</p>
<h4 id="使用-GCE-持久磁盘作为-pod-存储卷"><a href="#使用-GCE-持久磁盘作为-pod-存储卷" class="headerlink" title="使用 GCE 持久磁盘作为 pod 存储卷"></a>使用 GCE 持久磁盘作为 pod 存储卷</h4><p>步骤</p>
<ul>
<li>先创建 GCE 持久磁盘：将持久磁盘创建在相同区域的 Kubernetes 集群中；</li>
<li>创建一个使用持久磁盘卷的 pod；</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153544.png"></p>
<h4 id="通过底层持久化存储使用其他类型的卷"><a href="#通过底层持久化存储使用其他类型的卷" class="headerlink" title="通过底层持久化存储使用其他类型的卷"></a>通过底层持久化存储使用其他类型的卷</h4><p>方法大同小异，都是先准备好持久性的存储资源，然后在 pod 描述文件中进行配置以连接它们进行使用；</p>
<blockquote>
<p>但是这种方法有很大的缺点，即开发人员需要了解这些持久性存储资源，并且描述文件和它们强耦合，如果换了一个集群环境，描述文件将不再可用，这不是一种最佳实践，有待改进；</p>
</blockquote>
<h3 id="从底层存储技术解耦-pod"><a href="#从底层存储技术解耦-pod" class="headerlink" title="从底层存储技术解耦 pod"></a>从底层存储技术解耦 pod</h3><h4 id="介绍持久卷和持久卷声明"><a href="#介绍持久卷和持久卷声明" class="headerlink" title="介绍持久卷和持久卷声明"></a>介绍持久卷和持久卷声明</h4><p>持久卷 persistent volume（PV）是一种资源，就像 service&#x2F;pod 一样，它由集群的硬件管理员通过声明来创建；之后开发人员通过持久卷（使用）声明 persistent volume claim (PVC) 来绑定它，然后再通过 pod 声明来来引用相应的持久卷声明；</p>
<blockquote>
<p>在同一个时间点，持久卷只能被声明并创建一次，即在它没有被删除前，不能在集群中声明相同名称的另外一个持久卷，除非先把原来旧的删掉；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153558.png"></p>
<h4 id="创建持久卷"><a href="#创建持久卷" class="headerlink" title="创建持久卷"></a>创建持久卷</h4><p>集群硬件管理员通过声明挂载网络存储来生成持久卷</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153613.png"></p>
<p>注：持久卷是全局资源，即它不属于任何单独的命名空间，就像节点一样；但是持久卷的使用声明是归属于特定命名空间的；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153628.png"></p>
<h4 id="通过创建持久卷声明来获取持久卷"><a href="#通过创建持久卷声明来获取持久卷" class="headerlink" title="通过创建持久卷声明来获取持久卷"></a>通过创建持久卷声明来获取持久卷</h4><p>开发人员在 pod 中引用持久卷之前，需要先创建持久卷声明，绑定某个持久卷，之后才能在 pod 中进行引用该持久卷声明；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153643.png"></p>
<h4 id="在-pod-中使用持久卷声明"><a href="#在-pod-中使用持久卷声明" class="headerlink" title="在 pod 中使用持久卷声明"></a>在 pod 中使用持久卷声明</h4><p>在创建了持久卷声明后，接下来可以在 pod 声明中引用该持久卷声明；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153658.png"></p>
<h4 id="了解使用持久卷和持久卷声明的好处"><a href="#了解使用持久卷和持久卷声明的好处" class="headerlink" title="了解使用持久卷和持久卷声明的好处"></a>了解使用持久卷和持久卷声明的好处</h4><p>通过增加了两层抽象，让开发人员和硬件管理员之间的工作实现了解耦，并增加了代码的可移植性，无须更改代码即可在不同的集群之间进行部署；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153714.png"></p>
<p>硬件管理员负责写创建声明创建持久卷，开发人员负责写使用声明绑定和引用持久卷；</p>
<blockquote>
<p>持久卷有多种读写模式，例如 RWO, ROX, RWX，它们限定的单位是工作节点 node，而不是 pod</p>
</blockquote>
<h4 id="回收持久卷"><a href="#回收持久卷" class="headerlink" title="回收持久卷"></a>回收持久卷</h4><p>当删除了持久卷声明后，如果之前绑定的持久卷的 reclaim policy 为 retain，则此时该持久卷仍然处于不可用的状态，因为里面存放着上一个 pod 的数据，为了确保数据安全，此时需要手工回收持久卷（即删除并重新创建持久卷资源）；</p>
<p>reclaim polic 还有另外两个选项：</p>
<ul>
<li>recycle：删除卷中的内容，并可被绑定到新的声明；</li>
<li>delete：删除底层存储；</li>
</ul>
<blockquote>
<p>并不是每一种云存储都同时全部三个选项的，不同的云存储的支持情况不同；<br>持久卷的回收策略，在持久卷创建之后，仍然是可以变更的；</p>
</blockquote>
<h3 id="持久卷的动态卷配置"><a href="#持久卷的动态卷配置" class="headerlink" title="持久卷的动态卷配置"></a>持久卷的动态卷配置</h3><p>集群管理员除了通过手工的方式来创建一个特定技术或平台的存储卷以外，还可以使用动态配置来自动化执行这个任务；</p>
<p>Kubernetes 内置了主流云服务提供商的 provisioner 脚本，通过调用脚本，可以实现自动化的资源申请；</p>
<p>动态配置的工作原理是集群管理员声明一个或多个的存储类 storageClass，然后开发人员在引用的时候，在声明中指定需要使用的类即可；</p>
<h4 id="通过-StorageClass-资源定义可用存储类型"><a href="#通过-StorageClass-资源定义可用存储类型" class="headerlink" title="通过 StorageClass 资源定义可用存储类型"></a>通过 StorageClass 资源定义可用存储类型</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153732.png"></p>
<p>在 provisioner 属性中指定了使用哪个云服务供应商的脚本创建存储资源；</p>
<h4 id="请求持久卷声明中的存储类"><a href="#请求持久卷声明中的存储类" class="headerlink" title="请求持久卷声明中的存储类"></a>请求持久卷声明中的存储类</h4><p>在集群管理员创建了 storageClass 资源后，接下开发人员就可以在 PVC 中进行引用；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153749.png"></p>
<p>StorageClass 是通过名称进行引用的，这意味着 PVC 的描述文件是可以在不同的集群中移植的；</p>
<h4 id="不指定存储类的动态配置"><a href="#不指定存储类的动态配置" class="headerlink" title="不指定存储类的动态配置"></a>不指定存储类的动态配置</h4><p>Kubernetes 自带一个默认的存储类，当开发人员在 PVC 中没有显示指定要引用的存储类时，将会默认使用自带的存储类；因此，如果想要让 Kubernetes 将 PVC 绑定到预先创建的 PV 时，需要将 storangeClasName 设置为空字符串，不然它会调用默认的云服务资源置备脚本自动创建新的存储卷；</p>
<p>因此，设置持久化存储的最简单办法 是创建 PVC 资源就好，至于 PV 此时可以由默认的置备脚本自行创建；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153805.png"></p>
<h2 id="7-ConfigMap-和-Secret-配置应用程序"><a href="#7-ConfigMap-和-Secret-配置应用程序" class="headerlink" title="7 ConfigMap 和 Secret: 配置应用程序"></a>7 ConfigMap 和 Secret: 配置应用程序</h2><h3 id="配置容器内应用程序"><a href="#配置容器内应用程序" class="headerlink" title="配置容器内应用程序"></a>配置容器内应用程序</h3><p>常见的传递配置参数的做法：</p>
<ul>
<li>传递命令行参数：参数少的时候；</li>
<li>引用配置文件：参数多的时候，运行容器前将配置文件挂载到卷中；</li>
<li>设置环境变量</li>
</ul>
<blockquote>
<p>敏感配置数据应区别对待，在 Kubernetes 中一般使用 configMap 保存非敏感配置项，用 secret 保存敏感配置项；</p>
</blockquote>
<h3 id="向容器传递命令行参数"><a href="#向容器传递命令行参数" class="headerlink" title="向容器传递命令行参数"></a>向容器传递命令行参数</h3><h4 id="在-Docker-中定义命令与参数"><a href="#在-Docker-中定义命令与参数" class="headerlink" title="在 Docker 中定义命令与参数"></a>在 Docker 中定义命令与参数</h4><ul>
<li>ENTRYPOINT 负责定义启动时要调用的命令；</li>
<li>CMD 负责定义传递给 ENTRYPOINT 的参数；</li>
<li>RUN 附加参数（会覆盖 CMD 的参数设置，如有）；</li>
</ul>
<blockquote>
<p>虽然也可以使用 CMD 将要执行的命令传递给容器，而不使用 ENTRYPOINT，但这样不太好，因为设置了 ENTRYPOINT 后，即使没有 CMD 选项，容器也依然能够正常运行；因此，CMD 最好只用来传递参数即可；</p>
</blockquote>
<p>指令可以有两种格式，分别是：</p>
<ul>
<li>shell 格式：例如 node app.js，该格式将使得 node 进程在 shell 运行；</li>
<li>exec 格式：例如 [“node”, “app.js”]，该格式将直接运行 node 进程，不在 shell 中运行；</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153819.png"></p>
<h4 id="在-Kubernetes-中覆盖命令和参数"><a href="#在-Kubernetes-中覆盖命令和参数" class="headerlink" title="在 Kubernetes 中覆盖命令和参数"></a>在 Kubernetes 中覆盖命令和参数</h4><p>镜像中的 ENTRYPOINT 和 CMD 都可以被运行时的命令行参数 command 和 args 覆盖；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153836.png"></p>
<h3 id="为容器设置环境变量"><a href="#为容器设置环境变量" class="headerlink" title="为容器设置环境变量"></a>为容器设置环境变量</h3><h4 id="在容器定义中指定环境变量"><a href="#在容器定义中指定环境变量" class="headerlink" title="在容器定义中指定环境变量"></a>在容器定义中指定环境变量</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153849.png"></p>
<h4 id="在环境变量值中引用其他环境变量"><a href="#在环境变量值中引用其他环境变量" class="headerlink" title="在环境变量值中引用其他环境变量"></a>在环境变量值中引用其他环境变量</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153902.png"></p>
<h4 id="了解硬编码环境变量的不足之处"><a href="#了解硬编码环境变量的不足之处" class="headerlink" title="了解硬编码环境变量的不足之处"></a>了解硬编码环境变量的不足之处</h4><p>环境变量如果硬编码在 pod 和容器定义中，意味着需要区别生产容器和非生产容器，这将增加很多管理负担；如果能够将配置参数从 pod 定义中解耦脱离出来的话，将使得 pod 本币的定义更加纯粹；</p>
<h3 id="利用-ConfigMap-解耦配置"><a href="#利用-ConfigMap-解耦配置" class="headerlink" title="利用 ConfigMap 解耦配置"></a>利用 ConfigMap 解耦配置</h3><h4 id="ConfigMap-介绍"><a href="#ConfigMap-介绍" class="headerlink" title="ConfigMap 介绍"></a>ConfigMap 介绍</h4><p>为了解决前面遇到的配置项耦合问题，Kubernetes 提供了 ConfigMap 资源来单独管理配置项；它本质上只是简单的键值对映射，值可以是字面量，也可以是文件；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153919.png"></p>
<p>ConfigMap 是一种资源，它并不是直接传递给容器，而是通过卷或者环境变量的形式，传递到容器中；因此， 容器中的应用仍然像传统方式一样读取环境变量或者文件来做出不同的行为，这样可以让应用保持对 Kubernetes 的无感知（最佳实践，有利于移植）；</p>
<h4 id="创建-ConfigMap"><a href="#创建-ConfigMap" class="headerlink" title="创建 ConfigMap"></a>创建 ConfigMap</h4><p>有四种方法创建 ConfigMap：</p>
<ul>
<li>可以直接在命令行中写字面量；</li>
<li>通过描述文件来创建  .yaml</li>
<li>通过导入文件来创建  –from-file</li>
<li>通过导入文件夹来创建</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816153943.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154000.png"></p>
<h4 id="给容器传递-ConfigMap条目作为环境变量"><a href="#给容器传递-ConfigMap条目作为环境变量" class="headerlink" title="给容器传递 ConfigMap条目作为环境变量"></a>给容器传递 ConfigMap条目作为环境变量</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154020.png"></p>
<p>如果某个容器所引用的 ConfigMap 资源不存在时，该容器将无法正常创建，会处于挂起状态，需要一直等到 ConfigMap 可用以后，容器才会被创建；除非将 ConfigMap 的引用备注为 optional，则此时虽然没有 ConfigMap，容器也会正常启动；</p>
<blockquote>
<p>使用 ConfigMap 的好处在于将所有的配置参数作为全局资源进行管理，而不是分散在各个单独的资源描述文件中；</p>
</blockquote>
<h4 id="一次性传递-ConfigMap-的所有条目作为环境变量"><a href="#一次性传递-ConfigMap-的所有条目作为环境变量" class="headerlink" title="一次性传递 ConfigMap 的所有条目作为环境变量"></a>一次性传递 ConfigMap 的所有条目作为环境变量</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154035.png"></p>
<blockquote>
<p>若 ConfigMap 中存在不合格的键名，在创建的时候将被忽略；</p>
</blockquote>
<h4 id="传递-ConfigMap-条目作为命令行参数"><a href="#传递-ConfigMap-条目作为命令行参数" class="headerlink" title="传递 ConfigMap 条目作为命令行参数"></a>传递 ConfigMap 条目作为命令行参数</h4><p>ConfigMap 并不能直接传递命令行参数，但是可以曲线救国，即通过设置环境变量，然后在命令行参数中引用环境变量就可以了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154050.png"></p>
<h4 id="使用-ConfigMap-卷将条目暴露为文件"><a href="#使用-ConfigMap-卷将条目暴露为文件" class="headerlink" title="使用 ConfigMap 卷将条目暴露为文件"></a>使用 ConfigMap 卷将条目暴露为文件</h4><p>存储卷有一种特殊的类型是 ConfigMap 卷，在创建了以文件作为条目的 ConfigMap 后，在声明存储卷时，可以引用该 ConfigMap，这样 ConfigMap 中的文件条目将被存储到卷中，然后我们可以在 Pod 的描述中引用该存储卷即可；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154106.png"></p>
<p>在描述文件中引用</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154120.png"></p>
<p>另外还可以只暴露部分条目到卷中</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154134.png"></p>
<p>默认情况下，挂载卷到容器中的某个文件夹时，该文件夹中原本的内容将全部被隐藏覆盖；但是可以通过 subpath 字段来避免覆盖原来的文件；此时 mountPath 的值是一个文件名，而不是文件夹，subPath 则是卷中的一个条目，而不是整个卷；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154152.png"></p>
<p>当设置 ConfigMap 作为存储卷的内容来源时，还可以同时设置这些内容的读写权限</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154209.png"></p>
<h4 id="更新应用配置且不重启应用程序"><a href="#更新应用配置且不重启应用程序" class="headerlink" title="更新应用配置且不重启应用程序"></a>更新应用配置且不重启应用程序</h4><p>使用环境变量或者命令行参数给容器传递配置信息的缺点当配置信息出现变更时，无法动态将变更后的数据传递给容器；但是如果使用 configMap 卷就可以，不过此时还是需要容器内的应用有监控文件变化并自动重新加载才行；</p>
<p>对于挂载到容器中的卷，如果卷中的文件发生了变化，它在容器中的内容也是实时变化的，但是容器中的应用程序并不一定会监控变化并重新加载；但是如果有重新加载的话，则变化将实时的体现出来；</p>
<p>卷中文件的更新并不是逐个文件进行的，Kubernetes 实际是先将卷的所有文件都复制到容器中的一个新文件夹，然后再更改链接指向这个新建的文件夹；这样就可以避免仅更新部分文件，还没有完成所有文件更新的情况下，容器中的应用程序已经开始加载文件了；</p>
<p>这意味着挂载的更新是以文件夹为单位的，因此，如果挂载的是单个文件，而该文件不会被更新；</p>
<p>虽然对于单个 pod 内部的容器，文件的更新是一次性完整的，但是对于不同 pod 引用相同的 configMap 的情况，这些  pod 之间并不是同步的，它们的更新有先有后；</p>
<p>仅在容器中的应用可以监控并主动重新加载更新后的文件时，挂载可以动态变化配置文件的 ConfigMap 才比较有意义；因为不然即使 ConfigMap 中的文件变化了，应用程序也不需要跟着变化；</p>
<h3 id="使用-Secret-给容器传递敏感数据"><a href="#使用-Secret-给容器传递敏感数据" class="headerlink" title="使用 Secret 给容器传递敏感数据"></a>使用 Secret 给容器传递敏感数据</h3><h4 id="介绍-Secret"><a href="#介绍-Secret" class="headerlink" title="介绍 Secret"></a>介绍 Secret</h4><p>Secret 被设计用来存储敏感信息，它的用法跟 ConfigMap 类似，区别在于它在写入节点时，不会被物理存储，只是仅存储在内存中，这样当 pod 删除时，也不会在物理介质中留下痕迹；</p>
<h4 id="默认令牌-Secret-介绍"><a href="#默认令牌-Secret-介绍" class="headerlink" title="默认令牌 Secret 介绍"></a>默认令牌 Secret 介绍</h4><p>为了让 pod 从内部可以访问  Kubernetes API，每个 pod 初始化创建时，都会写入一个默认的 secret 资源，它包含用来访问 API 的三个条目，分别是 ca.cert, token, namespace 等；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20210720095728.png"></p>
<h4 id="创建-Secret"><a href="#创建-Secret" class="headerlink" title="创建 Secret"></a>创建 Secret</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154225.png"></p>
<h4 id="对比-ConfigMap-与-Secret"><a href="#对比-ConfigMap-与-Secret" class="headerlink" title="对比 ConfigMap 与 Secret"></a>对比 ConfigMap 与 Secret</h4><p>ConfigMap 中的条目以纯文件存储，但是 Secret 的条目会被以 base64 编码后存储；这样导致读取的时候，需要进行解码；不过正因为使用了 base64 编码，这意味着 secret 可以支持二进制格式的条目内容；</p>
<p>Secret 的大小有上限，最多只能是 1MB；</p>
<p>对于非二进制的数据，如果不想使用默认的 base64 编码，则可以在 secret 的描述文件中使用 stringData 属性来存放；但是在的展示时候看不出来，它仍然会以 base64 编码的形式展示在 data 字段中；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154238.png"></p>
<p>当 secret 卷被挂载到容器中后，条目的值会预先解码，并以原本的形式写入对应的文件，这样容器的应用程序在访问该值时，无须再做进一步的转换；</p>
<h4 id="在-pod-中使用-Secret"><a href="#在-pod-中使用-Secret" class="headerlink" title="在 pod 中使用 Secret"></a>在 pod 中使用 Secret</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154444.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154500.png"></p>
<p>将敏感数据暴露为环境变量的做法其实是有安全隐患的：</p>
<ul>
<li>有些应用程序在启动或报错时，会打印环境变量到日志中；</li>
<li>应用程序在创建子程序时，会复制当前进程的环境变量；子进程可以访问到这些敏感信息；</li>
</ul>
<p>当访问私有镜像仓库时，需要访问凭证进行登录，此时可以将访问凭证存放在 secret 中，然后在相关字段引用该 secret 即可；不过此时对凭证的引用是写在 pod 的定义文件中的，如果凭证被很多 pod 共用，则这显然不是一个好的作法，另外有一个 ServiceAcount 可以用来实现复用；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154516.png"></p>
<h2 id="8-从应用访问-pod-元数据以及其他资源"><a href="#8-从应用访问-pod-元数据以及其他资源" class="headerlink" title="8. 从应用访问 pod 元数据以及其他资源"></a>8. 从应用访问 pod 元数据以及其他资源</h2><h3 id="通过-Downward-API-传递元数据"><a href="#通过-Downward-API-传递元数据" class="headerlink" title="通过 Downward API 传递元数据"></a>通过 Downward API 传递元数据</h3><p>对于可以提前预知的信息，那么可以通过 ConfigMap 写入容器的环境变量，以便容器进行访问；但是对于容器生成之后才知道的信息，例如 pod 名称、IP 等，则这个方法就行不通了；此时可以使用 Downward API，它通过创建 DownwardAPI 卷，将 pod 的元数据作为环境变量或文件注入或挂载到容器中；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154539.png"></p>
<h4 id="了解可用的元数据"><a href="#了解可用的元数据" class="headerlink" title="了解可用的元数据"></a>了解可用的元数据</h4><ul>
<li>pod 的名称</li>
<li>pod 的 IP</li>
<li>pod 所在的命名空间</li>
<li>pod 运行节点的名称</li>
<li>pod 运行所归属的服务账户的名称</li>
<li>每个容器请求的 CPU 和内存的使用量</li>
<li>每个容器可以使用的 CPU 和内存的限制</li>
<li>pod 的标签</li>
<li>pod 的注解</li>
</ul>
<blockquote>
<p>服务账户是指 pod 访问 API 服务器时用来进行身份验证的账户；</p>
</blockquote>
<h4 id="通过环境变量暴露元数据"><a href="#通过环境变量暴露元数据" class="headerlink" title="通过环境变量暴露元数据"></a>通过环境变量暴露元数据</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154802.png"><br><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816154954.png"></p>
<h4 id="通过-downwardAPI-卷来传递元数据"><a href="#通过-downwardAPI-卷来传递元数据" class="headerlink" title="通过 downwardAPI 卷来传递元数据"></a>通过 downwardAPI 卷来传递元数据</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155036.png"><br><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155054.png"></p>
<blockquote>
<p>卷中包含的文件由 items 属性来定义；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155118.png"></p>
<blockquote>
<p>元数据被存储到了文件中，这些文件的访问权限可以由 downwardAPI 卷的 defaultMode 属性来设置；</p>
</blockquote>
<p>相对于环境变量的方式，使用卷的好处是当 pod 创建后，如果某些元数据出现变更，例如标签或注解，则卷中文件的数据会实时更新，而环境变量就做不到这一点了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155140.png"></p>
<p>由于卷是 pod 级别的资源，因此相对环境变量，它还有另外一个好处是可以让同一个 pod 上的多个容器共享彼此的元数据值；</p>
<blockquote>
<p>使用 downwardAPI 来获取元数据的好处是简单方便，缺点是它只能获取部分数据（例如仅限于单个 pod），并不能获取所有数据，如果想要获取更多数据，就需要使用 Kubernetes API 的方式；</p>
</blockquote>
<h3 id="与-Kubernetes-API-服务器交互"><a href="#与-Kubernetes-API-服务器交互" class="headerlink" title="与 Kubernetes API 服务器交互"></a>与 Kubernetes API 服务器交互</h3><h4 id="探究-Kubernetes-REST-API"><a href="#探究-Kubernetes-REST-API" class="headerlink" title="探究 Kubernetes REST API"></a>探究 Kubernetes REST API</h4><p>运行 kubectl 时，本质上是通过 HTTP 来调用 Kubernetes 的 REST API 接口 url；因此，沿用相同的思路，我们也可以从容器内部调用这些 API 来实现与 Kubernetes 服务器的交互；</p>
<p>以下两个命令的效果相同</p>
<ul>
<li>kubectl get job my-job -o json</li>
<li>curl <a target="_blank" rel="noopener" href="http://localhost:8001/apis/batch/v1/namespaces/default/jobs/my-job">http://localhost:8001/apis/batch/v1/namespaces/default/jobs/my-job</a></li>
</ul>
<h4 id="从-pod-内部与-API-服务器进行交互"><a href="#从-pod-内部与-API-服务器进行交互" class="headerlink" title="从 pod 内部与 API 服务器进行交互"></a>从 pod 内部与 API 服务器进行交互</h4><p>从 pod 内部与 API 服务器进行交互需要确认三件事情：</p>
<ul>
<li>找到 Kubernetes 服务器的 IP 地址和端口；</li>
<li>对服务器进行验证，确保是与真正的服务器交互，而不是冒充者；</li>
<li>通过服务器对客户端的验证，确保客户商具备相应的操作权限；</li>
</ul>
<blockquote>
<p>pod 创建过程中自动注入的 secret 含有用来和 Kubernetes 进行通信的证书；并且还含有令牌 token，用来实现已授权的操作；同时还有一个 namespace 文件包含当前 pod 所在的命名空间名称；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155157.png"></p>
<h4 id="通过-ambassador-容器简化与-API-服务器的交互"><a href="#通过-ambassador-容器简化与-API-服务器的交互" class="headerlink" title="通过 ambassador 容器简化与 API 服务器的交互"></a>通过 ambassador 容器简化与 API 服务器的交互</h4><p>ambassador 容器和应用程序的容器运行在同一个 pod 中，它的作用类似于一个中间代理；应用程序通过 HTTP 发送请求给它，再由它使用 HTTPS 和 API 服务器交互；ambassador 容器本质上是在其中运行了 kubectl proxy，就这么简单；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155212.png"></p>
<p> 同一个 pod 中的多个容器使用相同的本地回环地址，因此可以通过 localhost 来访问其他容器中暴露的服务端口；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155246.png"></p>
<h4 id="使用客户端库与-API-服务器交互"><a href="#使用客户端库与-API-服务器交互" class="headerlink" title="使用客户端库与 API 服务器交互"></a>使用客户端库与 API 服务器交互</h4><p>除了使用原始的 HTTPS 请求外，还可以使用第三方库来实现交互，不同的语言都有相应的实现，可以在应用程序代码中引入这些库，来实现与 API 服务器的交互；</p>
<p>另外 Kubernetes 还自带了一个 swagger API 框架可以用来生成客户端库和文档；同时还提供了 swagger UI 界面可用来查看和访问 API；但它默认没有开启，需要在启动时通过选项设置为开启，之后就可以通过浏览器进行访问了；</p>
<h2 id="9-Deployment：声明式地升级应用"><a href="#9-Deployment：声明式地升级应用" class="headerlink" title="9. Deployment：声明式地升级应用"></a>9. Deployment：声明式地升级应用</h2><h3 id="更新运行在-pod-内的应用程序"><a href="#更新运行在-pod-内的应用程序" class="headerlink" title="更新运行在 pod 内的应用程序"></a>更新运行在 pod 内的应用程序</h3><h4 id="删除旧版本-pod，创建新版本-pod"><a href="#删除旧版本-pod，创建新版本-pod" class="headerlink" title="删除旧版本 pod，创建新版本 pod"></a>删除旧版本 pod，创建新版本 pod</h4><p>更新 ReplicationController 中的模板信息（例如镜像版本）后，RC 控制器将会发现当前没有 pod 与模板相匹配，因此它会把旧版本的 pod 删除掉，之后创建新版本的 pod；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155300.png"></p>
<p>这种升级的方式非常简单易懂，但是它的缺点是在删除和新建之间，会出现短暂的服务不可用状态；</p>
<h4 id="先创建新-pod-再删除旧版本-pod"><a href="#先创建新-pod-再删除旧版本-pod" class="headerlink" title="先创建新 pod 再删除旧版本 pod"></a>先创建新 pod 再删除旧版本 pod</h4><p>由于 pod 一般使用 service 对外暴露服务，因此可以先等所有的新版本 pod 都创建好了后，再修改 service 的标签选择器，让其绑定到新的 pod 上面即可；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155325.png"></p>
<h3 id="使用-ReplicationController-实现自动的滚动升级"><a href="#使用-ReplicationController-实现自动的滚动升级" class="headerlink" title="使用 ReplicationController 实现自动的滚动升级"></a>使用 ReplicationController 实现自动的滚动升级</h3><p>kubectl rolling-update 命令可以用来执行滚动升级的操作；它会创建一个新的 replicationController ，然后由它来创建新版本的 pod；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155340.png"></p>
<p>kubectl 执行滚动升级的过程中，除了创建新 RC 外，它还会给旧的 RC 和旧的 pod 添加标签（不会改动旧标签，以免影响原来的服务稳定性），通过新增的标签来区分新旧 pod，然后通过逐渐递减旧 RC 的副本数和递增新 RC 的副本数，来实现滚动升级的过程；</p>
<p>kubectl rolling-update 并不是一种理想的滚动升级方式，原因如下：</p>
<ul>
<li>它在更新过程中会去修改旧的资源；</li>
<li>它通过 kubectl 客户端发起更新的请求，在这一过程中有可能出现网络异常和中断，将导致整个更新过程失败；</li>
</ul>
<h3 id="使用-Deployment-声明式的升级应用"><a href="#使用-Deployment-声明式的升级应用" class="headerlink" title="使用 Deployment 声明式的升级应用"></a>使用 Deployment 声明式的升级应用</h3><p>滚动升级过程不可避免涉及到了两个 replicaSet，一个用来管理旧 pod，一个负责新 pod；因此，通过在 relicaSet 之上引入新的 Deployment 资源，就可以实现两个 replicaSet 的协调工作，让开发人员将预期结果写在 deployment 的描述文件中，之后实现的复杂性被隐藏；</p>
<h4 id="创建-deployment"><a href="#创建-deployment" class="headerlink" title="创建 deployment"></a>创建 deployment</h4><p>deployment 并不直接创建 pod，它仍然通过 replicaSet 来管理和创建 pod；一个 deployment 可以对应多个 replicaSet，它通过给这些 replicaSet 加上模板的哈希值进行区分，同时也可以确保相同的模板会创建出相同的 pod；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155359.png"></p>
<h4 id="升级-deployment"><a href="#升级-deployment" class="headerlink" title="升级 deployment"></a>升级 deployment</h4><p>deployment 的升级是非常简单的，它非常类似于 pod 的扩容或缩容，只需要更改模板中的镜像 tag，Kubernetes 就会自动进行收敛，达成预期的状态；</p>
<p>deployment 的升级支持多种策略，默认使用 rollingUpdate 滚动升级，此外还支持 recreate 的一次性升级（即删除所有旧的，再创建所有新的，服务会短暂中断）；</p>
<p>deployment 比 kubectl rolling-update 更好的原因在于升级过程是由上kubernetes 的控制器来完成，而不是客户端，这样就可以避免可能出现的网络中断问题；</p>
<p>deployment 升级成功后，并不会删除旧的 replicaSet，因为它可以用来实现快速回滚；</p>
<h4 id="回滚-deployment"><a href="#回滚-deployment" class="headerlink" title="回滚 deployment"></a>回滚 deployment</h4><p>在升级的过程中，如果发现错误，此时可以使用 kubectl rollout undo 命令来实现回滚；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155415.png"></p>
<p>由于 deployment 保留着每一次升级时旧版本的 replicaSet，因此它也可以实现回滚到指定版本的 replicaSet</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155428.png"></p>
<h4 id="控制滚动升级速率"><a href="#控制滚动升级速率" class="headerlink" title="控制滚动升级速率"></a>控制滚动升级速率</h4><p>在更新策略中，有两个属性会影响升级速度</p>
<ul>
<li>maxSurge：表示允许超出预期副本数的 pod 数量或比例；</li>
<li>maxUnavailable：表示允许少于预期副本数的 pod 数量或比例；</li>
</ul>
<h4 id="暂停和恢复滚动升级"><a href="#暂停和恢复滚动升级" class="headerlink" title="暂停和恢复滚动升级"></a>暂停和恢复滚动升级</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155441.png"></p>
<h4 id="阻止出错版本的滚动升级"><a href="#阻止出错版本的滚动升级" class="headerlink" title="阻止出错版本的滚动升级"></a>阻止出错版本的滚动升级</h4><p>deployment 有一个 minReadySeconds 属性，它表示 pod 需要就绪一定的时间后，才能继续余下的升级工作，这样的好处是在发现 pod 有错误时，能否阻止错误进一步蔓延扩大到所有的 pod；一般来说它需要配合就绪探针使用；</p>
<blockquote>
<p>kubectl apply 可以用来更新当前已经创建的资源；如果资源不存在，则它会创建；</p>
</blockquote>
<p>deployment 有一个 progressDeadlineSeconds 属性，可以用来设置升级的最长时间，如果超过了这个时间，则意味着升级失败，升级操作将会被自动取消；</p>
<h2 id="10-StatefulSet：部署有状态的多副本应用"><a href="#10-StatefulSet：部署有状态的多副本应用" class="headerlink" title="10. StatefulSet：部署有状态的多副本应用"></a>10. StatefulSet：部署有状态的多副本应用</h2><h3 id="创建有状态-pod"><a href="#创建有状态-pod" class="headerlink" title="创建有状态 pod"></a>创建有状态 pod</h3><p>使用 replicaSet 创建的多个 pod，它们可以很容易的实现同一个持久卷的共享，但是如果想让每个 pod 拥有自己的持久卷，则无法实现；</p>
<p>有一种解决办法是让每个 replicaSet 只创建一个 pod，多个 pod 将产生个多个的 replicaSet，这样就可以实现每个 pod 有自己的独立存储；</p>
<p>另外，为了实现让每个 pod 都可以访问其他 pod，还需要为每个 pod 创建单独的 service，避免因为 pod 被删除后，重新创建的 pod 使用新的 IP 和名称，导致无法访问；</p>
<h3 id="了解-StatefulSet"><a href="#了解-StatefulSet" class="headerlink" title="了解 StatefulSet"></a>了解 StatefulSet</h3><h4 id="对比-StatefulSet-和-ReplicaSet"><a href="#对比-StatefulSet-和-ReplicaSet" class="headerlink" title="对比 StatefulSet 和 ReplicaSet"></a>对比 StatefulSet 和 ReplicaSet</h4><p>由ReplicaSet 创建的 pod，其名称是随机的，每次新建的 pod 的标识都跟之前的不同；它适用于完全无状态的应用，每个应用之间都可以相互替换而不会有影响；</p>
<p>由 StatefulSet 创建的 pod 将拥有唯一的标识和状态，名称是有规律和固定的（按顺序索引编号）；如果某个 pod 挂掉了，StatefulSet 将再创建一个有相同标识的 pod；</p>
<h4 id="提供稳定的网络标识"><a href="#提供稳定的网络标识" class="headerlink" title="提供稳定的网络标识"></a>提供稳定的网络标识</h4><p>每个 pod 的名称由 StatefulSet 的名称加上索引号来组成；如果某个 pod 挂了，新建的 pod 将仍然使用和之前一样的名称；</p>
<p>当 pod 有了固定的名称后，意味着可以创建基于该名称的服务，然后其他 pod 可以通过它来实现稳定的访问；这么做还可以顺带有一个效果，即通过检查服务的列表后，就可以发现有多少个 StatefulSet 的 pod；</p>
<p>StatefulSet 在缩容的时候，假设需要删除多个 pod，它每次只会操作一个，以便确保被删除的 pod 的数据有机会复制保存起来；因此，如果有某个 pod 处于不健康的状态，则此时不允许进行缩容操作，因为它可能会导致数据出现丢失；</p>
<h4 id="为每个有状态实例提供稳定的专属存储"><a href="#为每个有状态实例提供稳定的专属存储" class="headerlink" title="为每个有状态实例提供稳定的专属存储"></a>为每个有状态实例提供稳定的专属存储</h4><p>就像 StatefulSet 的 pod 与服务一一对应一样，如果需要为pod 提供持久存储，则在模板中同时写出持久卷声明，之后在创建 pod 之前，就会先创建出与 pod 一一对应的持久卷声明；而每个持久卷声明又将会与某个持久卷一一对应；</p>
<p>当 pod 被缩容删除后，它原先绑定的持久卷声明并不会被自动删除，而是会持续保留着，因为里面可能存储着有状态的数据；直到被手工删除为止；</p>
<h4 id="StatefulSet-的保障"><a href="#StatefulSet-的保障" class="headerlink" title="StatefulSet 的保障"></a>StatefulSet 的保障</h4><p>由于 StatefulSet 中的每个 pod 都有唯一标识和存储，因此这意味着 K8s 不应该创建出两个相同的 pod，或者会发生冲突；</p>
<h3 id="使用-StatefulSet"><a href="#使用-StatefulSet" class="headerlink" title="使用 StatefulSet"></a>使用 StatefulSet</h3><h4 id="创建应用和容器镜像"><a href="#创建应用和容器镜像" class="headerlink" title="创建应用和容器镜像"></a>创建应用和容器镜像</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155502.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155518.png"></p>
<h4 id="通过StatefulSet-部署应用"><a href="#通过StatefulSet-部署应用" class="headerlink" title="通过StatefulSet 部署应用"></a>通过StatefulSet 部署应用</h4><p>一般需要创建三个对象，包括：持久卷（用于存储数据）、Service（用来外部访问）、StatefulSet本身；以下以谷歌的 Kubernetes 集群做为示例。</p>
<h5 id="第1步：先创建磁盘"><a href="#第1步：先创建磁盘" class="headerlink" title="第1步：先创建磁盘"></a>第1步：先创建磁盘</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155541.png"></p>
<h5 id="第2步：创建三个持久卷"><a href="#第2步：创建三个持久卷" class="headerlink" title="第2步：创建三个持久卷"></a>第2步：创建三个持久卷</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155553.png"></p>
<h5 id="第3步：创建-Headless-Service"><a href="#第3步：创建-Headless-Service" class="headerlink" title="第3步：创建 Headless Service"></a>第3步：创建 Headless Service</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155605.png"></p>
<blockquote>
<p>好奇：为什么使用 headless service 可以让 pod 之间彼此发现，而普通的 service 就做不到这点了吗？<br>答：因为普通的 service 会对接请求，然后将请求随机转发至某个 pod，这样会导致 pod 之间不能实现与特定 pod 的通讯，因为普通 service 的转发是随机的；而 headless service 不再直接对接请求，而是让请求直接对接 pod，因此，它可以实现 pod 之间的直接访问；不过，为此付出的代价是，headless service 虽然也叫 service，但实际上并不能仅通过 service 来访问 pod，而是需要 <pod_name>.<serivice_name> 这样来访问；</p>
</blockquote>
<h5 id="第4步：创建-StatefulSet"><a href="#第4步：创建-StatefulSet" class="headerlink" title="第4步：创建 StatefulSet"></a>第4步：创建 StatefulSet</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155633.png"><br><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155705.png"></p>
<blockquote>
<p>由于 statefulset 的 pod 是有状态的，因此在启动 statefulset 时，它们并不是同时启动的，而是按顺序启动，以免引起竞态条件；</p>
</blockquote>
<h4 id="使用你的-pod"><a href="#使用你的-pod" class="headerlink" title="使用你的 pod"></a>使用你的 pod</h4><p>删除 statefulset 中的某个 pod 后，它会被重新创建，但不一定是调度到原来的节点上，有可能会被安排到新的节点上，不过问题不大，因为这个新建的 pod 会使用旧的名称，并且关联原有的旧的持久卷（如有）；</p>
<p>虽然 statefulset 在创建过程中，需要有一个 headless service；但是在 pod 都创建完毕后，也可以额外定义一个 service 来指向这些 pod；</p>
<h3 id="在-StatefulSet-中发现伙伴节点"><a href="#在-StatefulSet-中发现伙伴节点" class="headerlink" title="在 StatefulSet 中发现伙伴节点"></a>在 StatefulSet 中发现伙伴节点</h3><p>headless service 之所以可以让 pod 之间彼此发现和通信，其原理在于它使用了 DNS 域名系统中的 SRV 记录，它会将请求转发到提供特定服务的那台服务器上面；</p>
<blockquote>
<p>问：什么是 SRV？<br>答：DNS 系统中保存着很多域名解析的记录，当收到一个解析请求时，DNS 根据这些记录为请求找到相应的目标 IP 地址；DNS 保存的记录有很多种类型，它们分别适用于不同的解析场景，例如 A记录（指向一个 IPv4地址）、MX记录（指向电子邮件服务器的地址）、CNAME记录（用于将当前域名映射到另外一个域名），以及 SRV记录（指向提供特定服务的服务器的地址）等等；（怎么感觉它跟子域名很像？）</p>
</blockquote>
<h4 id="通过-DNS-实现伙伴间彼此发现"><a href="#通过-DNS-实现伙伴间彼此发现" class="headerlink" title="通过 DNS 实现伙伴间彼此发现"></a>通过 DNS 实现伙伴间彼此发现</h4><p>不同语言的代码都有关于如何做 SRV DNS 查询的实现，只要调用相应的方法，以服务域名作为参数，即可以查询该域名项下的所有的 SRV 记录，从而获得了各个 pod 的访问地址，实现 pod 之间的彼此发现；</p>
<h4 id="更新-Statefulset"><a href="#更新-Statefulset" class="headerlink" title="更新 Statefulset"></a>更新 Statefulset</h4><p>通过命令 kubectl edit statefulset <sts_name> 可以调用默认的编辑器打开某个资源相应的声明文件，在对其更改并进行保存后，就可以实现对资源的更新；</p>
<blockquote>
<p>此处 statefulset 有一个行为和 deployment 不太一样，即当对镜像的版本进行更新后，并不会影响原来已经在运行的容器，只会影响后续新建的容器；如果想让镜像马上得到使用的话，需要搬运删除原来的副本，然后 statefulset 就会根据新的模板创建新的容器；这一点跟 ReplicaSet 一致；</p>
</blockquote>
<h4 id="尝试集群数据存储"><a href="#尝试集群数据存储" class="headerlink" title="尝试集群数据存储"></a>尝试集群数据存储</h4><p>对于 Statefulset 里面的 pod 来说，每个 pod 有自己的独立存储，因此数据事实上是分散在不同的 pod 之间的；通过在应用中调取 SRV 记录，实现对其它的 pod 的访问，可以收集散落在各个 pod 中的数据，统一返回给客户端，这样可以解决数据分散存储的问题，实现访问上的统一；</p>
<blockquote>
<p>这种方式的缺点是代码写起来很麻烦，或许可以通过封装一个公用的函数来实现；</p>
</blockquote>
<h3 id="了解-StatuefulSet-如何处理节点失效"><a href="#了解-StatuefulSet-如何处理节点失效" class="headerlink" title="了解 StatuefulSet 如何处理节点失效"></a>了解 StatuefulSet 如何处理节点失效</h3><p>由于 statefulset 中的 pod 是唯一的，这意味着如果调度器在不能明确某个 pod 是否已经失效时，不能随意去创建新的 pod，不然将有可能跟原来的 pod 产生冲突；</p>
<h4 id="模拟一个节点的网络断开"><a href="#模拟一个节点的网络断开" class="headerlink" title="模拟一个节点的网络断开"></a>模拟一个节点的网络断开</h4><p>断开的命令： sudo ifconfig eth0 down，这个命令运行后，将导致原本进行中的 SSH 连接断开；</p>
<p>当断开网络连接时，pod 实际上是有在运行的，只是不再与调度器通信；调度器在失去该 pod 的通信后，一开始会将它标记为 unknown 状态，并在超过一定的时间后（可配置），会将 pod 从集群中删除掉；</p>
<h4 id="手动删除-pod"><a href="#手动删除-pod" class="headerlink" title="手动删除 pod"></a>手动删除 pod</h4><p>通过情况下，当通过命令调用 API 服务器来执行某个动作时（例如删除 pod ），API 服务器只是先发了一个删除指令给 kubelet，实际上是由 kubelet 来执行删除动作；在 kubelet 删除成功后，它会发通知给 API 服务器； API 服务器在收到通知后，更新自己的状态记录；</p>
<p>如果不想等待 kubelet 的通知，则可以在删除指令中加上 –force 和 –grace-period 两个参数，直接强制更新状态（一般情况下，最好不要使用这种方法，因为它有可能导致冲突）；</p>
<h2 id="11-了解-Kubernetes-机理"><a href="#11-了解-Kubernetes-机理" class="headerlink" title="11. 了解 Kubernetes 机理"></a>11. 了解 Kubernetes 机理</h2><h3 id="了解架构"><a href="#了解架构" class="headerlink" title="了解架构"></a>了解架构</h3><h4 id="Kubernetes-组件的分布式特性"><a href="#Kubernetes-组件的分布式特性" class="headerlink" title="Kubernetes 组件的分布式特性"></a>Kubernetes 组件的分布式特性</h4><p>总共有三种类型的组件，分别是主节点组件、工作节点组件，以及一些提供额外功能的附加组件；所有的组件之间都是通过 API 服务器进行通信；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200813082246.png"></p>
<p>工作节点上的组件是一个整体，它们需要被安排在同一个节点上才能协同工作，但是主节点上的组件则没有这个要求，它们可以是分布式部署在不同的节点上的，甚至还可以有多个实例（以此来保证高可用性）；不过多出的实例只是作为备用，在某个的时间点，有且只有一个组件在真正的工作；</p>
<p>除了 Kubelet 组件外，其他组件都是做为 pod 来运行的，只有 Kubelet 需要做为常规的系统应用直接部署在节点上，因为总是需要有一个人来完成自举的动作，将其他组件作为 pod 部署在节点上；</p>
<blockquote>
<p> Flannel pod 据说是用来为 pod 提供重叠网络，啥是重叠网络？</p>
</blockquote>
<h4 id="Kubernetes-如何使用-etcd"><a href="#Kubernetes-如何使用-etcd" class="headerlink" title="Kubernetes 如何使用 etcd"></a>Kubernetes 如何使用 etcd</h4><blockquote>
<p>问：什么是 etcd？</p>
<p>答：原来它是一个数据库应用，类似 redis，提供 key-value 形式的存储，支持分布式部署，以提供高可用性和更好的性能；它使用乐观并发控制（也叫乐观锁）功能，即为数据提供版本号，在客户端尝试对数据进行修改时，需要提供之前客户端读取的版本号，如果与当前数据库中保存的版本号一致，则允许修改；如果版本号不一致，则拒绝修改请求，并要求客户端重新读取一下最新的数据后，再根据情况重新提交修改请求；etcd 的键名支持斜杠，因此导致键名看起来很像目录名，感觉像是有层级存在一样；键的值是以 JSON 形式存储的；</p>
</blockquote>
<p>让所有组件通过 API 服务器来对接 etcd 有两个好处：</p>
<ul>
<li>只有 API 服务器本身实现了并发控制机制（乐观锁）即可，无须担心直接对接的场景下，有些组件没有遵循乐观锁机制；</li>
<li>API 服务器可以增加一层权限控制，确保授权的客户端才能够对数据发起修改；</li>
</ul>
<p>当存在多个 etcd 实例时，etcd 集群使用 RAFT 算法来保证节点之间数据的一致性；该算法要求集群过半数的节点参与，才能进入下一个状态；这样可以避免某几个实例失联后带来的影响；因此 etcd 的实例数据必须为单数，这样才有可能过半数，避免出现平局的情况；</p>
<h4 id="API-服务器做了什么"><a href="#API-服务器做了什么" class="headerlink" title="API 服务器做了什么"></a>API 服务器做了什么</h4><p>API 服务器以 REST API 的形式，提供了对集群状态进行增删改查 CRUD 的接口；</p>
<p>当客户端（例如 kubectl）向 API 服务器发起请求后，API 服务器在收到请求后，会先根据事先配置好的插件，对请求进行预处理，包括：验证身份（认证类插件）、授权核实（授权类插件）、准入控制（准入类插件）；</p>
<p>请求只有通过了以上所有这些插件的处理后，API 服务器才会验证存储到 etcd 的对象，然后返回响应给客户端；</p>
<h4 id="API-服务器如何通知客户端资源变更"><a href="#API-服务器如何通知客户端资源变更" class="headerlink" title="API 服务器如何通知客户端资源变更"></a>API 服务器如何通知客户端资源变更</h4><p>API 服务器除了做前面提到的那些工作外，其他就没有做其他的；唯一的事项是当资源发生变更时，给之前监听的客户端发送通知；关于资源的创建和维护工作，实际上是由其他组件完成的（例如调度器和 kubelet）；</p>
<h4 id="了解调度器"><a href="#了解调度器" class="headerlink" title="了解调度器"></a>了解调度器</h4><p>表面上看调度器做的工作很简单，当它监听到 API 服务器关于新建资源的通知后，它就为该资源指定一个节点，然后通知 API 服务器修改资源的定义，加上节点信息；之后 API 服务器会将该信息做为新通知发出来，此时处于监听状态的 kubelet 就会受到通知，然后在其节点上新建相应的资源；建好之后，再发通知给 API 服务器更新资源的状态；</p>
<p>虽然调度器的工作看上去很简单，但其实最难的部分在于如何最高效的调度资源，以便充分利用硬件资源，提高效率；此便会涉及到设计一套高效的调度算法；</p>
<p>调度算法分为两个步骤，第一步是先找出所有可用的节点；第二步是对可用节点进行排序，选择优先级分数最高的节点；</p>
<p>查找节点的工作涉及一系列应满足条件的判断；选择最佳节点则因情况而异，即不同情况下，有不同的优先级标准，例如是高可用性优先，还是成本优先等；</p>
<p>集群中允许有多个调度器，其中有一个会被当作默认调度器；当 pod 没有指定由哪个调度器进行调度时，则由默认的调度器进行调度；不同的调度器可以有不同的调度算法，以实现不同的优先级目标；</p>
<h4 id="了解控制器"><a href="#了解控制器" class="headerlink" title="了解控制器"></a>了解控制器</h4><p>不管是 API 服务器，或者是调度器，它们都只负责定义状态，而控制器的工作就在于让集群的状态向定义的状态收敛；控制器有很多个，每种资源都有一种相应的控制器；</p>
<p>当监听到 API 服务器关于资源状态的通知后，控制器就会去做实际的资源管理动作（例如新建、修改和删除等，注意：此处仅仅是操作资源，而不是容器），调整资源的最终状态与定义的状态相符，然后将新的资源状态反馈给 API 服务器；之后 API 服务器发布通知，最后由 Kubelet 完成容器级别的操作；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815131016.png"></p>
<h4 id="Kubelet-做了什么"><a href="#Kubelet-做了什么" class="headerlink" title="Kubelet 做了什么"></a>Kubelet 做了什么</h4><p>动作一：通知 API 服务器创建一个 Node 资源，以注册其所在的节点；</p>
<p>动作二：持续监听 API 服务器的通知，如果有新消息，就通知容器运行时（例如 Docker），对节点上的容器进行操作；</p>
<p>动作三：当容器启动后，持续监控容器的运行状态、资源消耗、触发事件等；</p>
<blockquote>
<p>有意思的是，Kubelet 不但可以从 API 服务器接收消息来创建和管理 pod，也可以从本地的文件目录中导入 pod 定义，来创建和管理 pod，即它是可以脱离 API 服务器独立运行的；</p>
</blockquote>
<h4 id="Kubernetes-Service-Proxy-的作用"><a href="#Kubernetes-Service-Proxy-的作用" class="headerlink" title="Kubernetes Service Proxy 的作用"></a>Kubernetes Service Proxy 的作用</h4><p>工作节点上除了运行 Kubelet 外，还会运行一个 kube-proxy，它用来确保客户端可以通过 Kubernetes API 连接到节点上的服务；</p>
<blockquote>
<p>kube-proxy 的名称中之所以带有 proxy 字样，是因为在早期的设计中，它确实扮演着 proxy 的功能，请求会被 iptables 转到它这里，并由它再转发给后端的 pod；但后来这个设计做了改进；kube-proxy 只负责更新 iptables 里面的规则就好，实际请求可以由 iptables 直接转发给 pod，不再经过 kube-proxy，这样可以很好的提高性能；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815130954.png"></p>
<h4 id="介绍-Kubernetes-插件"><a href="#介绍-Kubernetes-插件" class="headerlink" title="介绍 Kubernetes 插件"></a>介绍 Kubernetes 插件</h4><p>除了核心组件外，还有一些插件用来提供额外的功能，例如 DNS 服务器、仪表板、Ingress 控制器等；</p>
<p>DNS 插件可以为集群内的所有 pod 提供 DNS 服务，这样 pod 之间就可以使用服务名进行彼此的访问，而无须事先知道对方的 IP 地址是多少，甚至是无头服务的 pod 也可以；</p>
<p>Ingress 控制器实现的功能和 DNS 插件差不多，只是实现方式不同，它通过运行一个 nginx 服务器来实现创建和维护规则；相同的部分在于二者都是通过订阅监控 API 服务器的通知来实现更新；</p>
<h3 id="控制器如何协作"><a href="#控制器如何协作" class="headerlink" title="控制器如何协作"></a>控制器如何协作</h3><h4 id="了解涉及哪些组件"><a href="#了解涉及哪些组件" class="headerlink" title="了解涉及哪些组件"></a>了解涉及哪些组件</h4><p>当创建一个 deployment 资源时，将会涉及以下这些组件的相互协作</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815130935.png"></p>
<h4 id="事件链"><a href="#事件链" class="headerlink" title="事件链"></a>事件链</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815130909.png"></p>
<h4 id="观察集群事件"><a href="#观察集群事件" class="headerlink" title="观察集群事件"></a>观察集群事件</h4><p>通过 kubectl get events –watch 命令可以动态的观察集群中发生的事件；</p>
<blockquote>
<p>有意思的是，当主节点的组件或者工作节点的 kubelet 执行动作后，需要发送事件给 API 服务器时，它们是通过创建事件资源来实现的，而不是直接调用 API 服务器的接口发送相应的请求（有点意思，为什么要这么做呢？虽然增加了一层抽象后提高了健壮性，不过貌似动作成本也不小）；</p>
</blockquote>
<h3 id="了解运行中的-pod-是什么"><a href="#了解运行中的-pod-是什么" class="headerlink" title="了解运行中的  pod  是什么"></a>了解运行中的  pod  是什么</h3><p>当 kubelet 创建一个 pod 时，它并不仅仅只运行资源定义文件中声明的容器，它还会在 pod 上面运行一个基础容器，它用来保存命名空间，实现一个 pod 上的所有容器共享同一个网络和 Linux 命名空间；这个基础容器的生命周期和 pod 绑定在一起，当 pod 增加运行其他容器时，会从这个基础容器中获得需要的命名空间数据；</p>
<h3 id="跨-pod-网络"><a href="#跨-pod-网络" class="headerlink" title="跨  pod  网络"></a>跨  pod  网络</h3><h4 id="网络应该是什么样的"><a href="#网络应该是什么样的" class="headerlink" title="网络应该是什么样的"></a>网络应该是什么样的</h4><p>对于同一个 pod 内部的容器，它们之间实现相互访问是非常简单的，因为它们共享一个网络，因此使用本地网络 localhost 就可以实现相互访问了；但如果想要实现跨 pod 的容器之间的相互访问，就需要一套每个 pod 共用的网络机制，这样才能够让每个 pod 的 IP 地址在这个网络中保持唯一性，让其他 pod 可以使用 IP 地址就可以实现连接，而无需使用 NAT 进行网络地址的转换；</p>
<p>Kubernetes 本身只要求通信需要使用非 NAT 网络，但并没有规定这样的一个网络在技术上如何实现，而是交由插件来处理，这意味着可以根据需要，使用不同的网络插件来达到相同的目的；</p>
<h4 id="深入了解网络工作原理"><a href="#深入了解网络工作原理" class="headerlink" title="深入了解网络工作原理"></a>深入了解网络工作原理</h4><h5 id="同节点-上的-pod-通信"><a href="#同节点-上的-pod-通信" class="headerlink" title="同节点 上的 pod 通信"></a>同节点 上的 pod 通信</h5><p>假设 pod 是一台虚拟机的话，那么运行 pod 所在的节点有点像是一台物理机；虚拟机内部的容器之间由于共享一个网络，相互通信是很容易的；而对于节点所在这台物理机上面的不同 pod，它们本质上只是基于 Linux 命名空间的虚拟化技术下的一个分组，而节点 host 本身也是一个分组（即另一个命名空间）；分组和分组之间，共享节点上的同一个网络，但是它们的物理网卡接口却只有一个；为了解决这个问题，引入了一个叫做 veth（virtual ethernet）的虚拟网卡，并创建一个 veth 对，其中一个放在虚拟机的命名空间中，一个在物理机的命名空间中，二者之间形成一个管道，可以相互传输数据；同时将物理机的 veth 连接到物理机的网络上，这样就间接可以实现不同分组之间的相互通信了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815130716.png"></p>
<h5 id="不同节点上的-pod-通信"><a href="#不同节点上的-pod-通信" class="headerlink" title="不同节点上的 pod 通信"></a>不同节点上的 pod 通信</h5><p>对于不同节点之间的通信，由于涉及不同的网卡，开始需要引入交换机或者路由器，此时可以有多种实现方式，例如：</p>
<ul>
<li>underlay：即传统的网络基础结构，每个节点有一个自己的独立物理 IP 地址，因此所有其他节点都可以访问；</li>
<li>overlay：在 underlay 的基础上，增加一层逻辑网络（虚拟的），这样就可以脱离 IP 地址的限制，拥有自己独立的 IP 地址空间；</li>
<li>三层路由：节点之间共用一台交换机或者路由器进行连接，由路由器实现转发；此方案比较适合中小型局域网中；如果需要应对复杂的场景，则使用 SDN （软件定义网络）的 overlay 更合适；</li>
</ul>
<h4 id="引入容器网络接口"><a href="#引入容器网络接口" class="headerlink" title="引入容器网络接口"></a>引入容器网络接口</h4><p>为了实现容器连接到网络，以便和其他容器互相通信，有一系列的工作需要做，因此 Kubernetes 采用 Container Network Interface 接口来标准化这项工作；CNI 有很多插件实现，包括：Calino、Flannel、Romana 和 WaveNet 等；</p>
<h3 id="服务是如何实现的"><a href="#服务是如何实现的" class="headerlink" title="服务是如何实现的"></a>服务是如何实现的</h3><h4 id="引入-kube-proxy"><a href="#引入-kube-proxy" class="headerlink" title="引入 kube-proxy"></a>引入 kube-proxy</h4><p>每个节点上都会运行一个 kube-proxy，和 Service 相关的所有事情，实际上都是由 kube-proxy 进行处理的；虽然 service 对外提供了一个稳定的 IP 地址和端口号，但其实它们都是虚拟的，并不能真正的 ping 通；</p>
<p>kube-proxy 在早期版本的时候，确实有发挥代理的作用，对请求进行转发；但现在新的版本中，请求的转发工作是由 iptables 来处理的，kube-proxy 只需负责维护 iptables 的工作了；</p>
<h4 id="kube-proxy-如何使用-iptables"><a href="#kube-proxy-如何使用-iptables" class="headerlink" title="kube-proxy 如何使用 iptables"></a>kube-proxy 如何使用 iptables</h4><p>当创建了一个 service 资源时，API 服务器会给所有的节点发通知，kube-proxy 在收到通知后，就会更新自己负责的 iptables 规则，在上面建立一个映射，将服务的 IP 地址和端口映射到能够真正提供服务的 pod 的 IP 地址和端口；之后如果 iptables 发挥有数据包的目标地址是 service 的地址，它就会按映射表将其替换为实际的 pod 地址，将数据包重定向到 提供服务的 pod；</p>
<p>除了要监控 API 服务器关于 service 变更的通知外，kube-proxy 还需要监控 API 服务器关于 Endpoint 变更的通知；因为 Endpoint 对象中保存着关于提供某个 service 服务的 pod 信息（IP 地址和端口号）；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815171116.png"></p>
<h3 id="运行高可用集群"><a href="#运行高可用集群" class="headerlink" title="运行高可用集群"></a>运行高可用集群</h3><p>使用 Kubernetes 来部署应用的最核心目的，就是减少运维的工作，让应用能够以最简单的方式可靠的运行，因此 Kubernetes 还需要提供一系列的组件来监控各类资源的状态，确保它们在发生故障后，能够被及时处理；</p>
<h4 id="让应用变得高可用"><a href="#让应用变得高可用" class="headerlink" title="让应用变得高可用"></a>让应用变得高可用</h4><h5 id="方案一：运行多个实例来减少宕机的可能性"><a href="#方案一：运行多个实例来减少宕机的可能性" class="headerlink" title="方案一：运行多个实例来减少宕机的可能性"></a>方案一：运行多个实例来减少宕机的可能性</h5><p>该方案需要应用本身支持水平扩展；如果不支持，仍然可以使用 Deployment，只需将副本数设置为 1；这样当实例发生故障时，Deployment 会创建一个新的 pod 实例来替换它；当然，由于创建 pod 的过程需要一点时间，因此不可避免会出现一小段的宕机时间；</p>
<p>方案二：对无法实现水平扩展的应用使用领导选举机制</p>
<p>提前创建多个实例，但在某个时刻就有一个在工作，其中实例处于备用状态；当工作中的实例发生故障时，就在备用的实例中选举一个实例成为工作实例；</p>
<p>实例的选举工作可以在不改变原应用代码的情况下实现，即通过创建一个 sidecar 容器来完成领导选举的工作，<a target="_blank" rel="noopener" href="https://github.com/kubernetes/contrib/tree/master/election">点击这里</a>查看更多实现代码</p>
<h4 id="让-Kubernetes-主节点变得高可用"><a href="#让-Kubernetes-主节点变得高可用" class="headerlink" title="让 Kubernetes 主节点变得高可用"></a>让 Kubernetes 主节点变得高可用</h4><p>实现办法：增加多个主节点的实例</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815174220.png"></p>
<ul>
<li>etcd 本身就已经是多实例的分布式设计，多个实例之间会自动同步；</li>
<li>API 服务器是无状态的，本身不存储任何数据，因此多少个都没有问题；</li>
<li>管理器和调度器需要实施领导推选机制，某个时候有且只一个处于工作的状态，其他实例作为备用；（它的推举机制特别简单，类似乐观锁的机制，当某个实例能够将自己的名字写入指定对象的属性中时，谁就成为领导，剩下的成为备用；领导者默认每2秒钟需要做一次更新资源的动作；其他实例则监控领导者是否定时更新，如果它们发现领导者超过时间没有更新，大家就重新开始竞争将自己的名字写入指定对象的属性；</li>
</ul>
<h2 id="12-Kubernetes-API-服务器的安全防护"><a href="#12-Kubernetes-API-服务器的安全防护" class="headerlink" title="12. Kubernetes API 服务器的安全防护"></a>12. Kubernetes API 服务器的安全防护</h2><h3 id="了解认证机制"><a href="#了解认证机制" class="headerlink" title="了解认证机制"></a>了解认证机制</h3><p>当请求到达 API 服务器后，API 服务器需要验证该请求是否合法，因此将首先由认证类的插件提取请求中的用户身份，当获得用户的身份信息后，API 服务器就会停止调用剩下的其他插件，直接进入授权插件处理的阶段；常用的认证插件包括：</p>
<ul>
<li>客户端证书</li>
<li>HTTP 头部中的认证 token</li>
<li>基础的 HTTP 认证</li>
</ul>
<h4 id="用户和组"><a href="#用户和组" class="headerlink" title="用户和组"></a>用户和组</h4><p>API 服务器允许被两种类型的用户访问：</p>
<ul>
<li>一种是机器用户，例如 pod 或者运行在 pod 中的应用；</li>
<li>一种是真人用户，例如开发人员或者运维人员通过 kubectl 客户端发起的请求；</li>
</ul>
<p>每个用户都属于一个或者多个组，而每个组背后将关联不同的权限；认证插件在认证用户身份后，会返回该用户所属的组名；</p>
<h4 id="ServiceAccount-介绍"><a href="#ServiceAccount-介绍" class="headerlink" title="ServiceAccount 介绍"></a>ServiceAccount 介绍</h4><p>pod 与 API 服务器进行通信时，使用 ServiceAccount 机制来证明自己的身份，它会在请求中附带发送 token；token 的内容是在创建容器时，提前挂载到容器中的某个文件里面；</p>
<p>ServiceAccount 本身也是一个资源，跟 pod、secret、configMap 等资源的性质是一样的，因此它们只会作用于某个单独的命名空间，而不是全局有效的；</p>
<p>在一个命名空间中，可以有多个 ServiceAccount 资源；一个 ServiceAccount 资源可以被多个 pod 关联；但一个 pod 不能关联多个 ServiceAccount；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815185824.png"></p>
<p>在 pod 的声明文件中，如果不显式的指定 pod 所关联的 ServiceAccount，则 pod 将被关联到其所在的命名空间中的默认的 ServiceAccount；当然，也可以显式的指定要关联的其他 ServiceAccount 名称；</p>
<p>当 pod 关联 ServiceAccount 后，它所能访问的资源，将由 ServiceAccount 来决定了；</p>
<h4 id="创建-ServiceAccount"><a href="#创建-ServiceAccount" class="headerlink" title="创建 ServiceAccount"></a>创建 ServiceAccount</h4><p>默认的 ServiceAccount 的权限还是很大的，如果让所有的 pod 都使用默认的 ServiceAccount，显然这种做法并不够安全；每个 pod 所能操作的资源应当在不影响其正常工作的范围内，尽可能的小；</p>
<p>通过 kubectl create serviceaccount 命令就可以快速创建一个 ServiceAccount，但是在创建 ServiceAccount 之前，需要创建一个 token（用 Secret 资源来实现），因为创建 ServiceAccount 时，需要引用一个已经提前创建好的 token；</p>
<p>理论上 pod 允许挂载任何的 secret 到其容器中，但是这样有风险，会导致某些 secret 被暴露了；此时可以通过在 ServiceAccount 指定 pod 允许挂载的 secret 列表，来限制 pod 的挂载范围；</p>
<p>ServiceAccount 还有一个设置镜像拉取密钥的属性，这个属性不是用来限制可挂载的密钥范围的，而是用来实现挂载镜像拉取密钥的自动化；所有关联该 ServiceAccount 的 pod，都会自动被挂载该镜像拉取密钥，从而能够从私有仓库拉取需要的镜像；</p>
<h4 id="将-ServiceAccount-分配给-pod"><a href="#将-ServiceAccount-分配给-pod" class="headerlink" title="将 ServiceAccount 分配给 pod"></a>将 ServiceAccount 分配给 pod</h4><p>在 pod 的定义文件中的 spec.serviceAccountName 字段，即可以用来显式的指定 pod 所要关联的 ServiceAccount；该字段的值在 pod 创建后就不能修改了，需要在创建时提前设置好；</p>
<p>ServiceAccount 本身并不包含任何的权限功能（除了控制可挂载密钥的范围外），因此如果没有特别的进行设置的话，所有新创建  ServiceAccount 都默认具有全部的资源操作权限；因此它需要配合 RBAC 授权插件一起使用，才能起到控制权限的效果；</p>
<h3 id="通过基于角色的权限控制加强集群安全"><a href="#通过基于角色的权限控制加强集群安全" class="headerlink" title="通过基于角色的权限控制加强集群安全"></a>通过基于角色的权限控制加强集群安全</h3><p>在早期的 Kubernetes 版本中，由于安全控制做得不够完善，只要在某个 pod 中查找到其所用的 token，就可以实现和 API 服务器的通信，对集群中的资源做任何想做的操作；在 1.8 版本之后，RBAC 插件升级为全局可用并默认开启，它会阻止未授权的用户查看和修改集群的状态；</p>
<h4 id="介绍-RBAC-授权插件"><a href="#介绍-RBAC-授权插件" class="headerlink" title="介绍 RBAC 授权插件"></a>介绍 RBAC 授权插件</h4><p>背景：API 服务器对外暴露的是 REST 接口，因此用户是通过发送 HTTP 请求调用相应的接口来实现某个操作的；请求由动作+资源名称来组成；基于该背景，RBAC 的控制机制就是检查该请求的动作和资源是否都属于允许操作的范围；</p>
<p>RBAC 是基于用户所属的角色来检查用户的授权情况的；一个用户可能对应多个角色，只要某个角色拥有某种资源的某个操作权限，则请求就会得到通过；</p>
<h4 id="介绍-RBAC-资源"><a href="#介绍-RBAC-资源" class="headerlink" title="介绍 RBAC 资源"></a>介绍 RBAC 资源</h4><p>RBAC 授权规则通过四种资源来实现配置；这四种资源可分为两个组：</p>
<ul>
<li>角色组：Role、ClusterRole，它们指定了在资源上面可以执行哪些动词；二者的差别在于前者面向命名空间内的资源，后者面向集群级别的资源；</li>
<li>角色绑定组：RoleBinding、ClusterRoleBinding，它们将上述角色绑定到特定的用户、组或者 ServiceAccount 上面；</li>
</ul>
<blockquote>
<p> 角色组决定了用户可以做哪些操作，角色绑定组决定了谁可以做这些操作；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815193242.png"></p>
<p>虽然 RoleBinding 在命名空间下起作用，不能跨命名空间，但是这并不影响它们引用集群级别的角色，因此集群角色并不属于任何的命名空间；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200815193616.png"></p>
<p>在启用了 RBAC 插件后，pod 默认绑定的 serviceAccount 并不具备查询或修改集群资源的权限，这样可以最大程度的保证集群的安全性；</p>
<h4 id="使用-Role-和-RoleBinding"><a href="#使用-Role-和-RoleBinding" class="headerlink" title="使用 Role 和 RoleBinding"></a>使用 Role 和 RoleBinding</h4><p>定义 role 资源的示例</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200821075132.png"></p>
<blockquote>
<p>每个资源都属于某个 API 资源组，在声明文件中定义资源的时候，字段 apiVersion 即是指定资源所属的 API 资源组；</p>
<p>复数的资源名称表示可以访问所有的同类型资源，但是也可以通过增加资源名称进一步缩小访问范围；</p>
<p>Role 是归属于命名空间的资源，因为不同的命名空间可以拥有相同的 Role 名称，但里面的内容可能不同</p>
</blockquote>
<p>在 Kubernetes 中需要通过创建 RoleBinding 资源来实现角色与相关主体（如用户、ServiceAccount、组等）的绑定（这个理念很有意思，有点面向对象的意思，即想要实现的动作，通过创建对象来实现）；</p>
<blockquote>
<p>在 GKE 中创建角色之前，需要让当前的客户端账号获取集群管理员的角色，即需要为当前账号创建一个 clusterRoleBinding 资源，来进行集群管理员角色的绑定，示例如下：</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200821075712.png"></p>
</blockquote>
<p>RoleBinding 只能将单个角色绑定到一个或多个主体上，这些主体可以归属于不同的命名空间；但是不能反过来，即将多个角色绑定到一个或多个主体上；</p>
<blockquote>
<p>问：这貌似意味着如果主体需要绑定多个角色，要创建多个 RoleBinding 资源？</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200821084634.png"></p>
<h4 id="使用-ClusterRole-和-ClusterRoleBinding"><a href="#使用-ClusterRole-和-ClusterRoleBinding" class="headerlink" title="使用 ClusterRole 和 ClusterRoleBinding"></a>使用 ClusterRole 和 ClusterRoleBinding</h4><p>普通的角色只能访问到自己所处命名空间中的资源；ClusterRole 则可以访问集群级别的资源，或者所有命名空间中的资源（这样可以避免在多个命名空间中定义相同的角色，只需定义一个 ClusterRole 的角色，就可以多次使用了，即被不同命名空间中的 RoleBinding 进行绑定）；至于是哪一种，它是通过绑定过程来实现的；当使用 ClusterRoleBinding 进行绑定的时候，被绑定的主体就可以访问所有命名空间中的资源；当使用 RoleBinding 进行绑定的时候，被绑定的主体则只能访问其所在的命名空间中的资源；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200825080004.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200825080026.png"></p>
<h4 id="了解默认的-ClusterRole-和-ClusterRoleBinding"><a href="#了解默认的-ClusterRole-和-ClusterRoleBinding" class="headerlink" title="了解默认的 ClusterRole 和 ClusterRoleBinding"></a>了解默认的 ClusterRole 和 ClusterRoleBinding</h4><p>Kubernetes 启动时，即已经内置好了一些常用的 ClusterRole，其中最常用的四个分别是：</p>
<ul>
<li>edit：对命名空间中的资源的修改权（除不允许修改 Role 和 RoleBinding）；</li>
<li>view：对命名空间中的资源的读取权（除不能读取 Role、RoleBinding 和 Secret）；</li>
<li>admin：对命名空间中的资源的完全控制权（除 ResourceQuota 资源外）；</li>
<li>cluster-admin：对整个集群的完全控制权</li>
</ul>
<p>其中一些 ClusterRole 和相同名称的 ClusterRoleBinding 主要是用来给各种控制组件分配权限的；</p>
<h4 id="理性的授予权限"><a href="#理性的授予权限" class="headerlink" title="理性的授予权限"></a>理性的授予权限</h4><p>为了安全起见，默认的 ServiceAccount 几乎没有什么权限，连查看集群状态的权限都没有，几乎等于未经认证的用户；但这显然无法应对工作中的需要，好的做法不是给默认 ServiceAccount 添加各种权限，因为它会导致这些权限扩散到那些同样使用默认 ServiceAccount 的 pod 上；而是应该单独给每个需要权限的 pod 创建单独的 ServiceAccount、Role 和 RoleBinding，并在 Role 里面设置所需要的最小权限；</p>
<h2 id="13-保障集群内节点的网络安全"><a href="#13-保障集群内节点的网络安全" class="headerlink" title="13. 保障集群内节点的网络安全"></a>13. 保障集群内节点的网络安全</h2><h3 id="在-pod-中使用宿主节点的-Linux-命名空间"><a href="#在-pod-中使用宿主节点的-Linux-命名空间" class="headerlink" title="在 pod 中使用宿主节点的 Linux 命名空间"></a>在 pod 中使用宿主节点的 Linux 命名空间</h3><p>背景：宿主节点有自己的默认命名空间，而在节点上运行的每个 pod 也有各自的命名空间；通过命名空间实现了彼此的隔离；这些命名空间包括独立的 PID 命名空间、IPC 命名空间、网络命名空间等；</p>
<blockquote>
<p>问：貌似即使是同一 pod 中的容器也有各自的命名空间，那么它们如何实现与 pod 的对应？猜测有可能需要在某个地方进行映射登记；</p>
</blockquote>
<h4 id="在-pod-中使用宿主节点的网络命名空间"><a href="#在-pod-中使用宿主节点的网络命名空间" class="headerlink" title="在 pod 中使用宿主节点的网络命名空间"></a>在 pod 中使用宿主节点的网络命名空间</h4><p>缘起：某些 pod 需要运行在宿主节点的默认网络命名空间中，例如执行系统级功能的 pod（像那些运行 Kubernetes 的控制组件的 pod），这样它们才能够查看和操作节点上的资源和设备；</p>
<p>解决办法：在 pod 的 spec 字段中，启用 hostNetwork: true 选项；</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-with-host-network</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">	<span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main</span></span><br><span class="line">	  <span class="attr">image:</span> <span class="string">alpine</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&quot;/bin/sleep&quot;</span>, <span class="string">&quot;999999&quot;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="绑定宿主节点上的端口而不使用宿主节点的网络命名空间"><a href="#绑定宿主节点上的端口而不使用宿主节点的网络命名空间" class="headerlink" title="绑定宿主节点上的端口而不使用宿主节点的网络命名空间"></a>绑定宿主节点上的端口而不使用宿主节点的网络命名空间</h4><p>实现办法：在 spec.containers.ports 下，有一个 hostPort 属性，可以用来设置 pod 端口和节点端口的映射绑定；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826074948.png"></p>
<p>NodePort 类型的 service 也可以用来做相同的绑定，但是区别在于，它是通过修改 iptables 来实现的映射，并且它会作用在所有节点上的 iptables，不管该节点是否有运行 pod；同时，iptables 的路由是随机的，即当前节点 iptable 有可能将请求转发到节点上，以实现负载均衡；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826074746.png"></p>
<p>当使用宿主节点的端口时，将带来一个副作用，因为某个编号的端口在节点上有且仅有一个，这意味着该节点最多运行一个存在这种绑定的 pod；如果所需 pod 副本数大于节点数，将导致部分 pod 一直处于 pending，无法创建成功；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826074824.png"></p>
<p>hostPort 最初是设计用来给节点上 daemonSet 类型的 pod 暴露端口用的，它恰恰好也兼顾保证了一个 pod 只会被安排在节点一次；</p>
<blockquote>
<p>不过据说现在已经有其他更好的实现方法了；是什么呢？</p>
</blockquote>
<h4 id="使用宿主节点的-PID-与-IPC-命名空间"><a href="#使用宿主节点的-PID-与-IPC-命名空间" class="headerlink" title="使用宿主节点的 PID 与 IPC 命名空间"></a>使用宿主节点的 PID 与 IPC 命名空间</h4><p>跟通过 hostNetwork 属性开启与节点相同网络空间的方法一样，也存在 hostPID 和 hostIPC 选项，可以让容器使用节点上默认的进程命名空间和进程间通信空间；开启后，将可以在容器内看到节点上进行的进程，并可以使用内部进程通信机制与它们进行通信；</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-with-host-pid-and-ipc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostIPC:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">alpine</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/bash&quot;</span>, <span class="string">&quot;999999&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="配置节点的安全上下文"><a href="#配置节点的安全上下文" class="headerlink" title="配置节点的安全上下文"></a>配置节点的安全上下文</h3><p>容器中的进程常常以 root 身份运行应用，当容器和节点共享命名空间时，意味着有可能存在安全隐患，因此有必要进一步对 pod 对宿主节点的访问权限，进行更细粒度的设置；此时可以通过一个叫做安全上下文（security-context）的选项来实现配置；</p>
<h4 id="使用指定用户运行容器"><a href="#使用指定用户运行容器" class="headerlink" title="使用指定用户运行容器"></a>使用指定用户运行容器</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826082252.png"></p>
<h4 id="阻止容器以-root-用户运行"><a href="#阻止容器以-root-用户运行" class="headerlink" title="阻止容器以 root 用户运行"></a>阻止容器以 root 用户运行</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826082527.png"></p>
<p>容器以 root 用户运行存在一定的安全隐患，例如当节点上有目录被挂载到容器中时，将使得攻击者有机会访问和修改该目录中的内容；</p>
<h4 id="使用特权模式运行pod"><a href="#使用特权模式运行pod" class="headerlink" title="使用特权模式运行pod"></a>使用特权模式运行pod</h4><p>有时候根据业务场景需要，不可避免需要让 pod 访问节点上的资源，例如硬件设备、内核功能等；此时需要增加 pod 的权限，让其拥有访问的特权；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826083125.png"></p>
<h4 id="为容器单独添加内核功能"><a href="#为容器单独添加内核功能" class="headerlink" title="为容器单独添加内核功能"></a>为容器单独添加内核功能</h4><p>通过 privileged 开启特权模式并不是好的做法，因为它意味着赋予容器完全的权限，但实际上并不需要那么多，因此需要进一步做更细粒度的配置，仅赋予所需要的个别权限即可；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826083543.png"></p>
<h4 id="在容器中禁用内核功能"><a href="#在容器中禁用内核功能" class="headerlink" title="在容器中禁用内核功能"></a>在容器中禁用内核功能</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826083626.png"></p>
<h4 id="阻止对容器根文件系统的写入"><a href="#阻止对容器根文件系统的写入" class="headerlink" title="阻止对容器根文件系统的写入"></a>阻止对容器根文件系统的写入</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200826090621.png"></p>
<blockquote>
<p>好的实践：将根文件系统的阻止写入设置为 true，然后为需要写入的数据，例如日志文件、磁盘缓存等单独挂载存储卷； </p>
</blockquote>
<p>上述的各个上下文选项是在容器中设置的，但也可以设置在 pod 项下，这样会对 pod 中的所有容器都产生作用，而不局限于单个容器；</p>
<h4 id="容器使用不同用户运行时共享存储卷"><a href="#容器使用不同用户运行时共享存储卷" class="headerlink" title="容器使用不同用户运行时共享存储卷"></a>容器使用不同用户运行时共享存储卷</h4><p>通过存储卷，可以让两个不同的容器共享数据，例如一个负责写入，一个负责读取；但是这样做的前提是两个容器都以 root 用户来运行；如果不是的话则会出现权限问题，导致共享不成功；</p>
<p>有两个属性可以用来解决这个问题</p>
<ul>
<li>fsGroup：用来设置 pod 中所有容器在存储卷中创建的文件的所属组别</li>
<li>supplementalGroups：用来给容器中的用户添加新组别</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-with-shared-volume-fsgroup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">securityContext:</span></span><br><span class="line">    <span class="attr">fsGroup:</span> <span class="number">555</span> <span class="comment"># 写入存储卷的文件的组别</span></span><br><span class="line">    <span class="attr">supplementalGroups:</span> [<span class="number">666</span>, <span class="number">777</span>] <span class="comment"># 用户的其他组别</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">first</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">alpine</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sleep&quot;</span>, <span class="string">&quot;999999&quot;</span>]</span><br><span class="line">    <span class="attr">securityContext:</span></span><br><span class="line">      <span class="attr">runAsUser:</span> <span class="number">1111</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/volume</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">second</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">alpine</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sleep&quot;</span>, <span class="string">&quot;999999&quot;</span>]</span><br><span class="line">    <span class="attr">securityContext:</span></span><br><span class="line">      <span class="attr">runAsUser:</span> <span class="number">2222</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/volume</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-volume</span></span><br><span class="line">    <span class="attr">emptyDir:</span></span><br></pre></td></tr></table></figure>

<h3 id="限制-pod-使用安全相关的特性"><a href="#限制-pod-使用安全相关的特性" class="headerlink" title="限制 pod 使用安全相关的特性"></a>限制 pod 使用安全相关的特性</h3><p>集群中有两种角色，一个是集群的管理员（创建集群资源的人），一个是开发人员（使用集群资源的人）；为了避免开发人员滥用某些功能，例如开启容器的 privilege 权限，导致埋下安全隐患，集群管理员可以通过添加全局设置，来限制部分功能的使用；</p>
<h4 id="PodSecurityPolicy-资源介绍"><a href="#PodSecurityPolicy-资源介绍" class="headerlink" title="PodSecurityPolicy 资源介绍"></a>PodSecurityPolicy 资源介绍</h4><p>PodSecurityPolicy 是一个全局资源，即不属于任何的命名空间，用来限制 Pod 可以开启的安全特性；它需要集群开启 PodSecurityPolicy 插件（负责准入控制）后才能使用；当 API 服务器收到创建 Pod 的请求后，它会调用插件，检查该 Pod 的安全特征是否符合 PodSecurityPolicy  里面规定的要求；如果符合，则开始创建；如果不符合，则拒绝请求；</p>
<p>PodSecurityPolicy 能够控制的事情，差不多全部就是上一节提到的那些安全上下文选项，额外还有一项是可以控制 Pod 可以使用的存储卷类型；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827084949.png"></p>
<h4 id="了解-runAsUser、fsGroup-和-supplementalGroup-策略"><a href="#了解-runAsUser、fsGroup-和-supplementalGroup-策略" class="headerlink" title="了解 runAsUser、fsGroup 和 supplementalGroup 策略"></a>了解 runAsUser、fsGroup 和 supplementalGroup 策略</h4><p>对 Pod 可用的用户 ID、用户组 ID 进行限制的示例</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827085157.png"></p>
<blockquote>
<p>PodSecurityPolicy  仅会在创建 Pod 时起作用，如果在创建 PodSecurityPolicy  资源之前， Pod 已经创建了，则已经创建的 Pod 不会受到 PodSecurityPolicy 的影响；</p>
</blockquote>
<p>如果创建 Pod 时没有声明用户 ID，则 Pod 创建后，PodSecurityPolicy 会将容器中的用户 ID 强制修改为策略所允许的 ID，即使容器镜像有定义自己的 ID 也一样会被覆盖；</p>
<h4 id="配置允许、默认添加、禁止使用的内核功能"><a href="#配置允许、默认添加、禁止使用的内核功能" class="headerlink" title="配置允许、默认添加、禁止使用的内核功能"></a>配置允许、默认添加、禁止使用的内核功能</h4><p>通过以下三个字段实现控制：</p>
<ul>
<li>allowedCapabilities</li>
<li>defaultAddCapabilities</li>
<li>requiredDropCapabilities</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827085725.png"></p>
<p>对于出现在 defaultAddCapabilities 的功能，将会被自动添加到容器中；如果不希望某个容器拥有该功能，则可以在该 Pod 的声明文件中显式的禁用该功能；</p>
<h4 id="限制-pod-可以使用的存储卷类型"><a href="#限制-pod-可以使用的存储卷类型" class="headerlink" title="限制 pod 可以使用的存储卷类型"></a>限制 pod 可以使用的存储卷类型</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200827090111.png"></p>
<p>如果集群中存在多个 PodSecurityPolicy ，则容器可以使用的存储卷类型是所有 PodSecurityPolicy 中罗列出的类型的合集；</p>
<h4 id="对不同的用户与组分配不同的-PodSecurityPolicy"><a href="#对不同的用户与组分配不同的-PodSecurityPolicy" class="headerlink" title="对不同的用户与组分配不同的 PodSecurityPolicy"></a>对不同的用户与组分配不同的 PodSecurityPolicy</h4><p>虽然 PodSecurityPolicy 是集群组别的资源，不归属任何的命名空间，但是它并不会默认对所有命名空间中创建的 pod 生效；它需要被 ClusterRole 引用，然后经由 ClusterRoleBinding 绑定到指定的用户或组之后，才会生效；因此，本质上来说，策略并不针对命名空间，而是针对用户或组的； </p>
<h3 id="隔离-pod-的网络"><a href="#隔离-pod-的网络" class="headerlink" title="隔离 pod 的网络"></a>隔离 pod 的网络</h3><p>除了上一节提到的可以对 Pod 的安全选项进行配置外，还可以配置 Pod 的网络访问规则，允许或限制入网和出网通信，实现一定程度的网络隔离；默认情况下 Pod 是可以被任意来源的请求进行访问的；</p>
<h4 id="在一个命名空间中启用网络隔离"><a href="#在一个命名空间中启用网络隔离" class="headerlink" title="在一个命名空间中启用网络隔离"></a>在一个命名空间中启用网络隔离</h4><p>如果想把某个命名空间中的所有 Pod 隔离起来，可以创建一个没有写 ingress 入网规则的 NetworkPolicy，同时标签选择器放空，这样它会匹配命名空间中的所有 pod</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828075133.png"></p>
<blockquote>
<p>NetworkPolicy 资源能够生效的前提，是需要集群中的 CNI 插件支持这种资源；不然创建了资源，也不能发挥作用；</p>
</blockquote>
<h4 id="允许同一命名空间中的部分-pod-访问一个服务端-pod"><a href="#允许同一命名空间中的部分-pod-访问一个服务端-pod" class="headerlink" title="允许同一命名空间中的部分 pod 访问一个服务端 pod"></a>允许同一命名空间中的部分 pod 访问一个服务端 pod</h4><p>如果不加限制，同个命名空间中的 pod 之间，是可以自由的相互访问的，为了提高安全性，可以设置让某个 pod 只允许被指定pod 访问，而不能被未指定的 pod 访问；做法就是创建一个 NetworkPolicy，作用于该 pod，然后在入网规则中写上允许访问的 pod 的标签选择器和可访问的端口号，这些就只有标签选择器匹配的那些 pod， 才具有访问权限；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828075645.png"></p>
<blockquote>
<p>即使 pod 之间是通过 service 相互访问，以上规则仍然会生效；因为 service 的本质仍然是要回到 iptables 去实现的；</p>
</blockquote>
<h4 id="在不同命名空间之间进行网络隔离"><a href="#在不同命名空间之间进行网络隔离" class="headerlink" title="在不同命名空间之间进行网络隔离"></a>在不同命名空间之间进行网络隔离</h4><p>实现方法很简单，在入网规则中，有一个 namespaceSelector 的属性，可以用来写命名空间的选择器；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828080023.png"></p>
<h4 id="使用-CIDR-隔离网络"><a href="#使用-CIDR-隔离网络" class="headerlink" title="使用 CIDR 隔离网络"></a>使用 CIDR 隔离网络</h4><p>前面提到的入网规则是通过标签选择器来实现的，另外还可以通过 IP 段来限制，即只允许某个 IP 段范围内的请求，实现办法是通过 ipBlock.cidr 属性来实现</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828081338.png"></p>
<h4 id="限制-pod-的对外访问流量"><a href="#限制-pod-的对外访问流量" class="headerlink" title="限制 pod 的对外访问流量"></a>限制 pod 的对外访问流量</h4><p>通过对出网规则 egress 规则进入设置即可实现 pod 的对外访问</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828081450.png"></p>
<h2 id="14-计算资源管理"><a href="#14-计算资源管理" class="headerlink" title="14. 计算资源管理"></a>14. 计算资源管理</h2><h3 id="为-pod-中的容器申请资源"><a href="#为-pod-中的容器申请资源" class="headerlink" title="为 pod 中的容器申请资源"></a>为 pod 中的容器申请资源</h3><h4 id="创建包含资源-requests-的pod"><a href="#创建包含资源-requests-的pod" class="headerlink" title="创建包含资源 requests 的pod"></a>创建包含资源 requests 的pod</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155802.png"></p>
<h4 id="资源-requests-如何影响调度"><a href="#资源-requests-如何影响调度" class="headerlink" title="资源 requests 如何影响调度"></a>资源 requests 如何影响调度</h4><p>requests 用来指定容器所需要资源的最小值，而不是上限值；但它会影响调度器的调度，但调度器发现某个节点的资源已经不满足 requests 要求的最小值时，就不会将 pod 调度到该节点上；</p>
<p>调度器有两种优先级调度函数，一种是优先调度到最有空闲的节点，另一种是优先调度到最满负荷的节点；前者可以让节点的资源使用平均化；后者则可以尽量少的节点运行尽可能多的 pod；</p>
<p>当节点上的可用资源不足时，pod 将无法正常进入运行状态，而会一直处于 pending 状态，直到有 pod 被删除后资源被释放出来；</p>
<h4 id="CPU-requests-如何影响-CPU-时间分配"><a href="#CPU-requests-如何影响-CPU-时间分配" class="headerlink" title="CPU requests 如何影响 CPU 时间分配"></a>CPU requests 如何影响 CPU 时间分配</h4><p>CPU requests 不仅会影响调度器的调度工作，还会影响到节点上可用资源在多个 pod 之间的分配工作；调度器会根据申请的资源数量的比例，来分配余下的可用资源给相应的  pod；但如果剩余可用资源刚好没有其他 pod 占用时，调度器会将所有的剩余资源临时全部分配某个繁忙的容器；当其他容器开始要用时，再退还；</p>
<h4 id="定义和申请自定义资源"><a href="#定义和申请自定义资源" class="headerlink" title="定义和申请自定义资源"></a>定义和申请自定义资源</h4><p>CPU 和内存是常规的可用资源，Kubernetes 还支持一些自定义资源，例如 GPU；在使用这类自定义资源时，需要先将自定义资源加入节点 API 对象的 capacity属性中，以便 Kubernetes 可以知道该资源的存在；之后，就可以像常规资源一样去引用它了；</p>
<h3 id="限制容器的可用资源"><a href="#限制容器的可用资源" class="headerlink" title="限制容器的可用资源"></a>限制容器的可用资源</h3><h4 id="设置容器可使用资源量的硬限制"><a href="#设置容器可使用资源量的硬限制" class="headerlink" title="设置容器可使用资源量的硬限制"></a>设置容器可使用资源量的硬限制</h4><p>CPU 是一种可压缩资源，即对进程做出使用限制，并不会影响进程的正常运行，只是会让它的性能下降，计算时间变长而已；而内存是一种不可压缩资源，当为某个进程分配了一块内存后，如果进程没有释放该内存，将导致该块内存一直被占用，即使内存存在空闲，其他进程也没有机会使用；因此，对 pod 的可用资源数量做出最大限制是有必要的，这样可以防止出现恶意 pod 导致整个节点不可用；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155816.png"></p>
<blockquote>
<p>当设置了 limits 值后，如果没有设置 requests 值，而默认使用 limits 值做为 requests 值；</p>
</blockquote>
<p>调度器不会将 pod 调度到剩余资源不足的节点上，但是会调度到 limits 超过 100% 的节点上，limits 存在超卖现象；limits 并不作为节点调度的控制因素；但是当节点节点上的一个或多个容器使用的资源使用超过 limits 总量时，将导致个别容器被干掉；</p>
<h4 id="超过-limits"><a href="#超过-limits" class="headerlink" title="超过 limits"></a>超过 limits</h4><p>当某个容器申请超过 limits 限制的内存资源时，如果 pod 的重启策略设置为 Always 或者 OnFailure时，容器将会被干掉（OOMKilled， out of memory killed）；此时 pod 会呈现 CrashLoopBackOff 状态（即不断重启，每次增加一部的间隔时间，最大间隔规定为 5 分钟）；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816155830.png"></p>
<h4 id="容器中的应用如何看待-limits"><a href="#容器中的应用如何看待-limits" class="headerlink" title="容器中的应用如何看待 limits"></a>容器中的应用如何看待 limits</h4><p> 当在容器中运行 top 命令来查看内存使用情况时，显示的结果是节点的内存使用情况，而不是真实的容器中的进程所使用的内存情况；不仅内存有这个情况，CPU 的使用也是这个情况；</p>
<p> 因此，如果需要在代码中查询可用资源数量时，应避免使用常规的 linux<br> 命令来查看，而应该通过 downward API 来查看实际配置的 limits 值，然后再采取相应的操作；另外也可以通过 cgroup 系统来获取配置的 CPU 限制（如下面的两个文件）；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/sys/fs/cgroup/cpu/cpu.cfs_quota_us</span><br><span class="line">/sys/fs/cgroup/cpu/cpu.cfs_period_us</span><br></pre></td></tr></table></figure>


<h3 id="了解-pod-QoS-等级"><a href="#了解-pod-QoS-等级" class="headerlink" title="了解 pod QoS 等级"></a>了解 pod QoS 等级</h3><p>由于 limits 会被超卖导致某些容器在内存资源不足时被杀死，因此需要制定一个优先级的规则，来决定谁应该优先被杀死；</p>
<p>优先级从低到高分别是：</p>
<ul>
<li>BestEffort：低</li>
<li>Burstable：中</li>
<li>Guaranteed：高</li>
</ul>
<h4 id="定义-pod-的-QoS-等级"><a href="#定义-pod-的-QoS-等级" class="headerlink" title="定义 pod 的 QoS 等级"></a>定义 pod 的 QoS 等级</h4><p>QoS 等级来源于容器的 requests 和 limits 字段的配置，并没有一个单独的字段可以进行定义；</p>
<h5 id="BestEffort-等级"><a href="#BestEffort-等级" class="headerlink" title="BestEffort 等级"></a>BestEffort 等级</h5><p>容器没有设置 requests 和 limits 值的 pod 都属于这个等级；</p>
<ul>
<li>优点：内存资源充足的情况下，可使用的内存无上限；</li>
<li>缺点：没有任何的资源保证；资源不足时，则啥也分不到；需要释放资源时，首批被杀死；</li>
</ul>
<h5 id="Guaranteed-等级"><a href="#Guaranteed-等级" class="headerlink" title="Guaranteed 等级"></a>Guaranteed 等级</h5><p>所有容器 requests 和 limits 值相等的 pod 属于这个等级；</p>
<ul>
<li>优点：可保证所请求的资源能够全额分配；</li>
<li>缺点：除了已分配的外，无法使用更多的资源；</li>
</ul>
<h5 id="Burstable-资源"><a href="#Burstable-资源" class="headerlink" title="Burstable 资源"></a>Burstable 资源</h5><p>不属于前面两个等级的 pod，属于这个级别；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160108.png"></p>
<p>对于多容器的 pod，只有当所有的容器都属于 BestEffort 或者 Guranteed 等级时，pod 才是相应的等级，不然全部归属于 Burstable 等级；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160120.png"></p>
<h4 id="内存不足时哪个进程会被杀死"><a href="#内存不足时哪个进程会被杀死" class="headerlink" title="内存不足时哪个进程会被杀死"></a>内存不足时哪个进程会被杀死</h4><p>被杀掉的顺序跟 QoS 等级对应，BestEffort 最先被杀掉，最后是 Guaranteed；只有在系统进程需要内存时，Guranteed 进程才可能被杀掉；</p>
<p>对于两个等级相同的 pod，当内存不足时，那个实际使用内存量占申请量更高的 pod 将会被杀掉，即优先杀掉大骗子，留下小骗子；</p>
<h3 id="为命名空间中的-pod-设置默认的-requests-和-limits"><a href="#为命名空间中的-pod-设置默认的-requests-和-limits" class="headerlink" title="为命名空间中的 pod 设置默认的 requests 和 limits"></a>为命名空间中的 pod 设置默认的 requests 和 limits</h3><h4 id="LimitRange-资源简介"><a href="#LimitRange-资源简介" class="headerlink" title="LimitRange 资源简介"></a>LimitRange 资源简介</h4><p>LimitRange 资源有点像是一个模板，当没有显式的为 pod 设置资源使用声明时，默认使用模板提供的值；并且如果 pod 申请的值超过了模板允许的上限，pod 将不会被允许创建，直接出现报错；</p>
<p>LimitRange 只作用于单独的 pod，所以它不会对所有 pod 要使用的资源总量起作用；</p>
<h4 id="LimitRange-资源的创建"><a href="#LimitRange-资源的创建" class="headerlink" title="LimitRange 资源的创建"></a>LimitRange 资源的创建</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160139.png"></p>
<blockquote>
<p>示例的写法将不同类型对象的资源使用限制写在了同一个 LimitRange对象中，但是也可以拆分写在多个对象中，每个控制一种类型；</p>
</blockquote>
<p>LimitRange 只适用于在其后创建的资源，如果某个资源在 LimitRange 创建之前已经存在，则不会受到限制；</p>
<h4 id="强制进行限制"><a href="#强制进行限制" class="headerlink" title="强制进行限制"></a>强制进行限制</h4><p>当对可用资源进行了限制后，此时如果创建超过限制的对象，Kubernetes 将直接给出报错信息；</p>
<h4 id="应用资源-requests-和-limits-的默认值"><a href="#应用资源-requests-和-limits-的默认值" class="headerlink" title="应用资源 requests 和 limits 的默认值"></a>应用资源 requests 和 limits 的默认值</h4><p>LimitRange 的作用域是以命名空间为单位的，即只对当前命名内的对象有效，而对其他命名空间的对象无效；</p>
<h3 id="限制命名空间中的可用资源总量"><a href="#限制命名空间中的可用资源总量" class="headerlink" title="限制命名空间中的可用资源总量"></a>限制命名空间中的可用资源总量</h3><p>LimitRange 只能限制单个 pod 的资源使用，没有对可使用的资源总量做出限制，因此如果恶意创建大量的 pod，将会导致整个集群的资源全部被占用掉；</p>
<h4 id="ResourceQuota-资源介绍"><a href="#ResourceQuota-资源介绍" class="headerlink" title="ResourceQuota 资源介绍"></a>ResourceQuota 资源介绍</h4><p>ResourceQuota 可以对两个事情做出限制</p>
<ul>
<li>一个是所有 pod 可以使用的资源总量，当监控限制量此，如果此时新增一个 pod 导致超出限额，则该 pod 不会创建成功；</li>
<li>另一个是可创建的对象数量；</li>
</ul>
<h5 id="创建-ResouceQuota-对象示例"><a href="#创建-ResouceQuota-对象示例" class="headerlink" title="创建 ResouceQuota 对象示例"></a>创建 ResouceQuota 对象示例</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160155.png"></p>
<p>在创建 ResouceQuota 之前，必须先创建 LimitRange，这样 ResouceQuota 才能创建成功，不然会报错；因为如果没有 LimitRange，则 BestEffort 等级的 pod 可使用的资源是没有上限的；</p>
<h4 id="为持久化存储指定配额"><a href="#为持久化存储指定配额" class="headerlink" title="为持久化存储指定配额"></a>为持久化存储指定配额</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160209.png"></p>
<h4 id="限制可创建对象的个数"><a href="#限制可创建对象的个数" class="headerlink" title="限制可创建对象的个数"></a>限制可创建对象的个数</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">objects</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">hard:</span></span><br><span class="line">        <span class="attr">pods:</span> <span class="number">10</span></span><br><span class="line">        <span class="attr">replicationcontrollers:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">secrets:</span> <span class="number">10</span></span><br><span class="line">        <span class="attr">configmaps:</span> <span class="number">10</span></span><br><span class="line">        <span class="attr">persistentvolumeclaims:</span> <span class="number">4</span></span><br><span class="line">        <span class="attr">services:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">services.loadbalancers:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">services.nodeports:</span> <span class="number">2</span></span><br><span class="line">        <span class="attr">ss.storageclass.storage.k8s.io/persistentvolumeclaims:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h4 id="为特定的-pod-状态或者-QoS-等级指定配额"><a href="#为特定的-pod-状态或者-QoS-等级指定配额" class="headerlink" title="为特定的 pod 状态或者 QoS 等级指定配额"></a>为特定的 pod 状态或者 QoS 等级指定配额</h4><p>配额可以指定作用范围，总共有四种作用范围，只有当对象满足作用范围的条件时，配额限制才会生效；</p>
<ul>
<li>BestEffort：BestEffort 类型的对象</li>
<li>NotBestEffort：非 BestEffort 类型的对象</li>
<li>Terminating：Terminating 类型的对象（已进入 Failed 但未真正停止的状态）</li>
<li>NotTerminating：非Terminating 类型的对象</li>
</ul>
<blockquote>
<p>BestEffort 只允许限制 pod 的个数，而其他三种还可以限制 CPU 和内存；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816160224.png"></p>
<h3 id="监控-pod-的资源使用量"><a href="#监控-pod-的资源使用量" class="headerlink" title="监控 pod 的资源使用量"></a>监控 pod 的资源使用量</h3><p>资源使用配额如果写得太高，则会导致资源浪费，如果定得太低，则会导致应用经常被杀死，服务不稳定，因此需要找到一个最佳平衡点；平衡点的寻找办法即是通过监控应用的资源使用情况来进行决策；</p>
<h4 id="收集、获取实际资源使用情况"><a href="#收集、获取实际资源使用情况" class="headerlink" title="收集、获取实际资源使用情况"></a>收集、获取实际资源使用情况</h4><p>在每个节点上，Kubelet 自带有一个插件，可以用来收集节点上的资源消耗情况；而 Kubernetes 则可以通过附加组件 Heapster 来进行统计，得到监控信息；</p>
<blockquote>
<p>Heapster 已经停用，现在改成了 metrics-server,  本地集群的启用方法 minikube addons enable metrics-server，启用后，需要等待好几分钟才能收集到数据并准备好</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816173056.png"></p>
<h5 id="显示节点的-CPU-和内存使用量"><a href="#显示节点的-CPU-和内存使用量" class="headerlink" title="显示节点的 CPU 和内存使用量"></a>显示节点的 CPU 和内存使用量</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816173109.png"></p>
<h5 id="显示-pod-的-CPU-和内存使用量"><a href="#显示-pod-的-CPU-和内存使用量" class="headerlink" title="显示 pod 的 CPU 和内存使用量"></a>显示 pod 的 CPU 和内存使用量</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816173120.png"></p>
<blockquote>
<p>如果要查看容器的资源使用情况，则需要加上 –container 选项；</p>
</blockquote>
<h4 id="保存并分析历史资源的使用统计信息"><a href="#保存并分析历史资源的使用统计信息" class="headerlink" title="保存并分析历史资源的使用统计信息"></a>保存并分析历史资源的使用统计信息</h4><p>top 命令只显示当前的资源使用情况，而不是历史的统计；即使是 cAdvisor 和Heapster 也只保留了很短的一段时间内的数据；如果想要获得比较长的一段时间的统计数据，需要引入数据库对数据进行保存和可视化，常用的工具为 InfiuxDB 和 Grafana；</p>
<p> InfiuxDB 和 Grafana 都是以 pod 的形式运行的，因此只要下载相应的声明文件，即可快速部署；如果是 Minikube 则更加简单，只需要启用相应的插件就可以了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165304.png"></p>
<p>找到 grafana 的地址</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165332.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165345.png"></p>
<h2 id="15-自动横向伸缩-pod-与集群节点"><a href="#15-自动横向伸缩-pod-与集群节点" class="headerlink" title="15. 自动横向伸缩 pod 与集群节点"></a>15. 自动横向伸缩 pod 与集群节点</h2><p>在 pod 开始运行起来之后，如果发现请求量逐渐增加，通过手工更改 deployment、replicaSet 等资源的副本数量，可以实现 pod 数量的增加；但是这需要提前知道流量何时会增加，可是有时候并没有办法提前知道，因此需要引入一套监控的机制，当监控的指标发生变化时，让集群根据提前设置好的规则，自动增加 pod 的副本数量或者是节点数量；</p>
<h3 id="pod-横向自动伸缩"><a href="#pod-横向自动伸缩" class="headerlink" title="pod 横向自动伸缩"></a>pod 横向自动伸缩</h3><p>HPA 插件，horizontalPodAutoscaler，是一个专门用来监控 pod 的运行状态指标的插件，当规则条件满足时，它就会自动调整 pod 的副本数量；</p>
<h4 id="了解自动伸缩过程"><a href="#了解自动伸缩过程" class="headerlink" title="了解自动伸缩过程"></a>了解自动伸缩过程</h4><p>分为三个步骤来实现</p>
<h5 id="获取状态指标"><a href="#获取状态指标" class="headerlink" title="获取状态指标"></a>获取状态指标</h5><p>HPA 并不用自己去采集指标数据，因为有其他插件已经做了这个工作（即工作节点上的 cAdvisor 和主节点上的 Heapster），它只需要跟 Heapster 拿数据就可以了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828083208.png"></p>
<h5 id="计算所需-pod-副本数"><a href="#计算所需-pod-副本数" class="headerlink" title="计算所需 pod 副本数"></a>计算所需 pod 副本数</h5><p>一般根据 CPU 使用率和 QPS 每秒访问数量来计算</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828083458.png"></p>
<h5 id="调整-replica-属性"><a href="#调整-replica-属性" class="headerlink" title="调整 replica 属性"></a>调整 replica 属性</h5><p>HPA 并不是直接调用 API 服务器的接口对相关资源（如 Deployment、ReplicaSet等）的副本数进行修改，而是通过联系这些资源的子资源对象来修改；这样做的好处是任何资源如果在实现上有任何变更，HPA 这边不会受到任何影响，不需要做任何的修改，它们之间通过子资源实现了隔离；同时不同的资源之间也不会相互影响，因为它们只要管好自己的子资源就可以了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828083849.png"></p>
<h5 id="整个自动伸缩的过程"><a href="#整个自动伸缩的过程" class="headerlink" title="整个自动伸缩的过程"></a>整个自动伸缩的过程</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200828084003.png"></p>
<h4 id="基于-CPU-使用率进行自动伸缩"><a href="#基于-CPU-使用率进行自动伸缩" class="headerlink" title="基于 CPU 使用率进行自动伸缩"></a>基于 CPU 使用率进行自动伸缩</h4><p>在使用 CPU 使用率指标监控 pod 的使用情况时，HPA 插件实际上是根据 pod 定义中提到的 CPU 资源请求来计算的，即根据 pod 运行过程中使用的 CPU 和原请求的 CPU 之间的比例，来判断 pod 是否在超负荷运转；</p>
<p>HPA 对象有两种创建方法，一种是通过 YAML 声明文件，一种是通过 kubectl autoscale 命令（表面上看它操作的对象是 deployment，但在操作的过程中，它会自动创建一个 HPA 对象）</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200829081322.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200829081410.png"></p>
<p>当 pod 的 CPU 使用率超过目标值时，HPA 会对其进行扩容；反之变然，即当运行中的 pod 的 CPU 使用率远低于目标值时，HPA 也会做缩容的动作；</p>
<p>HPA 在扩容的时候，虽然会根据目标值进行计算，得到达成目标值的最少 pod 数量；但是它并不一定能够一步达到将 pod 调整到该数量，尤其是当这个数量比较大的时候；在单次扩容操作中，如果当前副本数小于等于2，则最多只能扩容到4个副本；如果当前副本数大于2，则最多只能扩容一倍；</p>
<p>另外触发扩容或者缩容也有时间间隔的限制；只有距离上一次扩缩容超过3分钟时，才会触发扩容；超过5分钟时，才会触发缩容；</p>
<p>当需要对 HPA 中设定的目标值进行修改时，有两种操作办法，一种是使用 kubectl edit 命令；另一种是先删除原先的 HPA 资源，然后再重新一个；</p>
<h4 id="基于内存使用进行自动伸缩"><a href="#基于内存使用进行自动伸缩" class="headerlink" title="基于内存使用进行自动伸缩"></a>基于内存使用进行自动伸缩</h4><p>使用方法跟 CPU 一样，没有区别，此处略；</p>
<h4 id="基于其他自定义度量进行自动伸缩"><a href="#基于其他自定义度量进行自动伸缩" class="headerlink" title="基于其他自定义度量进行自动伸缩"></a>基于其他自定义度量进行自动伸缩</h4><p>想要使用其他自定义度量进行自动伸缩，需要有一个前提，即度量涉及的指标数据有被收集；度量有有如下类型：</p>
<h5 id="resources-度量类型"><a href="#resources-度量类型" class="headerlink" title="resources 度量类型"></a>resources 度量类型</h5><p>例如 CPU，内存等；</p>
<h5 id="pod-度量类型"><a href="#pod-度量类型" class="headerlink" title="pod 度量类型"></a>pod 度量类型</h5><p>例如 QPS（每秒查询次数）</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200829084405.png"></p>
<h5 id="Object-度量类型"><a href="#Object-度量类型" class="headerlink" title="Object 度量类型"></a>Object 度量类型</h5><p>这种类型极大的扩展了 HPA 的使用场景，它让 HPA 可以根据集群中的其他资源对象的属性来计算是否需要扩缩容</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200829084620.png"></p>
<h4 id="确定哪些度量适合用于自动伸缩"><a href="#确定哪些度量适合用于自动伸缩" class="headerlink" title="确定哪些度量适合用于自动伸缩"></a>确定哪些度量适合用于自动伸缩</h4><p>如果增加副本数之后，并不能使度量的目标值线性的降低，而很可能让度量指标并不适宜；因为该指标的变化，跟 pod 扩缩容可能并不存在实际上的关系；</p>
<h4 id="缩容到零个副本"><a href="#缩容到零个副本" class="headerlink" title="缩容到零个副本"></a>缩容到零个副本</h4><p>目前暂时还不允许缩容到零个副本，但据说未来会实现这个功能；</p>
<h3 id="pod-的纵向自动伸缩"><a href="#pod-的纵向自动伸缩" class="headerlink" title="pod 的纵向自动伸缩"></a>pod 的纵向自动伸缩</h3><p>目前 Kubernetes 官方还没有实现这个功能，但是 google GKE 却有这个功能，它会统计 pod 的资源使用情况，然后自动调整 pod 定义信息中的 resource require 和 limit，以最大化的利用硬件资源；</p>
<h3 id="集群节点的横向伸缩"><a href="#集群节点的横向伸缩" class="headerlink" title="集群节点的横向伸缩"></a>集群节点的横向伸缩</h3><p>当现有的节点不再满足需求，需要添加更多节点时，有一个 ClusterAutoscaler 插件可以用来完成这个任务；</p>
<p>当要添加新节点时，还会遇到该新节点应该是什么样的规格，因此集群需要提前配置好可用的节点规格；这样 ClusterAutoscaler 插件会检索这些可用规格，从中找到一个能够满足 pod 要求的规格，然后创建该节点；</p>
<p>当有多个规格都能够满足 pod 需求时，此时插件就需要从中找一个最合适的；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200829090003.png"></p>
<p>当插件发现节点上所有 pod 的 CPU 和内存使用率都低于 50% 时，它会开始考虑归还该节点；但是前提上节点上运行的 pod 是否可以被调度到其他节点上，如果可以就归还；如果不可以，就不归还；</p>
<ul>
<li>kubectl cordon <node> 命令会将节点标记为不可调度（即不会再往该节点添加新 pod），但已在节点上运行的 pod 不受影响，仍然正常运行；</li>
<li>kubectl drain <node> 命令除了将节点标记为不可调度外，还会将节点上已在运行的 pod 疏散到其他节点上；</li>
</ul>
<h4 id="启用-Cluster-Autoscaler"><a href="#启用-Cluster-Autoscaler" class="headerlink" title="启用 Cluster Autoscaler"></a>启用 Cluster Autoscaler</h4><p>如果启用 Cluster Autoscaler 跟集群部署哪家云供应商有关系，因为不同的云供应商有不同的作法，以下是 GKE 的示例：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcloud container clusters update kubia --enable-autoscaling --min-nodes=3 --max-nodes=5</span><br></pre></td></tr></table></figure>

<h4 id="限制集群缩容时对服务的干扰"><a href="#限制集群缩容时对服务的干扰" class="headerlink" title="限制集群缩容时对服务的干扰"></a>限制集群缩容时对服务的干扰</h4><p>当发生缩容时，节点会被回收，因此运行在 pod 上的节点将变得不可用；但是有可能业务场景对可用的 pod 数量有最低要求，例如 mongo 至少需要有3个实例组成 replica set；因此，为了避免这种状况发生，可以通过创建 podDisruptionBudget 资源来限制集群缩容时对服务带来的干扰</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create pdb kubia-pdb --selector=app=kubia --min-available=3</span><br></pre></td></tr></table></figure>

<blockquote>
<p>podDisruptionBudget 资源的属性很简单，只由标签选择器和最小可用数 min-available 和 max-unavailable 两个属性组成；</p>
</blockquote>
<h2 id="16-高级调度"><a href="#16-高级调度" class="headerlink" title="16. 高级调度"></a>16. 高级调度</h2><h3 id="使用污点和容忍度阻-pod-调度到特定节点"><a href="#使用污点和容忍度阻-pod-调度到特定节点" class="headerlink" title="使用污点和容忍度阻 pod 调度到特定节点"></a>使用污点和容忍度阻 pod 调度到特定节点</h3><p>它的工作原理是给节点添加污点，然后只有那些在定义中规定该种污点可容忍的 pod， 才会被调度到该节点上（有污点相当于默认不分配，让普通 pod 远离该节点）；</p>
<blockquote>
<p>想要实现节点和 pod 之间的关系安排，不外乎有两种做法，一种是不主动对节点做标记，而是在 pod 中做标记，定义应使用哪些节点；另一种是反过来，不主动在 pod 中进行定义，而是先对节点做标记，然后只用那些在定义中明确表示可接受节点上的相关标记的 pod，才会被调度到该节点；</p>
</blockquote>
<h4 id="介绍污点和容忍度"><a href="#介绍污点和容忍度" class="headerlink" title="介绍污点和容忍度"></a>介绍污点和容忍度</h4><p>污点和容忍度的做法默认会用在主节点，这样确保只有标记了可容忍该污点的那些系统级 pod，才会被安排在主节点上；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200830090538.png"></p>
<blockquote>
<p> 此处 effect 字段的值是 NoSchedule，它表示不能容忍这种污点的 pod 不要调度到当前节点来</p>
</blockquote>
<p>污点的效果：</p>
<ul>
<li>NoSchedule：表示如果不能容忍，则不调度 pod 到节点上；</li>
<li>PreferedNoSchedue：表示如果不能容忍，则尽量不调度到该节点上，除非没有其他节点可以调度；</li>
<li>NoExecute：前两个 schedule 只会在创建 pod 时影响 pod 的调度；execute 则会在 pod 运行过程中影响调度；当某个节点在 pod 运行期间突然改变状态，导致 pod 不能容忍时，就会重新调度该 pod 到其他节点；</li>
</ul>
<h4 id="在节点上添加自定义污点"><a href="#在节点上添加自定义污点" class="headerlink" title="在节点上添加自定义污点"></a>在节点上添加自定义污点</h4><p>给节点 node1.k8s 添加自定义污点 node-type&#x3D;production，这样如果不属于生产环境的 pod，就不调度到该节点上，即该节点属于生产环境 pod 的专用；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node node1.k8s node-type=production:NoSchedule</span><br></pre></td></tr></table></figure>

<blockquote>
<p>虽然这种做法可以保证非生产环境 pod 不会被调度到该节点上，但却无法保证生产 pod 被调度到非生产环境的节点上；为了让生产环境和非生产环境的 pod 隔离开，还需要额外给非生产环境的节点添加污点；</p>
</blockquote>
<h4 id="在-pod-上添加污点容忍度"><a href="#在-pod-上添加污点容忍度" class="headerlink" title="在 pod 上添加污点容忍度"></a>在 pod 上添加污点容忍度</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200831082800.png"></p>
<blockquote>
<p>污点操作符除了 Equal 外，还有 Exist；</p>
</blockquote>
<h4 id="污点容忍度的时间限制"><a href="#污点容忍度的时间限制" class="headerlink" title="污点容忍度的时间限制"></a>污点容忍度的时间限制</h4><p>在某些情况下，节点可能会失效，此时集群管理组件会给节点添加污点 unready 或 unreachable，那么如果 pod 对这两种污点没有容忍度的话，就会被调度到其他节点上；但是有时节点在一定的时间后，会恢复正常，此时 pod 并不需要被重新调度，只需要等待一段时间即可；至于想要等待多久，可以通过在 pod 容忍度的设置中，添加容忍时间；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200831084736.png"></p>
<h3 id="使用节点亲缘性将-pod-调度到特定节点上"><a href="#使用节点亲缘性将-pod-调度到特定节点上" class="headerlink" title="使用节点亲缘性将 pod 调度到特定节点上"></a>使用节点亲缘性将 pod 调度到特定节点上</h3><p>关于如何调度 pod 到指定节点，早期 Kubernetes 的实现是使用 nodeSelector 的机制；但后来发现它并不能满足所有类型的业务需求，因此在新的版本中引入了亲缘性规则，后续预计将逐步替代旧的 nodeSelector 机制；</p>
<blockquote>
<p>问：节点亲缘性貌似并不是强制的，而是一种倾向偏好性，即当所有节点都无法满足 pod 的亲缘性需求时，调度组件就会将 pod 调度到任意节点上？</p>
<p>答：后来发现它的规则要复杂得多，虽然默认状态下是非强制性的，但也可以通过规则定义成强制性的；</p>
</blockquote>
<p>使用节点亲缘性的前提是节点需要设置有一些标签，这样 pod 才能根据这些标签判断节点是否有亲缘性；如果没有标签，那就没有办法了；</p>
<p>在 GKE 上面创建集群时，需要设置集群的名称，同时选择地理区域和该区域内部的可用分区，现在才发现，原来 GKE 是通过给节点添加亲缘性标签来实现的；而实质上所有的节点都是在一个大集群内，我们创建的小集群只是逻辑上的；</p>
<h4 id="指定强制性亲缘性规则"><a href="#指定强制性亲缘性规则" class="headerlink" title="指定强制性亲缘性规则"></a>指定强制性亲缘性规则</h4><p>强制指定 pod 只能被分配到配备有 GPU 的节点上</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">	<span class="attr">name:</span> <span class="string">kubia-gpu</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">	<span class="attr">affinity:</span></span><br><span class="line">		<span class="attr">nodeAffinity:</span></span><br><span class="line">			<span class="attr">requiredDuringSchedulingIgnoreDuringExecution:</span></span><br><span class="line">				<span class="attr">nodeSelectorTerms:</span></span><br><span class="line">					<span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">						<span class="bullet">-</span> <span class="attr">key:</span> <span class="string">gpu</span></span><br><span class="line">						  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">						  <span class="attr">values:</span></span><br><span class="line">						  	<span class="bullet">-</span> <span class="string">&quot;true&quot;</span>            </span><br></pre></td></tr></table></figure>

<blockquote>
<p>requiredDuringSchedulingIgnoreDuringExecution 表示本规则只适用于新创建的 pod， 不影响已经在运行中的 pod；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200831091150.png"></p>
<h4 id="调度-pod-时优先考虑某些节点"><a href="#调度-pod-时优先考虑某些节点" class="headerlink" title="调度 pod 时优先考虑某些节点"></a>调度 pod 时优先考虑某些节点</h4><p>前面提到亲缘性的规则要生效，节点本身必须被提前打上标签；有趣的是，还可以在这些标签中指定节点是独占的还是共享的；不同的标签还可以设置权重系数，用来计算优先级；</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">	<span class="attr">name:</span> <span class="string">pref</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">	<span class="attr">template:</span></span><br><span class="line">		<span class="string">...</span></span><br><span class="line">		<span class="attr">spec:</span></span><br><span class="line">			<span class="attr">affinity:</span></span><br><span class="line">            	<span class="attr">nodeAffinity:</span></span><br><span class="line">            		<span class="comment"># 此处使用了 preferred，而不是 required，表示是非强制性的，只是优先考虑</span></span><br><span class="line">            		<span class="attr">preferredDuringSchedulingIgnoreDuringExecution:</span></span><br><span class="line">            			<span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">80</span></span><br><span class="line">            			  <span class="attr">preference:</span></span><br><span class="line">            			  	<span class="attr">matchExpressions:</span></span><br><span class="line">            			  		<span class="bullet">-</span> <span class="attr">key:</span> <span class="string">availability-zone</span></span><br><span class="line">            			  		  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            			  		  <span class="attr">values:</span></span><br><span class="line">            			  		  	<span class="bullet">-</span> <span class="string">zone1</span></span><br><span class="line">            			<span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">20</span></span><br><span class="line">            			  <span class="attr">preference:</span></span><br><span class="line">            			  	<span class="attr">matchExpressions:</span></span><br><span class="line">            			  		<span class="bullet">-</span> <span class="attr">key:</span> <span class="string">share-type</span></span><br><span class="line">            			  		  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            			  		  <span class="attr">values:</span></span><br><span class="line">            			  		  	<span class="bullet">-</span> <span class="string">dedicated</span></span><br></pre></td></tr></table></figure>



<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200831091752.png"></p>
<h3 id="使用-pod-亲缘性与非亲缘性对-pod-进行协同部署"><a href="#使用-pod-亲缘性与非亲缘性对-pod-进行协同部署" class="headerlink" title="使用 pod 亲缘性与非亲缘性对 pod 进行协同部署"></a>使用 pod 亲缘性与非亲缘性对 pod 进行协同部署</h3><p>亲缘性的规则除了可以用来指定 pod 应该部署到哪些节点上，还可以用来设置哪些 pod 应该尽量被部署在相近的位置，就像亲人住在一起一样；</p>
<blockquote>
<p>前者通过 nodeAffinity 字段来实现，后者通过 podAffinity 字段来实现；</p>
</blockquote>
<h4 id="使用-pod-间亲缘性将多个-pod-部署在同一个节点上"><a href="#使用-pod-间亲缘性将多个-pod-部署在同一个节点上" class="headerlink" title="使用 pod 间亲缘性将多个 pod 部署在同一个节点上"></a>使用 pod 间亲缘性将多个 pod 部署在同一个节点上</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200901081330.png"></p>
<blockquote>
<p>此处使用了 labelSelector.matchLabels 字段来设置标签选择器，另外还可以使用表达能力更强的 matchExpressions 字段；</p>
</blockquote>
<p>假设 A pod 要追随 B pod 的部署位置，那么只需在 A pod 上面定义亲缘性规则即可，并不需要在 B pod 上面定义；但是，当 B pod 因为某些原因被删除而重新创建时，调度器仍然会根据 A pod 的规则，将 B pod 部署在 A pod 所处的节点上（这样做才能维护 A pod 亲缘性规则的一致性，不然如果 B pod 部署到节点上，规则就被违反了）</p>
<blockquote>
<p>实现原理：当存在多个可用节点时，调度器本质上是通过给不同节点的优先级打分以选择最合适的节点；</p>
</blockquote>
<h4 id="将-pod-部署在同一机柜、可用性区域或者地理地域"><a href="#将-pod-部署在同一机柜、可用性区域或者地理地域" class="headerlink" title="将 pod 部署在同一机柜、可用性区域或者地理地域"></a>将 pod 部署在同一机柜、可用性区域或者地理地域</h4><p>将所有的亲缘 pod 都部署在同一节点并不一定是最好的选择，因为当节点发生故障时，会导致服务不可用；从健壮性的角度，部署在相同地理区域的不同节点上，也是一种好的方案；此点可以通过 topologyKey 字段来实现；它可以有多种值，表示不同的规则</p>
<ul>
<li>failure-domain.beta.kubernetes.io&#x2F;zone 指定将 pod 部署在相同的可用区中；</li>
<li>failure-domain.beta.kubernetes.io&#x2F;region 指定将 pod 部署在相同的地理区域中；</li>
</ul>
<blockquote>
<p> topologyKey 字段有好几个值，看上去好像很复杂很神奇的样子，但其实它的实现原理特别简单，就是在节点上添加标签键值对，然后在 pod 定义中的 topologyKey 添加相应的键名，这样调度器会优先选择匹配的节点来部署相应的 pod，其作用很像是标签选择器；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200901082955.png"></p>
<h4 id="表达-pod-亲缘性优先级取代强制性要求"><a href="#表达-pod-亲缘性优先级取代强制性要求" class="headerlink" title="表达 pod 亲缘性优先级取代强制性要求"></a>表达 pod 亲缘性优先级取代强制性要求</h4><p>使用 required 类型的亲缘性规则意味着调度是强制性的，但如果不需要强制，只是优先考虑，则可以使用 prefered 开头的规则，并为之写上权重系数即可；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200902081721.png"></p>
<h4 id="利用-pod-的非亲缘性分开调度-pod"><a href="#利用-pod-的非亲缘性分开调度-pod" class="headerlink" title="利用 pod 的非亲缘性分开调度 pod"></a>利用 pod 的非亲缘性分开调度 pod</h4><p>有时候我们想将一些 pod 部署在一起，有时候则相反，想让某些 pod 具有互斥性，即不要安排在一起，这时可以使用非亲缘性（感觉用互斥性更直观）规则来实现这个效果，即 nodeAntiAffinity 或者 podAntiAffinity 字段；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200902082013.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200902082202.png"></p>
<blockquote>
<p>使用强制的互斥性规则来部署 pod 时，如果节点的数量不够，将使用一部分 pod 处于 pending 状态，无法调度成功；如果对互斥程度要求没有那么高，则可以考虑使用 prefered 规则来实现；</p>
</blockquote>
<h2 id="17-开发应用的最佳实践"><a href="#17-开发应用的最佳实践" class="headerlink" title="17. 开发应用的最佳实践"></a>17. 开发应用的最佳实践</h2><h3 id="集中一切资源"><a href="#集中一切资源" class="headerlink" title="集中一切资源"></a>集中一切资源</h3><p>在 Kubernetes 中，所有的一切都是资源，但是它们有些是由开发人员创建并维护的，有些则是由集群人员创建和维护；二者有所分工，互不耦合；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165409.png"></p>
<p>Pod 通常会用到两种类型的 secret 数据，一种是用来拉取镜像用的，一种是在 Pod 中运行的进程所用的；secret 一般并不作为声明文件的组成部分，而应该是由运维人员进行配置，并分配给 serviceAccount，然后 serviceAccount 再分配给各个 pod；</p>
<p>初始化环境变量一般使用 configMap 卷；这样对于开发人员来说，引用的卷是固定的，但是卷的内容是可以根据环境变化的；</p>
<p>集群管理员会创建一些 LimitRange 或 ResourceQuota 对象，由开发人员在声明文件中引用；这些对象可以控制 pod 可以使用的硬件资源；</p>
<h3 id="了解-pod-的生命周期"><a href="#了解-pod-的生命周期" class="headerlink" title="了解 pod 的生命周期"></a>了解 pod 的生命周期</h3><p>将应用交给 Kubernetes 来运行的注意事项：</p>
<ul>
<li>Pod 中的应用随时可能被杀死，并由新 Pod 来替代；</li>
<li>写入磁盘的数据可能会消失；</li>
<li>使用存储卷来跨容器持久化数据；</li>
<li>如果 Pod 是正常的，但 Pod 内的容器持续崩溃，Pod 并不会被销毁重建；</li>
<li>Pod 的启动是没有顺序的；</li>
<li>可以在 Pod 中创建 init 容器来控制主容器的启动顺序；</li>
<li>Pod 中的容器支持启动前 post-start 和启动后 pre-stop 的钩子；</li>
</ul>
<blockquote>
<p>问：貌似可以通过启动后钩子来控制容器的启动顺序？</p>
<p>答：后来发现更好的做法是让容器自己能够应对无顺序的情况，即在其他容器没有就绪前不会出错，而是会进行一定时间的等待；</p>
</blockquote>
<h4 id="以固定的顺序启动-pod"><a href="#以固定的顺序启动-pod" class="headerlink" title="以固定的顺序启动 pod"></a>以固定的顺序启动 pod</h4><p>通过在  pod 中创建 init 类型的容器，在它里面写一段脚本来监测其他容器或服务是否已经就绪，如果就绪，就开始启动主容器；init 容器写在声明文件的 spec 属性下面，如下图所示；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165429.png"></p>
<p>虽然有机制来控制应用的启动顺序，但更好的实践作法是放应用本身可以应对其所依赖的服务未准备好时的情况；例如对于应用所连接的数据库服务，当连接不上时，就先暂停，然后每隔一段时间后进行重试；</p>
<blockquote>
<p>问：应用有可能在中途出现断开依赖服务的情况，不知此时是否可以通过 readiness 探针来告知 Kubernetes 当前应用进入了未准备好的状态？如果 readiness 探针是一次性的话，那或许这个工作可以交给 liveness 探针来完成；</p>
<p>答：后果发现 readiness 的探针不是一次性的，它会在容器运行过程中仍然保持工作；</p>
</blockquote>
<h4 id="增加生命周期钩子"><a href="#增加生命周期钩子" class="headerlink" title="增加生命周期钩子"></a>增加生命周期钩子</h4><p>启动后钩子执行成功，容器才会启动，不然会呈现等待的状态，但它和容器中的主进程是同时开始执行的；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165441.png"></p>
<blockquote>
<p>钩子的输出信息如果是输出到标准输出的，将会导致查看不到，这样会不方便高度，因此，如果可以的话，最好还是输出信息到日志文件中更好；</p>
</blockquote>
<p>停止前钩子没有成功也不影响容器被终止；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165454.png"></p>
<h4 id="了解-pod-的关闭"><a href="#了解-pod-的关闭" class="headerlink" title="了解 pod  的关闭"></a>了解 pod  的关闭</h4><p>kubelet 关闭 pod 时涉及如下顺序的动作：</p>
<ul>
<li>执行容器停止前钩子（如有）；</li>
<li>向容器的主进程发送 SIGTERM 信号（因为容器本质上只是操作系统中的一个进程，所以关闭容器跟关闭进程本质上是一样的）；</li>
<li>给容器一定的时间（宽限期），让其优雅的关闭；</li>
<li>如果容器动作超时，则使用 SIGKILL 信号进行强制关闭；</li>
</ul>
<blockquote>
<p>终止宽限期的时间是可以配置的，默认是 30 秒；</p>
</blockquote>
<p>由于 kubelet 是将关闭信号发给容器，而不是发给容器中的应用，因此应用有可能并没有收到这个信号；此时应用可以通过停止前钩子来让自己得到通知；</p>
<blockquote>
<p>此处存在一个悖论，即 pod 是运行在节点上的，因此不管在 pod 中设计了何种优雅的关闭机制，它都无法保证和控制它所在的节点突然出现的崩溃；此时会导致它的任何优雅关闭流程被强行终止；针对这个悖论的解决办法是另辟蹊径，即通过长期或定期运行一个 job，检查有没有出现一些孤立的资源（说明其所有节点可能已经崩溃了），如果有的话，就把它们安置到妥善的地方去；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165508.png"></p>
<h3 id="确保所有的客户端请求都得到了妥善处理"><a href="#确保所有的客户端请求都得到了妥善处理" class="headerlink" title="确保所有的客户端请求都得到了妥善处理"></a>确保所有的客户端请求都得到了妥善处理</h3><h4 id="在-pod-启动时避免客户端连接断开"><a href="#在-pod-启动时避免客户端连接断开" class="headerlink" title="在 pod 启动时避免客户端连接断开"></a>在 pod 启动时避免客户端连接断开</h4><p>解决方案：在 pod 声明文件中添加一个就绪指针，探测 pod 就绪成功后，再对外提供服务；</p>
<h4 id="在-pod-关闭时避免客户端连接断开"><a href="#在-pod-关闭时避免客户端连接断开" class="headerlink" title="在 pod 关闭时避免客户端连接断开"></a>在 pod 关闭时避免客户端连接断开</h4><p>API 服务器在收到停止并删除某个 pod 的请求后，会同时做两件事情，一件是通知 endpoint 管理器更新转发规则，一件是通知 kubelet 删除 pod；前一个动作需要较长的执行时间（因为需要多个 endpoint 的 iptables 转发规则），后一个动作所需要的执行时间比较短，因此，后者大概率会以更快的速度完成；这会产生一个问题，即 pod 已经停止工作了，但是可能仍有请求被转发了进来，导致这些请求无法被正确处理；</p>
<p>以上问题并没有百分百的解决办法，唯一的办法是延长 pod 关闭时的等待时间，多几秒钟即可，例如 5-10 秒；这可以通过添加一个停止前的钩子，让容器睡眠一段时间来解决；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165520.png"></p>
<h3 id="让应用在-Kubernetes-中方便运行和管理"><a href="#让应用在-Kubernetes-中方便运行和管理" class="headerlink" title="让应用在 Kubernetes 中方便运行和管理"></a>让应用在 Kubernetes 中方便运行和管理</h3><h4 id="构建可管理的容器镜像"><a href="#构建可管理的容器镜像" class="headerlink" title="构建可管理的容器镜像"></a>构建可管理的容器镜像</h4><p>冲突点：生产环境使用的镜像应该尽可能的小，这样可以缩短节点上镜像的下载时间，让 pod 更快的进入准备就绪的状态；而开发环境使用的镜像应该大一些，尽量包括一些方便在开发过程中进行调试的工具，例如 ping、curl、dig 等；</p>
<h4 id="合理地给镜像打标签"><a href="#合理地给镜像打标签" class="headerlink" title="合理地给镜像打标签"></a>合理地给镜像打标签</h4><p>避免使用 latest 作为标签，因为无法通过这个标签知道当前 pod 运行的是那个版本的镜像，表面上它们的标签都一样，但实际上有一些可能是使用新镜像，一些使用的是旧镜像；</p>
<h4 id="资源使用多维度而不是单维度的标签"><a href="#资源使用多维度而不是单维度的标签" class="headerlink" title="资源使用多维度而不是单维度的标签"></a>资源使用多维度而不是单维度的标签</h4><p>资源常见的标签维度：</p>
<ul>
<li>资源所属的应用名称；</li>
<li>应用层级，例如前端、后端等；</li>
<li>运行环境，例如开发、测试、生产等；</li>
<li>版本号；</li>
<li>发布类型，例如稳定版、beta 版等；</li>
<li>分片，如果存在分片的话；</li>
<li>租户，如果存在租户的话（貌似还可以使用命名空间）；</li>
</ul>
<h4 id="通过注解描述每个资源"><a href="#通过注解描述每个资源" class="headerlink" title="通过注解描述每个资源"></a>通过注解描述每个资源</h4><p>注解可以给资源增加一些额外的信息，方便其他人更好的管理；一般有两个常用的注解，一个是关于资源负责人信息，一个是关于资源的描述；</p>
<p>其他类型的注解：</p>
<ul>
<li>pod 所依赖的服务：用来展示 pod 之间的依赖关系；</li>
<li>构建和版本信息；</li>
<li>第三方工具或图形界面可能要用到的元信息；</li>
</ul>
<h4 id="给进程终止提供更多的信息"><a href="#给进程终止提供更多的信息" class="headerlink" title="给进程终止提供更多的信息"></a>给进程终止提供更多的信息</h4><p>当容器挂掉后，需要调查挂掉的原因；为了让这个事情更便利，Kubernetes 提供了一个终止专用的日志文件 &#x2F;etc&#x2F;termination-log；当进程发生失败时，可以将消息写入这个文件，这样在调查原因时，可以通过 describe 查看到这个日志文件里面的内容；</p>
<blockquote>
<p>我们并不知道容器中的应用何时会因意外终止退出，因此貌似可以通过捕捉错误，并将错误写入集中式的日志，以便后续进行错误的定位和排查；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165544.png"></p>
<h4 id="处理应用日志"><a href="#处理应用日志" class="headerlink" title="处理应用日志"></a>处理应用日志</h4><p>在开发环境中，容器中的应用正常应将日志输出到标准输出，这样可以使用 logs 命令方便的进行查看；但如果是写到文件中，则需要使用 exec cat 命令进行查看；</p>
<p>在生产环境中，则使用一个集中式的日志管理器（不然崩溃的 pod 被删除后，pod 上面的日志也会跟着消失），它一般会部署在某个 pod 上，统一接收所有的日志消息；一个常见的解决方案是使用 EFK 栈，它们是三个工具，一个负责收集（FluentID）、一个存储（ElasticSearch)、一个展示（Kibana)；</p>
<h3 id="开发和测试的最佳实践"><a href="#开发和测试的最佳实践" class="headerlink" title="开发和测试的最佳实践"></a>开发和测试的最佳实践</h3><h4 id="开发过程中在-Kubernetes-之外运行应用"><a href="#开发过程中在-Kubernetes-之外运行应用" class="headerlink" title="开发过程中在 Kubernetes 之外运行应用"></a>开发过程中在 Kubernetes 之外运行应用</h4><p>Kubernetes 要求将应用打包成镜像之后才能执行它，但这样显然不利于提高开发效率；如果应用的运行需要用到 Kubernetes 的某些功能，则可以模拟出来；API 服务器对于集群内和集群外的请求都是透明的，对它们一视同仁；</p>
<blockquote>
<p>貌似唯一需要模拟的是 configMap 和 secret，其他的部分好像跟运行 docker-compose 没有特别大的差别；</p>
</blockquote>
<h4 id="在开发过程中使用-Minikube"><a href="#在开发过程中使用-Minikube" class="headerlink" title="在开发过程中使用 Minikube"></a>在开发过程中使用 Minikube</h4><p>可以使用 Minikube 来模拟集群，同时通过 minikube mount 的功能，将本地文件夹挂载到 minikube 虚拟机中，然后再通过 hostPath 载挂载到容器中，这样就可以让本地文件的更改，实时的传递到容器中了；</p>
<p>在 shell 中设置 DOCKER_HOST 变量，让 dockers daemon 指向 minikube 虚拟机中的 docker daemon 后，则可以通过本地的 docker 命令来实现对虚拟内的 docker操作</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165559.png"></p>
<p>将本地的镜像推送到 minikube 虚拟机中</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165608.png"></p>
<h4 id="发布版本和自动部署资源清单"><a href="#发布版本和自动部署资源清单" class="headerlink" title="发布版本和自动部署资源清单"></a>发布版本和自动部署资源清单</h4><p>声明文件可以使用版本系统进行单独管理，每次提交更改后，就可以使用 apply 命令来更新当前的资源了；</p>
<p>甚至连手工的 apply 动作也可以进行自动后，可以采用第三方工具例如 kube-applier，它的作用有点像 github 的 webhook，当检测到有新提交的声明文件版本后，就会自动更新资源；</p>
<h4 id="使用-Ksonnet-作为编写-YAML-JSON-声明文件的额外选择"><a href="#使用-Ksonnet-作为编写-YAML-JSON-声明文件的额外选择" class="headerlink" title="使用 Ksonnet 作为编写 YAML&#x2F;JSON 声明文件的额外选择"></a>使用 Ksonnet 作为编写 YAML&#x2F;JSON 声明文件的额外选择</h4><p>Ksonnet 可以将声明文件模块化（使用 JSON 格式），然后通过组合共用的模块来减少编写重复的代码；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165621.png"></p>
<p>编写完成后，调用命令行进行转换</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816165638.png"></p>
<h4 id="利用持续集成和持续交付"><a href="#利用持续集成和持续交付" class="headerlink" title="利用持续集成和持续交付"></a>利用持续集成和持续交付</h4><p>可以参考 Fabric8 项目 <a target="_blank" rel="noopener" href="http://fabric8.io/">http://fabric8.io</a></p>
<h2 id="18-Kubernetes-应用扩展"><a href="#18-Kubernetes-应用扩展" class="headerlink" title="18. Kubernetes 应用扩展"></a>18. Kubernetes 应用扩展</h2><h3 id="定义自定义对象"><a href="#定义自定义对象" class="headerlink" title="定义自定义对象"></a>定义自定义对象</h3><p>自定义对象可以让集群的使用者站在更宏观的角度来使用集群，由更抽象的高级对象来实现业务需求，而不再直接与 Deployment、Secret、Service、Pod 等基础对象打交道；整个集群的管理和使用变得更加傻瓜化了；</p>
<h4 id="CustomResourceDefinitions-介绍"><a href="#CustomResourceDefinitions-介绍" class="headerlink" title="CustomResourceDefinitions 介绍"></a>CustomResourceDefinitions 介绍</h4><p>简称 CRD，自定义资源应该至少由两部分构成，一个是该自定义资源对象的定义，另一个是资源的管理组件，这样当用户创建某个资源实例时，集群才能够调用该资源的管理组件，去做余下的工作（创建各种基础资源对象）；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903081242.png"></p>
<p>定义好了后，就可以通过声明文件或者命令创建该种类型的资源了；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903081417.png"></p>
<p>截止到这里，由于还没有创建控制器，因此实际上这些对象暂时还起不到任何实际的业务作用；</p>
<h4 id="使用自定义控制器自动定制资源"><a href="#使用自定义控制器自动定制资源" class="headerlink" title="使用自定义控制器自动定制资源"></a>使用自定义控制器自动定制资源</h4><p>控制器应该至少做两个动作，一个是监控 API 服务器发出的事件通知，另一个是向 API 服务器提交请求，创建相应的资源；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903081728.png"></p>
<p>当控制器启动后，它实际上并不是直接向 API 服务器发请求，而是通过当前 pod 中的 sidecar 容器 kubectl-proxy 来发送请求的，sidecar 充当了一个代理的作用；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903083005.png"></p>
<blockquote>
<p> 控制器的本质其实很简单，它其实就是持续监听相关资源的事件，然后将原来手工操作的动作，转换成代码来实现；这些动作包括创建资源、删除资源、更新资源、查看资源等；</p>
</blockquote>
<p>由于控制器本质上就是一个帮忙自动化干活的 pod，因此在部署到生产环境时，一般可以将它部署为 Deployment 资源，这样如果出现故障，可以自动恢复；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903083615.png"></p>
<blockquote>
<p>当实现了控制器的这些自动化的操作后，意味着可以将它们封装起来，对外隐藏复杂性，对于最终用户来说，他只要提供一个源代码的仓库链接，就可以快速的将网站部署起来，完全不需要了解关于 kubernetes 的任何知识；这样就可以构建 PaaS 服务了；</p>
</blockquote>
<h4 id="验证自定义对象"><a href="#验证自定义对象" class="headerlink" title="验证自定义对象"></a>验证自定义对象</h4><p>如果让用户直接提交 YAML 文件来创建自定义的资源对象，会存在一个问题，即用户可能会提交无效的字段；因此集群在收到用户的资源创建请求时，有必要对其进行验证，确保 YAML 合法有效时，才进行创建；由于此时创建事件还没有发生，因此控制器无法完成验证的工作；因此需要由 API 服务器来完成（通过启用 CustomResourceValidation 特性来实现，在 1.8 以上版本中才有）</p>
<h4 id="为自定义对象提供自定义-API-服务器"><a href="#为自定义对象提供自定义-API-服务器" class="headerlink" title="为自定义对象提供自定义 API 服务器"></a>为自定义对象提供自定义 API 服务器</h4><p>除了使用 CustomResourceValidation 来验证请求的合法性外，还有另外一种更激进的办法，即自定义一个 API 服务器；当有了这个自定义的 API 服务器后，甚至连原本的 CRD 对象都不需要了，可以直接写到自定义的 API 服务器中；此时多个 API 服务器形成了一种聚合，对客户端来说是无感知的，客户端的请求将被分发到不同的 API 服务器进行处理；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200903085130.png"></p>
<blockquote>
<p>原来以为多 API 服务器的实现将是一个很复杂的功能，后果发现原来 Kubernetes 有内置了一个 APIService 的资源（本质上就是将该某些自定义资源对象的请求转发到提供该  APIService 的 pod，并不复杂，转发规则为 API 组名+版本号），只要创建该类型的资源，就可以实现多个 API 服务器；主 API 服务器会根据请求的属性，将其转发到这些多出来的 API，由它们做进一步的处理（但是仍然不可避免需要提供此 APIService 的 pod 写上一段自动化的代码，即将原来 CRD 控制器的代码移到这里来了）；</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200904084249.png"></p>
<blockquote>
<p>除了可以自定义 API 服务器，还可以实现自定义 CLI 客户端，实现 Kubectl 不方便完成的更多自定义功能；</p>
</blockquote>
<h3 id="使用-Kubernetes-服务目录扩展-Kubernetes"><a href="#使用-Kubernetes-服务目录扩展-Kubernetes" class="headerlink" title="使用 Kubernetes 服务目录扩展 Kubernetes"></a>使用 Kubernetes 服务目录扩展 Kubernetes</h3><p>服务目录是指列出所有可用服务的目录，然后用户根据需要选择对应的服务即可，而不需要自己去创建各种基础资源（如 Deployment、Service 等），简化用户对 Kubernetes 的使用门槛；</p>
<h4 id="服务目录介绍"><a href="#服务目录介绍" class="headerlink" title="服务目录介绍"></a>服务目录介绍</h4><p>服务目录听上去很像是另外一种资源的抽象和封装，用户可以调用查看当前可用的服务目录，然后选择并创建某个服务；之后该服务会自动去创建各种基础资源，如 Deployment、Pod 等；</p>
<blockquote>
<p>后来发现，它最大的作用并止于此，而是 Kuberbetes 可以跟集群进行协作；即有些云服务供应商，或者是内部的不同部门的团队，它们可以创建自己的 Kubernetes 集群，然后对外提供一些特定服务；其他集群的用户只要通过服务目录这个功能，来调用它们提供的服务即可，而无须在自己的集群上创建资源；</p>
</blockquote>
<p>服务目录有四种内置的资源类型，分别为：</p>
<ul>
<li>ClusterServiceBroker</li>
<li>ClusterServiceClass</li>
<li>ServiceInstance</li>
<li>ServiceBinding</li>
</ul>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200908082441.png"></p>
<p>运作流程</p>
<ul>
<li>集群管理员为服务代理创建一个 ClusterServiceBroker 资源，对应一个外部的服务代理商；</li>
<li>集群通过该 Broker 资源，从服务代理商处获得它可以提供的服务列表，并为每种服务创建一个 ClusterServiceClass 资源；</li>
<li>当集群内的用户想要使用某种服务时，只须创建一个 ServiceInstance 实例，并创建一个 ServiceBinding 绑定该 instance；之后集群内的 pod 就可以访问该外部服务了；</li>
</ul>
<h4 id="服务目录-API-服务器与控制器管理器介绍"><a href="#服务目录-API-服务器与控制器管理器介绍" class="headerlink" title="服务目录 API 服务器与控制器管理器介绍"></a>服务目录 API 服务器与控制器管理器介绍</h4><p>服务目录跟集群一样，也有自己的 API 服务器、控制器管理器、etcd 数据库等三大件；通过这些组件，可以为外部其他集群的用户提供一些抽象后的高层级服务功能；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200908081946.png"></p>
<blockquote>
<p>以上示意图是站在服务目录提供商集群的视角，实际的用户处于 External  system；</p>
</blockquote>
<h4 id="Service-Broker-和-OpenServiceBroker-API"><a href="#Service-Broker-和-OpenServiceBroker-API" class="headerlink" title="Service Broker 和 OpenServiceBroker API"></a>Service Broker 和 OpenServiceBroker API</h4><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200908085621.png"></p>
<blockquote>
<p>当创建好 ClusterServiceBroker 后，集群就会根据资源中的 URL，去代理处请求得到相应的服务列表，之后自动创建相应的 SerivceClass 与之对应；</p>
</blockquote>
<h4 id="提供服务与使用服务"><a href="#提供服务与使用服务" class="headerlink" title="提供服务与使用服务"></a>提供服务与使用服务</h4><p>当需要使用某个外部服务时，只须创建相应的 ServiceInstance 实例，并创建 ServiceBinding 与该实例进行绑定即可；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200908085921.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200908085950.png"></p>
<h4 id="解除绑定与取消配置"><a href="#解除绑定与取消配置" class="headerlink" title="解除绑定与取消配置"></a>解除绑定与取消配置</h4><p>当不再需要服务时，通过删除服务实例和服务绑定即可取消；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete servicebinding &lt;my-postgres-db-binding-name&gt;</span><br><span class="line">kubectl delete serviceinstance &lt;my-postgres-db-name&gt;</span><br></pre></td></tr></table></figure>

<h3 id="基于-Kubernetes-搭建的平台"><a href="#基于-Kubernetes-搭建的平台" class="headerlink" title="基于 Kubernetes 搭建的平台"></a>基于 Kubernetes 搭建的平台</h3><p>由于 Kubernetes 方便拓展的特征，很多原本也研发 PaaS 平台的公司，也重新改写它们的产品，变成基于 Kubernetes 进行拓展；</p>
<h4 id="红帽-OpenShift-容器平台"><a href="#红帽-OpenShift-容器平台" class="headerlink" title="红帽 OpenShift 容器平台"></a>红帽 OpenShift 容器平台</h4><p>Kubernetes 中的很多资源还是非常底层的，OpenShift 对它们进行了封装，提供了更多的抽象资源，并提供参数化的模板，让开发者的工作变得更加简单起来，完全无须了解 Kubernetes 的知识，也能够轻松使用完成部署和维护的工作；</p>
<h4 id="Deis-Workfiow-与-Helm"><a href="#Deis-Workfiow-与-Helm" class="headerlink" title="Deis Workfiow 与 Helm"></a>Deis Workfiow 与 Helm</h4><p>另外一个有名的 PaaS 产品是 Deis 的 Workfiow（已被微软收购），该团队还开发了一个 Helm 工具，用来简化部署的过程；目前 Helm 已成为社区中的部署标准工具；</p>
<blockquote>
<p> 仅有镜像是不足以创建应用的，还需要配合声明文件；但对于很多常见的应用来说，例如数据库应用，编写这它们的声明文件就变成了一件重复造轮子的工作，为了避免这个问题，发明了 Helm 这个工具，它将应用和声明文件绑在一起，称为包，然后再结合用户的自定义配置文件，即可以形成应用的发行版本；就像很多人会共享镜像文件一样，也有很多人会共享做好的 Helm 包，当我们需要用到某个通包的软件时，应该先找一下有没有将其做成了 Helm 包，如果有的话，直接拿过来用就可以了；</p>
<p> 示例如下：</p>
</blockquote>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200816173143.png"></p>
<blockquote>
<p>OpenShift 本质上是一个基于 Kubernetes 开发的平台，它有自己优化后的 API 服务器和管理组件，因此，它并不能与用户的现在集群进行整合；而 Deis Workfiow 则可以部署到任何现有的 Kubernetes 集群中，因此 Workfiow 看起来更像是 Kubernetes 的一个插件，让集群的使用更加方便简单；</p>
</blockquote>
<p>Helm 是 Kubernetes 的一个包管理器，类似于 Ubuntu 里面的 apt，或者 CentOS 里面的 yum；它由两部分组成，一部分是客户端，用于接收和发送用户指令；另一部分则运行在 Kubernetes 集群中（以 pod 的形式存在，通过在集群中安装 Tiller 组件来实现），用来接收客户端发出的指令，并在集群中执行相应的动作；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20200909075759.png"></p>
<blockquote>
<p>Helm 仓库地址：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/charts">https://github.com/kubernetes/charts</a></p>
</blockquote>
<p>使用 Helm 的流程：</p>
<ul>
<li>在仓库中找到合适的图表，git clone 到本地</li>
<li>通过本地的 Helm 客户端，发送图表到集群中；</li>
<li>搞掂！</li>
</ul>
<h2 id="19-经验积累"><a href="#19-经验积累" class="headerlink" title="19. 经验积累"></a>19. 经验积累</h2><h3 id="K8s-的本质"><a href="#K8s-的本质" class="headerlink" title="K8s 的本质"></a>K8s 的本质</h3><p>感觉 Kubernetes 的本质就像一个部署的管理器，它可以将 YAML 所描述的抽象的资源，部署到集群中的机器上面去；这些抽象的资源包括应用、服务、任务、存储、管理器等；所有这些抽象的资源，都需要将它们镜像化和容器化；从而便资源的部署工作简化成创建和运行容器而已；</p>
<h3 id="GKE-工作方式"><a href="#GKE-工作方式" class="headerlink" title="GKE 工作方式"></a>GKE 工作方式</h3><p>对于 GKE，它自带一个客户端 gcloud 可用来实现集群层面的操作，包括创建、更新、删除集群等场景，增加和减少节点数量等；而集群内部的资源操作，则由 kubectl 处理；</p>
<h3 id="管理集群"><a href="#管理集群" class="headerlink" title="管理集群"></a>管理集群</h3><ul>
<li>创建一个 config 文件；</li>
</ul>
<h3 id="访问-pod-的几种方法"><a href="#访问-pod-的几种方法" class="headerlink" title="访问 pod 的几种方法"></a>访问 pod 的几种方法</h3><ul>
<li><p>在集群中创建一个 pod，在里面使用 curl 或者端口转发；</p>
</li>
<li><p>通过 API 服务器作为代理</p>
</li>
<li><p>运行命令： kubectl proxy，之后就可以通过代理 URL 来访问 pod 了；</p>
</li>
<li><p>直接访问的 URL：<apiServerHost>:<port>&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;kubia-0&#x2F;proxy&#x2F;<path><br>通过代理访问的 URL： localhost:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;kubia-0&#x2F;proxy&#x2F;<path></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/08/12/Kubernetes%20%E5%AE%9E%E6%88%98/" data-id="cm1c2djau0003wchpccic2vdj" data-title="Kubernetes 实战" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-微信小程序进度环" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/01/20/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%BF%9B%E5%BA%A6%E7%8E%AF/" class="article-date">
  <time class="dt-published" datetime="2020-01-20T01:06:40.000Z" itemprop="datePublished">2020-01-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/01/20/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%BF%9B%E5%BA%A6%E7%8E%AF/">微信小程序进度环</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>wx.createCanvasContext 的工作原理很像 JQuery 里面的选择器，通过 canvas-id 来选择 HTML 文件中相应的 canvas，然后对其进行相关操作实现绘图；</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211121838.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211122794.png" alt="扫码预览"></p>
<p>demo 代码 github 链接：<a target="_blank" rel="noopener" href="https://github.com/ccw1078/wx_progress_ring">https://github.com/ccw1078/wx_progress_ring</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/01/20/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%BF%9B%E5%BA%A6%E7%8E%AF/" data-id="cm1bl1uzu003g0khpdlm05ivb" data-title="微信小程序进度环" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/javascript/" rel="tag">javascript</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E4%BF%A1/" rel="tag">微信</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CentOS Nginx 安装 Dokuwiki 支持 Https 访问" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/10/20/CentOS%20Nginx%20%E5%AE%89%E8%A3%85%20Dokuwiki%20%E6%94%AF%E6%8C%81%20Https%20%E8%AE%BF%E9%97%AE/" class="article-date">
  <time class="dt-published" datetime="2019-10-20T04:02:39.000Z" itemprop="datePublished">2019-10-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/10/20/CentOS%20Nginx%20%E5%AE%89%E8%A3%85%20Dokuwiki%20%E6%94%AF%E6%8C%81%20Https%20%E8%AE%BF%E9%97%AE/">CentOS/Nginx 安装 Dokuwiki 支持 Https 访问</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="更新工具包"><a href="#更新工具包" class="headerlink" title="更新工具包"></a>更新工具包</h3><blockquote>
<p>注：此更新步骤仅为建议，非必须</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum -y update</span><br><span class="line"><span class="built_in">sudo</span> yum -y install vim bash-completion wget tar</span><br></pre></td></tr></table></figure>
<p>更新后重启系统</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> reboot</span><br></pre></td></tr></table></figure>
<h3 id="安装工具包"><a href="#安装工具包" class="headerlink" title="安装工具包"></a>安装工具包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install epel-release yum-utils</span><br><span class="line"><span class="built_in">sudo</span> yum install http://rpms.remirepo.net/enterprise/remi-release-7.rpm</span><br><span class="line"><span class="built_in">sudo</span> yum makecache fast</span><br><span class="line"><span class="built_in">sudo</span> yum-config-manager --<span class="built_in">disable</span> remi-php54</span><br><span class="line"><span class="built_in">sudo</span> yum-config-manager --<span class="built_in">enable</span> remi-php72</span><br></pre></td></tr></table></figure>
<h3 id="安装-php-和-Nginx"><a href="#安装-php-和-Nginx" class="headerlink" title="安装 php 和 Nginx"></a>安装 php 和 Nginx</h3><blockquote>
<p>注：若二者已安装，此步可跳过</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum -y install php-cli php-fpm php-mysql php-zip php-ldap </span><br><span class="line"><span class="built_in">sudo</span> yum -y install php-devel php-gd php-mcrypt php-mbstring </span><br><span class="line"><span class="built_in">sudo</span> yum -y install php-curl php-xml php-pear php-bcmath</span><br></pre></td></tr></table></figure>
<p>安装好了后，检查一下 php 版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php -v</span><br></pre></td></tr></table></figure>
<p>若正常，会显示如下信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PHP 7.2.10 (cli) (built: Sep 11 2018 11:22:20) ( NTS )</span><br><span class="line">Copyright (c) 1997-2018 The PHP Group</span><br><span class="line">Zend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：此处略去安装 Nginx 过程，如有需要，请参考其他教程</p>
</blockquote>
<h3 id="安装-Dokuwiki"><a href="#安装-Dokuwiki" class="headerlink" title="安装 Dokuwiki"></a>安装 Dokuwiki</h3><p>下载前，先到 <a target="_blank" rel="noopener" href="https://github.com/splitbrain/dokuwiki/releases">Github</a> 检查一下它的最新稳定版本，此处假设为”2018-04-22b”</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> RELEASE=<span class="string">&quot;2018-04-22b&quot;</span></span><br><span class="line">wget https://github.com/splitbrain/dokuwiki/archive/release_stable_<span class="variable">$&#123;RELEASE&#125;</span>.tar.gz</span><br></pre></td></tr></table></figure>
<p>解压下载的安装包，并转移到新建的文件夹 &#x2F;var&#x2F;www&#x2F;html&#x2F; 中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xvf release_stable_<span class="variable">$&#123;RELEASE&#125;</span>.tar.gz</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /var/www/html/ </span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> dokuwiki-release_stable_<span class="variable">$&#123;RELEASE&#125;</span>  /var/www/html/dokuwiki</span><br></pre></td></tr></table></figure>
<p>将文件夹 &#x2F;var&#x2F;www&#x2F;html&#x2F;dokuwiki 所有者权限修改为 nginx_user:nginx_group</p>
<blockquote>
<p>注1：更改文件夹的所有者权限，方便 Nginx 有权访问该文件夹中的内容；此处假设 Nginx 进程运行在 nginx_user:nginx_group 下面，如果不是，则相应修改<br>注2：查看 nginx 所属用户 username 的办法为 <code>ps aux | grep nginx</code><br>注3：查看某个用户 username 所属组的方法为 <code>groups username</code></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R nginx_user:nginx_group /var/www/html/dokuwiki</span><br></pre></td></tr></table></figure>
<h3 id="安装-SSL-证书"><a href="#安装-SSL-证书" class="headerlink" title="安装 SSL 证书"></a>安装 SSL 证书</h3><p>目的：支持使用 https 访问</p>
<h5 id="安装-certbot-auto-到本地的-usr-local-bin-下"><a href="#安装-certbot-auto-到本地的-usr-local-bin-下" class="headerlink" title="安装 certbot-auto 到本地的 &#x2F;usr&#x2F;local&#x2F;bin 下"></a>安装 certbot-auto 到本地的 &#x2F;usr&#x2F;local&#x2F;bin 下</h5><p>目的：方便从 Letsencrypt 机构申请免费证书并简化后续的证书到期更新工作</p>
<blockquote>
<p>注：若已安装过 certbot-auto 此步骤可略过</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> wget https://dl.eff.org/certbot-auto -P /usr/local/bin</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> a+x /usr/local/bin/certbot-auto</span><br></pre></td></tr></table></figure>
<h5 id="配置-pip-国内源"><a href="#配置-pip-国内源" class="headerlink" title="配置 pip 国内源"></a>配置 pip 国内源</h5><p>注：若之前已配置，请跳过此步骤；此步骤的目的是加速 CertBot 下载 python 模块的速度</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建 .pip 文件夹并进入</span></span><br><span class="line"><span class="built_in">mkdir</span> .pip &amp;&amp; <span class="built_in">cd</span> .pip</span><br><span class="line"><span class="comment"># 创建 pip.conf 文件</span></span><br><span class="line">vi pip.conf</span><br><span class="line"><span class="comment"># 在 pip.conf 文件中输入以下内容</span></span><br><span class="line">[global]</span><br><span class="line">index-url=http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br><span class="line"><span class="comment"># 保存退出</span></span><br></pre></td></tr></table></figure>

<h5 id="运行脚本，安装依赖"><a href="#运行脚本，安装依赖" class="headerlink" title="运行脚本，安装依赖"></a>运行脚本，安装依赖</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/certbot-auto --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>
<h5 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h5><p>目的：获取域名证书过程中， Let’s Encrypt 会对域名发起访问，以确认申请者对域名的所有权；故需要配置 nginx，以便能够对 Let’s Encrypt 的访问返回正确的响应；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹，用于  Let&#x27;s Encrypt 访问时返回响应内容</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/letsencrypt</span><br><span class="line"><span class="comment"># 打开 nginx 配置文件进行编辑，此处假设 nginx 的配置文件在以下路径：/usr/local/nginx/conf/nginx.conf，如不是，则相应修改路径</span></span><br><span class="line">vi /usr/local/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure>


<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 nginx 配置文件中，找到 http，添加一条监听 80 端口的新 server</span></span><br><span class="line">http &#123;</span><br><span class="line">    <span class="comment">//...(略)...</span></span><br><span class="line">    <span class="comment">// 添加如下内容，此处假设申请域名为 domain.example.com，请修改为实际申请的域名</span></span><br><span class="line">    server &#123;</span><br><span class="line">        listen <span class="number">80</span>;</span><br><span class="line">        server_name  domain.<span class="property">example</span>.<span class="property">com</span>;</span><br><span class="line">        location ~  <span class="regexp">/.well-known/</span>acme-challenge/ &#123;</span><br><span class="line">            defaulf_type <span class="string">&quot;text/plain&quot;</span>;</span><br><span class="line">            root  /home/letsencrypt/;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// ......以下略......</span></span><br></pre></td></tr></table></figure>
<h5 id="重启-nginx"><a href="#重启-nginx" class="headerlink" title="重启 nginx"></a>重启 nginx</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径</span></span><br><span class="line"><span class="comment"># 先使用 -t 参数测试配置文件格式是否正确</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -t</span><br><span class="line"><span class="comment"># 若正确，屏幕上将显示以下字样</span></span><br><span class="line">&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok</span><br><span class="line"><span class="comment"># 重启 Nginx</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>

<h5 id="运行脚本，申请证书"><a href="#运行脚本，申请证书" class="headerlink" title="运行脚本，申请证书"></a>运行脚本，申请证书</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处为域名 domain.example.com 申请一张证书，其中的 youremail.com 请替换为你自己的邮箱地址</span></span><br><span class="line">/usr/local/bin/certbot-auto certonly  --email youremail.com --webroot -w /home/letsencrypt -d domain.example.com</span><br></pre></td></tr></table></figure>
<p>申请成功后，界面下会有如下的成功提示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IMPORTANT NOTES:</span><br><span class="line">- Congratulations! Your certificate and chain have been saved at</span><br><span class="line">   /etc/letsencrypt/live/helloworld.com/fullchain.pem. Your cert</span><br><span class="line">   will expire on 2019-08-26. To obtain a new version of the</span><br><span class="line">   certificate <span class="keyword">in</span> the future, simply run Let<span class="string">&#x27;s Encrypt again......</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：记下以上提示信息中的 fullchain.pem 和 privkey.pem 两个文件路径，后续配置 nginx 会用到</p>
</blockquote>
<h3 id="配置-Nginx"><a href="#配置-Nginx" class="headerlink" title="配置 Nginx"></a>配置 Nginx</h3><p>打开 nginx 配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置文件的路径请根据实际情况修改</span></span><br><span class="line">vi /usr/local/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure>
<p>在nginx 配置文件中，新增两个 server 条目，内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    <span class="comment"># 注意替换此处的域名</span></span><br><span class="line">    server_name domain.example.com;</span><br><span class="line">    root /var/www/html/dokuwiki;</span><br><span class="line"></span><br><span class="line">    access_log /var/log/dokuwiki.access.log;</span><br><span class="line">    error_log /var/log/dokuwiki.error.log;</span><br><span class="line"></span><br><span class="line">    ssl on;</span><br><span class="line">    <span class="comment"># 注意替换此处的 fullchain.pem 和 privkey.pem 的路径为正确的实际路径</span></span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/domain.example.com/fullchain.pem;</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/domain.example.com/privkey.pem;</span><br><span class="line">    ssl_session_timeout 5m;</span><br><span class="line">    ssl_ciphers <span class="string">&#x27;AES128+EECDH:AES128+EDH:!aNULL&#x27;</span>;</span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">    index index.html index.php doku.php;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ @dokuwiki;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location @dokuwiki &#123;</span><br><span class="line">        rewrite ^/_media/(.*) /lib/exe/fetch.php?media=<span class="variable">$1</span> last;</span><br><span class="line">        rewrite ^/_detail/(.*) /lib/exe/detail.php?media=<span class="variable">$1</span> last;</span><br><span class="line">        rewrite ^/_export/([^/]+)/(.*) /doku.php?<span class="keyword">do</span>=export_<span class="variable">$1</span>&amp;<span class="built_in">id</span>=<span class="variable">$2</span> last;</span><br><span class="line">        rewrite ^/(.*) /doku.php?<span class="built_in">id</span>=<span class="variable">$1</span> last;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /(data|conf|bin|inc)/ &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~* \.(css|js|gif|jpe?g|png)$ &#123;</span><br><span class="line">        expires 1M;</span><br><span class="line">        add_header Pragma public;</span><br><span class="line">        add_header Cache-Control <span class="string">&quot;public, must-revalidate, proxy-revalidate&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        fastcgi_split_path_info ^(.+\.php)(/.+)$;</span><br><span class="line">        fastcgi_pass unix:/var/run/php-fpm/php-fpm.sock;</span><br><span class="line">        fastcgi_index index.php;</span><br><span class="line">        include fastcgi_params;</span><br><span class="line">        fastcgi_param SCRIPT_FILENAME $document_root<span class="variable">$fastcgi_script_name</span>;</span><br><span class="line">        fastcgi_intercept_errors off;</span><br><span class="line">        fastcgi_buffer_size 16k;</span><br><span class="line">        fastcgi_buffers 4 16k;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 若想支持 80 端口访问，则可以在原监听 80 端口的 server 条目中添加一些信息</span></span><br><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name  domain.example.com;</span><br><span class="line">        location ~  /.well-known/acme-challenge/ &#123;</span><br><span class="line">            defaulf_type <span class="string">&quot;text/plain&quot;</span>;</span><br><span class="line">            root  /home/letsencrypt/;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 以上是 location 原申请证书时已写好的信息，下面的新 location 是需要新添加的信息</span></span><br><span class="line">        location / &#123;</span><br><span class="line">            add_header Strict-Transport-Security max-age=2592000;</span><br><span class="line">            rewrite ^ https://$host<span class="variable">$request_uri</span>? permanent;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="配置-php-fpm"><a href="#配置-php-fpm" class="headerlink" title="配置 php-fpm"></a>配置 php-fpm</h3><p>打开以下 php-fpm 中的文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> vim /etc/php-fpm.d/www.conf</span><br></pre></td></tr></table></figure>
<p>将文件中以下几个键的值设置为如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意替换此处的 nginx_user 和 nginx_group 为实际的用户名和用户组</span></span><br><span class="line">user = nginx_user</span><br><span class="line">group = nginx_group</span><br><span class="line">listen = /var/run/php-fpm/php-fpm.sock</span><br><span class="line">listen.owner = nginx_user</span><br><span class="line">listen.group = nginx_group</span><br><span class="line">listen.mode = 0660</span><br></pre></td></tr></table></figure>
<p>启动 nginx 和 php-fpm</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start php-fpm</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> php-fpm</span><br></pre></td></tr></table></figure>
<p>重启 Nginx</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先使用 -t 参数测试配置文件格式是否正确</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -t</span><br><span class="line"><span class="comment"># 若正确，屏幕上将显示以下字样</span></span><br><span class="line">&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok</span><br><span class="line"><span class="comment"># 重启 Nginx</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>
<h3 id="配置-DokuWiki"><a href="#配置-DokuWiki" class="headerlink" title="配置 DokuWiki"></a>配置 DokuWiki</h3><p>使用浏览器打开网址：<a target="_blank" rel="noopener" href="https://domain.example.com/install.php%EF%BC%8C%E6%89%93%E5%BC%80%E5%90%8E%E9%A1%B5%E9%9D%A2%E5%A6%82%E4%B8%8B%EF%BC%8C%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95%E8%AF%B7%E5%8F%82%E8%80%83%E5%85%B6%E4%BB%96%E6%95%99%E7%A8%8B">https://domain.example.com/install.php，打开后页面如下，配置方法请参考其他教程</a></p>
<blockquote>
<p>注：domain.example.com 请相应替换为实际域名</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7490238-1fd596e7d3e73a2c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Letsenctrypt 的证书有效期为三个月，当剩余一个月时，Letsenctrypt 会发通知邮件到预留的邮箱；收到通知后，只需要登录服务器，运行相关命令，即可自动更新证书</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先使用 --dry-run 选项进行测试，非真正执行更新</span></span><br><span class="line">/usr/local/bin/certbot-auto renew --dry-run</span><br></pre></td></tr></table></figure>
<p>若显示如下字样，则表示自动更新功能测试成功</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Congratulations, all renewals succeeded. The following certs have been renewed:  </span><br><span class="line">   /etc/letsencrypt/live/www.helloworld.com/fullchain.pem (success)</span><br><span class="line">** DRY RUN: simulating <span class="string">&#x27;certbot renew&#x27;</span> close to cert expiry</span><br><span class="line">** (The <span class="built_in">test</span> certificates above have not been saved.)</span><br></pre></td></tr></table></figure>
<p>运行以下实际的更新命令，更新完了后，记得重启 nginx 服务器，以便启用新的证书</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/certbot-auto renew -v</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/10/20/CentOS%20Nginx%20%E5%AE%89%E8%A3%85%20Dokuwiki%20%E6%94%AF%E6%8C%81%20Https%20%E8%AE%BF%E9%97%AE/" data-id="cm1bl40wk003k0khpgsvv6gj9" data-title="CentOS/Nginx 安装 Dokuwiki 支持 Https 访问" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" rel="tag">服务器</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-gcc 链接器工作原理" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/09/28/gcc%20%E9%93%BE%E6%8E%A5%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/" class="article-date">
  <time class="dt-published" datetime="2019-09-28T14:22:33.000Z" itemprop="datePublished">2019-09-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/09/28/gcc%20%E9%93%BE%E6%8E%A5%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/">gcc 链接器工作原理</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>在编译源代码为可执行文件的时候，如果需要链接静态库，我们可能会遇到如下错误提示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">: In function &#x27;main&#x27; // 或者其他函数名</span><br><span class="line">(.text+0x7): undefined reference to &quot;foo&quot; // 或其他变量名</span><br></pre></td></tr></table></figure>
<p>编译出现了失败，提示找不到某些函数或变量的定义。但经过仔细检查核对，发现我们已经在编译命令中，提供了完整的库名称和库路径，因此找不到问题出在哪里</p>
<h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><p>出现这种问题的原因，很可能是在于静态库之间存在相互依赖，以及链接器的工作方式与我们预期不同造成的，在找出解决办法前，我们可以先了解一下编译器的工作流程</p>
<h2 id="编译及链接流程"><a href="#编译及链接流程" class="headerlink" title="编译及链接流程"></a>编译及链接流程</h2><p>假设我们的编译命令如下，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc f.c libx.a liby.a libz.a</span><br></pre></td></tr></table></figure>
<h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>编译器检查命令行中列出的文件，如果发现有 .c 文件，先将所有 .c 的文件翻译成 .o 文件，确保最后只剩下 .o 文件和 .a 文件</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>链接器出场，从左到右开始扫描，进行符号解析工作</p>
<h3 id="1-建立三个空的集合"><a href="#1-建立三个空的集合" class="headerlink" title="1. 建立三个空的集合"></a>1. 建立三个空的集合</h3><p>E 空文件集合：放入该集合中的文件，后续将用于合成最终的可执行文件；<br>U 空符号集合：用来存放在当前目标文件中引用，但没有定义的符号；<br>D 空符号集合：用来存放 E 集合的文件中那些已经定义的符号</p>
<blockquote>
<p>注：E\U\D，此处分别表示 Empty, Undefined, Defined</p>
</blockquote>
<h3 id="2-从左到右依次扫描每一个文件"><a href="#2-从左到右依次扫描每一个文件" class="headerlink" title="2. 从左到右依次扫描每一个文件"></a>2. 从左到右依次扫描每一个文件</h3><p>假设当前扫描到的第一个文件为 f</p>
<h4 id="如果-f-是一个-o-结尾的目标文件"><a href="#如果-f-是一个-o-结尾的目标文件" class="headerlink" title="如果 f 是一个 .o 结尾的目标文件"></a>如果 f 是一个 .o 结尾的目标文件</h4><p>将 f 放入 E 文件集合中<br>将 f 文件中定义的符号添加到 D 符号集合中<br>将 f 文件中引用却未定义的符号，添加到 U 符号集合中；</p>
<h4 id="如果-f-是一个-a-结尾的存档文件"><a href="#如果-f-是一个-a-结尾的存档文件" class="headerlink" title="如果 f 是一个 .a 结尾的存档文件"></a>如果 f 是一个 .a 结尾的存档文件</h4><blockquote>
<p>注：存档文件即静态库文件，它由一个或多个目标文件做为成员打包组成的，假设 f 中的第一个目标文件叫 m</p>
</blockquote>
<h5 id="第一步：匹配"><a href="#第一步：匹配" class="headerlink" title="第一步：匹配"></a>第一步：匹配</h5><p>检查 U 集合中未定义的符号是否在 m 的符号表中</p>
<h6 id="如果没有"><a href="#如果没有" class="headerlink" title="如果没有"></a>如果没有</h6><ul>
<li>抛弃 m，继续扫描 f 中的下一个成员文件；</li>
</ul>
<h6 id="如果有"><a href="#如果有" class="headerlink" title="如果有"></a>如果有</h6><ul>
<li>将 m 加入 E 集合中；</li>
<li>将 m 中定义的符号添加到 D 符号集合中</li>
<li>将 m 中引用却未定义的符号，添加到 U 符号集合中；</li>
</ul>
<h5 id="第二步：重复"><a href="#第二步：重复" class="headerlink" title="第二步：重复"></a>第二步：重复</h5><p>继续扫描 f 中的下一个成员文件，重复上一步的匹配过程，直到 U 和 D 都不再发生变化；</p>
<h5 id="第三步：筛选"><a href="#第三步：筛选" class="headerlink" title="第三步：筛选"></a>第三步：筛选</h5><p>将所有在 f 中但却不包含在 E 集合中的目标文件成员，抛弃；</p>
<h3 id="3-重复上一步，直到扫描完所有的输入文件"><a href="#3-重复上一步，直到扫描完所有的输入文件" class="headerlink" title="3. 重复上一步，直到扫描完所有的输入文件"></a>3. 重复上一步，直到扫描完所有的输入文件</h3><h3 id="4-检查-U-符号集合"><a href="#4-检查-U-符号集合" class="headerlink" title="4. 检查 U 符号集合"></a>4. 检查 U 符号集合</h3><p>如果 U 非空，则抛出错误，表示存在未定义的引用，并终止；<br>如果 U 为空，则合并和重定位 E 文件集合中的所有目标文件，生成最终的可执行文件，成功；</p>
<h1 id="问题解决思路"><a href="#问题解决思路" class="headerlink" title="问题解决思路"></a>问题解决思路</h1><p>在了解了编译器工作的流程后，我们会发现，当我们有多个静态库需要链接时，如果这些静态库之间存在依赖关系时，则对静态库的放置顺序是有要求的，即被依赖的库必须放置在依赖者的后面，否则链接器就会找不到未定义的符号；<br>例如 x.a 中引用了 y.a 中定义的函数，则 x.a 必须放置在 y.a 的前面，即正确的顺序应为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc main.c libx.a liby.a</span><br></pre></td></tr></table></figure>
<h2 id="库的顺序规则"><a href="#库的顺序规则" class="headerlink" title="库的顺序规则"></a>库的顺序规则</h2><ol>
<li>惯例：将所有库文件放在命令行的末尾，即在所有 .c 和 .o 文件的后面</li>
<li>如果所有库之间相互独立，那么天下太平，正常编译，回家睡觉</li>
<li>如果所有库之间存在引用，那么需要排列这些库的顺序</li>
</ol>
<ul>
<li>确保被引用的库排在引用者的后面</li>
<li>如果二者相互引用，则需要重复输入库名<br>例如：假设 foo 引用 x 库，x 库引用了 y 库，y 库又引用了 x 库，即<br>foo -&gt; x -&gt; y -&gt; x，那么编译命令的顺序如下，其中 x 库需要输入两次<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc foo.c libx.a liby.a libx.a</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/09/28/gcc%20%E9%93%BE%E6%8E%A5%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/" data-id="cm1bkzpyl00380khp8o34hq33" data-title="gcc 链接器工作原理" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/" rel="tag">C</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-使用 CertBot 自动更新 Let&#39;s Encrypt SSL 证书" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/05/26/%E4%BD%BF%E7%94%A8%20CertBot%20%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%20Let's%20Encrypt%20SSL%20%E8%AF%81%E4%B9%A6/" class="article-date">
  <time class="dt-published" datetime="2019-05-26T04:28:06.000Z" itemprop="datePublished">2019-05-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/05/26/%E4%BD%BF%E7%94%A8%20CertBot%20%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%20Let's%20Encrypt%20SSL%20%E8%AF%81%E4%B9%A6/">使用 CertBot 自动更新 Let&#39;s Encrypt SSL 证书</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="首次申请"><a href="#首次申请" class="headerlink" title="首次申请"></a>首次申请</h1><h3 id="下载安装-CertBot"><a href="#下载安装-CertBot" class="headerlink" title="下载安装 CertBot"></a>下载安装 CertBot</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 CertBot 脚本到当前目录，假设当前文件夹为 ~ 目录</span></span><br><span class="line">wget https://dl.eff.org/certbot-auto</span><br><span class="line"><span class="comment"># 为 CertBot 脚本增加执行权限，# a 为 all 简写，x 为 execute 简写，a+x 表示所有用户及群组的可执行权限</span></span><br><span class="line"><span class="built_in">chmod</span> a+x ./certbot-auto</span><br></pre></td></tr></table></figure>

<h3 id="配置-pip-国内源"><a href="#配置-pip-国内源" class="headerlink" title="配置 pip 国内源"></a>配置 pip 国内源</h3><p>注：若之前已配置，请跳过此步骤；此步骤的目的是加速 CertBot 下载 python 模块的速度</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建 .pip 文件夹并进入</span></span><br><span class="line"><span class="built_in">mkdir</span> .pip &amp;&amp; <span class="built_in">cd</span> .pip</span><br><span class="line"><span class="comment"># 创建 pip.conf 文件</span></span><br><span class="line">vi pip.conf</span><br><span class="line"><span class="comment"># 在 pip.conf 文件中输入以下内容</span></span><br><span class="line">[global]</span><br><span class="line">index-url=http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br><span class="line"><span class="comment"># 保存退出</span></span><br></pre></td></tr></table></figure>

<h3 id="运行脚本，安装依赖"><a href="#运行脚本，安装依赖" class="headerlink" title="运行脚本，安装依赖"></a>运行脚本，安装依赖</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./certbot-auto --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<h3 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h3><p>目的：获取域名证书过程中， Let’s Encrypt 会对域名发起访问，以确认申请者对域名的所有权；故需要配置 nginx，以便能够对 Let’s Encrypt 的访问返回正确的响应；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹，用于  Let&#x27;s Encrypt 访问时返回响应内容</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/letsencrypt</span><br><span class="line"><span class="comment"># 打开 nginx 配置文件进行编辑，此处假设 nginx 的配置文件在以下路径：/usr/local/nginx/conf/nginx.conf，如不是，则相应修改路径</span></span><br><span class="line">vi /usr/local/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure>


<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 nginx 配置文件中，找到 http 下监听 80 端口的 server</span></span><br><span class="line">http &#123;</span><br><span class="line">    <span class="comment">//...(略)...</span></span><br><span class="line">    server &#123;</span><br><span class="line">        listen <span class="number">80</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 添加如下内容，此处假设申请域名为 www.helloworld.com，请修改为实际申请的域名</span></span><br><span class="line">        server_name  www.<span class="property">helloworld</span>.<span class="property">com</span>;</span><br><span class="line">        location ^~  <span class="regexp">/.well-known/</span>acme-challenge/ &#123;</span><br><span class="line">            defaulf_type <span class="string">&quot;text/plain&quot;</span>;</span><br><span class="line">            root  /home/letsencrypt/;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// ......以下略......</span></span><br></pre></td></tr></table></figure>
<h3 id="重启-nginx"><a href="#重启-nginx" class="headerlink" title="重启 nginx"></a>重启 nginx</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径</span></span><br><span class="line"><span class="comment"># 先使用 -t 参数测试配置文件格式是否正确</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -t</span><br><span class="line"><span class="comment"># 若正确，屏幕上将显示以下字样</span></span><br><span class="line">&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok</span><br><span class="line"><span class="comment"># 重启 Nginx</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>

<h3 id="运行脚本，申请证书"><a href="#运行脚本，申请证书" class="headerlink" title="运行脚本，申请证书"></a>运行脚本，申请证书</h3><p>在申请证书前，记得先将域名的 DNS 解析指向当前的服务器 IP，这样 letsencrypt 机构在向域名发起连接请求的时候，才能路由到当前设置的机器</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处为域名 www.helloworld.com 申请一张证书，其中的 youremail.com 请替换为你自己的邮箱地址</span></span><br><span class="line">./certbot-auto certonly  --email youremail.com --webroot -w /home/letsencrypt -d www.helloworld.com</span><br><span class="line"><span class="comment"># 如果要为多个子域名（如 api/test/www） 申请一张证书，则相应修改命令如下</span></span><br><span class="line">./certbot-auto certonly --email youremail.com --webroot -w /home/letsencrypt -d api.helloworld.com -d test.helloworld.com -d www.helloworld.com</span><br></pre></td></tr></table></figure>
<p>申请成功后，界面下会有如下的成功提示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IMPORTANT NOTES:</span><br><span class="line">- Congratulations! Your certificate and chain have been saved at</span><br><span class="line">   /etc/letsencrypt/live/helloworld.com/fullchain.pem. Your cert</span><br><span class="line">   will expire on 2019-08-26. To obtain a new version of the</span><br><span class="line">   certificate <span class="keyword">in</span> the future, simply run Let<span class="string">&#x27;s Encrypt again......</span></span><br></pre></td></tr></table></figure>

<h3 id="配置-nginx，启用证书"><a href="#配置-nginx，启用证书" class="headerlink" title="配置 nginx，启用证书"></a>配置 nginx，启用证书</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 nginx 配置文件中，找到 http 下监听 443 端口的 server</span></span><br><span class="line">http &#123;</span><br><span class="line">    <span class="comment">//...(略)...</span></span><br><span class="line">    server &#123;</span><br><span class="line">        listen <span class="number">443</span> ssl;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 修改 server_name、ssl_certificate、ssl_certificate_key 三个字段的值</span></span><br><span class="line">        <span class="comment">// 此处假设申请域名为 www.helloworld.com，请修改为实际申请的域名</span></span><br><span class="line">        server_name  www.<span class="property">helloworld</span>.<span class="property">com</span>;</span><br><span class="line">        ssl_certificate      /etc/letsencrypt/live/www.<span class="property">helloworld</span>.<span class="property">com</span>/fullchain.<span class="property">pem</span>;</span><br><span class="line">        ssl_certificate_key  /etc/letsencrypt/live/www.<span class="property">helloworld</span>.<span class="property">com</span>/privkey.<span class="property">pem</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// ......以下略......</span></span><br></pre></td></tr></table></figure>

<p>当用户访问非加密的 80 端口时，如果需要让服务器自动跳转到 443 端口使用证书的 https 访问，则可以在 http 下 80 端口的 server 中增加如下内容：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 nginx 配置文件中，找到 http 下监听 80 端口的 server</span></span><br><span class="line">http &#123;</span><br><span class="line">    <span class="comment">//...(略)...</span></span><br><span class="line">    server &#123;</span><br><span class="line">        listen <span class="number">80</span>;</span><br><span class="line">        server_name  www.<span class="property">helloworld</span>.<span class="property">com</span>;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">// 添加如下内容，实现自动跳转</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">301</span> <span class="attr">https</span>:<span class="comment">//$server_name$request_uri</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// ......以下略......</span></span><br></pre></td></tr></table></figure>


<h3 id="重启-Nginx，让配置生效"><a href="#重启-Nginx，让配置生效" class="headerlink" title="重启 Nginx，让配置生效"></a>重启 Nginx，让配置生效</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径</span></span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>

<h3 id="测试自动更新"><a href="#测试自动更新" class="headerlink" title="测试自动更新"></a>测试自动更新</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 --dry-run 选项表示测试，非真正执行更新</span></span><br><span class="line">./certbot-auto renew --dry-run</span><br></pre></td></tr></table></figure>
<p>若显示如下字样，则表示自动更新功能测试成功</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Congratulations, all renewals succeeded. The following certs have been renewed:  </span><br><span class="line">   /etc/letsencrypt/live/www.helloworld.com/fullchain.pem (success)</span><br><span class="line">** DRY RUN: simulating <span class="string">&#x27;certbot renew&#x27;</span> close to cert expiry</span><br><span class="line">** (The <span class="built_in">test</span> certificates above have not been saved.)</span><br></pre></td></tr></table></figure>
<h1 id="到期更新"><a href="#到期更新" class="headerlink" title="到期更新"></a>到期更新</h1><p>由于 Let’s Encrypt 颁发的证书只有 90 天有效期，因此需要定期进行证书更新</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 手动更新</span></span><br><span class="line">./certbot-auto renew -v</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/05/26/%E4%BD%BF%E7%94%A8%20CertBot%20%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%20Let's%20Encrypt%20SSL%20%E8%AF%81%E4%B9%A6/" data-id="cm1bkyaa500340khpgaeq2fzy" data-title="使用 CertBot 自动更新 Let&#39;s Encrypt SSL 证书" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" rel="tag">服务器</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-windows 如何共享本地文件夹到 docker machine" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/03/windows%20%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%AB%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%20docker%20machine/" class="article-date">
  <time class="dt-published" datetime="2019-04-03T08:17:46.000Z" itemprop="datePublished">2019-04-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/03/windows%20%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%AB%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%20docker%20machine/">windows 如何共享本地文件夹到 docker machine</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>对于 win10 Home 及 win10 以下的系统，目前只能通过 Docker Toolbox 创建 docker machines 办法来使用 docker</p>
<blockquote>
<p>注：以下方法是针对 Docker Toolbox 的场景，如果是 Docker for Windows，则方法不同；</p>
</blockquote>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>docker 需要运行在 Linux 环境下，但 Windows 系统中没有 Linux 环境，因此需要先通过 Docker Toolbox 程序中携带的 Oracle VM VisualBox 工具， 先虚拟出 Linux 环境（即 docker machine），之后便可以在这些虚拟环境中使用 docker，就像在一台原生 Linux系统的电脑中使用 docker 一样；我们可以根据需要虚拟出很多台远程的 linux 环境，每一台都有自己的 docker，它们之间不会相互干扰；每个 docker 下面有对应的 images 和 containers；</p>
<h4 id="日常使用"><a href="#日常使用" class="headerlink" title="日常使用"></a>日常使用</h4><p>假设我们已经创建了一个叫 default 的虚拟 linux 环境（它以远程 linux 主机的形式出现），我们可以通过 <code>docker-machine ssh default</code> 命令，登录这台主机，进入 Linux 环境，然后在里面执行各种 docker 命令，就好像在原生的 Linux 系统上一样；</p>
<h4 id="如何与本地-windows-共享文件夹"><a href="#如何与本地-windows-共享文件夹" class="headerlink" title="如何与本地 windows 共享文件夹"></a>如何与本地 windows 共享文件夹</h4><h5 id="方法一：使用-Oracle-VM-VisualBox"><a href="#方法一：使用-Oracle-VM-VisualBox" class="headerlink" title="方法一：使用 Oracle VM VisualBox"></a>方法一：使用 Oracle VM VisualBox</h5><p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211117193.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211117295.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211117215.png"></p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/202409211117322.png"></p>
<h5 id="方法二：使用命令行"><a href="#方法二：使用命令行" class="headerlink" title="方法二：使用命令行"></a>方法二：使用命令行</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先暂停远程主机 default</span></span><br><span class="line">docker-machine stop default</span><br><span class="line"><span class="comment"># 使用 vboxmanage sharedfolder add 添加共享文件夹</span></span><br><span class="line">vboxmanage sharedfolder add default --name <span class="string">&quot;dir/path/on/linux&quot;</span> --hostpath <span class="string">&quot;dir/path/on/local/windows&quot;</span> --automount </span><br><span class="line"><span class="comment"># 最后重启远程主机</span></span><br><span class="line">docker-machine start default</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：此处假设远程主机名为 default，如果不是，则相应修改</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/03/windows%20%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%AB%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%20docker%20machine/" data-id="cm1bkvj5800300khpb88wg10g" data-title="windows 如何共享本地文件夹到 docker machine" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/" rel="tag">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-界面设计的原则" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/03/28/%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%9F%E5%88%99/" class="article-date">
  <time class="dt-published" datetime="2019-03-28T00:11:11.000Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/03/28/%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%9F%E5%88%99/">界面设计的原则</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="好看并不是界面设计的第一要义，实现产品目标才是。"><a href="#好看并不是界面设计的第一要义，实现产品目标才是。" class="headerlink" title="好看并不是界面设计的第一要义，实现产品目标才是。"></a>好看并不是界面设计的第一要义，实现产品目标才是。</h4><ul>
<li>一个好看，却不实现产品目标的设计，是差劲的；</li>
<li>一个不好看，但实现产品目标的设计，是合格的；</li>
<li>一个又好看，又实现产品目标的设计，是优秀的；</li>
</ul>
<h4 id="评价一个设计的好坏，步骤顺序如下："><a href="#评价一个设计的好坏，步骤顺序如下：" class="headerlink" title="评价一个设计的好坏，步骤顺序如下："></a>评价一个设计的好坏，步骤顺序如下：</h4><ol>
<li>先写出每个界面的产品目标，然后分析设计元素的使用，是否服务并实现了这个目标；</li>
<li>在实现第1条的基础上，根据设计的原理和规范，从颜色、版面、字体等维度，逐项检查设计是否满足了相关的设计原则，实现了美观；</li>
<li>当设计要素之间有冲突的时候，应该依据哪项更好的实现产品目标，进行取舍；</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/03/28/%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%9F%E5%88%99/" data-id="cm1bku1eb002w0khphw0ahq3c" data-title="界面设计的原则" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1/" rel="tag">设计</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Nginx 实现域名跳转" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/03/01/Nginx%20%E5%AE%9E%E7%8E%B0%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC/" class="article-date">
  <time class="dt-published" datetime="2019-03-01T09:00:10.000Z" itemprop="datePublished">2019-03-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/03/01/Nginx%20%E5%AE%9E%E7%8E%B0%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC/">Nginx 实现域名跳转</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <ul>
<li>目标：当访问 a 域名的目录 abc 时，跳转到 b 域名的目录 abc， nginx 新增一条 server 配置实现：<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span>  &#123;</span><br><span class="line">    <span class="attribute">listen</span>      <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server</span>      www.a.com;</span><br><span class="line">    <span class="section">location</span>    /abc/  &#123;</span><br><span class="line">            <span class="attribute">rewrite</span>  .+  http://www.b.com/<span class="variable">$request_uri</span> <span class="literal">permanent</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注：其中 <span class="variable">$request_uri</span> 表示请求参数的原始URI</span><br><span class="line">例如假设访问链接为：http://www.mysite.com:80/test1/test2/test3.html，</span><br><span class="line">则 <span class="variable">$request_uri</span> 表示 /test1/test2/test3.html</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/03/01/Nginx%20%E5%AE%9E%E7%8E%B0%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC/" data-id="cm1bkscse002s0khp1z7o4ti9" data-title="Nginx 实现域名跳转" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/3/">&laquo; zurück</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/5/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dart/" rel="tag">Dart</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kubernetes/" rel="tag">Kubernetes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/javascript/" rel="tag">javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E7%AB%AF/" rel="tag">前端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8/" rel="tag">安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E4%BF%A1/" rel="tag">微信</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" rel="tag">服务器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%B2%E6%9F%93/" rel="tag">渲染</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%BB%9C/" rel="tag">网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1/" rel="tag">设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6/" rel="tag">软件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%86%E5%90%91/" rel="tag">逆向</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" rel="tag">项目管理</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 11.43px;">C</a> <a href="/tags/C/" style="font-size: 11.43px;">C++</a> <a href="/tags/Dart/" style="font-size: 10px;">Dart</a> <a href="/tags/Kubernetes/" style="font-size: 10px;">Kubernetes</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/javascript/" style="font-size: 18.57px;">javascript</a> <a href="/tags/kubernetes/" style="font-size: 12.86px;">kubernetes</a> <a href="/tags/python/" style="font-size: 15.71px;">python</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 10px;">图像处理</a> <a href="/tags/%E5%AE%89%E5%85%A8/" style="font-size: 14.29px;">安全</a> <a href="/tags/%E5%BE%AE%E4%BF%A1/" style="font-size: 12.86px;">微信</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">操作系统</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.43px;">数据库</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 17.14px;">服务器</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 11.43px;">深度学习</a> <a href="/tags/%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">渲染</a> <a href="/tags/%E7%BD%91%E7%BB%9C/" style="font-size: 11.43px;">网络</a> <a href="/tags/%E8%AE%BE%E8%AE%A1/" style="font-size: 12.86px;">设计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6/" style="font-size: 20px;">软件</a> <a href="/tags/%E9%80%86%E5%90%91/" style="font-size: 10px;">逆向</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 10px;">项目管理</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/08/21/%E6%B8%B2%E6%9F%93%E5%8E%9F%E7%90%86/">渲染原理</a>
          </li>
        
          <li>
            <a href="/2024/06/22/VirtualDom%20%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/">VirtualDOM 简易实现</a>
          </li>
        
          <li>
            <a href="/2023/08/19/Vue3/">Vue3</a>
          </li>
        
          <li>
            <a href="/2023/08/18/Vue%20Router%20%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/">Vue Router 基本用法</a>
          </li>
        
          <li>
            <a href="/2023/08/04/Linux%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/">Linux 文件权限</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 ccw<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>