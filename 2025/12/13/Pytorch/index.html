

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ccw">
  <meta name="keywords" content="">
  
    <meta name="description" content="张量 类似 Numpy 中的 ndarray, 区别在于能够利用 GPU 进行并行计算. 初始化 有多种初始化张量的方法,示例如下: 1234567891011121314151617import torchimport numpy as np# 使用 python 列表data &#x3D; [[1, 2], [3, 4]]x_data &#x3D; torch.tensor(data)# 使用 numpy 数组n">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch">
<meta property="og:url" content="https://ccw1078.github.io/2025/12/13/Pytorch/index.html">
<meta property="og:site_name" content="Ccw&#39;s Blogs">
<meta property="og:description" content="张量 类似 Numpy 中的 ndarray, 区别在于能够利用 GPU 进行并行计算. 初始化 有多种初始化张量的方法,示例如下: 1234567891011121314151617import torchimport numpy as np# 使用 python 列表data &#x3D; [[1, 2], [3, 4]]x_data &#x3D; torch.tensor(data)# 使用 numpy 数组n">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251212083613.png">
<meta property="og:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251212154501.png">
<meta property="og:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251213164504.png">
<meta property="og:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251213172850.png">
<meta property="og:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251214210527.png">
<meta property="article:published_time" content="2025-12-13T10:08:00.000Z">
<meta property="article:modified_time" content="2025-12-14T14:01:46.549Z">
<meta property="article:author" content="ccw">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251212083613.png">
  
  
  
  <title>PyTorch - Ccw&#39;s Blogs</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"ccw1078.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Ccw's Blogs" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ccw&#39;s blogs</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="PyTorch"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-12-13 18:08" pubdate>
          2025年12月13日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          18k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          151 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">PyTorch</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="%E5%BC%A0%E9%87%8F" tabindex="-1">张量</h1>
<p>类似 Numpy 中的 ndarray, 区别在于能够利用 GPU 进行并行计算.</p>
<h2 id="%E5%88%9D%E5%A7%8B%E5%8C%96" tabindex="-1" id="初始化">初始化</h2>
<p>有多种初始化张量的方法,示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 使用 python 列表</span><br>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]<br>x_data = torch.tensor(data)<br><br><span class="hljs-comment"># 使用 numpy 数组</span><br>np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)<br><br><span class="hljs-comment"># 使用其他张量(tensor)</span><br>x_ones = torch.ones_like(x_data) <span class="hljs-comment"># retains the properties of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Ones Tensor: \n <span class="hljs-subst">&#123;x_ones&#125;</span> \n&quot;</span>)<br><br>x_rand = torch.rand_like(x_data, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># overrides the datatype of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Random Tensor: \n <span class="hljs-subst">&#123;x_rand&#125;</span> \n&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Ones Tensor:<br> tensor([[1, 1],<br>        [1, 1]])<br><br>Random Tensor:<br> tensor([[0.9769, 0.6933],<br>        [0.0915, 0.3702]])<br></code></pre></td></tr></table></figure>
<h2 id="%E5%BC%A0%E9%87%8F%E5%B1%9E%E6%80%A7" tabindex="-1" id="张量属性">张量属性</h2>
<p>形状, 数据类型, 存储设备</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Shape of tensor: <span class="hljs-subst">&#123;tensor.shape&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Datatype of tensor: <span class="hljs-subst">&#123;tensor.dtype&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">Shape of tensor: torch.Size([3, 4])<br>Datatype of tensor: torch.float32<br>Device tensor is stored on: cpu<br></code></pre></td></tr></table></figure>
<h2 id="%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C" tabindex="-1" id="张量操作">张量操作</h2>
<p>张量支持非常多的操作, 100 多种,例如转置, 索引, 切片, 数学去处, 线性代数, 随机抽样等等.</p>
<p>可将张量移动到 GPU 进行计算, 可以显著提高计算的速度.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We move our tensor to the GPU if available</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>  tensor = tensor.to(<span class="hljs-string">&#x27;cuda&#x27;</span>)<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Device tensor is stored on: cuda:0<br></code></pre></td></tr></table></figure>
<p><strong>类似 Numpy 的索引和切片</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.ones(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br>tensor[:,<span class="hljs-number">1</span>] = <span class="hljs-number">0</span> <span class="hljs-comment"># 所有行的第1列改为 0</span><br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensor([[1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.]])<br></code></pre></td></tr></table></figure>
<p><strong>归并 concate</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(t1)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],<br>        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],<br>        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],<br>        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])<br></code></pre></td></tr></table></figure>
<p><strong>逐元素乘法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 逐元素相乘</span><br>a = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>b = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br>c = a * b<br><span class="hljs-comment"># 结果：</span><br><span class="hljs-comment"># tensor([[ 5, 12],</span><br><span class="hljs-comment">#         [21, 32]])</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 如果形状不同,则会先广播之后再相乘</span><br>a = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])  <span class="hljs-comment"># shape: (2, 2)</span><br>b = torch.tensor([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>])          <span class="hljs-comment"># shape: (2,) 此处形状不同,会自动广播成([10, 20],[10, 20])</span><br>c = a * b<br><br><span class="hljs-comment"># 结果：</span><br><span class="hljs-comment"># tensor([[10, 40],</span><br><span class="hljs-comment">#         [30, 80]])</span><br></code></pre></td></tr></table></figure>
<p><strong>矩阵乘法</strong></p>
<p><code>torch.matmul()</code> 或者使用运算符 @</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])   <span class="hljs-comment"># (2, 2)</span><br>b = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])   <span class="hljs-comment"># (2, 2)</span><br><br>c = torch.matmul(a, b)  <span class="hljs-comment"># 或 a @ b</span><br><span class="hljs-comment"># 结果：</span><br><span class="hljs-comment"># tensor([[19, 22],</span><br><span class="hljs-comment">#         [43, 50]])</span><br></code></pre></td></tr></table></figure>
<p>计算过程：</p>
<p>第一行第一列：1×5 + 2×7 = 19<br>
第一行第二列：1×6 + 2×8 = 22</p>
<p><strong>就地更新</strong></p>
<p>在原方法的末尾添加下划线即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(tensor, <span class="hljs-string">&quot;\n&quot;</span>)<br>tensor.add_(<span class="hljs-number">5</span>)   <span class="hljs-comment"># add 方法变成 add_</span><br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensor([[1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.]])<br><br>tensor([[6., 5., 6., 6.],<br>        [6., 5., 6., 6.],<br>        [6., 5., 6., 6.],<br>        [6., 5., 6., 6.]])<br></code></pre></td></tr></table></figure>
<h3 id="%E5%85%B3%E8%81%94-numpy" tabindex="-1" id="关联-Numpy">关联 Numpy</h3>
<p>在 CPU 上的张量可以和 Numpy 共享内存, 修改其中一个会直接影响另外一个</p>
<p><strong>张量转 Numpy 数组</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">t = torch.ones(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br>n = t.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">t: tensor([1., 1., 1., 1., 1.])<br>n: [1. 1. 1. 1. 1.]<br></code></pre></td></tr></table></figure>
<p>当修改张量后, numpy 数组也会跟着变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">t.add_(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">t: tensor([2., 2., 2., 2., 2.])<br>n: [2. 2. 2. 2. 2.]<br></code></pre></td></tr></table></figure>
<p><strong>Numpy数组转张量</strong></p>
<p>修改 numpy 数组也会让张量跟着变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">n = np.ones(<span class="hljs-number">5</span>)<br>t = torch.from_numpy(n)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">np.add(n, 1, out=n) <span class="hljs-comment"># out=n 参数表示就地更新原来的数组 n</span><br><span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;t: &#123;t&#125;&quot;</span>)<br><span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;n: &#123;n&#125;&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)<br>n: [2. 2. 2. 2. 2.]<br></code></pre></td></tr></table></figure>
<h1 id="%E8%87%AA%E5%8A%A8%E6%A2%AF%E5%BA%A6" tabindex="-1">自动梯度</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet18, ResNet18_Weights<br><br>model = resnet18(weights=ResNet18_Weights.DEFAULT)<br>data = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>labels = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>)<br><br>prediction = model(data) <span class="hljs-comment"># 前向传播</span><br>loss = (prediction - labels).<span class="hljs-built_in">sum</span>()<br>loss.backward() <span class="hljs-comment"># 反向传播，自动计算梯度值，并保存到张量的 grad 属性中</span><br><br><span class="hljs-comment"># 初始化优化器（此处为小批量梯度下降）</span><br>optim = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-2</span>, momentum=<span class="hljs-number">0.9</span>)<br><br>optim.step() <span class="hljs-comment"># 根据梯度调整权重参数的值，调整幅度与学习率有关</span><br></code></pre></td></tr></table></figure>
<p>自动计算梯度的示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>a = torch.tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>], requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.tensor([<span class="hljs-number">6.</span>, <span class="hljs-number">4.</span>], requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>假设：</p>

    <span id="mjx-e813552">
      <style>
      #mjx-e813552{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.846ex" height="2.439ex" role="img" focusable="false" viewBox="0 -883.9 5678.1 1077.9" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(1068.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2124.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="msup" transform="translate(2624.6,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,413) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g><g data-mml-node="mo" transform="translate(3812.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(4812.6,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mn" transform="translate(462,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>Q</mi><mo>=</mo><mn>3</mn><msup><mi>a</mi><mn>3</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container>
    </span>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Q = <span class="hljs-number">3</span>*a**<span class="hljs-number">3</span> - b**<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>
<p>假设 a、b 为权重参数，那么 Q 相对 a，b 的导数为：</p>

    <span id="mjx-42bd699">
      <style>
      #mjx-42bd699{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="10.398ex" height="4.749ex" role="img" focusable="false" viewBox="0 -1391 4596.1 2099" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g></g><g data-mml-node="mrow" transform="translate(351,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><rect width="1557" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(2074.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3130.6,0)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path></g><g data-mml-node="msup" transform="translate(3630.6,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>∂</mi><mi>Q</mi></mrow><mrow><mi>∂</mi><mi>a</mi></mrow></mfrac><mo>=</mo><mn>9</mn><msup><mi>a</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container>
    </span>
  
    <span id="mjx-3871b71">
      <style>
      #mjx-3871b71{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="10.945ex" height="4.749ex" role="img" focusable="false" viewBox="0 -1391 4837.6 2099" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g></g><g data-mml-node="mrow" transform="translate(401,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g><rect width="1557" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(2074.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3130.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(3908.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(4408.6,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>∂</mi><mi>Q</mi></mrow><mrow><mi>∂</mi><mi>b</mi></mrow></mfrac><mo>=</mo><mo>−</mo><mn>2</mn><mi>b</mi></math></mjx-assistive-mml></mjx-container>
    </span>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 假设梯度向量值为 [1, 1]</span><br>external_grad = torch.tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>Q.backward(gradient=external_grad)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-number">9</span>*a**<span class="hljs-number">2</span> == a.grad)<br><span class="hljs-built_in">print</span>(-<span class="hljs-number">2</span>*b == b.grad)<br><span class="hljs-built_in">print</span>(a.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensor([True, True])<br>tensor([True, True])<br>tensor([ 36.0000, 81.0000])<br>tensor([ -2.0000, -2.0000])<br></code></pre></td></tr></table></figure>
<blockquote>
<p>导数的本质是变化率,即当自变量 x 出现 1 个单位的变化时, 因变量 y 会出现多大的变化. 而损失值则是期待的变化幅度(变了多少个单位后将满足目标值).</p>
</blockquote>
<h2 id="%E8%AE%A1%E7%AE%97%E5%9B%BE" tabindex="-1" id="计算图">计算图</h2>
<p>当调用 loss.backward() 时, torch 会自动计算损失向量(梯度)的雅可比积, 将损失函数的梯度反向传播到所有相关的可训练权重参数, 用于后续的参数更新. 损失值与梯度的乘积即表示参数应该更新的量, 但通常会乘以一个学习率,以便实现小幅度的更新, 避免过于剧烈的震荡.</p>
<p>计算图是一个单向无环图(DAG), 记录着从输入的张量到输出的张量之间的每一步计算过程.</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251212083613.png" srcset="/img/loading.gif" lazyload alt=""></p>
<blockquote>
<p>计算图是在前向传播的过程中动态构建的, 同时在调用 backward() 方法后会自动释放, 以便节省内存. 如果缓存计算图, 需要设置参数 retain_graph=true. 当重复调用 backward 时, 会报错. 因为第一次调用后会释放, 导致后续的调用找不到计算图了.</p>
</blockquote>
<p>如果某个张量不需要构建计算图, 可设置参数 required_grad=False</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>)<br>y = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>)<br>z = torch.rand((<span class="hljs-number">5</span>, <span class="hljs-number">5</span>), requires_grad=<span class="hljs-literal">True</span>)<br><br>a = x + y<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Does `a` require gradients?: <span class="hljs-subst">&#123;a.requires_grad&#125;</span>&quot;</span>)<br>b = x + z<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Does `b` require gradients?: <span class="hljs-subst">&#123;b.requires_grad&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Does `a` require gradients?: False<br>Does `b` require gradients?: True<br></code></pre></td></tr></table></figure>
<p>当设置 required_grad=False 时, 因为没有构建计算图, 因此参数在训练过程中不会被更新, 相当于被冻结了. 这个功能在微调模型的场景中很有用, 因为我们通常需要冻结主干模型, 只训练最后的分类层.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, optim<br><br>model = resnet18(weights=ResNet18_Weights.DEFAULT)<br><br><span class="hljs-comment"># 冻结所有参数</span><br><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters():<br>    param.requires_grad = <span class="hljs-literal">False</span><br>    <br><span class="hljs-comment"># 将模型最后的 fc 层替换为一个新的线性层, 该线性层的参数没有冻结, 可进行微调训练</span><br>model.fc = nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>)<br><br><span class="hljs-comment"># 虽然模型参数都传递给了优化器, 但实际上只有最后一层的参数会构建计算图计算梯度并被优化器更新</span><br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-2</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<p>另外还有一个全局的暂停自动梯度计算的方法是使用  torch.no_grad()</p>
<h1 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" tabindex="-1">神经网络</h1>
<p>nn.Module 类可用来构建一个神经网络中的模块(神经元), 模块由一个或多个层构成, 有一个 forward 前向传播的方法, 并返回一个计算结果 output</p>
<blockquote>
<p>神经元通常包含一个非线性的激活层, 以便能够实现对复杂函数的拟合.</p>
</blockquote>
<h2 id="%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B" tabindex="-1" id="网络示例">网络示例</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 输入1张图片, 6 个输出通道, 使用 5x5 的卷积核</span><br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-comment"># 仿射变换: y = Wx + b</span><br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)  <span class="hljs-comment"># 5*5 from image dimension</span><br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-comment"># 卷积层 C1: 输入1张图片, 6 个输出通道, 使用 5x5 的卷积核, 使用 ReLU 激活函数</span><br>        <span class="hljs-comment"># 输入张量尺寸 (N, 6, 28, 28), N 为单批的数量(即样本数)</span><br>        c1 = F.relu(<span class="hljs-variable language_">self</span>.conv1(<span class="hljs-built_in">input</span>))<br>        <span class="hljs-comment"># Subsampling layer S2: 2x2 grid, purely functional,</span><br>        <span class="hljs-comment"># this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor</span><br>        s2 = F.max_pool2d(c1, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># Convolution layer C3: 6 input channels, 16 output channels,</span><br>        <span class="hljs-comment"># 5x5 square convolution, it uses RELU activation function, and</span><br>        <span class="hljs-comment"># outputs a (N, 16, 10, 10) Tensor</span><br>        c3 = F.relu(<span class="hljs-variable language_">self</span>.conv2(s2))<br>        <span class="hljs-comment"># Subsampling layer S4: 2x2 grid, purely functional,</span><br>        <span class="hljs-comment"># this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor</span><br>        s4 = F.max_pool2d(c3, <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># Flatten operation: purely functional, outputs a (N, 400) Tensor</span><br>        s4 = torch.flatten(s4, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># Fully connected layer F5: (N, 400) Tensor input,</span><br>        <span class="hljs-comment"># and outputs a (N, 120) Tensor, it uses RELU activation function</span><br>        f5 = F.relu(<span class="hljs-variable language_">self</span>.fc1(s4))<br>        <span class="hljs-comment"># Fully connected layer F6: (N, 120) Tensor input,</span><br>        <span class="hljs-comment"># and outputs a (N, 84) Tensor, it uses RELU activation function</span><br>        f6 = F.relu(<span class="hljs-variable language_">self</span>.fc2(f5))<br>        <span class="hljs-comment"># Fully connected layer OUTPUT: (N, 84) Tensor input, and</span><br>        <span class="hljs-comment"># outputs a (N, 10) Tensor</span><br>        output = <span class="hljs-variable language_">self</span>.fc3(f6)<br>        <span class="hljs-keyword">return</span> output<br><br><br>net = Net()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Net(<br>  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))<br>  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))<br>  (fc1): Linear(in_features=400, out_features=120, bias=True)<br>  (fc2): Linear(in_features=120, out_features=84, bias=True)<br>  (fc3): Linear(in_features=84, out_features=10, bias=True)<br>)<br></code></pre></td></tr></table></figure>
<p>可使用 model.parameters() 方法访问所有可学习参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">params = <span class="hljs-built_in">list</span>(net.parameters())<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(params))<br><span class="hljs-built_in">print</span>(params[<span class="hljs-number">0</span>].size())  <span class="hljs-comment"># conv1&#x27;s .weight</span><br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">10<br>torch.Size([6, 1, 5, 5])<br></code></pre></td></tr></table></figure>
<p>可使用 model.zero_grad() 方法重置梯度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">net.zero_grad()<br>out.backward(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>
<p>torch.nn 强制要求样本以批次为单位作为输入, 不能以单个样本为单位作为输入. 最小批次数量为 1, 因此输入张量的第 1 个维度即是单批的样本数量. 如果每批只有一个样本, 则该值为 1.</p>
<blockquote>
<p>对于单个样本, 可使用 input.unsqueeze(0) 方法, 给样本添加一个批次的维度</p>
</blockquote>
<h2 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0" tabindex="-1" id="损失函数">损失函数</h2>
<p>损失函数用于计算模型的输出和目标值之间的差异</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">output = net(<span class="hljs-built_in">input</span>)<br>target = torch.randn(<span class="hljs-number">10</span>)  <span class="hljs-comment"># a dummy target, for example</span><br>target = target.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># make it the same shape as output</span><br>criterion = nn.MSELoss() <br><br>loss = criterion(output, target)<br><span class="hljs-built_in">print</span>(loss)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensor(1.2850, grad_fn=&lt;MseLossBackward0&gt;)<br></code></pre></td></tr></table></figure>
<p>以下是损失张量的计算图</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d<br>      -&gt; flatten -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear<br>      -&gt; MSELoss<br>      -&gt; loss<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(loss.grad_fn)  <span class="hljs-comment"># MSELoss</span><br><span class="hljs-built_in">print</span>(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  <span class="hljs-comment"># Linear</span><br><span class="hljs-built_in">print</span>(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  <span class="hljs-comment"># ReLU</span><br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;MseLossBackward0 object at 0x7febcb77eb00&gt;<br>&lt;AddmmBackward0 object at 0x7febcb77f310&gt;<br>&lt;AccumulateGrad object at 0x7febcb471cf0&gt;<br></code></pre></td></tr></table></figure>
<h2 id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD" tabindex="-1" id="反向传播">反向传播</h2>
<p>梯度值是累加的, 因此每次进行反向传播时, 需要先调用 model.zero_grad 方法重置梯度值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">net.zero_grad()     <span class="hljs-comment"># 清除可学习参数上的旧梯度值</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;conv1.bias.grad before backward&#x27;</span>)<br><span class="hljs-built_in">print</span>(net.conv1.bias.grad)<br><br>loss.backward()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;conv1.bias.grad after backward&#x27;</span>)<br><span class="hljs-built_in">print</span>(net.conv1.bias.grad)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">conv1.bias.grad before backward<br>None<br>conv1.bias.grad after backward<br>tensor([ 0.0101, -0.0044,  0.0021,  0.0144,  0.0112,  0.0002])<br></code></pre></td></tr></table></figure>
<h2 id="%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0" tabindex="-1" id="更新参数">更新参数</h2>
<p>对于 SGD 小批量梯度优化器, 参数的更新规则如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">weight = weight - learning_rate * gradient<br></code></pre></td></tr></table></figure>
<p>使用 python 代码实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">learning_rate = <span class="hljs-number">0.01</span><br><span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> net.parameters():<br>    f.data.sub_(f.grad.data * learning_rate) <span class="hljs-comment"># 使用 sub_ 方法实现就地更新</span><br></code></pre></td></tr></table></figure>
<p>除了 SGD 外, 还有很多种参数更新方法, 例如: Nesterov-SGD, Adam, RMSProp 等. 可以使用 torch.optim 进行初始化, 选择合适的优化器, 实现对参数的更新</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># 创建优化器</span><br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># 更新过程:</span><br>optimizer.zero_grad()   <span class="hljs-comment"># 需要手动重置梯度(因为每次计算梯度值后会默认自动累积,而不是替换)</span><br>output = net(<span class="hljs-built_in">input</span>)<br>loss = criterion(output, target)<br>loss.backward()<br>optimizer.step()    <span class="hljs-comment"># 调用 step() 后才会开始更新</span><br></code></pre></td></tr></table></figure>
<h1 id="%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8" tabindex="-1">训练分类器</h1>
<h2 id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" tabindex="-1" id="数据预处理">数据预处理</h2>
<p>可使用一些常见的 python 库将文本, 图片, 音频, 视频等数据转成 numpy 格式, 然后再转成 Tensor 张量. 对于视频类型的数据, torch 有一个专门的 torchvision 库可实现常见数据集的加载和预处理.</p>
<h2 id="%E8%AE%AD%E7%BB%83%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E5%99%A8" tabindex="-1" id="训练图片分类器">训练图片分类器</h2>
<h3 id="%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A7%84%E8%8C%83%E5%8C%96" tabindex="-1" id="加载数据并规范化">加载数据并规范化</h3>
<p>此处以 CIFAR10 数据集进行示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose(<br>    [transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]) <span class="hljs-comment"># 规划化器</span><br><br>batch_size = <span class="hljs-number">4</span><br><span class="hljs-comment"># 定义训练集</span><br>trainset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>,<br>                                        download=<span class="hljs-literal">True</span>, transform=transform)<br><span class="hljs-comment"># 定义数据加载器(本质上是一个迭代器)</span><br>trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,<br>                                          shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 测试集</span><br>testset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">False</span>,<br>                                       download=<span class="hljs-literal">True</span>, transform=transform)<br>testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,<br>                                         shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">2</span>)<br><br>classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>,<br>           <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="%E5%AE%9A%E4%B9%89%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" tabindex="-1" id="定义神经网络">定义神经网络</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-variable language_">self</span>.pool = nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.pool(F.relu(<span class="hljs-variable language_">self</span>.conv1(x)))<br>        x = <span class="hljs-variable language_">self</span>.pool(F.relu(<span class="hljs-variable language_">self</span>.conv2(x)))<br>        x = torch.flatten(x, <span class="hljs-number">1</span>) <span class="hljs-comment"># flatten all dimensions except batch</span><br>        x = F.relu(<span class="hljs-variable language_">self</span>.fc1(x))<br>        x = F.relu(<span class="hljs-variable language_">self</span>.fc2(x))<br>        x = <span class="hljs-variable language_">self</span>.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>net = Net()<br></code></pre></td></tr></table></figure>
<h3 id="%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8" tabindex="-1" id="定义损失函数和优化器">定义损失函数和优化器</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<h3 id="%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C" tabindex="-1" id="训练网络">训练网络</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):  <span class="hljs-comment"># loop over the dataset multiple times</span><br><br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br>        <span class="hljs-comment"># 遍历数据</span><br>        inputs, labels = data<br><br>        <span class="hljs-comment"># 重置梯度</span><br>        optimizer.zero_grad()<br><br>        <span class="hljs-comment"># 前向传播 + 反向传播 + 优化</span><br>        outputs = net(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-comment"># 打印统计</span><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:    <span class="hljs-comment"># 每 2000 批</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;[<span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, <span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>:5d&#125;</span>] loss: <span class="hljs-subst">&#123;running_loss / <span class="hljs-number">2000</span>:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>            running_loss = <span class="hljs-number">0.0</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">[1,  2000] loss: 2.229<br>[1,  4000] loss: 1.905<br>[1,  6000] loss: 1.667<br>[1,  8000] loss: 1.566<br>[1, 10000] loss: 1.507<br>[1, 12000] loss: 1.469<br>[2,  2000] loss: 1.403<br>[2,  4000] loss: 1.362<br>[2,  6000] loss: 1.339<br>[2,  8000] loss: 1.319<br>[2, 10000] loss: 1.303<br>[2, 12000] loss: 1.270<br>Finished Training<br></code></pre></td></tr></table></figure>
<p>保存训练后的模型参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">PATH = <span class="hljs-string">&#x27;./cifar_net.pth&#x27;</span><br>torch.save(net.state_dict(), PATH)<br></code></pre></td></tr></table></figure>
<h3 id="%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B" tabindex="-1" id="测试网络模型">测试网络模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">dataiter = <span class="hljs-built_in">iter</span>(testloader)<br>images, labels = <span class="hljs-built_in">next</span>(dataiter)<br><br>net = Net()<br>net.load_state_dict(torch.load(PATH, weights_only=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = net(images)<br><br>_, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;classes[predicted[j]]:5s&#125;</span>&#x27;</span><br>                              <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Predicted:  <span class="hljs-built_in">cat</span>   ship  ship  ship<br></code></pre></td></tr></table></figure>
<h2 id="%E4%BD%BF%E7%94%A8-gpu-%E8%AE%AD%E7%BB%83" tabindex="-1" id="使用-GPU-训练">使用 GPU 训练</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&#x27;cuda:0&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br><span class="hljs-comment"># 将模型复制到 GPU 设备</span><br>net.to(device) <br><span class="hljs-comment"># 输入和标签也需要复制到 GPU</span><br>inputs, labels = data[<span class="hljs-number">0</span>].to(device), data[<span class="hljs-number">1</span>].to(device)<br></code></pre></td></tr></table></figure>
<h2 id="%E5%A4%9A-gpu-%E8%AE%AD%E7%BB%83" tabindex="-1" id="多-GPU-训练">多 GPU 训练</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 复制模型和数据</span><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br>model.to(device)<br><span class="hljs-comment"># tensor.to(device) 方法会返回一个指向新张量的引用,而不是就地更新</span><br>mytensor = my_tensor.to(device)<br><span class="hljs-comment"># 开启多 GPU 的并行</span><br>model = nn.DataParallel(model)<br></code></pre></td></tr></table></figure>
<h3 id="%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE" tabindex="-1" id="准备数据">准备数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><br><span class="hljs-comment"># Parameters and DataLoaders</span><br>input_size = <span class="hljs-number">5</span><br>output_size = <span class="hljs-number">2</span><br><br>batch_size = <span class="hljs-number">30</span><br>data_size = <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 随机数据集</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RandomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, length</span>):<br>        <span class="hljs-variable language_">self</span>.<span class="hljs-built_in">len</span> = length<br>        <span class="hljs-variable language_">self</span>.data = torch.randn(length, size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data[index]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.<span class="hljs-built_in">len</span><br><br>rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),<br>                         batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h3 id="%E5%87%86%E5%A4%87%E6%A8%A1%E5%9E%8B" tabindex="-1" id="准备模型">准备模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-comment"># Our model</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(Model, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc = nn.Linear(input_size, output_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-variable language_">self</span>.fc(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\tIn Model: input size&quot;</span>, <span class="hljs-built_in">input</span>.size(),<br>              <span class="hljs-string">&quot;output size&quot;</span>, output.size())<br><br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>
<h3 id="%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83" tabindex="-1" id="并行训练">并行训练</h3>
<p>检查是否有多个 GPU 可用, 如有, 开启并行训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">model = Model(input_size, output_size)<br><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="hljs-string">&quot;GPUs!&quot;</span>)<br>  <span class="hljs-comment"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span><br>  model = nn.DataParallel(model) <span class="hljs-comment"># 开启并行</span><br><br>model.to(device)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Let<span class="hljs-string">&#x27;s use 4 GPUs!</span><br><span class="hljs-string"></span><br><span class="hljs-string">DataParallel(</span><br><span class="hljs-string">  (module): Model(</span><br><span class="hljs-string">    (fc): Linear(in_features=5, out_features=2, bias=True)</span><br><span class="hljs-string">  )</span><br><span class="hljs-string">)</span><br></code></pre></td></tr></table></figure>
<h3 id="%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B" tabindex="-1" id="运行模型">运行模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> rand_loader:<br>    <span class="hljs-built_in">input</span> = data.to(device)<br>    output = model(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Outside: input size&quot;</span>, <span class="hljs-built_in">input</span>.size(),<br>          <span class="hljs-string">&quot;output_size&quot;</span>, output.size())<br></code></pre></td></tr></table></figure>
<p>以下是有 4 个 GPU 并行时的输出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([6, 5]) output size torch.Size([6, 2])<br>Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([8, 5]) output size torch.Size([8, 2])<br>        In Model: input size torch.Size([6, 5]) output size torch.Size([6, 2])<br>Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])<br>        In Model: input size torch.Size([3, 5]) output size torch.Size([3, 2])<br>        In Model: input size torch.Size([3, 5]) output size torch.Size([3, 2])<br>        In Model: input size torch.Size([3, 5]) output size torch.Size([3, 2])<br>        In Model: input size torch.Size([1, 5]) output size torch.Size([1, 2])<br>Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])<br></code></pre></td></tr></table></figure>
<p>2 个 GPU 时:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># on 2 GPUs</span><br>Let<span class="hljs-string">&#x27;s use 2 GPUs!</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])</span><br></code></pre></td></tr></table></figure>
<p>3 个 GPU 时</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash">Let<span class="hljs-string">&#x27;s use 3 GPUs!</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])</span><br></code></pre></td></tr></table></figure>
<p>8 个 GPU 时</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">Let<span class="hljs-string">&#x27;s use 8 GPUs!</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</span><br><span class="hljs-string">Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])</span><br></code></pre></td></tr></table></figure>
<p>DataParallel 实现的是数据并行, 即将数据拆分到不同的 GPU 上进行计算, 最后再合并计算结果.</p>
<h1 id="%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B" tabindex="-1">简单示例</h1>
<h2 id="numpy" tabindex="-1" id="numpy">numpy</h2>
<p>使用 numpy 来计算梯度的示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> math<br><br><span class="hljs-comment"># Create random input and output data</span><br>x = np.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>)<br>y = np.sin(x)<br><br><span class="hljs-comment"># 随机初始化参数值</span><br>a = np.random.randn()<br>b = np.random.randn()<br>c = np.random.randn()<br>d = np.random.randn()<br><br>learning_rate = <span class="hljs-number">1e-6</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br>    <span class="hljs-comment"># 前向传播 y = a + b x + c x^2 + d x^3</span><br>    y_pred = a + b * x + c * x ** <span class="hljs-number">2</span> + d * x ** <span class="hljs-number">3</span><br><br>    <span class="hljs-comment"># 计算损失</span><br>    loss = np.square(y_pred - y).<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss)<br><br>    <span class="hljs-comment"># 计算参数 a, b, c, d 相对 loss 的偏层数</span><br>    grad_y_pred = <span class="hljs-number">2.0</span> * (y_pred - y) <span class="hljs-comment"># 因为是均方差, 所以有个导数是 2.0</span><br>    grad_a = grad_y_pred.<span class="hljs-built_in">sum</span>() <span class="hljs-comment"># 最后需要 sum 各个梯度值</span><br>    grad_b = (grad_y_pred * x).<span class="hljs-built_in">sum</span>()<br>    grad_c = (grad_y_pred * x ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>    grad_d = (grad_y_pred * x ** <span class="hljs-number">3</span>).<span class="hljs-built_in">sum</span>()<br><br>    <span class="hljs-comment"># 更新参数</span><br>    a -= learning_rate * grad_a<br>    b -= learning_rate * grad_b<br>    c -= learning_rate * grad_c<br>    d -= learning_rate * grad_d<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;a&#125;</span> + <span class="hljs-subst">&#123;b&#125;</span> x + <span class="hljs-subst">&#123;c&#125;</span> x^2 + <span class="hljs-subst">&#123;d&#125;</span> x^3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>由于损失值的计算公式如下:</p>

    <span id="mjx-810969a">
      <style>
      #mjx-810969a{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -1.018ex;" xmlns="http://www.w3.org/2000/svg" width="41.428ex" height="3.167ex" role="img" focusable="false" viewBox="0 -950 18311.2 1400" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(958.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2014.6,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="mo" transform="translate(3458.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3847.6,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4559.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(5560,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msup" transform="translate(6050,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(6875.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(7153.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(8320.2,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(9088,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(10143.8,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(10895,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(11895.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(12324.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(13118.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(14118.7,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="msup" transform="translate(14551.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(15782.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(16782.7,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="msup" transform="translate(17302.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,413) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>L</mi><mo>=</mo><mo data-mjx-texclass="OP">∑</mo><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>,</mo><mstyle scriptlevel="0"><mspace width="1em"></mspace></mstyle><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mi>x</mi><mo>+</mo><mi>c</mi><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mi>d</mi><msup><mi>x</mi><mn>3</mn></msup></math></mjx-assistive-mml></mjx-container>
    </span>
  <p>因此, 损失 L 相对 a, b, c, d 的导数计算公式如下:</p>
<ul>
<li>
    <span id="mjx-c8dbc25">
      <style>
      #mjx-c8dbc25{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.817ex;" xmlns="http://www.w3.org/2000/svg" width="29.101ex" height="2.852ex" role="img" focusable="false" viewBox="0 -899.6 12862.4 1260.7" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(273.7,-345.6) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><rect width="1081.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1599.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2655.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mn" transform="translate(3878,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(4378,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4767,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5479.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(6479.4,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6969.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7580.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mn" transform="translate(8080.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(8858.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(9914.4,0)"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(892,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1948,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2448,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow><mrow><mi>∂</mi><mi>a</mi></mrow></mfrac><mo>=</mo><mo data-mjx-texclass="OP">∑</mo><mn>2</mn><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋅</mo><mn>1</mn><mo>=</mo><mtext>grad_a</mtext></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
<li>
    <span id="mjx-3dd5049">
      <style>
      #mjx-3dd5049{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.817ex;" xmlns="http://www.w3.org/2000/svg" width="29.39ex" height="2.852ex" role="img" focusable="false" viewBox="0 -899.6 12990.4 1260.7" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(309.1,-345.6) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g><rect width="1081.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1599.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2655.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mn" transform="translate(3878,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(4378,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4767,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5479.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(6479.4,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6969.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7580.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(8080.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(8930.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(9986.4,0)"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(892,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1948,0)"></path><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z" transform="translate(2448,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow><mrow><mi>∂</mi><mi>b</mi></mrow></mfrac><mo>=</mo><mo data-mjx-texclass="OP">∑</mo><mn>2</mn><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>x</mi><mo>=</mo><mtext>grad_b</mtext></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
<li>
    <span id="mjx-d62df04">
      <style>
      #mjx-d62df04{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.817ex;" xmlns="http://www.w3.org/2000/svg" width="30.124ex" height="2.852ex" role="img" focusable="false" viewBox="0 -899.6 13315 1260.7" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(307.7,-345.6) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g><rect width="1081.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1599.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2655.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mn" transform="translate(3878,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(4378,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4767,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5479.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(6479.4,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6969.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7580.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msup" transform="translate(8080.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(9367.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(10423,0)"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(892,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1948,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(2448,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow><mrow><mi>∂</mi><mi>c</mi></mrow></mfrac><mo>=</mo><mo data-mjx-texclass="OP">∑</mo><mn>2</mn><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>x</mi><mn>2</mn></msup><mo>=</mo><mtext>grad_c</mtext></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
<li>
    <span id="mjx-dd5f0fd">
      <style>
      #mjx-dd5f0fd{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.817ex;" xmlns="http://www.w3.org/2000/svg" width="30.378ex" height="2.852ex" role="img" focusable="false" viewBox="0 -899.6 13427 1260.7" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(276.9,-345.6) scale(0.707)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><rect width="1081.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1599.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2655.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mn" transform="translate(3878,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(4378,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4767,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5479.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(6479.4,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6969.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7580.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msup" transform="translate(8080.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g><g data-mml-node="mo" transform="translate(9367.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(10423,0)"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(892,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1948,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2448,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow><mrow><mi>∂</mi><mi>d</mi></mrow></mfrac><mo>=</mo><mo data-mjx-texclass="OP">∑</mo><mn>2</mn><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>x</mi><mn>3</mn></msup><mo>=</mo><mtext>grad_d</mtext></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
</ul>
<h2 id="tensors" tabindex="-1" id="Tensors">Tensors</h2>
<p>相比 numpy array, Tensor 最大的好处是可以利用 GPU 实现并行计算, 能够显著提高计算速度(可能达50x)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 以下是使用 tensor 实现相同的计算</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br><br>dtype = torch.<span class="hljs-built_in">float</span><br>device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>) <span class="hljs-comment"># 使用 CPU 计算</span><br><span class="hljs-comment"># device = torch.device(&quot;cuda:0&quot;) # 使用 GPU 计算</span><br><br><span class="hljs-comment"># 输入</span><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>, device=device, dtype=dtype)<br>y = torch.sin(x)<br><br><span class="hljs-comment"># Randomly initialize weights</span><br>a = torch.randn((), device=device, dtype=dtype)<br>b = torch.randn((), device=device, dtype=dtype)<br>c = torch.randn((), device=device, dtype=dtype)<br>d = torch.randn((), device=device, dtype=dtype)<br><br>learning_rate = <span class="hljs-number">1e-6</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br>    <span class="hljs-comment"># 前向传播, 计算预测值 y_pred</span><br>    y_pred = a + b * x + c * x ** <span class="hljs-number">2</span> + d * x ** <span class="hljs-number">3</span><br><br>    <span class="hljs-comment"># 计算损失</span><br>    loss = (y_pred - y).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>().item()<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss)<br><br>    <span class="hljs-comment"># 计算梯度</span><br>    grad_y_pred = <span class="hljs-number">2.0</span> * (y_pred - y)<br>    grad_a = grad_y_pred.<span class="hljs-built_in">sum</span>()<br>    grad_b = (grad_y_pred * x).<span class="hljs-built_in">sum</span>()<br>    grad_c = (grad_y_pred * x ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>    grad_d = (grad_y_pred * x ** <span class="hljs-number">3</span>).<span class="hljs-built_in">sum</span>()<br><br>    <span class="hljs-comment"># 更新参数</span><br>    a -= learning_rate * grad_a<br>    b -= learning_rate * grad_b<br>    c -= learning_rate * grad_c<br>    d -= learning_rate * grad_d<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;a.item()&#125;</span> + <span class="hljs-subst">&#123;b.item()&#125;</span> x + <span class="hljs-subst">&#123;c.item()&#125;</span> x^2 + <span class="hljs-subst">&#123;d.item()&#125;</span> x^3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="autograd" tabindex="-1" id="Autograd">Autograd</h2>
<p>以上示例是手动实现前向和反向传播,  对于只有1~2 层的神经网络来说还可以接受. 但对于深度神经网络来说, 工作量就会变得非常恐怖了.  PyTorch 通过引入计算图, 来实现自动的梯度计算.</p>
<p>计算图的节点是输入张量, 边是计算输出张量的函数. 例如假设 x 是一个输入张量, 那么 x.grad 里面将用于存放输出的标量相对于 x 的梯度.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br>dtype = torch.<span class="hljs-built_in">float</span><br>device = torch.accelerator.current_accelerator().<span class="hljs-built_in">type</span> <span class="hljs-keyword">if</span> torch.accelerator.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;device&#125;</span> device&quot;</span>)<br>torch.set_default_device(device)<br><br>x = torch.linspace(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2000</span>, dtype=dtype)<br>y = torch.exp(x) <span class="hljs-comment"># 泰勒展开式为1 + x + (1/2) x**2 + (1/3!) x**3 + ...</span><br><br>a = torch.randn((), dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.randn((), dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>c = torch.randn((), dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>d = torch.randn((), dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br><br>initial_loss = <span class="hljs-number">1.</span><br>learning_rate = <span class="hljs-number">1e-5</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5000</span>):<br>    y_pred = a + b * x + c * x ** <span class="hljs-number">2</span> + d * x ** <span class="hljs-number">3</span><br><br>    <span class="hljs-comment"># 损失为方差和</span><br>    loss = (y_pred - y).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br><br>    <span class="hljs-comment"># 保存初始损失, 以便可以比对训练过程中的损失值下降情况</span><br>    <span class="hljs-keyword">if</span> t==<span class="hljs-number">0</span>:<br>        initial_loss=loss.item()<br><br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Iteration t = <span class="hljs-subst">&#123;t:4d&#125;</span>  loss(t)/loss(0) = <span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(loss.item()/initial_loss, <span class="hljs-number">6</span>):<span class="hljs-number">10.6</span>f&#125;</span>  a = <span class="hljs-subst">&#123;a.item():<span class="hljs-number">10.6</span>f&#125;</span>  b = <span class="hljs-subst">&#123;b.item():<span class="hljs-number">10.6</span>f&#125;</span>  c = <span class="hljs-subst">&#123;c.item():<span class="hljs-number">10.6</span>f&#125;</span>  d = <span class="hljs-subst">&#123;d.item():<span class="hljs-number">10.6</span>f&#125;</span>&#x27;</span>)<br>        <br>    <span class="hljs-comment"># 自动计算梯度</span><br>    loss.backward()<br><br>    <span class="hljs-comment"># 手动更新参数, 注意:此处的 grad 不再是手动计算, 而 backward 时自动计算并存储在 grad 属性中</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        a -= learning_rate * a.grad<br>        b -= learning_rate * b.grad<br>        c -= learning_rate * c.grad<br>        d -= learning_rate * d.grad<br><br>        <span class="hljs-comment"># 重置梯度</span><br>        a.grad = <span class="hljs-literal">None</span><br>        b.grad = <span class="hljs-literal">None</span><br>        c.grad = <span class="hljs-literal">None</span><br>        d.grad = <span class="hljs-literal">None</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;a.item()&#125;</span> + <span class="hljs-subst">&#123;b.item()&#125;</span> x + <span class="hljs-subst">&#123;c.item()&#125;</span> x^2 + <span class="hljs-subst">&#123;d.item()&#125;</span> x^3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="%E8%87%AA%E5%AE%9A%E4%B9%89-autograd" tabindex="-1" id="自定义-autograd">自定义 autograd</h2>
<p>autograd 运算符实际由两个函数构成,一个是前向传播函数, 它根据输入计算输出. 一个是反向传播函数, 它根据输出张量相某个标量损失的梯度计算输入张量相对同一个标量损失的梯度.</p>
<p>通过继承 torch.autograd.Function 可以自定义 autograd 运算符, 只需实现 forward 和 backward 函数即可.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LegendrePolynomial3</span>(torch.autograd.Function):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    通过继承 torch.autograd.Function 类，并实现其中的前向传播和反向传播方法来创建自定义的自动求导函数。这些方法操作的是张量</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">ctx, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        在前向传播中，会接收到一个包含输入数据的张量，并返回一个包含输出结果的张量。ctx是一个上下文对象，可用于暂存反向传播计算所需的信息。可以通过 ctx.save_for_backward方法缓存张量以供反向传播使用。其他对象可以直接作为 ctx对象的属性存储，例如 ctx.my_object = my_object</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        ctx.save_for_backward(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * (<span class="hljs-number">5</span> * <span class="hljs-built_in">input</span> ** <span class="hljs-number">3</span> - <span class="hljs-number">3</span> * <span class="hljs-built_in">input</span>)<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">ctx, grad_output</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        在反向传播中，会接收到一个包含损失相对于输出梯度的张量，然后需要计算损失相对于输入的梯度。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">input</span>, = ctx.saved_tensors<br>        <span class="hljs-keyword">return</span> grad_output * <span class="hljs-number">1.5</span> * (<span class="hljs-number">5</span> * <span class="hljs-built_in">input</span> ** <span class="hljs-number">2</span> - <span class="hljs-number">1</span>)<br><br><br>dtype = torch.<span class="hljs-built_in">float</span><br>device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-comment"># device = torch.device(&quot;cuda:0&quot;)  # 使用 GPU</span><br><br><span class="hljs-comment"># 创建张量来存储输入和输出</span><br><span class="hljs-comment"># 默认情况下，requires_grad=False，这表示在反向传播过程中，我们不需要计算这些张量的梯度</span><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>, device=device, dtype=dtype)<br>y = torch.sin(x)<br><br>a = torch.full((), <span class="hljs-number">0.0</span>, device=device, dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.full((), -<span class="hljs-number">1.0</span>, device=device, dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>c = torch.full((), <span class="hljs-number">0.0</span>, device=device, dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br>d = torch.full((), <span class="hljs-number">0.3</span>, device=device, dtype=dtype, requires_grad=<span class="hljs-literal">True</span>)<br><br>learning_rate = <span class="hljs-number">5e-6</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br><br>    P3 = LegendrePolynomial3.apply<br>    y_pred = a + b * P3(c + d * x)<br><br>    loss = (y_pred - y).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss.item())<br><br>    loss.backward()<br><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        a -= learning_rate * a.grad<br>        b -= learning_rate * b.grad<br>        c -= learning_rate * c.grad<br>        d -= learning_rate * d.grad<br><br>        <span class="hljs-comment"># 重置梯度</span><br>        a.grad = <span class="hljs-literal">None</span><br>        b.grad = <span class="hljs-literal">None</span><br>        c.grad = <span class="hljs-literal">None</span><br>        d.grad = <span class="hljs-literal">None</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;a.item()&#125;</span> + <span class="hljs-subst">&#123;b.item()&#125;</span> * P3(<span class="hljs-subst">&#123;c.item()&#125;</span> + <span class="hljs-subst">&#123;d.item()&#125;</span> x)&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="nn-%E6%A8%A1%E5%9D%97" tabindex="-1" id="nn-模块">nn 模块</h2>
<p>相比 autograd 运算符, nn.Module 提供了一个更高层级的抽象, 以便能够更加便捷的构建神经网络, 它有点类似于网络中的层.</p>
<p>nn 库中包括一些模块(Modules) 同样是基于输入张量, 计算输出张量. 但它拥有一些内部状态, 例如包含可学习参数. nn 库还包含一些常用的损失函数.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>)<br>y = torch.sin(x)<br><br><span class="hljs-comment"># y = x + x^2 + x^3</span><br>p = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><span class="hljs-comment"># unsqueeze 用来给张量添加新维度, -1 表示新维度添加在最末尾, 添加后, 原本的 [2000,] 变成了 [2000, 1]</span><br>xu = x.unsqueeze(-<span class="hljs-number">1</span>)<br>xx = xu.<span class="hljs-built_in">pow</span>(p) <br><br><span class="hljs-comment"># 由于 p 的形状是 (3,), xu 的形状是 (2000, 1), pow 运算会触发广播, 使得最终的形状为 (2000, 3)</span><br><br><span class="hljs-comment"># nn.Sequential 可用来顺序组合多个层</span><br><span class="hljs-comment"># nn.Linear 线性层使用线性函数基于输入计算输出</span><br><span class="hljs-comment"># nn.Flatten 层将线性层的输出还原为一维张量, 以便跟最终的 y 的形状相同</span><br>model = torch.nn.Sequential(<br>    torch.nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>),<br>    torch.nn.Flatten(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>)<br><br><br><span class="hljs-comment"># 使用 nn 库中 的 MSE 函数作为损失函数</span><br>loss_fn = torch.nn.MSELoss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br><br>learning_rate = <span class="hljs-number">1e-6</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br><br>    y_pred = model(xx)<br><br>    loss = loss_fn(y_pred, y)<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss.item())<br><br>    <span class="hljs-comment"># 重置梯度</span><br>    model.zero_grad()<br><br>    <span class="hljs-comment"># 反向传播, 自动计算所有可学习参数的梯度</span><br>    loss.backward()<br><br>    <span class="hljs-comment"># 更新参数, 如果有使用优化器, 则此时可直接调用优化器的 step 方法自动完成参数更新</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters():<br>            param -= learning_rate * param.grad<br><br><br>linear_layer = model[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 对于线性层, 其参数的形式为 (weight, bias)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;linear_layer.bias.item()&#125;</span> + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">0</span>].item()&#125;</span> x + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">1</span>].item()&#125;</span> x^2 + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">2</span>].item()&#125;</span> x^3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="optim" tabindex="-1" id="optim">optim</h2>
<p>nn 库使用 optim 类实现对参数优化算法的封装</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>)<br>y = torch.sin(x)<br><br>p = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>xx = x.unsqueeze(-<span class="hljs-number">1</span>).<span class="hljs-built_in">pow</span>(p)<br><br>model = torch.nn.Sequential(<br>    torch.nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>),<br>    torch.nn.Flatten(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>)<br>loss_fn = torch.nn.MSELoss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br><br>learning_rate = <span class="hljs-number">1e-3</span><br><span class="hljs-comment"># 使用 RMSprop 算法作为优化器</span><br>optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br>    y_pred = model(xx)<br>    loss = loss_fn(y_pred, y)<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss.item())<br>    optimizer.zero_grad()<br>    loss.backward()<br><br>    <span class="hljs-comment"># 更新参数</span><br>    optimizer.step()<br><br><br>linear_layer = model[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: y = <span class="hljs-subst">&#123;linear_layer.bias.item()&#125;</span> + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">0</span>].item()&#125;</span> x + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">1</span>].item()&#125;</span> x^2 + <span class="hljs-subst">&#123;linear_layer.weight[:, <span class="hljs-number">2</span>].item()&#125;</span> x^3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="%E8%87%AA%E5%AE%9A%E4%B9%89-module" tabindex="-1" id="自定义-Module">自定义 Module</h2>
<p>继承 nn.Module, 实现 forward 方法返回输出张量即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Polynomial3</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.a = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.b = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.c = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.d = torch.nn.Parameter(torch.randn(()))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.a + <span class="hljs-variable language_">self</span>.b * x + <span class="hljs-variable language_">self</span>.c * x ** <span class="hljs-number">2</span> + <span class="hljs-variable language_">self</span>.d * x ** <span class="hljs-number">3</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">string</span>(<span class="hljs-params">self</span>):<br>		<span class="hljs-comment"># 可以添加一些自定义方法</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;y = <span class="hljs-subst">&#123;self.a.item()&#125;</span> + <span class="hljs-subst">&#123;self.b.item()&#125;</span> x + <span class="hljs-subst">&#123;self.c.item()&#125;</span> x^2 + <span class="hljs-subst">&#123;self.d.item()&#125;</span> x^3&#x27;</span><br><br><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>)<br>y = torch.sin(x)<br><br>model = Polynomial3()<br><br><span class="hljs-comment"># 创建损失函数和优化器</span><br>criterion = torch.nn.MSELoss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-6</span>)<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):<br>    y_pred = model(x)<br>    loss = criterion(y_pred, y)<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>        <span class="hljs-built_in">print</span>(t, loss.item())<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: <span class="hljs-subst">&#123;model.string()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="%E6%8E%A7%E5%88%B6%E6%B5%81%2B%E6%9D%83%E9%87%8D%E5%85%B1%E4%BA%AB" tabindex="-1" id="控制流-权重共享">控制流+权重共享</h2>
<p>在前向传播中引入条件分支, 这会导致不同的计算图路径. 由于 Pytorch 会动态构建计算图, 因此能够很好的支持这种条件分支.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> math<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DynamicNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.a = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.b = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.c = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.d = torch.nn.Parameter(torch.randn(()))<br>        <span class="hljs-variable language_">self</span>.e = torch.nn.Parameter(torch.randn(()))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y = <span class="hljs-variable language_">self</span>.a + <span class="hljs-variable language_">self</span>.b * x + <span class="hljs-variable language_">self</span>.c * x ** <span class="hljs-number">2</span> + <span class="hljs-variable language_">self</span>.d * x ** <span class="hljs-number">3</span><br>        <span class="hljs-keyword">for</span> exp <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>, random.randint(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>)):<br>            y = y + <span class="hljs-variable language_">self</span>.e * x ** exp <span class="hljs-comment"># exp 的取值范围为 4 或 5, 随机的</span><br>        <span class="hljs-keyword">return</span> y<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">string</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;y = <span class="hljs-subst">&#123;self.a.item()&#125;</span> + <span class="hljs-subst">&#123;self.b.item()&#125;</span> x + <span class="hljs-subst">&#123;self.c.item()&#125;</span> x^2 + <span class="hljs-subst">&#123;self.d.item()&#125;</span> x^3 + <span class="hljs-subst">&#123;self.e.item()&#125;</span> x^4 ? + <span class="hljs-subst">&#123;self.e.item()&#125;</span> x^5 ?&#x27;</span><br><br><br>x = torch.linspace(-math.pi, math.pi, <span class="hljs-number">2000</span>)<br>y = torch.sin(x)<br><br>model = DynamicNet()<br><br>criterion = torch.nn.MSELoss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-8</span>, momentum=<span class="hljs-number">0.9</span>)<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30000</span>):<br>    y_pred = model(x)<br>    loss = criterion(y_pred, y)<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:<br>        <span class="hljs-built_in">print</span>(t, loss.item())<br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Result: <span class="hljs-subst">&#123;model.string()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h1 id="%E6%A2%AF%E5%BA%A6" tabindex="-1">梯度</h1>
<h2 id="requires_grad" tabindex="-1" id="requires-grad">requires_grad</h2>
<p>假设存在以下示例网络:</p>

    <span id="mjx-1176244">
      <style>
      #mjx-1176244{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="22.626ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 10000.8 1037.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(954,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1420,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2222.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3278.3,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(4037.3,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4503.3,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(5184.3,0)"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mo" transform="translate(5951.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6340.3,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(6912.3,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(8182.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(9182.8,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(9611.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>y</mi><mrow data-mjx-texclass="ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>x</mi><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>
    </span>
  
    <span id="mjx-5303c6e">
      <style>
      #mjx-5303c6e{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="18.398ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 8132 1037.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(958.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2014.6,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(3065.6,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(3710.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(4474.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4863.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(954,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1420,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6808.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7253,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7743,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>L</mi><mo>=</mo><mi>M</mi><mi>S</mi><mi>E</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow data-mjx-texclass="ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>
    </span>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tensor setup</span><br>x = torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)                      <span class="hljs-comment"># input with shape: (1, 3)</span><br>W = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># weights with shape: (3, 2)</span><br>b = torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># bias with shape: (1, 2)</span><br>y = torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)                      <span class="hljs-comment"># output with shape: (1, 2)</span><br><br><span class="hljs-comment"># forward pass</span><br>z = (x @ W) + b                           <span class="hljs-comment"># pre-activation with shape: (1, 2)</span><br>y_pred = F.relu(z)                        <span class="hljs-comment"># activation with shape: (1, 2)</span><br>loss = F.mse_loss(y_pred, y)              <span class="hljs-comment"># scalar loss</span><br></code></pre></td></tr></table></figure>

    <span id="mjx-7e403cb">
      <style>
      #mjx-7e403cb{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.313ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 11188.3 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D432" d="M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z"></path></g></g><g data-mml-node="mo" transform="translate(884.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1940.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D41F" d="M308 0Q290 3 172 3Q58 3 49 0H40V62H109V382H42V444H109V503L110 562L112 572Q127 625 178 658T316 699Q318 699 330 699T348 700Q381 698 404 687T436 658T449 629T452 606Q452 576 432 557T383 537Q355 537 335 555T314 605Q314 635 328 649H325Q311 649 293 644T253 618T227 560Q226 555 226 498V444H340V382H232V62H318V0H308Z"></path></g></g><g data-mml-node="mi" transform="translate(384,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mrow" transform="translate(2909.6,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D41F" d="M308 0Q290 3 172 3Q58 3 49 0H40V62H109V382H42V444H109V503L110 562L112 572Q127 625 178 658T316 699Q318 699 330 699T348 700Q381 698 404 687T436 658T449 629T452 606Q452 576 432 557T383 537Q355 537 335 555T314 605Q314 635 328 649H325Q311 649 293 644T253 618T227 560Q226 555 226 498V444H340V382H232V62H318V0H308Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(384,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1299,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2261.8,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="msub" transform="translate(1727.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D41F" d="M308 0Q290 3 172 3Q58 3 49 0H40V62H109V382H42V444H109V503L110 562L112 572Q127 625 178 658T316 699Q318 699 330 699T348 700Q381 698 404 687T436 658T449 629T452 606Q452 576 432 557T383 537Q355 537 335 555T314 605Q314 635 328 649H325Q311 649 293 644T253 618T227 560Q226 555 226 498V444H340V382H232V62H318V0H308Z"></path></g></g><g data-mml-node="mn" transform="translate(384,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2515.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2904.2,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mo" transform="translate(3511.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4066.9,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(5238.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(7889.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">y</mi></mrow><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">f</mi></mrow><mi>k</mi></msub><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">f</mi></mrow><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mo>…</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">f</mi></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo><mo>…</mo><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>
    </span>
  
    <span id="mjx-8fb0a6a">
      <style>
      #mjx-8fb0a6a{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -2.023ex;" xmlns="http://www.w3.org/2000/svg" width="31.495ex" height="5.17ex" role="img" focusable="false" viewBox="0 -1391 13920.6 2285" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(278.5,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g><rect width="1373" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1890.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2946.6,0)"><g data-mml-node="mrow" transform="translate(671.8,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1299,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g><rect width="2611.1" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6019.9,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mfrac" transform="translate(6520.1,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1299,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1299,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g><rect width="2611.1" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(9593.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(10093.6,0)"><path data-c="22EF" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path></g><g data-mml-node="mo" transform="translate(11487.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mfrac" transform="translate(11988.1,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(379.8,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g><rect width="1692.6" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>∂</mi><mi>y</mi></mrow><mrow><mi>∂</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>∂</mi><msub><mi>f</mi><mi>k</mi></msub></mrow><mrow><mi>∂</mi><msub><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi>∂</mi><msub><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><mrow><mi>∂</mi><msub><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow></mfrac><mo>⋅</mo><mo>⋯</mo><mo>⋅</mo><mfrac><mrow><mi>∂</mi><msub><mi>f</mi><mn>1</mn></msub></mrow><mrow><mi>∂</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></mrow></mfrac></math></mjx-assistive-mml></mjx-container>
    </span>
  <p>前向传播之后生成的计算图:</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251212154501.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>如果一个节点不是由带 requires_grad=True 的张量计算出来的, 那么它就是一个叶子节点, 否则就是非叶子节点. 对于非叶子节点, 其 requires_grad=True 必然是 True, 不然反向传播就无法成功了. 对于叶子节点, 则在初始化时, 需要显式的设置参数 requires_grad=True (默认是 False, 如果初始化时没有设置, 可通过调用 requires_grad_() 方法后补)</p>
<h2 id="retain_grad" tabindex="-1" id="retain-grad">retain_grad</h2>
<p>在反向传播时,非叶子节点的梯度是会计算的, 但是不会保存在非叶子节点(张量)的 .grad 属性上, 因此它无法使用 .grad 直接访问. 除非显式的设置参数 retain_grad=True</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">z = (x @ W) + b<br>y_pred = F.relu(z)<br>loss = F.mse_loss(y_pred, y)<br><br><span class="hljs-comment"># 显式要求保存这几个张量的梯度</span><br>z.retain_grad()<br>y_pred.retain_grad()<br>loss.retain_grad()<br><br><span class="hljs-comment"># 重置(避免累积)</span><br>W.grad = <span class="hljs-literal">None</span><br>b.grad = <span class="hljs-literal">None</span><br><br>loss.backward()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;W.grad=&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;b.grad=&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;z.grad=&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;y_pred.grad=&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;loss.grad=&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">W.grad=tensor([[3., 3.],<br>        [3., 3.],<br>        [3., 3.]])<br>b.grad=tensor([[3., 3.]])<br>z.grad=tensor([[3., 3.]])<br>y_pred.grad=tensor([[3., 3.]])<br>loss.grad=tensor(1.)<br></code></pre></td></tr></table></figure>
<p>对于叶子节点, 如果 requires_grad=True, 那么默认是保存梯度的. 此时再额外调用 <code>retain_grad()</code> 属于冗余的操作. 但如果叶子节点的 requires_grad=False 的话, 那么调用 retain_grad() 方法会报错, 因为该节点的梯度不会被计算, 因此自然也无法保存. 所以说,  retain_grad() 只在非叶子节点的场景中使用.</p>
<h1 id="%E4%B8%BB%E5%AD%98%E5%88%B0%E6%98%BE%E5%AD%98" tabindex="-1">主存到显存</h1>
<p>主存是分块的, 当 OS 尝试从某个主存块中读取数据却找不到时, 会触发触常, 然后 OS 会从磁盘加载数据到内存中. 同理, 此时如果主存已满, 则 OS 会将部分数据移动到磁盘上, 以便主存能够腾出空间容纳新的数据.</p>
<blockquote>
<p>分块的目的是为了能够更充分的利用内存空间, 但是代价是数据的物理内存地址可能不连续. 此时将无法充分发挥 DMA 的效率, 导致将数据复制到 GPU 前需要多一次整理的动作(将数据先复制到缓冲区, 再从缓冲区复制到 GPU), 带来了额外的开锁.</p>
</blockquote>
<p>数据在内存中也可以显式设置为固定类型(页锁定, pin_memory), 对于页锁定内在, 它不会被交换到磁盘.</p>
<p>当 OS 加载一个文件时, 它并不会一下子将所有数据都加载到内存中, 而是等到使用时, 如果内存中找不到, 才会触发数据的加载. 当尝试将数据从主存复制到 GPU 的显存时, 由于数据有可能不在主存中, 而是在磁盘中. 为避免等待 IO, 这个复制过程通常是异步的, non_blocking=True</p>
<p>从页锁定的主存中复制数据会更快, 因为数据已经提前加载到内存中了. 同时由于物理地址连续, 可以直接使用 DMA 读取.</p>
<p>数据从主存复制到显存时, CUDA 会自动处理好数据同步问题, 不会出现要读取数据时, 数据却不存在导致报错的情况. 反之, 如果是将数据从显存拷贝到主存, 则需要手工同步一下, 才能保证读取数据前, 数据已经拷贝完成.</p>
<h1 id="%E6%A2%AF%E5%BA%A6%E5%8F%AF%E8%A7%86%E5%8C%96" tabindex="-1">梯度可视化</h1>
<p>方便排查处理训练过程中出现的梯度消失或梯度爆炸问题.</p>
<p>示例: 设计两个简单的模型, 一个使用 BatchNorm, 一个没有使用. 并跟踪梯度变化, 以便观察 BatchNorm 能否缓解梯度消失问题.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">fc_layer</span>(<span class="hljs-params">in_size, out_size, norm_layer</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Return a stack of linear-&gt;norm-&gt;sigmoid layers&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> nn.Sequential(nn.Linear(in_size, out_size), norm_layer(out_size), nn.Sigmoid())<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Define a network that has num_layers of linear-&gt;norm-&gt;sigmoid transformations&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_size=<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, hidden_size=<span class="hljs-number">128</span>,</span><br><span class="hljs-params">                 out_size=<span class="hljs-number">10</span>, num_layers=<span class="hljs-number">3</span>, batchnorm=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">if</span> batchnorm <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>:<br>            norm_layer = nn.Identity<br>        <span class="hljs-keyword">else</span>:<br>            norm_layer = nn.BatchNorm1d<br><br>        layers = []<br>        layers.append(fc_layer(in_size, hidden_size, norm_layer))<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers-<span class="hljs-number">1</span>):<br>            layers.append(fc_layer(hidden_size, hidden_size, norm_layer))<br><br>        layers.append(nn.Linear(hidden_size, out_size))<br><br>        <span class="hljs-variable language_">self</span>.layers = nn.Sequential(*layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.layers(x)<br></code></pre></td></tr></table></figure>
<p>初始化数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># set up dummy data</span><br>x = torch.randn(<span class="hljs-number">10</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br>y = torch.randint(<span class="hljs-number">10</span>, (<span class="hljs-number">10</span>, ))<br><br><span class="hljs-comment"># init model</span><br>model_bn = Net(batchnorm=<span class="hljs-literal">True</span>, num_layers=<span class="hljs-number">3</span>)<br>model_nobn = Net(batchnorm=<span class="hljs-literal">False</span>, num_layers=<span class="hljs-number">3</span>)<br><br>model_bn.train()<br>model_nobn.train()<br><br>optimizer_bn = optim.SGD(model_bn.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)<br>optimizer_nobn = optim.SGD(model_nobn.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(model_bn.layers[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(model_nobn.layers[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">Sequential(<br>  (0): Linear(in_features=784, out_features=128, bias=True)<br>  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br>  (2): Sigmoid()<br>)<br>Sequential(<br>  (0): Linear(in_features=784, out_features=128, bias=True)<br>  (1): Identity()<br>  (2): Sigmoid()<br>)<br></code></pre></td></tr></table></figure>
<h2 id="%E6%B3%A8%E5%86%8C%E9%92%A9%E5%AD%90" tabindex="-1" id="注册钩子">注册钩子</h2>
<p>为了能够读取中间状态的数据, 相比使用 retain_grad(), 更推荐的方法是注册反向传播钩子(backward pass hook).</p>
<p>定义钩子:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">hook_forward</span>(<span class="hljs-params">module_name, grads, hook_backward</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">hook</span>(<span class="hljs-params">module, args, output</span>):<br>        <span class="hljs-comment"># 在前向传播过程中, 为每个输出张量注册反向钩子</span><br>        output.register_hook(hook_backward(module_name, grads))<br>    <span class="hljs-keyword">return</span> hook<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hook_backward</span>(<span class="hljs-params">module_name, grads</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">hook</span>(<span class="hljs-params">grad</span>):<br>        <span class="hljs-comment"># 反向传播钩子, 用来收集梯度</span><br>        grads.append((module_name, grad))<br>    <span class="hljs-keyword">return</span> hook<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_all_layers</span>(<span class="hljs-params">model, hook_forward, hook_backward</span>):<br>    layers = <span class="hljs-built_in">dict</span>()<br>    grads = []<br>    <span class="hljs-keyword">for</span> name, layer <span class="hljs-keyword">in</span> model.named_modules():<br>        <span class="hljs-comment"># 仅处理叶子模块(没有子模块)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(layer.children()) <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>:<br>            layers[layer] = name<br>            layer.register_forward_hook(hook_forward(name, grads, hook_backward))<br>    <span class="hljs-keyword">return</span> layers, grads<br><br>layers_bn, grads_bn = get_all_layers(model_bn, hook_forward, hook_backward)<br>layers_nobn, grads_nobn = get_all_layers(model_nobn, hook_forward, hook_backward)<br></code></pre></td></tr></table></figure>
<p>训练并可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">epochs = <span class="hljs-number">10</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br><br>    <span class="hljs-comment"># 每轮训练前先清空, 避免累积</span><br>    grads_bn.clear()<br>    grads_nobn.clear()<br><br>    optimizer_bn.zero_grad()<br>    optimizer_nobn.zero_grad()<br><br>    y_pred_bn = model_bn(x)<br>    y_pred_nobn = model_nobn(x)<br><br>    loss_bn = F.cross_entropy(y_pred_bn, y)<br>    loss_nobn = F.cross_entropy(y_pred_nobn, y)<br><br>    loss_bn.backward()<br>    loss_nobn.backward()<br><br>    optimizer_bn.step()<br>    optimizer_nobn.step()<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_grads</span>(<span class="hljs-params">grads</span>):<br>    layer_idx = []<br>    avg_grads = []<br>    <span class="hljs-keyword">for</span> idx, (name, grad) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(grads):<br>        <span class="hljs-keyword">if</span> grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            avg_grad = grad.<span class="hljs-built_in">abs</span>().mean()<br>            avg_grads.append(avg_grad)<br>            <span class="hljs-comment"># idx is backwards since we appended in backward pass</span><br>            layer_idx.append(<span class="hljs-built_in">len</span>(grads) - <span class="hljs-number">1</span> - idx)<br>    <span class="hljs-keyword">return</span> layer_idx, avg_grads<br><br>layer_idx_bn, avg_grads_bn = get_grads(grads_bn)<br>layer_idx_nobn, avg_grads_nobn = get_grads(grads_nobn)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">fig, ax = plt.subplots()<br>ax.plot(layer_idx_bn, avg_grads_bn, label=<span class="hljs-string">&quot;With BatchNorm&quot;</span>, marker=<span class="hljs-string">&quot;o&quot;</span>)<br>ax.plot(layer_idx_nobn, avg_grads_nobn, label=<span class="hljs-string">&quot;Without BatchNorm&quot;</span>, marker=<span class="hljs-string">&quot;x&quot;</span>)<br>ax.set_xlabel(<span class="hljs-string">&quot;Layer depth&quot;</span>)<br>ax.set_ylabel(<span class="hljs-string">&quot;Average gradient&quot;</span>)<br>ax.set_title(<span class="hljs-string">&quot;Gradient flow&quot;</span>)<br>ax.grid(<span class="hljs-literal">True</span>)<br>ax.legend()<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251213164504.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h1 id="%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83" tabindex="-1">分布式训练</h1>
<h2 id="ddp" tabindex="-1" id="DDP">DDP</h2>
<p>数据并行, 每张显卡部署相同的模型和优化器. 每张显卡训练的数据不同, 因此在更新参数前, 需要先同步数据, 之后再统一更新参数, 确保更新后的模型参数是每张显卡上面是一样的.</p>
<blockquote>
<p>DistributedSampler 可用来确保每张显卡获得的数据不重复</p>
</blockquote>
<p>数据的同步是可以并行的, 例如有 4 张显卡, 每次同步 1/4 到另外一张显卡上. 通过使用环状同步, 可以实现同步的并行.</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251213172850.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>相较早期更简单的 DataParallel, DDP 的性能更好一些, 二者的对比如下:</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>DataParallel</th>
<th>DistributedDataParallel</th>
</tr>
</thead>
<tbody>
<tr>
<td>开销</td>
<td>更大；模型在每次前向传播时都会被复制并销毁</td>
<td>模型仅复制一次</td>
</tr>
<tr>
<td>并行支持</td>
<td>仅支持单机并行</td>
<td>支持扩展到多台机器</td>
</tr>
<tr>
<td>性能</td>
<td>速度较慢；在单个进程中使用多线程，会遇到全局解释器锁（GIL）竞争</td>
<td>速度更快（无 GIL 竞争），因为它使用多进程</td>
</tr>
</tbody>
</table>
<p>以下是单 GPU 训练时的代码脚本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> datautils <span class="hljs-keyword">import</span> MyTrainDataset<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        model: torch.nn.Module,</span><br><span class="hljs-params">        train_data: DataLoader,</span><br><span class="hljs-params">        optimizer: torch.optim.Optimizer,</span><br><span class="hljs-params">        gpu_id: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        save_every: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.gpu_id = gpu_id<br>        <span class="hljs-variable language_">self</span>.model = model.to(gpu_id)<br>        <span class="hljs-variable language_">self</span>.train_data = train_data<br>        <span class="hljs-variable language_">self</span>.optimizer = optimizer<br>        <span class="hljs-variable language_">self</span>.save_every = save_every<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_batch</span>(<span class="hljs-params">self, source, targets</span>):<br>        <span class="hljs-variable language_">self</span>.optimizer.zero_grad()<br>        output = <span class="hljs-variable language_">self</span>.model(source)<br>        loss = F.cross_entropy(output, targets)<br>        loss.backward()<br>        <span class="hljs-variable language_">self</span>.optimizer.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_epoch</span>(<span class="hljs-params">self, epoch</span>):<br>        b_sz = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(<span class="hljs-variable language_">self</span>.train_data))[<span class="hljs-number">0</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[GPU<span class="hljs-subst">&#123;self.gpu_id&#125;</span>] Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Batchsize: <span class="hljs-subst">&#123;b_sz&#125;</span> | Steps: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(self.train_data)&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">for</span> source, targets <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.train_data:<br>            source = source.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            targets = targets.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            <span class="hljs-variable language_">self</span>._run_batch(source, targets)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_save_checkpoint</span>(<span class="hljs-params">self, epoch</span>):<br>        ckp = <span class="hljs-variable language_">self</span>.model.state_dict()<br>        PATH = <span class="hljs-string">&quot;checkpoint.pt&quot;</span><br>        torch.save(ckp, PATH)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Training checkpoint saved at <span class="hljs-subst">&#123;PATH&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, max_epochs: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_epochs):<br>            <span class="hljs-variable language_">self</span>._run_epoch(epoch)<br>            <span class="hljs-keyword">if</span> epoch % <span class="hljs-variable language_">self</span>.save_every == <span class="hljs-number">0</span>:<br>                <span class="hljs-variable language_">self</span>._save_checkpoint(epoch)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_train_objs</span>():<br>    train_set = MyTrainDataset(<span class="hljs-number">2048</span>)  <span class="hljs-comment"># 虚拟一份数据集</span><br>    model = torch.nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 用一个线性层模拟待训练模型</span><br>    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>    <span class="hljs-keyword">return</span> train_set, model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>(<span class="hljs-params">dataset: Dataset, batch_size: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">return</span> DataLoader(<br>        dataset,<br>        batch_size=batch_size,<br>        pin_memory=<span class="hljs-literal">True</span>,<br>        shuffle=<span class="hljs-literal">True</span><br>    )<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">device, total_epochs, save_every, batch_size</span>):<br>    dataset, model, optimizer = load_train_objs()<br>    train_data = prepare_dataloader(dataset, batch_size)<br>    trainer = Trainer(model, train_data, optimizer, device, save_every)<br>    trainer.train(total_epochs)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> argparse<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;simple distributed training job&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;total_epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Total epochs to train the model&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;save_every&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;How often to save a snapshot&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch_size&#x27;</span>, default=<span class="hljs-number">32</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Input batch size on each device (default: 32)&#x27;</span>)<br>    args = parser.parse_args()<br>    <br>    device = <span class="hljs-number">0</span>  <span class="hljs-comment"># shorthand for cuda:0</span><br>    main(device, args.total_epochs, args.save_every, args.batch_size)<br></code></pre></td></tr></table></figure>
<p>以下是切换到 DDP 模式进行训练的脚本:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> datautils <span class="hljs-keyword">import</span> MyTrainDataset<br><br><span class="hljs-comment"># 引入一些新的库</span><br><span class="hljs-keyword">import</span> torch.multiprocessing <span class="hljs-keyword">as</span> mp <span class="hljs-comment"># 多线程管理不同的 GPU</span><br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler <span class="hljs-comment"># 按 GPU 切分数据</span><br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP <span class="hljs-comment"># 数据并行</span><br><span class="hljs-keyword">from</span> torch.distributed <span class="hljs-keyword">import</span> init_process_group, destroy_process_group <span class="hljs-comment"># 进程管理</span><br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 设置 DDP 的参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ddp_setup</span>(<span class="hljs-params">rank, world_size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        rank: Unique identifier of each process 每个线程的识别代号</span><br><span class="hljs-string">        world_size: Total number of processes 进程总数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    os.environ[<span class="hljs-string">&quot;MASTER_ADDR&quot;</span>] = <span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-comment"># 因为是一机多卡, 所以 IP 地址是自己</span><br>    os.environ[<span class="hljs-string">&quot;MASTER_PORT&quot;</span>] = <span class="hljs-string">&quot;12355&quot;</span> <span class="hljs-comment"># 监听的端口</span><br>    torch.cuda.set_device(rank)<br>    <span class="hljs-comment"># 使用 nccl 库负责 CUDA GPU 间的通讯(XPU 用 xccl, CPU 用 gloo)</span><br>    <span class="hljs-comment"># init_process_group 负责初始化分布式训练的进程组</span><br>    init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        model: torch.nn.Module,</span><br><span class="hljs-params">        train_data: DataLoader,</span><br><span class="hljs-params">        optimizer: torch.optim.Optimizer,</span><br><span class="hljs-params">        gpu_id: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        save_every: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.gpu_id = gpu_id<br>        <span class="hljs-variable language_">self</span>.model = model.to(gpu_id)<br>        <span class="hljs-variable language_">self</span>.train_data = train_data<br>        <span class="hljs-variable language_">self</span>.optimizer = optimizer<br>        <span class="hljs-variable language_">self</span>.save_every = save_every<br>        <span class="hljs-variable language_">self</span>.model = DDP(model, device_ids=[gpu_id]) <span class="hljs-comment"># 用 DDP 对 model 进行封装</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_batch</span>(<span class="hljs-params">self, source, targets</span>):<br>        <span class="hljs-variable language_">self</span>.optimizer.zero_grad()<br>        output = <span class="hljs-variable language_">self</span>.model(source)<br>        loss = F.cross_entropy(output, targets)<br>        loss.backward()<br>        <span class="hljs-variable language_">self</span>.optimizer.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_epoch</span>(<span class="hljs-params">self, epoch</span>):<br>        b_sz = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(<span class="hljs-variable language_">self</span>.train_data))[<span class="hljs-number">0</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[GPU<span class="hljs-subst">&#123;self.gpu_id&#125;</span>] Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Batchsize: <span class="hljs-subst">&#123;b_sz&#125;</span> | Steps: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(self.train_data)&#125;</span>&quot;</span>)<br>        <span class="hljs-variable language_">self</span>.train_data.sampler.set_epoch(epoch) <span class="hljs-comment"># 调用 set_epoch 模拟 shuffle</span><br>        <span class="hljs-keyword">for</span> source, targets <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.train_data:<br>            source = source.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            targets = targets.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            <span class="hljs-variable language_">self</span>._run_batch(source, targets)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_save_checkpoint</span>(<span class="hljs-params">self, epoch</span>):<br>        ckp = <span class="hljs-variable language_">self</span>.model.module.state_dict()<br>        PATH = <span class="hljs-string">&quot;checkpoint.pt&quot;</span><br>        torch.save(ckp, PATH)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Training checkpoint saved at <span class="hljs-subst">&#123;PATH&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, max_epochs: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_epochs):<br>            <span class="hljs-variable language_">self</span>._run_epoch(epoch)<br>            <span class="hljs-comment"># 仅让一个 GPU 负责保存模型参数即可, 毕竟所有 GPU 上的模型是相同的, 没必要重复保存</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.gpu_id == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> epoch % <span class="hljs-variable language_">self</span>.save_every == <span class="hljs-number">0</span>:<br>                <span class="hljs-variable language_">self</span>._save_checkpoint(epoch)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_train_objs</span>():<br>    train_set = MyTrainDataset(<span class="hljs-number">2048</span>)  <br>    model = torch.nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>) <br>    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>    <span class="hljs-keyword">return</span> train_set, model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>(<span class="hljs-params">dataset: Dataset, batch_size: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">return</span> DataLoader(<br>        dataset,<br>        batch_size=batch_size,<br>        pin_memory=<span class="hljs-literal">True</span>,<br>        shuffle=<span class="hljs-literal">False</span>, <span class="hljs-comment"># 关闭 shuffle</span><br>        sampler=DistributedSampler(dataset) <span class="hljs-comment"># 使用 DistributedSampler 切分训练数据</span><br>    )<br><br><span class="hljs-comment"># 增加了 rank 和 world_size 参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">rank: <span class="hljs-built_in">int</span>, world_size: <span class="hljs-built_in">int</span>, save_every: <span class="hljs-built_in">int</span>, total_epochs: <span class="hljs-built_in">int</span>, batch_size: <span class="hljs-built_in">int</span></span>):<br>    ddp_setup(rank, world_size) <span class="hljs-comment"># 初始化 DDP</span><br>    dataset, model, optimizer = load_train_objs()<br>    train_data = prepare_dataloader(dataset, batch_size)<br>    trainer = Trainer(model, train_data, optimizer, rank, save_every) <span class="hljs-comment"># 用 rank 替换 device</span><br>    trainer.train(total_epochs)<br>    destroy_process_group() <span class="hljs-comment"># 训练结束后销毁进程</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> argparse<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;simple distributed training job&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;total_epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Total epochs to train the model&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;save_every&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;How often to save a snapshot&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch_size&#x27;</span>, default=<span class="hljs-number">32</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Input batch size on each device (default: 32)&#x27;</span>)<br>    args = parser.parse_args()<br><br>    world_size = torch.cuda.device_count() <span class="hljs-comment"># 获取可用的 GPU 数量</span><br>    mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size) <span class="hljs-comment"># 孵化多个进程</span><br></code></pre></td></tr></table></figure>
<h3 id="%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86" tabindex="-1" id="异常处理">异常处理</h3>
<p>由于涉及多节点多进程多个 GPU, 训练过程中出现异常的概率会大幅上升. 为避免出现中断导致从头开始训练, 需要引入一个从中断处继续训练的机制. 可使用  pytorch torchrun 提供的 snapshot 功能, 为每轮训练保存快照, 这样当出现中断时, 就可以从快照中快速恢复.</p>
<blockquote>
<p>虽然每轮或每几轮会保存 checkpoint 检查点, 但是检查点只包括模型的参数, 没有保存中断前的整个状态, 例如epoch 轮次等. 因此需要使用 snapshot 来完整的恢复中断现场</p>
</blockquote>
<p>使用 torchrun 后的几个变化:</p>
<ul>
<li>无须手动设置 rank, world_size 等环境变量, torchrun 会自动计算</li>
<li>无须手动使用 mp.spawn 孵化多个进程, torchrun 会自动创建多个进程(单节点也可以适用)；</li>
</ul>
<p>当某个进程出现异常导致训练中断后, torchrun 会中断其他所有进程.  再次运行 torchrun 会从中断处继续训练, 损失多少取决于快照保存的时间间隔.</p>
<blockquote>
<p>在训练过程中, 如果添加或删除节点, torchrun 会自动在所有节点上重启所有进程, 无需手动干预</p>
</blockquote>
<p>引入 snapshot 后, 代码结构大致变成下面这个样子:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>  load_snapshot(snapshot_path) <span class="hljs-comment"># 运行时优先加载快照(如有)</span><br>  initialize()<br>  train()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>  <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">iter</span>(dataset):<br>    train_step(batch)<br><br>    <span class="hljs-keyword">if</span> should_checkpoint: <span class="hljs-comment"># 在训练过程中设置保存快照的条件</span><br>      save_snapshot(snapshot_path)<br></code></pre></td></tr></table></figure>
<p>以下是引入 torchrun 和 snapshot 后的代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> datautils <span class="hljs-keyword">import</span> MyTrainDataset<br><br><span class="hljs-keyword">import</span> torch.multiprocessing <span class="hljs-keyword">as</span> mp<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><span class="hljs-keyword">from</span> torch.distributed <span class="hljs-keyword">import</span> init_process_group, destroy_process_group<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># torchrun 会自动设置 RANK, 因此无需再手动配置 rank 和 world_size</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ddp_setup</span>():<br>    torch.cuda.set_device(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])) <span class="hljs-comment"># 使用 torchrun 设置的 RANK 环境变量</span><br>    init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        model: torch.nn.Module,</span><br><span class="hljs-params">        train_data: DataLoader,</span><br><span class="hljs-params">        optimizer: torch.optim.Optimizer,</span><br><span class="hljs-params">        save_every: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        snapshot_path: <span class="hljs-built_in">str</span>, <span class="hljs-comment"># 快照保存路径</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.gpu_id = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]) <span class="hljs-comment"># 使用 torchrun 设置的 RANK 环境变量</span><br>        <span class="hljs-variable language_">self</span>.model = model.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>        <span class="hljs-variable language_">self</span>.train_data = train_data<br>        <span class="hljs-variable language_">self</span>.optimizer = optimizer<br>        <span class="hljs-variable language_">self</span>.save_every = save_every<br>        <span class="hljs-variable language_">self</span>.epochs_run = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.snapshot_path = snapshot_path<br>        <span class="hljs-keyword">if</span> os.path.exists(snapshot_path): <span class="hljs-comment"># 如有快照, 优先加载, 而非从头开始</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading snapshot&quot;</span>)<br>            <span class="hljs-variable language_">self</span>._load_snapshot(snapshot_path)<br><br>        <span class="hljs-variable language_">self</span>.model = DDP(<span class="hljs-variable language_">self</span>.model, device_ids=[<span class="hljs-variable language_">self</span>.gpu_id])<br><br>    <span class="hljs-comment"># 加载快照    </span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_load_snapshot</span>(<span class="hljs-params">self, snapshot_path</span>):<br>        loc = <span class="hljs-string">f&quot;cuda:<span class="hljs-subst">&#123;self.gpu_id&#125;</span>&quot;</span><br>        snapshot = torch.load(snapshot_path, map_location=loc)<br>        <span class="hljs-comment"># 读取快照中的数据</span><br>        <span class="hljs-variable language_">self</span>.model.load_state_dict(snapshot[<span class="hljs-string">&quot;MODEL_STATE&quot;</span>])<br>        <span class="hljs-variable language_">self</span>.epochs_run = snapshot[<span class="hljs-string">&quot;EPOCHS_RUN&quot;</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Resuming training from snapshot at Epoch <span class="hljs-subst">&#123;self.epochs_run&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_batch</span>(<span class="hljs-params">self, source, targets</span>):<br>        <span class="hljs-variable language_">self</span>.optimizer.zero_grad()<br>        output = <span class="hljs-variable language_">self</span>.model(source)<br>        loss = F.cross_entropy(output, targets)<br>        loss.backward()<br>        <span class="hljs-variable language_">self</span>.optimizer.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_epoch</span>(<span class="hljs-params">self, epoch</span>):<br>        b_sz = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(<span class="hljs-variable language_">self</span>.train_data))[<span class="hljs-number">0</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[GPU<span class="hljs-subst">&#123;self.gpu_id&#125;</span>] Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Batchsize: <span class="hljs-subst">&#123;b_sz&#125;</span> | Steps: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(self.train_data)&#125;</span>&quot;</span>)<br>        <span class="hljs-variable language_">self</span>.train_data.sampler.set_epoch(epoch)<br>        <span class="hljs-keyword">for</span> source, targets <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.train_data:<br>            source = source.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            targets = targets.to(<span class="hljs-variable language_">self</span>.gpu_id)<br>            <span class="hljs-variable language_">self</span>._run_batch(source, targets)<br>    <br>    <span class="hljs-comment"># 保存快照, 取代 checkpoint 保存</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_save_snapshot</span>(<span class="hljs-params">self, epoch</span>):<br>        <span class="hljs-comment"># 保存 model.module.state_dict 和 epoch 两个值, 原 checkpoint 只保存了前者</span><br>        snapshot = &#123;<br>            <span class="hljs-string">&quot;MODEL_STATE&quot;</span>: <span class="hljs-variable language_">self</span>.model.module.state_dict(),<br>            <span class="hljs-string">&quot;EPOCHS_RUN&quot;</span>: epoch,<br>        &#125;<br>        torch.save(snapshot, <span class="hljs-variable language_">self</span>.snapshot_path)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Training snapshot saved at <span class="hljs-subst">&#123;self.snapshot_path&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, max_epochs: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-comment"># 从 epochs_run 处开始, 不再从 0 开始</span><br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-variable language_">self</span>.epochs_run, max_epochs):<br>            <span class="hljs-variable language_">self</span>._run_epoch(epoch)<br>            <span class="hljs-comment"># 按 save_every 保存快照(仅在 GPU:0 上面保存, 之前是保存 checkpoint)</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.gpu_id == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> epoch % <span class="hljs-variable language_">self</span>.save_every == <span class="hljs-number">0</span>:<br>                <span class="hljs-variable language_">self</span>._save_snapshot(epoch)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_train_objs</span>():<br>    train_set = MyTrainDataset(<span class="hljs-number">2048</span>)  <span class="hljs-comment"># load your dataset</span><br>    model = torch.nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># load your model</span><br>    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>    <span class="hljs-keyword">return</span> train_set, model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>(<span class="hljs-params">dataset: Dataset, batch_size: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">return</span> DataLoader(<br>        dataset,<br>        batch_size=batch_size,<br>        pin_memory=<span class="hljs-literal">True</span>,<br>        shuffle=<span class="hljs-literal">False</span>,<br>        sampler=DistributedSampler(dataset)<br>    )<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">save_every: <span class="hljs-built_in">int</span>, total_epochs: <span class="hljs-built_in">int</span>, batch_size: <span class="hljs-built_in">int</span>, snapshot_path: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;snapshot.pt&quot;</span></span>):<br>    ddp_setup()<br>    dataset, model, optimizer = load_train_objs()<br>    train_data = prepare_dataloader(dataset, batch_size)<br>    trainer = Trainer(model, train_data, optimizer, save_every, snapshot_path)<br>    trainer.train(total_epochs)<br>    destroy_process_group()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> argparse<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;simple distributed training job&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;total_epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Total epochs to train the model&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;save_every&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;How often to save a snapshot&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch_size&#x27;</span>, default=<span class="hljs-number">32</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Input batch size on each device (default: 32)&#x27;</span>)<br>    args = parser.parse_args()<br>	<span class="hljs-comment"># 直接调用 main 函数, 由 torchrun 进行调度, 不再需要手动 mp.spawn</span><br>    main(args.save_every, args.total_epochs, args.batch_size)<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">torchrun --standalone --nproc_per_node=4 multigpu_torchrun.py 50 10<br></code></pre></td></tr></table></figure>
<h3 id="%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AE%AD%E7%BB%83" tabindex="-1" id="多节点训练">多节点训练</h3>
<p>当使用多个节点时, 因为快照只保存在其中一台机器(节点)上, 因此当出现异常导致所有进程重启时, 所有节点都需要从该节点获取快照, 因此有两点很重要, 一是该节点的带宽尽量大一些； 二是确保 TCP 能够连通(注意检查防火墙设置)</p>
<blockquote>
<p>由于多节点需要通过网络进行通讯, 其带宽远小于相同节点多个 GPU 之间的通讯带宽, 因此 1 机多卡的训练速度要远大于多机单卡；</p>
</blockquote>
<p>有两种方法进行多节点的训练:</p>
<ul>
<li>在每个节点上面运行相同参数的 torchrun 命令；</li>
<li>创建一个集群, 然后使用一个管理器统一进行调度(例如 slurm)；</li>
</ul>
<p>在单节点场景中, gpu_id 来自 torchrun 设置的 LOCAL_RANK 环境变量. 在多点节场景中, 还需要使用 torchrun 设置的另外一个全局 RANK 环境变量, 以便唯一识别每个 GPU 进程.</p>
<blockquote>
<p>当出现异常导致 torchrun 重启所有进程时, 每个进程获得的 LOCAL_RANK 和 RANK 变量可能和之前的不同.</p>
</blockquote>
<p>torchrun 支持异构扩展, 即每个节点的 GPU 数量可以不同, 例如有些节点配备 4 个 GPU, 有些配备 2 个GPU</p>
<p>调试时, 可设置环境变量 NCCL_DEBUG=INFO, 这些可以查看详细的日志.</p>
<p>以下是使用多节点训练时的代码变更:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> datautils <span class="hljs-keyword">import</span> MyTrainDataset<br><br><span class="hljs-keyword">import</span> torch.multiprocessing <span class="hljs-keyword">as</span> mp<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><span class="hljs-keyword">from</span> torch.distributed <span class="hljs-keyword">import</span> init_process_group, destroy_process_group<br><span class="hljs-keyword">import</span> os<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ddp_setup</span>():<br>    torch.cuda.set_device(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]))<br>    init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        model: torch.nn.Module,</span><br><span class="hljs-params">        train_data: DataLoader,</span><br><span class="hljs-params">        optimizer: torch.optim.Optimizer,</span><br><span class="hljs-params">        save_every: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        snapshot_path: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]) <span class="hljs-comment"># 原 gpu_id 属性替换为 local_rank</span><br>        <span class="hljs-variable language_">self</span>.global_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;RANK&quot;</span>]) <span class="hljs-comment"># 此处使用 RANK 来唯一识别 GPU 进程</span><br>        <span class="hljs-variable language_">self</span>.model = model.to(<span class="hljs-variable language_">self</span>.local_rank)<br>        <span class="hljs-variable language_">self</span>.train_data = train_data<br>        <span class="hljs-variable language_">self</span>.optimizer = optimizer<br>        <span class="hljs-variable language_">self</span>.save_every = save_every<br>        <span class="hljs-variable language_">self</span>.epochs_run = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.snapshot_path = snapshot_path<br>        <span class="hljs-keyword">if</span> os.path.exists(snapshot_path):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading snapshot&quot;</span>)<br>            <span class="hljs-variable language_">self</span>._load_snapshot(snapshot_path)<br><br>        <span class="hljs-variable language_">self</span>.model = DDP(<span class="hljs-variable language_">self</span>.model, device_ids=[<span class="hljs-variable language_">self</span>.local_rank])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_load_snapshot</span>(<span class="hljs-params">self, snapshot_path</span>):<br>        loc = <span class="hljs-string">f&quot;cuda:<span class="hljs-subst">&#123;self.local_rank&#125;</span>&quot;</span><br>        snapshot = torch.load(snapshot_path, map_location=loc)<br>        <span class="hljs-variable language_">self</span>.model.load_state_dict(snapshot[<span class="hljs-string">&quot;MODEL_STATE&quot;</span>])<br>        <span class="hljs-variable language_">self</span>.epochs_run = snapshot[<span class="hljs-string">&quot;EPOCHS_RUN&quot;</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Resuming training from snapshot at Epoch <span class="hljs-subst">&#123;self.epochs_run&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_batch</span>(<span class="hljs-params">self, source, targets</span>):<br>        <span class="hljs-variable language_">self</span>.optimizer.zero_grad()<br>        output = <span class="hljs-variable language_">self</span>.model(source)<br>        loss = F.cross_entropy(output, targets)<br>        loss.backward()<br>        <span class="hljs-variable language_">self</span>.optimizer.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run_epoch</span>(<span class="hljs-params">self, epoch</span>):<br>        b_sz = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(<span class="hljs-variable language_">self</span>.train_data))[<span class="hljs-number">0</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[GPU<span class="hljs-subst">&#123;self.global_rank&#125;</span>] Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Batchsize: <span class="hljs-subst">&#123;b_sz&#125;</span> | Steps: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(self.train_data)&#125;</span>&quot;</span>) <span class="hljs-comment"># 打印日志时, 使用 global_rank 进行区分不同的 GPU 进程</span><br>        <span class="hljs-variable language_">self</span>.train_data.sampler.set_epoch(epoch)<br>        <span class="hljs-keyword">for</span> source, targets <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.train_data:<br>            source = source.to(<span class="hljs-variable language_">self</span>.local_rank)<br>            targets = targets.to(<span class="hljs-variable language_">self</span>.local_rank)<br>            <span class="hljs-variable language_">self</span>._run_batch(source, targets)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_save_snapshot</span>(<span class="hljs-params">self, epoch</span>):<br>        snapshot = &#123;<br>            <span class="hljs-string">&quot;MODEL_STATE&quot;</span>: <span class="hljs-variable language_">self</span>.model.module.state_dict(),<br>            <span class="hljs-string">&quot;EPOCHS_RUN&quot;</span>: epoch,<br>        &#125;<br>        torch.save(snapshot, <span class="hljs-variable language_">self</span>.snapshot_path)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch&#125;</span> | Training snapshot saved at <span class="hljs-subst">&#123;self.snapshot_path&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, max_epochs: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-variable language_">self</span>.epochs_run, max_epochs):<br>            <span class="hljs-variable language_">self</span>._run_epoch(epoch)<br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.global_rank == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> epoch % <span class="hljs-variable language_">self</span>.save_every == <span class="hljs-number">0</span>:<br>                <span class="hljs-variable language_">self</span>._save_snapshot(epoch)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_train_objs</span>():<br>    train_set = MyTrainDataset(<span class="hljs-number">2048</span>)  <span class="hljs-comment"># load your dataset</span><br>    model = torch.nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># load your model</span><br>    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>    <span class="hljs-keyword">return</span> train_set, model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>(<span class="hljs-params">dataset: Dataset, batch_size: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">return</span> DataLoader(<br>        dataset,<br>        batch_size=batch_size,<br>        pin_memory=<span class="hljs-literal">True</span>,<br>        shuffle=<span class="hljs-literal">False</span>,<br>        sampler=DistributedSampler(dataset)<br>    )<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">save_every: <span class="hljs-built_in">int</span>, total_epochs: <span class="hljs-built_in">int</span>, batch_size: <span class="hljs-built_in">int</span>, snapshot_path: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;snapshot.pt&quot;</span></span>):<br>    ddp_setup()<br>    dataset, model, optimizer = load_train_objs()<br>    train_data = prepare_dataloader(dataset, batch_size)<br>    trainer = Trainer(model, train_data, optimizer, save_every, snapshot_path)<br>    trainer.train(total_epochs)<br>    destroy_process_group()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> argparse<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;simple distributed training job&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;total_epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Total epochs to train the model&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;save_every&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;How often to save a snapshot&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch_size&#x27;</span>, default=<span class="hljs-number">32</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Input batch size on each device (default: 32)&#x27;</span>)<br>    args = parser.parse_args()<br><br>    main(args.save_every, args.total_epochs, args.batch_size)<br></code></pre></td></tr></table></figure>
<p>方案一: 在每台节点上手动单独运行 torchrun 命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 节点1</span><br>torchrun \<br>--proc_per_node=4 \  <span class="hljs-comment"># 这里的数字取决于每个节点上的 GPU 数量, 在不同的节点上的 GPU 数量可能不同</span><br>--nnodes=2 \ <span class="hljs-comment"># 节点总数</span><br>--node_rank=0 \ <span class="hljs-comment"># 当前节点编号</span><br>--rdzv_id=456 \ <span class="hljs-comment"># renderzvous 会合节点ID, 各节点相同</span><br>--rdzv_endpoint=172.31.43.139:29603 \ <span class="hljs-comment"># 会合节点的IP:端口, 各节点相同</span><br>multinode_torchrun.py 50 10<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 节点2</span><br>torchrun \<br>--proc_per_node=2 \ <span class="hljs-comment"># 当前节点只有 2 个 GPU</span><br>--nnodes=2 \ <span class="hljs-comment"># 节点总数</span><br>--node_rank=1 \ <span class="hljs-comment"># 当前节点编号</span><br>--rdzv_id=456 \ <span class="hljs-comment"># renderzvous 会合节点ID, 各节点相同</span><br>--rdzv_endpoint=172.31.43.139:29603 \ <span class="hljs-comment"># 会合节点的IP:端口, 各节点相同</span><br>multinode_torchrun.py 50 10<br></code></pre></td></tr></table></figure>
<p>方案二: 创建集群, 使用调度器</p>
<blockquote>
<p>不同云服务商有不同的创建集群的方法</p>
</blockquote>
<p>创建 slurm 脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-comment">#SBATCH --job-name=multinode-example</span><br><span class="hljs-comment">#SBATCH --nodes=4</span><br><span class="hljs-comment">#SBATCH --ntasks=4</span><br><span class="hljs-comment">#SBATCH --gpus-per-task=1</span><br><span class="hljs-comment">#SBATCH --cpus-per-task=4  # 多个 CPU 可以让数据加载变快一些</span><br><br>nodes=( $( scontrol show hostnames <span class="hljs-variable">$SLURM_JOB_NODELIST</span> ) )<br>nodes_array=(<span class="hljs-variable">$nodes</span>)<br>head_node=<span class="hljs-variable">$&#123;nodes_array[0]&#125;</span><br>head_node_ip=$(srun --nodes=1 --ntasks=1 -w <span class="hljs-string">&quot;<span class="hljs-variable">$head_node</span>&quot;</span> hostname --ip-address)<br><br><span class="hljs-built_in">echo</span> Node IP: <span class="hljs-variable">$head_node_ip</span><br><span class="hljs-built_in">export</span> LOGLEVEL=INFO<br><br>srun torchrun \<br>--nnodes 4 \<br>--nproc_per_node 1 \<br>--rdzv_id <span class="hljs-variable">$RANDOM</span> \<br>--rdzv_backend c10d \<br>--rdzv_endpoint <span class="hljs-variable">$head_node_ip</span>:29500 \<br>/shared/examples/multinode_torchrun.py 50 10<br></code></pre></td></tr></table></figure>
<p>运行脚本开始训练</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sbatch slurm/sbatch_run.sh<br></code></pre></td></tr></table></figure>
<blockquote>
<p>可使用 squeue 命令查看任务队列</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/pytorch/examples/blob/main/distributed/minGPT-ddp/README.md">使用 DDP 模式单机多卡或多机多卡训练 minGPT 的示例</a></p>
<p>DDP 的实现原理: 给模型的参数注册钩子, 在反向传播时, 将梯度同步到所有进程, 以便所有进程对应的模型的参数梯度值达成最终一致性, 这样各个进程在更新参数后的模型状态能够保持一致.</p>
<h3 id="%E5%A4%84%E7%90%86%E9%80%9F%E5%BA%A6%E5%B7%AE%E5%BC%82" tabindex="-1" id="处理速度差异">处理速度差异</h3>
<p>不同的进程的计算进度通常有先有后, 在数据同步时, 不同进程之间需要相互等待, 确保所有分片的数据完成同步后, 再进行下一步的计算. 因此需要设置一个足够大的 timeout 值, 避免有些进程在等待的过程中出现超时.</p>
<p>torch.distributed 库中有个 barrier() 方法可用来设置集合点, 确保所有进程到达该集合点后, 再进入下一步. 这样可以避免 A 进程还未保存模型数据, B 进程已经先加载数据并往下计算.</p>
<h3 id="%E7%BB%93%E5%90%88%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C" tabindex="-1" id="结合模型并行">结合模型并行</h3>
<p>Model Parallelism, 将模型的不同层放在不同的 GPU 上面, 不同 GPU 组成流水线；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ToyMpModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dev0, dev1</span>): <span class="hljs-comment"># 参数是两个 GPU</span><br>        <span class="hljs-built_in">super</span>(ToyMpModel, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.dev0 = dev0<br>        <span class="hljs-variable language_">self</span>.dev1 = dev1<br>        <span class="hljs-variable language_">self</span>.net1 = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>).to(dev0) <span class="hljs-comment"># 线性层1 在 dev0</span><br>        <span class="hljs-variable language_">self</span>.relu = torch.nn.ReLU()<br>        <span class="hljs-variable language_">self</span>.net2 = torch.nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>).to(dev1) <span class="hljs-comment"># 线性层2 在 dev1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.to(<span class="hljs-variable language_">self</span>.dev0) <span class="hljs-comment"># 复制输入到 dev0</span><br>        x = <span class="hljs-variable language_">self</span>.relu(<span class="hljs-variable language_">self</span>.net1(x))<br>        x = x.to(<span class="hljs-variable language_">self</span>.dev1) <span class="hljs-comment"># 复制上一层的输出到 dev1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.net2(x)<br></code></pre></td></tr></table></figure>
<h3 id="uneven-inputs" tabindex="-1" id="Uneven-Inputs">Uneven Inputs</h3>
<p>不同的 GPU 进程可能收到的 batch 大小不同, 出现不均衡的输入, 会导致不同的进程的迭代次数不一样.  此时某些进程可能提前完成计算, 但其他进程可能还在训练中. 如果让完成计算的进程退出, 会导致后续同步数据时, 其他进程一直处理等待的状态, 最终造成死锁.</p>
<p>为避免这个问题 torch.distributed.algorithms.join 库中引入了 Join 上下文管理器. 当某些进程提前完成数据的计算后, 会进入 join 模式. 在这个模式下, 该进程不会提前退出, 而是会假装仍在工作, 会继续参与数据同步的工作, 只是它发的梯度数据是零, 同时在 step 时也不会更新模型的参数. 直到所有进程都完成计算后, 整个上下文才会终止.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">import</span> torch.multiprocessing <span class="hljs-keyword">as</span> mp<br><span class="hljs-keyword">from</span> torch.distributed.algorithms.join <span class="hljs-keyword">import</span> Join<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><br>BACKEND = <span class="hljs-string">&quot;nccl&quot;</span><br>WORLD_SIZE = <span class="hljs-number">2</span><br>NUM_INPUTS = <span class="hljs-number">5</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">worker</span>(<span class="hljs-params">rank</span>):<br>    os.environ[<span class="hljs-string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="hljs-string">&#x27;localhost&#x27;</span><br>    os.environ[<span class="hljs-string">&#x27;MASTER_PORT&#x27;</span>] = <span class="hljs-string">&#x27;29500&#x27;</span><br>    dist.init_process_group(BACKEND, rank=rank, world_size=WORLD_SIZE)<br><br>    model = DDP(torch.nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(rank), device_ids=[rank])<br>    <span class="hljs-comment"># Rank 1 比 rank 0 多一个输入, 模拟输入不平衡的场景</span><br>    inputs = [torch.tensor([<span class="hljs-number">1</span>]).<span class="hljs-built_in">float</span>() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_INPUTS + rank)]<br><br>    num_inputs = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> Join([model]): <span class="hljs-comment"># 使用 Join 管理上下文</span><br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> inputs:<br>            num_inputs += <span class="hljs-number">1</span><br>            loss = model(<span class="hljs-built_in">input</span>).<span class="hljs-built_in">sum</span>()<br>            loss.backward()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rank <span class="hljs-subst">&#123;rank&#125;</span> has exhausted all <span class="hljs-subst">&#123;num_inputs&#125;</span> of its inputs!&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    mp.spawn(worker, nprocs=WORLD_SIZE, join=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>
<p>Join 还可以同时管理多个类, 例如 ZeroRedundancyOptimizer, 示例如下:</p>
<blockquote>
<p>ZeroRedundancyOptimizer 用来给优化器进行分片, 这样优化器的数据也可以像梯度一样是分布式的, 好处是可以减少单个 GPU 的内存占用, 等实际需要使用时, 多个 GPU 之间再进行同步即可. 缺点是需要付出一点数据同步的时间. 以时间换空间</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.distributed.optim <span class="hljs-keyword">import</span> ZeroRedundancyOptimizer <span class="hljs-keyword">as</span> ZeRO<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">worker</span>(<span class="hljs-params">rank</span>):<br>    os.environ[<span class="hljs-string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="hljs-string">&#x27;localhost&#x27;</span><br>    os.environ[<span class="hljs-string">&#x27;MASTER_PORT&#x27;</span>] = <span class="hljs-string">&#x27;29500&#x27;</span><br>    dist.init_process_group(BACKEND, rank=rank, world_size=WORLD_SIZE)<br><br>    model = DDP(torch.nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(rank), device_ids=[rank])<br>    optim = ZeRO(model.parameters(), Adam, lr=<span class="hljs-number">0.01</span>) <span class="hljs-comment"># 使用 ZeroRedundancyOptimizer</span><br>    <span class="hljs-comment"># Rank 1 比 rank 0 多一个输入, 模拟输入不平衡的场景</span><br>    inputs = [torch.tensor([<span class="hljs-number">1</span>]).<span class="hljs-built_in">float</span>() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_INPUTS + rank)]<br><br>    num_inputs = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> Join([model, optim]): <span class="hljs-comment"># 优化器和模型一起 Join</span><br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> inputs:<br>            num_inputs += <span class="hljs-number">1</span><br>            loss = model(<span class="hljs-built_in">input</span>).<span class="hljs-built_in">sum</span>()<br>            loss.backward()<br>            optim.step()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rank <span class="hljs-subst">&#123;rank&#125;</span> has exhausted all <span class="hljs-subst">&#123;num_inputs&#125;</span> of its inputs!&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>Join 支持传入一些参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 传入 divide_by_initial_world_size 参数</span><br><span class="hljs-keyword">with</span> Join([model, optim], divide_by_initial_world_size=<span class="hljs-literal">False</span>):<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> inputs:<br>        ...<br></code></pre></td></tr></table></figure>
<h2 id="fsdp2" tabindex="-1" id="FSDP2">FSDP2</h2>
<p>Fully Sharded Data Parallel, 全分片数据并行. DDP 只是训练数据分片,  FSDP 则更进一步, 连模型参数, 优化器状态都进行分片, 这样做的好处是可以减少单个 GPU 的内存容量要求.</p>
<p>由于 FSDP 将模型的参数也分片了, 因此相比 DDP, 它不仅要同步梯度, 还多了一个同步参数的动作. 即每个 GPU 需要先all-gather 动态的收集其他 GPU 上面的参数, 基于完整的模型参数计算出结果后, 再释放掉内存, 只保留自己所负责的那部分参数. 所以从结果上来看, 每个 GPU 上面的模型参数好像是完整的, 但实际上这种完整是一种临时拼凑的状态，是一种逻辑上的完整，而不是物理上的完整. 计算结束后, 实际保存的仍然只是一个参数分片.</p>
<blockquote>
<p>FSDP 或许可视为一种更加激进的分片策略, 通过极致的以时间换空间, 进一步压榨 GPU 显存</p>
</blockquote>
<h3 id="%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96" tabindex="-1" id="模型初始化">模型初始化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.distributed.fsdp <span class="hljs-keyword">import</span> fully_shard, FSDPModule<br><br>model = Transformer()<br><br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> model.layers:<br>    fully_shard(layer) <span class="hljs-comment"># 模型的每一层都要 fully_shard 进行分片</span><br>    <br>fully_shard(model) <span class="hljs-comment"># 最后模型也要分片 fully_shard</span><br><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(model, Transformer)<br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(model, FSDPModule)<br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-comment">#  FSDPTransformer(</span><br><span class="hljs-comment">#    (tok_embeddings): Embedding(...)</span><br><span class="hljs-comment">#    ...</span><br><span class="hljs-comment">#    (layers): 3 x FSDPTransformerBlock(...)</span><br><span class="hljs-comment">#    (output): Linear(...)</span><br><span class="hljs-comment">#  )</span><br></code></pre></td></tr></table></figure>
<p>fully_shard 会将模型的参数由 Tensor 转成 DTensor 类型(一种数据抽象), 用来表示它是做了分片的参数. DTensor 有助于简化各项操作的逻辑, 减少手动处理这些分片数据的同步工作.</p>
<p>FSDP2 在参数的第一个维度上进行分片, 因此第一维的数量需要是 world size 的倍数, 否则无法均匀分片. 此时 FSDP 默认会报错.</p>
<p>由于 FSDP2 模式下参数是分片的, 因此在保存模型时, 可以借助 DCP（Distributed Checkpointing）实现分布式保存. 每个  GPU 进程只保存自己的那部分参数, 这样可以减少通讯成本. 后续加载参数时, 每个 GPU 也可以只加载自己负责的那部分参数.</p>
<h3 id="%E5%89%8D%E5%90%91%2F%E5%90%8E%E5%90%91%E9%A2%84%E5%8F%96" tabindex="-1" id="前向-后向预取">前向/后向预取</h3>
<p>由于模型参数是分片, 计算前需要实时 all-gather 聚合, 这样就涉及了通信的时间. 理想情况下让计算和通信同时进行, 这样计算的时候,不用等待通信. 有两种实现的方案:</p>
<ul>
<li>隐式预取: 在计算当前层的时候, 后台自动偷偷 all-gather 预取下一个 layer 或 block 所需的参数.</li>
<li>显式预取: 手动控制什么时候预取参数, 好处是非常灵活, 一般有以下几种使用场景:
<ul>
<li>隐式只预取一层, 显式则可以预取多层, 好处是减少等待的发生, 缺点是占用多一些内存空间；</li>
<li>预热: 在调用  model(x) 之前先预取, 这样调用 model 后直接开算, 不用等待；</li>
<li>CPU 工作负载过高, 没有及时发出预取指令, 造成空闲等待, 因此只能手动完成；</li>
</ul>
</li>
</ul>
<p>以下是隐式预取的图示:</p>
<p><img src="https://lhwccw.oss-cn-shenzhen.aliyuncs.com/20251214210527.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>以下是显式预取的代码示例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">num_to_forward_prefetch = <span class="hljs-number">2</span><br><span class="hljs-keyword">for</span> i, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(model.layers):<br>    <span class="hljs-keyword">if</span> i &gt;= <span class="hljs-built_in">len</span>(model.layers) - num_to_forward_prefetch:<br>        <span class="hljs-keyword">break</span><br>    layers_to_prefetch = [<br>        model.layers[i + j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_to_forward_prefetch + <span class="hljs-number">1</span>)<br>    ]<br>    layer.set_modules_to_forward_prefetch(layers_to_prefetch) <span class="hljs-comment"># 前向预取</span><br><br>num_to_backward_prefetch = <span class="hljs-number">2</span><br><span class="hljs-keyword">for</span> i, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(model.layers):<br>    <span class="hljs-keyword">if</span> i &lt; num_to_backward_prefetch:<br>        <span class="hljs-keyword">continue</span><br>    layers_to_prefetch = [<br>        model.layers[i - j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_to_backward_prefetch + <span class="hljs-number">1</span>)<br>    ]<br>    layer.set_modules_to_backward_prefetch(layers_to_prefetch) <span class="hljs-comment"># 后向预取</span><br><br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    model.unshard() <span class="hljs-comment"># 手动触发一次 all-gather, 减少后续 GPU 的等待时间, 正常 unshard 是隐式触发的</span><br>    x = torch.randint(<span class="hljs-number">0</span>, vocab_size, (batch_size, seq_len), device=device)<br>    loss = model(x).<span class="hljs-built_in">sum</span>()<br>    loss.backward()<br>    optim.step()<br>    optim.zero_grad()<br></code></pre></td></tr></table></figure>
<h3 id="%E5%BC%80%E5%90%AF%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6" tabindex="-1" id="开启混合精度">开启混合精度</h3>
<p>FSDP2 支持灵活的混合精度策略, 以便提高训练的速度. 典型用法示例:</p>
<ul>
<li>在前向和后向传播将默认的 float32 转成 bfloat16 类型, 这样可以节省显存占用；</li>
<li>做梯度聚合时, 将 bfloat16 类型转回 float32, 以便提高梯度计算的精度, 避免误差可能带来的发散；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">model = Transformer(model_args)<br><span class="hljs-comment"># 混合精度策略</span><br>fsdp_kwargs = &#123;<br>    <span class="hljs-string">&quot;mp_policy&quot;</span>: MixedPrecisionPolicy( <br>        param_dtype=torch.bfloat16, <span class="hljs-comment"># 参数用 bfloat16</span><br>        reduce_dtype=torch.float32, <span class="hljs-comment"># 梯度聚合用 float32</span><br>    )<br>&#125;<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> model.layers:<br>    fully_shard(layer, **fsdp_kwargs) <span class="hljs-comment"># 传递策略参数</span><br>fully_shard(model, **fsdp_kwargs) <span class="hljs-comment"># 传递策略参数</span><br><br><span class="hljs-comment"># sharded parameters are float32</span><br><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters():<br>    <span class="hljs-keyword">assert</span> param.dtype == torch.float32<br><br><span class="hljs-comment"># unsharded parameters are bfloat16</span><br>model.unshard()<br><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters(recurse=<span class="hljs-literal">False</span>):<br>    <span class="hljs-keyword">assert</span> param.dtype == torch.bfloat16<br>model.reshard()<br><br><span class="hljs-comment"># 优化器使用默认的 float32</span><br>optim = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">1e-2</span>)<br><br><span class="hljs-comment"># training loop</span><br><span class="hljs-comment"># ...</span><br></code></pre></td></tr></table></figure>
<h3 id="%E6%A2%AF%E5%BA%A6%E8%A3%81%E5%89%AA%E4%B8%8E%E5%9F%BA%E4%BA%8E-dtensor-%E7%9A%84%E4%BC%98%E5%8C%96%E5%99%A8" tabindex="-1" id="梯度裁剪与基于-DTensor-的优化器">梯度裁剪与基于 DTensor 的优化器</h3>
<p>在 full_shard 模型后, 再初始化优化器, 以便优化器能够正确跟踪分布在不同 GPU 上面的参数分片.</p>
<p>参数分片后的包装类型是 DTensor, 它默认支持梯度裁剪. 梯度裁剪涉及计算范数, 此时需要先聚合梯度. DTensor 会自动拦截各种张量 Tensor 的正常操作, 然后在需要时会自动完成通信聚合的相关工作, 对用户来说是透明的.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%B7%A5%E5%85%B7/" class="category-chain-item">工具</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#深度学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>PyTorch</div>
      <div>https://ccw1078.github.io/2025/12/13/Pytorch/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ccw</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年12月13日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/11/08/LangChain%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" title="LangChain 大模型应用开发">
                        <span class="hidden-mobile">LangChain 大模型应用开发</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
